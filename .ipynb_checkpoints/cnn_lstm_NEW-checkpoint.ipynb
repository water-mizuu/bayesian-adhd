{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "181da2fc-dae6-4638-8d23-8214b7560c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "import time\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import Adam, RMSprop, SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af714077-585f-4de6-b357-1e50dc4993ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (6623, 77, 19, 1)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"./processed_adhdata.csv\")\n",
    "df['Class'] = LabelEncoder().fit_transform(df['Class'])  # ADHD->1, Control->0\n",
    "\n",
    "frequency_count = len(df['Frequency'].unique())\n",
    "window_count = len(df['Window'].unique())\n",
    "numeric_df = df.drop(['ID', 'Window'], axis=1)\n",
    "\n",
    "# shape: (windows, freqs, features)\n",
    "full_ndarray = numeric_df.values.reshape((window_count, frequency_count, numeric_df.shape[1]))\n",
    "\n",
    "X = full_ndarray[:, :, 2:]     # drop ID/Class columns\n",
    "y = full_ndarray[:, 0, 0]      # class label is repeated across freq rows\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y)\n",
    "\n",
    "# Add channel dimension (N, 1, freq, electrodes)\n",
    "X_train = X_train[..., np.newaxis]   # (N, freq, electrodes, 1)\n",
    "X_test  = X_test[...,  np.newaxis]\n",
    "\n",
    "# Standardize across the entire dataset\n",
    "scaler = StandardScaler()\n",
    "X_train_flat = X_train.reshape(-1, X_train.shape[-1])\n",
    "X_test_flat  = X_test.reshape(-1, X_test.shape[-1])\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train_flat)\n",
    "X_test_scaled  = scaler.transform(X_test_flat)\n",
    "\n",
    "X_train = X_train_scaled.reshape(X_train.shape)\n",
    "X_test  = X_test_scaled.reshape(X_test.shape)\n",
    "\n",
    "print(\"Train shape:\", X_train.shape)  # (N, freq, electrodes, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2595397-63c0-4fd7-9f9a-4242370f5bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EEGDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32).permute(0, 3, 1, 2)  \n",
    "        # -> (N, 1, freq, electrodes)\n",
    "        self.y = torch.tensor(y, dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "train_ds = EEGDataset(X_train, y_train)\n",
    "test_ds  = EEGDataset(X_test,  y_test)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=36, shuffle=True)\n",
    "test_loader  = DataLoader(test_ds, batch_size=36, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3e658ff5-0dd2-4898-9f4a-d71d0cc79bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "class EEG_CNN_LSTM(nn.Module):\n",
    "    \"\"\"\n",
    "    CNN -> LSTM -> FC\n",
    "    Input: (N, 1, freq, electrodes)\n",
    "    \"\"\"\n",
    "    def __init__(self, lstm_hidden=64, lstm_layers=2, dropout=0.3, num_classes=2):\n",
    "        super().__init__()\n",
    "\n",
    "        # --- CNN feature extractor ---\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
    "        self.pool1 = nn.AvgPool2d(2)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.pool2 = nn.AvgPool2d(2)\n",
    "\n",
    "        # Determine flattened feature size after CNN\n",
    "        with torch.no_grad():\n",
    "            dummy = torch.zeros(1, 1, X_train.shape[1], X_train.shape[2])\n",
    "            out = self._forward_cnn(dummy)\n",
    "            # We'll treat the *width* dimension as sequence length\n",
    "            # and flatten channels*height as LSTM input_size\n",
    "            self.seq_len = out.size(-1)\n",
    "            self.feature_dim = out.size(1) * out.size(2)   # (channels * height)\n",
    "\n",
    "        # --- LSTM ---\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=self.feature_dim,\n",
    "            hidden_size=lstm_hidden,\n",
    "            num_layers=lstm_layers,\n",
    "            batch_first=True,\n",
    "            dropout=dropout if lstm_layers > 1 else 0.0\n",
    "        )\n",
    "\n",
    "        # --- Classifier ---\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(lstm_hidden, num_classes)\n",
    "        )\n",
    "\n",
    "    def _forward_cnn(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool1(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool2(x)\n",
    "        return x  # (N, C, H, W)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # CNN extraction\n",
    "        x = self._forward_cnn(x)           # (N, C, H, W)\n",
    "\n",
    "        # Prepare for LSTM: treat W as sequence length\n",
    "        x = x.permute(0, 3, 1, 2)          # (N, W, C, H)\n",
    "        x = x.reshape(x.size(0), x.size(1), -1)  # (N, seq_len=W, feature_dim=C*H)\n",
    "\n",
    "        # LSTM\n",
    "        _, (h_n, _) = self.lstm(x)\n",
    "        out = h_n[-1]                      # last layer hidden state\n",
    "\n",
    "        # Classification\n",
    "        return self.fc(out)\n",
    "\n",
    "    def fit(self, train_loader, val_loader, epochs, criterion, optimizer,\n",
    "            device=\"cpu\", patience=30):\n",
    "        best_val_loss = float('inf')\n",
    "        no_improve = 0\n",
    "        best_state = None\n",
    "\n",
    "        train_losses, val_losses = [], []\n",
    "        train_accs,  val_accs  = [], []\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            # ---- Train ----\n",
    "            self.train()\n",
    "            train_loss, train_correct = 0.0, 0\n",
    "            for xb, yb in train_loader:\n",
    "                xb, yb = xb.to(device), yb.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                out = self(xb)\n",
    "                loss = criterion(out, yb)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                train_loss += loss.item() * xb.size(0)\n",
    "                train_correct += (out.argmax(1) == yb).sum().item()\n",
    "\n",
    "            train_loss /= len(train_loader.dataset)\n",
    "            train_acc  = train_correct / len(train_loader.dataset)\n",
    "            train_losses.append(train_loss)\n",
    "            train_accs.append(train_acc)\n",
    "\n",
    "            # ---- Validate ----\n",
    "            self.eval()\n",
    "            val_loss, val_correct = 0.0, 0\n",
    "            with torch.no_grad():\n",
    "                for xb, yb in val_loader:\n",
    "                    xb, yb = xb.to(device), yb.to(device)\n",
    "                    out = self(xb)\n",
    "                    loss = criterion(out, yb)\n",
    "                    val_loss += loss.item() * xb.size(0)\n",
    "                    val_correct += (out.argmax(1) == yb).sum().item()\n",
    "\n",
    "            val_loss /= len(val_loader.dataset)\n",
    "            val_acc  = val_correct / len(val_loader.dataset)\n",
    "            val_losses.append(val_loss)\n",
    "            val_accs.append(val_acc)\n",
    "\n",
    "            print(f\"Epoch {epoch+1:03d} | \"\n",
    "                  f\"Train Loss: {train_loss:.4f} Acc: {train_acc:.4f} | \"\n",
    "                  f\"Val Loss: {val_loss:.4f} Acc: {val_acc:.4f}\")\n",
    "\n",
    "            if val_loss - train_loss > 0.3:\n",
    "                print(\"Overfitting detected\")\n",
    "                break\n",
    "            \n",
    "            # Early stopping\n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                best_state = self.state_dict()\n",
    "                no_improve = 0\n",
    "            else:\n",
    "                no_improve += 1\n",
    "                if no_improve >= patience:\n",
    "                    print(\"Early stopping triggered.\")\n",
    "                    break\n",
    "\n",
    "        if best_state:\n",
    "            self.load_state_dict(best_state)\n",
    "\n",
    "        return {\n",
    "            \"train_losses\": np.array(train_losses),\n",
    "            \"val_losses\":   np.array(val_losses),\n",
    "            \"train_accs\":   np.array(train_accs),\n",
    "            \"val_accs\":     np.array(val_accs)\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "66da3aeb-8c19-4073-a7c9-c72b8506bf09",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001 | Train Loss: 0.6778 Acc: 0.5851 | Val Loss: 0.6774 Acc: 0.5882\n",
      "Epoch 002 | Train Loss: 0.6746 Acc: 0.5904 | Val Loss: 0.6756 Acc: 0.5876\n",
      "Epoch 003 | Train Loss: 0.6726 Acc: 0.5929 | Val Loss: 0.6735 Acc: 0.5924\n",
      "Epoch 004 | Train Loss: 0.6687 Acc: 0.5953 | Val Loss: 0.6719 Acc: 0.5894\n",
      "Epoch 005 | Train Loss: 0.6677 Acc: 0.6008 | Val Loss: 0.6697 Acc: 0.5948\n",
      "Epoch 006 | Train Loss: 0.6639 Acc: 0.6024 | Val Loss: 0.6667 Acc: 0.5954\n",
      "Epoch 007 | Train Loss: 0.6596 Acc: 0.6064 | Val Loss: 0.6638 Acc: 0.5996\n",
      "Epoch 008 | Train Loss: 0.6553 Acc: 0.6083 | Val Loss: 0.6607 Acc: 0.5978\n",
      "Epoch 009 | Train Loss: 0.6512 Acc: 0.6145 | Val Loss: 0.6526 Acc: 0.6021\n",
      "Epoch 010 | Train Loss: 0.6468 Acc: 0.6233 | Val Loss: 0.6514 Acc: 0.6021\n",
      "Epoch 011 | Train Loss: 0.6410 Acc: 0.6346 | Val Loss: 0.6400 Acc: 0.6564\n",
      "Epoch 012 | Train Loss: 0.6338 Acc: 0.6486 | Val Loss: 0.6322 Acc: 0.6781\n",
      "Epoch 013 | Train Loss: 0.6264 Acc: 0.6508 | Val Loss: 0.6258 Acc: 0.6691\n",
      "Epoch 014 | Train Loss: 0.6267 Acc: 0.6650 | Val Loss: 0.6202 Acc: 0.6806\n",
      "Epoch 015 | Train Loss: 0.6175 Acc: 0.6787 | Val Loss: 0.6230 Acc: 0.6588\n",
      "Epoch 016 | Train Loss: 0.6173 Acc: 0.6721 | Val Loss: 0.6153 Acc: 0.6860\n",
      "Epoch 017 | Train Loss: 0.6134 Acc: 0.6810 | Val Loss: 0.6254 Acc: 0.6570\n",
      "Epoch 018 | Train Loss: 0.6061 Acc: 0.6796 | Val Loss: 0.6068 Acc: 0.6860\n",
      "Epoch 019 | Train Loss: 0.6058 Acc: 0.6823 | Val Loss: 0.6042 Acc: 0.6763\n",
      "Epoch 020 | Train Loss: 0.6010 Acc: 0.6879 | Val Loss: 0.6029 Acc: 0.6920\n",
      "Epoch 021 | Train Loss: 0.6003 Acc: 0.6932 | Val Loss: 0.6265 Acc: 0.6667\n",
      "Epoch 022 | Train Loss: 0.5973 Acc: 0.6882 | Val Loss: 0.5976 Acc: 0.6769\n",
      "Epoch 023 | Train Loss: 0.5962 Acc: 0.6942 | Val Loss: 0.5943 Acc: 0.6957\n",
      "Epoch 024 | Train Loss: 0.5900 Acc: 0.6958 | Val Loss: 0.5900 Acc: 0.6950\n",
      "Epoch 025 | Train Loss: 0.5849 Acc: 0.7060 | Val Loss: 0.5859 Acc: 0.6975\n",
      "Epoch 026 | Train Loss: 0.5855 Acc: 0.6997 | Val Loss: 0.5863 Acc: 0.7035\n",
      "Epoch 027 | Train Loss: 0.5817 Acc: 0.7035 | Val Loss: 0.5847 Acc: 0.7005\n",
      "Epoch 028 | Train Loss: 0.5800 Acc: 0.7038 | Val Loss: 0.5828 Acc: 0.6975\n",
      "Epoch 029 | Train Loss: 0.5757 Acc: 0.7033 | Val Loss: 0.5873 Acc: 0.7023\n",
      "Epoch 030 | Train Loss: 0.5726 Acc: 0.7145 | Val Loss: 0.5804 Acc: 0.6842\n",
      "Epoch 031 | Train Loss: 0.5721 Acc: 0.7093 | Val Loss: 0.5749 Acc: 0.7107\n",
      "Epoch 032 | Train Loss: 0.5690 Acc: 0.7118 | Val Loss: 0.5723 Acc: 0.7156\n",
      "Epoch 033 | Train Loss: 0.5673 Acc: 0.7154 | Val Loss: 0.5809 Acc: 0.7138\n",
      "Epoch 034 | Train Loss: 0.5632 Acc: 0.7154 | Val Loss: 0.5661 Acc: 0.7077\n",
      "Epoch 035 | Train Loss: 0.5624 Acc: 0.7143 | Val Loss: 0.5671 Acc: 0.7204\n",
      "Epoch 036 | Train Loss: 0.5528 Acc: 0.7193 | Val Loss: 0.5689 Acc: 0.7041\n",
      "Epoch 037 | Train Loss: 0.5532 Acc: 0.7223 | Val Loss: 0.5614 Acc: 0.7228\n",
      "Epoch 038 | Train Loss: 0.5525 Acc: 0.7219 | Val Loss: 0.5584 Acc: 0.7162\n",
      "Epoch 039 | Train Loss: 0.5519 Acc: 0.7279 | Val Loss: 0.5699 Acc: 0.7029\n",
      "Epoch 040 | Train Loss: 0.5483 Acc: 0.7269 | Val Loss: 0.5589 Acc: 0.7168\n",
      "Epoch 041 | Train Loss: 0.5479 Acc: 0.7238 | Val Loss: 0.5747 Acc: 0.7174\n",
      "Epoch 042 | Train Loss: 0.5475 Acc: 0.7275 | Val Loss: 0.5532 Acc: 0.7107\n",
      "Epoch 043 | Train Loss: 0.5384 Acc: 0.7334 | Val Loss: 0.5607 Acc: 0.7210\n",
      "Epoch 044 | Train Loss: 0.5396 Acc: 0.7335 | Val Loss: 0.5579 Acc: 0.7077\n",
      "Epoch 045 | Train Loss: 0.5375 Acc: 0.7284 | Val Loss: 0.5786 Acc: 0.7216\n",
      "Epoch 046 | Train Loss: 0.5340 Acc: 0.7362 | Val Loss: 0.5553 Acc: 0.7132\n",
      "Epoch 047 | Train Loss: 0.5337 Acc: 0.7364 | Val Loss: 0.5593 Acc: 0.7053\n",
      "Epoch 048 | Train Loss: 0.5272 Acc: 0.7408 | Val Loss: 0.5528 Acc: 0.7144\n",
      "Epoch 049 | Train Loss: 0.5276 Acc: 0.7403 | Val Loss: 0.5583 Acc: 0.7114\n",
      "Epoch 050 | Train Loss: 0.5249 Acc: 0.7395 | Val Loss: 0.5463 Acc: 0.7301\n",
      "Epoch 051 | Train Loss: 0.5256 Acc: 0.7401 | Val Loss: 0.5705 Acc: 0.7234\n",
      "Epoch 052 | Train Loss: 0.5204 Acc: 0.7471 | Val Loss: 0.5533 Acc: 0.7089\n",
      "Epoch 053 | Train Loss: 0.5213 Acc: 0.7486 | Val Loss: 0.5337 Acc: 0.7307\n",
      "Epoch 054 | Train Loss: 0.5149 Acc: 0.7468 | Val Loss: 0.5347 Acc: 0.7325\n",
      "Epoch 055 | Train Loss: 0.5164 Acc: 0.7495 | Val Loss: 0.5394 Acc: 0.7325\n",
      "Epoch 056 | Train Loss: 0.5168 Acc: 0.7436 | Val Loss: 0.5296 Acc: 0.7391\n",
      "Epoch 057 | Train Loss: 0.5131 Acc: 0.7519 | Val Loss: 0.5576 Acc: 0.7234\n",
      "Epoch 058 | Train Loss: 0.5089 Acc: 0.7542 | Val Loss: 0.5289 Acc: 0.7355\n",
      "Epoch 059 | Train Loss: 0.5108 Acc: 0.7501 | Val Loss: 0.5319 Acc: 0.7258\n",
      "Epoch 060 | Train Loss: 0.5045 Acc: 0.7619 | Val Loss: 0.5312 Acc: 0.7373\n",
      "Epoch 061 | Train Loss: 0.5057 Acc: 0.7524 | Val Loss: 0.5247 Acc: 0.7403\n",
      "Epoch 062 | Train Loss: 0.5011 Acc: 0.7604 | Val Loss: 0.5564 Acc: 0.7240\n",
      "Epoch 063 | Train Loss: 0.5010 Acc: 0.7575 | Val Loss: 0.5319 Acc: 0.7397\n",
      "Epoch 064 | Train Loss: 0.4991 Acc: 0.7537 | Val Loss: 0.5203 Acc: 0.7409\n",
      "Epoch 065 | Train Loss: 0.4961 Acc: 0.7610 | Val Loss: 0.5264 Acc: 0.7403\n",
      "Epoch 066 | Train Loss: 0.4943 Acc: 0.7605 | Val Loss: 0.5213 Acc: 0.7361\n",
      "Epoch 067 | Train Loss: 0.4971 Acc: 0.7598 | Val Loss: 0.5144 Acc: 0.7542\n",
      "Epoch 068 | Train Loss: 0.4888 Acc: 0.7631 | Val Loss: 0.5235 Acc: 0.7482\n",
      "Epoch 069 | Train Loss: 0.4872 Acc: 0.7699 | Val Loss: 0.5205 Acc: 0.7482\n",
      "Epoch 070 | Train Loss: 0.4843 Acc: 0.7670 | Val Loss: 0.5240 Acc: 0.7325\n",
      "Epoch 071 | Train Loss: 0.4878 Acc: 0.7658 | Val Loss: 0.5214 Acc: 0.7409\n",
      "Epoch 072 | Train Loss: 0.4799 Acc: 0.7723 | Val Loss: 0.5369 Acc: 0.7367\n",
      "Epoch 073 | Train Loss: 0.4795 Acc: 0.7750 | Val Loss: 0.5004 Acc: 0.7488\n",
      "Epoch 074 | Train Loss: 0.4778 Acc: 0.7752 | Val Loss: 0.5204 Acc: 0.7325\n",
      "Epoch 075 | Train Loss: 0.4770 Acc: 0.7762 | Val Loss: 0.5188 Acc: 0.7494\n",
      "Epoch 076 | Train Loss: 0.4732 Acc: 0.7764 | Val Loss: 0.5178 Acc: 0.7325\n",
      "Epoch 077 | Train Loss: 0.4715 Acc: 0.7740 | Val Loss: 0.4921 Acc: 0.7597\n",
      "Epoch 078 | Train Loss: 0.4679 Acc: 0.7811 | Val Loss: 0.4992 Acc: 0.7506\n",
      "Epoch 079 | Train Loss: 0.4691 Acc: 0.7812 | Val Loss: 0.5500 Acc: 0.7319\n",
      "Epoch 080 | Train Loss: 0.4656 Acc: 0.7790 | Val Loss: 0.4914 Acc: 0.7609\n",
      "Epoch 081 | Train Loss: 0.4637 Acc: 0.7794 | Val Loss: 0.4880 Acc: 0.7639\n",
      "Epoch 082 | Train Loss: 0.4632 Acc: 0.7824 | Val Loss: 0.4967 Acc: 0.7464\n",
      "Epoch 083 | Train Loss: 0.4571 Acc: 0.7812 | Val Loss: 0.4809 Acc: 0.7693\n",
      "Epoch 084 | Train Loss: 0.4580 Acc: 0.7853 | Val Loss: 0.5564 Acc: 0.7041\n",
      "Epoch 085 | Train Loss: 0.4553 Acc: 0.7823 | Val Loss: 0.4764 Acc: 0.7633\n",
      "Epoch 086 | Train Loss: 0.4518 Acc: 0.7894 | Val Loss: 0.4781 Acc: 0.7615\n",
      "Epoch 087 | Train Loss: 0.4489 Acc: 0.7865 | Val Loss: 0.4748 Acc: 0.7705\n",
      "Epoch 088 | Train Loss: 0.4507 Acc: 0.7833 | Val Loss: 0.4788 Acc: 0.7675\n",
      "Epoch 089 | Train Loss: 0.4480 Acc: 0.7838 | Val Loss: 0.5023 Acc: 0.7591\n",
      "Epoch 090 | Train Loss: 0.4428 Acc: 0.7913 | Val Loss: 0.4659 Acc: 0.7760\n",
      "Epoch 091 | Train Loss: 0.4379 Acc: 0.7987 | Val Loss: 0.4661 Acc: 0.7723\n",
      "Epoch 092 | Train Loss: 0.4464 Acc: 0.7913 | Val Loss: 0.4712 Acc: 0.7711\n",
      "Epoch 093 | Train Loss: 0.4364 Acc: 0.7953 | Val Loss: 0.4833 Acc: 0.7645\n",
      "Epoch 094 | Train Loss: 0.4379 Acc: 0.7931 | Val Loss: 0.5040 Acc: 0.7421\n",
      "Epoch 095 | Train Loss: 0.4377 Acc: 0.7950 | Val Loss: 0.4646 Acc: 0.7778\n",
      "Epoch 096 | Train Loss: 0.4337 Acc: 0.7947 | Val Loss: 0.4715 Acc: 0.7681\n",
      "Epoch 097 | Train Loss: 0.4275 Acc: 0.7989 | Val Loss: 0.4621 Acc: 0.7736\n",
      "Epoch 098 | Train Loss: 0.4292 Acc: 0.7993 | Val Loss: 0.4615 Acc: 0.7748\n",
      "Epoch 099 | Train Loss: 0.4238 Acc: 0.8016 | Val Loss: 0.4597 Acc: 0.7772\n",
      "Epoch 100 | Train Loss: 0.4260 Acc: 0.8021 | Val Loss: 0.4500 Acc: 0.7790\n",
      "Epoch 101 | Train Loss: 0.4243 Acc: 0.7993 | Val Loss: 0.4587 Acc: 0.7754\n",
      "Epoch 102 | Train Loss: 0.4234 Acc: 0.8002 | Val Loss: 0.4509 Acc: 0.7899\n",
      "Epoch 103 | Train Loss: 0.4179 Acc: 0.8052 | Val Loss: 0.4574 Acc: 0.7717\n",
      "Epoch 104 | Train Loss: 0.4219 Acc: 0.8046 | Val Loss: 0.4415 Acc: 0.7874\n",
      "Epoch 105 | Train Loss: 0.4155 Acc: 0.8067 | Val Loss: 0.4742 Acc: 0.7548\n",
      "Epoch 106 | Train Loss: 0.4200 Acc: 0.8043 | Val Loss: 0.4690 Acc: 0.7669\n",
      "Epoch 107 | Train Loss: 0.4142 Acc: 0.8058 | Val Loss: 0.4485 Acc: 0.7856\n",
      "Epoch 108 | Train Loss: 0.4119 Acc: 0.8110 | Val Loss: 0.4789 Acc: 0.7603\n",
      "Epoch 109 | Train Loss: 0.4089 Acc: 0.8128 | Val Loss: 0.4345 Acc: 0.7905\n",
      "Epoch 110 | Train Loss: 0.4065 Acc: 0.8131 | Val Loss: 0.4465 Acc: 0.7862\n",
      "Epoch 111 | Train Loss: 0.4070 Acc: 0.8132 | Val Loss: 0.4487 Acc: 0.7808\n",
      "Epoch 112 | Train Loss: 0.4025 Acc: 0.8170 | Val Loss: 0.4421 Acc: 0.7905\n",
      "Epoch 113 | Train Loss: 0.3996 Acc: 0.8172 | Val Loss: 0.4424 Acc: 0.7772\n",
      "Epoch 114 | Train Loss: 0.4051 Acc: 0.8146 | Val Loss: 0.4308 Acc: 0.7905\n",
      "Epoch 115 | Train Loss: 0.3939 Acc: 0.8185 | Val Loss: 0.4593 Acc: 0.7717\n",
      "Epoch 116 | Train Loss: 0.3981 Acc: 0.8146 | Val Loss: 0.4615 Acc: 0.7705\n",
      "Epoch 117 | Train Loss: 0.3962 Acc: 0.8172 | Val Loss: 0.4203 Acc: 0.8007\n",
      "Epoch 118 | Train Loss: 0.3900 Acc: 0.8268 | Val Loss: 0.4260 Acc: 0.7917\n",
      "Epoch 119 | Train Loss: 0.3928 Acc: 0.8238 | Val Loss: 0.4212 Acc: 0.7953\n",
      "Epoch 120 | Train Loss: 0.3888 Acc: 0.8208 | Val Loss: 0.4556 Acc: 0.7772\n",
      "Epoch 121 | Train Loss: 0.3866 Acc: 0.8220 | Val Loss: 0.4205 Acc: 0.8007\n",
      "Epoch 122 | Train Loss: 0.3860 Acc: 0.8256 | Val Loss: 0.4125 Acc: 0.7977\n",
      "Epoch 123 | Train Loss: 0.3822 Acc: 0.8298 | Val Loss: 0.4135 Acc: 0.8025\n",
      "Epoch 124 | Train Loss: 0.3821 Acc: 0.8242 | Val Loss: 0.4158 Acc: 0.8013\n",
      "Epoch 125 | Train Loss: 0.3788 Acc: 0.8304 | Val Loss: 0.4142 Acc: 0.8031\n",
      "Epoch 126 | Train Loss: 0.3783 Acc: 0.8300 | Val Loss: 0.4123 Acc: 0.7989\n",
      "Epoch 127 | Train Loss: 0.3769 Acc: 0.8329 | Val Loss: 0.4260 Acc: 0.7905\n",
      "Epoch 128 | Train Loss: 0.3740 Acc: 0.8332 | Val Loss: 0.4268 Acc: 0.7947\n",
      "Epoch 129 | Train Loss: 0.3737 Acc: 0.8316 | Val Loss: 0.4134 Acc: 0.7959\n",
      "Epoch 130 | Train Loss: 0.3768 Acc: 0.8294 | Val Loss: 0.4521 Acc: 0.7808\n",
      "Epoch 131 | Train Loss: 0.3666 Acc: 0.8386 | Val Loss: 0.4517 Acc: 0.7729\n",
      "Epoch 132 | Train Loss: 0.3701 Acc: 0.8354 | Val Loss: 0.4162 Acc: 0.7995\n",
      "Epoch 133 | Train Loss: 0.3690 Acc: 0.8333 | Val Loss: 0.4095 Acc: 0.8116\n",
      "Epoch 134 | Train Loss: 0.3597 Acc: 0.8377 | Val Loss: 0.4801 Acc: 0.7639\n",
      "Epoch 135 | Train Loss: 0.3690 Acc: 0.8329 | Val Loss: 0.4165 Acc: 0.8001\n",
      "Epoch 136 | Train Loss: 0.3618 Acc: 0.8383 | Val Loss: 0.4076 Acc: 0.8037\n",
      "Epoch 137 | Train Loss: 0.3631 Acc: 0.8386 | Val Loss: 0.4025 Acc: 0.8098\n",
      "Epoch 138 | Train Loss: 0.3598 Acc: 0.8348 | Val Loss: 0.4061 Acc: 0.8074\n",
      "Epoch 139 | Train Loss: 0.3560 Acc: 0.8401 | Val Loss: 0.4022 Acc: 0.8074\n",
      "Epoch 140 | Train Loss: 0.3510 Acc: 0.8415 | Val Loss: 0.5620 Acc: 0.7385\n",
      "Epoch 141 | Train Loss: 0.3540 Acc: 0.8404 | Val Loss: 0.4034 Acc: 0.8086\n",
      "Epoch 142 | Train Loss: 0.3565 Acc: 0.8457 | Val Loss: 0.4182 Acc: 0.8019\n",
      "Epoch 143 | Train Loss: 0.3554 Acc: 0.8415 | Val Loss: 0.4305 Acc: 0.7899\n",
      "Epoch 144 | Train Loss: 0.3515 Acc: 0.8449 | Val Loss: 0.4157 Acc: 0.8019\n",
      "Epoch 145 | Train Loss: 0.3461 Acc: 0.8446 | Val Loss: 0.3944 Acc: 0.8086\n",
      "Epoch 146 | Train Loss: 0.3430 Acc: 0.8451 | Val Loss: 0.3866 Acc: 0.8231\n",
      "Epoch 147 | Train Loss: 0.3436 Acc: 0.8492 | Val Loss: 0.3931 Acc: 0.8134\n",
      "Epoch 148 | Train Loss: 0.3464 Acc: 0.8495 | Val Loss: 0.4038 Acc: 0.8098\n",
      "Epoch 149 | Train Loss: 0.3469 Acc: 0.8466 | Val Loss: 0.3854 Acc: 0.8176\n",
      "Epoch 150 | Train Loss: 0.3351 Acc: 0.8544 | Val Loss: 0.4211 Acc: 0.8007\n",
      "Epoch 151 | Train Loss: 0.3459 Acc: 0.8464 | Val Loss: 0.4520 Acc: 0.7802\n",
      "Epoch 152 | Train Loss: 0.3393 Acc: 0.8502 | Val Loss: 0.4120 Acc: 0.8056\n",
      "Epoch 153 | Train Loss: 0.3374 Acc: 0.8544 | Val Loss: 0.4178 Acc: 0.7995\n",
      "Epoch 154 | Train Loss: 0.3340 Acc: 0.8543 | Val Loss: 0.3819 Acc: 0.8182\n",
      "Epoch 155 | Train Loss: 0.3370 Acc: 0.8529 | Val Loss: 0.3808 Acc: 0.8207\n",
      "Epoch 156 | Train Loss: 0.3293 Acc: 0.8535 | Val Loss: 0.3794 Acc: 0.8152\n",
      "Epoch 157 | Train Loss: 0.3303 Acc: 0.8528 | Val Loss: 0.4253 Acc: 0.7935\n",
      "Epoch 158 | Train Loss: 0.3262 Acc: 0.8554 | Val Loss: 0.3775 Acc: 0.8213\n",
      "Epoch 159 | Train Loss: 0.3275 Acc: 0.8567 | Val Loss: 0.4443 Acc: 0.7856\n",
      "Epoch 160 | Train Loss: 0.3238 Acc: 0.8590 | Val Loss: 0.3767 Acc: 0.8194\n",
      "Epoch 161 | Train Loss: 0.3271 Acc: 0.8558 | Val Loss: 0.3739 Acc: 0.8273\n",
      "Epoch 162 | Train Loss: 0.3154 Acc: 0.8650 | Val Loss: 0.3982 Acc: 0.8200\n",
      "Epoch 163 | Train Loss: 0.3209 Acc: 0.8605 | Val Loss: 0.3752 Acc: 0.8261\n",
      "Epoch 164 | Train Loss: 0.3241 Acc: 0.8572 | Val Loss: 0.5128 Acc: 0.7669\n",
      "Epoch 165 | Train Loss: 0.3162 Acc: 0.8661 | Val Loss: 0.3971 Acc: 0.8158\n",
      "Epoch 166 | Train Loss: 0.3170 Acc: 0.8614 | Val Loss: 0.3678 Acc: 0.8297\n",
      "Epoch 167 | Train Loss: 0.3136 Acc: 0.8661 | Val Loss: 0.3801 Acc: 0.8285\n",
      "Epoch 168 | Train Loss: 0.3141 Acc: 0.8667 | Val Loss: 0.3718 Acc: 0.8279\n",
      "Epoch 169 | Train Loss: 0.3147 Acc: 0.8632 | Val Loss: 0.3729 Acc: 0.8303\n",
      "Epoch 170 | Train Loss: 0.3092 Acc: 0.8697 | Val Loss: 0.3651 Acc: 0.8364\n",
      "Epoch 171 | Train Loss: 0.3145 Acc: 0.8628 | Val Loss: 0.3698 Acc: 0.8382\n",
      "Epoch 172 | Train Loss: 0.3091 Acc: 0.8688 | Val Loss: 0.3668 Acc: 0.8382\n",
      "Epoch 173 | Train Loss: 0.3065 Acc: 0.8695 | Val Loss: 0.3710 Acc: 0.8279\n",
      "Epoch 174 | Train Loss: 0.3068 Acc: 0.8652 | Val Loss: 0.3613 Acc: 0.8388\n",
      "Epoch 175 | Train Loss: 0.3047 Acc: 0.8709 | Val Loss: 0.3998 Acc: 0.8164\n",
      "Epoch 176 | Train Loss: 0.2936 Acc: 0.8709 | Val Loss: 0.4419 Acc: 0.8025\n",
      "Epoch 177 | Train Loss: 0.3010 Acc: 0.8700 | Val Loss: 0.3659 Acc: 0.8333\n",
      "Epoch 178 | Train Loss: 0.2976 Acc: 0.8715 | Val Loss: 0.3616 Acc: 0.8345\n",
      "Epoch 179 | Train Loss: 0.2948 Acc: 0.8745 | Val Loss: 0.3972 Acc: 0.8225\n",
      "Epoch 180 | Train Loss: 0.2948 Acc: 0.8745 | Val Loss: 0.3672 Acc: 0.8357\n",
      "Epoch 181 | Train Loss: 0.2948 Acc: 0.8732 | Val Loss: 0.3658 Acc: 0.8364\n",
      "Epoch 182 | Train Loss: 0.2920 Acc: 0.8774 | Val Loss: 0.3785 Acc: 0.8315\n",
      "Epoch 183 | Train Loss: 0.2960 Acc: 0.8744 | Val Loss: 0.3534 Acc: 0.8364\n",
      "Epoch 184 | Train Loss: 0.2911 Acc: 0.8729 | Val Loss: 0.3504 Acc: 0.8460\n",
      "Epoch 185 | Train Loss: 0.2839 Acc: 0.8780 | Val Loss: 0.3894 Acc: 0.8219\n",
      "Epoch 186 | Train Loss: 0.2855 Acc: 0.8824 | Val Loss: 0.3538 Acc: 0.8394\n",
      "Epoch 187 | Train Loss: 0.2839 Acc: 0.8789 | Val Loss: 0.3631 Acc: 0.8382\n",
      "Epoch 188 | Train Loss: 0.2836 Acc: 0.8772 | Val Loss: 0.3570 Acc: 0.8357\n",
      "Epoch 189 | Train Loss: 0.2847 Acc: 0.8795 | Val Loss: 0.3943 Acc: 0.8273\n",
      "Epoch 190 | Train Loss: 0.2806 Acc: 0.8812 | Val Loss: 0.3903 Acc: 0.8297\n",
      "Epoch 191 | Train Loss: 0.2806 Acc: 0.8846 | Val Loss: 0.4089 Acc: 0.8134\n",
      "Epoch 192 | Train Loss: 0.2799 Acc: 0.8813 | Val Loss: 0.3466 Acc: 0.8364\n",
      "Epoch 193 | Train Loss: 0.2764 Acc: 0.8806 | Val Loss: 0.3766 Acc: 0.8376\n",
      "Epoch 194 | Train Loss: 0.2767 Acc: 0.8842 | Val Loss: 0.3595 Acc: 0.8400\n",
      "Epoch 195 | Train Loss: 0.2777 Acc: 0.8830 | Val Loss: 0.4119 Acc: 0.8110\n",
      "Epoch 196 | Train Loss: 0.2746 Acc: 0.8854 | Val Loss: 0.3477 Acc: 0.8430\n",
      "Epoch 197 | Train Loss: 0.2726 Acc: 0.8843 | Val Loss: 0.3942 Acc: 0.8315\n",
      "Epoch 198 | Train Loss: 0.2704 Acc: 0.8863 | Val Loss: 0.3387 Acc: 0.8430\n",
      "Epoch 199 | Train Loss: 0.2717 Acc: 0.8875 | Val Loss: 0.3985 Acc: 0.8279\n",
      "Epoch 200 | Train Loss: 0.2633 Acc: 0.8940 | Val Loss: 0.3878 Acc: 0.8297\n",
      "Epoch 201 | Train Loss: 0.2665 Acc: 0.8883 | Val Loss: 0.3441 Acc: 0.8466\n",
      "Epoch 202 | Train Loss: 0.2657 Acc: 0.8896 | Val Loss: 0.3532 Acc: 0.8388\n",
      "Epoch 203 | Train Loss: 0.2653 Acc: 0.8899 | Val Loss: 0.3490 Acc: 0.8448\n",
      "Epoch 204 | Train Loss: 0.2617 Acc: 0.8889 | Val Loss: 0.3505 Acc: 0.8460\n",
      "Epoch 205 | Train Loss: 0.2612 Acc: 0.8911 | Val Loss: 0.3458 Acc: 0.8490\n",
      "Epoch 206 | Train Loss: 0.2581 Acc: 0.8961 | Val Loss: 0.3573 Acc: 0.8400\n",
      "Epoch 207 | Train Loss: 0.2591 Acc: 0.8898 | Val Loss: 0.3467 Acc: 0.8484\n",
      "Epoch 208 | Train Loss: 0.2555 Acc: 0.8914 | Val Loss: 0.3518 Acc: 0.8490\n",
      "Epoch 209 | Train Loss: 0.2587 Acc: 0.8895 | Val Loss: 0.3838 Acc: 0.8357\n",
      "Epoch 210 | Train Loss: 0.2519 Acc: 0.9010 | Val Loss: 0.3492 Acc: 0.8496\n",
      "Epoch 211 | Train Loss: 0.2570 Acc: 0.8934 | Val Loss: 0.3602 Acc: 0.8460\n",
      "Epoch 212 | Train Loss: 0.2563 Acc: 0.8913 | Val Loss: 0.3420 Acc: 0.8563\n",
      "Epoch 213 | Train Loss: 0.2451 Acc: 0.8970 | Val Loss: 0.3540 Acc: 0.8406\n",
      "Epoch 214 | Train Loss: 0.2451 Acc: 0.9011 | Val Loss: 0.3759 Acc: 0.8321\n",
      "Epoch 215 | Train Loss: 0.2487 Acc: 0.8960 | Val Loss: 0.3349 Acc: 0.8502\n",
      "Epoch 216 | Train Loss: 0.2456 Acc: 0.8978 | Val Loss: 0.3460 Acc: 0.8490\n",
      "Epoch 217 | Train Loss: 0.2471 Acc: 0.8964 | Val Loss: 0.3354 Acc: 0.8593\n",
      "Epoch 218 | Train Loss: 0.2420 Acc: 0.9020 | Val Loss: 0.3397 Acc: 0.8502\n",
      "Epoch 219 | Train Loss: 0.2456 Acc: 0.8964 | Val Loss: 0.4498 Acc: 0.7971\n",
      "Epoch 220 | Train Loss: 0.2389 Acc: 0.9005 | Val Loss: 0.3540 Acc: 0.8496\n",
      "Epoch 221 | Train Loss: 0.2394 Acc: 0.8985 | Val Loss: 0.3522 Acc: 0.8376\n",
      "Epoch 222 | Train Loss: 0.2407 Acc: 0.9005 | Val Loss: 0.3543 Acc: 0.8545\n",
      "Epoch 223 | Train Loss: 0.2356 Acc: 0.9035 | Val Loss: 0.3299 Acc: 0.8605\n",
      "Epoch 224 | Train Loss: 0.2359 Acc: 0.8993 | Val Loss: 0.3331 Acc: 0.8527\n",
      "Epoch 225 | Train Loss: 0.2341 Acc: 0.9038 | Val Loss: 0.4415 Acc: 0.8188\n",
      "Epoch 226 | Train Loss: 0.2337 Acc: 0.9037 | Val Loss: 0.4844 Acc: 0.8043\n",
      "Epoch 227 | Train Loss: 0.2334 Acc: 0.9014 | Val Loss: 0.3377 Acc: 0.8557\n",
      "Epoch 228 | Train Loss: 0.2371 Acc: 0.9028 | Val Loss: 0.3340 Acc: 0.8599\n",
      "Epoch 229 | Train Loss: 0.2340 Acc: 0.9047 | Val Loss: 0.3352 Acc: 0.8605\n",
      "Epoch 230 | Train Loss: 0.2270 Acc: 0.9058 | Val Loss: 0.3373 Acc: 0.8629\n",
      "Epoch 231 | Train Loss: 0.2297 Acc: 0.9087 | Val Loss: 0.3245 Acc: 0.8647\n",
      "Epoch 232 | Train Loss: 0.2301 Acc: 0.9049 | Val Loss: 0.3398 Acc: 0.8665\n",
      "Epoch 233 | Train Loss: 0.2254 Acc: 0.9067 | Val Loss: 0.3289 Acc: 0.8617\n",
      "Epoch 234 | Train Loss: 0.2276 Acc: 0.9041 | Val Loss: 0.3712 Acc: 0.8490\n",
      "Epoch 235 | Train Loss: 0.2231 Acc: 0.9094 | Val Loss: 0.3473 Acc: 0.8448\n",
      "Epoch 236 | Train Loss: 0.2224 Acc: 0.9109 | Val Loss: 0.3344 Acc: 0.8575\n",
      "Epoch 237 | Train Loss: 0.2206 Acc: 0.9096 | Val Loss: 0.3785 Acc: 0.8508\n",
      "Epoch 238 | Train Loss: 0.2203 Acc: 0.9068 | Val Loss: 0.3696 Acc: 0.8521\n",
      "Epoch 239 | Train Loss: 0.2218 Acc: 0.9082 | Val Loss: 0.3558 Acc: 0.8581\n",
      "Epoch 240 | Train Loss: 0.2152 Acc: 0.9096 | Val Loss: 0.3270 Acc: 0.8557\n",
      "Epoch 241 | Train Loss: 0.2165 Acc: 0.9132 | Val Loss: 0.3406 Acc: 0.8617\n",
      "Epoch 242 | Train Loss: 0.2187 Acc: 0.9106 | Val Loss: 0.3286 Acc: 0.8593\n",
      "Epoch 243 | Train Loss: 0.2163 Acc: 0.9111 | Val Loss: 0.3178 Acc: 0.8696\n",
      "Epoch 244 | Train Loss: 0.2100 Acc: 0.9147 | Val Loss: 0.4415 Acc: 0.8110\n",
      "Epoch 245 | Train Loss: 0.2166 Acc: 0.9161 | Val Loss: 0.3438 Acc: 0.8629\n",
      "Epoch 246 | Train Loss: 0.2128 Acc: 0.9157 | Val Loss: 0.3259 Acc: 0.8720\n",
      "Epoch 247 | Train Loss: 0.2112 Acc: 0.9141 | Val Loss: 0.3383 Acc: 0.8508\n",
      "Epoch 248 | Train Loss: 0.2080 Acc: 0.9174 | Val Loss: 0.3403 Acc: 0.8508\n",
      "Epoch 249 | Train Loss: 0.2063 Acc: 0.9144 | Val Loss: 0.3510 Acc: 0.8653\n",
      "Epoch 250 | Train Loss: 0.2082 Acc: 0.9136 | Val Loss: 0.3235 Acc: 0.8744\n",
      "Epoch 251 | Train Loss: 0.2051 Acc: 0.9161 | Val Loss: 0.3278 Acc: 0.8605\n",
      "Epoch 252 | Train Loss: 0.2098 Acc: 0.9142 | Val Loss: 0.3500 Acc: 0.8635\n",
      "Epoch 253 | Train Loss: 0.1998 Acc: 0.9210 | Val Loss: 0.3160 Acc: 0.8720\n",
      "Epoch 254 | Train Loss: 0.1944 Acc: 0.9203 | Val Loss: 0.3203 Acc: 0.8684\n",
      "Epoch 255 | Train Loss: 0.2050 Acc: 0.9162 | Val Loss: 0.4799 Acc: 0.8122\n",
      "Epoch 256 | Train Loss: 0.2036 Acc: 0.9167 | Val Loss: 0.3252 Acc: 0.8665\n",
      "Epoch 257 | Train Loss: 0.2035 Acc: 0.9168 | Val Loss: 0.3928 Acc: 0.8448\n",
      "Epoch 258 | Train Loss: 0.2025 Acc: 0.9180 | Val Loss: 0.3225 Acc: 0.8605\n",
      "Epoch 259 | Train Loss: 0.1941 Acc: 0.9236 | Val Loss: 0.3237 Acc: 0.8684\n",
      "Epoch 260 | Train Loss: 0.1968 Acc: 0.9209 | Val Loss: 0.3443 Acc: 0.8671\n",
      "Epoch 261 | Train Loss: 0.1915 Acc: 0.9219 | Val Loss: 0.4046 Acc: 0.8508\n",
      "Epoch 262 | Train Loss: 0.2004 Acc: 0.9206 | Val Loss: 0.3106 Acc: 0.8726\n",
      "Epoch 263 | Train Loss: 0.1891 Acc: 0.9219 | Val Loss: 0.3846 Acc: 0.8545\n",
      "Epoch 264 | Train Loss: 0.1932 Acc: 0.9228 | Val Loss: 0.4113 Acc: 0.8261\n",
      "Epoch 265 | Train Loss: 0.1851 Acc: 0.9266 | Val Loss: 0.3221 Acc: 0.8738\n",
      "Epoch 266 | Train Loss: 0.1971 Acc: 0.9167 | Val Loss: 0.3244 Acc: 0.8744\n",
      "Epoch 267 | Train Loss: 0.1953 Acc: 0.9168 | Val Loss: 0.3223 Acc: 0.8659\n",
      "Epoch 268 | Train Loss: 0.1875 Acc: 0.9239 | Val Loss: 0.3214 Acc: 0.8714\n",
      "Epoch 269 | Train Loss: 0.1929 Acc: 0.9161 | Val Loss: 0.3175 Acc: 0.8665\n",
      "Epoch 270 | Train Loss: 0.1879 Acc: 0.9241 | Val Loss: 0.3186 Acc: 0.8684\n",
      "Epoch 271 | Train Loss: 0.1910 Acc: 0.9209 | Val Loss: 0.3395 Acc: 0.8690\n",
      "Epoch 272 | Train Loss: 0.1885 Acc: 0.9248 | Val Loss: 0.3441 Acc: 0.8665\n",
      "Epoch 273 | Train Loss: 0.1852 Acc: 0.9271 | Val Loss: 0.3162 Acc: 0.8816\n",
      "Epoch 274 | Train Loss: 0.1840 Acc: 0.9250 | Val Loss: 0.3232 Acc: 0.8744\n",
      "Epoch 275 | Train Loss: 0.1845 Acc: 0.9253 | Val Loss: 0.3646 Acc: 0.8623\n",
      "Epoch 276 | Train Loss: 0.1769 Acc: 0.9280 | Val Loss: 0.3238 Acc: 0.8762\n",
      "Epoch 277 | Train Loss: 0.1803 Acc: 0.9321 | Val Loss: 0.3268 Acc: 0.8684\n",
      "Epoch 278 | Train Loss: 0.1759 Acc: 0.9266 | Val Loss: 0.3323 Acc: 0.8587\n",
      "Epoch 279 | Train Loss: 0.1766 Acc: 0.9292 | Val Loss: 0.3147 Acc: 0.8822\n",
      "Epoch 280 | Train Loss: 0.1754 Acc: 0.9295 | Val Loss: 0.3016 Acc: 0.8816\n",
      "Epoch 281 | Train Loss: 0.1755 Acc: 0.9307 | Val Loss: 0.3535 Acc: 0.8720\n",
      "Epoch 282 | Train Loss: 0.1713 Acc: 0.9318 | Val Loss: 0.3094 Acc: 0.8786\n",
      "Epoch 283 | Train Loss: 0.1739 Acc: 0.9328 | Val Loss: 0.3119 Acc: 0.8810\n",
      "Epoch 284 | Train Loss: 0.1713 Acc: 0.9298 | Val Loss: 0.3569 Acc: 0.8521\n",
      "Epoch 285 | Train Loss: 0.1687 Acc: 0.9318 | Val Loss: 0.3239 Acc: 0.8653\n",
      "Epoch 286 | Train Loss: 0.1688 Acc: 0.9342 | Val Loss: 0.3208 Acc: 0.8847\n",
      "Epoch 287 | Train Loss: 0.1669 Acc: 0.9301 | Val Loss: 0.3438 Acc: 0.8726\n",
      "Epoch 288 | Train Loss: 0.1628 Acc: 0.9352 | Val Loss: 0.3357 Acc: 0.8792\n",
      "Epoch 289 | Train Loss: 0.1679 Acc: 0.9328 | Val Loss: 0.3068 Acc: 0.8847\n",
      "Epoch 290 | Train Loss: 0.1645 Acc: 0.9340 | Val Loss: 0.3453 Acc: 0.8762\n",
      "Epoch 291 | Train Loss: 0.1612 Acc: 0.9373 | Val Loss: 0.3589 Acc: 0.8539\n",
      "Epoch 292 | Train Loss: 0.1673 Acc: 0.9336 | Val Loss: 0.3033 Acc: 0.8816\n",
      "Epoch 293 | Train Loss: 0.1637 Acc: 0.9318 | Val Loss: 0.3245 Acc: 0.8810\n",
      "Epoch 294 | Train Loss: 0.1620 Acc: 0.9354 | Val Loss: 0.3064 Acc: 0.8786\n",
      "Epoch 295 | Train Loss: 0.1655 Acc: 0.9325 | Val Loss: 0.3054 Acc: 0.8829\n",
      "Epoch 296 | Train Loss: 0.1580 Acc: 0.9358 | Val Loss: 0.3805 Acc: 0.8605\n",
      "Epoch 297 | Train Loss: 0.1543 Acc: 0.9411 | Val Loss: 0.3090 Acc: 0.8798\n",
      "Epoch 298 | Train Loss: 0.1645 Acc: 0.9363 | Val Loss: 0.3617 Acc: 0.8539\n",
      "Epoch 299 | Train Loss: 0.1611 Acc: 0.9384 | Val Loss: 0.3157 Acc: 0.8841\n",
      "Epoch 300 | Train Loss: 0.1598 Acc: 0.9363 | Val Loss: 0.4391 Acc: 0.8460\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = EEG_CNN_LSTM(lstm_layers=1).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.RMSprop(model.parameters(), lr=5e-5, weight_decay=1e-5)\n",
    "\n",
    "history = model.fit(train_loader, test_loader,\n",
    "                    epochs=300,\n",
    "                    criterion=criterion,\n",
    "                    optimizer=optimizer,\n",
    "                    device=device,\n",
    "                    patience=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e20ab9a3-cf9a-4fbf-b321-8d29d0797a49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Accuracy: 0.8460144927536232\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.97      0.88       925\n",
      "           1       0.94      0.69      0.80       731\n",
      "\n",
      "    accuracy                           0.85      1656\n",
      "   macro avg       0.87      0.83      0.84      1656\n",
      "weighted avg       0.86      0.85      0.84      1656\n",
      "\n",
      "[[895  30]\n",
      " [225 506]]\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "all_preds, all_labels = [], []\n",
    "with torch.no_grad():\n",
    "    for xb, yb in test_loader:\n",
    "        xb = xb.to(device)\n",
    "        preds = model(xb).argmax(1).cpu().numpy()\n",
    "        all_preds.append(preds)\n",
    "        all_labels.append(yb.numpy())\n",
    "\n",
    "all_preds = np.concatenate(all_preds)\n",
    "all_labels = np.concatenate(all_labels)\n",
    "\n",
    "print(\"\\nTest Accuracy:\", accuracy_score(all_labels, all_preds))\n",
    "print(classification_report(all_labels, all_preds))\n",
    "print(confusion_matrix(all_labels, all_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f5ba6aae-6a97-4f20-9edd-a31e8d0a355d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history['train_accs'], label='Training Accuracy')\n",
    "plt.plot(history['val_accs'], label='Validation Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history['train_losses'], label='Training Loss')\n",
    "plt.plot(history['val_losses'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a44a95e4-3107-4685-b3c1-8b5acc451aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EEG_CNN_LSTM_HPO(nn.Module):\n",
    "    \"\"\"\n",
    "    Configurable CNN -> per-step projection -> LSTM -> FC\n",
    "    Mirrors the structure/forward logic of your original EEG_CNN_LSTM but\n",
    "    exposes cnn kernel counts/sizes and dense sizes for HPO.\n",
    "    Input: (N, 1, freq, electrodes)\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 cnn_kernels_1=32,\n",
    "                 cnn_kernel_size_1=3,\n",
    "                 cnn_kernels_2=64,\n",
    "                 cnn_dropout=0.3,\n",
    "                 cnn_dense=64,\n",
    "                 lstm_hidden_size=64,\n",
    "                 lstm_layers=2,\n",
    "                 lstm_dense=64,\n",
    "                 dropout=0.3,\n",
    "                 num_classes=2):\n",
    "        super().__init__()\n",
    "\n",
    "        # --- CNN feature extractor (configurable) ---\n",
    "        pad1 = cnn_kernel_size_1 // 2\n",
    "        self.conv1 = nn.Conv2d(1, int(cnn_kernels_1), kernel_size=cnn_kernel_size_1, padding=pad1)\n",
    "        self.pool1 = nn.AvgPool2d(2)\n",
    "        # keep conv2 kernel size 3 for stability; could be made configurable too\n",
    "        self.conv2 = nn.Conv2d(int(cnn_kernels_1), int(cnn_kernels_2), kernel_size=3, padding=1)\n",
    "        self.pool2 = nn.AvgPool2d(2)\n",
    "        self.cnn_dropout = nn.Dropout(cnn_dropout)\n",
    "\n",
    "        # compute dims after CNN using X_train shape present in the session\n",
    "        with torch.no_grad():\n",
    "            dummy = torch.zeros(1, 1, X_train.shape[1], X_train.shape[2])\n",
    "            out = self._forward_cnn(dummy)\n",
    "            # We'll treat width (W) as seq_len and flatten channels*height as feature_dim\n",
    "            self.seq_len = out.size(-1)           # W\n",
    "            self.feature_dim = out.size(1) * out.size(2)  # C * H\n",
    "\n",
    "        # projection per time-step from feature_dim -> cnn_dense\n",
    "        self.cnn_dense = nn.Linear(self.feature_dim, int(cnn_dense))\n",
    "\n",
    "        # --- LSTM (takes cnn_dense as input_size) ---\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=int(cnn_dense),\n",
    "            hidden_size=int(lstm_hidden_size),\n",
    "            num_layers=int(lstm_layers),\n",
    "            batch_first=True,\n",
    "            dropout=dropout if lstm_layers > 1 else 0.0\n",
    "        )\n",
    "\n",
    "        # optional dense after LSTM\n",
    "        self.lstm_dense = nn.Linear(int(lstm_hidden_size), int(lstm_dense))\n",
    "\n",
    "        # final classifier (match your original final style: dropout + linear)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(int(lstm_dense), num_classes)\n",
    "        )\n",
    "\n",
    "    def _forward_cnn(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool1(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool2(x)\n",
    "        x = self.cnn_dropout(x)\n",
    "        return x  # (N, C, H, W)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # CNN extraction\n",
    "        x = self._forward_cnn(x)           # (N, C, H, W)\n",
    "\n",
    "        # Prepare for LSTM: treat W as sequence length, flatten C*H to feature\n",
    "        x = x.permute(0, 3, 1, 2)          # (N, W, C, H)\n",
    "        x = x.reshape(x.size(0), x.size(1), -1)  # (N, seq_len=W, feature_dim=C*H)\n",
    "\n",
    "        # project per time-step\n",
    "        x = F.relu(self.cnn_dense(x))      # (N, seq_len, cnn_dense)\n",
    "\n",
    "        # LSTM\n",
    "        _, (h_n, _) = self.lstm(x)         # h_n: (num_layers, batch, hidden)\n",
    "        out = h_n[-1]                      # last layer hidden state -> (batch, hidden)\n",
    "\n",
    "        # post-LSTM dense + classifier\n",
    "        out = F.relu(self.lstm_dense(out))\n",
    "        return self.classifier(out)\n",
    "\n",
    "    # Fit method adapted from your original\n",
    "    def fit(self, train_loader, val_loader, epochs, criterion, optimizer,\n",
    "            device=\"cpu\", patience=30, is_verbose=True):\n",
    "        best_val_loss = float('inf')\n",
    "        no_improve = 0\n",
    "        best_state = None\n",
    "\n",
    "        train_losses, val_losses = [], []\n",
    "        train_accs,  val_accs  = [], []\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            # ---- Train ----\n",
    "            self.train()\n",
    "            train_loss, train_correct = 0.0, 0\n",
    "            for xb, yb in train_loader:\n",
    "                xb, yb = xb.to(device), yb.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                out = self(xb)\n",
    "                loss = criterion(out, yb)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                train_loss += loss.item() * xb.size(0)\n",
    "                train_correct += (out.argmax(1) == yb).sum().item()\n",
    "\n",
    "            train_loss /= len(train_loader.dataset)\n",
    "            train_acc  = train_correct / len(train_loader.dataset)\n",
    "            train_losses.append(train_loss)\n",
    "            train_accs.append(train_acc)\n",
    "\n",
    "            # ---- Validate ----\n",
    "            self.eval()\n",
    "            val_loss, val_correct = 0.0, 0\n",
    "            with torch.no_grad():\n",
    "                for xb, yb in val_loader:\n",
    "                    xb, yb = xb.to(device), yb.to(device)\n",
    "                    out = self(xb)\n",
    "                    loss = criterion(out, yb)\n",
    "                    val_loss += loss.item() * xb.size(0)\n",
    "                    val_correct += (out.argmax(1) == yb).sum().item()\n",
    "\n",
    "            val_loss /= len(val_loader.dataset)\n",
    "            val_acc  = val_correct / len(val_loader.dataset)\n",
    "            val_losses.append(val_loss)\n",
    "            val_accs.append(val_acc)\n",
    "\n",
    "            if is_verbose:\n",
    "                print(f\"Epoch {epoch+1:03d} | \"\n",
    "                      f\"Train Loss: {train_loss:.4f} Acc: {train_acc:.4f} | \"\n",
    "                      f\"Val Loss: {val_loss:.4f} Acc: {val_acc:.4f}\")\n",
    "\n",
    "            if val_loss - train_loss > 0.3:\n",
    "                print(\"Overfitting detected\")\n",
    "                break\n",
    "\n",
    "            # Early stopping\n",
    "            if val_loss <= best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                best_state = self.state_dict()\n",
    "                no_improve = 0\n",
    "            else:\n",
    "                no_improve += 1\n",
    "                if no_improve >= patience:\n",
    "                    print(\"Early stopping triggered.\")\n",
    "                    break\n",
    "\n",
    "        if best_state:\n",
    "            self.load_state_dict(best_state)\n",
    "\n",
    "        return {\n",
    "            \"train_losses\": np.array(train_losses),\n",
    "            \"val_losses\":   np.array(val_losses),\n",
    "            \"train_accs\":   np.array(train_accs),\n",
    "            \"val_accs\":     np.array(val_accs)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9c48d591-8730-4da4-8c31-5705d18f0bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from hyperopt import fmin, tpe, hp, Trials, STATUS_OK\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "\n",
    "# -------------------------\n",
    "# Hyperopt search space\n",
    "# -------------------------\n",
    "space = {\n",
    "    'cnn_kernels_1'    : hp.choice('cnn_kernels_1', [16, 32, 48, 64]),\n",
    "    'cnn_kernel_size_1': hp.choice('cnn_kernel_size_1', [3, 5]),\n",
    "    'cnn_kernels_2'    : hp.choice('cnn_kernels_2', [16, 32, 64, 96]),\n",
    "    'cnn_dropout'      : hp.uniform('cnn_dropout', 0.0, 0.7),\n",
    "    'cnn_dense'        : hp.choice('cnn_dense', [32, 64, 128, 256]),\n",
    "    'lstm_hidden_size' : hp.choice('lstm_hidden_size', [32, 64, 96, 128]),\n",
    "    'lstm_layers'      : hp.choice('lstm_layers', [1, 2, 3]),\n",
    "    'lstm_dense'       : hp.choice('lstm_dense', [32, 64, 128, 256]),\n",
    "    'learning_rate'    : hp.loguniform('learning_rate', np.log(1e-4), np.log(1e-2)),\n",
    "    'optimizer'        : hp.choice('optimizer', ['adam', 'rmsprop', 'sgd']),\n",
    "    'batch_size'       : hp.choice('batch_size', [16, 32, 36, 48, 64])\n",
    "}\n",
    "\n",
    "# -------------------------\n",
    "# Objective for Hyperopt\n",
    "# -------------------------\n",
    "def objective(params):\n",
    "    # map params to integers where needed\n",
    "    params = dict(params)  # copy\n",
    "    params['cnn_kernels_1'] = int(params['cnn_kernels_1'])\n",
    "    params['cnn_kernel_size_1'] = int(params['cnn_kernel_size_1'])\n",
    "    params['cnn_kernels_2'] = int(params['cnn_kernels_2'])\n",
    "    params['cnn_dense'] = int(params['cnn_dense'])\n",
    "    params['lstm_hidden_size'] = int(params['lstm_hidden_size'])\n",
    "    params['lstm_layers'] = int(params['lstm_layers'])\n",
    "    params['lstm_dense'] = int(params['lstm_dense'])\n",
    "    params['batch_size'] = int(params['batch_size'])\n",
    "\n",
    "    print(\"Trial params:\", params)\n",
    "\n",
    "    # build dataloaders from the existing train_ds/test_ds in this session\n",
    "    train_loader = DataLoader(train_ds, batch_size=params['batch_size'], shuffle=True)\n",
    "    val_loader   = DataLoader(test_ds,  batch_size=params['batch_size'], shuffle=False)\n",
    "\n",
    "    # create model (note we pass dropout into lstm dropout and cnn dropout)\n",
    "    model = EEG_CNN_LSTM_HPO(\n",
    "        cnn_kernels_1=params['cnn_kernels_1'],\n",
    "        cnn_kernel_size_1=params['cnn_kernel_size_1'],\n",
    "        cnn_kernels_2=params['cnn_kernels_2'],\n",
    "        cnn_dropout=float(params['cnn_dropout']),\n",
    "        cnn_dense=params['cnn_dense'],\n",
    "        lstm_hidden_size=params['lstm_hidden_size'],\n",
    "        lstm_layers=params['lstm_layers'],\n",
    "        lstm_dense=params['lstm_dense'],\n",
    "        dropout=float(params['cnn_dropout']),  # use cnn_dropout as a simple shared dropout param\n",
    "        num_classes=2\n",
    "    ).to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    if params['optimizer'] == 'adam':\n",
    "        optimizer = optim.Adam(model.parameters(), lr=params['learning_rate'], weight_decay=1e-4)\n",
    "    elif params['optimizer'] == 'rmsprop':\n",
    "        optimizer = optim.RMSprop(model.parameters(), lr=params['learning_rate'], weight_decay=1e-4)\n",
    "    else:\n",
    "        optimizer = optim.SGD(model.parameters(), lr=params['learning_rate'], momentum=0.9, weight_decay=1e-4)\n",
    "\n",
    "    # Train with modest epochs; early stopping inside fit handles rest\n",
    "    history = model.fit(\n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader,\n",
    "        epochs=60,\n",
    "        criterion=criterion,\n",
    "        optimizer=optimizer,\n",
    "        device=device,\n",
    "        patience=10\n",
    "    )\n",
    "\n",
    "    best_val_loss = float(np.min(history['val_losses'])) if len(history['val_losses'])>0 else 0.0\n",
    "\n",
    "    # Hyperopt minimizes -> return negative accuracy\n",
    "    return {'loss': best_val_loss, 'status': STATUS_OK, 'attachments': {'history': history}}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d7d5d1cf-c805-41d3-b1b3-c2d431d7ffef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial params:                                                                                                        \n",
      "{'batch_size': 48, 'cnn_dense': 256, 'cnn_dropout': 0.4345008150748326, 'cnn_kernel_size_1': 5, 'cnn_kernels_1': 64, 'cnn_kernels_2': 16, 'learning_rate': 0.00015481601850539107, 'lstm_dense': 128, 'lstm_hidden_size': 32, 'lstm_layers': 3, 'optimizer': 'adam'}\n",
      "Epoch 001 | Train Loss: 0.6868 Acc: 0.5590 | Val Loss: 0.6851 Acc: 0.5586                                            \n",
      "Epoch 002 | Train Loss: 0.6828 Acc: 0.5683 | Val Loss: 0.6828 Acc: 0.5737                                            \n",
      "Epoch 003 | Train Loss: 0.6770 Acc: 0.5883 | Val Loss: 0.6773 Acc: 0.5809                                            \n",
      "Epoch 004 | Train Loss: 0.6728 Acc: 0.5931 | Val Loss: 0.6718 Acc: 0.5894                                            \n",
      "Epoch 005 | Train Loss: 0.6667 Acc: 0.6020 | Val Loss: 0.6646 Acc: 0.6045                                            \n",
      "Epoch 006 | Train Loss: 0.6601 Acc: 0.6083 | Val Loss: 0.6486 Acc: 0.6576                                            \n",
      "Epoch 007 | Train Loss: 0.6410 Acc: 0.6345 | Val Loss: 0.6367 Acc: 0.6467                                            \n",
      "Epoch 008 | Train Loss: 0.6224 Acc: 0.6687 | Val Loss: 0.6133 Acc: 0.6787                                            \n",
      "Epoch 009 | Train Loss: 0.6180 Acc: 0.6736 | Val Loss: 0.6071 Acc: 0.6812                                            \n",
      "Epoch 010 | Train Loss: 0.6134 Acc: 0.6835 | Val Loss: 0.5966 Acc: 0.6999                                            \n",
      "Epoch 011 | Train Loss: 0.6065 Acc: 0.6837 | Val Loss: 0.6169 Acc: 0.6733                                            \n",
      "Epoch 012 | Train Loss: 0.6010 Acc: 0.6933 | Val Loss: 0.6000 Acc: 0.6890                                            \n",
      "Epoch 013 | Train Loss: 0.5977 Acc: 0.6953 | Val Loss: 0.5855 Acc: 0.7065                                            \n",
      "Epoch 014 | Train Loss: 0.5932 Acc: 0.6979 | Val Loss: 0.5817 Acc: 0.7089                                            \n",
      "Epoch 015 | Train Loss: 0.5866 Acc: 0.7078 | Val Loss: 0.5795 Acc: 0.7095                                            \n",
      "Epoch 016 | Train Loss: 0.5834 Acc: 0.7100 | Val Loss: 0.5738 Acc: 0.7216                                            \n",
      "Epoch 017 | Train Loss: 0.5798 Acc: 0.7127 | Val Loss: 0.5711 Acc: 0.7210                                            \n",
      "Epoch 018 | Train Loss: 0.5757 Acc: 0.7181 | Val Loss: 0.5774 Acc: 0.6999                                            \n",
      "Epoch 019 | Train Loss: 0.5720 Acc: 0.7163 | Val Loss: 0.5605 Acc: 0.7325                                            \n",
      "Epoch 020 | Train Loss: 0.5655 Acc: 0.7243 | Val Loss: 0.5582 Acc: 0.7301                                            \n",
      "Epoch 021 | Train Loss: 0.5638 Acc: 0.7270 | Val Loss: 0.5557 Acc: 0.7271                                            \n",
      "Epoch 022 | Train Loss: 0.5606 Acc: 0.7269 | Val Loss: 0.5638 Acc: 0.7216                                            \n",
      "Epoch 023 | Train Loss: 0.5553 Acc: 0.7318 | Val Loss: 0.5541 Acc: 0.7307                                            \n",
      "Epoch 024 | Train Loss: 0.5538 Acc: 0.7309 | Val Loss: 0.5497 Acc: 0.7289                                            \n",
      "Epoch 025 | Train Loss: 0.5465 Acc: 0.7355 | Val Loss: 0.5452 Acc: 0.7325                                            \n",
      "Epoch 026 | Train Loss: 0.5459 Acc: 0.7373 | Val Loss: 0.5428 Acc: 0.7325                                            \n",
      "Epoch 027 | Train Loss: 0.5454 Acc: 0.7398 | Val Loss: 0.5544 Acc: 0.7246                                            \n",
      "Epoch 028 | Train Loss: 0.5378 Acc: 0.7432 | Val Loss: 0.5510 Acc: 0.7301                                            \n",
      "Epoch 029 | Train Loss: 0.5361 Acc: 0.7427 | Val Loss: 0.5417 Acc: 0.7343                                            \n",
      "Epoch 030 | Train Loss: 0.5342 Acc: 0.7466 | Val Loss: 0.5324 Acc: 0.7349                                            \n",
      "Epoch 031 | Train Loss: 0.5327 Acc: 0.7456 | Val Loss: 0.5307 Acc: 0.7452                                            \n",
      "Epoch 032 | Train Loss: 0.5290 Acc: 0.7500 | Val Loss: 0.5308 Acc: 0.7379                                            \n",
      "Epoch 033 | Train Loss: 0.5193 Acc: 0.7552 | Val Loss: 0.5478 Acc: 0.7277                                            \n",
      "Epoch 034 | Train Loss: 0.5291 Acc: 0.7483 | Val Loss: 0.5255 Acc: 0.7385                                            \n",
      "Epoch 035 | Train Loss: 0.5195 Acc: 0.7533 | Val Loss: 0.5238 Acc: 0.7403                                            \n",
      "Epoch 036 | Train Loss: 0.5158 Acc: 0.7534 | Val Loss: 0.5496 Acc: 0.7289                                            \n",
      "Epoch 037 | Train Loss: 0.5197 Acc: 0.7513 | Val Loss: 0.5264 Acc: 0.7434                                            \n",
      "Epoch 038 | Train Loss: 0.5166 Acc: 0.7548 | Val Loss: 0.5229 Acc: 0.7421                                            \n",
      "Epoch 039 | Train Loss: 0.5118 Acc: 0.7587 | Val Loss: 0.5219 Acc: 0.7440                                            \n",
      "Epoch 040 | Train Loss: 0.5143 Acc: 0.7560 | Val Loss: 0.5152 Acc: 0.7452                                            \n",
      "Epoch 041 | Train Loss: 0.5067 Acc: 0.7620 | Val Loss: 0.5159 Acc: 0.7452                                            \n",
      "Epoch 042 | Train Loss: 0.5068 Acc: 0.7628 | Val Loss: 0.5230 Acc: 0.7452                                            \n",
      "Epoch 043 | Train Loss: 0.5049 Acc: 0.7592 | Val Loss: 0.5174 Acc: 0.7421                                            \n",
      "Epoch 044 | Train Loss: 0.5092 Acc: 0.7620 | Val Loss: 0.5407 Acc: 0.7283                                            \n",
      "Epoch 045 | Train Loss: 0.5044 Acc: 0.7580 | Val Loss: 0.5090 Acc: 0.7585                                            \n",
      "Epoch 046 | Train Loss: 0.4993 Acc: 0.7678 | Val Loss: 0.5074 Acc: 0.7482                                            \n",
      "Epoch 047 | Train Loss: 0.5001 Acc: 0.7651 | Val Loss: 0.5101 Acc: 0.7476                                            \n",
      "Epoch 048 | Train Loss: 0.4959 Acc: 0.7703 | Val Loss: 0.5001 Acc: 0.7482                                            \n",
      "Epoch 049 | Train Loss: 0.4926 Acc: 0.7753 | Val Loss: 0.5011 Acc: 0.7585                                            \n",
      "Epoch 050 | Train Loss: 0.4908 Acc: 0.7722 | Val Loss: 0.5072 Acc: 0.7482                                            \n",
      "Epoch 051 | Train Loss: 0.4925 Acc: 0.7714 | Val Loss: 0.5015 Acc: 0.7566                                            \n",
      "Epoch 052 | Train Loss: 0.4837 Acc: 0.7797 | Val Loss: 0.5027 Acc: 0.7609                                            \n",
      "Epoch 053 | Train Loss: 0.4827 Acc: 0.7755 | Val Loss: 0.4951 Acc: 0.7717                                            \n",
      "Epoch 054 | Train Loss: 0.4770 Acc: 0.7785 | Val Loss: 0.4978 Acc: 0.7548                                            \n",
      "Epoch 055 | Train Loss: 0.4774 Acc: 0.7814 | Val Loss: 0.4995 Acc: 0.7482                                            \n",
      "Epoch 056 | Train Loss: 0.4721 Acc: 0.7827 | Val Loss: 0.4792 Acc: 0.7669                                            \n",
      "Epoch 057 | Train Loss: 0.4767 Acc: 0.7802 | Val Loss: 0.4815 Acc: 0.7778                                            \n",
      "Epoch 058 | Train Loss: 0.4698 Acc: 0.7856 | Val Loss: 0.5260 Acc: 0.7409                                            \n",
      "Epoch 059 | Train Loss: 0.4686 Acc: 0.7873 | Val Loss: 0.4892 Acc: 0.7603                                            \n",
      "Epoch 060 | Train Loss: 0.4621 Acc: 0.7898 | Val Loss: 0.4721 Acc: 0.7754                                            \n",
      "Trial params:                                                                                                        \n",
      "{'batch_size': 48, 'cnn_dense': 64, 'cnn_dropout': 0.0035272602033583175, 'cnn_kernel_size_1': 5, 'cnn_kernels_1': 16, 'cnn_kernels_2': 32, 'learning_rate': 0.0010326687512129996, 'lstm_dense': 64, 'lstm_hidden_size': 128, 'lstm_layers': 3, 'optimizer': 'adam'}\n",
      "Epoch 001 | Train Loss: 0.6860 Acc: 0.5570 | Val Loss: 0.6821 Acc: 0.5719                                            \n",
      "Epoch 002 | Train Loss: 0.6758 Acc: 0.5881 | Val Loss: 0.6691 Acc: 0.5930                                            \n",
      "Epoch 003 | Train Loss: 0.6698 Acc: 0.6009 | Val Loss: 0.6539 Acc: 0.6202                                            \n",
      "Epoch 004 | Train Loss: 0.6414 Acc: 0.6483 | Val Loss: 0.6781 Acc: 0.5936                                            \n",
      "Epoch 005 | Train Loss: 0.6336 Acc: 0.6563 | Val Loss: 0.6311 Acc: 0.6558                                            \n",
      "Epoch 006 | Train Loss: 0.5940 Acc: 0.6989 | Val Loss: 0.5820 Acc: 0.7029                                            \n",
      "Epoch 007 | Train Loss: 0.5718 Acc: 0.7166 | Val Loss: 0.5626 Acc: 0.7168                                            \n",
      "Epoch 008 | Train Loss: 0.5527 Acc: 0.7356 | Val Loss: 0.5507 Acc: 0.7277                                            \n",
      "Epoch 009 | Train Loss: 0.5328 Acc: 0.7501 | Val Loss: 0.5441 Acc: 0.7343                                            \n",
      "Epoch 010 | Train Loss: 0.5172 Acc: 0.7528 | Val Loss: 0.5247 Acc: 0.7397                                            \n",
      "Epoch 011 | Train Loss: 0.4975 Acc: 0.7645 | Val Loss: 0.5119 Acc: 0.7524                                            \n",
      "Epoch 012 | Train Loss: 0.4780 Acc: 0.7779 | Val Loss: 0.5095 Acc: 0.7494                                            \n",
      "Epoch 013 | Train Loss: 0.4496 Acc: 0.7879 | Val Loss: 0.4852 Acc: 0.7669                                            \n",
      "Epoch 014 | Train Loss: 0.4403 Acc: 0.7984 | Val Loss: 0.5010 Acc: 0.7530                                            \n",
      "Epoch 015 | Train Loss: 0.4203 Acc: 0.8096 | Val Loss: 0.4351 Acc: 0.8007                                            \n",
      "Epoch 016 | Train Loss: 0.3988 Acc: 0.8232 | Val Loss: 0.4757 Acc: 0.7566                                            \n",
      "Epoch 017 | Train Loss: 0.3787 Acc: 0.8368 | Val Loss: 0.4266 Acc: 0.7989                                            \n",
      "Epoch 018 | Train Loss: 0.3651 Acc: 0.8442 | Val Loss: 0.4281 Acc: 0.8001                                            \n",
      "Epoch 019 | Train Loss: 0.3449 Acc: 0.8477 | Val Loss: 0.3814 Acc: 0.8279                                            \n",
      "Epoch 020 | Train Loss: 0.3319 Acc: 0.8600 | Val Loss: 0.4520 Acc: 0.8031                                            \n",
      "Epoch 021 | Train Loss: 0.3108 Acc: 0.8700 | Val Loss: 0.3430 Acc: 0.8496                                            \n",
      "Epoch 022 | Train Loss: 0.2882 Acc: 0.8798 | Val Loss: 0.3455 Acc: 0.8527                                            \n",
      "Epoch 023 | Train Loss: 0.2755 Acc: 0.8874 | Val Loss: 0.3356 Acc: 0.8557                                            \n",
      "Epoch 024 | Train Loss: 0.2498 Acc: 0.8999 | Val Loss: 0.3321 Acc: 0.8659                                            \n",
      "Epoch 025 | Train Loss: 0.2326 Acc: 0.9056 | Val Loss: 0.3009 Acc: 0.8678                                            \n",
      "Epoch 026 | Train Loss: 0.2221 Acc: 0.9103 | Val Loss: 0.3127 Acc: 0.8647                                            \n",
      "Epoch 027 | Train Loss: 0.2048 Acc: 0.9186 | Val Loss: 0.2865 Acc: 0.8859                                            \n",
      "Epoch 028 | Train Loss: 0.1873 Acc: 0.9265 | Val Loss: 0.2894 Acc: 0.8841                                            \n",
      "Epoch 029 | Train Loss: 0.1842 Acc: 0.9280 | Val Loss: 0.3237 Acc: 0.8684                                            \n",
      "Epoch 030 | Train Loss: 0.1571 Acc: 0.9360 | Val Loss: 0.3004 Acc: 0.8786                                            \n",
      "Epoch 031 | Train Loss: 0.1460 Acc: 0.9447 | Val Loss: 0.2967 Acc: 0.8859                                            \n",
      "Epoch 032 | Train Loss: 0.1505 Acc: 0.9402 | Val Loss: 0.2869 Acc: 0.8973                                            \n",
      "Epoch 033 | Train Loss: 0.1310 Acc: 0.9485 | Val Loss: 0.2953 Acc: 0.8841                                            \n",
      "Epoch 034 | Train Loss: 0.1277 Acc: 0.9529 | Val Loss: 0.3619 Acc: 0.8774                                            \n",
      "Epoch 035 | Train Loss: 0.1267 Acc: 0.9535 | Val Loss: 0.3608 Acc: 0.8810                                            \n",
      "Epoch 036 | Train Loss: 0.1128 Acc: 0.9539 | Val Loss: 0.2835 Acc: 0.9010                                            \n",
      "Epoch 037 | Train Loss: 0.1085 Acc: 0.9571 | Val Loss: 0.3094 Acc: 0.8889                                            \n",
      "Epoch 038 | Train Loss: 0.0963 Acc: 0.9644 | Val Loss: 0.3029 Acc: 0.9064                                            \n",
      "Epoch 039 | Train Loss: 0.0955 Acc: 0.9645 | Val Loss: 0.2831 Acc: 0.9082                                            \n",
      "Epoch 040 | Train Loss: 0.0991 Acc: 0.9632 | Val Loss: 0.3006 Acc: 0.8967                                            \n",
      "Epoch 041 | Train Loss: 0.0950 Acc: 0.9635 | Val Loss: 0.2947 Acc: 0.8931                                            \n",
      "Epoch 042 | Train Loss: 0.0728 Acc: 0.9704 | Val Loss: 0.3572 Acc: 0.8907                                            \n",
      "Epoch 043 | Train Loss: 0.0757 Acc: 0.9721 | Val Loss: 0.3110 Acc: 0.8925                                            \n",
      "Epoch 044 | Train Loss: 0.0666 Acc: 0.9760 | Val Loss: 0.3060 Acc: 0.9064                                            \n",
      "Epoch 045 | Train Loss: 0.0738 Acc: 0.9706 | Val Loss: 0.2879 Acc: 0.9070                                            \n",
      "Epoch 046 | Train Loss: 0.0657 Acc: 0.9754 | Val Loss: 0.3358 Acc: 0.9022                                            \n",
      "Epoch 047 | Train Loss: 0.0618 Acc: 0.9799 | Val Loss: 0.2774 Acc: 0.9058                                            \n",
      "Epoch 048 | Train Loss: 0.0647 Acc: 0.9775 | Val Loss: 0.3955 Acc: 0.8998                                            \n",
      "Overfitting detected                                                                                                 \n",
      "Trial params:                                                                                                        \n",
      "{'batch_size': 16, 'cnn_dense': 32, 'cnn_dropout': 0.0039292918900647785, 'cnn_kernel_size_1': 5, 'cnn_kernels_1': 48, 'cnn_kernels_2': 32, 'learning_rate': 0.0005287659290713118, 'lstm_dense': 256, 'lstm_hidden_size': 32, 'lstm_layers': 1, 'optimizer': 'sgd'}\n",
      "Epoch 001 | Train Loss: 0.6879 Acc: 0.5467 | Val Loss: 0.6856 Acc: 0.5586                                            \n",
      "Epoch 002 | Train Loss: 0.6858 Acc: 0.5588 | Val Loss: 0.6851 Acc: 0.5598                                            \n",
      "Epoch 003 | Train Loss: 0.6847 Acc: 0.5600 | Val Loss: 0.6846 Acc: 0.5616                                            \n",
      "Epoch 004 | Train Loss: 0.6846 Acc: 0.5648 | Val Loss: 0.6839 Acc: 0.5628                                            \n",
      "Epoch 005 | Train Loss: 0.6834 Acc: 0.5650 | Val Loss: 0.6830 Acc: 0.5700                                            \n",
      "Epoch 006 | Train Loss: 0.6817 Acc: 0.5726 | Val Loss: 0.6820 Acc: 0.5725                                            \n",
      "Epoch 007 | Train Loss: 0.6805 Acc: 0.5768 | Val Loss: 0.6811 Acc: 0.5767                                            \n",
      "Epoch 008 | Train Loss: 0.6806 Acc: 0.5789 | Val Loss: 0.6802 Acc: 0.5785                                            \n",
      "Epoch 009 | Train Loss: 0.6779 Acc: 0.5831 | Val Loss: 0.6794 Acc: 0.5833                                            \n",
      "Epoch 010 | Train Loss: 0.6777 Acc: 0.5822 | Val Loss: 0.6790 Acc: 0.5857                                            \n",
      "Epoch 011 | Train Loss: 0.6768 Acc: 0.5860 | Val Loss: 0.6787 Acc: 0.5882                                            \n",
      "Epoch 012 | Train Loss: 0.6765 Acc: 0.5861 | Val Loss: 0.6787 Acc: 0.5870                                            \n",
      "Epoch 013 | Train Loss: 0.6765 Acc: 0.5867 | Val Loss: 0.6784 Acc: 0.5851                                            \n",
      "Epoch 014 | Train Loss: 0.6769 Acc: 0.5881 | Val Loss: 0.6786 Acc: 0.5876                                            \n",
      "Epoch 015 | Train Loss: 0.6761 Acc: 0.5863 | Val Loss: 0.6782 Acc: 0.5845                                            \n",
      "Epoch 016 | Train Loss: 0.6756 Acc: 0.5878 | Val Loss: 0.6781 Acc: 0.5876                                            \n",
      "Epoch 017 | Train Loss: 0.6763 Acc: 0.5867 | Val Loss: 0.6780 Acc: 0.5833                                            \n",
      "Epoch 018 | Train Loss: 0.6765 Acc: 0.5875 | Val Loss: 0.6779 Acc: 0.5870                                            \n",
      "Epoch 019 | Train Loss: 0.6748 Acc: 0.5886 | Val Loss: 0.6778 Acc: 0.5851                                            \n",
      "Epoch 020 | Train Loss: 0.6754 Acc: 0.5892 | Val Loss: 0.6777 Acc: 0.5839                                            \n",
      "Epoch 021 | Train Loss: 0.6750 Acc: 0.5890 | Val Loss: 0.6778 Acc: 0.5876                                            \n",
      "Epoch 022 | Train Loss: 0.6757 Acc: 0.5884 | Val Loss: 0.6775 Acc: 0.5864                                            \n",
      "Epoch 023 | Train Loss: 0.6753 Acc: 0.5886 | Val Loss: 0.6776 Acc: 0.5845                                            \n",
      "Epoch 024 | Train Loss: 0.6749 Acc: 0.5884 | Val Loss: 0.6774 Acc: 0.5845                                            \n",
      "Epoch 025 | Train Loss: 0.6742 Acc: 0.5902 | Val Loss: 0.6773 Acc: 0.5876                                            \n",
      "Epoch 026 | Train Loss: 0.6741 Acc: 0.5898 | Val Loss: 0.6774 Acc: 0.5857                                            \n",
      "Epoch 027 | Train Loss: 0.6746 Acc: 0.5892 | Val Loss: 0.6771 Acc: 0.5870                                            \n",
      "Epoch 028 | Train Loss: 0.6739 Acc: 0.5892 | Val Loss: 0.6770 Acc: 0.5876                                            \n",
      "Epoch 029 | Train Loss: 0.6750 Acc: 0.5901 | Val Loss: 0.6769 Acc: 0.5876                                            \n",
      "Epoch 030 | Train Loss: 0.6744 Acc: 0.5913 | Val Loss: 0.6769 Acc: 0.5876                                            \n",
      "Epoch 031 | Train Loss: 0.6745 Acc: 0.5931 | Val Loss: 0.6768 Acc: 0.5882                                            \n",
      "Epoch 032 | Train Loss: 0.6749 Acc: 0.5883 | Val Loss: 0.6766 Acc: 0.5870                                            \n",
      "Epoch 033 | Train Loss: 0.6743 Acc: 0.5875 | Val Loss: 0.6765 Acc: 0.5870                                            \n",
      "Epoch 034 | Train Loss: 0.6737 Acc: 0.5920 | Val Loss: 0.6764 Acc: 0.5882                                            \n",
      "Epoch 035 | Train Loss: 0.6738 Acc: 0.5892 | Val Loss: 0.6763 Acc: 0.5882                                            \n",
      "Epoch 036 | Train Loss: 0.6736 Acc: 0.5913 | Val Loss: 0.6762 Acc: 0.5888                                            \n",
      "Epoch 037 | Train Loss: 0.6734 Acc: 0.5895 | Val Loss: 0.6760 Acc: 0.5894                                            \n",
      "Epoch 038 | Train Loss: 0.6724 Acc: 0.5935 | Val Loss: 0.6760 Acc: 0.5900                                            \n",
      "Epoch 039 | Train Loss: 0.6738 Acc: 0.5902 | Val Loss: 0.6761 Acc: 0.5882                                            \n",
      "Epoch 040 | Train Loss: 0.6729 Acc: 0.5911 | Val Loss: 0.6756 Acc: 0.5894                                            \n",
      "Epoch 041 | Train Loss: 0.6727 Acc: 0.5913 | Val Loss: 0.6755 Acc: 0.5912                                            \n",
      "Epoch 042 | Train Loss: 0.6729 Acc: 0.5899 | Val Loss: 0.6752 Acc: 0.5894                                            \n",
      "Epoch 043 | Train Loss: 0.6716 Acc: 0.5914 | Val Loss: 0.6750 Acc: 0.5900                                            \n",
      "Epoch 044 | Train Loss: 0.6721 Acc: 0.5944 | Val Loss: 0.6748 Acc: 0.5888                                            \n",
      "Epoch 045 | Train Loss: 0.6719 Acc: 0.5914 | Val Loss: 0.6745 Acc: 0.5900                                            \n",
      "Epoch 046 | Train Loss: 0.6721 Acc: 0.5943 | Val Loss: 0.6747 Acc: 0.5918                                            \n",
      "Epoch 047 | Train Loss: 0.6710 Acc: 0.5935 | Val Loss: 0.6741 Acc: 0.5894                                            \n",
      "Epoch 048 | Train Loss: 0.6701 Acc: 0.5935 | Val Loss: 0.6740 Acc: 0.5912                                            \n",
      "Epoch 049 | Train Loss: 0.6699 Acc: 0.5955 | Val Loss: 0.6734 Acc: 0.5906                                            \n",
      "Epoch 050 | Train Loss: 0.6702 Acc: 0.5955 | Val Loss: 0.6734 Acc: 0.5924                                            \n",
      "Epoch 051 | Train Loss: 0.6685 Acc: 0.5982 | Val Loss: 0.6728 Acc: 0.5912                                            \n",
      "Epoch 052 | Train Loss: 0.6687 Acc: 0.5981 | Val Loss: 0.6729 Acc: 0.5924                                            \n",
      "Epoch 053 | Train Loss: 0.6690 Acc: 0.5981 | Val Loss: 0.6719 Acc: 0.5906                                            \n",
      "Epoch 054 | Train Loss: 0.6678 Acc: 0.6005 | Val Loss: 0.6713 Acc: 0.5894                                            \n",
      "Epoch 055 | Train Loss: 0.6668 Acc: 0.6017 | Val Loss: 0.6711 Acc: 0.5900                                            \n",
      "Epoch 056 | Train Loss: 0.6661 Acc: 0.5985 | Val Loss: 0.6707 Acc: 0.5924                                            \n",
      "Epoch 057 | Train Loss: 0.6664 Acc: 0.6029 | Val Loss: 0.6708 Acc: 0.5960                                            \n",
      "Epoch 058 | Train Loss: 0.6649 Acc: 0.6035 | Val Loss: 0.6698 Acc: 0.5942                                            \n",
      "Epoch 059 | Train Loss: 0.6639 Acc: 0.6046 | Val Loss: 0.6687 Acc: 0.5942                                            \n",
      "Epoch 060 | Train Loss: 0.6631 Acc: 0.6037 | Val Loss: 0.6683 Acc: 0.5942                                            \n",
      "Trial params:                                                                                                        \n",
      "{'batch_size': 16, 'cnn_dense': 32, 'cnn_dropout': 0.3526359457490698, 'cnn_kernel_size_1': 5, 'cnn_kernels_1': 16, 'cnn_kernels_2': 16, 'learning_rate': 0.0006240587684081365, 'lstm_dense': 128, 'lstm_hidden_size': 96, 'lstm_layers': 3, 'optimizer': 'adam'}\n",
      "Epoch 001 | Train Loss: 0.6828 Acc: 0.5680 | Val Loss: 0.6822 Acc: 0.5815                                            \n",
      "Epoch 002 | Train Loss: 0.6783 Acc: 0.5869 | Val Loss: 0.6756 Acc: 0.5857                                            \n",
      "Epoch 003 | Train Loss: 0.6763 Acc: 0.5893 | Val Loss: 0.6747 Acc: 0.5906                                            \n",
      "Epoch 004 | Train Loss: 0.6728 Acc: 0.5920 | Val Loss: 0.6736 Acc: 0.5924                                            \n",
      "Epoch 005 | Train Loss: 0.6688 Acc: 0.5993 | Val Loss: 0.6839 Acc: 0.5833                                            \n",
      "Epoch 006 | Train Loss: 0.6634 Acc: 0.6044 | Val Loss: 0.6664 Acc: 0.6014                                            \n",
      "Epoch 007 | Train Loss: 0.6593 Acc: 0.6150 | Val Loss: 0.6623 Acc: 0.6105                                            \n",
      "Epoch 008 | Train Loss: 0.6214 Acc: 0.6671 | Val Loss: 0.6065 Acc: 0.6932                                            \n",
      "Epoch 009 | Train Loss: 0.5873 Acc: 0.7062 | Val Loss: 0.5835 Acc: 0.6987                                            \n",
      "Epoch 010 | Train Loss: 0.5721 Acc: 0.7131 | Val Loss: 0.5734 Acc: 0.7162                                            \n",
      "Epoch 011 | Train Loss: 0.5635 Acc: 0.7169 | Val Loss: 0.5697 Acc: 0.7132                                            \n",
      "Epoch 012 | Train Loss: 0.5519 Acc: 0.7293 | Val Loss: 0.5517 Acc: 0.7168                                            \n",
      "Epoch 013 | Train Loss: 0.5435 Acc: 0.7287 | Val Loss: 0.5524 Acc: 0.7192                                            \n",
      "Epoch 014 | Train Loss: 0.5392 Acc: 0.7338 | Val Loss: 0.5605 Acc: 0.7216                                            \n",
      "Epoch 015 | Train Loss: 0.5343 Acc: 0.7350 | Val Loss: 0.5421 Acc: 0.7331                                            \n",
      "Epoch 016 | Train Loss: 0.5266 Acc: 0.7435 | Val Loss: 0.5362 Acc: 0.7415                                            \n",
      "Epoch 017 | Train Loss: 0.5136 Acc: 0.7498 | Val Loss: 0.5309 Acc: 0.7361                                            \n",
      "Epoch 018 | Train Loss: 0.5116 Acc: 0.7565 | Val Loss: 0.5200 Acc: 0.7446                                            \n",
      "Epoch 019 | Train Loss: 0.5088 Acc: 0.7548 | Val Loss: 0.5186 Acc: 0.7470                                            \n",
      "Epoch 020 | Train Loss: 0.4961 Acc: 0.7601 | Val Loss: 0.5492 Acc: 0.7264                                            \n",
      "Epoch 021 | Train Loss: 0.4964 Acc: 0.7565 | Val Loss: 0.5009 Acc: 0.7560                                            \n",
      "Epoch 022 | Train Loss: 0.4801 Acc: 0.7700 | Val Loss: 0.4978 Acc: 0.7579                                            \n",
      "Epoch 023 | Train Loss: 0.4706 Acc: 0.7740 | Val Loss: 0.4781 Acc: 0.7669                                            \n",
      "Epoch 024 | Train Loss: 0.4666 Acc: 0.7788 | Val Loss: 0.4851 Acc: 0.7585                                            \n",
      "Epoch 025 | Train Loss: 0.4608 Acc: 0.7793 | Val Loss: 0.4601 Acc: 0.7784                                            \n",
      "Epoch 026 | Train Loss: 0.4509 Acc: 0.7883 | Val Loss: 0.4473 Acc: 0.7814                                            \n",
      "Epoch 027 | Train Loss: 0.4485 Acc: 0.7910 | Val Loss: 0.4512 Acc: 0.7874                                            \n",
      "Epoch 028 | Train Loss: 0.4341 Acc: 0.7981 | Val Loss: 0.4581 Acc: 0.7723                                            \n",
      "Epoch 029 | Train Loss: 0.4345 Acc: 0.7975 | Val Loss: 0.4500 Acc: 0.7832                                            \n",
      "Epoch 030 | Train Loss: 0.4277 Acc: 0.8064 | Val Loss: 0.4390 Acc: 0.7868                                            \n",
      "Epoch 031 | Train Loss: 0.4210 Acc: 0.8076 | Val Loss: 0.4361 Acc: 0.7941                                            \n",
      "Epoch 032 | Train Loss: 0.4139 Acc: 0.8138 | Val Loss: 0.4447 Acc: 0.7862                                            \n",
      "Epoch 033 | Train Loss: 0.4064 Acc: 0.8153 | Val Loss: 0.4453 Acc: 0.7856                                            \n",
      "Epoch 034 | Train Loss: 0.4015 Acc: 0.8156 | Val Loss: 0.4329 Acc: 0.7923                                            \n",
      "Epoch 035 | Train Loss: 0.3984 Acc: 0.8188 | Val Loss: 0.4182 Acc: 0.8019                                            \n",
      "Epoch 036 | Train Loss: 0.3926 Acc: 0.8236 | Val Loss: 0.4158 Acc: 0.8031                                            \n",
      "Epoch 037 | Train Loss: 0.3829 Acc: 0.8288 | Val Loss: 0.4019 Acc: 0.8152                                            \n",
      "Epoch 038 | Train Loss: 0.3891 Acc: 0.8277 | Val Loss: 0.4116 Acc: 0.8013                                            \n",
      "Epoch 039 | Train Loss: 0.3801 Acc: 0.8330 | Val Loss: 0.3922 Acc: 0.8261                                            \n",
      "Epoch 040 | Train Loss: 0.3666 Acc: 0.8404 | Val Loss: 0.3985 Acc: 0.8116                                            \n",
      "Epoch 041 | Train Loss: 0.3701 Acc: 0.8378 | Val Loss: 0.3817 Acc: 0.8194                                            \n",
      "Epoch 042 | Train Loss: 0.3644 Acc: 0.8360 | Val Loss: 0.3727 Acc: 0.8303                                            \n",
      "Epoch 043 | Train Loss: 0.3499 Acc: 0.8448 | Val Loss: 0.3659 Acc: 0.8243                                            \n",
      "Epoch 044 | Train Loss: 0.3422 Acc: 0.8502 | Val Loss: 0.3909 Acc: 0.8261                                            \n",
      "Epoch 045 | Train Loss: 0.3447 Acc: 0.8470 | Val Loss: 0.3472 Acc: 0.8466                                            \n",
      "Epoch 046 | Train Loss: 0.3328 Acc: 0.8567 | Val Loss: 0.3544 Acc: 0.8376                                            \n",
      "Epoch 047 | Train Loss: 0.3287 Acc: 0.8541 | Val Loss: 0.3530 Acc: 0.8424                                            \n",
      "Epoch 048 | Train Loss: 0.3194 Acc: 0.8621 | Val Loss: 0.3516 Acc: 0.8478                                            \n",
      "Epoch 049 | Train Loss: 0.3201 Acc: 0.8581 | Val Loss: 0.3785 Acc: 0.8357                                            \n",
      "Epoch 050 | Train Loss: 0.3166 Acc: 0.8594 | Val Loss: 0.3387 Acc: 0.8575                                            \n",
      "Epoch 051 | Train Loss: 0.3180 Acc: 0.8656 | Val Loss: 0.3404 Acc: 0.8551                                            \n",
      "Epoch 052 | Train Loss: 0.3063 Acc: 0.8677 | Val Loss: 0.3289 Acc: 0.8508                                            \n",
      "Epoch 053 | Train Loss: 0.2966 Acc: 0.8753 | Val Loss: 0.3445 Acc: 0.8496                                            \n",
      "Epoch 054 | Train Loss: 0.3019 Acc: 0.8727 | Val Loss: 0.3309 Acc: 0.8581                                            \n",
      "Epoch 055 | Train Loss: 0.3000 Acc: 0.8721 | Val Loss: 0.3260 Acc: 0.8508                                            \n",
      "Epoch 056 | Train Loss: 0.2921 Acc: 0.8754 | Val Loss: 0.3310 Acc: 0.8569                                            \n",
      "Epoch 057 | Train Loss: 0.2959 Acc: 0.8778 | Val Loss: 0.3153 Acc: 0.8647                                            \n",
      "Epoch 058 | Train Loss: 0.2807 Acc: 0.8869 | Val Loss: 0.2985 Acc: 0.8714                                            \n",
      "Epoch 059 | Train Loss: 0.2861 Acc: 0.8768 | Val Loss: 0.3455 Acc: 0.8502                                            \n",
      "Epoch 060 | Train Loss: 0.2745 Acc: 0.8866 | Val Loss: 0.3023 Acc: 0.8678                                            \n",
      "Trial params:                                                                                                        \n",
      "{'batch_size': 64, 'cnn_dense': 32, 'cnn_dropout': 0.5281255356291215, 'cnn_kernel_size_1': 5, 'cnn_kernels_1': 64, 'cnn_kernels_2': 32, 'learning_rate': 0.0015912845834926477, 'lstm_dense': 128, 'lstm_hidden_size': 96, 'lstm_layers': 2, 'optimizer': 'rmsprop'}\n",
      "Epoch 001 | Train Loss: 0.6879 Acc: 0.5704 | Val Loss: 0.6764 Acc: 0.5888                                            \n",
      "Epoch 002 | Train Loss: 0.6768 Acc: 0.5828 | Val Loss: 0.7244 Acc: 0.5550                                            \n",
      "Epoch 003 | Train Loss: 0.6677 Acc: 0.5993 | Val Loss: 0.6418 Acc: 0.6298                                            \n",
      "Epoch 004 | Train Loss: 0.6257 Acc: 0.6653 | Val Loss: 0.6055 Acc: 0.6800                                            \n",
      "Epoch 005 | Train Loss: 0.5895 Acc: 0.6982 | Val Loss: 0.5792 Acc: 0.7011                                            \n",
      "Epoch 006 | Train Loss: 0.5662 Acc: 0.7195 | Val Loss: 0.5638 Acc: 0.7186                                            \n",
      "Epoch 007 | Train Loss: 0.5521 Acc: 0.7237 | Val Loss: 0.5637 Acc: 0.7114                                            \n",
      "Epoch 008 | Train Loss: 0.5448 Acc: 0.7323 | Val Loss: 0.5492 Acc: 0.7313                                            \n",
      "Epoch 009 | Train Loss: 0.5340 Acc: 0.7438 | Val Loss: 0.5346 Acc: 0.7355                                            \n",
      "Epoch 010 | Train Loss: 0.5174 Acc: 0.7506 | Val Loss: 0.5249 Acc: 0.7428                                            \n",
      "Epoch 011 | Train Loss: 0.5146 Acc: 0.7521 | Val Loss: 0.5885 Acc: 0.6896                                            \n",
      "Epoch 012 | Train Loss: 0.4974 Acc: 0.7651 | Val Loss: 0.5101 Acc: 0.7548                                            \n",
      "Epoch 013 | Train Loss: 0.4793 Acc: 0.7725 | Val Loss: 0.4768 Acc: 0.7699                                            \n",
      "Epoch 014 | Train Loss: 0.4766 Acc: 0.7729 | Val Loss: 0.4647 Acc: 0.7705                                            \n",
      "Epoch 015 | Train Loss: 0.4623 Acc: 0.7844 | Val Loss: 0.4694 Acc: 0.7705                                            \n",
      "Epoch 016 | Train Loss: 0.4484 Acc: 0.7925 | Val Loss: 0.4961 Acc: 0.7699                                            \n",
      "Epoch 017 | Train Loss: 0.4333 Acc: 0.7996 | Val Loss: 0.4355 Acc: 0.8013                                            \n",
      "Epoch 018 | Train Loss: 0.4331 Acc: 0.7956 | Val Loss: 0.4448 Acc: 0.7880                                            \n",
      "Epoch 019 | Train Loss: 0.4210 Acc: 0.8066 | Val Loss: 0.3860 Acc: 0.8164                                            \n",
      "Epoch 020 | Train Loss: 0.4091 Acc: 0.8205 | Val Loss: 0.3956 Acc: 0.8158                                            \n",
      "Epoch 021 | Train Loss: 0.3979 Acc: 0.8194 | Val Loss: 0.3880 Acc: 0.8152                                            \n",
      "Epoch 022 | Train Loss: 0.3843 Acc: 0.8285 | Val Loss: 0.3869 Acc: 0.8237                                            \n",
      "Epoch 023 | Train Loss: 0.3809 Acc: 0.8283 | Val Loss: 0.4000 Acc: 0.8200                                            \n",
      "Epoch 024 | Train Loss: 0.3663 Acc: 0.8412 | Val Loss: 0.3825 Acc: 0.8231                                            \n",
      "Epoch 025 | Train Loss: 0.3561 Acc: 0.8401 | Val Loss: 0.3363 Acc: 0.8557                                            \n",
      "Epoch 026 | Train Loss: 0.3464 Acc: 0.8502 | Val Loss: 0.3345 Acc: 0.8605                                            \n",
      "Epoch 027 | Train Loss: 0.3403 Acc: 0.8517 | Val Loss: 0.3278 Acc: 0.8533                                            \n",
      "Epoch 028 | Train Loss: 0.3282 Acc: 0.8596 | Val Loss: 0.3743 Acc: 0.8315                                            \n",
      "Epoch 029 | Train Loss: 0.3320 Acc: 0.8558 | Val Loss: 0.3031 Acc: 0.8708                                            \n",
      "Epoch 030 | Train Loss: 0.3061 Acc: 0.8705 | Val Loss: 0.3043 Acc: 0.8702                                            \n",
      "Epoch 031 | Train Loss: 0.3169 Acc: 0.8674 | Val Loss: 0.3163 Acc: 0.8684                                            \n",
      "Epoch 032 | Train Loss: 0.3065 Acc: 0.8689 | Val Loss: 0.2775 Acc: 0.8816                                            \n",
      "Epoch 033 | Train Loss: 0.3010 Acc: 0.8738 | Val Loss: 0.2903 Acc: 0.8756                                            \n",
      "Epoch 034 | Train Loss: 0.2918 Acc: 0.8783 | Val Loss: 0.2818 Acc: 0.8822                                            \n",
      "Epoch 035 | Train Loss: 0.2873 Acc: 0.8813 | Val Loss: 0.2790 Acc: 0.8774                                            \n",
      "Epoch 036 | Train Loss: 0.2717 Acc: 0.8881 | Val Loss: 0.2521 Acc: 0.8913                                            \n",
      "Epoch 037 | Train Loss: 0.2835 Acc: 0.8834 | Val Loss: 0.2700 Acc: 0.8883                                            \n",
      "Epoch 038 | Train Loss: 0.2726 Acc: 0.8898 | Val Loss: 0.2698 Acc: 0.8816                                            \n",
      "Epoch 039 | Train Loss: 0.2654 Acc: 0.8933 | Val Loss: 0.3013 Acc: 0.8702                                            \n",
      "Epoch 040 | Train Loss: 0.2564 Acc: 0.8954 | Val Loss: 0.2525 Acc: 0.8901                                            \n",
      "Epoch 041 | Train Loss: 0.2595 Acc: 0.8945 | Val Loss: 0.2859 Acc: 0.8768                                            \n",
      "Epoch 042 | Train Loss: 0.2600 Acc: 0.8975 | Val Loss: 0.2739 Acc: 0.8829                                            \n",
      "Epoch 043 | Train Loss: 0.2471 Acc: 0.9014 | Val Loss: 0.2477 Acc: 0.8925                                            \n",
      "Epoch 044 | Train Loss: 0.2433 Acc: 0.8996 | Val Loss: 0.2141 Acc: 0.9094                                            \n",
      "Epoch 045 | Train Loss: 0.2345 Acc: 0.9070 | Val Loss: 0.2217 Acc: 0.9040                                            \n",
      "Epoch 046 | Train Loss: 0.2400 Acc: 0.9059 | Val Loss: 0.2564 Acc: 0.8871                                            \n",
      "Epoch 047 | Train Loss: 0.2289 Acc: 0.9071 | Val Loss: 0.2376 Acc: 0.8967                                            \n",
      "Epoch 048 | Train Loss: 0.2308 Acc: 0.9032 | Val Loss: 0.2019 Acc: 0.9179                                            \n",
      "Epoch 049 | Train Loss: 0.2292 Acc: 0.9040 | Val Loss: 0.3197 Acc: 0.8690                                            \n",
      "Epoch 050 | Train Loss: 0.2144 Acc: 0.9136 | Val Loss: 0.2558 Acc: 0.8883                                            \n",
      "Epoch 051 | Train Loss: 0.2147 Acc: 0.9115 | Val Loss: 0.2333 Acc: 0.9058                                            \n",
      "Epoch 052 | Train Loss: 0.2207 Acc: 0.9074 | Val Loss: 0.2674 Acc: 0.9028                                            \n",
      "Epoch 053 | Train Loss: 0.2112 Acc: 0.9161 | Val Loss: 0.2399 Acc: 0.9016                                            \n",
      "Epoch 054 | Train Loss: 0.2082 Acc: 0.9176 | Val Loss: 0.2712 Acc: 0.8853                                            \n",
      "Epoch 055 | Train Loss: 0.2124 Acc: 0.9142 | Val Loss: 0.2099 Acc: 0.9130                                            \n",
      "Epoch 056 | Train Loss: 0.2037 Acc: 0.9206 | Val Loss: 0.2318 Acc: 0.8967                                            \n",
      "Epoch 057 | Train Loss: 0.2078 Acc: 0.9177 | Val Loss: 0.1953 Acc: 0.9221                                            \n",
      "Epoch 058 | Train Loss: 0.2029 Acc: 0.9218 | Val Loss: 0.2087 Acc: 0.9112                                            \n",
      "Epoch 059 | Train Loss: 0.1979 Acc: 0.9215 | Val Loss: 0.2225 Acc: 0.9118                                            \n",
      "Epoch 060 | Train Loss: 0.1971 Acc: 0.9219 | Val Loss: 0.2317 Acc: 0.9100                                            \n",
      "Trial params:                                                                                                        \n",
      "{'batch_size': 36, 'cnn_dense': 128, 'cnn_dropout': 0.37417732645995094, 'cnn_kernel_size_1': 5, 'cnn_kernels_1': 48, 'cnn_kernels_2': 16, 'learning_rate': 0.0025847517720477176, 'lstm_dense': 64, 'lstm_hidden_size': 32, 'lstm_layers': 3, 'optimizer': 'rmsprop'}\n",
      "Epoch 001 | Train Loss: 0.6868 Acc: 0.5652 | Val Loss: 0.6782 Acc: 0.5845                                            \n",
      "Epoch 002 | Train Loss: 0.6730 Acc: 0.5944 | Val Loss: 0.6628 Acc: 0.6051                                            \n",
      "Epoch 003 | Train Loss: 0.6627 Acc: 0.6082 | Val Loss: 0.6567 Acc: 0.6117                                            \n",
      "Epoch 004 | Train Loss: 0.6513 Acc: 0.6299 | Val Loss: 0.6250 Acc: 0.6769                                            \n",
      "Epoch 005 | Train Loss: 0.6287 Acc: 0.6689 | Val Loss: 0.6025 Acc: 0.6993                                            \n",
      "Epoch 006 | Train Loss: 0.5988 Acc: 0.7024 | Val Loss: 0.5771 Acc: 0.7083                                            \n",
      "Epoch 007 | Train Loss: 0.5765 Acc: 0.7133 | Val Loss: 0.5679 Acc: 0.7107                                            \n",
      "Epoch 008 | Train Loss: 0.5661 Acc: 0.7226 | Val Loss: 0.5485 Acc: 0.7331                                            \n",
      "Epoch 009 | Train Loss: 0.5506 Acc: 0.7371 | Val Loss: 0.5575 Acc: 0.7186                                            \n",
      "Epoch 010 | Train Loss: 0.5389 Acc: 0.7409 | Val Loss: 0.5208 Acc: 0.7367                                            \n",
      "Epoch 011 | Train Loss: 0.5249 Acc: 0.7498 | Val Loss: 0.5237 Acc: 0.7403                                            \n",
      "Epoch 012 | Train Loss: 0.5153 Acc: 0.7543 | Val Loss: 0.4933 Acc: 0.7621                                            \n",
      "Epoch 013 | Train Loss: 0.5067 Acc: 0.7640 | Val Loss: 0.4855 Acc: 0.7723                                            \n",
      "Epoch 014 | Train Loss: 0.4884 Acc: 0.7726 | Val Loss: 0.4506 Acc: 0.7820                                            \n",
      "Epoch 015 | Train Loss: 0.4768 Acc: 0.7839 | Val Loss: 0.4403 Acc: 0.7905                                            \n",
      "Epoch 016 | Train Loss: 0.4554 Acc: 0.7877 | Val Loss: 0.4317 Acc: 0.7929                                            \n",
      "Epoch 017 | Train Loss: 0.4590 Acc: 0.7909 | Val Loss: 0.4623 Acc: 0.7711                                            \n",
      "Epoch 018 | Train Loss: 0.4358 Acc: 0.8046 | Val Loss: 0.4039 Acc: 0.8062                                            \n",
      "Epoch 019 | Train Loss: 0.4213 Acc: 0.8131 | Val Loss: 0.3832 Acc: 0.8339                                            \n",
      "Epoch 020 | Train Loss: 0.4100 Acc: 0.8155 | Val Loss: 0.3923 Acc: 0.8303                                            \n",
      "Epoch 021 | Train Loss: 0.3932 Acc: 0.8218 | Val Loss: 0.3802 Acc: 0.8152                                            \n",
      "Epoch 022 | Train Loss: 0.3834 Acc: 0.8339 | Val Loss: 0.3747 Acc: 0.8364                                            \n",
      "Epoch 023 | Train Loss: 0.3672 Acc: 0.8418 | Val Loss: 0.3393 Acc: 0.8587                                            \n",
      "Epoch 024 | Train Loss: 0.3621 Acc: 0.8443 | Val Loss: 0.3619 Acc: 0.8394                                            \n",
      "Epoch 025 | Train Loss: 0.3430 Acc: 0.8554 | Val Loss: 0.5258 Acc: 0.7295                                            \n",
      "Epoch 026 | Train Loss: 0.3430 Acc: 0.8564 | Val Loss: 0.3163 Acc: 0.8635                                            \n",
      "Epoch 027 | Train Loss: 0.3276 Acc: 0.8659 | Val Loss: 0.3311 Acc: 0.8539                                            \n",
      "Epoch 028 | Train Loss: 0.3137 Acc: 0.8647 | Val Loss: 0.2975 Acc: 0.8853                                            \n",
      "Epoch 029 | Train Loss: 0.3044 Acc: 0.8736 | Val Loss: 0.2933 Acc: 0.8816                                            \n",
      "Epoch 030 | Train Loss: 0.3060 Acc: 0.8724 | Val Loss: 0.3192 Acc: 0.8587                                            \n",
      "Epoch 031 | Train Loss: 0.3010 Acc: 0.8785 | Val Loss: 0.3170 Acc: 0.8708                                            \n",
      "Epoch 032 | Train Loss: 0.2806 Acc: 0.8839 | Val Loss: 0.2768 Acc: 0.8859                                            \n",
      "Epoch 033 | Train Loss: 0.2816 Acc: 0.8857 | Val Loss: 0.2547 Acc: 0.9010                                            \n",
      "Epoch 034 | Train Loss: 0.2759 Acc: 0.8910 | Val Loss: 0.2676 Acc: 0.8889                                            \n",
      "Epoch 035 | Train Loss: 0.2681 Acc: 0.8949 | Val Loss: 0.2844 Acc: 0.8835                                            \n",
      "Epoch 036 | Train Loss: 0.2457 Acc: 0.9046 | Val Loss: 0.2447 Acc: 0.9028                                            \n",
      "Epoch 037 | Train Loss: 0.2531 Acc: 0.8969 | Val Loss: 0.2745 Acc: 0.8816                                            \n",
      "Epoch 038 | Train Loss: 0.2510 Acc: 0.9026 | Val Loss: 0.2517 Acc: 0.9028                                            \n",
      "Epoch 039 | Train Loss: 0.2414 Acc: 0.9062 | Val Loss: 0.2251 Acc: 0.9088                                            \n",
      "Epoch 040 | Train Loss: 0.2374 Acc: 0.9038 | Val Loss: 0.2352 Acc: 0.9046                                            \n",
      "Epoch 041 | Train Loss: 0.2311 Acc: 0.9094 | Val Loss: 0.2778 Acc: 0.8696                                            \n",
      "Epoch 042 | Train Loss: 0.2250 Acc: 0.9114 | Val Loss: 0.2458 Acc: 0.9046                                            \n",
      "Epoch 043 | Train Loss: 0.2252 Acc: 0.9151 | Val Loss: 0.2079 Acc: 0.9136                                            \n",
      "Epoch 044 | Train Loss: 0.2074 Acc: 0.9171 | Val Loss: 0.2118 Acc: 0.9143                                            \n",
      "Epoch 045 | Train Loss: 0.2127 Acc: 0.9173 | Val Loss: 0.2177 Acc: 0.9161                                            \n",
      "Epoch 046 | Train Loss: 0.2110 Acc: 0.9195 | Val Loss: 0.2181 Acc: 0.9161                                            \n",
      "Epoch 047 | Train Loss: 0.2044 Acc: 0.9227 | Val Loss: 0.2530 Acc: 0.9040                                            \n",
      "Epoch 048 | Train Loss: 0.2025 Acc: 0.9209 | Val Loss: 0.2206 Acc: 0.9167                                            \n",
      "Epoch 049 | Train Loss: 0.2005 Acc: 0.9210 | Val Loss: 0.2090 Acc: 0.9197                                            \n",
      "Epoch 050 | Train Loss: 0.1986 Acc: 0.9266 | Val Loss: 0.2157 Acc: 0.9227                                            \n",
      "Epoch 051 | Train Loss: 0.1867 Acc: 0.9269 | Val Loss: 0.2090 Acc: 0.9185                                            \n",
      "Epoch 052 | Train Loss: 0.1843 Acc: 0.9284 | Val Loss: 0.2125 Acc: 0.9233                                            \n",
      "Epoch 053 | Train Loss: 0.1807 Acc: 0.9334 | Val Loss: 0.2278 Acc: 0.9088                                            \n",
      "Early stopping triggered.                                                                                            \n",
      "Trial params:                                                                                                        \n",
      "{'batch_size': 16, 'cnn_dense': 128, 'cnn_dropout': 0.33017254569830606, 'cnn_kernel_size_1': 5, 'cnn_kernels_1': 32, 'cnn_kernels_2': 32, 'learning_rate': 0.00041924287820583423, 'lstm_dense': 64, 'lstm_hidden_size': 128, 'lstm_layers': 3, 'optimizer': 'adam'}\n",
      "Epoch 001 | Train Loss: 0.6817 Acc: 0.5792 | Val Loss: 0.6785 Acc: 0.5767                                            \n",
      "Epoch 002 | Train Loss: 0.6708 Acc: 0.5966 | Val Loss: 0.6637 Acc: 0.5930                                            \n",
      "Epoch 003 | Train Loss: 0.6515 Acc: 0.6260 | Val Loss: 0.6489 Acc: 0.6298                                            \n",
      "Epoch 004 | Train Loss: 0.6188 Acc: 0.6813 | Val Loss: 0.5906 Acc: 0.7083                                            \n",
      "Epoch 005 | Train Loss: 0.5822 Acc: 0.7139 | Val Loss: 0.5667 Acc: 0.7168                                            \n",
      "Epoch 006 | Train Loss: 0.5685 Acc: 0.7219 | Val Loss: 0.5694 Acc: 0.7047                                            \n",
      "Epoch 007 | Train Loss: 0.5510 Acc: 0.7347 | Val Loss: 0.5530 Acc: 0.7331                                            \n",
      "Epoch 008 | Train Loss: 0.5431 Acc: 0.7359 | Val Loss: 0.5580 Acc: 0.7156                                            \n",
      "Epoch 009 | Train Loss: 0.5288 Acc: 0.7504 | Val Loss: 0.5264 Acc: 0.7379                                            \n",
      "Epoch 010 | Train Loss: 0.5201 Acc: 0.7521 | Val Loss: 0.5177 Acc: 0.7434                                            \n",
      "Epoch 011 | Train Loss: 0.5096 Acc: 0.7595 | Val Loss: 0.5388 Acc: 0.7331                                            \n",
      "Epoch 012 | Train Loss: 0.5045 Acc: 0.7610 | Val Loss: 0.5022 Acc: 0.7524                                            \n",
      "Epoch 013 | Train Loss: 0.4889 Acc: 0.7743 | Val Loss: 0.5007 Acc: 0.7633                                            \n",
      "Epoch 014 | Train Loss: 0.4800 Acc: 0.7743 | Val Loss: 0.4769 Acc: 0.7687                                            \n",
      "Epoch 015 | Train Loss: 0.4658 Acc: 0.7850 | Val Loss: 0.4650 Acc: 0.7760                                            \n",
      "Epoch 016 | Train Loss: 0.4611 Acc: 0.7841 | Val Loss: 0.4542 Acc: 0.7856                                            \n",
      "Epoch 017 | Train Loss: 0.4509 Acc: 0.7907 | Val Loss: 0.4461 Acc: 0.7874                                            \n",
      "Epoch 018 | Train Loss: 0.4417 Acc: 0.7934 | Val Loss: 0.4521 Acc: 0.7868                                            \n",
      "Epoch 019 | Train Loss: 0.4338 Acc: 0.7971 | Val Loss: 0.4271 Acc: 0.7923                                            \n",
      "Epoch 020 | Train Loss: 0.4158 Acc: 0.8076 | Val Loss: 0.4011 Acc: 0.8092                                            \n",
      "Epoch 021 | Train Loss: 0.3997 Acc: 0.8170 | Val Loss: 0.4017 Acc: 0.8074                                            \n",
      "Epoch 022 | Train Loss: 0.3883 Acc: 0.8262 | Val Loss: 0.3897 Acc: 0.8134                                            \n",
      "Epoch 023 | Train Loss: 0.3730 Acc: 0.8372 | Val Loss: 0.3793 Acc: 0.8249                                            \n",
      "Epoch 024 | Train Loss: 0.3563 Acc: 0.8412 | Val Loss: 0.3450 Acc: 0.8442                                            \n",
      "Epoch 025 | Train Loss: 0.3410 Acc: 0.8499 | Val Loss: 0.3320 Acc: 0.8478                                            \n",
      "Epoch 026 | Train Loss: 0.3299 Acc: 0.8557 | Val Loss: 0.3444 Acc: 0.8460                                            \n",
      "Epoch 027 | Train Loss: 0.3185 Acc: 0.8621 | Val Loss: 0.3115 Acc: 0.8653                                            \n",
      "Epoch 028 | Train Loss: 0.3104 Acc: 0.8682 | Val Loss: 0.3244 Acc: 0.8611                                            \n",
      "Epoch 029 | Train Loss: 0.3007 Acc: 0.8717 | Val Loss: 0.2927 Acc: 0.8720                                            \n",
      "Epoch 030 | Train Loss: 0.2867 Acc: 0.8813 | Val Loss: 0.3068 Acc: 0.8647                                            \n",
      "Epoch 031 | Train Loss: 0.2800 Acc: 0.8852 | Val Loss: 0.2970 Acc: 0.8762                                            \n",
      "Epoch 032 | Train Loss: 0.2703 Acc: 0.8868 | Val Loss: 0.2588 Acc: 0.8943                                            \n",
      "Epoch 033 | Train Loss: 0.2609 Acc: 0.8913 | Val Loss: 0.2895 Acc: 0.8810                                            \n",
      "Epoch 034 | Train Loss: 0.2551 Acc: 0.8920 | Val Loss: 0.2640 Acc: 0.8816                                            \n",
      "Epoch 035 | Train Loss: 0.2424 Acc: 0.9013 | Val Loss: 0.3103 Acc: 0.8690                                            \n",
      "Epoch 036 | Train Loss: 0.2340 Acc: 0.9035 | Val Loss: 0.2574 Acc: 0.8859                                            \n",
      "Epoch 037 | Train Loss: 0.2240 Acc: 0.9094 | Val Loss: 0.2746 Acc: 0.8835                                            \n",
      "Epoch 038 | Train Loss: 0.2195 Acc: 0.9144 | Val Loss: 0.2404 Acc: 0.8913                                            \n",
      "Epoch 039 | Train Loss: 0.2102 Acc: 0.9115 | Val Loss: 0.2418 Acc: 0.8949                                            \n",
      "Epoch 040 | Train Loss: 0.2090 Acc: 0.9188 | Val Loss: 0.2478 Acc: 0.8973                                            \n",
      "Epoch 041 | Train Loss: 0.2144 Acc: 0.9162 | Val Loss: 0.2764 Acc: 0.8889                                            \n",
      "Epoch 042 | Train Loss: 0.2026 Acc: 0.9188 | Val Loss: 0.2303 Acc: 0.9022                                            \n",
      "Epoch 043 | Train Loss: 0.1938 Acc: 0.9233 | Val Loss: 0.2113 Acc: 0.9173                                            \n",
      "Epoch 044 | Train Loss: 0.1870 Acc: 0.9263 | Val Loss: 0.2209 Acc: 0.9118                                            \n",
      "Epoch 045 | Train Loss: 0.1838 Acc: 0.9289 | Val Loss: 0.2067 Acc: 0.9155                                            \n",
      "Epoch 046 | Train Loss: 0.1807 Acc: 0.9275 | Val Loss: 0.2286 Acc: 0.9179                                            \n",
      "Epoch 047 | Train Loss: 0.1774 Acc: 0.9301 | Val Loss: 0.2020 Acc: 0.9203                                            \n",
      "Epoch 048 | Train Loss: 0.1740 Acc: 0.9316 | Val Loss: 0.2064 Acc: 0.9118                                            \n",
      "Epoch 049 | Train Loss: 0.1748 Acc: 0.9315 | Val Loss: 0.2024 Acc: 0.9197                                            \n",
      "Epoch 050 | Train Loss: 0.1648 Acc: 0.9337 | Val Loss: 0.1965 Acc: 0.9197                                            \n",
      "Epoch 051 | Train Loss: 0.1509 Acc: 0.9402 | Val Loss: 0.2487 Acc: 0.9082                                            \n",
      "Epoch 052 | Train Loss: 0.1664 Acc: 0.9392 | Val Loss: 0.2044 Acc: 0.9209                                            \n",
      "Epoch 053 | Train Loss: 0.1519 Acc: 0.9407 | Val Loss: 0.1794 Acc: 0.9318                                            \n",
      "Epoch 054 | Train Loss: 0.1570 Acc: 0.9393 | Val Loss: 0.2072 Acc: 0.9233                                            \n",
      "Epoch 055 | Train Loss: 0.1408 Acc: 0.9459 | Val Loss: 0.1999 Acc: 0.9245                                            \n",
      "Epoch 056 | Train Loss: 0.1456 Acc: 0.9446 | Val Loss: 0.2217 Acc: 0.9070                                            \n",
      "Epoch 057 | Train Loss: 0.1423 Acc: 0.9469 | Val Loss: 0.1688 Acc: 0.9312                                            \n",
      "Epoch 058 | Train Loss: 0.1291 Acc: 0.9505 | Val Loss: 0.1871 Acc: 0.9245                                            \n",
      "Epoch 059 | Train Loss: 0.1272 Acc: 0.9529 | Val Loss: 0.1988 Acc: 0.9173                                            \n",
      "Epoch 060 | Train Loss: 0.1348 Acc: 0.9462 | Val Loss: 0.1831 Acc: 0.9287                                            \n",
      "Trial params:                                                                                                        \n",
      "{'batch_size': 36, 'cnn_dense': 128, 'cnn_dropout': 0.5308051973238408, 'cnn_kernel_size_1': 3, 'cnn_kernels_1': 32, 'cnn_kernels_2': 32, 'learning_rate': 0.004868043675509128, 'lstm_dense': 256, 'lstm_hidden_size': 128, 'lstm_layers': 3, 'optimizer': 'rmsprop'}\n",
      "Epoch 001 | Train Loss: 0.8163 Acc: 0.5463 | Val Loss: 0.7120 Acc: 0.5374                                            \n",
      "Epoch 002 | Train Loss: 0.6861 Acc: 0.5537 | Val Loss: 0.6798 Acc: 0.5586                                            \n",
      "Epoch 003 | Train Loss: 0.6790 Acc: 0.5695 | Val Loss: 0.6705 Acc: 0.5797                                            \n",
      "Epoch 004 | Train Loss: 0.6742 Acc: 0.6038 | Val Loss: 0.6510 Acc: 0.6250                                            \n",
      "Epoch 005 | Train Loss: 0.6854 Acc: 0.5938 | Val Loss: 0.6439 Acc: 0.6316                                            \n",
      "Epoch 006 | Train Loss: 0.6659 Acc: 0.6171 | Val Loss: 0.6407 Acc: 0.6516                                            \n",
      "Epoch 007 | Train Loss: 0.6493 Acc: 0.6420 | Val Loss: 0.6501 Acc: 0.6534                                            \n",
      "Epoch 008 | Train Loss: 0.6366 Acc: 0.6589 | Val Loss: 0.6320 Acc: 0.6649                                            \n",
      "Epoch 009 | Train Loss: 0.6284 Acc: 0.6705 | Val Loss: 0.6279 Acc: 0.6618                                            \n",
      "Epoch 010 | Train Loss: 0.6223 Acc: 0.6779 | Val Loss: 0.6007 Acc: 0.6914                                            \n",
      "Epoch 011 | Train Loss: 0.6210 Acc: 0.6787 | Val Loss: 0.5921 Acc: 0.6981                                            \n",
      "Epoch 012 | Train Loss: 0.6134 Acc: 0.6843 | Val Loss: 0.5817 Acc: 0.7017                                            \n",
      "Epoch 013 | Train Loss: 0.6140 Acc: 0.6945 | Val Loss: 0.5885 Acc: 0.7186                                            \n",
      "Epoch 014 | Train Loss: 0.6116 Acc: 0.6873 | Val Loss: 0.6037 Acc: 0.6950                                            \n",
      "Epoch 015 | Train Loss: 0.6216 Acc: 0.6776 | Val Loss: 0.6083 Acc: 0.6727                                            \n",
      "Epoch 016 | Train Loss: 0.6172 Acc: 0.6795 | Val Loss: 0.5727 Acc: 0.7150                                            \n",
      "Epoch 017 | Train Loss: 0.6019 Acc: 0.6945 | Val Loss: 0.5784 Acc: 0.7029                                            \n",
      "Epoch 018 | Train Loss: 0.6056 Acc: 0.6867 | Val Loss: 0.5891 Acc: 0.6908                                            \n",
      "Epoch 019 | Train Loss: 0.5995 Acc: 0.6941 | Val Loss: 0.5783 Acc: 0.7083                                            \n",
      "Epoch 020 | Train Loss: 0.6022 Acc: 0.6844 | Val Loss: 0.6138 Acc: 0.6486                                            \n",
      "Epoch 021 | Train Loss: 0.5892 Acc: 0.6997 | Val Loss: 0.5743 Acc: 0.7059                                            \n",
      "Epoch 022 | Train Loss: 0.5899 Acc: 0.6989 | Val Loss: 0.5635 Acc: 0.7210                                            \n",
      "Epoch 023 | Train Loss: 0.5810 Acc: 0.7066 | Val Loss: 0.5759 Acc: 0.6920                                            \n",
      "Epoch 024 | Train Loss: 0.5852 Acc: 0.7060 | Val Loss: 0.5745 Acc: 0.7222                                            \n",
      "Epoch 025 | Train Loss: 0.5812 Acc: 0.7125 | Val Loss: 0.5703 Acc: 0.7210                                            \n",
      "Epoch 026 | Train Loss: 0.5699 Acc: 0.7208 | Val Loss: 0.5579 Acc: 0.7168                                            \n",
      "Epoch 027 | Train Loss: 0.5679 Acc: 0.7235 | Val Loss: 0.5417 Acc: 0.7373                                            \n",
      "Epoch 028 | Train Loss: 0.5639 Acc: 0.7294 | Val Loss: 0.5419 Acc: 0.7301                                            \n",
      "Epoch 029 | Train Loss: 0.5578 Acc: 0.7243 | Val Loss: 0.5622 Acc: 0.7186                                            \n",
      "Epoch 030 | Train Loss: 0.5527 Acc: 0.7383 | Val Loss: 0.5859 Acc: 0.6908                                            \n",
      "Epoch 031 | Train Loss: 0.5551 Acc: 0.7287 | Val Loss: 0.5562 Acc: 0.7198                                            \n",
      "Epoch 032 | Train Loss: 0.5483 Acc: 0.7332 | Val Loss: 0.5273 Acc: 0.7379                                            \n",
      "Epoch 033 | Train Loss: 0.5379 Acc: 0.7403 | Val Loss: 0.5155 Acc: 0.7506                                            \n",
      "Epoch 034 | Train Loss: 0.5444 Acc: 0.7352 | Val Loss: 0.5126 Acc: 0.7512                                            \n",
      "Epoch 035 | Train Loss: 0.5378 Acc: 0.7442 | Val Loss: 0.5200 Acc: 0.7591                                            \n",
      "Epoch 036 | Train Loss: 0.5289 Acc: 0.7507 | Val Loss: 0.5029 Acc: 0.7572                                            \n",
      "Epoch 037 | Train Loss: 0.5308 Acc: 0.7462 | Val Loss: 0.5102 Acc: 0.7566                                            \n",
      "Epoch 038 | Train Loss: 0.5234 Acc: 0.7521 | Val Loss: 0.5125 Acc: 0.7458                                            \n",
      "Epoch 039 | Train Loss: 0.5259 Acc: 0.7504 | Val Loss: 0.4973 Acc: 0.7814                                            \n",
      "Epoch 040 | Train Loss: 0.5197 Acc: 0.7522 | Val Loss: 0.4845 Acc: 0.7742                                            \n",
      "Epoch 041 | Train Loss: 0.5112 Acc: 0.7537 | Val Loss: 0.5045 Acc: 0.7615                                            \n",
      "Epoch 042 | Train Loss: 0.5150 Acc: 0.7548 | Val Loss: 0.4951 Acc: 0.7669                                            \n",
      "Epoch 043 | Train Loss: 0.5031 Acc: 0.7664 | Val Loss: 0.4847 Acc: 0.7560                                            \n",
      "Epoch 044 | Train Loss: 0.4985 Acc: 0.7636 | Val Loss: 0.4683 Acc: 0.7856                                            \n",
      "Epoch 045 | Train Loss: 0.5001 Acc: 0.7685 | Val Loss: 0.4914 Acc: 0.7591                                            \n",
      "Epoch 046 | Train Loss: 0.4984 Acc: 0.7670 | Val Loss: 0.4923 Acc: 0.7657                                            \n",
      "Epoch 047 | Train Loss: 0.4953 Acc: 0.7679 | Val Loss: 0.4521 Acc: 0.7953                                            \n",
      "Epoch 048 | Train Loss: 0.4899 Acc: 0.7666 | Val Loss: 0.4570 Acc: 0.7899                                            \n",
      "Epoch 049 | Train Loss: 0.4730 Acc: 0.7818 | Val Loss: 0.4617 Acc: 0.7802                                            \n",
      "Epoch 050 | Train Loss: 0.4816 Acc: 0.7773 | Val Loss: 0.4398 Acc: 0.8007                                            \n",
      "Epoch 051 | Train Loss: 0.4763 Acc: 0.7771 | Val Loss: 0.4323 Acc: 0.8031                                            \n",
      "Epoch 052 | Train Loss: 0.4687 Acc: 0.7800 | Val Loss: 0.5088 Acc: 0.7440                                            \n",
      "Epoch 053 | Train Loss: 0.4573 Acc: 0.7853 | Val Loss: 0.4468 Acc: 0.7935                                            \n",
      "Epoch 054 | Train Loss: 0.4573 Acc: 0.7868 | Val Loss: 0.4307 Acc: 0.7995                                            \n",
      "Epoch 055 | Train Loss: 0.4520 Acc: 0.7904 | Val Loss: 0.4655 Acc: 0.7808                                            \n",
      "Epoch 056 | Train Loss: 0.4647 Acc: 0.7815 | Val Loss: 0.4355 Acc: 0.7947                                            \n",
      "Epoch 057 | Train Loss: 0.4441 Acc: 0.8001 | Val Loss: 0.4327 Acc: 0.7947                                            \n",
      "Epoch 058 | Train Loss: 0.4365 Acc: 0.8008 | Val Loss: 0.4312 Acc: 0.7911                                            \n",
      "Epoch 059 | Train Loss: 0.4207 Acc: 0.8042 | Val Loss: 0.4090 Acc: 0.8062                                            \n",
      "Epoch 060 | Train Loss: 0.4271 Acc: 0.8039 | Val Loss: 0.4142 Acc: 0.7905                                            \n",
      "Trial params:                                                                                                        \n",
      "{'batch_size': 64, 'cnn_dense': 64, 'cnn_dropout': 0.19320503261085464, 'cnn_kernel_size_1': 3, 'cnn_kernels_1': 64, 'cnn_kernels_2': 32, 'learning_rate': 0.0022890567463014692, 'lstm_dense': 128, 'lstm_hidden_size': 128, 'lstm_layers': 2, 'optimizer': 'sgd'}\n",
      "Epoch 001 | Train Loss: 0.6875 Acc: 0.5582 | Val Loss: 0.6864 Acc: 0.5586                                            \n",
      "Epoch 002 | Train Loss: 0.6868 Acc: 0.5582 | Val Loss: 0.6863 Acc: 0.5586                                            \n",
      "Epoch 003 | Train Loss: 0.6865 Acc: 0.5582 | Val Loss: 0.6863 Acc: 0.5586                                            \n",
      "Epoch 004 | Train Loss: 0.6863 Acc: 0.5582 | Val Loss: 0.6863 Acc: 0.5586                                            \n",
      "Epoch 005 | Train Loss: 0.6864 Acc: 0.5582 | Val Loss: 0.6863 Acc: 0.5586                                            \n",
      "Epoch 006 | Train Loss: 0.6866 Acc: 0.5582 | Val Loss: 0.6863 Acc: 0.5586                                            \n",
      "Epoch 007 | Train Loss: 0.6865 Acc: 0.5582 | Val Loss: 0.6863 Acc: 0.5586                                            \n",
      "Epoch 008 | Train Loss: 0.6867 Acc: 0.5582 | Val Loss: 0.6863 Acc: 0.5586                                            \n",
      "Epoch 009 | Train Loss: 0.6866 Acc: 0.5582 | Val Loss: 0.6862 Acc: 0.5586                                            \n",
      "Epoch 010 | Train Loss: 0.6867 Acc: 0.5582 | Val Loss: 0.6863 Acc: 0.5586                                            \n",
      "Epoch 011 | Train Loss: 0.6867 Acc: 0.5582 | Val Loss: 0.6862 Acc: 0.5586                                            \n",
      "Epoch 012 | Train Loss: 0.6865 Acc: 0.5582 | Val Loss: 0.6863 Acc: 0.5586                                            \n",
      "Epoch 013 | Train Loss: 0.6867 Acc: 0.5582 | Val Loss: 0.6862 Acc: 0.5586                                            \n",
      "Epoch 014 | Train Loss: 0.6865 Acc: 0.5582 | Val Loss: 0.6862 Acc: 0.5586                                            \n",
      "Epoch 015 | Train Loss: 0.6864 Acc: 0.5582 | Val Loss: 0.6862 Acc: 0.5586                                            \n",
      "Epoch 016 | Train Loss: 0.6865 Acc: 0.5582 | Val Loss: 0.6862 Acc: 0.5586                                            \n",
      "Epoch 017 | Train Loss: 0.6866 Acc: 0.5582 | Val Loss: 0.6862 Acc: 0.5586                                            \n",
      "Epoch 018 | Train Loss: 0.6866 Acc: 0.5582 | Val Loss: 0.6862 Acc: 0.5586                                            \n",
      "Epoch 019 | Train Loss: 0.6864 Acc: 0.5582 | Val Loss: 0.6862 Acc: 0.5586                                            \n",
      "Epoch 020 | Train Loss: 0.6864 Acc: 0.5582 | Val Loss: 0.6862 Acc: 0.5586                                            \n",
      "Epoch 021 | Train Loss: 0.6862 Acc: 0.5582 | Val Loss: 0.6862 Acc: 0.5586                                            \n",
      "Epoch 022 | Train Loss: 0.6865 Acc: 0.5582 | Val Loss: 0.6862 Acc: 0.5586                                            \n",
      "Epoch 023 | Train Loss: 0.6864 Acc: 0.5582 | Val Loss: 0.6862 Acc: 0.5586                                            \n",
      "Epoch 024 | Train Loss: 0.6863 Acc: 0.5582 | Val Loss: 0.6862 Acc: 0.5586                                            \n",
      "Epoch 025 | Train Loss: 0.6863 Acc: 0.5582 | Val Loss: 0.6862 Acc: 0.5586                                            \n",
      "Epoch 026 | Train Loss: 0.6863 Acc: 0.5582 | Val Loss: 0.6862 Acc: 0.5586                                            \n",
      "Epoch 027 | Train Loss: 0.6863 Acc: 0.5582 | Val Loss: 0.6862 Acc: 0.5586                                            \n",
      "Epoch 028 | Train Loss: 0.6865 Acc: 0.5582 | Val Loss: 0.6862 Acc: 0.5586                                            \n",
      "Epoch 029 | Train Loss: 0.6863 Acc: 0.5582 | Val Loss: 0.6862 Acc: 0.5586                                            \n",
      "Epoch 030 | Train Loss: 0.6863 Acc: 0.5582 | Val Loss: 0.6861 Acc: 0.5586                                            \n",
      "Epoch 031 | Train Loss: 0.6865 Acc: 0.5582 | Val Loss: 0.6862 Acc: 0.5586                                            \n",
      "Epoch 032 | Train Loss: 0.6861 Acc: 0.5582 | Val Loss: 0.6861 Acc: 0.5586                                            \n",
      "Epoch 033 | Train Loss: 0.6863 Acc: 0.5582 | Val Loss: 0.6861 Acc: 0.5586                                            \n",
      "Epoch 034 | Train Loss: 0.6863 Acc: 0.5582 | Val Loss: 0.6861 Acc: 0.5586                                            \n",
      "Epoch 035 | Train Loss: 0.6864 Acc: 0.5582 | Val Loss: 0.6861 Acc: 0.5586                                            \n",
      "Epoch 036 | Train Loss: 0.6862 Acc: 0.5582 | Val Loss: 0.6861 Acc: 0.5586                                            \n",
      "Epoch 037 | Train Loss: 0.6864 Acc: 0.5582 | Val Loss: 0.6861 Acc: 0.5586                                            \n",
      "Epoch 038 | Train Loss: 0.6862 Acc: 0.5582 | Val Loss: 0.6861 Acc: 0.5586                                            \n",
      "Epoch 039 | Train Loss: 0.6862 Acc: 0.5582 | Val Loss: 0.6860 Acc: 0.5586                                            \n",
      "Epoch 040 | Train Loss: 0.6864 Acc: 0.5582 | Val Loss: 0.6860 Acc: 0.5586                                            \n",
      "Epoch 041 | Train Loss: 0.6862 Acc: 0.5582 | Val Loss: 0.6860 Acc: 0.5586                                            \n",
      "Epoch 042 | Train Loss: 0.6863 Acc: 0.5582 | Val Loss: 0.6860 Acc: 0.5586                                            \n",
      "Epoch 043 | Train Loss: 0.6862 Acc: 0.5582 | Val Loss: 0.6860 Acc: 0.5586                                            \n",
      "Epoch 044 | Train Loss: 0.6860 Acc: 0.5582 | Val Loss: 0.6859 Acc: 0.5586                                            \n",
      "Epoch 045 | Train Loss: 0.6862 Acc: 0.5582 | Val Loss: 0.6859 Acc: 0.5586                                            \n",
      "Epoch 046 | Train Loss: 0.6860 Acc: 0.5582 | Val Loss: 0.6859 Acc: 0.5586                                            \n",
      "Epoch 047 | Train Loss: 0.6861 Acc: 0.5582 | Val Loss: 0.6859 Acc: 0.5586                                            \n",
      "Epoch 048 | Train Loss: 0.6862 Acc: 0.5582 | Val Loss: 0.6859 Acc: 0.5586                                            \n",
      "Epoch 049 | Train Loss: 0.6860 Acc: 0.5582 | Val Loss: 0.6858 Acc: 0.5586                                            \n",
      "Epoch 050 | Train Loss: 0.6860 Acc: 0.5582 | Val Loss: 0.6858 Acc: 0.5586                                            \n",
      "Epoch 051 | Train Loss: 0.6858 Acc: 0.5582 | Val Loss: 0.6858 Acc: 0.5586                                            \n",
      "Epoch 052 | Train Loss: 0.6856 Acc: 0.5582 | Val Loss: 0.6857 Acc: 0.5586                                            \n",
      "Epoch 053 | Train Loss: 0.6856 Acc: 0.5582 | Val Loss: 0.6856 Acc: 0.5586                                            \n",
      "Epoch 054 | Train Loss: 0.6857 Acc: 0.5582 | Val Loss: 0.6856 Acc: 0.5586                                            \n",
      "Epoch 055 | Train Loss: 0.6855 Acc: 0.5582 | Val Loss: 0.6855 Acc: 0.5586                                            \n",
      "Epoch 056 | Train Loss: 0.6852 Acc: 0.5584 | Val Loss: 0.6854 Acc: 0.5586                                            \n",
      "Epoch 057 | Train Loss: 0.6855 Acc: 0.5582 | Val Loss: 0.6854 Acc: 0.5586                                            \n",
      "Epoch 058 | Train Loss: 0.6852 Acc: 0.5582 | Val Loss: 0.6853 Acc: 0.5586                                            \n",
      "Epoch 059 | Train Loss: 0.6853 Acc: 0.5582 | Val Loss: 0.6852 Acc: 0.5586                                            \n",
      "Epoch 060 | Train Loss: 0.6851 Acc: 0.5584 | Val Loss: 0.6851 Acc: 0.5586                                            \n",
      "Trial params:                                                                                                        \n",
      "{'batch_size': 36, 'cnn_dense': 64, 'cnn_dropout': 0.6841760249439856, 'cnn_kernel_size_1': 5, 'cnn_kernels_1': 64, 'cnn_kernels_2': 64, 'learning_rate': 0.0003753469069767162, 'lstm_dense': 64, 'lstm_hidden_size': 128, 'lstm_layers': 3, 'optimizer': 'adam'}\n",
      "Epoch 001 | Train Loss: 0.6859 Acc: 0.5629 | Val Loss: 0.6799 Acc: 0.5725                                            \n",
      "Epoch 002 | Train Loss: 0.6766 Acc: 0.5849 | Val Loss: 0.6781 Acc: 0.5815                                            \n",
      "Epoch 003 | Train Loss: 0.6666 Acc: 0.6006 | Val Loss: 0.6622 Acc: 0.6069                                            \n",
      "Epoch 004 | Train Loss: 0.6505 Acc: 0.6251 | Val Loss: 0.6257 Acc: 0.6582                                            \n",
      "Epoch 005 | Train Loss: 0.6202 Acc: 0.6733 | Val Loss: 0.6261 Acc: 0.6486                                            \n",
      "Epoch 006 | Train Loss: 0.6145 Acc: 0.6817 | Val Loss: 0.6125 Acc: 0.6800                                            \n",
      "Epoch 007 | Train Loss: 0.5939 Acc: 0.7019 | Val Loss: 0.5778 Acc: 0.7053                                            \n",
      "Epoch 008 | Train Loss: 0.5824 Acc: 0.7103 | Val Loss: 0.5802 Acc: 0.7174                                            \n",
      "Epoch 009 | Train Loss: 0.5723 Acc: 0.7181 | Val Loss: 0.5720 Acc: 0.7168                                            \n",
      "Epoch 010 | Train Loss: 0.5704 Acc: 0.7222 | Val Loss: 0.5641 Acc: 0.7144                                            \n",
      "Epoch 011 | Train Loss: 0.5626 Acc: 0.7273 | Val Loss: 0.5522 Acc: 0.7210                                            \n",
      "Epoch 012 | Train Loss: 0.5635 Acc: 0.7279 | Val Loss: 0.5552 Acc: 0.7210                                            \n",
      "Epoch 013 | Train Loss: 0.5566 Acc: 0.7288 | Val Loss: 0.5624 Acc: 0.7150                                            \n",
      "Epoch 014 | Train Loss: 0.5446 Acc: 0.7392 | Val Loss: 0.5429 Acc: 0.7222                                            \n",
      "Epoch 015 | Train Loss: 0.5419 Acc: 0.7367 | Val Loss: 0.5455 Acc: 0.7301                                            \n",
      "Epoch 016 | Train Loss: 0.5379 Acc: 0.7386 | Val Loss: 0.5348 Acc: 0.7307                                            \n",
      "Epoch 017 | Train Loss: 0.5339 Acc: 0.7433 | Val Loss: 0.5390 Acc: 0.7289                                            \n",
      "Epoch 018 | Train Loss: 0.5344 Acc: 0.7465 | Val Loss: 0.5541 Acc: 0.7216                                            \n",
      "Epoch 019 | Train Loss: 0.5247 Acc: 0.7509 | Val Loss: 0.5233 Acc: 0.7421                                            \n",
      "Epoch 020 | Train Loss: 0.5228 Acc: 0.7501 | Val Loss: 0.5259 Acc: 0.7373                                            \n",
      "Epoch 021 | Train Loss: 0.5261 Acc: 0.7491 | Val Loss: 0.5169 Acc: 0.7452                                            \n",
      "Epoch 022 | Train Loss: 0.5164 Acc: 0.7542 | Val Loss: 0.5243 Acc: 0.7385                                            \n",
      "Epoch 023 | Train Loss: 0.5068 Acc: 0.7587 | Val Loss: 0.5181 Acc: 0.7476                                            \n",
      "Epoch 024 | Train Loss: 0.5071 Acc: 0.7620 | Val Loss: 0.5059 Acc: 0.7464                                            \n",
      "Epoch 025 | Train Loss: 0.5028 Acc: 0.7645 | Val Loss: 0.4973 Acc: 0.7554                                            \n",
      "Epoch 026 | Train Loss: 0.4966 Acc: 0.7646 | Val Loss: 0.4985 Acc: 0.7585                                            \n",
      "Epoch 027 | Train Loss: 0.4883 Acc: 0.7661 | Val Loss: 0.4925 Acc: 0.7585                                            \n",
      "Epoch 028 | Train Loss: 0.4874 Acc: 0.7711 | Val Loss: 0.4869 Acc: 0.7609                                            \n",
      "Epoch 029 | Train Loss: 0.4871 Acc: 0.7684 | Val Loss: 0.4799 Acc: 0.7627                                            \n",
      "Epoch 030 | Train Loss: 0.4787 Acc: 0.7746 | Val Loss: 0.4784 Acc: 0.7669                                            \n",
      "Epoch 031 | Train Loss: 0.4709 Acc: 0.7791 | Val Loss: 0.4694 Acc: 0.7687                                            \n",
      "Epoch 032 | Train Loss: 0.4722 Acc: 0.7806 | Val Loss: 0.5043 Acc: 0.7452                                            \n",
      "Epoch 033 | Train Loss: 0.4697 Acc: 0.7832 | Val Loss: 0.4635 Acc: 0.7669                                            \n",
      "Epoch 034 | Train Loss: 0.4663 Acc: 0.7836 | Val Loss: 0.4671 Acc: 0.7736                                            \n",
      "Epoch 035 | Train Loss: 0.4569 Acc: 0.7904 | Val Loss: 0.5071 Acc: 0.7446                                            \n",
      "Epoch 036 | Train Loss: 0.4490 Acc: 0.7930 | Val Loss: 0.4490 Acc: 0.7790                                            \n",
      "Epoch 037 | Train Loss: 0.4437 Acc: 0.7927 | Val Loss: 0.4432 Acc: 0.7838                                            \n",
      "Epoch 038 | Train Loss: 0.4471 Acc: 0.7945 | Val Loss: 0.4579 Acc: 0.7760                                            \n",
      "Epoch 039 | Train Loss: 0.4435 Acc: 0.7939 | Val Loss: 0.4392 Acc: 0.7953                                            \n",
      "Epoch 040 | Train Loss: 0.4505 Acc: 0.7833 | Val Loss: 0.4394 Acc: 0.7874                                            \n",
      "Epoch 041 | Train Loss: 0.4324 Acc: 0.8027 | Val Loss: 0.4234 Acc: 0.7959                                            \n",
      "Epoch 042 | Train Loss: 0.4252 Acc: 0.8030 | Val Loss: 0.4154 Acc: 0.8086                                            \n",
      "Epoch 043 | Train Loss: 0.4323 Acc: 0.7975 | Val Loss: 0.4129 Acc: 0.8043                                            \n",
      "Epoch 044 | Train Loss: 0.4187 Acc: 0.8073 | Val Loss: 0.4141 Acc: 0.7977                                            \n",
      "Epoch 045 | Train Loss: 0.4131 Acc: 0.8082 | Val Loss: 0.4069 Acc: 0.8031                                            \n",
      "Epoch 046 | Train Loss: 0.4157 Acc: 0.8082 | Val Loss: 0.3979 Acc: 0.8146                                            \n",
      "Epoch 047 | Train Loss: 0.4090 Acc: 0.8113 | Val Loss: 0.4139 Acc: 0.8025                                            \n",
      "Epoch 048 | Train Loss: 0.4091 Acc: 0.8126 | Val Loss: 0.3858 Acc: 0.8152                                            \n",
      "Epoch 049 | Train Loss: 0.4012 Acc: 0.8193 | Val Loss: 0.3803 Acc: 0.8219                                            \n",
      "Epoch 050 | Train Loss: 0.3924 Acc: 0.8214 | Val Loss: 0.3744 Acc: 0.8194                                            \n",
      "Epoch 051 | Train Loss: 0.3907 Acc: 0.8242 | Val Loss: 0.3709 Acc: 0.8237                                            \n",
      "Epoch 052 | Train Loss: 0.3910 Acc: 0.8264 | Val Loss: 0.3870 Acc: 0.8146                                            \n",
      "Epoch 053 | Train Loss: 0.3767 Acc: 0.8291 | Val Loss: 0.3733 Acc: 0.8267                                            \n",
      "Epoch 054 | Train Loss: 0.3779 Acc: 0.8288 | Val Loss: 0.3820 Acc: 0.8188                                            \n",
      "Epoch 055 | Train Loss: 0.3776 Acc: 0.8323 | Val Loss: 0.3692 Acc: 0.8237                                            \n",
      "Epoch 056 | Train Loss: 0.3628 Acc: 0.8383 | Val Loss: 0.3613 Acc: 0.8376                                            \n",
      "Epoch 057 | Train Loss: 0.3655 Acc: 0.8345 | Val Loss: 0.3534 Acc: 0.8478                                            \n",
      "Epoch 058 | Train Loss: 0.3602 Acc: 0.8410 | Val Loss: 0.3403 Acc: 0.8412                                            \n",
      "Epoch 059 | Train Loss: 0.3573 Acc: 0.8356 | Val Loss: 0.3384 Acc: 0.8430                                            \n",
      "Epoch 060 | Train Loss: 0.3515 Acc: 0.8457 | Val Loss: 0.3410 Acc: 0.8424                                            \n",
      "Trial params:                                                                                                        \n",
      "{'batch_size': 48, 'cnn_dense': 64, 'cnn_dropout': 0.21640094483845024, 'cnn_kernel_size_1': 5, 'cnn_kernels_1': 16, 'cnn_kernels_2': 16, 'learning_rate': 0.00048408905763733256, 'lstm_dense': 256, 'lstm_hidden_size': 128, 'lstm_layers': 1, 'optimizer': 'sgd'}\n",
      "Epoch 001 | Train Loss: 0.6928 Acc: 0.5140 | Val Loss: 0.6898 Acc: 0.5586                                            \n",
      "Epoch 002 | Train Loss: 0.6886 Acc: 0.5587 | Val Loss: 0.6874 Acc: 0.5586                                            \n",
      "Epoch 003 | Train Loss: 0.6868 Acc: 0.5582 | Val Loss: 0.6866 Acc: 0.5586                                            \n",
      "Epoch 004 | Train Loss: 0.6867 Acc: 0.5582 | Val Loss: 0.6863 Acc: 0.5586                                            \n",
      "Epoch 005 | Train Loss: 0.6861 Acc: 0.5582 | Val Loss: 0.6862 Acc: 0.5586                                            \n",
      "Epoch 006 | Train Loss: 0.6866 Acc: 0.5582 | Val Loss: 0.6862 Acc: 0.5586                                            \n",
      "Epoch 007 | Train Loss: 0.6862 Acc: 0.5582 | Val Loss: 0.6861 Acc: 0.5586                                            \n",
      "Epoch 008 | Train Loss: 0.6867 Acc: 0.5582 | Val Loss: 0.6861 Acc: 0.5586                                            \n",
      "Epoch 009 | Train Loss: 0.6862 Acc: 0.5582 | Val Loss: 0.6861 Acc: 0.5586                                            \n",
      "Epoch 010 | Train Loss: 0.6861 Acc: 0.5582 | Val Loss: 0.6861 Acc: 0.5586                                            \n",
      "Epoch 011 | Train Loss: 0.6864 Acc: 0.5582 | Val Loss: 0.6861 Acc: 0.5586                                            \n",
      "Epoch 012 | Train Loss: 0.6863 Acc: 0.5582 | Val Loss: 0.6860 Acc: 0.5586                                            \n",
      "Epoch 013 | Train Loss: 0.6864 Acc: 0.5582 | Val Loss: 0.6860 Acc: 0.5586                                            \n",
      "Epoch 014 | Train Loss: 0.6862 Acc: 0.5582 | Val Loss: 0.6860 Acc: 0.5586                                            \n",
      "Epoch 015 | Train Loss: 0.6861 Acc: 0.5582 | Val Loss: 0.6860 Acc: 0.5586                                            \n",
      "Epoch 016 | Train Loss: 0.6861 Acc: 0.5582 | Val Loss: 0.6860 Acc: 0.5586                                            \n",
      "Epoch 017 | Train Loss: 0.6862 Acc: 0.5582 | Val Loss: 0.6859 Acc: 0.5586                                            \n",
      "Epoch 018 | Train Loss: 0.6864 Acc: 0.5582 | Val Loss: 0.6859 Acc: 0.5586                                            \n",
      "Epoch 019 | Train Loss: 0.6861 Acc: 0.5582 | Val Loss: 0.6859 Acc: 0.5586                                            \n",
      "Epoch 020 | Train Loss: 0.6859 Acc: 0.5582 | Val Loss: 0.6859 Acc: 0.5586                                            \n",
      "Epoch 021 | Train Loss: 0.6860 Acc: 0.5582 | Val Loss: 0.6859 Acc: 0.5586                                            \n",
      "Epoch 022 | Train Loss: 0.6860 Acc: 0.5582 | Val Loss: 0.6858 Acc: 0.5586                                            \n",
      "Epoch 023 | Train Loss: 0.6858 Acc: 0.5582 | Val Loss: 0.6858 Acc: 0.5586                                            \n",
      "Epoch 024 | Train Loss: 0.6856 Acc: 0.5584 | Val Loss: 0.6858 Acc: 0.5586                                            \n",
      "Epoch 025 | Train Loss: 0.6859 Acc: 0.5582 | Val Loss: 0.6857 Acc: 0.5586                                            \n",
      "Epoch 026 | Train Loss: 0.6857 Acc: 0.5584 | Val Loss: 0.6857 Acc: 0.5586                                            \n",
      "Epoch 027 | Train Loss: 0.6857 Acc: 0.5584 | Val Loss: 0.6857 Acc: 0.5586                                            \n",
      "Epoch 028 | Train Loss: 0.6854 Acc: 0.5585 | Val Loss: 0.6856 Acc: 0.5586                                            \n",
      "Epoch 029 | Train Loss: 0.6857 Acc: 0.5584 | Val Loss: 0.6856 Acc: 0.5586                                            \n",
      "Epoch 030 | Train Loss: 0.6856 Acc: 0.5582 | Val Loss: 0.6856 Acc: 0.5586                                            \n",
      "Epoch 031 | Train Loss: 0.6858 Acc: 0.5585 | Val Loss: 0.6855 Acc: 0.5586                                            \n",
      "Epoch 032 | Train Loss: 0.6855 Acc: 0.5584 | Val Loss: 0.6855 Acc: 0.5586                                            \n",
      "Epoch 033 | Train Loss: 0.6855 Acc: 0.5584 | Val Loss: 0.6854 Acc: 0.5586                                            \n",
      "Epoch 034 | Train Loss: 0.6855 Acc: 0.5582 | Val Loss: 0.6854 Acc: 0.5586                                            \n",
      "Epoch 035 | Train Loss: 0.6853 Acc: 0.5587 | Val Loss: 0.6853 Acc: 0.5586                                            \n",
      "Epoch 036 | Train Loss: 0.6850 Acc: 0.5585 | Val Loss: 0.6853 Acc: 0.5586                                            \n",
      "Epoch 037 | Train Loss: 0.6856 Acc: 0.5588 | Val Loss: 0.6852 Acc: 0.5598                                            \n",
      "Epoch 038 | Train Loss: 0.6850 Acc: 0.5585 | Val Loss: 0.6852 Acc: 0.5598                                            \n",
      "Epoch 039 | Train Loss: 0.6849 Acc: 0.5591 | Val Loss: 0.6851 Acc: 0.5598                                            \n",
      "Epoch 040 | Train Loss: 0.6851 Acc: 0.5594 | Val Loss: 0.6850 Acc: 0.5598                                            \n",
      "Epoch 041 | Train Loss: 0.6848 Acc: 0.5588 | Val Loss: 0.6850 Acc: 0.5598                                            \n",
      "Epoch 042 | Train Loss: 0.6848 Acc: 0.5599 | Val Loss: 0.6849 Acc: 0.5598                                            \n",
      "Epoch 043 | Train Loss: 0.6849 Acc: 0.5588 | Val Loss: 0.6848 Acc: 0.5598                                            \n",
      "Epoch 044 | Train Loss: 0.6847 Acc: 0.5591 | Val Loss: 0.6847 Acc: 0.5604                                            \n",
      "Epoch 045 | Train Loss: 0.6846 Acc: 0.5599 | Val Loss: 0.6846 Acc: 0.5604                                            \n",
      "Epoch 046 | Train Loss: 0.6845 Acc: 0.5606 | Val Loss: 0.6845 Acc: 0.5604                                            \n",
      "Epoch 047 | Train Loss: 0.6846 Acc: 0.5597 | Val Loss: 0.6844 Acc: 0.5604                                            \n",
      "Epoch 048 | Train Loss: 0.6841 Acc: 0.5621 | Val Loss: 0.6843 Acc: 0.5610                                            \n",
      "Epoch 049 | Train Loss: 0.6843 Acc: 0.5629 | Val Loss: 0.6842 Acc: 0.5616                                            \n",
      "Epoch 050 | Train Loss: 0.6839 Acc: 0.5621 | Val Loss: 0.6841 Acc: 0.5622                                            \n",
      "Epoch 051 | Train Loss: 0.6836 Acc: 0.5635 | Val Loss: 0.6840 Acc: 0.5646                                            \n",
      "Epoch 052 | Train Loss: 0.6837 Acc: 0.5635 | Val Loss: 0.6838 Acc: 0.5652                                            \n",
      "Epoch 053 | Train Loss: 0.6832 Acc: 0.5658 | Val Loss: 0.6837 Acc: 0.5652                                            \n",
      "Epoch 054 | Train Loss: 0.6835 Acc: 0.5652 | Val Loss: 0.6835 Acc: 0.5652                                            \n",
      "Epoch 055 | Train Loss: 0.6835 Acc: 0.5636 | Val Loss: 0.6834 Acc: 0.5664                                            \n",
      "Epoch 056 | Train Loss: 0.6830 Acc: 0.5662 | Val Loss: 0.6832 Acc: 0.5676                                            \n",
      "Epoch 057 | Train Loss: 0.6829 Acc: 0.5659 | Val Loss: 0.6830 Acc: 0.5670                                            \n",
      "Epoch 058 | Train Loss: 0.6824 Acc: 0.5695 | Val Loss: 0.6829 Acc: 0.5664                                            \n",
      "Epoch 059 | Train Loss: 0.6821 Acc: 0.5677 | Val Loss: 0.6827 Acc: 0.5670                                            \n",
      "Epoch 060 | Train Loss: 0.6819 Acc: 0.5701 | Val Loss: 0.6825 Acc: 0.5682                                            \n",
      "Trial params:                                                                                                        \n",
      "{'batch_size': 48, 'cnn_dense': 256, 'cnn_dropout': 0.20371127841145442, 'cnn_kernel_size_1': 5, 'cnn_kernels_1': 16, 'cnn_kernels_2': 64, 'learning_rate': 0.0003395706086351762, 'lstm_dense': 32, 'lstm_hidden_size': 64, 'lstm_layers': 1, 'optimizer': 'sgd'}\n",
      "Epoch 001 | Train Loss: 0.6886 Acc: 0.5585 | Val Loss: 0.6877 Acc: 0.5586                                            \n",
      "Epoch 002 | Train Loss: 0.6874 Acc: 0.5582 | Val Loss: 0.6870 Acc: 0.5586                                            \n",
      "Epoch 003 | Train Loss: 0.6876 Acc: 0.5584 | Val Loss: 0.6866 Acc: 0.5586                                            \n",
      "Epoch 004 | Train Loss: 0.6866 Acc: 0.5585 | Val Loss: 0.6863 Acc: 0.5586                                            \n",
      "Epoch 005 | Train Loss: 0.6861 Acc: 0.5587 | Val Loss: 0.6860 Acc: 0.5586                                            \n",
      "Epoch 006 | Train Loss: 0.6860 Acc: 0.5591 | Val Loss: 0.6858 Acc: 0.5598                                            \n",
      "Epoch 007 | Train Loss: 0.6858 Acc: 0.5588 | Val Loss: 0.6855 Acc: 0.5598                                            \n",
      "Epoch 008 | Train Loss: 0.6860 Acc: 0.5597 | Val Loss: 0.6854 Acc: 0.5604                                            \n",
      "Epoch 009 | Train Loss: 0.6854 Acc: 0.5593 | Val Loss: 0.6852 Acc: 0.5604                                            \n",
      "Epoch 010 | Train Loss: 0.6853 Acc: 0.5602 | Val Loss: 0.6850 Acc: 0.5604                                            \n",
      "Epoch 011 | Train Loss: 0.6855 Acc: 0.5603 | Val Loss: 0.6849 Acc: 0.5610                                            \n",
      "Epoch 012 | Train Loss: 0.6849 Acc: 0.5596 | Val Loss: 0.6847 Acc: 0.5616                                            \n",
      "Epoch 013 | Train Loss: 0.6848 Acc: 0.5615 | Val Loss: 0.6845 Acc: 0.5616                                            \n",
      "Epoch 014 | Train Loss: 0.6848 Acc: 0.5615 | Val Loss: 0.6844 Acc: 0.5622                                            \n",
      "Epoch 015 | Train Loss: 0.6843 Acc: 0.5624 | Val Loss: 0.6842 Acc: 0.5628                                            \n",
      "Epoch 016 | Train Loss: 0.6841 Acc: 0.5632 | Val Loss: 0.6840 Acc: 0.5634                                            \n",
      "Epoch 017 | Train Loss: 0.6838 Acc: 0.5638 | Val Loss: 0.6839 Acc: 0.5652                                            \n",
      "Epoch 018 | Train Loss: 0.6839 Acc: 0.5639 | Val Loss: 0.6837 Acc: 0.5652                                            \n",
      "Epoch 019 | Train Loss: 0.6838 Acc: 0.5644 | Val Loss: 0.6835 Acc: 0.5664                                            \n",
      "Epoch 020 | Train Loss: 0.6833 Acc: 0.5659 | Val Loss: 0.6833 Acc: 0.5664                                            \n",
      "Epoch 021 | Train Loss: 0.6830 Acc: 0.5650 | Val Loss: 0.6831 Acc: 0.5664                                            \n",
      "Epoch 022 | Train Loss: 0.6829 Acc: 0.5694 | Val Loss: 0.6829 Acc: 0.5664                                            \n",
      "Epoch 023 | Train Loss: 0.6825 Acc: 0.5685 | Val Loss: 0.6827 Acc: 0.5664                                            \n",
      "Epoch 024 | Train Loss: 0.6825 Acc: 0.5688 | Val Loss: 0.6826 Acc: 0.5676                                            \n",
      "Epoch 025 | Train Loss: 0.6822 Acc: 0.5695 | Val Loss: 0.6824 Acc: 0.5700                                            \n",
      "Epoch 026 | Train Loss: 0.6818 Acc: 0.5721 | Val Loss: 0.6822 Acc: 0.5694                                            \n",
      "Epoch 027 | Train Loss: 0.6819 Acc: 0.5707 | Val Loss: 0.6820 Acc: 0.5713                                            \n",
      "Epoch 028 | Train Loss: 0.6817 Acc: 0.5713 | Val Loss: 0.6818 Acc: 0.5719                                            \n",
      "Epoch 029 | Train Loss: 0.6811 Acc: 0.5709 | Val Loss: 0.6816 Acc: 0.5713                                            \n",
      "Epoch 030 | Train Loss: 0.6816 Acc: 0.5704 | Val Loss: 0.6815 Acc: 0.5713                                            \n",
      "Epoch 031 | Train Loss: 0.6807 Acc: 0.5744 | Val Loss: 0.6813 Acc: 0.5725                                            \n",
      "Epoch 032 | Train Loss: 0.6804 Acc: 0.5730 | Val Loss: 0.6811 Acc: 0.5755                                            \n",
      "Epoch 033 | Train Loss: 0.6804 Acc: 0.5789 | Val Loss: 0.6809 Acc: 0.5755                                            \n",
      "Epoch 034 | Train Loss: 0.6796 Acc: 0.5775 | Val Loss: 0.6807 Acc: 0.5749                                            \n",
      "Epoch 035 | Train Loss: 0.6798 Acc: 0.5772 | Val Loss: 0.6805 Acc: 0.5737                                            \n",
      "Epoch 036 | Train Loss: 0.6800 Acc: 0.5768 | Val Loss: 0.6804 Acc: 0.5731                                            \n",
      "Epoch 037 | Train Loss: 0.6787 Acc: 0.5834 | Val Loss: 0.6802 Acc: 0.5755                                            \n",
      "Epoch 038 | Train Loss: 0.6791 Acc: 0.5789 | Val Loss: 0.6800 Acc: 0.5755                                            \n",
      "Epoch 039 | Train Loss: 0.6788 Acc: 0.5796 | Val Loss: 0.6799 Acc: 0.5755                                            \n",
      "Epoch 040 | Train Loss: 0.6795 Acc: 0.5798 | Val Loss: 0.6797 Acc: 0.5755                                            \n",
      "Epoch 041 | Train Loss: 0.6786 Acc: 0.5806 | Val Loss: 0.6796 Acc: 0.5773                                            \n",
      "Epoch 042 | Train Loss: 0.6788 Acc: 0.5819 | Val Loss: 0.6794 Acc: 0.5791                                            \n",
      "Epoch 043 | Train Loss: 0.6786 Acc: 0.5796 | Val Loss: 0.6793 Acc: 0.5767                                            \n",
      "Epoch 044 | Train Loss: 0.6781 Acc: 0.5795 | Val Loss: 0.6792 Acc: 0.5779                                            \n",
      "Epoch 045 | Train Loss: 0.6780 Acc: 0.5821 | Val Loss: 0.6791 Acc: 0.5773                                            \n",
      "Epoch 046 | Train Loss: 0.6784 Acc: 0.5813 | Val Loss: 0.6790 Acc: 0.5803                                            \n",
      "Epoch 047 | Train Loss: 0.6774 Acc: 0.5827 | Val Loss: 0.6789 Acc: 0.5797                                            \n",
      "Epoch 048 | Train Loss: 0.6772 Acc: 0.5810 | Val Loss: 0.6788 Acc: 0.5803                                            \n",
      "Epoch 049 | Train Loss: 0.6774 Acc: 0.5813 | Val Loss: 0.6787 Acc: 0.5803                                            \n",
      "Epoch 050 | Train Loss: 0.6772 Acc: 0.5843 | Val Loss: 0.6786 Acc: 0.5815                                            \n",
      "Epoch 051 | Train Loss: 0.6772 Acc: 0.5839 | Val Loss: 0.6785 Acc: 0.5821                                            \n",
      "Epoch 052 | Train Loss: 0.6781 Acc: 0.5825 | Val Loss: 0.6785 Acc: 0.5821                                            \n",
      "Epoch 053 | Train Loss: 0.6770 Acc: 0.5846 | Val Loss: 0.6784 Acc: 0.5833                                            \n",
      "Epoch 054 | Train Loss: 0.6773 Acc: 0.5854 | Val Loss: 0.6784 Acc: 0.5845                                            \n",
      "Epoch 055 | Train Loss: 0.6771 Acc: 0.5861 | Val Loss: 0.6783 Acc: 0.5851                                            \n",
      "Epoch 056 | Train Loss: 0.6761 Acc: 0.5863 | Val Loss: 0.6782 Acc: 0.5857                                            \n",
      "Epoch 057 | Train Loss: 0.6768 Acc: 0.5848 | Val Loss: 0.6782 Acc: 0.5857                                            \n",
      "Epoch 058 | Train Loss: 0.6769 Acc: 0.5831 | Val Loss: 0.6782 Acc: 0.5857                                            \n",
      "Epoch 059 | Train Loss: 0.6766 Acc: 0.5836 | Val Loss: 0.6781 Acc: 0.5851                                            \n",
      "Epoch 060 | Train Loss: 0.6768 Acc: 0.5809 | Val Loss: 0.6781 Acc: 0.5857                                            \n",
      "Trial params:                                                                                                        \n",
      "{'batch_size': 32, 'cnn_dense': 32, 'cnn_dropout': 0.19135765366891827, 'cnn_kernel_size_1': 3, 'cnn_kernels_1': 64, 'cnn_kernels_2': 64, 'learning_rate': 0.00014497162965856566, 'lstm_dense': 128, 'lstm_hidden_size': 96, 'lstm_layers': 2, 'optimizer': 'rmsprop'}\n",
      "Epoch 001 | Train Loss: 0.6827 Acc: 0.5735 | Val Loss: 0.6786 Acc: 0.5797                                            \n",
      "Epoch 002 | Train Loss: 0.6749 Acc: 0.5889 | Val Loss: 0.6754 Acc: 0.5930                                            \n",
      "Epoch 003 | Train Loss: 0.6733 Acc: 0.5960 | Val Loss: 0.6737 Acc: 0.5918                                            \n",
      "Epoch 004 | Train Loss: 0.6694 Acc: 0.5963 | Val Loss: 0.6698 Acc: 0.5972                                            \n",
      "Epoch 005 | Train Loss: 0.6640 Acc: 0.6040 | Val Loss: 0.6630 Acc: 0.6002                                            \n",
      "Epoch 006 | Train Loss: 0.6573 Acc: 0.6095 | Val Loss: 0.6573 Acc: 0.6111                                            \n",
      "Epoch 007 | Train Loss: 0.6500 Acc: 0.6174 | Val Loss: 0.6484 Acc: 0.6184                                            \n",
      "Epoch 008 | Train Loss: 0.6425 Acc: 0.6373 | Val Loss: 0.6352 Acc: 0.6612                                            \n",
      "Epoch 009 | Train Loss: 0.6303 Acc: 0.6604 | Val Loss: 0.6322 Acc: 0.6636                                            \n",
      "Epoch 010 | Train Loss: 0.6248 Acc: 0.6701 | Val Loss: 0.6156 Acc: 0.6842                                            \n",
      "Epoch 011 | Train Loss: 0.6150 Acc: 0.6775 | Val Loss: 0.6161 Acc: 0.6781                                            \n",
      "Epoch 012 | Train Loss: 0.6043 Acc: 0.6875 | Val Loss: 0.6026 Acc: 0.6969                                            \n",
      "Epoch 013 | Train Loss: 0.5981 Acc: 0.6952 | Val Loss: 0.6119 Acc: 0.6745                                            \n",
      "Epoch 014 | Train Loss: 0.5914 Acc: 0.7024 | Val Loss: 0.6767 Acc: 0.6135                                            \n",
      "Epoch 015 | Train Loss: 0.5861 Acc: 0.7045 | Val Loss: 0.5985 Acc: 0.6908                                            \n",
      "Epoch 016 | Train Loss: 0.5809 Acc: 0.7107 | Val Loss: 0.5801 Acc: 0.7059                                            \n",
      "Epoch 017 | Train Loss: 0.5746 Acc: 0.7146 | Val Loss: 0.5782 Acc: 0.7071                                            \n",
      "Epoch 018 | Train Loss: 0.5676 Acc: 0.7219 | Val Loss: 0.5735 Acc: 0.7132                                            \n",
      "Epoch 019 | Train Loss: 0.5625 Acc: 0.7247 | Val Loss: 0.5718 Acc: 0.7107                                            \n",
      "Epoch 020 | Train Loss: 0.5616 Acc: 0.7249 | Val Loss: 0.5692 Acc: 0.7168                                            \n",
      "Epoch 021 | Train Loss: 0.5507 Acc: 0.7308 | Val Loss: 0.5586 Acc: 0.7210                                            \n",
      "Epoch 022 | Train Loss: 0.5512 Acc: 0.7303 | Val Loss: 0.5590 Acc: 0.7228                                            \n",
      "Epoch 023 | Train Loss: 0.5477 Acc: 0.7332 | Val Loss: 0.5582 Acc: 0.7228                                            \n",
      "Epoch 024 | Train Loss: 0.5381 Acc: 0.7421 | Val Loss: 0.5547 Acc: 0.7204                                            \n",
      "Epoch 025 | Train Loss: 0.5353 Acc: 0.7445 | Val Loss: 0.5783 Acc: 0.7120                                            \n",
      "Epoch 026 | Train Loss: 0.5306 Acc: 0.7453 | Val Loss: 0.5558 Acc: 0.7192                                            \n",
      "Epoch 027 | Train Loss: 0.5300 Acc: 0.7460 | Val Loss: 0.5585 Acc: 0.7186                                            \n",
      "Epoch 028 | Train Loss: 0.5265 Acc: 0.7512 | Val Loss: 0.5413 Acc: 0.7313                                            \n",
      "Epoch 029 | Train Loss: 0.5236 Acc: 0.7471 | Val Loss: 0.5463 Acc: 0.7307                                            \n",
      "Epoch 030 | Train Loss: 0.5168 Acc: 0.7543 | Val Loss: 0.5572 Acc: 0.7192                                            \n",
      "Epoch 031 | Train Loss: 0.5153 Acc: 0.7552 | Val Loss: 0.5392 Acc: 0.7367                                            \n",
      "Epoch 032 | Train Loss: 0.5130 Acc: 0.7613 | Val Loss: 0.5330 Acc: 0.7277                                            \n",
      "Epoch 033 | Train Loss: 0.5121 Acc: 0.7601 | Val Loss: 0.5262 Acc: 0.7403                                            \n",
      "Epoch 034 | Train Loss: 0.5085 Acc: 0.7617 | Val Loss: 0.5291 Acc: 0.7361                                            \n",
      "Epoch 035 | Train Loss: 0.5047 Acc: 0.7642 | Val Loss: 0.5512 Acc: 0.7283                                            \n",
      "Epoch 036 | Train Loss: 0.4993 Acc: 0.7623 | Val Loss: 0.5288 Acc: 0.7391                                            \n",
      "Epoch 037 | Train Loss: 0.4967 Acc: 0.7678 | Val Loss: 0.5250 Acc: 0.7452                                            \n",
      "Epoch 038 | Train Loss: 0.4956 Acc: 0.7660 | Val Loss: 0.5264 Acc: 0.7361                                            \n",
      "Epoch 039 | Train Loss: 0.4874 Acc: 0.7667 | Val Loss: 0.5149 Acc: 0.7470                                            \n",
      "Epoch 040 | Train Loss: 0.4833 Acc: 0.7717 | Val Loss: 0.5168 Acc: 0.7542                                            \n",
      "Epoch 041 | Train Loss: 0.4876 Acc: 0.7714 | Val Loss: 0.5197 Acc: 0.7452                                            \n",
      "Epoch 042 | Train Loss: 0.4770 Acc: 0.7790 | Val Loss: 0.5133 Acc: 0.7530                                            \n",
      "Epoch 043 | Train Loss: 0.4765 Acc: 0.7776 | Val Loss: 0.5117 Acc: 0.7494                                            \n",
      "Epoch 044 | Train Loss: 0.4732 Acc: 0.7796 | Val Loss: 0.5165 Acc: 0.7536                                            \n",
      "Epoch 045 | Train Loss: 0.4720 Acc: 0.7793 | Val Loss: 0.4975 Acc: 0.7603                                            \n",
      "Epoch 046 | Train Loss: 0.4639 Acc: 0.7886 | Val Loss: 0.5339 Acc: 0.7434                                            \n",
      "Epoch 047 | Train Loss: 0.4584 Acc: 0.7871 | Val Loss: 0.5035 Acc: 0.7548                                            \n",
      "Epoch 048 | Train Loss: 0.4565 Acc: 0.7874 | Val Loss: 0.5384 Acc: 0.7615                                            \n",
      "Epoch 049 | Train Loss: 0.4527 Acc: 0.7904 | Val Loss: 0.4963 Acc: 0.7687                                            \n",
      "Epoch 050 | Train Loss: 0.4491 Acc: 0.7941 | Val Loss: 0.4833 Acc: 0.7723                                            \n",
      "Epoch 051 | Train Loss: 0.4519 Acc: 0.7930 | Val Loss: 0.4822 Acc: 0.7693                                            \n",
      "Epoch 052 | Train Loss: 0.4448 Acc: 0.7927 | Val Loss: 0.5099 Acc: 0.7470                                            \n",
      "Epoch 053 | Train Loss: 0.4390 Acc: 0.7977 | Val Loss: 0.4723 Acc: 0.7856                                            \n",
      "Epoch 054 | Train Loss: 0.4392 Acc: 0.7971 | Val Loss: 0.4756 Acc: 0.7742                                            \n",
      "Epoch 055 | Train Loss: 0.4345 Acc: 0.8019 | Val Loss: 0.4635 Acc: 0.7790                                            \n",
      "Epoch 056 | Train Loss: 0.4310 Acc: 0.8016 | Val Loss: 0.4644 Acc: 0.7826                                            \n",
      "Epoch 057 | Train Loss: 0.4242 Acc: 0.8075 | Val Loss: 0.5400 Acc: 0.7560                                            \n",
      "Epoch 058 | Train Loss: 0.4273 Acc: 0.8019 | Val Loss: 0.4644 Acc: 0.7893                                            \n",
      "Epoch 059 | Train Loss: 0.4183 Acc: 0.8087 | Val Loss: 0.4522 Acc: 0.7850                                            \n",
      "Epoch 060 | Train Loss: 0.4142 Acc: 0.8085 | Val Loss: 0.4755 Acc: 0.7663                                            \n",
      "Trial params:                                                                                                        \n",
      "{'batch_size': 32, 'cnn_dense': 64, 'cnn_dropout': 0.2843658733599042, 'cnn_kernel_size_1': 3, 'cnn_kernels_1': 64, 'cnn_kernels_2': 96, 'learning_rate': 0.0026174908010500875, 'lstm_dense': 128, 'lstm_hidden_size': 96, 'lstm_layers': 3, 'optimizer': 'adam'}\n",
      "Epoch 001 | Train Loss: 0.6876 Acc: 0.5582 | Val Loss: 0.6867 Acc: 0.5586                                            \n",
      "Epoch 002 | Train Loss: 0.6872 Acc: 0.5582 | Val Loss: 0.6864 Acc: 0.5586                                            \n",
      "Epoch 003 | Train Loss: 0.6867 Acc: 0.5582 | Val Loss: 0.6864 Acc: 0.5586                                            \n",
      "Epoch 004 | Train Loss: 0.6869 Acc: 0.5582 | Val Loss: 0.6863 Acc: 0.5586                                            \n",
      "Epoch 005 | Train Loss: 0.6867 Acc: 0.5582 | Val Loss: 0.6868 Acc: 0.5586                                            \n",
      "Epoch 006 | Train Loss: 0.6870 Acc: 0.5582 | Val Loss: 0.6863 Acc: 0.5586                                            \n",
      "Epoch 007 | Train Loss: 0.6865 Acc: 0.5582 | Val Loss: 0.6863 Acc: 0.5586                                            \n",
      "Epoch 008 | Train Loss: 0.6866 Acc: 0.5582 | Val Loss: 0.6863 Acc: 0.5586                                            \n",
      "Epoch 009 | Train Loss: 0.6867 Acc: 0.5582 | Val Loss: 0.6863 Acc: 0.5586                                            \n",
      "Epoch 010 | Train Loss: 0.6865 Acc: 0.5582 | Val Loss: 0.6864 Acc: 0.5586                                            \n",
      "Epoch 011 | Train Loss: 0.6867 Acc: 0.5582 | Val Loss: 0.6863 Acc: 0.5586                                            \n",
      "Epoch 012 | Train Loss: 0.6865 Acc: 0.5582 | Val Loss: 0.6864 Acc: 0.5586                                            \n",
      "Epoch 013 | Train Loss: 0.6867 Acc: 0.5575 | Val Loss: 0.6863 Acc: 0.5586                                            \n",
      "Epoch 014 | Train Loss: 0.6867 Acc: 0.5582 | Val Loss: 0.6863 Acc: 0.5586                                            \n",
      "Epoch 015 | Train Loss: 0.6866 Acc: 0.5582 | Val Loss: 0.6863 Acc: 0.5586                                            \n",
      "Epoch 016 | Train Loss: 0.6866 Acc: 0.5582 | Val Loss: 0.6863 Acc: 0.5586                                            \n",
      "Early stopping triggered.                                                                                            \n",
      "Trial params:                                                                                                        \n",
      "{'batch_size': 48, 'cnn_dense': 128, 'cnn_dropout': 0.3543227106089886, 'cnn_kernel_size_1': 5, 'cnn_kernels_1': 64, 'cnn_kernels_2': 64, 'learning_rate': 0.0012210949073693624, 'lstm_dense': 128, 'lstm_hidden_size': 128, 'lstm_layers': 3, 'optimizer': 'rmsprop'}\n",
      "Epoch 001 | Train Loss: 0.6842 Acc: 0.5718 | Val Loss: 0.6725 Acc: 0.5888                                            \n",
      "Epoch 002 | Train Loss: 0.6623 Acc: 0.6065 | Val Loss: 0.6390 Acc: 0.6540                                            \n",
      "Epoch 003 | Train Loss: 0.6127 Acc: 0.6832 | Val Loss: 0.5972 Acc: 0.6963                                            \n",
      "Epoch 004 | Train Loss: 0.5769 Acc: 0.7083 | Val Loss: 0.5637 Acc: 0.7095                                            \n",
      "Epoch 005 | Train Loss: 0.5523 Acc: 0.7260 | Val Loss: 0.5380 Acc: 0.7252                                            \n",
      "Epoch 006 | Train Loss: 0.5294 Acc: 0.7386 | Val Loss: 0.5215 Acc: 0.7337                                            \n",
      "Epoch 007 | Train Loss: 0.5094 Acc: 0.7498 | Val Loss: 0.5226 Acc: 0.7446                                            \n",
      "Epoch 008 | Train Loss: 0.4836 Acc: 0.7706 | Val Loss: 0.4974 Acc: 0.7585                                            \n",
      "Epoch 009 | Train Loss: 0.4647 Acc: 0.7811 | Val Loss: 0.4670 Acc: 0.7754                                            \n",
      "Epoch 010 | Train Loss: 0.4421 Acc: 0.7919 | Val Loss: 0.4590 Acc: 0.7633                                            \n",
      "Epoch 011 | Train Loss: 0.4174 Acc: 0.8105 | Val Loss: 0.4186 Acc: 0.7983                                            \n",
      "Epoch 012 | Train Loss: 0.4103 Acc: 0.8150 | Val Loss: 0.4389 Acc: 0.7989                                            \n",
      "Epoch 013 | Train Loss: 0.3816 Acc: 0.8294 | Val Loss: 0.3844 Acc: 0.8182                                            \n",
      "Epoch 014 | Train Loss: 0.3562 Acc: 0.8421 | Val Loss: 0.4035 Acc: 0.8104                                            \n",
      "Epoch 015 | Train Loss: 0.3393 Acc: 0.8496 | Val Loss: 0.3537 Acc: 0.8364                                            \n",
      "Epoch 016 | Train Loss: 0.3255 Acc: 0.8582 | Val Loss: 0.3421 Acc: 0.8533                                            \n",
      "Epoch 017 | Train Loss: 0.3030 Acc: 0.8735 | Val Loss: 0.4162 Acc: 0.8207                                            \n",
      "Epoch 018 | Train Loss: 0.2860 Acc: 0.8804 | Val Loss: 0.3334 Acc: 0.8551                                            \n",
      "Epoch 019 | Train Loss: 0.2618 Acc: 0.8908 | Val Loss: 0.2726 Acc: 0.8774                                            \n",
      "Epoch 020 | Train Loss: 0.2540 Acc: 0.8949 | Val Loss: 0.2674 Acc: 0.8895                                            \n",
      "Epoch 021 | Train Loss: 0.2403 Acc: 0.9050 | Val Loss: 0.2732 Acc: 0.8889                                            \n",
      "Epoch 022 | Train Loss: 0.2259 Acc: 0.9085 | Val Loss: 0.2527 Acc: 0.8961                                            \n",
      "Epoch 023 | Train Loss: 0.2137 Acc: 0.9153 | Val Loss: 0.2351 Acc: 0.8967                                            \n",
      "Epoch 024 | Train Loss: 0.2085 Acc: 0.9162 | Val Loss: 0.2134 Acc: 0.9136                                            \n",
      "Epoch 025 | Train Loss: 0.1848 Acc: 0.9274 | Val Loss: 0.2207 Acc: 0.9088                                            \n",
      "Epoch 026 | Train Loss: 0.1780 Acc: 0.9289 | Val Loss: 0.1888 Acc: 0.9269                                            \n",
      "Epoch 027 | Train Loss: 0.1780 Acc: 0.9318 | Val Loss: 0.2104 Acc: 0.9191                                            \n",
      "Epoch 028 | Train Loss: 0.1635 Acc: 0.9357 | Val Loss: 0.1916 Acc: 0.9221                                            \n",
      "Epoch 029 | Train Loss: 0.1657 Acc: 0.9376 | Val Loss: 0.1825 Acc: 0.9269                                            \n",
      "Epoch 030 | Train Loss: 0.1469 Acc: 0.9426 | Val Loss: 0.2115 Acc: 0.9185                                            \n",
      "Epoch 031 | Train Loss: 0.1507 Acc: 0.9435 | Val Loss: 0.2153 Acc: 0.9143                                            \n",
      "Epoch 032 | Train Loss: 0.1392 Acc: 0.9469 | Val Loss: 0.2240 Acc: 0.9112                                            \n",
      "Epoch 033 | Train Loss: 0.1255 Acc: 0.9539 | Val Loss: 0.3043 Acc: 0.8853                                            \n",
      "Epoch 034 | Train Loss: 0.1307 Acc: 0.9484 | Val Loss: 0.1753 Acc: 0.9366                                            \n",
      "Epoch 035 | Train Loss: 0.1284 Acc: 0.9539 | Val Loss: 0.1922 Acc: 0.9330                                            \n",
      "Epoch 036 | Train Loss: 0.1287 Acc: 0.9529 | Val Loss: 0.1701 Acc: 0.9402                                            \n",
      "Epoch 037 | Train Loss: 0.1130 Acc: 0.9558 | Val Loss: 0.1583 Acc: 0.9450                                            \n",
      "Epoch 038 | Train Loss: 0.1076 Acc: 0.9580 | Val Loss: 0.1579 Acc: 0.9457                                            \n",
      "Epoch 039 | Train Loss: 0.0994 Acc: 0.9626 | Val Loss: 0.1708 Acc: 0.9408                                            \n",
      "Epoch 040 | Train Loss: 0.1048 Acc: 0.9618 | Val Loss: 0.1472 Acc: 0.9450                                            \n",
      "Epoch 041 | Train Loss: 0.1013 Acc: 0.9627 | Val Loss: 0.1636 Acc: 0.9432                                            \n",
      "Epoch 042 | Train Loss: 0.0988 Acc: 0.9623 | Val Loss: 0.2275 Acc: 0.9155                                            \n",
      "Epoch 043 | Train Loss: 0.0948 Acc: 0.9659 | Val Loss: 0.1581 Acc: 0.9408                                            \n",
      "Epoch 044 | Train Loss: 0.0839 Acc: 0.9657 | Val Loss: 0.1832 Acc: 0.9396                                            \n",
      "Epoch 045 | Train Loss: 0.0886 Acc: 0.9668 | Val Loss: 0.1689 Acc: 0.9408                                            \n",
      "Epoch 046 | Train Loss: 0.0848 Acc: 0.9698 | Val Loss: 0.1635 Acc: 0.9426                                            \n",
      "Epoch 047 | Train Loss: 0.0780 Acc: 0.9731 | Val Loss: 0.1563 Acc: 0.9487                                            \n",
      "Epoch 048 | Train Loss: 0.0795 Acc: 0.9692 | Val Loss: 0.1734 Acc: 0.9360                                            \n",
      "Epoch 049 | Train Loss: 0.0778 Acc: 0.9728 | Val Loss: 0.1748 Acc: 0.9457                                            \n",
      "Epoch 050 | Train Loss: 0.0788 Acc: 0.9725 | Val Loss: 0.1562 Acc: 0.9463                                            \n",
      "Early stopping triggered.                                                                                            \n",
      "Trial params:                                                                                                        \n",
      "{'batch_size': 64, 'cnn_dense': 32, 'cnn_dropout': 0.4546198969148949, 'cnn_kernel_size_1': 5, 'cnn_kernels_1': 48, 'cnn_kernels_2': 64, 'learning_rate': 0.0006214643312779717, 'lstm_dense': 64, 'lstm_hidden_size': 32, 'lstm_layers': 1, 'optimizer': 'rmsprop'}\n",
      "Epoch 001 | Train Loss: 0.6806 Acc: 0.5778 | Val Loss: 0.6746 Acc: 0.5912                                            \n",
      "Epoch 002 | Train Loss: 0.6710 Acc: 0.5981 | Val Loss: 0.6717 Acc: 0.5839                                            \n",
      "Epoch 003 | Train Loss: 0.6592 Acc: 0.6040 | Val Loss: 0.6575 Acc: 0.6027                                            \n",
      "Epoch 004 | Train Loss: 0.6329 Acc: 0.6408 | Val Loss: 0.6240 Acc: 0.6636                                            \n",
      "Epoch 005 | Train Loss: 0.5997 Acc: 0.6888 | Val Loss: 0.5846 Acc: 0.7041                                            \n",
      "Epoch 006 | Train Loss: 0.5784 Acc: 0.7062 | Val Loss: 0.5847 Acc: 0.6932                                            \n",
      "Epoch 007 | Train Loss: 0.5615 Acc: 0.7190 | Val Loss: 0.5553 Acc: 0.7120                                            \n",
      "Epoch 008 | Train Loss: 0.5481 Acc: 0.7270 | Val Loss: 0.5460 Acc: 0.7283                                            \n",
      "Epoch 009 | Train Loss: 0.5401 Acc: 0.7332 | Val Loss: 0.5471 Acc: 0.7295                                            \n",
      "Epoch 010 | Train Loss: 0.5234 Acc: 0.7466 | Val Loss: 0.5211 Acc: 0.7440                                            \n",
      "Epoch 011 | Train Loss: 0.5104 Acc: 0.7506 | Val Loss: 0.5237 Acc: 0.7397                                            \n",
      "Epoch 012 | Train Loss: 0.5073 Acc: 0.7540 | Val Loss: 0.5317 Acc: 0.7409                                            \n",
      "Epoch 013 | Train Loss: 0.4915 Acc: 0.7655 | Val Loss: 0.5033 Acc: 0.7488                                            \n",
      "Epoch 014 | Train Loss: 0.4834 Acc: 0.7700 | Val Loss: 0.4901 Acc: 0.7681                                            \n",
      "Epoch 015 | Train Loss: 0.4765 Acc: 0.7734 | Val Loss: 0.4682 Acc: 0.7820                                            \n",
      "Epoch 016 | Train Loss: 0.4627 Acc: 0.7844 | Val Loss: 0.4621 Acc: 0.7820                                            \n",
      "Epoch 017 | Train Loss: 0.4551 Acc: 0.7880 | Val Loss: 0.4607 Acc: 0.7862                                            \n",
      "Epoch 018 | Train Loss: 0.4432 Acc: 0.7971 | Val Loss: 0.5018 Acc: 0.7518                                            \n",
      "Epoch 019 | Train Loss: 0.4344 Acc: 0.8019 | Val Loss: 0.4317 Acc: 0.8013                                            \n",
      "Epoch 020 | Train Loss: 0.4288 Acc: 0.8004 | Val Loss: 0.4220 Acc: 0.8037                                            \n",
      "Epoch 021 | Train Loss: 0.4166 Acc: 0.8108 | Val Loss: 0.4010 Acc: 0.8146                                            \n",
      "Epoch 022 | Train Loss: 0.4037 Acc: 0.8137 | Val Loss: 0.3944 Acc: 0.8188                                            \n",
      "Epoch 023 | Train Loss: 0.3872 Acc: 0.8283 | Val Loss: 0.4035 Acc: 0.8092                                            \n",
      "Epoch 024 | Train Loss: 0.3779 Acc: 0.8306 | Val Loss: 0.3824 Acc: 0.8194                                            \n",
      "Epoch 025 | Train Loss: 0.3724 Acc: 0.8271 | Val Loss: 0.3649 Acc: 0.8309                                            \n",
      "Epoch 026 | Train Loss: 0.3577 Acc: 0.8365 | Val Loss: 0.3789 Acc: 0.8225                                            \n",
      "Epoch 027 | Train Loss: 0.3498 Acc: 0.8436 | Val Loss: 0.3687 Acc: 0.8219                                            \n",
      "Epoch 028 | Train Loss: 0.3366 Acc: 0.8508 | Val Loss: 0.3735 Acc: 0.8261                                            \n",
      "Epoch 029 | Train Loss: 0.3290 Acc: 0.8563 | Val Loss: 0.3288 Acc: 0.8539                                            \n",
      "Epoch 030 | Train Loss: 0.3166 Acc: 0.8632 | Val Loss: 0.3586 Acc: 0.8400                                            \n",
      "Epoch 031 | Train Loss: 0.3175 Acc: 0.8637 | Val Loss: 0.3196 Acc: 0.8623                                            \n",
      "Epoch 032 | Train Loss: 0.3009 Acc: 0.8700 | Val Loss: 0.3047 Acc: 0.8605                                            \n",
      "Epoch 033 | Train Loss: 0.2868 Acc: 0.8791 | Val Loss: 0.3073 Acc: 0.8581                                            \n",
      "Epoch 034 | Train Loss: 0.2851 Acc: 0.8774 | Val Loss: 0.2697 Acc: 0.8859                                            \n",
      "Epoch 035 | Train Loss: 0.2763 Acc: 0.8807 | Val Loss: 0.2877 Acc: 0.8792                                            \n",
      "Epoch 036 | Train Loss: 0.2632 Acc: 0.8893 | Val Loss: 0.2939 Acc: 0.8684                                            \n",
      "Epoch 037 | Train Loss: 0.2627 Acc: 0.8922 | Val Loss: 0.2793 Acc: 0.8780                                            \n",
      "Epoch 038 | Train Loss: 0.2570 Acc: 0.8920 | Val Loss: 0.2839 Acc: 0.8816                                            \n",
      "Epoch 039 | Train Loss: 0.2467 Acc: 0.9028 | Val Loss: 0.2819 Acc: 0.8738                                            \n",
      "Epoch 040 | Train Loss: 0.2371 Acc: 0.9020 | Val Loss: 0.2708 Acc: 0.8822                                            \n",
      "Epoch 041 | Train Loss: 0.2295 Acc: 0.9058 | Val Loss: 0.2507 Acc: 0.8889                                            \n",
      "Epoch 042 | Train Loss: 0.2200 Acc: 0.9105 | Val Loss: 0.2652 Acc: 0.8835                                            \n",
      "Epoch 043 | Train Loss: 0.2270 Acc: 0.9070 | Val Loss: 0.2691 Acc: 0.8871                                            \n",
      "Epoch 044 | Train Loss: 0.2275 Acc: 0.9068 | Val Loss: 0.2397 Acc: 0.8986                                            \n",
      "Epoch 045 | Train Loss: 0.2096 Acc: 0.9135 | Val Loss: 0.2314 Acc: 0.9064                                            \n",
      "Epoch 046 | Train Loss: 0.1988 Acc: 0.9167 | Val Loss: 0.2952 Acc: 0.8816                                            \n",
      "Epoch 047 | Train Loss: 0.2102 Acc: 0.9157 | Val Loss: 0.2890 Acc: 0.8756                                            \n",
      "Epoch 048 | Train Loss: 0.1922 Acc: 0.9238 | Val Loss: 0.2595 Acc: 0.8810                                            \n",
      "Epoch 049 | Train Loss: 0.1895 Acc: 0.9256 | Val Loss: 0.2165 Acc: 0.9076                                            \n",
      "Epoch 050 | Train Loss: 0.1853 Acc: 0.9260 | Val Loss: 0.2533 Acc: 0.8937                                            \n",
      "Epoch 051 | Train Loss: 0.1879 Acc: 0.9224 | Val Loss: 0.2885 Acc: 0.8853                                            \n",
      "Epoch 052 | Train Loss: 0.1786 Acc: 0.9311 | Val Loss: 0.2600 Acc: 0.8979                                            \n",
      "Epoch 053 | Train Loss: 0.1720 Acc: 0.9322 | Val Loss: 0.2955 Acc: 0.8877                                            \n",
      "Epoch 054 | Train Loss: 0.1695 Acc: 0.9308 | Val Loss: 0.1943 Acc: 0.9239                                            \n",
      "Epoch 055 | Train Loss: 0.1699 Acc: 0.9340 | Val Loss: 0.2010 Acc: 0.9233                                            \n",
      "Epoch 056 | Train Loss: 0.1673 Acc: 0.9336 | Val Loss: 0.1962 Acc: 0.9263                                            \n",
      "Epoch 057 | Train Loss: 0.1509 Acc: 0.9396 | Val Loss: 0.1867 Acc: 0.9251                                            \n",
      "Epoch 058 | Train Loss: 0.1474 Acc: 0.9420 | Val Loss: 0.2030 Acc: 0.9143                                            \n",
      "Epoch 059 | Train Loss: 0.1472 Acc: 0.9452 | Val Loss: 0.2012 Acc: 0.9227                                            \n",
      "Epoch 060 | Train Loss: 0.1589 Acc: 0.9370 | Val Loss: 0.1849 Acc: 0.9233                                            \n",
      "Trial params:                                                                                                        \n",
      "{'batch_size': 36, 'cnn_dense': 64, 'cnn_dropout': 0.5840618673633665, 'cnn_kernel_size_1': 5, 'cnn_kernels_1': 48, 'cnn_kernels_2': 64, 'learning_rate': 0.0014153310678003813, 'lstm_dense': 32, 'lstm_hidden_size': 32, 'lstm_layers': 2, 'optimizer': 'rmsprop'}\n",
      "Epoch 001 | Train Loss: 0.6812 Acc: 0.5736 | Val Loss: 0.6760 Acc: 0.5864                                            \n",
      "Epoch 002 | Train Loss: 0.6772 Acc: 0.5886 | Val Loss: 0.6721 Acc: 0.5936                                            \n",
      "Epoch 003 | Train Loss: 0.6723 Acc: 0.5976 | Val Loss: 0.6816 Acc: 0.5719                                            \n",
      "Epoch 004 | Train Loss: 0.6637 Acc: 0.6071 | Val Loss: 0.6518 Acc: 0.6178                                            \n",
      "Epoch 005 | Train Loss: 0.6383 Acc: 0.6482 | Val Loss: 0.6199 Acc: 0.6806                                            \n",
      "Epoch 006 | Train Loss: 0.6041 Acc: 0.7006 | Val Loss: 0.5852 Acc: 0.6981                                            \n",
      "Epoch 007 | Train Loss: 0.5826 Acc: 0.7113 | Val Loss: 0.5758 Acc: 0.7168                                            \n",
      "Epoch 008 | Train Loss: 0.5654 Acc: 0.7204 | Val Loss: 0.5540 Acc: 0.7228                                            \n",
      "Epoch 009 | Train Loss: 0.5530 Acc: 0.7276 | Val Loss: 0.5475 Acc: 0.7264                                            \n",
      "Epoch 010 | Train Loss: 0.5412 Acc: 0.7376 | Val Loss: 0.5201 Acc: 0.7446                                            \n",
      "Epoch 011 | Train Loss: 0.5278 Acc: 0.7438 | Val Loss: 0.5277 Acc: 0.7246                                            \n",
      "Epoch 012 | Train Loss: 0.5062 Acc: 0.7578 | Val Loss: 0.5087 Acc: 0.7542                                            \n",
      "Epoch 013 | Train Loss: 0.5021 Acc: 0.7617 | Val Loss: 0.4814 Acc: 0.7711                                            \n",
      "Epoch 014 | Train Loss: 0.4954 Acc: 0.7672 | Val Loss: 0.4798 Acc: 0.7663                                            \n",
      "Epoch 015 | Train Loss: 0.4839 Acc: 0.7703 | Val Loss: 0.4731 Acc: 0.7736                                            \n",
      "Epoch 016 | Train Loss: 0.4626 Acc: 0.7874 | Val Loss: 0.4540 Acc: 0.7826                                            \n",
      "Epoch 017 | Train Loss: 0.4569 Acc: 0.7862 | Val Loss: 0.4426 Acc: 0.7874                                            \n",
      "Epoch 018 | Train Loss: 0.4455 Acc: 0.7910 | Val Loss: 0.4317 Acc: 0.7983                                            \n",
      "Epoch 019 | Train Loss: 0.4326 Acc: 0.8051 | Val Loss: 0.4106 Acc: 0.8043                                            \n",
      "Epoch 020 | Train Loss: 0.4255 Acc: 0.8073 | Val Loss: 0.4107 Acc: 0.8158                                            \n",
      "Epoch 021 | Train Loss: 0.4126 Acc: 0.8169 | Val Loss: 0.4243 Acc: 0.8170                                            \n",
      "Epoch 022 | Train Loss: 0.4043 Acc: 0.8179 | Val Loss: 0.3738 Acc: 0.8345                                            \n",
      "Epoch 023 | Train Loss: 0.3879 Acc: 0.8280 | Val Loss: 0.4005 Acc: 0.8200                                            \n",
      "Epoch 024 | Train Loss: 0.3881 Acc: 0.8286 | Val Loss: 0.3753 Acc: 0.8321                                            \n",
      "Epoch 025 | Train Loss: 0.3653 Acc: 0.8466 | Val Loss: 0.3538 Acc: 0.8339                                            \n",
      "Epoch 026 | Train Loss: 0.3645 Acc: 0.8439 | Val Loss: 0.3899 Acc: 0.8158                                            \n",
      "Epoch 027 | Train Loss: 0.3479 Acc: 0.8510 | Val Loss: 0.3382 Acc: 0.8400                                            \n",
      "Epoch 028 | Train Loss: 0.3454 Acc: 0.8522 | Val Loss: 0.3524 Acc: 0.8388                                            \n",
      "Epoch 029 | Train Loss: 0.3276 Acc: 0.8628 | Val Loss: 0.3395 Acc: 0.8388                                            \n",
      "Epoch 030 | Train Loss: 0.3246 Acc: 0.8634 | Val Loss: 0.3230 Acc: 0.8617                                            \n",
      "Epoch 031 | Train Loss: 0.3215 Acc: 0.8644 | Val Loss: 0.3245 Acc: 0.8605                                            \n",
      "Epoch 032 | Train Loss: 0.3047 Acc: 0.8771 | Val Loss: 0.3068 Acc: 0.8605                                            \n",
      "Epoch 033 | Train Loss: 0.3044 Acc: 0.8766 | Val Loss: 0.2793 Acc: 0.8756                                            \n",
      "Epoch 034 | Train Loss: 0.2966 Acc: 0.8792 | Val Loss: 0.2887 Acc: 0.8786                                            \n",
      "Epoch 035 | Train Loss: 0.2795 Acc: 0.8845 | Val Loss: 0.2777 Acc: 0.8853                                            \n",
      "Epoch 036 | Train Loss: 0.2750 Acc: 0.8868 | Val Loss: 0.3762 Acc: 0.8388                                            \n",
      "Epoch 037 | Train Loss: 0.2770 Acc: 0.8852 | Val Loss: 0.2573 Acc: 0.8907                                            \n",
      "Epoch 038 | Train Loss: 0.2765 Acc: 0.8911 | Val Loss: 0.2802 Acc: 0.8774                                            \n",
      "Epoch 039 | Train Loss: 0.2517 Acc: 0.8972 | Val Loss: 0.2660 Acc: 0.8853                                            \n",
      "Epoch 040 | Train Loss: 0.2492 Acc: 0.9019 | Val Loss: 0.3556 Acc: 0.8460                                            \n",
      "Epoch 041 | Train Loss: 0.2416 Acc: 0.8991 | Val Loss: 0.2282 Acc: 0.9082                                            \n",
      "Epoch 042 | Train Loss: 0.2387 Acc: 0.9052 | Val Loss: 0.2258 Acc: 0.9136                                            \n",
      "Epoch 043 | Train Loss: 0.2360 Acc: 0.9070 | Val Loss: 0.2327 Acc: 0.9100                                            \n",
      "Epoch 044 | Train Loss: 0.2148 Acc: 0.9129 | Val Loss: 0.2751 Acc: 0.8913                                            \n",
      "Epoch 045 | Train Loss: 0.2221 Acc: 0.9132 | Val Loss: 0.2390 Acc: 0.9046                                            \n",
      "Epoch 046 | Train Loss: 0.2222 Acc: 0.9130 | Val Loss: 0.2086 Acc: 0.9185                                            \n",
      "Epoch 047 | Train Loss: 0.2071 Acc: 0.9206 | Val Loss: 0.2432 Acc: 0.9046                                            \n",
      "Epoch 048 | Train Loss: 0.2092 Acc: 0.9216 | Val Loss: 0.2568 Acc: 0.9052                                            \n",
      "Epoch 049 | Train Loss: 0.2076 Acc: 0.9225 | Val Loss: 0.3557 Acc: 0.8635                                            \n",
      "Epoch 050 | Train Loss: 0.2009 Acc: 0.9221 | Val Loss: 0.2452 Acc: 0.9046                                            \n",
      "Epoch 051 | Train Loss: 0.2031 Acc: 0.9238 | Val Loss: 0.2105 Acc: 0.9149                                            \n",
      "Epoch 052 | Train Loss: 0.1924 Acc: 0.9263 | Val Loss: 0.2415 Acc: 0.9112                                            \n",
      "Epoch 053 | Train Loss: 0.1900 Acc: 0.9263 | Val Loss: 0.2317 Acc: 0.9209                                            \n",
      "Epoch 054 | Train Loss: 0.1789 Acc: 0.9307 | Val Loss: 0.1994 Acc: 0.9233                                            \n",
      "Epoch 055 | Train Loss: 0.1820 Acc: 0.9293 | Val Loss: 0.1924 Acc: 0.9312                                            \n",
      "Epoch 056 | Train Loss: 0.1782 Acc: 0.9355 | Val Loss: 0.1937 Acc: 0.9263                                            \n",
      "Epoch 057 | Train Loss: 0.1693 Acc: 0.9346 | Val Loss: 0.1840 Acc: 0.9300                                            \n",
      "Epoch 058 | Train Loss: 0.1683 Acc: 0.9322 | Val Loss: 0.2494 Acc: 0.9010                                            \n",
      "Epoch 059 | Train Loss: 0.1735 Acc: 0.9348 | Val Loss: 0.1812 Acc: 0.9300                                            \n",
      "Epoch 060 | Train Loss: 0.1664 Acc: 0.9363 | Val Loss: 0.1825 Acc: 0.9354                                            \n",
      "Trial params:                                                                                                        \n",
      "{'batch_size': 32, 'cnn_dense': 128, 'cnn_dropout': 0.5375032647905167, 'cnn_kernel_size_1': 5, 'cnn_kernels_1': 32, 'cnn_kernels_2': 32, 'learning_rate': 0.0003610915430470101, 'lstm_dense': 32, 'lstm_hidden_size': 32, 'lstm_layers': 2, 'optimizer': 'adam'}\n",
      "Epoch 001 | Train Loss: 0.6824 Acc: 0.5733 | Val Loss: 0.6781 Acc: 0.5876                                            \n",
      "Epoch 002 | Train Loss: 0.6763 Acc: 0.5863 | Val Loss: 0.6751 Acc: 0.5900                                            \n",
      "Epoch 003 | Train Loss: 0.6729 Acc: 0.5931 | Val Loss: 0.6725 Acc: 0.5876                                            \n",
      "Epoch 004 | Train Loss: 0.6682 Acc: 0.6017 | Val Loss: 0.6619 Acc: 0.6069                                            \n",
      "Epoch 005 | Train Loss: 0.6585 Acc: 0.6091 | Val Loss: 0.6459 Acc: 0.6262                                            \n",
      "Epoch 006 | Train Loss: 0.6453 Acc: 0.6328 | Val Loss: 0.6259 Acc: 0.6685                                            \n",
      "Epoch 007 | Train Loss: 0.6298 Acc: 0.6610 | Val Loss: 0.6266 Acc: 0.6649                                            \n",
      "Epoch 008 | Train Loss: 0.6129 Acc: 0.6826 | Val Loss: 0.5962 Acc: 0.7017                                            \n",
      "Epoch 009 | Train Loss: 0.5999 Acc: 0.6973 | Val Loss: 0.5857 Acc: 0.6999                                            \n",
      "Epoch 010 | Train Loss: 0.5867 Acc: 0.7022 | Val Loss: 0.5794 Acc: 0.7114                                            \n",
      "Epoch 011 | Train Loss: 0.5720 Acc: 0.7192 | Val Loss: 0.5601 Acc: 0.7210                                            \n",
      "Epoch 012 | Train Loss: 0.5693 Acc: 0.7190 | Val Loss: 0.5487 Acc: 0.7228                                            \n",
      "Epoch 013 | Train Loss: 0.5516 Acc: 0.7368 | Val Loss: 0.5491 Acc: 0.7349                                            \n",
      "Epoch 014 | Train Loss: 0.5417 Acc: 0.7438 | Val Loss: 0.5369 Acc: 0.7325                                            \n",
      "Epoch 015 | Train Loss: 0.5380 Acc: 0.7414 | Val Loss: 0.5358 Acc: 0.7367                                            \n",
      "Epoch 016 | Train Loss: 0.5338 Acc: 0.7474 | Val Loss: 0.5292 Acc: 0.7385                                            \n",
      "Epoch 017 | Train Loss: 0.5234 Acc: 0.7566 | Val Loss: 0.5078 Acc: 0.7518                                            \n",
      "Epoch 018 | Train Loss: 0.5119 Acc: 0.7596 | Val Loss: 0.5121 Acc: 0.7579                                            \n",
      "Epoch 019 | Train Loss: 0.5096 Acc: 0.7654 | Val Loss: 0.4967 Acc: 0.7615                                            \n",
      "Epoch 020 | Train Loss: 0.4988 Acc: 0.7688 | Val Loss: 0.4814 Acc: 0.7729                                            \n",
      "Epoch 021 | Train Loss: 0.4918 Acc: 0.7687 | Val Loss: 0.4878 Acc: 0.7669                                            \n",
      "Epoch 022 | Train Loss: 0.4879 Acc: 0.7731 | Val Loss: 0.4865 Acc: 0.7657                                            \n",
      "Epoch 023 | Train Loss: 0.4763 Acc: 0.7749 | Val Loss: 0.4808 Acc: 0.7645                                            \n",
      "Epoch 024 | Train Loss: 0.4765 Acc: 0.7796 | Val Loss: 0.4631 Acc: 0.7808                                            \n",
      "Epoch 025 | Train Loss: 0.4700 Acc: 0.7876 | Val Loss: 0.4527 Acc: 0.7832                                            \n",
      "Epoch 026 | Train Loss: 0.4592 Acc: 0.7885 | Val Loss: 0.4400 Acc: 0.7929                                            \n",
      "Epoch 027 | Train Loss: 0.4530 Acc: 0.7965 | Val Loss: 0.4403 Acc: 0.7983                                            \n",
      "Epoch 028 | Train Loss: 0.4496 Acc: 0.7957 | Val Loss: 0.4249 Acc: 0.8050                                            \n",
      "Epoch 029 | Train Loss: 0.4426 Acc: 0.8010 | Val Loss: 0.4309 Acc: 0.8001                                            \n",
      "Epoch 030 | Train Loss: 0.4418 Acc: 0.8021 | Val Loss: 0.4212 Acc: 0.8019                                            \n",
      "Epoch 031 | Train Loss: 0.4272 Acc: 0.8061 | Val Loss: 0.4823 Acc: 0.7681                                            \n",
      "Epoch 032 | Train Loss: 0.4322 Acc: 0.7987 | Val Loss: 0.4497 Acc: 0.7844                                            \n",
      "Epoch 033 | Train Loss: 0.4248 Acc: 0.8099 | Val Loss: 0.3924 Acc: 0.8194                                            \n",
      "Epoch 034 | Train Loss: 0.4107 Acc: 0.8161 | Val Loss: 0.4135 Acc: 0.8092                                            \n",
      "Epoch 035 | Train Loss: 0.4099 Acc: 0.8141 | Val Loss: 0.3846 Acc: 0.8152                                            \n",
      "Epoch 036 | Train Loss: 0.3939 Acc: 0.8191 | Val Loss: 0.3708 Acc: 0.8267                                            \n",
      "Epoch 037 | Train Loss: 0.3968 Acc: 0.8217 | Val Loss: 0.3884 Acc: 0.8273                                            \n",
      "Epoch 038 | Train Loss: 0.3928 Acc: 0.8179 | Val Loss: 0.3745 Acc: 0.8315                                            \n",
      "Epoch 039 | Train Loss: 0.3777 Acc: 0.8285 | Val Loss: 0.3703 Acc: 0.8382                                            \n",
      "Epoch 040 | Train Loss: 0.3744 Acc: 0.8327 | Val Loss: 0.3633 Acc: 0.8297                                            \n",
      "Epoch 041 | Train Loss: 0.3676 Acc: 0.8362 | Val Loss: 0.3554 Acc: 0.8364                                            \n",
      "Epoch 042 | Train Loss: 0.3608 Acc: 0.8434 | Val Loss: 0.3911 Acc: 0.8225                                            \n",
      "Epoch 043 | Train Loss: 0.3592 Acc: 0.8419 | Val Loss: 0.3356 Acc: 0.8436                                            \n",
      "Epoch 044 | Train Loss: 0.3519 Acc: 0.8409 | Val Loss: 0.3207 Acc: 0.8581                                            \n",
      "Epoch 045 | Train Loss: 0.3454 Acc: 0.8523 | Val Loss: 0.3229 Acc: 0.8521                                            \n",
      "Epoch 046 | Train Loss: 0.3426 Acc: 0.8472 | Val Loss: 0.3150 Acc: 0.8557                                            \n",
      "Epoch 047 | Train Loss: 0.3401 Acc: 0.8470 | Val Loss: 0.3155 Acc: 0.8611                                            \n",
      "Epoch 048 | Train Loss: 0.3283 Acc: 0.8544 | Val Loss: 0.2976 Acc: 0.8756                                            \n",
      "Epoch 049 | Train Loss: 0.3193 Acc: 0.8638 | Val Loss: 0.2915 Acc: 0.8690                                            \n",
      "Epoch 050 | Train Loss: 0.3219 Acc: 0.8623 | Val Loss: 0.2916 Acc: 0.8780                                            \n",
      "Epoch 051 | Train Loss: 0.3182 Acc: 0.8655 | Val Loss: 0.2837 Acc: 0.8750                                            \n",
      "Epoch 052 | Train Loss: 0.3138 Acc: 0.8683 | Val Loss: 0.3062 Acc: 0.8647                                            \n",
      "Epoch 053 | Train Loss: 0.3077 Acc: 0.8723 | Val Loss: 0.2757 Acc: 0.8792                                            \n",
      "Epoch 054 | Train Loss: 0.3041 Acc: 0.8762 | Val Loss: 0.2872 Acc: 0.8762                                            \n",
      "Epoch 055 | Train Loss: 0.3003 Acc: 0.8726 | Val Loss: 0.2826 Acc: 0.8732                                            \n",
      "Epoch 056 | Train Loss: 0.2901 Acc: 0.8786 | Val Loss: 0.2810 Acc: 0.8810                                            \n",
      "Epoch 057 | Train Loss: 0.2953 Acc: 0.8774 | Val Loss: 0.2879 Acc: 0.8774                                            \n",
      "Epoch 058 | Train Loss: 0.2903 Acc: 0.8780 | Val Loss: 0.2592 Acc: 0.8889                                            \n",
      "Epoch 059 | Train Loss: 0.2744 Acc: 0.8893 | Val Loss: 0.2877 Acc: 0.8774                                            \n",
      "Epoch 060 | Train Loss: 0.2744 Acc: 0.8908 | Val Loss: 0.2477 Acc: 0.8961                                            \n",
      "Trial params:                                                                                                        \n",
      "{'batch_size': 16, 'cnn_dense': 64, 'cnn_dropout': 0.6318190180603019, 'cnn_kernel_size_1': 3, 'cnn_kernels_1': 64, 'cnn_kernels_2': 16, 'learning_rate': 0.0005424305662912839, 'lstm_dense': 128, 'lstm_hidden_size': 64, 'lstm_layers': 3, 'optimizer': 'adam'}\n",
      "Epoch 001 | Train Loss: 0.6815 Acc: 0.5692 | Val Loss: 0.6782 Acc: 0.5894                                            \n",
      "Epoch 002 | Train Loss: 0.6771 Acc: 0.5887 | Val Loss: 0.6755 Acc: 0.5930                                            \n",
      "Epoch 003 | Train Loss: 0.6757 Acc: 0.5883 | Val Loss: 0.6750 Acc: 0.5912                                            \n",
      "Epoch 004 | Train Loss: 0.6749 Acc: 0.5937 | Val Loss: 0.6732 Acc: 0.5948                                            \n",
      "Epoch 005 | Train Loss: 0.6740 Acc: 0.5901 | Val Loss: 0.6701 Acc: 0.5954                                            \n",
      "Epoch 006 | Train Loss: 0.6680 Acc: 0.5955 | Val Loss: 0.6590 Acc: 0.5996                                            \n",
      "Epoch 007 | Train Loss: 0.6566 Acc: 0.6136 | Val Loss: 0.6433 Acc: 0.6292                                            \n",
      "Epoch 008 | Train Loss: 0.6439 Acc: 0.6408 | Val Loss: 0.6265 Acc: 0.6624                                            \n",
      "Epoch 009 | Train Loss: 0.6242 Acc: 0.6701 | Val Loss: 0.6050 Acc: 0.6787                                            \n",
      "Epoch 010 | Train Loss: 0.6044 Acc: 0.6823 | Val Loss: 0.6047 Acc: 0.6896                                            \n",
      "Epoch 011 | Train Loss: 0.5956 Acc: 0.6938 | Val Loss: 0.5791 Acc: 0.7065                                            \n",
      "Epoch 012 | Train Loss: 0.5918 Acc: 0.6920 | Val Loss: 0.5791 Acc: 0.6987                                            \n",
      "Epoch 013 | Train Loss: 0.5822 Acc: 0.7065 | Val Loss: 0.5697 Acc: 0.7101                                            \n",
      "Epoch 014 | Train Loss: 0.5751 Acc: 0.7084 | Val Loss: 0.5656 Acc: 0.7071                                            \n",
      "Epoch 015 | Train Loss: 0.5727 Acc: 0.7136 | Val Loss: 0.5574 Acc: 0.7186                                            \n",
      "Epoch 016 | Train Loss: 0.5635 Acc: 0.7211 | Val Loss: 0.5554 Acc: 0.7174                                            \n",
      "Epoch 017 | Train Loss: 0.5641 Acc: 0.7149 | Val Loss: 0.5583 Acc: 0.7144                                            \n",
      "Epoch 018 | Train Loss: 0.5658 Acc: 0.7163 | Val Loss: 0.5516 Acc: 0.7180                                            \n",
      "Epoch 019 | Train Loss: 0.5670 Acc: 0.7193 | Val Loss: 0.5537 Acc: 0.7234                                            \n",
      "Epoch 020 | Train Loss: 0.5626 Acc: 0.7238 | Val Loss: 0.5539 Acc: 0.7198                                            \n",
      "Epoch 021 | Train Loss: 0.5553 Acc: 0.7311 | Val Loss: 0.5454 Acc: 0.7252                                            \n",
      "Epoch 022 | Train Loss: 0.5535 Acc: 0.7288 | Val Loss: 0.5654 Acc: 0.7174                                            \n",
      "Epoch 023 | Train Loss: 0.5504 Acc: 0.7326 | Val Loss: 0.5428 Acc: 0.7271                                            \n",
      "Epoch 024 | Train Loss: 0.5427 Acc: 0.7353 | Val Loss: 0.5565 Acc: 0.7180                                            \n",
      "Epoch 025 | Train Loss: 0.5448 Acc: 0.7326 | Val Loss: 0.5403 Acc: 0.7440                                            \n",
      "Epoch 026 | Train Loss: 0.5433 Acc: 0.7297 | Val Loss: 0.5372 Acc: 0.7277                                            \n",
      "Epoch 027 | Train Loss: 0.5424 Acc: 0.7352 | Val Loss: 0.5282 Acc: 0.7379                                            \n",
      "Epoch 028 | Train Loss: 0.5361 Acc: 0.7385 | Val Loss: 0.5323 Acc: 0.7409                                            \n",
      "Epoch 029 | Train Loss: 0.5363 Acc: 0.7377 | Val Loss: 0.5293 Acc: 0.7428                                            \n",
      "Epoch 030 | Train Loss: 0.5365 Acc: 0.7433 | Val Loss: 0.5318 Acc: 0.7403                                            \n",
      "Epoch 031 | Train Loss: 0.5294 Acc: 0.7527 | Val Loss: 0.5270 Acc: 0.7428                                            \n",
      "Epoch 032 | Train Loss: 0.5323 Acc: 0.7385 | Val Loss: 0.5206 Acc: 0.7464                                            \n",
      "Epoch 033 | Train Loss: 0.5346 Acc: 0.7414 | Val Loss: 0.5099 Acc: 0.7542                                            \n",
      "Epoch 034 | Train Loss: 0.5307 Acc: 0.7462 | Val Loss: 0.5240 Acc: 0.7494                                            \n",
      "Epoch 035 | Train Loss: 0.5207 Acc: 0.7472 | Val Loss: 0.5075 Acc: 0.7585                                            \n",
      "Epoch 036 | Train Loss: 0.5189 Acc: 0.7521 | Val Loss: 0.5122 Acc: 0.7500                                            \n",
      "Epoch 037 | Train Loss: 0.5140 Acc: 0.7539 | Val Loss: 0.5041 Acc: 0.7579                                            \n",
      "Epoch 038 | Train Loss: 0.5070 Acc: 0.7602 | Val Loss: 0.4986 Acc: 0.7639                                            \n",
      "Epoch 039 | Train Loss: 0.5082 Acc: 0.7551 | Val Loss: 0.4994 Acc: 0.7615                                            \n",
      "Epoch 040 | Train Loss: 0.5033 Acc: 0.7629 | Val Loss: 0.4899 Acc: 0.7669                                            \n",
      "Epoch 041 | Train Loss: 0.5037 Acc: 0.7666 | Val Loss: 0.4846 Acc: 0.7693                                            \n",
      "Epoch 042 | Train Loss: 0.5018 Acc: 0.7652 | Val Loss: 0.4882 Acc: 0.7603                                            \n",
      "Epoch 043 | Train Loss: 0.4928 Acc: 0.7737 | Val Loss: 0.4977 Acc: 0.7518                                            \n",
      "Epoch 044 | Train Loss: 0.4886 Acc: 0.7703 | Val Loss: 0.4794 Acc: 0.7736                                            \n",
      "Epoch 045 | Train Loss: 0.4893 Acc: 0.7746 | Val Loss: 0.4845 Acc: 0.7729                                            \n",
      "Epoch 046 | Train Loss: 0.4879 Acc: 0.7750 | Val Loss: 0.4673 Acc: 0.7705                                            \n",
      "Epoch 047 | Train Loss: 0.4783 Acc: 0.7826 | Val Loss: 0.5026 Acc: 0.7542                                            \n",
      "Epoch 048 | Train Loss: 0.4823 Acc: 0.7771 | Val Loss: 0.4768 Acc: 0.7844                                            \n",
      "Epoch 049 | Train Loss: 0.4871 Acc: 0.7729 | Val Loss: 0.4631 Acc: 0.7814                                            \n",
      "Epoch 050 | Train Loss: 0.4778 Acc: 0.7756 | Val Loss: 0.4503 Acc: 0.7899                                            \n",
      "Epoch 051 | Train Loss: 0.4736 Acc: 0.7830 | Val Loss: 0.4522 Acc: 0.7778                                            \n",
      "Epoch 052 | Train Loss: 0.4710 Acc: 0.7803 | Val Loss: 0.4710 Acc: 0.7754                                            \n",
      "Epoch 053 | Train Loss: 0.4726 Acc: 0.7815 | Val Loss: 0.4487 Acc: 0.7923                                            \n",
      "Epoch 054 | Train Loss: 0.4729 Acc: 0.7799 | Val Loss: 0.4519 Acc: 0.7820                                            \n",
      "Epoch 055 | Train Loss: 0.4667 Acc: 0.7895 | Val Loss: 0.4587 Acc: 0.7784                                            \n",
      "Epoch 056 | Train Loss: 0.4618 Acc: 0.7903 | Val Loss: 0.4347 Acc: 0.8031                                            \n",
      "Epoch 057 | Train Loss: 0.4695 Acc: 0.7815 | Val Loss: 0.4432 Acc: 0.7844                                            \n",
      "Epoch 058 | Train Loss: 0.4610 Acc: 0.7944 | Val Loss: 0.4515 Acc: 0.7959                                            \n",
      "Epoch 059 | Train Loss: 0.4631 Acc: 0.7847 | Val Loss: 0.4208 Acc: 0.8080                                            \n",
      "Epoch 060 | Train Loss: 0.4565 Acc: 0.7907 | Val Loss: 0.4441 Acc: 0.7893                                            \n",
      "Trial params:                                                                                                        \n",
      "{'batch_size': 64, 'cnn_dense': 256, 'cnn_dropout': 0.6253538874947929, 'cnn_kernel_size_1': 5, 'cnn_kernels_1': 64, 'cnn_kernels_2': 32, 'learning_rate': 0.0009396849866569698, 'lstm_dense': 128, 'lstm_hidden_size': 32, 'lstm_layers': 3, 'optimizer': 'sgd'}\n",
      "Epoch 001 | Train Loss: 0.6961 Acc: 0.4835 | Val Loss: 0.6892 Acc: 0.5586                                            \n",
      "Epoch 002 | Train Loss: 0.6882 Acc: 0.5540 | Val Loss: 0.6865 Acc: 0.5586                                            \n",
      "Epoch 003 | Train Loss: 0.6862 Acc: 0.5584 | Val Loss: 0.6863 Acc: 0.5586                                            \n",
      "Epoch 004 | Train Loss: 0.6866 Acc: 0.5582 | Val Loss: 0.6863 Acc: 0.5586                                            \n",
      "Epoch 005 | Train Loss: 0.6861 Acc: 0.5582 | Val Loss: 0.6863 Acc: 0.5586                                            \n",
      "Epoch 006 | Train Loss: 0.6871 Acc: 0.5582 | Val Loss: 0.6863 Acc: 0.5586                                            \n",
      "Epoch 007 | Train Loss: 0.6867 Acc: 0.5582 | Val Loss: 0.6863 Acc: 0.5586                                            \n",
      "Epoch 008 | Train Loss: 0.6871 Acc: 0.5582 | Val Loss: 0.6863 Acc: 0.5586                                            \n",
      "Epoch 009 | Train Loss: 0.6871 Acc: 0.5582 | Val Loss: 0.6863 Acc: 0.5586                                            \n",
      "Epoch 010 | Train Loss: 0.6869 Acc: 0.5582 | Val Loss: 0.6863 Acc: 0.5586                                            \n",
      "Epoch 011 | Train Loss: 0.6867 Acc: 0.5582 | Val Loss: 0.6863 Acc: 0.5586                                            \n",
      "Epoch 012 | Train Loss: 0.6866 Acc: 0.5582 | Val Loss: 0.6863 Acc: 0.5586                                            \n",
      "Epoch 013 | Train Loss: 0.6870 Acc: 0.5582 | Val Loss: 0.6863 Acc: 0.5586                                            \n",
      "Epoch 014 | Train Loss: 0.6869 Acc: 0.5582 | Val Loss: 0.6863 Acc: 0.5586                                            \n",
      "Epoch 015 | Train Loss: 0.6867 Acc: 0.5582 | Val Loss: 0.6863 Acc: 0.5586                                            \n",
      "Epoch 016 | Train Loss: 0.6865 Acc: 0.5582 | Val Loss: 0.6863 Acc: 0.5586                                            \n",
      "Epoch 017 | Train Loss: 0.6868 Acc: 0.5582 | Val Loss: 0.6863 Acc: 0.5586                                            \n",
      "Epoch 018 | Train Loss: 0.6868 Acc: 0.5582 | Val Loss: 0.6863 Acc: 0.5586                                            \n",
      "Epoch 019 | Train Loss: 0.6868 Acc: 0.5582 | Val Loss: 0.6863 Acc: 0.5586                                            \n",
      "Epoch 020 | Train Loss: 0.6872 Acc: 0.5582 | Val Loss: 0.6863 Acc: 0.5586                                            \n",
      "Epoch 021 | Train Loss: 0.6860 Acc: 0.5582 | Val Loss: 0.6863 Acc: 0.5586                                            \n",
      "Epoch 022 | Train Loss: 0.6864 Acc: 0.5582 | Val Loss: 0.6863 Acc: 0.5586                                            \n",
      "Epoch 023 | Train Loss: 0.6865 Acc: 0.5582 | Val Loss: 0.6863 Acc: 0.5586                                            \n",
      "Epoch 024 | Train Loss: 0.6865 Acc: 0.5582 | Val Loss: 0.6863 Acc: 0.5586                                            \n",
      "Epoch 025 | Train Loss: 0.6867 Acc: 0.5582 | Val Loss: 0.6863 Acc: 0.5586                                            \n",
      "Epoch 026 | Train Loss: 0.6868 Acc: 0.5582 | Val Loss: 0.6863 Acc: 0.5586                                            \n",
      "Epoch 027 | Train Loss: 0.6863 Acc: 0.5582 | Val Loss: 0.6863 Acc: 0.5586                                            \n",
      "Epoch 028 | Train Loss: 0.6862 Acc: 0.5582 | Val Loss: 0.6863 Acc: 0.5586                                            \n",
      "Epoch 029 | Train Loss: 0.6866 Acc: 0.5582 | Val Loss: 0.6863 Acc: 0.5586                                            \n",
      "Epoch 030 | Train Loss: 0.6866 Acc: 0.5582 | Val Loss: 0.6863 Acc: 0.5586                                            \n",
      "Epoch 031 | Train Loss: 0.6868 Acc: 0.5582 | Val Loss: 0.6863 Acc: 0.5586                                            \n",
      "Epoch 032 | Train Loss: 0.6869 Acc: 0.5582 | Val Loss: 0.6863 Acc: 0.5586                                            \n",
      "Epoch 033 | Train Loss: 0.6866 Acc: 0.5582 | Val Loss: 0.6863 Acc: 0.5586                                            \n",
      "Epoch 034 | Train Loss: 0.6864 Acc: 0.5582 | Val Loss: 0.6863 Acc: 0.5586                                            \n",
      "Epoch 035 | Train Loss: 0.6867 Acc: 0.5582 | Val Loss: 0.6863 Acc: 0.5586                                            \n",
      "Epoch 036 | Train Loss: 0.6865 Acc: 0.5582 | Val Loss: 0.6863 Acc: 0.5586                                            \n",
      "Epoch 037 | Train Loss: 0.6865 Acc: 0.5582 | Val Loss: 0.6863 Acc: 0.5586                                            \n",
      "Epoch 038 | Train Loss: 0.6868 Acc: 0.5582 | Val Loss: 0.6863 Acc: 0.5586                                            \n",
      "Epoch 039 | Train Loss: 0.6862 Acc: 0.5582 | Val Loss: 0.6863 Acc: 0.5586                                            \n",
      "Epoch 040 | Train Loss: 0.6864 Acc: 0.5582 | Val Loss: 0.6863 Acc: 0.5586                                            \n",
      "Epoch 041 | Train Loss: 0.6866 Acc: 0.5582 | Val Loss: 0.6863 Acc: 0.5586                                            \n",
      "Epoch 042 | Train Loss: 0.6864 Acc: 0.5582 | Val Loss: 0.6863 Acc: 0.5586                                            \n",
      "Epoch 043 | Train Loss: 0.6863 Acc: 0.5582 | Val Loss: 0.6863 Acc: 0.5586                                            \n",
      "Epoch 044 | Train Loss: 0.6863 Acc: 0.5582 | Val Loss: 0.6863 Acc: 0.5586                                            \n",
      "Epoch 045 | Train Loss: 0.6867 Acc: 0.5582 | Val Loss: 0.6863 Acc: 0.5586                                            \n",
      "Epoch 046 | Train Loss: 0.6870 Acc: 0.5582 | Val Loss: 0.6863 Acc: 0.5586                                            \n",
      "Epoch 047 | Train Loss: 0.6864 Acc: 0.5582 | Val Loss: 0.6863 Acc: 0.5586                                            \n",
      "Epoch 048 | Train Loss: 0.6865 Acc: 0.5582 | Val Loss: 0.6863 Acc: 0.5586                                            \n",
      "Epoch 049 | Train Loss: 0.6862 Acc: 0.5582 | Val Loss: 0.6863 Acc: 0.5586                                            \n",
      "Epoch 050 | Train Loss: 0.6864 Acc: 0.5582 | Val Loss: 0.6863 Acc: 0.5586                                            \n",
      "Epoch 051 | Train Loss: 0.6863 Acc: 0.5582 | Val Loss: 0.6863 Acc: 0.5586                                            \n",
      "Epoch 052 | Train Loss: 0.6868 Acc: 0.5582 | Val Loss: 0.6863 Acc: 0.5586                                            \n",
      "Epoch 053 | Train Loss: 0.6870 Acc: 0.5582 | Val Loss: 0.6863 Acc: 0.5586                                            \n",
      "Epoch 054 | Train Loss: 0.6863 Acc: 0.5582 | Val Loss: 0.6862 Acc: 0.5586                                            \n",
      "Epoch 055 | Train Loss: 0.6866 Acc: 0.5582 | Val Loss: 0.6863 Acc: 0.5586                                            \n",
      "Epoch 056 | Train Loss: 0.6866 Acc: 0.5582 | Val Loss: 0.6862 Acc: 0.5586                                            \n",
      "Epoch 057 | Train Loss: 0.6868 Acc: 0.5582 | Val Loss: 0.6862 Acc: 0.5586                                            \n",
      "Epoch 058 | Train Loss: 0.6865 Acc: 0.5582 | Val Loss: 0.6863 Acc: 0.5586                                            \n",
      "Epoch 059 | Train Loss: 0.6868 Acc: 0.5582 | Val Loss: 0.6863 Acc: 0.5586                                            \n",
      "Epoch 060 | Train Loss: 0.6864 Acc: 0.5582 | Val Loss: 0.6863 Acc: 0.5586                                            \n",
      "Trial params:                                                                                                        \n",
      "{'batch_size': 16, 'cnn_dense': 128, 'cnn_dropout': 0.09922062365725956, 'cnn_kernel_size_1': 5, 'cnn_kernels_1': 32, 'cnn_kernels_2': 96, 'learning_rate': 0.00021068604848522077, 'lstm_dense': 64, 'lstm_hidden_size': 128, 'lstm_layers': 3, 'optimizer': 'rmsprop'}\n",
      "Epoch 001 | Train Loss: 0.6802 Acc: 0.5786 | Val Loss: 0.6818 Acc: 0.5707                                            \n",
      "Epoch 002 | Train Loss: 0.6737 Acc: 0.5913 | Val Loss: 0.6830 Acc: 0.5688                                            \n",
      "Epoch 003 | Train Loss: 0.6683 Acc: 0.5970 | Val Loss: 0.6649 Acc: 0.5996                                            \n",
      "Epoch 004 | Train Loss: 0.6563 Acc: 0.6160 | Val Loss: 0.6842 Acc: 0.5459                                            \n",
      "Epoch 005 | Train Loss: 0.6397 Acc: 0.6480 | Val Loss: 0.6323 Acc: 0.6449                                            \n",
      "Epoch 006 | Train Loss: 0.6213 Acc: 0.6714 | Val Loss: 0.6094 Acc: 0.6733                                            \n",
      "Epoch 007 | Train Loss: 0.6110 Acc: 0.6825 | Val Loss: 0.6326 Acc: 0.6558                                            \n",
      "Epoch 008 | Train Loss: 0.5900 Acc: 0.6968 | Val Loss: 0.5827 Acc: 0.7095                                            \n",
      "Epoch 009 | Train Loss: 0.5695 Acc: 0.7196 | Val Loss: 0.5788 Acc: 0.7029                                            \n",
      "Epoch 010 | Train Loss: 0.5527 Acc: 0.7317 | Val Loss: 0.5591 Acc: 0.7144                                            \n",
      "Epoch 011 | Train Loss: 0.5413 Acc: 0.7420 | Val Loss: 0.5966 Acc: 0.6890                                            \n",
      "Epoch 012 | Train Loss: 0.5285 Acc: 0.7513 | Val Loss: 0.5555 Acc: 0.7277                                            \n",
      "Epoch 013 | Train Loss: 0.5169 Acc: 0.7542 | Val Loss: 0.5425 Acc: 0.7319                                            \n",
      "Epoch 014 | Train Loss: 0.5098 Acc: 0.7660 | Val Loss: 0.5237 Acc: 0.7476                                            \n",
      "Epoch 015 | Train Loss: 0.4993 Acc: 0.7709 | Val Loss: 0.5136 Acc: 0.7560                                            \n",
      "Epoch 016 | Train Loss: 0.4925 Acc: 0.7746 | Val Loss: 0.5269 Acc: 0.7566                                            \n",
      "Epoch 017 | Train Loss: 0.4865 Acc: 0.7826 | Val Loss: 0.5171 Acc: 0.7591                                            \n",
      "Epoch 018 | Train Loss: 0.4796 Acc: 0.7839 | Val Loss: 0.5128 Acc: 0.7633                                            \n",
      "Epoch 019 | Train Loss: 0.4675 Acc: 0.7924 | Val Loss: 0.4960 Acc: 0.7609                                            \n",
      "Epoch 020 | Train Loss: 0.4593 Acc: 0.7977 | Val Loss: 0.5214 Acc: 0.7639                                            \n",
      "Epoch 021 | Train Loss: 0.4554 Acc: 0.7971 | Val Loss: 0.4899 Acc: 0.7754                                            \n",
      "Epoch 022 | Train Loss: 0.4482 Acc: 0.8036 | Val Loss: 0.4755 Acc: 0.7820                                            \n",
      "Epoch 023 | Train Loss: 0.4379 Acc: 0.8069 | Val Loss: 0.4989 Acc: 0.7705                                            \n",
      "Epoch 024 | Train Loss: 0.4280 Acc: 0.8108 | Val Loss: 0.4559 Acc: 0.7826                                            \n",
      "Epoch 025 | Train Loss: 0.4231 Acc: 0.8167 | Val Loss: 0.4454 Acc: 0.8037                                            \n",
      "Epoch 026 | Train Loss: 0.4140 Acc: 0.8212 | Val Loss: 0.4623 Acc: 0.7911                                            \n",
      "Epoch 027 | Train Loss: 0.4030 Acc: 0.8274 | Val Loss: 0.4275 Acc: 0.8043                                            \n",
      "Epoch 028 | Train Loss: 0.3891 Acc: 0.8345 | Val Loss: 0.4104 Acc: 0.8170                                            \n",
      "Epoch 029 | Train Loss: 0.3773 Acc: 0.8363 | Val Loss: 0.4229 Acc: 0.8152                                            \n",
      "Epoch 030 | Train Loss: 0.3658 Acc: 0.8393 | Val Loss: 0.4740 Acc: 0.7808                                            \n",
      "Epoch 031 | Train Loss: 0.3429 Acc: 0.8557 | Val Loss: 0.4597 Acc: 0.7989                                            \n",
      "Epoch 032 | Train Loss: 0.3358 Acc: 0.8564 | Val Loss: 0.3699 Acc: 0.8333                                            \n",
      "Epoch 033 | Train Loss: 0.3129 Acc: 0.8692 | Val Loss: 0.4908 Acc: 0.7778                                            \n",
      "Epoch 034 | Train Loss: 0.2949 Acc: 0.8774 | Val Loss: 0.3767 Acc: 0.8333                                            \n",
      "Epoch 035 | Train Loss: 0.2897 Acc: 0.8813 | Val Loss: 0.3828 Acc: 0.8412                                            \n",
      "Epoch 036 | Train Loss: 0.2722 Acc: 0.8877 | Val Loss: 0.3508 Acc: 0.8545                                            \n",
      "Epoch 037 | Train Loss: 0.2550 Acc: 0.8985 | Val Loss: 0.3477 Acc: 0.8581                                            \n",
      "Epoch 038 | Train Loss: 0.2491 Acc: 0.9023 | Val Loss: 0.3290 Acc: 0.8605                                            \n",
      "Epoch 039 | Train Loss: 0.2319 Acc: 0.9041 | Val Loss: 0.3242 Acc: 0.8569                                            \n",
      "Epoch 040 | Train Loss: 0.2205 Acc: 0.9115 | Val Loss: 0.3268 Acc: 0.8653                                            \n",
      "Epoch 041 | Train Loss: 0.2120 Acc: 0.9139 | Val Loss: 0.3374 Acc: 0.8551                                            \n",
      "Epoch 042 | Train Loss: 0.1955 Acc: 0.9259 | Val Loss: 0.3503 Acc: 0.8388                                            \n",
      "Epoch 043 | Train Loss: 0.1810 Acc: 0.9265 | Val Loss: 0.3524 Acc: 0.8623                                            \n",
      "Epoch 044 | Train Loss: 0.1762 Acc: 0.9361 | Val Loss: 0.2985 Acc: 0.8768                                            \n",
      "Epoch 045 | Train Loss: 0.1648 Acc: 0.9373 | Val Loss: 0.2960 Acc: 0.8798                                            \n",
      "Epoch 046 | Train Loss: 0.1573 Acc: 0.9423 | Val Loss: 0.3030 Acc: 0.8768                                            \n",
      "Epoch 047 | Train Loss: 0.1436 Acc: 0.9449 | Val Loss: 0.5401 Acc: 0.7983                                            \n",
      "Overfitting detected                                                                                                 \n",
      "Trial params:                                                                                                        \n",
      "{'batch_size': 48, 'cnn_dense': 128, 'cnn_dropout': 0.2646704421394981, 'cnn_kernel_size_1': 5, 'cnn_kernels_1': 32, 'cnn_kernels_2': 96, 'learning_rate': 0.004595926261898936, 'lstm_dense': 64, 'lstm_hidden_size': 128, 'lstm_layers': 3, 'optimizer': 'adam'}\n",
      "Epoch 001 | Train Loss: 0.6840 Acc: 0.5726 | Val Loss: 0.6754 Acc: 0.5888                                            \n",
      "Epoch 002 | Train Loss: 0.6770 Acc: 0.5969 | Val Loss: 0.6602 Acc: 0.6123                                            \n",
      "Epoch 003 | Train Loss: 0.6580 Acc: 0.6172 | Val Loss: 0.6791 Acc: 0.5731                                            \n",
      "Epoch 004 | Train Loss: 0.6338 Acc: 0.6609 | Val Loss: 0.6463 Acc: 0.6310                                            \n",
      "Epoch 005 | Train Loss: 0.6216 Acc: 0.6870 | Val Loss: 0.6060 Acc: 0.6957                                            \n",
      "Epoch 006 | Train Loss: 0.5836 Acc: 0.7231 | Val Loss: 0.5696 Acc: 0.7156                                            \n",
      "Epoch 007 | Train Loss: 0.5655 Acc: 0.7318 | Val Loss: 0.5595 Acc: 0.7204                                            \n",
      "Epoch 008 | Train Loss: 0.5514 Acc: 0.7356 | Val Loss: 0.5595 Acc: 0.7162                                            \n",
      "Epoch 009 | Train Loss: 0.5483 Acc: 0.7343 | Val Loss: 0.5699 Acc: 0.7083                                            \n",
      "Epoch 010 | Train Loss: 0.5424 Acc: 0.7388 | Val Loss: 0.5382 Acc: 0.7355                                            \n",
      "Epoch 011 | Train Loss: 0.5185 Acc: 0.7512 | Val Loss: 0.5042 Acc: 0.7518                                            \n",
      "Epoch 012 | Train Loss: 0.5016 Acc: 0.7613 | Val Loss: 0.4916 Acc: 0.7476                                            \n",
      "Epoch 013 | Train Loss: 0.4990 Acc: 0.7643 | Val Loss: 0.4997 Acc: 0.7560                                            \n",
      "Epoch 014 | Train Loss: 0.4740 Acc: 0.7728 | Val Loss: 0.4875 Acc: 0.7699                                            \n",
      "Epoch 015 | Train Loss: 0.4674 Acc: 0.7750 | Val Loss: 0.4813 Acc: 0.7603                                            \n",
      "Epoch 016 | Train Loss: 0.4639 Acc: 0.7824 | Val Loss: 0.4588 Acc: 0.7820                                            \n",
      "Epoch 017 | Train Loss: 0.4428 Acc: 0.7900 | Val Loss: 0.4380 Acc: 0.7886                                            \n",
      "Epoch 018 | Train Loss: 0.4219 Acc: 0.8011 | Val Loss: 0.4204 Acc: 0.8013                                            \n",
      "Epoch 019 | Train Loss: 0.4240 Acc: 0.8061 | Val Loss: 0.4237 Acc: 0.8128                                            \n",
      "Epoch 020 | Train Loss: 0.3994 Acc: 0.8258 | Val Loss: 0.4134 Acc: 0.8104                                            \n",
      "Epoch 021 | Train Loss: 0.3946 Acc: 0.8268 | Val Loss: 0.4067 Acc: 0.8333                                            \n",
      "Epoch 022 | Train Loss: 0.3711 Acc: 0.8378 | Val Loss: 0.3598 Acc: 0.8430                                            \n",
      "Epoch 023 | Train Loss: 0.3418 Acc: 0.8573 | Val Loss: 0.3707 Acc: 0.8412                                            \n",
      "Epoch 024 | Train Loss: 0.3348 Acc: 0.8597 | Val Loss: 0.3083 Acc: 0.8647                                            \n",
      "Epoch 025 | Train Loss: 0.3143 Acc: 0.8689 | Val Loss: 0.2997 Acc: 0.8678                                            \n",
      "Epoch 026 | Train Loss: 0.3007 Acc: 0.8735 | Val Loss: 0.3667 Acc: 0.8315                                            \n",
      "Epoch 027 | Train Loss: 0.3093 Acc: 0.8768 | Val Loss: 0.2764 Acc: 0.8937                                            \n",
      "Epoch 028 | Train Loss: 0.2718 Acc: 0.8928 | Val Loss: 0.2779 Acc: 0.8853                                            \n",
      "Epoch 029 | Train Loss: 0.2730 Acc: 0.8964 | Val Loss: 0.3180 Acc: 0.8798                                            \n",
      "Epoch 030 | Train Loss: 0.2729 Acc: 0.8961 | Val Loss: 0.2688 Acc: 0.8847                                            \n",
      "Epoch 031 | Train Loss: 0.2492 Acc: 0.9016 | Val Loss: 0.2942 Acc: 0.8750                                            \n",
      "Epoch 032 | Train Loss: 0.2504 Acc: 0.9005 | Val Loss: 0.3359 Acc: 0.8702                                            \n",
      "Epoch 033 | Train Loss: 0.2529 Acc: 0.9056 | Val Loss: 0.2482 Acc: 0.9028                                            \n",
      "Epoch 034 | Train Loss: 0.2273 Acc: 0.9094 | Val Loss: 0.2552 Acc: 0.8979                                            \n",
      "Epoch 035 | Train Loss: 0.2380 Acc: 0.9111 | Val Loss: 0.2672 Acc: 0.8955                                            \n",
      "Epoch 036 | Train Loss: 0.2145 Acc: 0.9182 | Val Loss: 0.2458 Acc: 0.8998                                            \n",
      "Epoch 037 | Train Loss: 0.2075 Acc: 0.9213 | Val Loss: 0.2413 Acc: 0.9004                                            \n",
      "Epoch 038 | Train Loss: 0.2154 Acc: 0.9177 | Val Loss: 0.2476 Acc: 0.8943                                            \n",
      "Epoch 039 | Train Loss: 0.2106 Acc: 0.9192 | Val Loss: 0.2600 Acc: 0.8992                                            \n",
      "Epoch 040 | Train Loss: 0.1971 Acc: 0.9274 | Val Loss: 0.2325 Acc: 0.9076                                            \n",
      "Epoch 041 | Train Loss: 0.1903 Acc: 0.9331 | Val Loss: 0.2144 Acc: 0.9185                                            \n",
      "Epoch 042 | Train Loss: 0.1934 Acc: 0.9253 | Val Loss: 0.2279 Acc: 0.9106                                            \n",
      "Epoch 043 | Train Loss: 0.1949 Acc: 0.9287 | Val Loss: 0.2401 Acc: 0.9070                                            \n",
      "Epoch 044 | Train Loss: 0.1750 Acc: 0.9337 | Val Loss: 0.2352 Acc: 0.9161                                            \n",
      "Epoch 045 | Train Loss: 0.1884 Acc: 0.9286 | Val Loss: 0.2792 Acc: 0.8986                                            \n",
      "Epoch 046 | Train Loss: 0.1790 Acc: 0.9325 | Val Loss: 0.2155 Acc: 0.9136                                            \n",
      "Epoch 047 | Train Loss: 0.1531 Acc: 0.9435 | Val Loss: 0.2315 Acc: 0.9124                                            \n",
      "Epoch 048 | Train Loss: 0.1683 Acc: 0.9361 | Val Loss: 0.2458 Acc: 0.9094                                            \n",
      "Epoch 049 | Train Loss: 0.1668 Acc: 0.9379 | Val Loss: 0.2431 Acc: 0.9143                                            \n",
      "Epoch 050 | Train Loss: 0.1509 Acc: 0.9413 | Val Loss: 0.2136 Acc: 0.9318                                            \n",
      "Epoch 051 | Train Loss: 0.1578 Acc: 0.9402 | Val Loss: 0.1933 Acc: 0.9203                                            \n",
      "Epoch 052 | Train Loss: 0.1585 Acc: 0.9423 | Val Loss: 0.1879 Acc: 0.9354                                            \n",
      "Epoch 053 | Train Loss: 0.1537 Acc: 0.9396 | Val Loss: 0.2362 Acc: 0.9070                                            \n",
      "Epoch 054 | Train Loss: 0.1539 Acc: 0.9435 | Val Loss: 0.2146 Acc: 0.9149                                            \n",
      "Epoch 055 | Train Loss: 0.1512 Acc: 0.9452 | Val Loss: 0.1865 Acc: 0.9324                                            \n",
      "Epoch 056 | Train Loss: 0.1487 Acc: 0.9505 | Val Loss: 0.1856 Acc: 0.9390                                            \n",
      "Epoch 057 | Train Loss: 0.1410 Acc: 0.9500 | Val Loss: 0.2160 Acc: 0.9191                                            \n",
      "Epoch 058 | Train Loss: 0.1322 Acc: 0.9514 | Val Loss: 0.1883 Acc: 0.9360                                            \n",
      "Epoch 059 | Train Loss: 0.1452 Acc: 0.9447 | Val Loss: 0.1942 Acc: 0.9251                                            \n",
      "Epoch 060 | Train Loss: 0.1495 Acc: 0.9453 | Val Loss: 0.2182 Acc: 0.9245                                            \n",
      "Trial params:                                                                                                        \n",
      "{'batch_size': 16, 'cnn_dense': 128, 'cnn_dropout': 0.44096472471573167, 'cnn_kernel_size_1': 5, 'cnn_kernels_1': 32, 'cnn_kernels_2': 64, 'learning_rate': 0.0002406867388528373, 'lstm_dense': 64, 'lstm_hidden_size': 128, 'lstm_layers': 3, 'optimizer': 'rmsprop'}\n",
      "Epoch 001 | Train Loss: 0.6786 Acc: 0.5842 | Val Loss: 0.6696 Acc: 0.5960                                            \n",
      "Epoch 002 | Train Loss: 0.6604 Acc: 0.6126 | Val Loss: 0.6454 Acc: 0.6612                                            \n",
      "Epoch 003 | Train Loss: 0.6327 Acc: 0.6580 | Val Loss: 0.6415 Acc: 0.6341                                            \n",
      "Epoch 004 | Train Loss: 0.6182 Acc: 0.6802 | Val Loss: 0.6105 Acc: 0.6787                                            \n",
      "Epoch 005 | Train Loss: 0.6033 Acc: 0.6924 | Val Loss: 0.6117 Acc: 0.6757                                            \n",
      "Epoch 006 | Train Loss: 0.5943 Acc: 0.7026 | Val Loss: 0.6062 Acc: 0.6842                                            \n",
      "Epoch 007 | Train Loss: 0.5750 Acc: 0.7160 | Val Loss: 0.5834 Acc: 0.7077                                            \n",
      "Epoch 008 | Train Loss: 0.5658 Acc: 0.7223 | Val Loss: 0.5665 Acc: 0.7204                                            \n",
      "Epoch 009 | Train Loss: 0.5585 Acc: 0.7311 | Val Loss: 0.5612 Acc: 0.7216                                            \n",
      "Epoch 010 | Train Loss: 0.5530 Acc: 0.7321 | Val Loss: 0.5592 Acc: 0.7192                                            \n",
      "Epoch 011 | Train Loss: 0.5423 Acc: 0.7438 | Val Loss: 0.5424 Acc: 0.7277                                            \n",
      "Epoch 012 | Train Loss: 0.5337 Acc: 0.7456 | Val Loss: 0.5392 Acc: 0.7313                                            \n",
      "Epoch 013 | Train Loss: 0.5260 Acc: 0.7471 | Val Loss: 0.5512 Acc: 0.7325                                            \n",
      "Epoch 014 | Train Loss: 0.5219 Acc: 0.7542 | Val Loss: 0.5347 Acc: 0.7301                                            \n",
      "Epoch 015 | Train Loss: 0.5174 Acc: 0.7546 | Val Loss: 0.5231 Acc: 0.7415                                            \n",
      "Epoch 016 | Train Loss: 0.5073 Acc: 0.7622 | Val Loss: 0.5355 Acc: 0.7440                                            \n",
      "Epoch 017 | Train Loss: 0.5008 Acc: 0.7655 | Val Loss: 0.5112 Acc: 0.7476                                            \n",
      "Epoch 018 | Train Loss: 0.4918 Acc: 0.7725 | Val Loss: 0.5012 Acc: 0.7572                                            \n",
      "Epoch 019 | Train Loss: 0.4831 Acc: 0.7774 | Val Loss: 0.5033 Acc: 0.7548                                            \n",
      "Epoch 020 | Train Loss: 0.4744 Acc: 0.7821 | Val Loss: 0.4904 Acc: 0.7675                                            \n",
      "Epoch 021 | Train Loss: 0.4713 Acc: 0.7794 | Val Loss: 0.4947 Acc: 0.7591                                            \n",
      "Epoch 022 | Train Loss: 0.4596 Acc: 0.7883 | Val Loss: 0.4555 Acc: 0.7953                                            \n",
      "Epoch 023 | Train Loss: 0.4541 Acc: 0.7930 | Val Loss: 0.4488 Acc: 0.7935                                            \n",
      "Epoch 024 | Train Loss: 0.4412 Acc: 0.7993 | Val Loss: 0.4429 Acc: 0.7971                                            \n",
      "Epoch 025 | Train Loss: 0.4339 Acc: 0.7974 | Val Loss: 0.4441 Acc: 0.7995                                            \n",
      "Epoch 026 | Train Loss: 0.4229 Acc: 0.8058 | Val Loss: 0.4364 Acc: 0.7911                                            \n",
      "Epoch 027 | Train Loss: 0.4146 Acc: 0.8125 | Val Loss: 0.4351 Acc: 0.8019                                            \n",
      "Epoch 028 | Train Loss: 0.4056 Acc: 0.8155 | Val Loss: 0.4069 Acc: 0.8116                                            \n",
      "Epoch 029 | Train Loss: 0.3816 Acc: 0.8276 | Val Loss: 0.4209 Acc: 0.8194                                            \n",
      "Epoch 030 | Train Loss: 0.3802 Acc: 0.8316 | Val Loss: 0.3698 Acc: 0.8327                                            \n",
      "Epoch 031 | Train Loss: 0.3718 Acc: 0.8371 | Val Loss: 0.3697 Acc: 0.8351                                            \n",
      "Epoch 032 | Train Loss: 0.3492 Acc: 0.8419 | Val Loss: 0.3559 Acc: 0.8418                                            \n",
      "Epoch 033 | Train Loss: 0.3443 Acc: 0.8460 | Val Loss: 0.3555 Acc: 0.8333                                            \n",
      "Epoch 034 | Train Loss: 0.3328 Acc: 0.8551 | Val Loss: 0.3327 Acc: 0.8527                                            \n",
      "Epoch 035 | Train Loss: 0.3190 Acc: 0.8585 | Val Loss: 0.3292 Acc: 0.8575                                            \n",
      "Epoch 036 | Train Loss: 0.3123 Acc: 0.8635 | Val Loss: 0.3052 Acc: 0.8641                                            \n",
      "Epoch 037 | Train Loss: 0.2992 Acc: 0.8724 | Val Loss: 0.3133 Acc: 0.8671                                            \n",
      "Epoch 038 | Train Loss: 0.2852 Acc: 0.8748 | Val Loss: 0.3242 Acc: 0.8551                                            \n",
      "Epoch 039 | Train Loss: 0.2736 Acc: 0.8840 | Val Loss: 0.2785 Acc: 0.8889                                            \n",
      "Epoch 040 | Train Loss: 0.2565 Acc: 0.8893 | Val Loss: 0.2912 Acc: 0.8792                                            \n",
      "Epoch 041 | Train Loss: 0.2529 Acc: 0.8908 | Val Loss: 0.2727 Acc: 0.8895                                            \n",
      "Epoch 042 | Train Loss: 0.2380 Acc: 0.8985 | Val Loss: 0.3210 Acc: 0.8635                                            \n",
      "Epoch 043 | Train Loss: 0.2350 Acc: 0.9061 | Val Loss: 0.2817 Acc: 0.8865                                            \n",
      "Epoch 044 | Train Loss: 0.2294 Acc: 0.9076 | Val Loss: 0.2520 Acc: 0.8973                                            \n",
      "Epoch 045 | Train Loss: 0.2185 Acc: 0.9141 | Val Loss: 0.2649 Acc: 0.8901                                            \n",
      "Epoch 046 | Train Loss: 0.2101 Acc: 0.9157 | Val Loss: 0.2388 Acc: 0.9052                                            \n",
      "Epoch 047 | Train Loss: 0.2057 Acc: 0.9195 | Val Loss: 0.2636 Acc: 0.8961                                            \n",
      "Epoch 048 | Train Loss: 0.2005 Acc: 0.9201 | Val Loss: 0.3099 Acc: 0.8720                                            \n",
      "Epoch 049 | Train Loss: 0.1842 Acc: 0.9245 | Val Loss: 0.2428 Acc: 0.9130                                            \n",
      "Epoch 050 | Train Loss: 0.1890 Acc: 0.9233 | Val Loss: 0.2336 Acc: 0.9010                                            \n",
      "Epoch 051 | Train Loss: 0.1796 Acc: 0.9313 | Val Loss: 0.2156 Acc: 0.9179                                            \n",
      "Epoch 052 | Train Loss: 0.1770 Acc: 0.9301 | Val Loss: 0.2244 Acc: 0.9070                                            \n",
      "Epoch 053 | Train Loss: 0.1776 Acc: 0.9301 | Val Loss: 0.2119 Acc: 0.9064                                            \n",
      "Epoch 054 | Train Loss: 0.1598 Acc: 0.9392 | Val Loss: 0.2124 Acc: 0.9245                                            \n",
      "Epoch 055 | Train Loss: 0.1633 Acc: 0.9381 | Val Loss: 0.2270 Acc: 0.9191                                            \n",
      "Epoch 056 | Train Loss: 0.1580 Acc: 0.9376 | Val Loss: 0.1950 Acc: 0.9179                                            \n",
      "Epoch 057 | Train Loss: 0.1510 Acc: 0.9411 | Val Loss: 0.1943 Acc: 0.9227                                            \n",
      "Epoch 058 | Train Loss: 0.1516 Acc: 0.9422 | Val Loss: 0.2183 Acc: 0.9143                                            \n",
      "Epoch 059 | Train Loss: 0.1492 Acc: 0.9420 | Val Loss: 0.2012 Acc: 0.9203                                            \n",
      "Epoch 060 | Train Loss: 0.1438 Acc: 0.9437 | Val Loss: 0.1940 Acc: 0.9239                                            \n",
      "Trial params:                                                                                                        \n",
      "{'batch_size': 16, 'cnn_dense': 128, 'cnn_dropout': 0.09910944056987697, 'cnn_kernel_size_1': 5, 'cnn_kernels_1': 32, 'cnn_kernels_2': 64, 'learning_rate': 0.000933063591018396, 'lstm_dense': 256, 'lstm_hidden_size': 128, 'lstm_layers': 3, 'optimizer': 'adam'}\n",
      "Epoch 001 | Train Loss: 0.6813 Acc: 0.5771 | Val Loss: 0.6777 Acc: 0.5845                                            \n",
      "Epoch 002 | Train Loss: 0.6617 Acc: 0.6094 | Val Loss: 0.6201 Acc: 0.6636                                            \n",
      "Epoch 003 | Train Loss: 0.5926 Acc: 0.7027 | Val Loss: 0.5845 Acc: 0.7017                                            \n",
      "Epoch 004 | Train Loss: 0.5567 Acc: 0.7220 | Val Loss: 0.5619 Acc: 0.7204                                            \n",
      "Epoch 005 | Train Loss: 0.5355 Acc: 0.7334 | Val Loss: 0.5486 Acc: 0.7240                                            \n",
      "Epoch 006 | Train Loss: 0.5162 Acc: 0.7552 | Val Loss: 0.5381 Acc: 0.7428                                            \n",
      "Epoch 007 | Train Loss: 0.4938 Acc: 0.7673 | Val Loss: 0.5206 Acc: 0.7409                                            \n",
      "Epoch 008 | Train Loss: 0.4713 Acc: 0.7794 | Val Loss: 0.4794 Acc: 0.7579                                            \n",
      "Epoch 009 | Train Loss: 0.4365 Acc: 0.7981 | Val Loss: 0.4405 Acc: 0.7886                                            \n",
      "Epoch 010 | Train Loss: 0.4010 Acc: 0.8211 | Val Loss: 0.4185 Acc: 0.8007                                            \n",
      "Epoch 011 | Train Loss: 0.3698 Acc: 0.8416 | Val Loss: 0.4548 Acc: 0.7977                                            \n",
      "Epoch 012 | Train Loss: 0.3403 Acc: 0.8543 | Val Loss: 0.4140 Acc: 0.8140                                            \n",
      "Epoch 013 | Train Loss: 0.3143 Acc: 0.8688 | Val Loss: 0.3242 Acc: 0.8539                                            \n",
      "Epoch 014 | Train Loss: 0.2903 Acc: 0.8797 | Val Loss: 0.3098 Acc: 0.8726                                            \n",
      "Epoch 015 | Train Loss: 0.2695 Acc: 0.8877 | Val Loss: 0.3076 Acc: 0.8702                                            \n",
      "Epoch 016 | Train Loss: 0.2554 Acc: 0.8976 | Val Loss: 0.3154 Acc: 0.8611                                            \n",
      "Epoch 017 | Train Loss: 0.2369 Acc: 0.9080 | Val Loss: 0.2877 Acc: 0.8835                                            \n",
      "Epoch 018 | Train Loss: 0.2177 Acc: 0.9093 | Val Loss: 0.2732 Acc: 0.8859                                            \n",
      "Epoch 019 | Train Loss: 0.2058 Acc: 0.9186 | Val Loss: 0.2599 Acc: 0.9058                                            \n",
      "Epoch 020 | Train Loss: 0.1898 Acc: 0.9259 | Val Loss: 0.2558 Acc: 0.9010                                            \n",
      "Epoch 021 | Train Loss: 0.1755 Acc: 0.9284 | Val Loss: 0.2340 Acc: 0.9094                                            \n",
      "Epoch 022 | Train Loss: 0.1669 Acc: 0.9358 | Val Loss: 0.2758 Acc: 0.8949                                            \n",
      "Epoch 023 | Train Loss: 0.1521 Acc: 0.9411 | Val Loss: 0.2309 Acc: 0.9046                                            \n",
      "Epoch 024 | Train Loss: 0.1453 Acc: 0.9441 | Val Loss: 0.2058 Acc: 0.9245                                            \n",
      "Epoch 025 | Train Loss: 0.1320 Acc: 0.9484 | Val Loss: 0.2590 Acc: 0.9046                                            \n",
      "Epoch 026 | Train Loss: 0.1236 Acc: 0.9543 | Val Loss: 0.2489 Acc: 0.9106                                            \n",
      "Epoch 027 | Train Loss: 0.1144 Acc: 0.9556 | Val Loss: 0.2549 Acc: 0.9046                                            \n",
      "Epoch 028 | Train Loss: 0.1156 Acc: 0.9574 | Val Loss: 0.2357 Acc: 0.9149                                            \n",
      "Epoch 029 | Train Loss: 0.1078 Acc: 0.9612 | Val Loss: 0.2509 Acc: 0.9046                                            \n",
      "Epoch 030 | Train Loss: 0.0972 Acc: 0.9647 | Val Loss: 0.2144 Acc: 0.9167                                            \n",
      "Epoch 031 | Train Loss: 0.0979 Acc: 0.9636 | Val Loss: 0.2316 Acc: 0.9167                                            \n",
      "Epoch 032 | Train Loss: 0.0890 Acc: 0.9678 | Val Loss: 0.2533 Acc: 0.9106                                            \n",
      "Epoch 033 | Train Loss: 0.0901 Acc: 0.9659 | Val Loss: 0.2384 Acc: 0.9227                                            \n",
      "Epoch 034 | Train Loss: 0.0878 Acc: 0.9669 | Val Loss: 0.2523 Acc: 0.9076                                            \n",
      "Early stopping triggered.                                                                                            \n",
      "Trial params:                                                                                                        \n",
      "{'batch_size': 48, 'cnn_dense': 128, 'cnn_dropout': 0.2936917703260592, 'cnn_kernel_size_1': 5, 'cnn_kernels_1': 32, 'cnn_kernels_2': 32, 'learning_rate': 0.008211264266890695, 'lstm_dense': 32, 'lstm_hidden_size': 64, 'lstm_layers': 3, 'optimizer': 'rmsprop'}\n",
      "Epoch 001 | Train Loss: 0.7100 Acc: 0.5458 | Val Loss: 0.6863 Acc: 0.5586                                            \n",
      "Epoch 002 | Train Loss: 0.6877 Acc: 0.5579 | Val Loss: 0.6863 Acc: 0.5586                                            \n",
      "Epoch 003 | Train Loss: 0.6867 Acc: 0.5582 | Val Loss: 0.6873 Acc: 0.5586                                            \n",
      "Epoch 004 | Train Loss: 0.6868 Acc: 0.5582 | Val Loss: 0.6863 Acc: 0.5586                                            \n",
      "Epoch 005 | Train Loss: 0.6866 Acc: 0.5582 | Val Loss: 0.6867 Acc: 0.5586                                            \n",
      "Epoch 006 | Train Loss: 0.6868 Acc: 0.5582 | Val Loss: 0.6864 Acc: 0.5586                                            \n",
      "Epoch 007 | Train Loss: 0.6869 Acc: 0.5582 | Val Loss: 0.6863 Acc: 0.5586                                            \n",
      "Epoch 008 | Train Loss: 0.6867 Acc: 0.5582 | Val Loss: 0.6863 Acc: 0.5586                                            \n",
      "Epoch 009 | Train Loss: 0.6865 Acc: 0.5582 | Val Loss: 0.6871 Acc: 0.5586                                            \n",
      "Epoch 010 | Train Loss: 0.6867 Acc: 0.5582 | Val Loss: 0.6866 Acc: 0.5586                                            \n",
      "Epoch 011 | Train Loss: 0.6868 Acc: 0.5582 | Val Loss: 0.6863 Acc: 0.5586                                            \n",
      "Epoch 012 | Train Loss: 0.6868 Acc: 0.5582 | Val Loss: 0.6863 Acc: 0.5586                                            \n",
      "Epoch 013 | Train Loss: 0.6867 Acc: 0.5582 | Val Loss: 0.6863 Acc: 0.5586                                            \n",
      "Epoch 014 | Train Loss: 0.6866 Acc: 0.5582 | Val Loss: 0.6869 Acc: 0.5586                                            \n",
      "Epoch 015 | Train Loss: 0.6868 Acc: 0.5582 | Val Loss: 0.6864 Acc: 0.5586                                            \n",
      "Epoch 016 | Train Loss: 0.6865 Acc: 0.5582 | Val Loss: 0.6870 Acc: 0.5586                                            \n",
      "Epoch 017 | Train Loss: 0.6869 Acc: 0.5582 | Val Loss: 0.6864 Acc: 0.5586                                            \n",
      "Early stopping triggered.                                                                                            \n",
      "Trial params:                                                                                                        \n",
      "{'batch_size': 48, 'cnn_dense': 128, 'cnn_dropout': 0.3887360553315606, 'cnn_kernel_size_1': 3, 'cnn_kernels_1': 32, 'cnn_kernels_2': 96, 'learning_rate': 0.00010431152854793579, 'lstm_dense': 64, 'lstm_hidden_size': 128, 'lstm_layers': 3, 'optimizer': 'adam'}\n",
      "Epoch 001 | Train Loss: 0.6924 Acc: 0.5146 | Val Loss: 0.6845 Acc: 0.5725                                            \n",
      "Epoch 002 | Train Loss: 0.6812 Acc: 0.5819 | Val Loss: 0.6795 Acc: 0.5888                                            \n",
      "Epoch 003 | Train Loss: 0.6758 Acc: 0.5883 | Val Loss: 0.6734 Acc: 0.5845                                            \n",
      "Epoch 004 | Train Loss: 0.6684 Acc: 0.5994 | Val Loss: 0.6651 Acc: 0.5984                                            \n",
      "Epoch 005 | Train Loss: 0.6630 Acc: 0.6071 | Val Loss: 0.6556 Acc: 0.6099                                            \n",
      "Epoch 006 | Train Loss: 0.6507 Acc: 0.6269 | Val Loss: 0.6347 Acc: 0.6552                                            \n",
      "Epoch 007 | Train Loss: 0.6434 Acc: 0.6431 | Val Loss: 0.6347 Acc: 0.6419                                            \n",
      "Epoch 008 | Train Loss: 0.6325 Acc: 0.6574 | Val Loss: 0.6210 Acc: 0.6721                                            \n",
      "Epoch 009 | Train Loss: 0.6227 Acc: 0.6677 | Val Loss: 0.6208 Acc: 0.6703                                            \n",
      "Epoch 010 | Train Loss: 0.6156 Acc: 0.6798 | Val Loss: 0.6221 Acc: 0.6630                                            \n",
      "Epoch 011 | Train Loss: 0.6126 Acc: 0.6779 | Val Loss: 0.6062 Acc: 0.6854                                            \n",
      "Epoch 012 | Train Loss: 0.6144 Acc: 0.6775 | Val Loss: 0.6041 Acc: 0.6787                                            \n",
      "Epoch 013 | Train Loss: 0.6025 Acc: 0.6939 | Val Loss: 0.6215 Acc: 0.6576                                            \n",
      "Epoch 014 | Train Loss: 0.5990 Acc: 0.6915 | Val Loss: 0.5982 Acc: 0.6872                                            \n",
      "Epoch 015 | Train Loss: 0.5990 Acc: 0.6914 | Val Loss: 0.6299 Acc: 0.6624                                            \n",
      "Epoch 016 | Train Loss: 0.5932 Acc: 0.7026 | Val Loss: 0.5867 Acc: 0.7114                                            \n",
      "Epoch 017 | Train Loss: 0.5826 Acc: 0.7078 | Val Loss: 0.5825 Acc: 0.7089                                            \n",
      "Epoch 018 | Train Loss: 0.5802 Acc: 0.7143 | Val Loss: 0.5918 Acc: 0.7005                                            \n",
      "Epoch 019 | Train Loss: 0.5755 Acc: 0.7187 | Val Loss: 0.5784 Acc: 0.7029                                            \n",
      "Epoch 020 | Train Loss: 0.5711 Acc: 0.7196 | Val Loss: 0.5777 Acc: 0.7041                                            \n",
      "Epoch 021 | Train Loss: 0.5642 Acc: 0.7288 | Val Loss: 0.5665 Acc: 0.7216                                            \n",
      "Epoch 022 | Train Loss: 0.5565 Acc: 0.7296 | Val Loss: 0.5628 Acc: 0.7216                                            \n",
      "Epoch 023 | Train Loss: 0.5544 Acc: 0.7337 | Val Loss: 0.5931 Acc: 0.6902                                            \n",
      "Epoch 024 | Train Loss: 0.5570 Acc: 0.7284 | Val Loss: 0.5602 Acc: 0.7240                                            \n",
      "Epoch 025 | Train Loss: 0.5412 Acc: 0.7432 | Val Loss: 0.5530 Acc: 0.7252                                            \n",
      "Epoch 026 | Train Loss: 0.5422 Acc: 0.7421 | Val Loss: 0.5556 Acc: 0.7198                                            \n",
      "Epoch 027 | Train Loss: 0.5434 Acc: 0.7367 | Val Loss: 0.5481 Acc: 0.7313                                            \n",
      "Epoch 028 | Train Loss: 0.5367 Acc: 0.7441 | Val Loss: 0.5528 Acc: 0.7228                                            \n",
      "Epoch 029 | Train Loss: 0.5287 Acc: 0.7495 | Val Loss: 0.5458 Acc: 0.7246                                            \n",
      "Epoch 030 | Train Loss: 0.5265 Acc: 0.7494 | Val Loss: 0.5478 Acc: 0.7289                                            \n",
      "Epoch 031 | Train Loss: 0.5305 Acc: 0.7512 | Val Loss: 0.5423 Acc: 0.7289                                            \n",
      "Epoch 032 | Train Loss: 0.5226 Acc: 0.7521 | Val Loss: 0.5394 Acc: 0.7331                                            \n",
      "Epoch 033 | Train Loss: 0.5221 Acc: 0.7549 | Val Loss: 0.5365 Acc: 0.7355                                            \n",
      "Epoch 034 | Train Loss: 0.5275 Acc: 0.7488 | Val Loss: 0.5370 Acc: 0.7349                                            \n",
      "Epoch 035 | Train Loss: 0.5229 Acc: 0.7540 | Val Loss: 0.5381 Acc: 0.7361                                            \n",
      "Epoch 036 | Train Loss: 0.5175 Acc: 0.7601 | Val Loss: 0.5337 Acc: 0.7349                                            \n",
      "Epoch 037 | Train Loss: 0.5199 Acc: 0.7546 | Val Loss: 0.5390 Acc: 0.7343                                            \n",
      "Epoch 038 | Train Loss: 0.5093 Acc: 0.7584 | Val Loss: 0.5286 Acc: 0.7337                                            \n",
      "Epoch 039 | Train Loss: 0.5096 Acc: 0.7589 | Val Loss: 0.5276 Acc: 0.7403                                            \n",
      "Epoch 040 | Train Loss: 0.5085 Acc: 0.7631 | Val Loss: 0.5255 Acc: 0.7403                                            \n",
      "Epoch 041 | Train Loss: 0.5037 Acc: 0.7646 | Val Loss: 0.5288 Acc: 0.7421                                            \n",
      "Epoch 042 | Train Loss: 0.5038 Acc: 0.7676 | Val Loss: 0.5299 Acc: 0.7415                                            \n",
      "Epoch 043 | Train Loss: 0.4983 Acc: 0.7690 | Val Loss: 0.5243 Acc: 0.7470                                            \n",
      "Epoch 044 | Train Loss: 0.5038 Acc: 0.7719 | Val Loss: 0.5195 Acc: 0.7428                                            \n",
      "Epoch 045 | Train Loss: 0.5029 Acc: 0.7720 | Val Loss: 0.5256 Acc: 0.7434                                            \n",
      "Epoch 046 | Train Loss: 0.4931 Acc: 0.7759 | Val Loss: 0.5219 Acc: 0.7446                                            \n",
      "Epoch 047 | Train Loss: 0.4952 Acc: 0.7717 | Val Loss: 0.5203 Acc: 0.7476                                            \n",
      "Epoch 048 | Train Loss: 0.4881 Acc: 0.7726 | Val Loss: 0.5150 Acc: 0.7494                                            \n",
      "Epoch 049 | Train Loss: 0.4932 Acc: 0.7734 | Val Loss: 0.5295 Acc: 0.7397                                            \n",
      "Epoch 050 | Train Loss: 0.4901 Acc: 0.7770 | Val Loss: 0.5622 Acc: 0.7156                                            \n",
      "Epoch 051 | Train Loss: 0.4833 Acc: 0.7830 | Val Loss: 0.5075 Acc: 0.7536                                            \n",
      "Epoch 052 | Train Loss: 0.4869 Acc: 0.7749 | Val Loss: 0.5050 Acc: 0.7542                                            \n",
      "Epoch 053 | Train Loss: 0.4776 Acc: 0.7854 | Val Loss: 0.5091 Acc: 0.7560                                            \n",
      "Epoch 054 | Train Loss: 0.4819 Acc: 0.7788 | Val Loss: 0.5079 Acc: 0.7530                                            \n",
      "Epoch 055 | Train Loss: 0.4749 Acc: 0.7900 | Val Loss: 0.5008 Acc: 0.7591                                            \n",
      "Epoch 056 | Train Loss: 0.4733 Acc: 0.7856 | Val Loss: 0.5043 Acc: 0.7548                                            \n",
      "Epoch 057 | Train Loss: 0.4776 Acc: 0.7873 | Val Loss: 0.4953 Acc: 0.7675                                            \n",
      "Epoch 058 | Train Loss: 0.4704 Acc: 0.7870 | Val Loss: 0.4972 Acc: 0.7615                                            \n",
      "Epoch 059 | Train Loss: 0.4638 Acc: 0.7901 | Val Loss: 0.4984 Acc: 0.7603                                            \n",
      "Epoch 060 | Train Loss: 0.4625 Acc: 0.7968 | Val Loss: 0.4907 Acc: 0.7651                                            \n",
      "Trial params:                                                                                                        \n",
      "{'batch_size': 16, 'cnn_dense': 128, 'cnn_dropout': 0.12332611223938106, 'cnn_kernel_size_1': 5, 'cnn_kernels_1': 32, 'cnn_kernels_2': 64, 'learning_rate': 0.001630009543559559, 'lstm_dense': 128, 'lstm_hidden_size': 128, 'lstm_layers': 1, 'optimizer': 'rmsprop'}\n",
      "Epoch 001 | Train Loss: 0.6854 Acc: 0.5667 | Val Loss: 0.6495 Acc: 0.6353                                            \n",
      "Epoch 002 | Train Loss: 0.5993 Acc: 0.6926 | Val Loss: 0.5825 Acc: 0.6836                                            \n",
      "Epoch 003 | Train Loss: 0.5530 Acc: 0.7273 | Val Loss: 0.5512 Acc: 0.7198                                            \n",
      "Epoch 004 | Train Loss: 0.5128 Acc: 0.7525 | Val Loss: 0.4981 Acc: 0.7524                                            \n",
      "Epoch 005 | Train Loss: 0.4622 Acc: 0.7850 | Val Loss: 0.4510 Acc: 0.7893                                            \n",
      "Epoch 006 | Train Loss: 0.4105 Acc: 0.8072 | Val Loss: 0.4229 Acc: 0.7983                                            \n",
      "Epoch 007 | Train Loss: 0.3649 Acc: 0.8392 | Val Loss: 0.3505 Acc: 0.8448                                            \n",
      "Epoch 008 | Train Loss: 0.3221 Acc: 0.8637 | Val Loss: 0.3147 Acc: 0.8738                                            \n",
      "Epoch 009 | Train Loss: 0.2770 Acc: 0.8813 | Val Loss: 0.3044 Acc: 0.8768                                            \n",
      "Epoch 010 | Train Loss: 0.2551 Acc: 0.8926 | Val Loss: 0.2775 Acc: 0.8835                                            \n",
      "Epoch 011 | Train Loss: 0.2189 Acc: 0.9111 | Val Loss: 0.2481 Acc: 0.9040                                            \n",
      "Epoch 012 | Train Loss: 0.2120 Acc: 0.9139 | Val Loss: 0.2325 Acc: 0.9076                                            \n",
      "Epoch 013 | Train Loss: 0.1888 Acc: 0.9254 | Val Loss: 0.2294 Acc: 0.9088                                            \n",
      "Epoch 014 | Train Loss: 0.1661 Acc: 0.9349 | Val Loss: 0.2245 Acc: 0.9040                                            \n",
      "Epoch 015 | Train Loss: 0.1609 Acc: 0.9375 | Val Loss: 0.2241 Acc: 0.9076                                            \n",
      "Epoch 016 | Train Loss: 0.1449 Acc: 0.9428 | Val Loss: 0.2727 Acc: 0.8907                                            \n",
      "Epoch 017 | Train Loss: 0.1380 Acc: 0.9462 | Val Loss: 0.2787 Acc: 0.8998                                            \n",
      "Epoch 018 | Train Loss: 0.1257 Acc: 0.9541 | Val Loss: 0.2099 Acc: 0.9155                                            \n",
      "Epoch 019 | Train Loss: 0.1139 Acc: 0.9565 | Val Loss: 0.3257 Acc: 0.8804                                            \n",
      "Epoch 020 | Train Loss: 0.1085 Acc: 0.9577 | Val Loss: 0.2185 Acc: 0.9233                                            \n",
      "Epoch 021 | Train Loss: 0.0963 Acc: 0.9636 | Val Loss: 0.2138 Acc: 0.9293                                            \n",
      "Epoch 022 | Train Loss: 0.0934 Acc: 0.9644 | Val Loss: 0.2275 Acc: 0.9287                                            \n",
      "Epoch 023 | Train Loss: 0.0880 Acc: 0.9650 | Val Loss: 0.2094 Acc: 0.9348                                            \n",
      "Epoch 024 | Train Loss: 0.0891 Acc: 0.9632 | Val Loss: 0.1687 Acc: 0.9281                                            \n",
      "Epoch 025 | Train Loss: 0.0861 Acc: 0.9692 | Val Loss: 0.2515 Acc: 0.9088                                            \n",
      "Epoch 026 | Train Loss: 0.0735 Acc: 0.9761 | Val Loss: 0.2349 Acc: 0.9221                                            \n",
      "Epoch 027 | Train Loss: 0.0762 Acc: 0.9731 | Val Loss: 0.2421 Acc: 0.9203                                            \n",
      "Epoch 028 | Train Loss: 0.0759 Acc: 0.9712 | Val Loss: 0.2475 Acc: 0.9251                                            \n",
      "Epoch 029 | Train Loss: 0.0666 Acc: 0.9767 | Val Loss: 0.1839 Acc: 0.9396                                            \n",
      "Epoch 030 | Train Loss: 0.0693 Acc: 0.9749 | Val Loss: 0.2142 Acc: 0.9257                                            \n",
      "Epoch 031 | Train Loss: 0.0601 Acc: 0.9780 | Val Loss: 0.1783 Acc: 0.9396                                            \n",
      "Epoch 032 | Train Loss: 0.0581 Acc: 0.9770 | Val Loss: 0.2331 Acc: 0.9324                                            \n",
      "Epoch 033 | Train Loss: 0.0604 Acc: 0.9784 | Val Loss: 0.2316 Acc: 0.9239                                            \n",
      "Epoch 034 | Train Loss: 0.0617 Acc: 0.9769 | Val Loss: 0.2597 Acc: 0.9209                                            \n",
      "Early stopping triggered.                                                                                            \n",
      "Trial params:                                                                                                        \n",
      "{'batch_size': 16, 'cnn_dense': 128, 'cnn_dropout': 0.11059299985352161, 'cnn_kernel_size_1': 5, 'cnn_kernels_1': 64, 'cnn_kernels_2': 64, 'learning_rate': 0.004347049720435664, 'lstm_dense': 128, 'lstm_hidden_size': 128, 'lstm_layers': 1, 'optimizer': 'rmsprop'}\n",
      "Epoch 001 | Train Loss: 0.7145 Acc: 0.5482 | Val Loss: 0.6851 Acc: 0.5586                                            \n",
      "Epoch 002 | Train Loss: 0.6932 Acc: 0.5549 | Val Loss: 0.6871 Acc: 0.5586                                            \n",
      "Epoch 003 | Train Loss: 0.6921 Acc: 0.5508 | Val Loss: 0.6998 Acc: 0.4414                                            \n",
      "Epoch 004 | Train Loss: 0.6891 Acc: 0.5570 | Val Loss: 0.6866 Acc: 0.5586                                            \n",
      "Epoch 005 | Train Loss: 0.6875 Acc: 0.5578 | Val Loss: 0.6865 Acc: 0.5586                                            \n",
      "Epoch 006 | Train Loss: 0.6890 Acc: 0.5576 | Val Loss: 0.6866 Acc: 0.5586                                            \n",
      "Epoch 007 | Train Loss: 0.6944 Acc: 0.5476 | Val Loss: 0.6878 Acc: 0.5586                                            \n",
      "Epoch 008 | Train Loss: 0.6908 Acc: 0.5531 | Val Loss: 0.6881 Acc: 0.5586                                            \n",
      "Epoch 009 | Train Loss: 0.6983 Acc: 0.5498 | Val Loss: 0.6863 Acc: 0.5586                                            \n",
      "Epoch 010 | Train Loss: 0.6888 Acc: 0.5570 | Val Loss: 0.6861 Acc: 0.5586                                            \n",
      "Epoch 011 | Train Loss: 0.6977 Acc: 0.5502 | Val Loss: 0.6866 Acc: 0.5586                                            \n",
      "Early stopping triggered.                                                                                            \n",
      "Trial params:                                                                                                        \n",
      "{'batch_size': 48, 'cnn_dense': 256, 'cnn_dropout': 0.05700547970947559, 'cnn_kernel_size_1': 5, 'cnn_kernels_1': 64, 'cnn_kernels_2': 64, 'learning_rate': 0.009474222265137779, 'lstm_dense': 128, 'lstm_hidden_size': 64, 'lstm_layers': 1, 'optimizer': 'rmsprop'}\n",
      "Epoch 001 | Train Loss: 0.7730 Acc: 0.5425 | Val Loss: 0.6863 Acc: 0.5586                                            \n",
      "Epoch 002 | Train Loss: 0.6895 Acc: 0.5540 | Val Loss: 0.6901 Acc: 0.5586                                            \n",
      "Epoch 003 | Train Loss: 0.6887 Acc: 0.5529 | Val Loss: 0.6864 Acc: 0.5586                                            \n",
      "Epoch 004 | Train Loss: 0.6871 Acc: 0.5582 | Val Loss: 0.6863 Acc: 0.5586                                            \n",
      "Epoch 005 | Train Loss: 0.7039 Acc: 0.5410 | Val Loss: 0.6879 Acc: 0.5586                                            \n",
      "Epoch 006 | Train Loss: 0.6897 Acc: 0.5561 | Val Loss: 0.6865 Acc: 0.5586                                            \n",
      "Epoch 007 | Train Loss: 0.6934 Acc: 0.5508 | Val Loss: 0.6868 Acc: 0.5586                                            \n",
      "Epoch 008 | Train Loss: 0.6901 Acc: 0.5564 | Val Loss: 0.6874 Acc: 0.5586                                            \n",
      "Epoch 009 | Train Loss: 0.6983 Acc: 0.5496 | Val Loss: 0.6959 Acc: 0.5586                                            \n",
      "Epoch 010 | Train Loss: 0.6957 Acc: 0.5555 | Val Loss: 0.6872 Acc: 0.5586                                            \n",
      "Epoch 011 | Train Loss: 0.6882 Acc: 0.5584 | Val Loss: 0.6905 Acc: 0.5586                                            \n",
      "Epoch 012 | Train Loss: 0.6939 Acc: 0.5505 | Val Loss: 0.6864 Acc: 0.5586                                            \n",
      "Epoch 013 | Train Loss: 0.6966 Acc: 0.5488 | Val Loss: 0.6867 Acc: 0.5586                                            \n",
      "Epoch 014 | Train Loss: 0.6892 Acc: 0.5547 | Val Loss: 0.6864 Acc: 0.5586                                            \n",
      "Early stopping triggered.                                                                                            \n",
      "Trial params:                                                                                                        \n",
      "{'batch_size': 32, 'cnn_dense': 128, 'cnn_dropout': 0.4638385183857614, 'cnn_kernel_size_1': 3, 'cnn_kernels_1': 48, 'cnn_kernels_2': 64, 'learning_rate': 0.0017830677008644053, 'lstm_dense': 128, 'lstm_hidden_size': 128, 'lstm_layers': 1, 'optimizer': 'rmsprop'}\n",
      "Epoch 001 | Train Loss: 0.6877 Acc: 0.5692 | Val Loss: 0.6815 Acc: 0.5682                                            \n",
      "Epoch 002 | Train Loss: 0.6771 Acc: 0.5886 | Val Loss: 0.6649 Acc: 0.5966                                            \n",
      "Epoch 003 | Train Loss: 0.6309 Acc: 0.6567 | Val Loss: 0.6178 Acc: 0.6715                                            \n",
      "Epoch 004 | Train Loss: 0.5859 Acc: 0.7001 | Val Loss: 0.5666 Acc: 0.6981                                            \n",
      "Epoch 005 | Train Loss: 0.5656 Acc: 0.7128 | Val Loss: 0.5461 Acc: 0.7198                                            \n",
      "Epoch 006 | Train Loss: 0.5407 Acc: 0.7315 | Val Loss: 0.5376 Acc: 0.7307                                            \n",
      "Epoch 007 | Train Loss: 0.5224 Acc: 0.7436 | Val Loss: 0.5326 Acc: 0.7319                                            \n",
      "Epoch 008 | Train Loss: 0.4928 Acc: 0.7631 | Val Loss: 0.5211 Acc: 0.7458                                            \n",
      "Epoch 009 | Train Loss: 0.4796 Acc: 0.7717 | Val Loss: 0.4784 Acc: 0.7772                                            \n",
      "Epoch 010 | Train Loss: 0.4462 Acc: 0.7894 | Val Loss: 0.4242 Acc: 0.7959                                            \n",
      "Epoch 011 | Train Loss: 0.4258 Acc: 0.8036 | Val Loss: 0.4235 Acc: 0.8050                                            \n",
      "Epoch 012 | Train Loss: 0.4028 Acc: 0.8178 | Val Loss: 0.4100 Acc: 0.8122                                            \n",
      "Epoch 013 | Train Loss: 0.3836 Acc: 0.8303 | Val Loss: 0.4061 Acc: 0.8104                                            \n",
      "Epoch 014 | Train Loss: 0.3702 Acc: 0.8319 | Val Loss: 0.3578 Acc: 0.8303                                            \n",
      "Epoch 015 | Train Loss: 0.3565 Acc: 0.8445 | Val Loss: 0.3488 Acc: 0.8351                                            \n",
      "Epoch 016 | Train Loss: 0.3197 Acc: 0.8643 | Val Loss: 0.3243 Acc: 0.8563                                            \n",
      "Epoch 017 | Train Loss: 0.3144 Acc: 0.8658 | Val Loss: 0.2944 Acc: 0.8859                                            \n",
      "Epoch 018 | Train Loss: 0.2933 Acc: 0.8760 | Val Loss: 0.2999 Acc: 0.8720                                            \n",
      "Epoch 019 | Train Loss: 0.2715 Acc: 0.8810 | Val Loss: 0.2661 Acc: 0.8841                                            \n",
      "Epoch 020 | Train Loss: 0.2665 Acc: 0.8886 | Val Loss: 0.2563 Acc: 0.8986                                            \n",
      "Epoch 021 | Train Loss: 0.2523 Acc: 0.8957 | Val Loss: 0.2620 Acc: 0.8859                                            \n",
      "Epoch 022 | Train Loss: 0.2459 Acc: 0.9010 | Val Loss: 0.2529 Acc: 0.8967                                            \n",
      "Epoch 023 | Train Loss: 0.2326 Acc: 0.9041 | Val Loss: 0.3078 Acc: 0.8792                                            \n",
      "Epoch 024 | Train Loss: 0.2187 Acc: 0.9093 | Val Loss: 0.2579 Acc: 0.8877                                            \n",
      "Epoch 025 | Train Loss: 0.2168 Acc: 0.9165 | Val Loss: 0.2026 Acc: 0.9173                                            \n",
      "Epoch 026 | Train Loss: 0.1937 Acc: 0.9241 | Val Loss: 0.1887 Acc: 0.9227                                            \n",
      "Epoch 027 | Train Loss: 0.1988 Acc: 0.9203 | Val Loss: 0.2319 Acc: 0.9034                                            \n",
      "Epoch 028 | Train Loss: 0.1903 Acc: 0.9225 | Val Loss: 0.1929 Acc: 0.9257                                            \n",
      "Epoch 029 | Train Loss: 0.1779 Acc: 0.9305 | Val Loss: 0.2359 Acc: 0.9070                                            \n",
      "Epoch 030 | Train Loss: 0.1709 Acc: 0.9343 | Val Loss: 0.2023 Acc: 0.9245                                            \n",
      "Epoch 031 | Train Loss: 0.1660 Acc: 0.9336 | Val Loss: 0.1883 Acc: 0.9233                                            \n",
      "Epoch 032 | Train Loss: 0.1648 Acc: 0.9343 | Val Loss: 0.1767 Acc: 0.9384                                            \n",
      "Epoch 033 | Train Loss: 0.1593 Acc: 0.9364 | Val Loss: 0.1899 Acc: 0.9312                                            \n",
      "Epoch 034 | Train Loss: 0.1543 Acc: 0.9370 | Val Loss: 0.1674 Acc: 0.9324                                            \n",
      "Epoch 035 | Train Loss: 0.1435 Acc: 0.9446 | Val Loss: 0.1761 Acc: 0.9281                                            \n",
      "Epoch 036 | Train Loss: 0.1418 Acc: 0.9455 | Val Loss: 0.1648 Acc: 0.9402                                            \n",
      "Epoch 037 | Train Loss: 0.1402 Acc: 0.9438 | Val Loss: 0.1609 Acc: 0.9396                                            \n",
      "Epoch 038 | Train Loss: 0.1363 Acc: 0.9455 | Val Loss: 0.1776 Acc: 0.9293                                            \n",
      "Epoch 039 | Train Loss: 0.1293 Acc: 0.9505 | Val Loss: 0.1698 Acc: 0.9293                                            \n",
      "Epoch 040 | Train Loss: 0.1237 Acc: 0.9536 | Val Loss: 0.1841 Acc: 0.9293                                            \n",
      "Epoch 041 | Train Loss: 0.1279 Acc: 0.9479 | Val Loss: 0.1484 Acc: 0.9312                                            \n",
      "Epoch 042 | Train Loss: 0.1168 Acc: 0.9535 | Val Loss: 0.1581 Acc: 0.9396                                            \n",
      "Epoch 043 | Train Loss: 0.1084 Acc: 0.9574 | Val Loss: 0.1493 Acc: 0.9384                                            \n",
      "Epoch 044 | Train Loss: 0.1122 Acc: 0.9594 | Val Loss: 0.1546 Acc: 0.9372                                            \n",
      "Epoch 045 | Train Loss: 0.1170 Acc: 0.9579 | Val Loss: 0.1514 Acc: 0.9444                                            \n",
      "Epoch 046 | Train Loss: 0.1092 Acc: 0.9579 | Val Loss: 0.1977 Acc: 0.9281                                            \n",
      "Epoch 047 | Train Loss: 0.1134 Acc: 0.9574 | Val Loss: 0.1689 Acc: 0.9336                                            \n",
      "Epoch 048 | Train Loss: 0.1048 Acc: 0.9624 | Val Loss: 0.1388 Acc: 0.9499                                            \n",
      "Epoch 049 | Train Loss: 0.1013 Acc: 0.9610 | Val Loss: 0.1498 Acc: 0.9402                                            \n",
      "Epoch 050 | Train Loss: 0.0970 Acc: 0.9626 | Val Loss: 0.1556 Acc: 0.9444                                            \n",
      "Epoch 051 | Train Loss: 0.0986 Acc: 0.9632 | Val Loss: 0.1197 Acc: 0.9601                                            \n",
      "Epoch 052 | Train Loss: 0.0964 Acc: 0.9623 | Val Loss: 0.1393 Acc: 0.9523                                            \n",
      "Epoch 053 | Train Loss: 0.0973 Acc: 0.9618 | Val Loss: 0.1393 Acc: 0.9457                                            \n",
      "Epoch 054 | Train Loss: 0.1004 Acc: 0.9616 | Val Loss: 0.1345 Acc: 0.9529                                            \n",
      "Epoch 055 | Train Loss: 0.0968 Acc: 0.9642 | Val Loss: 0.1360 Acc: 0.9505                                            \n",
      "Epoch 056 | Train Loss: 0.0939 Acc: 0.9653 | Val Loss: 0.1228 Acc: 0.9571                                            \n",
      "Epoch 057 | Train Loss: 0.0784 Acc: 0.9724 | Val Loss: 0.1337 Acc: 0.9517                                            \n",
      "Epoch 058 | Train Loss: 0.0842 Acc: 0.9695 | Val Loss: 0.1431 Acc: 0.9505                                            \n",
      "Epoch 059 | Train Loss: 0.0891 Acc: 0.9669 | Val Loss: 0.1468 Acc: 0.9469                                            \n",
      "Epoch 060 | Train Loss: 0.0846 Acc: 0.9660 | Val Loss: 0.1414 Acc: 0.9481                                            \n",
      "Trial params:                                                                                                        \n",
      "{'batch_size': 32, 'cnn_dense': 256, 'cnn_dropout': 0.4794046021172476, 'cnn_kernel_size_1': 3, 'cnn_kernels_1': 48, 'cnn_kernels_2': 64, 'learning_rate': 0.0035407024272465708, 'lstm_dense': 128, 'lstm_hidden_size': 128, 'lstm_layers': 1, 'optimizer': 'rmsprop'}\n",
      "Epoch 001 | Train Loss: 0.7247 Acc: 0.5377 | Val Loss: 0.6867 Acc: 0.5586                                            \n",
      "Epoch 002 | Train Loss: 0.6896 Acc: 0.5526 | Val Loss: 0.6872 Acc: 0.5586                                            \n",
      "Epoch 003 | Train Loss: 0.6889 Acc: 0.5558 | Val Loss: 0.6979 Acc: 0.4414                                            \n",
      "Epoch 004 | Train Loss: 0.6887 Acc: 0.5544 | Val Loss: 0.6862 Acc: 0.5586                                            \n",
      "Epoch 005 | Train Loss: 0.6875 Acc: 0.5575 | Val Loss: 0.6852 Acc: 0.5586                                            \n",
      "Epoch 006 | Train Loss: 0.6816 Acc: 0.5700 | Val Loss: 0.6678 Acc: 0.5791                                            \n",
      "Epoch 007 | Train Loss: 0.6472 Acc: 0.6337 | Val Loss: 0.6175 Acc: 0.6763                                            \n",
      "Epoch 008 | Train Loss: 0.5982 Acc: 0.6878 | Val Loss: 0.5971 Acc: 0.6763                                            \n",
      "Epoch 009 | Train Loss: 0.5789 Acc: 0.7092 | Val Loss: 0.5806 Acc: 0.6938                                            \n",
      "Epoch 010 | Train Loss: 0.5636 Acc: 0.7201 | Val Loss: 0.5552 Acc: 0.7222                                            \n",
      "Epoch 011 | Train Loss: 0.5532 Acc: 0.7211 | Val Loss: 0.5745 Acc: 0.7138                                            \n",
      "Epoch 012 | Train Loss: 0.5328 Acc: 0.7382 | Val Loss: 0.5190 Acc: 0.7470                                            \n",
      "Epoch 013 | Train Loss: 0.5215 Acc: 0.7395 | Val Loss: 0.5162 Acc: 0.7367                                            \n",
      "Epoch 014 | Train Loss: 0.5093 Acc: 0.7516 | Val Loss: 0.5023 Acc: 0.7554                                            \n",
      "Epoch 015 | Train Loss: 0.4956 Acc: 0.7628 | Val Loss: 0.4968 Acc: 0.7566                                            \n",
      "Epoch 016 | Train Loss: 0.4709 Acc: 0.7779 | Val Loss: 0.4644 Acc: 0.7790                                            \n",
      "Epoch 017 | Train Loss: 0.4571 Acc: 0.7805 | Val Loss: 0.4559 Acc: 0.7826                                            \n",
      "Epoch 018 | Train Loss: 0.4386 Acc: 0.7977 | Val Loss: 0.4095 Acc: 0.8080                                            \n",
      "Epoch 019 | Train Loss: 0.4147 Acc: 0.8049 | Val Loss: 0.3995 Acc: 0.8164                                            \n",
      "Epoch 020 | Train Loss: 0.4028 Acc: 0.8165 | Val Loss: 0.3797 Acc: 0.8237                                            \n",
      "Epoch 021 | Train Loss: 0.3836 Acc: 0.8286 | Val Loss: 0.3754 Acc: 0.8376                                            \n",
      "Epoch 022 | Train Loss: 0.3658 Acc: 0.8384 | Val Loss: 0.3414 Acc: 0.8490                                            \n",
      "Epoch 023 | Train Loss: 0.3559 Acc: 0.8449 | Val Loss: 0.3418 Acc: 0.8521                                            \n",
      "Epoch 024 | Train Loss: 0.3372 Acc: 0.8528 | Val Loss: 0.3376 Acc: 0.8478                                            \n",
      "Epoch 025 | Train Loss: 0.3312 Acc: 0.8544 | Val Loss: 0.3157 Acc: 0.8617                                            \n",
      "Epoch 026 | Train Loss: 0.3185 Acc: 0.8631 | Val Loss: 0.3002 Acc: 0.8690                                            \n",
      "Epoch 027 | Train Loss: 0.2998 Acc: 0.8769 | Val Loss: 0.2901 Acc: 0.8780                                            \n",
      "Epoch 028 | Train Loss: 0.2916 Acc: 0.8798 | Val Loss: 0.2817 Acc: 0.8877                                            \n",
      "Epoch 029 | Train Loss: 0.2852 Acc: 0.8791 | Val Loss: 0.2835 Acc: 0.8738                                            \n",
      "Epoch 030 | Train Loss: 0.2670 Acc: 0.8954 | Val Loss: 0.2774 Acc: 0.8835                                            \n",
      "Epoch 031 | Train Loss: 0.2553 Acc: 0.8896 | Val Loss: 0.2591 Acc: 0.8913                                            \n",
      "Epoch 032 | Train Loss: 0.2487 Acc: 0.8985 | Val Loss: 0.2613 Acc: 0.8919                                            \n",
      "Epoch 033 | Train Loss: 0.2459 Acc: 0.9008 | Val Loss: 0.2813 Acc: 0.8937                                            \n",
      "Epoch 034 | Train Loss: 0.2350 Acc: 0.9071 | Val Loss: 0.2229 Acc: 0.9022                                            \n",
      "Epoch 035 | Train Loss: 0.2290 Acc: 0.9121 | Val Loss: 0.2049 Acc: 0.9167                                            \n",
      "Epoch 036 | Train Loss: 0.2219 Acc: 0.9076 | Val Loss: 0.2355 Acc: 0.9106                                            \n",
      "Epoch 037 | Train Loss: 0.2152 Acc: 0.9183 | Val Loss: 0.2327 Acc: 0.9028                                            \n",
      "Epoch 038 | Train Loss: 0.2006 Acc: 0.9209 | Val Loss: 0.2233 Acc: 0.9070                                            \n",
      "Epoch 039 | Train Loss: 0.1976 Acc: 0.9206 | Val Loss: 0.1969 Acc: 0.9203                                            \n",
      "Epoch 040 | Train Loss: 0.1984 Acc: 0.9209 | Val Loss: 0.1973 Acc: 0.9221                                            \n",
      "Epoch 041 | Train Loss: 0.1840 Acc: 0.9284 | Val Loss: 0.2050 Acc: 0.9136                                            \n",
      "Epoch 042 | Train Loss: 0.1850 Acc: 0.9263 | Val Loss: 0.1997 Acc: 0.9209                                            \n",
      "Epoch 043 | Train Loss: 0.1917 Acc: 0.9254 | Val Loss: 0.1909 Acc: 0.9233                                            \n",
      "Epoch 044 | Train Loss: 0.1782 Acc: 0.9318 | Val Loss: 0.3374 Acc: 0.8641                                            \n",
      "Epoch 045 | Train Loss: 0.1743 Acc: 0.9325 | Val Loss: 0.2269 Acc: 0.9016                                            \n",
      "Epoch 046 | Train Loss: 0.1666 Acc: 0.9354 | Val Loss: 0.2161 Acc: 0.9082                                            \n",
      "Epoch 047 | Train Loss: 0.1687 Acc: 0.9340 | Val Loss: 0.1935 Acc: 0.9251                                            \n",
      "Epoch 048 | Train Loss: 0.1715 Acc: 0.9346 | Val Loss: 0.2333 Acc: 0.9028                                            \n",
      "Epoch 049 | Train Loss: 0.1567 Acc: 0.9420 | Val Loss: 0.1900 Acc: 0.9215                                            \n",
      "Epoch 050 | Train Loss: 0.1565 Acc: 0.9419 | Val Loss: 0.1700 Acc: 0.9378                                            \n",
      "Epoch 051 | Train Loss: 0.1461 Acc: 0.9462 | Val Loss: 0.1862 Acc: 0.9257                                            \n",
      "Epoch 052 | Train Loss: 0.1499 Acc: 0.9440 | Val Loss: 0.1935 Acc: 0.9251                                            \n",
      "Epoch 053 | Train Loss: 0.1510 Acc: 0.9441 | Val Loss: 0.1751 Acc: 0.9414                                            \n",
      "Epoch 054 | Train Loss: 0.1494 Acc: 0.9419 | Val Loss: 0.1646 Acc: 0.9366                                            \n",
      "Epoch 055 | Train Loss: 0.1379 Acc: 0.9476 | Val Loss: 0.1758 Acc: 0.9330                                            \n",
      "Epoch 056 | Train Loss: 0.1415 Acc: 0.9494 | Val Loss: 0.2218 Acc: 0.9167                                            \n",
      "Epoch 057 | Train Loss: 0.1388 Acc: 0.9467 | Val Loss: 0.1942 Acc: 0.9191                                            \n",
      "Epoch 058 | Train Loss: 0.1337 Acc: 0.9473 | Val Loss: 0.1772 Acc: 0.9354                                            \n",
      "Epoch 059 | Train Loss: 0.1300 Acc: 0.9523 | Val Loss: 0.2473 Acc: 0.9136                                            \n",
      "Epoch 060 | Train Loss: 0.1326 Acc: 0.9511 | Val Loss: 0.1581 Acc: 0.9408                                            \n",
      "Trial params:                                                                                                        \n",
      "{'batch_size': 32, 'cnn_dense': 128, 'cnn_dropout': 0.40587173059486487, 'cnn_kernel_size_1': 3, 'cnn_kernels_1': 48, 'cnn_kernels_2': 64, 'learning_rate': 0.001203341201275633, 'lstm_dense': 128, 'lstm_hidden_size': 128, 'lstm_layers': 1, 'optimizer': 'rmsprop'}\n",
      "Epoch 001 | Train Loss: 0.6799 Acc: 0.5795 | Val Loss: 0.6638 Acc: 0.5966                                            \n",
      "Epoch 002 | Train Loss: 0.6457 Acc: 0.6269 | Val Loss: 0.6138 Acc: 0.6685                                            \n",
      "Epoch 003 | Train Loss: 0.6028 Acc: 0.6840 | Val Loss: 0.5808 Acc: 0.6914                                            \n",
      "Epoch 004 | Train Loss: 0.5764 Acc: 0.7080 | Val Loss: 0.5730 Acc: 0.7035                                            \n",
      "Epoch 005 | Train Loss: 0.5541 Acc: 0.7229 | Val Loss: 0.5651 Acc: 0.7120                                            \n",
      "Epoch 006 | Train Loss: 0.5373 Acc: 0.7364 | Val Loss: 0.5285 Acc: 0.7373                                            \n",
      "Epoch 007 | Train Loss: 0.5168 Acc: 0.7515 | Val Loss: 0.5037 Acc: 0.7428                                            \n",
      "Epoch 008 | Train Loss: 0.4915 Acc: 0.7619 | Val Loss: 0.4942 Acc: 0.7536                                            \n",
      "Epoch 009 | Train Loss: 0.4713 Acc: 0.7750 | Val Loss: 0.4706 Acc: 0.7699                                            \n",
      "Epoch 010 | Train Loss: 0.4394 Acc: 0.7937 | Val Loss: 0.4345 Acc: 0.7929                                            \n",
      "Epoch 011 | Train Loss: 0.4185 Acc: 0.8061 | Val Loss: 0.4117 Acc: 0.7989                                            \n",
      "Epoch 012 | Train Loss: 0.4005 Acc: 0.8217 | Val Loss: 0.3725 Acc: 0.8327                                            \n",
      "Epoch 013 | Train Loss: 0.3665 Acc: 0.8372 | Val Loss: 0.3675 Acc: 0.8321                                            \n",
      "Epoch 014 | Train Loss: 0.3457 Acc: 0.8467 | Val Loss: 0.3528 Acc: 0.8533                                            \n",
      "Epoch 015 | Train Loss: 0.3391 Acc: 0.8472 | Val Loss: 0.3308 Acc: 0.8575                                            \n",
      "Epoch 016 | Train Loss: 0.3073 Acc: 0.8649 | Val Loss: 0.3128 Acc: 0.8587                                            \n",
      "Epoch 017 | Train Loss: 0.2948 Acc: 0.8772 | Val Loss: 0.2995 Acc: 0.8780                                            \n",
      "Epoch 018 | Train Loss: 0.2860 Acc: 0.8768 | Val Loss: 0.3069 Acc: 0.8629                                            \n",
      "Epoch 019 | Train Loss: 0.2601 Acc: 0.8913 | Val Loss: 0.2693 Acc: 0.8895                                            \n",
      "Epoch 020 | Train Loss: 0.2547 Acc: 0.8949 | Val Loss: 0.2965 Acc: 0.8714                                            \n",
      "Epoch 021 | Train Loss: 0.2398 Acc: 0.9002 | Val Loss: 0.2552 Acc: 0.8919                                            \n",
      "Epoch 022 | Train Loss: 0.2354 Acc: 0.9013 | Val Loss: 0.2427 Acc: 0.9034                                            \n",
      "Epoch 023 | Train Loss: 0.2202 Acc: 0.9117 | Val Loss: 0.2399 Acc: 0.9040                                            \n",
      "Epoch 024 | Train Loss: 0.2096 Acc: 0.9154 | Val Loss: 0.2409 Acc: 0.9070                                            \n",
      "Epoch 025 | Train Loss: 0.2131 Acc: 0.9171 | Val Loss: 0.2492 Acc: 0.9070                                            \n",
      "Epoch 026 | Train Loss: 0.1912 Acc: 0.9227 | Val Loss: 0.2232 Acc: 0.9203                                            \n",
      "Epoch 027 | Train Loss: 0.1769 Acc: 0.9269 | Val Loss: 0.2347 Acc: 0.9040                                            \n",
      "Epoch 028 | Train Loss: 0.1682 Acc: 0.9360 | Val Loss: 0.2255 Acc: 0.9082                                            \n",
      "Epoch 029 | Train Loss: 0.1649 Acc: 0.9336 | Val Loss: 0.2977 Acc: 0.8810                                            \n",
      "Epoch 030 | Train Loss: 0.1636 Acc: 0.9319 | Val Loss: 0.2231 Acc: 0.9197                                            \n",
      "Epoch 031 | Train Loss: 0.1504 Acc: 0.9411 | Val Loss: 0.1948 Acc: 0.9269                                            \n",
      "Epoch 032 | Train Loss: 0.1476 Acc: 0.9387 | Val Loss: 0.2031 Acc: 0.9221                                            \n",
      "Epoch 033 | Train Loss: 0.1361 Acc: 0.9456 | Val Loss: 0.1886 Acc: 0.9233                                            \n",
      "Epoch 034 | Train Loss: 0.1344 Acc: 0.9455 | Val Loss: 0.1951 Acc: 0.9312                                            \n",
      "Epoch 035 | Train Loss: 0.1330 Acc: 0.9481 | Val Loss: 0.2312 Acc: 0.9221                                            \n",
      "Epoch 036 | Train Loss: 0.1237 Acc: 0.9521 | Val Loss: 0.1828 Acc: 0.9324                                            \n",
      "Epoch 037 | Train Loss: 0.1177 Acc: 0.9536 | Val Loss: 0.1779 Acc: 0.9360                                            \n",
      "Epoch 038 | Train Loss: 0.1144 Acc: 0.9547 | Val Loss: 0.1732 Acc: 0.9318                                            \n",
      "Epoch 039 | Train Loss: 0.1133 Acc: 0.9533 | Val Loss: 0.1723 Acc: 0.9348                                            \n",
      "Epoch 040 | Train Loss: 0.1129 Acc: 0.9555 | Val Loss: 0.1715 Acc: 0.9378                                            \n",
      "Epoch 041 | Train Loss: 0.1035 Acc: 0.9598 | Val Loss: 0.1666 Acc: 0.9396                                            \n",
      "Epoch 042 | Train Loss: 0.1058 Acc: 0.9577 | Val Loss: 0.1552 Acc: 0.9499                                            \n",
      "Epoch 043 | Train Loss: 0.0944 Acc: 0.9639 | Val Loss: 0.1573 Acc: 0.9402                                            \n",
      "Epoch 044 | Train Loss: 0.0936 Acc: 0.9669 | Val Loss: 0.1589 Acc: 0.9426                                            \n",
      "Epoch 045 | Train Loss: 0.0883 Acc: 0.9663 | Val Loss: 0.1637 Acc: 0.9438                                            \n",
      "Epoch 046 | Train Loss: 0.0880 Acc: 0.9669 | Val Loss: 0.1779 Acc: 0.9330                                            \n",
      "Epoch 047 | Train Loss: 0.0945 Acc: 0.9645 | Val Loss: 0.1732 Acc: 0.9342                                            \n",
      "Epoch 048 | Train Loss: 0.0872 Acc: 0.9642 | Val Loss: 0.1463 Acc: 0.9444                                            \n",
      "Epoch 049 | Train Loss: 0.0754 Acc: 0.9718 | Val Loss: 0.1697 Acc: 0.9414                                            \n",
      "Epoch 050 | Train Loss: 0.0862 Acc: 0.9690 | Val Loss: 0.1550 Acc: 0.9402                                            \n",
      "Epoch 051 | Train Loss: 0.0732 Acc: 0.9718 | Val Loss: 0.1765 Acc: 0.9469                                            \n",
      "Epoch 052 | Train Loss: 0.0818 Acc: 0.9680 | Val Loss: 0.1823 Acc: 0.9372                                            \n",
      "Epoch 053 | Train Loss: 0.0702 Acc: 0.9761 | Val Loss: 0.1577 Acc: 0.9469                                            \n",
      "Epoch 054 | Train Loss: 0.0793 Acc: 0.9684 | Val Loss: 0.1506 Acc: 0.9414                                            \n",
      "Epoch 055 | Train Loss: 0.0820 Acc: 0.9695 | Val Loss: 0.1612 Acc: 0.9420                                            \n",
      "Epoch 056 | Train Loss: 0.0643 Acc: 0.9761 | Val Loss: 0.1749 Acc: 0.9366                                            \n",
      "Epoch 057 | Train Loss: 0.0764 Acc: 0.9734 | Val Loss: 0.1841 Acc: 0.9420                                            \n",
      "Epoch 058 | Train Loss: 0.0741 Acc: 0.9739 | Val Loss: 0.1582 Acc: 0.9438                                            \n",
      "Early stopping triggered.                                                                                            \n",
      "Trial params:                                                                                                        \n",
      "{'batch_size': 32, 'cnn_dense': 128, 'cnn_dropout': 0.4096102631819671, 'cnn_kernel_size_1': 3, 'cnn_kernels_1': 48, 'cnn_kernels_2': 64, 'learning_rate': 0.006946565188395619, 'lstm_dense': 128, 'lstm_hidden_size': 96, 'lstm_layers': 1, 'optimizer': 'rmsprop'}\n",
      "Epoch 001 | Train Loss: 0.7696 Acc: 0.5292 | Val Loss: 0.6863 Acc: 0.5586                                            \n",
      "Epoch 002 | Train Loss: 0.6919 Acc: 0.5549 | Val Loss: 0.7046 Acc: 0.4414                                            \n",
      "Epoch 003 | Train Loss: 0.6922 Acc: 0.5499 | Val Loss: 0.6836 Acc: 0.5586                                            \n",
      "Epoch 004 | Train Loss: 0.6911 Acc: 0.5516 | Val Loss: 0.6851 Acc: 0.5586                                            \n",
      "Epoch 005 | Train Loss: 0.6881 Acc: 0.5546 | Val Loss: 0.6799 Acc: 0.5870                                            \n",
      "Epoch 006 | Train Loss: 0.6926 Acc: 0.5552 | Val Loss: 0.6885 Acc: 0.5586                                            \n",
      "Epoch 007 | Train Loss: 0.6886 Acc: 0.5537 | Val Loss: 0.6798 Acc: 0.5586                                            \n",
      "Epoch 008 | Train Loss: 0.6906 Acc: 0.5535 | Val Loss: 0.6826 Acc: 0.5586                                            \n",
      "Epoch 009 | Train Loss: 0.6809 Acc: 0.5836 | Val Loss: 0.6706 Acc: 0.5912                                            \n",
      "Epoch 010 | Train Loss: 0.6369 Acc: 0.6482 | Val Loss: 0.6190 Acc: 0.6643                                            \n",
      "Epoch 011 | Train Loss: 0.6092 Acc: 0.6804 | Val Loss: 0.5857 Acc: 0.6854                                            \n",
      "Epoch 012 | Train Loss: 0.5831 Acc: 0.7053 | Val Loss: 0.5713 Acc: 0.7017                                            \n",
      "Epoch 013 | Train Loss: 0.5704 Acc: 0.7199 | Val Loss: 0.5602 Acc: 0.7258                                            \n",
      "Epoch 014 | Train Loss: 0.5586 Acc: 0.7231 | Val Loss: 0.5596 Acc: 0.7162                                            \n",
      "Epoch 015 | Train Loss: 0.5494 Acc: 0.7272 | Val Loss: 0.5323 Acc: 0.7337                                            \n",
      "Epoch 016 | Train Loss: 0.5323 Acc: 0.7433 | Val Loss: 0.5160 Acc: 0.7428                                            \n",
      "Epoch 017 | Train Loss: 0.5201 Acc: 0.7423 | Val Loss: 0.5129 Acc: 0.7452                                            \n",
      "Epoch 018 | Train Loss: 0.5092 Acc: 0.7542 | Val Loss: 0.5319 Acc: 0.7144                                            \n",
      "Epoch 019 | Train Loss: 0.4958 Acc: 0.7607 | Val Loss: 0.5552 Acc: 0.7083                                            \n",
      "Epoch 020 | Train Loss: 0.4797 Acc: 0.7747 | Val Loss: 0.4534 Acc: 0.7868                                            \n",
      "Epoch 021 | Train Loss: 0.4598 Acc: 0.7821 | Val Loss: 0.4348 Acc: 0.7995                                            \n",
      "Epoch 022 | Train Loss: 0.4532 Acc: 0.7874 | Val Loss: 0.4228 Acc: 0.8098                                            \n",
      "Epoch 023 | Train Loss: 0.4368 Acc: 0.8028 | Val Loss: 0.4164 Acc: 0.8092                                            \n",
      "Epoch 024 | Train Loss: 0.4293 Acc: 0.8087 | Val Loss: 0.4061 Acc: 0.8134                                            \n",
      "Epoch 025 | Train Loss: 0.4107 Acc: 0.8134 | Val Loss: 0.3954 Acc: 0.8213                                            \n",
      "Epoch 026 | Train Loss: 0.3952 Acc: 0.8250 | Val Loss: 0.4874 Acc: 0.7597                                            \n",
      "Epoch 027 | Train Loss: 0.3856 Acc: 0.8271 | Val Loss: 0.3667 Acc: 0.8351                                            \n",
      "Epoch 028 | Train Loss: 0.3658 Acc: 0.8410 | Val Loss: 0.3821 Acc: 0.8382                                            \n",
      "Epoch 029 | Train Loss: 0.3592 Acc: 0.8477 | Val Loss: 0.3323 Acc: 0.8502                                            \n",
      "Epoch 030 | Train Loss: 0.3565 Acc: 0.8510 | Val Loss: 0.3269 Acc: 0.8527                                            \n",
      "Epoch 031 | Train Loss: 0.3396 Acc: 0.8560 | Val Loss: 0.3107 Acc: 0.8738                                            \n",
      "Epoch 032 | Train Loss: 0.3315 Acc: 0.8611 | Val Loss: 0.2909 Acc: 0.8780                                            \n",
      "Epoch 033 | Train Loss: 0.3257 Acc: 0.8640 | Val Loss: 0.3304 Acc: 0.8599                                            \n",
      "Epoch 034 | Train Loss: 0.3219 Acc: 0.8599 | Val Loss: 0.5004 Acc: 0.7802                                            \n",
      "Epoch 035 | Train Loss: 0.3095 Acc: 0.8665 | Val Loss: 0.2836 Acc: 0.8931                                            \n",
      "Epoch 036 | Train Loss: 0.3029 Acc: 0.8756 | Val Loss: 0.2933 Acc: 0.8810                                            \n",
      "Epoch 037 | Train Loss: 0.2945 Acc: 0.8783 | Val Loss: 0.2864 Acc: 0.8714                                            \n",
      "Epoch 038 | Train Loss: 0.2886 Acc: 0.8857 | Val Loss: 0.3087 Acc: 0.8635                                            \n",
      "Epoch 039 | Train Loss: 0.2801 Acc: 0.8892 | Val Loss: 0.2948 Acc: 0.8822                                            \n",
      "Epoch 040 | Train Loss: 0.2698 Acc: 0.8928 | Val Loss: 0.2879 Acc: 0.8829                                            \n",
      "Epoch 041 | Train Loss: 0.2665 Acc: 0.8949 | Val Loss: 0.3308 Acc: 0.8708                                            \n",
      "Epoch 042 | Train Loss: 0.2713 Acc: 0.8908 | Val Loss: 0.2530 Acc: 0.8973                                            \n",
      "Epoch 043 | Train Loss: 0.2504 Acc: 0.9019 | Val Loss: 0.2557 Acc: 0.9004                                            \n",
      "Epoch 044 | Train Loss: 0.2567 Acc: 0.8955 | Val Loss: 0.2593 Acc: 0.8925                                            \n",
      "Epoch 045 | Train Loss: 0.2574 Acc: 0.8933 | Val Loss: 0.2436 Acc: 0.9022                                            \n",
      "Epoch 046 | Train Loss: 0.2532 Acc: 0.9002 | Val Loss: 0.2430 Acc: 0.8986                                            \n",
      "Epoch 047 | Train Loss: 0.2467 Acc: 0.9014 | Val Loss: 0.2617 Acc: 0.9016                                            \n",
      "Epoch 048 | Train Loss: 0.2395 Acc: 0.9068 | Val Loss: 0.2570 Acc: 0.8979                                            \n",
      "Epoch 049 | Train Loss: 0.2402 Acc: 0.9059 | Val Loss: 0.2638 Acc: 0.8992                                            \n",
      "Epoch 050 | Train Loss: 0.2400 Acc: 0.9059 | Val Loss: 0.2228 Acc: 0.9064                                            \n",
      "Epoch 051 | Train Loss: 0.2388 Acc: 0.9080 | Val Loss: 0.2228 Acc: 0.9112                                            \n",
      "Epoch 052 | Train Loss: 0.2322 Acc: 0.9087 | Val Loss: 0.2188 Acc: 0.9227                                            \n",
      "Epoch 053 | Train Loss: 0.2239 Acc: 0.9135 | Val Loss: 0.2178 Acc: 0.9118                                            \n",
      "Epoch 054 | Train Loss: 0.2103 Acc: 0.9157 | Val Loss: 0.2157 Acc: 0.9136                                            \n",
      "Epoch 055 | Train Loss: 0.2158 Acc: 0.9161 | Val Loss: 0.2385 Acc: 0.9203                                            \n",
      "Epoch 056 | Train Loss: 0.2121 Acc: 0.9168 | Val Loss: 0.2203 Acc: 0.9215                                            \n",
      "Epoch 057 | Train Loss: 0.2170 Acc: 0.9151 | Val Loss: 0.2203 Acc: 0.9149                                            \n",
      "Epoch 058 | Train Loss: 0.2133 Acc: 0.9180 | Val Loss: 0.2394 Acc: 0.9058                                            \n",
      "Epoch 059 | Train Loss: 0.2061 Acc: 0.9219 | Val Loss: 0.2641 Acc: 0.8967                                            \n",
      "Epoch 060 | Train Loss: 0.2121 Acc: 0.9195 | Val Loss: 0.2756 Acc: 0.8810                                            \n",
      "Trial params:                                                                                                        \n",
      "{'batch_size': 32, 'cnn_dense': 32, 'cnn_dropout': 0.4819419484932425, 'cnn_kernel_size_1': 3, 'cnn_kernels_1': 48, 'cnn_kernels_2': 16, 'learning_rate': 0.0007805720277612393, 'lstm_dense': 256, 'lstm_hidden_size': 64, 'lstm_layers': 1, 'optimizer': 'rmsprop'}\n",
      "Epoch 001 | Train Loss: 0.6779 Acc: 0.5815 | Val Loss: 0.6770 Acc: 0.5870                                            \n",
      "Epoch 002 | Train Loss: 0.6666 Acc: 0.5952 | Val Loss: 0.6597 Acc: 0.6081                                            \n",
      "Epoch 003 | Train Loss: 0.6322 Acc: 0.6499 | Val Loss: 0.6213 Acc: 0.6655                                            \n",
      "Epoch 004 | Train Loss: 0.6026 Acc: 0.6875 | Val Loss: 0.6014 Acc: 0.6745                                            \n",
      "Epoch 005 | Train Loss: 0.5764 Acc: 0.7027 | Val Loss: 0.5748 Acc: 0.7029                                            \n",
      "Epoch 006 | Train Loss: 0.5636 Acc: 0.7180 | Val Loss: 0.5629 Acc: 0.7138                                            \n",
      "Epoch 007 | Train Loss: 0.5571 Acc: 0.7184 | Val Loss: 0.5572 Acc: 0.7132                                            \n",
      "Epoch 008 | Train Loss: 0.5467 Acc: 0.7255 | Val Loss: 0.5481 Acc: 0.7210                                            \n",
      "Epoch 009 | Train Loss: 0.5337 Acc: 0.7382 | Val Loss: 0.5514 Acc: 0.7240                                            \n",
      "Epoch 010 | Train Loss: 0.5311 Acc: 0.7392 | Val Loss: 0.5281 Acc: 0.7397                                            \n",
      "Epoch 011 | Train Loss: 0.5210 Acc: 0.7459 | Val Loss: 0.5300 Acc: 0.7319                                            \n",
      "Epoch 012 | Train Loss: 0.5208 Acc: 0.7435 | Val Loss: 0.5210 Acc: 0.7355                                            \n",
      "Epoch 013 | Train Loss: 0.5158 Acc: 0.7485 | Val Loss: 0.5155 Acc: 0.7421                                            \n",
      "Epoch 014 | Train Loss: 0.5051 Acc: 0.7571 | Val Loss: 0.5149 Acc: 0.7373                                            \n",
      "Epoch 015 | Train Loss: 0.4997 Acc: 0.7587 | Val Loss: 0.5126 Acc: 0.7464                                            \n",
      "Epoch 016 | Train Loss: 0.4935 Acc: 0.7617 | Val Loss: 0.4956 Acc: 0.7572                                            \n",
      "Epoch 017 | Train Loss: 0.4868 Acc: 0.7711 | Val Loss: 0.4945 Acc: 0.7500                                            \n",
      "Epoch 018 | Train Loss: 0.4806 Acc: 0.7629 | Val Loss: 0.4798 Acc: 0.7717                                            \n",
      "Epoch 019 | Train Loss: 0.4730 Acc: 0.7716 | Val Loss: 0.4836 Acc: 0.7657                                            \n",
      "Epoch 020 | Train Loss: 0.4632 Acc: 0.7814 | Val Loss: 0.4893 Acc: 0.7597                                            \n",
      "Epoch 021 | Train Loss: 0.4617 Acc: 0.7824 | Val Loss: 0.4663 Acc: 0.7699                                            \n",
      "Epoch 022 | Train Loss: 0.4476 Acc: 0.7904 | Val Loss: 0.4473 Acc: 0.7880                                            \n",
      "Epoch 023 | Train Loss: 0.4357 Acc: 0.7987 | Val Loss: 0.4841 Acc: 0.7736                                            \n",
      "Epoch 024 | Train Loss: 0.4411 Acc: 0.7919 | Val Loss: 0.4521 Acc: 0.7796                                            \n",
      "Epoch 025 | Train Loss: 0.4275 Acc: 0.8007 | Val Loss: 0.4338 Acc: 0.7893                                            \n",
      "Epoch 026 | Train Loss: 0.4145 Acc: 0.8076 | Val Loss: 0.4240 Acc: 0.7935                                            \n",
      "Epoch 027 | Train Loss: 0.4108 Acc: 0.8158 | Val Loss: 0.4030 Acc: 0.8092                                            \n",
      "Epoch 028 | Train Loss: 0.3930 Acc: 0.8211 | Val Loss: 0.4060 Acc: 0.8056                                            \n",
      "Epoch 029 | Train Loss: 0.3949 Acc: 0.8170 | Val Loss: 0.3806 Acc: 0.8333                                            \n",
      "Epoch 030 | Train Loss: 0.3821 Acc: 0.8289 | Val Loss: 0.3804 Acc: 0.8249                                            \n",
      "Epoch 031 | Train Loss: 0.3824 Acc: 0.8252 | Val Loss: 0.4108 Acc: 0.8104                                            \n",
      "Epoch 032 | Train Loss: 0.3747 Acc: 0.8267 | Val Loss: 0.3806 Acc: 0.8213                                            \n",
      "Epoch 033 | Train Loss: 0.3565 Acc: 0.8449 | Val Loss: 0.4275 Acc: 0.8007                                            \n",
      "Epoch 034 | Train Loss: 0.3555 Acc: 0.8362 | Val Loss: 0.3434 Acc: 0.8400                                            \n",
      "Epoch 035 | Train Loss: 0.3565 Acc: 0.8386 | Val Loss: 0.3523 Acc: 0.8424                                            \n",
      "Epoch 036 | Train Loss: 0.3497 Acc: 0.8390 | Val Loss: 0.3437 Acc: 0.8442                                            \n",
      "Epoch 037 | Train Loss: 0.3339 Acc: 0.8525 | Val Loss: 0.3438 Acc: 0.8424                                            \n",
      "Epoch 038 | Train Loss: 0.3381 Acc: 0.8496 | Val Loss: 0.3406 Acc: 0.8508                                            \n",
      "Epoch 039 | Train Loss: 0.3276 Acc: 0.8514 | Val Loss: 0.3330 Acc: 0.8545                                            \n",
      "Epoch 040 | Train Loss: 0.3268 Acc: 0.8581 | Val Loss: 0.3504 Acc: 0.8454                                            \n",
      "Epoch 041 | Train Loss: 0.3171 Acc: 0.8635 | Val Loss: 0.3090 Acc: 0.8696                                            \n",
      "Epoch 042 | Train Loss: 0.3212 Acc: 0.8612 | Val Loss: 0.3178 Acc: 0.8569                                            \n",
      "Epoch 043 | Train Loss: 0.3130 Acc: 0.8638 | Val Loss: 0.3105 Acc: 0.8671                                            \n",
      "Epoch 044 | Train Loss: 0.3051 Acc: 0.8717 | Val Loss: 0.3075 Acc: 0.8696                                            \n",
      "Epoch 045 | Train Loss: 0.2984 Acc: 0.8729 | Val Loss: 0.3065 Acc: 0.8702                                            \n",
      "Epoch 046 | Train Loss: 0.2941 Acc: 0.8750 | Val Loss: 0.3278 Acc: 0.8617                                            \n",
      "Epoch 047 | Train Loss: 0.2917 Acc: 0.8750 | Val Loss: 0.3229 Acc: 0.8629                                            \n",
      "Epoch 048 | Train Loss: 0.2898 Acc: 0.8757 | Val Loss: 0.2942 Acc: 0.8678                                            \n",
      "Epoch 049 | Train Loss: 0.2810 Acc: 0.8816 | Val Loss: 0.2925 Acc: 0.8792                                            \n",
      "Epoch 050 | Train Loss: 0.2848 Acc: 0.8786 | Val Loss: 0.2741 Acc: 0.8913                                            \n",
      "Epoch 051 | Train Loss: 0.2841 Acc: 0.8775 | Val Loss: 0.2870 Acc: 0.8762                                            \n",
      "Epoch 052 | Train Loss: 0.2693 Acc: 0.8863 | Val Loss: 0.2622 Acc: 0.8937                                            \n",
      "Epoch 053 | Train Loss: 0.2660 Acc: 0.8868 | Val Loss: 0.2955 Acc: 0.8708                                            \n",
      "Epoch 054 | Train Loss: 0.2647 Acc: 0.8878 | Val Loss: 0.2637 Acc: 0.8877                                            \n",
      "Epoch 055 | Train Loss: 0.2611 Acc: 0.8910 | Val Loss: 0.2667 Acc: 0.8877                                            \n",
      "Epoch 056 | Train Loss: 0.2631 Acc: 0.8919 | Val Loss: 0.2417 Acc: 0.8986                                            \n",
      "Epoch 057 | Train Loss: 0.2534 Acc: 0.8923 | Val Loss: 0.2701 Acc: 0.8865                                            \n",
      "Epoch 058 | Train Loss: 0.2504 Acc: 0.8972 | Val Loss: 0.2566 Acc: 0.8877                                            \n",
      "Epoch 059 | Train Loss: 0.2535 Acc: 0.8898 | Val Loss: 0.2463 Acc: 0.8961                                            \n",
      "Epoch 060 | Train Loss: 0.2410 Acc: 0.8982 | Val Loss: 0.2618 Acc: 0.8859                                            \n",
      "Trial params:                                                                                                        \n",
      "{'batch_size': 32, 'cnn_dense': 128, 'cnn_dropout': 0.5948403046428545, 'cnn_kernel_size_1': 3, 'cnn_kernels_1': 48, 'cnn_kernels_2': 64, 'learning_rate': 0.0019485110007438345, 'lstm_dense': 128, 'lstm_hidden_size': 128, 'lstm_layers': 1, 'optimizer': 'sgd'}\n",
      "Epoch 001 | Train Loss: 0.6876 Acc: 0.5531 | Val Loss: 0.6861 Acc: 0.5586                                            \n",
      "Epoch 002 | Train Loss: 0.6862 Acc: 0.5588 | Val Loss: 0.6855 Acc: 0.5586                                            \n",
      "Epoch 003 | Train Loss: 0.6856 Acc: 0.5588 | Val Loss: 0.6849 Acc: 0.5598                                            \n",
      "Epoch 004 | Train Loss: 0.6847 Acc: 0.5615 | Val Loss: 0.6840 Acc: 0.5634                                            \n",
      "Epoch 005 | Train Loss: 0.6837 Acc: 0.5639 | Val Loss: 0.6829 Acc: 0.5664                                            \n",
      "Epoch 006 | Train Loss: 0.6821 Acc: 0.5704 | Val Loss: 0.6815 Acc: 0.5713                                            \n",
      "Epoch 007 | Train Loss: 0.6800 Acc: 0.5757 | Val Loss: 0.6799 Acc: 0.5779                                            \n",
      "Epoch 008 | Train Loss: 0.6784 Acc: 0.5792 | Val Loss: 0.6790 Acc: 0.5876                                            \n",
      "Epoch 009 | Train Loss: 0.6770 Acc: 0.5842 | Val Loss: 0.6798 Acc: 0.5821                                            \n",
      "Epoch 010 | Train Loss: 0.6775 Acc: 0.5892 | Val Loss: 0.6783 Acc: 0.5894                                            \n",
      "Epoch 011 | Train Loss: 0.6769 Acc: 0.5834 | Val Loss: 0.6782 Acc: 0.5870                                            \n",
      "Epoch 012 | Train Loss: 0.6760 Acc: 0.5852 | Val Loss: 0.6780 Acc: 0.5876                                            \n",
      "Epoch 013 | Train Loss: 0.6763 Acc: 0.5858 | Val Loss: 0.6779 Acc: 0.5876                                            \n",
      "Epoch 014 | Train Loss: 0.6760 Acc: 0.5854 | Val Loss: 0.6778 Acc: 0.5876                                            \n",
      "Epoch 015 | Train Loss: 0.6759 Acc: 0.5872 | Val Loss: 0.6778 Acc: 0.5851                                            \n",
      "Epoch 016 | Train Loss: 0.6759 Acc: 0.5858 | Val Loss: 0.6777 Acc: 0.5870                                            \n",
      "Epoch 017 | Train Loss: 0.6762 Acc: 0.5843 | Val Loss: 0.6776 Acc: 0.5876                                            \n",
      "Epoch 018 | Train Loss: 0.6760 Acc: 0.5861 | Val Loss: 0.6775 Acc: 0.5870                                            \n",
      "Epoch 019 | Train Loss: 0.6756 Acc: 0.5911 | Val Loss: 0.6775 Acc: 0.5888                                            \n",
      "Epoch 020 | Train Loss: 0.6740 Acc: 0.5884 | Val Loss: 0.6774 Acc: 0.5882                                            \n",
      "Epoch 021 | Train Loss: 0.6750 Acc: 0.5904 | Val Loss: 0.6773 Acc: 0.5857                                            \n",
      "Epoch 022 | Train Loss: 0.6753 Acc: 0.5898 | Val Loss: 0.6773 Acc: 0.5882                                            \n",
      "Epoch 023 | Train Loss: 0.6754 Acc: 0.5886 | Val Loss: 0.6770 Acc: 0.5894                                            \n",
      "Epoch 024 | Train Loss: 0.6746 Acc: 0.5878 | Val Loss: 0.6770 Acc: 0.5888                                            \n",
      "Epoch 025 | Train Loss: 0.6745 Acc: 0.5895 | Val Loss: 0.6770 Acc: 0.5882                                            \n",
      "Epoch 026 | Train Loss: 0.6749 Acc: 0.5876 | Val Loss: 0.6768 Acc: 0.5876                                            \n",
      "Epoch 027 | Train Loss: 0.6739 Acc: 0.5892 | Val Loss: 0.6768 Acc: 0.5888                                            \n",
      "Epoch 028 | Train Loss: 0.6742 Acc: 0.5898 | Val Loss: 0.6766 Acc: 0.5894                                            \n",
      "Epoch 029 | Train Loss: 0.6741 Acc: 0.5896 | Val Loss: 0.6764 Acc: 0.5894                                            \n",
      "Epoch 030 | Train Loss: 0.6742 Acc: 0.5886 | Val Loss: 0.6765 Acc: 0.5882                                            \n",
      "Epoch 031 | Train Loss: 0.6733 Acc: 0.5913 | Val Loss: 0.6764 Acc: 0.5900                                            \n",
      "Epoch 032 | Train Loss: 0.6731 Acc: 0.5901 | Val Loss: 0.6765 Acc: 0.5900                                            \n",
      "Epoch 033 | Train Loss: 0.6739 Acc: 0.5899 | Val Loss: 0.6762 Acc: 0.5900                                            \n",
      "Epoch 034 | Train Loss: 0.6727 Acc: 0.5917 | Val Loss: 0.6761 Acc: 0.5900                                            \n",
      "Epoch 035 | Train Loss: 0.6730 Acc: 0.5925 | Val Loss: 0.6760 Acc: 0.5900                                            \n",
      "Epoch 036 | Train Loss: 0.6735 Acc: 0.5895 | Val Loss: 0.6758 Acc: 0.5876                                            \n",
      "Epoch 037 | Train Loss: 0.6726 Acc: 0.5923 | Val Loss: 0.6754 Acc: 0.5894                                            \n",
      "Epoch 038 | Train Loss: 0.6726 Acc: 0.5907 | Val Loss: 0.6753 Acc: 0.5918                                            \n",
      "Epoch 039 | Train Loss: 0.6717 Acc: 0.5926 | Val Loss: 0.6750 Acc: 0.5882                                            \n",
      "Epoch 040 | Train Loss: 0.6728 Acc: 0.5934 | Val Loss: 0.6747 Acc: 0.5912                                            \n",
      "Epoch 041 | Train Loss: 0.6709 Acc: 0.5938 | Val Loss: 0.6745 Acc: 0.5930                                            \n",
      "Epoch 042 | Train Loss: 0.6719 Acc: 0.5889 | Val Loss: 0.6740 Acc: 0.5912                                            \n",
      "Epoch 043 | Train Loss: 0.6709 Acc: 0.5970 | Val Loss: 0.6740 Acc: 0.5918                                            \n",
      "Epoch 044 | Train Loss: 0.6702 Acc: 0.5944 | Val Loss: 0.6735 Acc: 0.5924                                            \n",
      "Epoch 045 | Train Loss: 0.6708 Acc: 0.5937 | Val Loss: 0.6728 Acc: 0.5954                                            \n",
      "Epoch 046 | Train Loss: 0.6695 Acc: 0.6003 | Val Loss: 0.6724 Acc: 0.5954                                            \n",
      "Epoch 047 | Train Loss: 0.6686 Acc: 0.5973 | Val Loss: 0.6722 Acc: 0.5900                                            \n",
      "Epoch 048 | Train Loss: 0.6700 Acc: 0.5963 | Val Loss: 0.6709 Acc: 0.5924                                            \n",
      "Epoch 049 | Train Loss: 0.6684 Acc: 0.5960 | Val Loss: 0.6702 Acc: 0.5942                                            \n",
      "Epoch 050 | Train Loss: 0.6656 Acc: 0.5982 | Val Loss: 0.6688 Acc: 0.5954                                            \n",
      "Epoch 051 | Train Loss: 0.6636 Acc: 0.6077 | Val Loss: 0.6678 Acc: 0.5972                                            \n",
      "Epoch 052 | Train Loss: 0.6637 Acc: 0.5987 | Val Loss: 0.6658 Acc: 0.5966                                            \n",
      "Epoch 053 | Train Loss: 0.6615 Acc: 0.6037 | Val Loss: 0.6676 Acc: 0.5966                                            \n",
      "Epoch 054 | Train Loss: 0.6617 Acc: 0.6049 | Val Loss: 0.6622 Acc: 0.5996                                            \n",
      "Epoch 055 | Train Loss: 0.6590 Acc: 0.6043 | Val Loss: 0.6647 Acc: 0.5870                                            \n",
      "Epoch 056 | Train Loss: 0.6584 Acc: 0.6109 | Val Loss: 0.6580 Acc: 0.6027                                            \n",
      "Epoch 057 | Train Loss: 0.6558 Acc: 0.6073 | Val Loss: 0.6585 Acc: 0.5978                                            \n",
      "Epoch 058 | Train Loss: 0.6547 Acc: 0.6111 | Val Loss: 0.6568 Acc: 0.6057                                            \n",
      "Epoch 059 | Train Loss: 0.6520 Acc: 0.6129 | Val Loss: 0.6505 Acc: 0.6081                                            \n",
      "Epoch 060 | Train Loss: 0.6504 Acc: 0.6154 | Val Loss: 0.6513 Acc: 0.6184                                            \n",
      "Trial params:                                                                                                        \n",
      "{'batch_size': 32, 'cnn_dense': 256, 'cnn_dropout': 0.6887563482694885, 'cnn_kernel_size_1': 3, 'cnn_kernels_1': 48, 'cnn_kernels_2': 96, 'learning_rate': 0.003068224037942107, 'lstm_dense': 128, 'lstm_hidden_size': 96, 'lstm_layers': 1, 'optimizer': 'rmsprop'}\n",
      "Epoch 001 | Train Loss: 0.7020 Acc: 0.5507 | Val Loss: 0.6873 Acc: 0.5586                                            \n",
      "Epoch 002 | Train Loss: 0.6888 Acc: 0.5558 | Val Loss: 0.6874 Acc: 0.5586                                            \n",
      "Epoch 003 | Train Loss: 0.6884 Acc: 0.5576 | Val Loss: 0.6863 Acc: 0.5586                                            \n",
      "Epoch 004 | Train Loss: 0.6890 Acc: 0.5528 | Val Loss: 0.6869 Acc: 0.5586                                            \n",
      "Epoch 005 | Train Loss: 0.6871 Acc: 0.5538 | Val Loss: 0.6837 Acc: 0.5586                                            \n",
      "Epoch 006 | Train Loss: 0.6835 Acc: 0.5715 | Val Loss: 0.6821 Acc: 0.5755                                            \n",
      "Epoch 007 | Train Loss: 0.6809 Acc: 0.5809 | Val Loss: 0.6764 Acc: 0.5894                                            \n",
      "Epoch 008 | Train Loss: 0.6749 Acc: 0.5893 | Val Loss: 0.6752 Acc: 0.5731                                            \n",
      "Epoch 009 | Train Loss: 0.6577 Acc: 0.6172 | Val Loss: 0.6410 Acc: 0.6268                                            \n",
      "Epoch 010 | Train Loss: 0.6229 Acc: 0.6731 | Val Loss: 0.5973 Acc: 0.6763                                            \n",
      "Epoch 011 | Train Loss: 0.5970 Acc: 0.6941 | Val Loss: 0.5826 Acc: 0.6926                                            \n",
      "Epoch 012 | Train Loss: 0.5788 Acc: 0.7029 | Val Loss: 0.5689 Acc: 0.7095                                            \n",
      "Epoch 013 | Train Loss: 0.5610 Acc: 0.7170 | Val Loss: 0.5616 Acc: 0.7204                                            \n",
      "Epoch 014 | Train Loss: 0.5499 Acc: 0.7247 | Val Loss: 0.5518 Acc: 0.7168                                            \n",
      "Epoch 015 | Train Loss: 0.5427 Acc: 0.7317 | Val Loss: 0.5358 Acc: 0.7234                                            \n",
      "Epoch 016 | Train Loss: 0.5338 Acc: 0.7352 | Val Loss: 0.5320 Acc: 0.7373                                            \n",
      "Epoch 017 | Train Loss: 0.5255 Acc: 0.7451 | Val Loss: 0.5518 Acc: 0.7186                                            \n",
      "Epoch 018 | Train Loss: 0.5132 Acc: 0.7489 | Val Loss: 0.5118 Acc: 0.7560                                            \n",
      "Epoch 019 | Train Loss: 0.5008 Acc: 0.7581 | Val Loss: 0.5075 Acc: 0.7548                                            \n",
      "Epoch 020 | Train Loss: 0.4979 Acc: 0.7632 | Val Loss: 0.4906 Acc: 0.7615                                            \n",
      "Epoch 021 | Train Loss: 0.4880 Acc: 0.7716 | Val Loss: 0.5100 Acc: 0.7554                                            \n",
      "Epoch 022 | Train Loss: 0.4740 Acc: 0.7776 | Val Loss: 0.4682 Acc: 0.7808                                            \n",
      "Epoch 023 | Train Loss: 0.4661 Acc: 0.7797 | Val Loss: 0.4435 Acc: 0.7941                                            \n",
      "Epoch 024 | Train Loss: 0.4609 Acc: 0.7812 | Val Loss: 0.4514 Acc: 0.7941                                            \n",
      "Epoch 025 | Train Loss: 0.4461 Acc: 0.7941 | Val Loss: 0.4316 Acc: 0.7977                                            \n",
      "Epoch 026 | Train Loss: 0.4351 Acc: 0.7972 | Val Loss: 0.4448 Acc: 0.7989                                            \n",
      "Epoch 027 | Train Loss: 0.4314 Acc: 0.7974 | Val Loss: 0.4138 Acc: 0.8225                                            \n",
      "Epoch 028 | Train Loss: 0.4204 Acc: 0.8055 | Val Loss: 0.4069 Acc: 0.8267                                            \n",
      "Epoch 029 | Train Loss: 0.4096 Acc: 0.8149 | Val Loss: 0.4143 Acc: 0.8086                                            \n",
      "Epoch 030 | Train Loss: 0.3981 Acc: 0.8187 | Val Loss: 0.4051 Acc: 0.8303                                            \n",
      "Epoch 031 | Train Loss: 0.3957 Acc: 0.8224 | Val Loss: 0.3977 Acc: 0.8122                                            \n",
      "Epoch 032 | Train Loss: 0.3786 Acc: 0.8292 | Val Loss: 0.3933 Acc: 0.8357                                            \n",
      "Epoch 033 | Train Loss: 0.3754 Acc: 0.8323 | Val Loss: 0.3474 Acc: 0.8502                                            \n",
      "Epoch 034 | Train Loss: 0.3682 Acc: 0.8409 | Val Loss: 0.3987 Acc: 0.8261                                            \n",
      "Epoch 035 | Train Loss: 0.3562 Acc: 0.8445 | Val Loss: 0.3544 Acc: 0.8406                                            \n",
      "Epoch 036 | Train Loss: 0.3391 Acc: 0.8511 | Val Loss: 0.3201 Acc: 0.8726                                            \n",
      "Epoch 037 | Train Loss: 0.3330 Acc: 0.8567 | Val Loss: 0.3251 Acc: 0.8593                                            \n",
      "Epoch 038 | Train Loss: 0.3241 Acc: 0.8617 | Val Loss: 0.2842 Acc: 0.8792                                            \n",
      "Epoch 039 | Train Loss: 0.3129 Acc: 0.8705 | Val Loss: 0.2950 Acc: 0.8726                                            \n",
      "Epoch 040 | Train Loss: 0.3112 Acc: 0.8688 | Val Loss: 0.2983 Acc: 0.8750                                            \n",
      "Epoch 041 | Train Loss: 0.3033 Acc: 0.8714 | Val Loss: 0.2828 Acc: 0.8762                                            \n",
      "Epoch 042 | Train Loss: 0.2953 Acc: 0.8789 | Val Loss: 0.2988 Acc: 0.8696                                            \n",
      "Epoch 043 | Train Loss: 0.2865 Acc: 0.8750 | Val Loss: 0.2784 Acc: 0.8829                                            \n",
      "Epoch 044 | Train Loss: 0.2718 Acc: 0.8908 | Val Loss: 0.2606 Acc: 0.8901                                            \n",
      "Epoch 045 | Train Loss: 0.2770 Acc: 0.8836 | Val Loss: 0.2710 Acc: 0.8859                                            \n",
      "Epoch 046 | Train Loss: 0.2729 Acc: 0.8878 | Val Loss: 0.2778 Acc: 0.8883                                            \n",
      "Epoch 047 | Train Loss: 0.2589 Acc: 0.8958 | Val Loss: 0.2392 Acc: 0.9040                                            \n",
      "Epoch 048 | Train Loss: 0.2594 Acc: 0.8972 | Val Loss: 0.3032 Acc: 0.8798                                            \n",
      "Epoch 049 | Train Loss: 0.2571 Acc: 0.8934 | Val Loss: 0.2367 Acc: 0.9088                                            \n",
      "Epoch 050 | Train Loss: 0.2503 Acc: 0.8958 | Val Loss: 0.2172 Acc: 0.9112                                            \n",
      "Epoch 051 | Train Loss: 0.2394 Acc: 0.9002 | Val Loss: 0.2488 Acc: 0.8961                                            \n",
      "Epoch 052 | Train Loss: 0.2411 Acc: 0.9003 | Val Loss: 0.2096 Acc: 0.9155                                            \n",
      "Epoch 053 | Train Loss: 0.2400 Acc: 0.9014 | Val Loss: 0.2251 Acc: 0.9106                                            \n",
      "Epoch 054 | Train Loss: 0.2343 Acc: 0.9028 | Val Loss: 0.2753 Acc: 0.8877                                            \n",
      "Epoch 055 | Train Loss: 0.2197 Acc: 0.9148 | Val Loss: 0.2452 Acc: 0.9094                                            \n",
      "Epoch 056 | Train Loss: 0.2305 Acc: 0.9097 | Val Loss: 0.2065 Acc: 0.9167                                            \n",
      "Epoch 057 | Train Loss: 0.2172 Acc: 0.9168 | Val Loss: 0.2269 Acc: 0.9070                                            \n",
      "Epoch 058 | Train Loss: 0.2149 Acc: 0.9180 | Val Loss: 0.2259 Acc: 0.9064                                            \n",
      "Epoch 059 | Train Loss: 0.2176 Acc: 0.9135 | Val Loss: 0.2129 Acc: 0.9209                                            \n",
      "Epoch 060 | Train Loss: 0.2140 Acc: 0.9138 | Val Loss: 0.2000 Acc: 0.9149                                            \n",
      "Trial params:                                                                                                        \n",
      "{'batch_size': 32, 'cnn_dense': 128, 'cnn_dropout': 0.48883857442265405, 'cnn_kernel_size_1': 3, 'cnn_kernels_1': 48, 'cnn_kernels_2': 64, 'learning_rate': 0.0007402885708654736, 'lstm_dense': 128, 'lstm_hidden_size': 128, 'lstm_layers': 1, 'optimizer': 'rmsprop'}\n",
      "Epoch 001 | Train Loss: 0.6773 Acc: 0.5849 | Val Loss: 0.6673 Acc: 0.5857                                            \n",
      "Epoch 002 | Train Loss: 0.6465 Acc: 0.6219 | Val Loss: 0.6336 Acc: 0.6624                                            \n",
      "Epoch 003 | Train Loss: 0.6141 Acc: 0.6793 | Val Loss: 0.6108 Acc: 0.6733                                            \n",
      "Epoch 004 | Train Loss: 0.5787 Acc: 0.7096 | Val Loss: 0.5904 Acc: 0.6914                                            \n",
      "Epoch 005 | Train Loss: 0.5605 Acc: 0.7186 | Val Loss: 0.5674 Acc: 0.6987                                            \n",
      "Epoch 006 | Train Loss: 0.5439 Acc: 0.7309 | Val Loss: 0.5504 Acc: 0.7174                                            \n",
      "Epoch 007 | Train Loss: 0.5382 Acc: 0.7340 | Val Loss: 0.5637 Acc: 0.7126                                            \n",
      "Epoch 008 | Train Loss: 0.5273 Acc: 0.7408 | Val Loss: 0.5334 Acc: 0.7222                                            \n",
      "Epoch 009 | Train Loss: 0.5122 Acc: 0.7469 | Val Loss: 0.5141 Acc: 0.7385                                            \n",
      "Epoch 010 | Train Loss: 0.5011 Acc: 0.7574 | Val Loss: 0.5095 Acc: 0.7421                                            \n",
      "Epoch 011 | Train Loss: 0.4820 Acc: 0.7696 | Val Loss: 0.4828 Acc: 0.7675                                            \n",
      "Epoch 012 | Train Loss: 0.4686 Acc: 0.7790 | Val Loss: 0.5320 Acc: 0.7319                                            \n",
      "Epoch 013 | Train Loss: 0.4390 Acc: 0.7945 | Val Loss: 0.4438 Acc: 0.7826                                            \n",
      "Epoch 014 | Train Loss: 0.4190 Acc: 0.8055 | Val Loss: 0.4737 Acc: 0.7675                                            \n",
      "Epoch 015 | Train Loss: 0.4052 Acc: 0.8120 | Val Loss: 0.4229 Acc: 0.7965                                            \n",
      "Epoch 016 | Train Loss: 0.3829 Acc: 0.8256 | Val Loss: 0.4116 Acc: 0.8068                                            \n",
      "Epoch 017 | Train Loss: 0.3674 Acc: 0.8333 | Val Loss: 0.3520 Acc: 0.8406                                            \n",
      "Epoch 018 | Train Loss: 0.3440 Acc: 0.8520 | Val Loss: 0.3538 Acc: 0.8388                                            \n",
      "Epoch 019 | Train Loss: 0.3335 Acc: 0.8554 | Val Loss: 0.3505 Acc: 0.8388                                            \n",
      "Epoch 020 | Train Loss: 0.3153 Acc: 0.8643 | Val Loss: 0.3332 Acc: 0.8496                                            \n",
      "Epoch 021 | Train Loss: 0.2993 Acc: 0.8711 | Val Loss: 0.3085 Acc: 0.8659                                            \n",
      "Epoch 022 | Train Loss: 0.2850 Acc: 0.8846 | Val Loss: 0.3341 Acc: 0.8539                                            \n",
      "Epoch 023 | Train Loss: 0.2666 Acc: 0.8875 | Val Loss: 0.2725 Acc: 0.8919                                            \n",
      "Epoch 024 | Train Loss: 0.2541 Acc: 0.8963 | Val Loss: 0.2601 Acc: 0.8907                                            \n",
      "Epoch 025 | Train Loss: 0.2447 Acc: 0.8940 | Val Loss: 0.2869 Acc: 0.8853                                            \n",
      "Epoch 026 | Train Loss: 0.2377 Acc: 0.9005 | Val Loss: 0.2666 Acc: 0.8865                                            \n",
      "Epoch 027 | Train Loss: 0.2223 Acc: 0.9106 | Val Loss: 0.2636 Acc: 0.9004                                            \n",
      "Epoch 028 | Train Loss: 0.2188 Acc: 0.9108 | Val Loss: 0.2499 Acc: 0.8979                                            \n",
      "Epoch 029 | Train Loss: 0.2082 Acc: 0.9159 | Val Loss: 0.2363 Acc: 0.8992                                            \n",
      "Epoch 030 | Train Loss: 0.1935 Acc: 0.9262 | Val Loss: 0.2197 Acc: 0.9046                                            \n",
      "Epoch 031 | Train Loss: 0.2010 Acc: 0.9200 | Val Loss: 0.2299 Acc: 0.9064                                            \n",
      "Epoch 032 | Train Loss: 0.1839 Acc: 0.9259 | Val Loss: 0.2284 Acc: 0.9070                                            \n",
      "Epoch 033 | Train Loss: 0.1743 Acc: 0.9319 | Val Loss: 0.2756 Acc: 0.8919                                            \n",
      "Epoch 034 | Train Loss: 0.1693 Acc: 0.9328 | Val Loss: 0.2196 Acc: 0.9094                                            \n",
      "Epoch 035 | Train Loss: 0.1589 Acc: 0.9364 | Val Loss: 0.1920 Acc: 0.9263                                            \n",
      "Epoch 036 | Train Loss: 0.1462 Acc: 0.9444 | Val Loss: 0.2121 Acc: 0.9179                                            \n",
      "Epoch 037 | Train Loss: 0.1504 Acc: 0.9431 | Val Loss: 0.2101 Acc: 0.9161                                            \n",
      "Epoch 038 | Train Loss: 0.1483 Acc: 0.9443 | Val Loss: 0.2123 Acc: 0.9203                                            \n",
      "Epoch 039 | Train Loss: 0.1361 Acc: 0.9462 | Val Loss: 0.2081 Acc: 0.9257                                            \n",
      "Epoch 040 | Train Loss: 0.1296 Acc: 0.9473 | Val Loss: 0.1800 Acc: 0.9300                                            \n",
      "Epoch 041 | Train Loss: 0.1286 Acc: 0.9505 | Val Loss: 0.2172 Acc: 0.9094                                            \n",
      "Epoch 042 | Train Loss: 0.1222 Acc: 0.9529 | Val Loss: 0.1977 Acc: 0.9233                                            \n",
      "Epoch 043 | Train Loss: 0.1222 Acc: 0.9530 | Val Loss: 0.1705 Acc: 0.9348                                            \n",
      "Epoch 044 | Train Loss: 0.1177 Acc: 0.9529 | Val Loss: 0.1850 Acc: 0.9336                                            \n",
      "Epoch 045 | Train Loss: 0.1116 Acc: 0.9567 | Val Loss: 0.2180 Acc: 0.9173                                            \n",
      "Epoch 046 | Train Loss: 0.1108 Acc: 0.9580 | Val Loss: 0.1674 Acc: 0.9402                                            \n",
      "Epoch 047 | Train Loss: 0.1031 Acc: 0.9595 | Val Loss: 0.2139 Acc: 0.9227                                            \n",
      "Epoch 048 | Train Loss: 0.1013 Acc: 0.9601 | Val Loss: 0.2142 Acc: 0.9263                                            \n",
      "Epoch 049 | Train Loss: 0.0938 Acc: 0.9616 | Val Loss: 0.1977 Acc: 0.9275                                            \n",
      "Epoch 050 | Train Loss: 0.0948 Acc: 0.9639 | Val Loss: 0.1613 Acc: 0.9511                                            \n",
      "Epoch 051 | Train Loss: 0.0870 Acc: 0.9659 | Val Loss: 0.1687 Acc: 0.9396                                            \n",
      "Epoch 052 | Train Loss: 0.0878 Acc: 0.9677 | Val Loss: 0.1661 Acc: 0.9432                                            \n",
      "Epoch 053 | Train Loss: 0.0836 Acc: 0.9684 | Val Loss: 0.1790 Acc: 0.9342                                            \n",
      "Epoch 054 | Train Loss: 0.0857 Acc: 0.9703 | Val Loss: 0.1619 Acc: 0.9432                                            \n",
      "Epoch 055 | Train Loss: 0.0919 Acc: 0.9648 | Val Loss: 0.1685 Acc: 0.9450                                            \n",
      "Epoch 056 | Train Loss: 0.0862 Acc: 0.9668 | Val Loss: 0.1692 Acc: 0.9390                                            \n",
      "Epoch 057 | Train Loss: 0.0770 Acc: 0.9701 | Val Loss: 0.1724 Acc: 0.9384                                            \n",
      "Epoch 058 | Train Loss: 0.0763 Acc: 0.9728 | Val Loss: 0.1605 Acc: 0.9432                                            \n",
      "Epoch 059 | Train Loss: 0.0734 Acc: 0.9715 | Val Loss: 0.1654 Acc: 0.9378                                            \n",
      "Epoch 060 | Train Loss: 0.0751 Acc: 0.9727 | Val Loss: 0.1680 Acc: 0.9438                                            \n",
      "Trial params:                                                                                                        \n",
      "{'batch_size': 32, 'cnn_dense': 32, 'cnn_dropout': 0.41133219224702167, 'cnn_kernel_size_1': 3, 'cnn_kernels_1': 48, 'cnn_kernels_2': 16, 'learning_rate': 0.0012672939111410876, 'lstm_dense': 32, 'lstm_hidden_size': 128, 'lstm_layers': 1, 'optimizer': 'rmsprop'}\n",
      "Epoch 001 | Train Loss: 0.6815 Acc: 0.5757 | Val Loss: 0.6820 Acc: 0.5719                                            \n",
      "Epoch 002 | Train Loss: 0.6602 Acc: 0.6124 | Val Loss: 0.6272 Acc: 0.6576                                            \n",
      "Epoch 003 | Train Loss: 0.6139 Acc: 0.6793 | Val Loss: 0.5903 Acc: 0.6830                                            \n",
      "Epoch 004 | Train Loss: 0.5938 Acc: 0.7010 | Val Loss: 0.5824 Acc: 0.6993                                            \n",
      "Epoch 005 | Train Loss: 0.5712 Acc: 0.7134 | Val Loss: 0.5678 Acc: 0.7053                                            \n",
      "Epoch 006 | Train Loss: 0.5637 Acc: 0.7183 | Val Loss: 0.5558 Acc: 0.7192                                            \n",
      "Epoch 007 | Train Loss: 0.5481 Acc: 0.7273 | Val Loss: 0.5460 Acc: 0.7222                                            \n",
      "Epoch 008 | Train Loss: 0.5401 Acc: 0.7294 | Val Loss: 0.5431 Acc: 0.7204                                            \n",
      "Epoch 009 | Train Loss: 0.5261 Acc: 0.7421 | Val Loss: 0.5095 Acc: 0.7464                                            \n",
      "Epoch 010 | Train Loss: 0.5143 Acc: 0.7497 | Val Loss: 0.5040 Acc: 0.7566                                            \n",
      "Epoch 011 | Train Loss: 0.5023 Acc: 0.7580 | Val Loss: 0.4822 Acc: 0.7609                                            \n",
      "Epoch 012 | Train Loss: 0.4815 Acc: 0.7723 | Val Loss: 0.4827 Acc: 0.7615                                            \n",
      "Epoch 013 | Train Loss: 0.4788 Acc: 0.7675 | Val Loss: 0.4681 Acc: 0.7736                                            \n",
      "Epoch 014 | Train Loss: 0.4627 Acc: 0.7817 | Val Loss: 0.4613 Acc: 0.7657                                            \n",
      "Epoch 015 | Train Loss: 0.4484 Acc: 0.7845 | Val Loss: 0.4348 Acc: 0.7796                                            \n",
      "Epoch 016 | Train Loss: 0.4408 Acc: 0.7928 | Val Loss: 0.4221 Acc: 0.7935                                            \n",
      "Epoch 017 | Train Loss: 0.4246 Acc: 0.8036 | Val Loss: 0.3920 Acc: 0.8164                                            \n",
      "Epoch 018 | Train Loss: 0.4177 Acc: 0.8126 | Val Loss: 0.3940 Acc: 0.8207                                            \n",
      "Epoch 019 | Train Loss: 0.4064 Acc: 0.8114 | Val Loss: 0.3806 Acc: 0.8243                                            \n",
      "Epoch 020 | Train Loss: 0.3960 Acc: 0.8203 | Val Loss: 0.3776 Acc: 0.8207                                            \n",
      "Epoch 021 | Train Loss: 0.3791 Acc: 0.8301 | Val Loss: 0.3613 Acc: 0.8382                                            \n",
      "Epoch 022 | Train Loss: 0.3721 Acc: 0.8393 | Val Loss: 0.3546 Acc: 0.8376                                            \n",
      "Epoch 023 | Train Loss: 0.3587 Acc: 0.8396 | Val Loss: 0.3348 Acc: 0.8539                                            \n",
      "Epoch 024 | Train Loss: 0.3537 Acc: 0.8433 | Val Loss: 0.3455 Acc: 0.8502                                            \n",
      "Epoch 025 | Train Loss: 0.3414 Acc: 0.8516 | Val Loss: 0.3269 Acc: 0.8617                                            \n",
      "Epoch 026 | Train Loss: 0.3293 Acc: 0.8547 | Val Loss: 0.3044 Acc: 0.8792                                            \n",
      "Epoch 027 | Train Loss: 0.3237 Acc: 0.8599 | Val Loss: 0.3078 Acc: 0.8720                                            \n",
      "Epoch 028 | Train Loss: 0.3122 Acc: 0.8689 | Val Loss: 0.3173 Acc: 0.8605                                            \n",
      "Epoch 029 | Train Loss: 0.2992 Acc: 0.8723 | Val Loss: 0.2945 Acc: 0.8829                                            \n",
      "Epoch 030 | Train Loss: 0.2997 Acc: 0.8750 | Val Loss: 0.3658 Acc: 0.8418                                            \n",
      "Epoch 031 | Train Loss: 0.2889 Acc: 0.8763 | Val Loss: 0.2934 Acc: 0.8780                                            \n",
      "Epoch 032 | Train Loss: 0.2822 Acc: 0.8815 | Val Loss: 0.2864 Acc: 0.8901                                            \n",
      "Epoch 033 | Train Loss: 0.2829 Acc: 0.8865 | Val Loss: 0.3636 Acc: 0.8412                                            \n",
      "Epoch 034 | Train Loss: 0.2710 Acc: 0.8887 | Val Loss: 0.2761 Acc: 0.8889                                            \n",
      "Epoch 035 | Train Loss: 0.2691 Acc: 0.8886 | Val Loss: 0.2598 Acc: 0.8961                                            \n",
      "Epoch 036 | Train Loss: 0.2576 Acc: 0.8929 | Val Loss: 0.2697 Acc: 0.8883                                            \n",
      "Epoch 037 | Train Loss: 0.2563 Acc: 0.8949 | Val Loss: 0.2381 Acc: 0.9064                                            \n",
      "Epoch 038 | Train Loss: 0.2471 Acc: 0.8982 | Val Loss: 0.2659 Acc: 0.8822                                            \n",
      "Epoch 039 | Train Loss: 0.2481 Acc: 0.8979 | Val Loss: 0.2428 Acc: 0.8979                                            \n",
      "Epoch 040 | Train Loss: 0.2353 Acc: 0.9062 | Val Loss: 0.2543 Acc: 0.8992                                            \n",
      "Epoch 041 | Train Loss: 0.2335 Acc: 0.9064 | Val Loss: 0.2407 Acc: 0.9118                                            \n",
      "Epoch 042 | Train Loss: 0.2198 Acc: 0.9074 | Val Loss: 0.2315 Acc: 0.9082                                            \n",
      "Epoch 043 | Train Loss: 0.2191 Acc: 0.9114 | Val Loss: 0.2639 Acc: 0.8883                                            \n",
      "Epoch 044 | Train Loss: 0.2290 Acc: 0.9111 | Val Loss: 0.2214 Acc: 0.9155                                            \n",
      "Epoch 045 | Train Loss: 0.2146 Acc: 0.9176 | Val Loss: 0.2234 Acc: 0.9100                                            \n",
      "Epoch 046 | Train Loss: 0.2100 Acc: 0.9156 | Val Loss: 0.2116 Acc: 0.9167                                            \n",
      "Epoch 047 | Train Loss: 0.2018 Acc: 0.9194 | Val Loss: 0.2530 Acc: 0.8979                                            \n",
      "Epoch 048 | Train Loss: 0.2066 Acc: 0.9136 | Val Loss: 0.2125 Acc: 0.9112                                            \n",
      "Epoch 049 | Train Loss: 0.1987 Acc: 0.9200 | Val Loss: 0.2423 Acc: 0.9046                                            \n",
      "Epoch 050 | Train Loss: 0.2020 Acc: 0.9218 | Val Loss: 0.2113 Acc: 0.9197                                            \n",
      "Epoch 051 | Train Loss: 0.1920 Acc: 0.9245 | Val Loss: 0.1940 Acc: 0.9293                                            \n",
      "Epoch 052 | Train Loss: 0.1828 Acc: 0.9251 | Val Loss: 0.1731 Acc: 0.9390                                            \n",
      "Epoch 053 | Train Loss: 0.1721 Acc: 0.9290 | Val Loss: 0.1934 Acc: 0.9336                                            \n",
      "Epoch 054 | Train Loss: 0.1768 Acc: 0.9328 | Val Loss: 0.2003 Acc: 0.9227                                            \n",
      "Epoch 055 | Train Loss: 0.1743 Acc: 0.9311 | Val Loss: 0.1828 Acc: 0.9275                                            \n",
      "Epoch 056 | Train Loss: 0.1647 Acc: 0.9355 | Val Loss: 0.1780 Acc: 0.9330                                            \n",
      "Epoch 057 | Train Loss: 0.1680 Acc: 0.9308 | Val Loss: 0.1662 Acc: 0.9408                                            \n",
      "Epoch 058 | Train Loss: 0.1615 Acc: 0.9355 | Val Loss: 0.1757 Acc: 0.9300                                            \n",
      "Epoch 059 | Train Loss: 0.1551 Acc: 0.9388 | Val Loss: 0.1703 Acc: 0.9336                                            \n",
      "Epoch 060 | Train Loss: 0.1592 Acc: 0.9387 | Val Loss: 0.1957 Acc: 0.9263                                            \n",
      "Trial params:                                                                                                        \n",
      "{'batch_size': 32, 'cnn_dense': 128, 'cnn_dropout': 0.5613905277576746, 'cnn_kernel_size_1': 3, 'cnn_kernels_1': 16, 'cnn_kernels_2': 64, 'learning_rate': 0.0018562638582129488, 'lstm_dense': 256, 'lstm_hidden_size': 128, 'lstm_layers': 1, 'optimizer': 'sgd'}\n",
      "Epoch 001 | Train Loss: 0.6873 Acc: 0.5559 | Val Loss: 0.6861 Acc: 0.5586                                            \n",
      "Epoch 002 | Train Loss: 0.6863 Acc: 0.5582 | Val Loss: 0.6860 Acc: 0.5586                                            \n",
      "Epoch 003 | Train Loss: 0.6862 Acc: 0.5582 | Val Loss: 0.6855 Acc: 0.5586                                            \n",
      "Epoch 004 | Train Loss: 0.6853 Acc: 0.5582 | Val Loss: 0.6849 Acc: 0.5598                                            \n",
      "Epoch 005 | Train Loss: 0.6847 Acc: 0.5597 | Val Loss: 0.6842 Acc: 0.5616                                            \n",
      "Epoch 006 | Train Loss: 0.6836 Acc: 0.5632 | Val Loss: 0.6832 Acc: 0.5676                                            \n",
      "Epoch 007 | Train Loss: 0.6823 Acc: 0.5712 | Val Loss: 0.6820 Acc: 0.5719                                            \n",
      "Epoch 008 | Train Loss: 0.6809 Acc: 0.5754 | Val Loss: 0.6807 Acc: 0.5749                                            \n",
      "Epoch 009 | Train Loss: 0.6790 Acc: 0.5809 | Val Loss: 0.6795 Acc: 0.5797                                            \n",
      "Epoch 010 | Train Loss: 0.6772 Acc: 0.5842 | Val Loss: 0.6786 Acc: 0.5821                                            \n",
      "Epoch 011 | Train Loss: 0.6761 Acc: 0.5831 | Val Loss: 0.6784 Acc: 0.5839                                            \n",
      "Epoch 012 | Train Loss: 0.6765 Acc: 0.5842 | Val Loss: 0.6781 Acc: 0.5845                                            \n",
      "Epoch 013 | Train Loss: 0.6775 Acc: 0.5886 | Val Loss: 0.6779 Acc: 0.5882                                            \n",
      "Epoch 014 | Train Loss: 0.6758 Acc: 0.5860 | Val Loss: 0.6780 Acc: 0.5870                                            \n",
      "Epoch 015 | Train Loss: 0.6750 Acc: 0.5864 | Val Loss: 0.6777 Acc: 0.5882                                            \n",
      "Epoch 016 | Train Loss: 0.6753 Acc: 0.5896 | Val Loss: 0.6779 Acc: 0.5876                                            \n",
      "Epoch 017 | Train Loss: 0.6755 Acc: 0.5883 | Val Loss: 0.6778 Acc: 0.5888                                            \n",
      "Epoch 018 | Train Loss: 0.6753 Acc: 0.5892 | Val Loss: 0.6776 Acc: 0.5851                                            \n",
      "Epoch 019 | Train Loss: 0.6742 Acc: 0.5898 | Val Loss: 0.6775 Acc: 0.5870                                            \n",
      "Epoch 020 | Train Loss: 0.6752 Acc: 0.5861 | Val Loss: 0.6774 Acc: 0.5864                                            \n",
      "Epoch 021 | Train Loss: 0.6753 Acc: 0.5855 | Val Loss: 0.6773 Acc: 0.5876                                            \n",
      "Epoch 022 | Train Loss: 0.6746 Acc: 0.5876 | Val Loss: 0.6773 Acc: 0.5870                                            \n",
      "Epoch 023 | Train Loss: 0.6746 Acc: 0.5863 | Val Loss: 0.6773 Acc: 0.5864                                            \n",
      "Epoch 024 | Train Loss: 0.6754 Acc: 0.5886 | Val Loss: 0.6769 Acc: 0.5882                                            \n",
      "Epoch 025 | Train Loss: 0.6753 Acc: 0.5883 | Val Loss: 0.6768 Acc: 0.5882                                            \n",
      "Epoch 026 | Train Loss: 0.6744 Acc: 0.5886 | Val Loss: 0.6768 Acc: 0.5882                                            \n",
      "Epoch 027 | Train Loss: 0.6746 Acc: 0.5916 | Val Loss: 0.6767 Acc: 0.5900                                            \n",
      "Epoch 028 | Train Loss: 0.6742 Acc: 0.5887 | Val Loss: 0.6765 Acc: 0.5888                                            \n",
      "Epoch 029 | Train Loss: 0.6743 Acc: 0.5873 | Val Loss: 0.6765 Acc: 0.5894                                            \n",
      "Epoch 030 | Train Loss: 0.6736 Acc: 0.5902 | Val Loss: 0.6765 Acc: 0.5888                                            \n",
      "Epoch 031 | Train Loss: 0.6740 Acc: 0.5869 | Val Loss: 0.6764 Acc: 0.5894                                            \n",
      "Epoch 032 | Train Loss: 0.6737 Acc: 0.5907 | Val Loss: 0.6761 Acc: 0.5900                                            \n",
      "Epoch 033 | Train Loss: 0.6721 Acc: 0.5902 | Val Loss: 0.6761 Acc: 0.5888                                            \n",
      "Epoch 034 | Train Loss: 0.6732 Acc: 0.5892 | Val Loss: 0.6758 Acc: 0.5894                                            \n",
      "Epoch 035 | Train Loss: 0.6732 Acc: 0.5920 | Val Loss: 0.6758 Acc: 0.5906                                            \n",
      "Epoch 036 | Train Loss: 0.6727 Acc: 0.5934 | Val Loss: 0.6754 Acc: 0.5888                                            \n",
      "Epoch 037 | Train Loss: 0.6719 Acc: 0.5925 | Val Loss: 0.6763 Acc: 0.5864                                            \n",
      "Epoch 038 | Train Loss: 0.6724 Acc: 0.5934 | Val Loss: 0.6749 Acc: 0.5888                                            \n",
      "Epoch 039 | Train Loss: 0.6721 Acc: 0.5917 | Val Loss: 0.6745 Acc: 0.5918                                            \n",
      "Epoch 040 | Train Loss: 0.6713 Acc: 0.5934 | Val Loss: 0.6743 Acc: 0.5912                                            \n",
      "Epoch 041 | Train Loss: 0.6708 Acc: 0.5950 | Val Loss: 0.6758 Acc: 0.5864                                            \n",
      "Epoch 042 | Train Loss: 0.6704 Acc: 0.5982 | Val Loss: 0.6734 Acc: 0.5906                                            \n",
      "Epoch 043 | Train Loss: 0.6703 Acc: 0.5943 | Val Loss: 0.6727 Acc: 0.5912                                            \n",
      "Epoch 044 | Train Loss: 0.6703 Acc: 0.5950 | Val Loss: 0.6721 Acc: 0.5888                                            \n",
      "Epoch 045 | Train Loss: 0.6695 Acc: 0.5963 | Val Loss: 0.6715 Acc: 0.5906                                            \n",
      "Epoch 046 | Train Loss: 0.6690 Acc: 0.5975 | Val Loss: 0.6711 Acc: 0.5936                                            \n",
      "Epoch 047 | Train Loss: 0.6683 Acc: 0.5961 | Val Loss: 0.6705 Acc: 0.5900                                            \n",
      "Epoch 048 | Train Loss: 0.6668 Acc: 0.6030 | Val Loss: 0.6694 Acc: 0.5912                                            \n",
      "Epoch 049 | Train Loss: 0.6662 Acc: 0.5966 | Val Loss: 0.6691 Acc: 0.5948                                            \n",
      "Epoch 050 | Train Loss: 0.6630 Acc: 0.6041 | Val Loss: 0.6676 Acc: 0.5954                                            \n",
      "Epoch 051 | Train Loss: 0.6647 Acc: 0.6012 | Val Loss: 0.6661 Acc: 0.5924                                            \n",
      "Epoch 052 | Train Loss: 0.6632 Acc: 0.6052 | Val Loss: 0.6655 Acc: 0.5918                                            \n",
      "Epoch 053 | Train Loss: 0.6611 Acc: 0.6068 | Val Loss: 0.6647 Acc: 0.5990                                            \n",
      "Epoch 054 | Train Loss: 0.6618 Acc: 0.6030 | Val Loss: 0.6622 Acc: 0.5996                                            \n",
      "Epoch 055 | Train Loss: 0.6605 Acc: 0.6055 | Val Loss: 0.6608 Acc: 0.5972                                            \n",
      "Epoch 056 | Train Loss: 0.6591 Acc: 0.6073 | Val Loss: 0.6607 Acc: 0.5942                                            \n",
      "Epoch 057 | Train Loss: 0.6570 Acc: 0.6083 | Val Loss: 0.6589 Acc: 0.6033                                            \n",
      "Epoch 058 | Train Loss: 0.6554 Acc: 0.6106 | Val Loss: 0.6574 Acc: 0.5996                                            \n",
      "Epoch 059 | Train Loss: 0.6561 Acc: 0.6150 | Val Loss: 0.6620 Acc: 0.6027                                            \n",
      "Epoch 060 | Train Loss: 0.6543 Acc: 0.6124 | Val Loss: 0.6555 Acc: 0.6099                                            \n",
      "Trial params:                                                                                                        \n",
      "{'batch_size': 36, 'cnn_dense': 128, 'cnn_dropout': 0.3245211401583477, 'cnn_kernel_size_1': 3, 'cnn_kernels_1': 48, 'cnn_kernels_2': 64, 'learning_rate': 0.001017950595131245, 'lstm_dense': 128, 'lstm_hidden_size': 96, 'lstm_layers': 1, 'optimizer': 'rmsprop'}\n",
      "Epoch 001 | Train Loss: 0.6775 Acc: 0.5834 | Val Loss: 0.6662 Acc: 0.5954                                            \n",
      "Epoch 002 | Train Loss: 0.6340 Acc: 0.6506 | Val Loss: 0.6149 Acc: 0.6661                                            \n",
      "Epoch 003 | Train Loss: 0.5865 Acc: 0.6997 | Val Loss: 0.5676 Acc: 0.7071                                            \n",
      "Epoch 004 | Train Loss: 0.5539 Acc: 0.7263 | Val Loss: 0.6071 Acc: 0.7017                                            \n",
      "Epoch 005 | Train Loss: 0.5348 Acc: 0.7320 | Val Loss: 0.5499 Acc: 0.7186                                            \n",
      "Epoch 006 | Train Loss: 0.5191 Acc: 0.7483 | Val Loss: 0.5434 Acc: 0.7319                                            \n",
      "Epoch 007 | Train Loss: 0.4980 Acc: 0.7625 | Val Loss: 0.4972 Acc: 0.7566                                            \n",
      "Epoch 008 | Train Loss: 0.4753 Acc: 0.7723 | Val Loss: 0.4858 Acc: 0.7639                                            \n",
      "Epoch 009 | Train Loss: 0.4584 Acc: 0.7854 | Val Loss: 0.4633 Acc: 0.7760                                            \n",
      "Epoch 010 | Train Loss: 0.4271 Acc: 0.8037 | Val Loss: 0.4383 Acc: 0.7862                                            \n",
      "Epoch 011 | Train Loss: 0.3979 Acc: 0.8246 | Val Loss: 0.4223 Acc: 0.7983                                            \n",
      "Epoch 012 | Train Loss: 0.3703 Acc: 0.8362 | Val Loss: 0.4427 Acc: 0.7935                                            \n",
      "Epoch 013 | Train Loss: 0.3469 Acc: 0.8481 | Val Loss: 0.3627 Acc: 0.8339                                            \n",
      "Epoch 014 | Train Loss: 0.3315 Acc: 0.8531 | Val Loss: 0.3411 Acc: 0.8436                                            \n",
      "Epoch 015 | Train Loss: 0.3090 Acc: 0.8665 | Val Loss: 0.3140 Acc: 0.8708                                            \n",
      "Epoch 016 | Train Loss: 0.2924 Acc: 0.8788 | Val Loss: 0.3187 Acc: 0.8665                                            \n",
      "Epoch 017 | Train Loss: 0.2748 Acc: 0.8810 | Val Loss: 0.2764 Acc: 0.8847                                            \n",
      "Epoch 018 | Train Loss: 0.2547 Acc: 0.8929 | Val Loss: 0.2868 Acc: 0.8720                                            \n",
      "Epoch 019 | Train Loss: 0.2397 Acc: 0.9038 | Val Loss: 0.2682 Acc: 0.8907                                            \n",
      "Epoch 020 | Train Loss: 0.2254 Acc: 0.9076 | Val Loss: 0.2760 Acc: 0.8919                                            \n",
      "Epoch 021 | Train Loss: 0.2155 Acc: 0.9076 | Val Loss: 0.3056 Acc: 0.8671                                            \n",
      "Epoch 022 | Train Loss: 0.2057 Acc: 0.9171 | Val Loss: 0.2312 Acc: 0.9004                                            \n",
      "Epoch 023 | Train Loss: 0.1924 Acc: 0.9269 | Val Loss: 0.2363 Acc: 0.8986                                            \n",
      "Epoch 024 | Train Loss: 0.1855 Acc: 0.9224 | Val Loss: 0.2243 Acc: 0.9088                                            \n",
      "Epoch 025 | Train Loss: 0.1804 Acc: 0.9268 | Val Loss: 0.3675 Acc: 0.8605                                            \n",
      "Epoch 026 | Train Loss: 0.1709 Acc: 0.9310 | Val Loss: 0.2328 Acc: 0.9046                                            \n",
      "Epoch 027 | Train Loss: 0.1590 Acc: 0.9396 | Val Loss: 0.2247 Acc: 0.9064                                            \n",
      "Epoch 028 | Train Loss: 0.1437 Acc: 0.9420 | Val Loss: 0.2277 Acc: 0.9149                                            \n",
      "Epoch 029 | Train Loss: 0.1499 Acc: 0.9431 | Val Loss: 0.1805 Acc: 0.9300                                            \n",
      "Epoch 030 | Train Loss: 0.1240 Acc: 0.9500 | Val Loss: 0.1807 Acc: 0.9318                                            \n",
      "Epoch 031 | Train Loss: 0.1240 Acc: 0.9514 | Val Loss: 0.2237 Acc: 0.9124                                            \n",
      "Epoch 032 | Train Loss: 0.1206 Acc: 0.9505 | Val Loss: 0.1938 Acc: 0.9269                                            \n",
      "Epoch 033 | Train Loss: 0.1167 Acc: 0.9567 | Val Loss: 0.2086 Acc: 0.9227                                            \n",
      "Epoch 034 | Train Loss: 0.1096 Acc: 0.9576 | Val Loss: 0.2023 Acc: 0.9257                                            \n",
      "Epoch 035 | Train Loss: 0.1113 Acc: 0.9591 | Val Loss: 0.1786 Acc: 0.9360                                            \n",
      "Epoch 036 | Train Loss: 0.1030 Acc: 0.9603 | Val Loss: 0.1945 Acc: 0.9306                                            \n",
      "Epoch 037 | Train Loss: 0.1057 Acc: 0.9579 | Val Loss: 0.2041 Acc: 0.9300                                            \n",
      "Epoch 038 | Train Loss: 0.0847 Acc: 0.9657 | Val Loss: 0.1835 Acc: 0.9366                                            \n",
      "Epoch 039 | Train Loss: 0.0903 Acc: 0.9659 | Val Loss: 0.1874 Acc: 0.9360                                            \n",
      "Epoch 040 | Train Loss: 0.0899 Acc: 0.9644 | Val Loss: 0.1742 Acc: 0.9360                                            \n",
      "Epoch 041 | Train Loss: 0.0924 Acc: 0.9633 | Val Loss: 0.1598 Acc: 0.9444                                            \n",
      "Epoch 042 | Train Loss: 0.0813 Acc: 0.9672 | Val Loss: 0.2040 Acc: 0.9390                                            \n",
      "Epoch 043 | Train Loss: 0.0776 Acc: 0.9715 | Val Loss: 0.1863 Acc: 0.9396                                            \n",
      "Epoch 044 | Train Loss: 0.0733 Acc: 0.9746 | Val Loss: 0.2821 Acc: 0.9149                                            \n",
      "Epoch 045 | Train Loss: 0.0809 Acc: 0.9698 | Val Loss: 0.2337 Acc: 0.9312                                            \n",
      "Epoch 046 | Train Loss: 0.0769 Acc: 0.9733 | Val Loss: 0.2059 Acc: 0.9251                                            \n",
      "Epoch 047 | Train Loss: 0.0752 Acc: 0.9693 | Val Loss: 0.1603 Acc: 0.9408                                            \n",
      "Epoch 048 | Train Loss: 0.0713 Acc: 0.9746 | Val Loss: 0.1582 Acc: 0.9450                                            \n",
      "Epoch 049 | Train Loss: 0.0733 Acc: 0.9748 | Val Loss: 0.1771 Acc: 0.9414                                            \n",
      "Epoch 050 | Train Loss: 0.0673 Acc: 0.9740 | Val Loss: 0.1522 Acc: 0.9481                                            \n",
      "Epoch 051 | Train Loss: 0.0637 Acc: 0.9755 | Val Loss: 0.2376 Acc: 0.9245                                            \n",
      "Epoch 052 | Train Loss: 0.0612 Acc: 0.9775 | Val Loss: 0.1769 Acc: 0.9463                                            \n",
      "Epoch 053 | Train Loss: 0.0647 Acc: 0.9766 | Val Loss: 0.1652 Acc: 0.9481                                            \n",
      "Epoch 054 | Train Loss: 0.0618 Acc: 0.9781 | Val Loss: 0.1795 Acc: 0.9378                                            \n",
      "Epoch 055 | Train Loss: 0.0714 Acc: 0.9772 | Val Loss: 0.1821 Acc: 0.9354                                            \n",
      "Epoch 056 | Train Loss: 0.0635 Acc: 0.9755 | Val Loss: 0.1433 Acc: 0.9511                                            \n",
      "Epoch 057 | Train Loss: 0.0608 Acc: 0.9804 | Val Loss: 0.1433 Acc: 0.9505                                            \n",
      "Epoch 058 | Train Loss: 0.0484 Acc: 0.9829 | Val Loss: 0.1378 Acc: 0.9577                                            \n",
      "Epoch 059 | Train Loss: 0.0529 Acc: 0.9786 | Val Loss: 0.1726 Acc: 0.9499                                            \n",
      "Epoch 060 | Train Loss: 0.0582 Acc: 0.9784 | Val Loss: 0.1575 Acc: 0.9475                                            \n",
      "100%|| 40/40 [26:36<00:00, 39.90s/trial, best loss: 0.1197136838151061]\n",
      "Best (raw indices): {'batch_size': np.int64(1), 'cnn_dense': np.int64(2), 'cnn_dropout': np.float64(0.4638385183857614), 'cnn_kernel_size_1': np.int64(0), 'cnn_kernels_1': np.int64(2), 'cnn_kernels_2': np.int64(2), 'learning_rate': np.float64(0.0017830677008644053), 'lstm_dense': np.int64(2), 'lstm_hidden_size': np.int64(3), 'lstm_layers': np.int64(0), 'optimizer': np.int64(1)}\n",
      "Best (interpreted): {'batch_size': 32, 'cnn_dense': 128, 'cnn_dropout': np.float64(0.4638385183857614), 'cnn_kernel_size_1': 3, 'cnn_kernels_1': 48, 'cnn_kernels_2': 64, 'learning_rate': np.float64(0.0017830677008644053), 'lstm_dense': 128, 'lstm_hidden_size': 128, 'lstm_layers': 1, 'optimizer': 'rmsprop'}\n"
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "\n",
    "print(\"Starting TPE search...\")\n",
    "t0 = time.time()\n",
    "best = fmin(\n",
    "    fn=objective,\n",
    "    space=space,\n",
    "    algo=tpe.suggest,\n",
    "    max_evals=40,   # increase for more thorough search\n",
    "    trials=trials\n",
    ")\n",
    "\n",
    "print(\"Best hyperparameters:\", best)\n",
    "t1 = time.time()\n",
    "print(f\"TPE search finished in {(t1 - t0):.2f} seconds\")\n",
    "\n",
    "print(\"Best (raw indices):\", best)\n",
    "# Convert choice indices back to values for readability:\n",
    "def choice_value(key, val):\n",
    "    mapping = {\n",
    "        'cnn_kernels_1': [16, 32, 48, 64],\n",
    "        'cnn_kernel_size_1': [3, 5],\n",
    "        'cnn_kernels_2': [16, 32, 64, 96],\n",
    "        'cnn_dense': [32, 64, 128, 256],\n",
    "        'lstm_hidden_size': [32, 64, 96, 128],\n",
    "        'lstm_layers': [1, 2, 3],\n",
    "        'lstm_dense': [32, 64, 128, 256],\n",
    "        'optimizer': ['adam', 'rmsprop', 'sgd'],\n",
    "        'batch_size': [16, 32, 36, 48, 64]\n",
    "    }\n",
    "    return mapping[key][int(val)] if key in mapping else val\n",
    "\n",
    "readable = {k: choice_value(k, v) if k in ['cnn_kernels_1','cnn_kernel_size_1','cnn_kernels_2',\n",
    "                                           'cnn_dense','lstm_hidden_size','lstm_layers',\n",
    "                                           'lstm_dense','optimizer','batch_size'] else v\n",
    "            for k,v in best.items()}\n",
    "print(\"Best (interpreted):\", readable)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "615d1433-0cbd-4ce1-909b-d3a368a6e485",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (6623, 77, 19, 1)\n",
      "Epoch 001 | Train Loss: 0.6859 Acc: 0.5531 | Val Loss: 0.6800 Acc: 0.5984\n",
      "Epoch 002 | Train Loss: 0.6723 Acc: 0.5890 | Val Loss: 0.6500 Acc: 0.6310\n",
      "Epoch 003 | Train Loss: 0.6410 Acc: 0.6425 | Val Loss: 0.6201 Acc: 0.6588\n",
      "Epoch 004 | Train Loss: 0.6176 Acc: 0.6814 | Val Loss: 0.5913 Acc: 0.6806\n",
      "Epoch 005 | Train Loss: 0.5886 Acc: 0.7048 | Val Loss: 0.5590 Acc: 0.7228\n",
      "Epoch 006 | Train Loss: 0.5778 Acc: 0.7142 | Val Loss: 0.5381 Acc: 0.7240\n",
      "Epoch 007 | Train Loss: 0.5718 Acc: 0.7202 | Val Loss: 0.5767 Acc: 0.7023\n",
      "Epoch 008 | Train Loss: 0.5554 Acc: 0.7321 | Val Loss: 0.5426 Acc: 0.7264\n",
      "Epoch 009 | Train Loss: 0.5394 Acc: 0.7444 | Val Loss: 0.5107 Acc: 0.7536\n",
      "Epoch 010 | Train Loss: 0.5310 Acc: 0.7420 | Val Loss: 0.4874 Acc: 0.7729\n",
      "Epoch 011 | Train Loss: 0.5131 Acc: 0.7528 | Val Loss: 0.5229 Acc: 0.7464\n",
      "Epoch 012 | Train Loss: 0.5039 Acc: 0.7675 | Val Loss: 0.4552 Acc: 0.7820\n",
      "Epoch 013 | Train Loss: 0.4877 Acc: 0.7717 | Val Loss: 0.4456 Acc: 0.7953\n",
      "Epoch 014 | Train Loss: 0.4739 Acc: 0.7771 | Val Loss: 0.4315 Acc: 0.7935\n",
      "Epoch 015 | Train Loss: 0.4668 Acc: 0.7880 | Val Loss: 0.4245 Acc: 0.8007\n",
      "Epoch 016 | Train Loss: 0.4529 Acc: 0.7912 | Val Loss: 0.4142 Acc: 0.7965\n",
      "Epoch 017 | Train Loss: 0.4461 Acc: 0.7913 | Val Loss: 0.3904 Acc: 0.8315\n",
      "Epoch 018 | Train Loss: 0.4266 Acc: 0.8070 | Val Loss: 0.3922 Acc: 0.8237\n",
      "Epoch 019 | Train Loss: 0.4171 Acc: 0.8054 | Val Loss: 0.3743 Acc: 0.8484\n",
      "Epoch 020 | Train Loss: 0.4011 Acc: 0.8255 | Val Loss: 0.3401 Acc: 0.8527\n",
      "Epoch 021 | Train Loss: 0.3967 Acc: 0.8246 | Val Loss: 0.3530 Acc: 0.8412\n",
      "Epoch 022 | Train Loss: 0.3828 Acc: 0.8268 | Val Loss: 0.3345 Acc: 0.8575\n",
      "Epoch 023 | Train Loss: 0.3640 Acc: 0.8393 | Val Loss: 0.3195 Acc: 0.8696\n",
      "Epoch 024 | Train Loss: 0.3587 Acc: 0.8460 | Val Loss: 0.3042 Acc: 0.8762\n",
      "Epoch 025 | Train Loss: 0.3501 Acc: 0.8549 | Val Loss: 0.2941 Acc: 0.8847\n",
      "Epoch 026 | Train Loss: 0.3431 Acc: 0.8555 | Val Loss: 0.2926 Acc: 0.8816\n",
      "Epoch 027 | Train Loss: 0.3223 Acc: 0.8685 | Val Loss: 0.2825 Acc: 0.8822\n",
      "Epoch 028 | Train Loss: 0.3213 Acc: 0.8673 | Val Loss: 0.2811 Acc: 0.8810\n",
      "Epoch 029 | Train Loss: 0.3117 Acc: 0.8698 | Val Loss: 0.2681 Acc: 0.8883\n",
      "Epoch 030 | Train Loss: 0.3030 Acc: 0.8777 | Val Loss: 0.2810 Acc: 0.8841\n",
      "Epoch 031 | Train Loss: 0.3024 Acc: 0.8798 | Val Loss: 0.3229 Acc: 0.8605\n",
      "Epoch 032 | Train Loss: 0.2884 Acc: 0.8801 | Val Loss: 0.2867 Acc: 0.8756\n",
      "Epoch 033 | Train Loss: 0.2810 Acc: 0.8818 | Val Loss: 0.2381 Acc: 0.9118\n",
      "Epoch 034 | Train Loss: 0.2755 Acc: 0.8890 | Val Loss: 0.2352 Acc: 0.9016\n",
      "Epoch 035 | Train Loss: 0.2632 Acc: 0.8958 | Val Loss: 0.2282 Acc: 0.9070\n",
      "Epoch 036 | Train Loss: 0.2644 Acc: 0.8919 | Val Loss: 0.2392 Acc: 0.9052\n",
      "Epoch 037 | Train Loss: 0.2519 Acc: 0.8996 | Val Loss: 0.2278 Acc: 0.9064\n",
      "Epoch 038 | Train Loss: 0.2527 Acc: 0.8991 | Val Loss: 0.2249 Acc: 0.9118\n",
      "Epoch 039 | Train Loss: 0.2459 Acc: 0.9064 | Val Loss: 0.2116 Acc: 0.9203\n",
      "Epoch 040 | Train Loss: 0.2479 Acc: 0.9062 | Val Loss: 0.2593 Acc: 0.8901\n",
      "Epoch 041 | Train Loss: 0.2440 Acc: 0.9040 | Val Loss: 0.2174 Acc: 0.9143\n",
      "Epoch 042 | Train Loss: 0.2283 Acc: 0.9100 | Val Loss: 0.2305 Acc: 0.9088\n",
      "Epoch 043 | Train Loss: 0.2269 Acc: 0.9115 | Val Loss: 0.2284 Acc: 0.8973\n",
      "Epoch 044 | Train Loss: 0.2184 Acc: 0.9154 | Val Loss: 0.2071 Acc: 0.9149\n",
      "Epoch 045 | Train Loss: 0.2151 Acc: 0.9162 | Val Loss: 0.1907 Acc: 0.9300\n",
      "Epoch 046 | Train Loss: 0.2114 Acc: 0.9197 | Val Loss: 0.2156 Acc: 0.9155\n",
      "Epoch 047 | Train Loss: 0.2076 Acc: 0.9224 | Val Loss: 0.2043 Acc: 0.9263\n",
      "Epoch 048 | Train Loss: 0.2064 Acc: 0.9188 | Val Loss: 0.2084 Acc: 0.9191\n",
      "Epoch 049 | Train Loss: 0.2119 Acc: 0.9171 | Val Loss: 0.1909 Acc: 0.9257\n",
      "Epoch 050 | Train Loss: 0.1921 Acc: 0.9241 | Val Loss: 0.2146 Acc: 0.9185\n",
      "Epoch 051 | Train Loss: 0.1989 Acc: 0.9277 | Val Loss: 0.1796 Acc: 0.9336\n",
      "Epoch 052 | Train Loss: 0.1985 Acc: 0.9251 | Val Loss: 0.1787 Acc: 0.9324\n",
      "Epoch 053 | Train Loss: 0.1863 Acc: 0.9292 | Val Loss: 0.2031 Acc: 0.9197\n",
      "Epoch 054 | Train Loss: 0.1876 Acc: 0.9277 | Val Loss: 0.1776 Acc: 0.9312\n",
      "Epoch 055 | Train Loss: 0.1815 Acc: 0.9321 | Val Loss: 0.1782 Acc: 0.9324\n",
      "Epoch 056 | Train Loss: 0.1725 Acc: 0.9387 | Val Loss: 0.1890 Acc: 0.9245\n",
      "Epoch 057 | Train Loss: 0.1807 Acc: 0.9310 | Val Loss: 0.1937 Acc: 0.9251\n",
      "Epoch 058 | Train Loss: 0.1739 Acc: 0.9354 | Val Loss: 0.1708 Acc: 0.9354\n",
      "Epoch 059 | Train Loss: 0.1684 Acc: 0.9390 | Val Loss: 0.1652 Acc: 0.9402\n",
      "Epoch 060 | Train Loss: 0.1748 Acc: 0.9337 | Val Loss: 0.1700 Acc: 0.9336\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "frequency_count = len(df['Frequency'].unique())\n",
    "window_count = len(df['Window'].unique())\n",
    "numeric_df = df.drop(['ID', 'Window'], axis=1)\n",
    "\n",
    "# shape: (windows, freqs, features)\n",
    "full_ndarray = numeric_df.values.reshape((window_count, frequency_count, numeric_df.shape[1]))\n",
    "\n",
    "X = full_ndarray[:, :, 2:]     # drop ID/Class columns\n",
    "y = full_ndarray[:, 0, 0]      # class label is repeated across freq rows\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y)\n",
    "\n",
    "# Add channel dimension (N, 1, freq, electrodes)\n",
    "X_train = X_train[..., np.newaxis]   # (N, freq, electrodes, 1)\n",
    "X_test  = X_test[...,  np.newaxis]\n",
    "\n",
    "# Standardize across the entire dataset\n",
    "scaler = StandardScaler()\n",
    "X_train_flat = X_train.reshape(-1, X_train.shape[-1])\n",
    "X_test_flat  = X_test.reshape(-1, X_test.shape[-1])\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train_flat)\n",
    "X_test_scaled  = scaler.transform(X_test_flat)\n",
    "\n",
    "X_train = X_train_scaled.reshape(X_train.shape)\n",
    "X_test  = X_test_scaled.reshape(X_test.shape)\n",
    "\n",
    "print(\"Train shape:\", X_train.shape)  # (N, freq, electrodes, 1)\n",
    "\n",
    "train_ds = EEGDataset(X_train, y_train)\n",
    "test_ds  = EEGDataset(X_test,  y_test)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=36, shuffle=True)\n",
    "test_loader  = DataLoader(test_ds, batch_size=36, shuffle=False)\n",
    "\n",
    "device = \"cuda\"\n",
    "params = {'batch_size': 36, 'cnn_dense': 64, 'cnn_dropout': 0.5840618673633665, 'cnn_kernel_size_1': 5, 'cnn_kernels_1': 48, 'cnn_kernels_2': 64, 'learning_rate': 0.0014153310678003813, 'lstm_dense': 32, 'lstm_hidden_size': 32, 'lstm_layers': 2, 'optimizer': 'rmsprop'}\n",
    "model = EEG_CNN_LSTM_HPO(\n",
    "    cnn_kernels_1=params['cnn_kernels_1'],\n",
    "    cnn_kernel_size_1=params['cnn_kernel_size_1'],\n",
    "    cnn_kernels_2=params['cnn_kernels_2'],\n",
    "    cnn_dropout=float(params['cnn_dropout']),\n",
    "    cnn_dense=params['cnn_dense'],\n",
    "    lstm_hidden_size=params['lstm_hidden_size'],\n",
    "    lstm_layers=params['lstm_layers'],\n",
    "    lstm_dense=params['lstm_dense'],\n",
    "    dropout=float(params['cnn_dropout']),  # use cnn_dropout as a simple shared dropout param\n",
    "    num_classes=2\n",
    ").to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "if params['optimizer'] == 'adam':\n",
    "    optimizer = optim.Adam(model.parameters(), lr=params['learning_rate'], weight_decay=1e-4)\n",
    "elif params['optimizer'] == 'rmsprop':\n",
    "    optimizer = optim.RMSprop(model.parameters(), lr=params['learning_rate'], weight_decay=1e-4)\n",
    "else:\n",
    "    optimizer = optim.SGD(model.parameters(), lr=params['learning_rate'], momentum=0.9, weight_decay=1e-4)\n",
    "    \n",
    "# Train with modest epochs; early stopping inside fit handles rest\n",
    "history = model.fit(\n",
    "    train_loader=train_loader,\n",
    "    val_loader=test_loader,\n",
    "    epochs=60,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    device=device,\n",
    "    patience=10,\n",
    "    is_verbose=True\n",
    ")\n",
    "\n",
    "model.eval()\n",
    "all_preds, all_labels = [], []\n",
    "with torch.no_grad():\n",
    "    for xb, yb in test_loader:\n",
    "        xb = xb.to(device)\n",
    "        preds = model(xb).argmax(1).cpu().numpy()\n",
    "        all_preds.append(preds)\n",
    "        all_labels.append(yb.numpy())\n",
    "\n",
    "all_preds = np.concatenate(all_preds)\n",
    "all_labels = np.concatenate(all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7d371cee-08f6-46f5-86b2-c78c3f74662a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Accuracy: 0.9335748792270532\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94       925\n",
      "           1       0.92      0.92      0.92       731\n",
      "\n",
      "    accuracy                           0.93      1656\n",
      "   macro avg       0.93      0.93      0.93      1656\n",
      "weighted avg       0.93      0.93      0.93      1656\n",
      "\n",
      "[[870  55]\n",
      " [ 55 676]]\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "all_preds, all_labels = [], []\n",
    "with torch.no_grad():\n",
    "    for xb, yb in test_loader:\n",
    "        xb = xb.to(device)\n",
    "        preds = model(xb).argmax(1).cpu().numpy()\n",
    "        all_preds.append(preds)\n",
    "        all_labels.append(yb.numpy())\n",
    "\n",
    "all_preds = np.concatenate(all_preds)\n",
    "all_labels = np.concatenate(all_labels)\n",
    "\n",
    "print(\"\\nTest Accuracy:\", accuracy_score(all_labels, all_preds))\n",
    "print(classification_report(all_labels, all_preds))\n",
    "print(confusion_matrix(all_labels, all_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3b0f300f-c2d2-467d-bde3-1de67c9393fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history['train_accs'], label='Training Accuracy')\n",
    "plt.plot(history['val_accs'], label='Validation Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history['train_losses'], label='Training Loss')\n",
    "plt.plot(history['val_losses'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "13f235c3-685c-446b-aad0-49c5e74d9923",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(df, scaler, is_train=False, batch_size=36):\n",
    "    frequency_count = len(df['Frequency'].unique())\n",
    "    window_count = len(df['Window'].unique())\n",
    "    numeric_df = df.drop(['ID', 'Window'], axis=1)\n",
    "    \n",
    "    # shape: (windows, freqs, features)\n",
    "    full_ndarray = numeric_df.values.reshape((window_count, frequency_count, numeric_df.shape[1]))\n",
    "    \n",
    "    X = full_ndarray[:, :, 2:]     # drop ID/Class columns\n",
    "    y = full_ndarray[:, 0, 0]      # class label is repeated across freq rows\n",
    "\n",
    "    # Add channel dimension (N, 1, freq, electrodes)\n",
    "    X = X[..., np.newaxis]   # (N, freq, electrodes, 1)\n",
    "    \n",
    "    # Standardize across the entire dataset\n",
    "    X_flat = X.reshape(-1, X.shape[-1])\n",
    "    if is_train:\n",
    "        scaler.fit(X_flat)\n",
    "\n",
    "    X_scaled = scaler.transform(X_flat)\n",
    "    X = X_scaled.reshape(X.shape)\n",
    "    \n",
    "    return DataLoader(EEGDataset(X, y),\n",
    "                      batch_size=batch_size,\n",
    "                      shuffle=is_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "595fcf6e-e340-40f9-aa46-0293e8043350",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overfitting detected\n",
      "Fold Accuracy: 0.2037037037037037\n",
      "Overfitting detected\n",
      "Fold Accuracy: 0.582089552238806\n",
      "Overfitting detected\n",
      "Fold Accuracy: 0.6119402985074627\n",
      "Overfitting detected\n",
      "Fold Accuracy: 0.41916167664670656\n",
      "Early stopping triggered.\n",
      "Fold Accuracy: 0.9139784946236559\n",
      "Overfitting detected\n",
      "Fold Accuracy: 0.6875\n",
      "Overfitting detected\n",
      "Fold Accuracy: 0.6292134831460674\n",
      "Overfitting detected\n",
      "Fold Accuracy: 0.7391304347826086\n",
      "Overfitting detected\n",
      "Fold Accuracy: 0.36496350364963503\n",
      "Overfitting detected\n",
      "Fold Accuracy: 0.6507936507936508\n",
      "Overfitting detected\n",
      "Fold Accuracy: 0.34782608695652173\n",
      "Overfitting detected\n",
      "Fold Accuracy: 0.6349206349206349\n",
      "Overfitting detected\n",
      "Fold Accuracy: 0.2702702702702703\n",
      "Overfitting detected\n",
      "Fold Accuracy: 0.43243243243243246\n",
      "Overfitting detected\n",
      "Fold Accuracy: 0.6698113207547169\n",
      "Overfitting detected\n",
      "Fold Accuracy: 0.3978494623655914\n",
      "Overfitting detected\n",
      "Fold Accuracy: 0.012048192771084338\n",
      "Overfitting detected\n",
      "Fold Accuracy: 0.13636363636363635\n",
      "Overfitting detected\n",
      "Fold Accuracy: 0.7391304347826086\n",
      "Overfitting detected\n",
      "Fold Accuracy: 0.5752212389380531\n",
      "Overfitting detected\n",
      "Fold Accuracy: 0.0\n",
      "Overfitting detected\n",
      "Fold Accuracy: 0.5344827586206896\n",
      "Overfitting detected\n",
      "Fold Accuracy: 0.10606060606060606\n",
      "Overfitting detected\n",
      "Fold Accuracy: 0.4857142857142857\n",
      "Overfitting detected\n",
      "Fold Accuracy: 0.5578947368421052\n",
      "Overfitting detected\n",
      "Fold Accuracy: 0.5\n",
      "Overfitting detected\n",
      "Fold Accuracy: 0.36923076923076925\n",
      "Overfitting detected\n",
      "Fold Accuracy: 0.4025974025974026\n",
      "Overfitting detected\n",
      "Fold Accuracy: 0.29850746268656714\n",
      "Overfitting detected\n",
      "Fold Accuracy: 0.6166666666666667\n",
      "Overfitting detected\n",
      "Fold Accuracy: 0.203125\n",
      "Overfitting detected\n",
      "Fold Accuracy: 0.7291666666666666\n",
      "Overfitting detected\n",
      "Fold Accuracy: 0.575\n",
      "Overfitting detected\n",
      "Fold Accuracy: 0.5915492957746479\n",
      "Overfitting detected\n",
      "Fold Accuracy: 0.288135593220339\n",
      "Overfitting detected\n",
      "Fold Accuracy: 0.5686274509803921\n",
      "Overfitting detected\n",
      "Fold Accuracy: 0.49333333333333335\n",
      "Overfitting detected\n",
      "Fold Accuracy: 0.3541666666666667\n",
      "Early stopping triggered.\n",
      "Fold Accuracy: 0.9487179487179487\n",
      "Overfitting detected\n",
      "Fold Accuracy: 0.4675324675324675\n",
      "Overfitting detected\n",
      "Fold Accuracy: 0.09401709401709402\n",
      "Early stopping triggered.\n",
      "Fold Accuracy: 1.0\n",
      "Overfitting detected\n",
      "Fold Accuracy: 0.6097560975609756\n",
      "Overfitting detected\n",
      "Fold Accuracy: 0.3619047619047619\n",
      "Overfitting detected\n",
      "Fold Accuracy: 0.4074074074074074\n",
      "Overfitting detected\n",
      "Fold Accuracy: 0.6710526315789473\n",
      "Overfitting detected\n",
      "Fold Accuracy: 0.7803030303030303\n",
      "Overfitting detected\n",
      "Fold Accuracy: 0.29411764705882354\n",
      "Overfitting detected\n",
      "Fold Accuracy: 0.02702702702702703\n",
      "Overfitting detected\n",
      "Fold Accuracy: 0.5960264900662252\n",
      "Overfitting detected\n",
      "Fold Accuracy: 0.573170731707317\n",
      "Overfitting detected\n",
      "Fold Accuracy: 0.37735849056603776\n",
      "Overfitting detected\n",
      "Fold Accuracy: 0.8205128205128205\n",
      "Overfitting detected\n",
      "Fold Accuracy: 0.49295774647887325\n",
      "Overfitting detected\n",
      "Fold Accuracy: 0.6\n",
      "Overfitting detected\n",
      "Fold Accuracy: 0.24175824175824176\n",
      "Overfitting detected\n",
      "Fold Accuracy: 0.25757575757575757\n",
      "Overfitting detected\n",
      "Fold Accuracy: 0.38961038961038963\n",
      "Early stopping triggered.\n",
      "Fold Accuracy: 0.7796610169491526\n",
      "Overfitting detected\n",
      "Fold Accuracy: 0.3023255813953488\n",
      "Overfitting detected\n",
      "Fold Accuracy: 0.4805194805194805\n",
      "Overfitting detected\n",
      "Fold Accuracy: 0.5263157894736842\n",
      "Overfitting detected\n",
      "Fold Accuracy: 0.4794520547945205\n",
      "Overfitting detected\n",
      "Fold Accuracy: 0.7377049180327869\n",
      "Early stopping triggered.\n",
      "Fold Accuracy: 0.9206349206349206\n",
      "Overfitting detected\n",
      "Fold Accuracy: 0.3448275862068966\n",
      "Early stopping triggered.\n",
      "Fold Accuracy: 0.9672131147540983\n",
      "Early stopping triggered.\n",
      "Fold Accuracy: 0.9661016949152542\n",
      "Overfitting detected\n",
      "Fold Accuracy: 0.3\n",
      "Early stopping triggered.\n",
      "Fold Accuracy: 0.9666666666666667\n",
      "Early stopping triggered.\n",
      "Fold Accuracy: 1.0\n",
      "Overfitting detected\n",
      "Fold Accuracy: 0.06382978723404255\n",
      "Overfitting detected\n",
      "Fold Accuracy: 0.5625\n",
      "Overfitting detected\n",
      "Fold Accuracy: 0.0\n",
      "Overfitting detected\n",
      "Fold Accuracy: 0.16279069767441862\n",
      "Overfitting detected\n",
      "Fold Accuracy: 0.0975609756097561\n",
      "Overfitting detected\n",
      "Fold Accuracy: 0.08108108108108109\n",
      "Overfitting detected\n",
      "Fold Accuracy: 0.12195121951219512\n",
      "Overfitting detected\n",
      "Fold Accuracy: 0.1794871794871795\n",
      "Overfitting detected\n",
      "Fold Accuracy: 0.078125\n",
      "Overfitting detected\n",
      "Fold Accuracy: 0.0967741935483871\n",
      "Overfitting detected\n",
      "Fold Accuracy: 0.23333333333333334\n",
      "Overfitting detected\n",
      "Fold Accuracy: 0.16981132075471697\n",
      "Overfitting detected\n",
      "Fold Accuracy: 0.2328767123287671\n",
      "Overfitting detected\n",
      "Fold Accuracy: 0.4189189189189189\n",
      "Overfitting detected\n",
      "Fold Accuracy: 0.0\n",
      "Overfitting detected\n",
      "Fold Accuracy: 0.2222222222222222\n",
      "Overfitting detected\n",
      "Fold Accuracy: 0.23214285714285715\n",
      "Overfitting detected\n",
      "Fold Accuracy: 0.0\n",
      "Overfitting detected\n",
      "Fold Accuracy: 0.031746031746031744\n",
      "Overfitting detected\n",
      "Fold Accuracy: 0.5306122448979592\n",
      "Early stopping triggered.\n",
      "Fold Accuracy: 0.9191919191919192\n",
      "Overfitting detected\n",
      "Fold Accuracy: 0.6666666666666666\n",
      "Overfitting detected\n",
      "Fold Accuracy: 0.5217391304347826\n",
      "Early stopping triggered.\n",
      "Fold Accuracy: 0.9354838709677419\n",
      "Early stopping triggered.\n",
      "Fold Accuracy: 0.9636363636363636\n",
      "Early stopping triggered.\n",
      "Fold Accuracy: 1.0\n",
      "Overfitting detected\n",
      "Fold Accuracy: 0.32142857142857145\n",
      "Early stopping triggered.\n",
      "Fold Accuracy: 0.9761904761904762\n",
      "Overfitting detected\n",
      "Fold Accuracy: 0.78125\n",
      "Early stopping triggered.\n",
      "Fold Accuracy: 0.9473684210526315\n",
      "Overfitting detected\n",
      "Fold Accuracy: 0.17647058823529413\n",
      "Overfitting detected\n",
      "Fold Accuracy: 0.23404255319148937\n",
      "Overfitting detected\n",
      "Fold Accuracy: 0.045454545454545456\n",
      "Overfitting detected\n",
      "Fold Accuracy: 0.288135593220339\n",
      "Overfitting detected\n",
      "Fold Accuracy: 0.018518518518518517\n",
      "Overfitting detected\n",
      "Fold Accuracy: 0.4153846153846154\n",
      "Overfitting detected\n",
      "Fold Accuracy: 0.3375\n",
      "Overfitting detected\n",
      "Fold Accuracy: 0.038461538461538464\n",
      "Overfitting detected\n",
      "Fold Accuracy: 0.0\n",
      "Overfitting detected\n",
      "Fold Accuracy: 0.023529411764705882\n",
      "Overfitting detected\n",
      "Fold Accuracy: 0.22\n",
      "Overfitting detected\n",
      "Fold Accuracy: 0.23529411764705882\n",
      "Overfitting detected\n",
      "Fold Accuracy: 0.25675675675675674\n",
      "Overfitting detected\n",
      "Fold Accuracy: 0.0392156862745098\n",
      "Overfitting detected\n",
      "Fold Accuracy: 0.1744186046511628\n",
      "Overfitting detected\n",
      "Fold Accuracy: 0.04285714285714286\n",
      "Overfitting detected\n",
      "Fold Accuracy: 0.19318181818181818\n",
      "Overfitting detected\n",
      "Fold Accuracy: 0.15384615384615385\n",
      "Overfitting detected\n",
      "Fold Accuracy: 0.37894736842105264\n",
      "Overfitting detected\n",
      "Fold Accuracy: 0.29411764705882354\n",
      "\n",
      "LOSOCV Mean Accuracy: 0.4264  0.2888\n"
     ]
    }
   ],
   "source": [
    "unique_subjects = df['ID'].unique()\n",
    "params = readable\n",
    "accs = []\n",
    "batch_size = params['batch_size']\n",
    "\n",
    "for subj in unique_subjects:\n",
    "    scaler = StandardScaler()\n",
    "    train_loader = get_dataset(df[df['ID'] != subj], scaler, is_train=True, batch_size=batch_size)\n",
    "    val_loader  = get_dataset(df[df['ID'] == subj], scaler, is_train=False, batch_size=batch_size)\n",
    "\n",
    "    model = EEG_CNN_LSTM_HPO(\n",
    "        cnn_kernels_1=params['cnn_kernels_1'],\n",
    "        cnn_kernel_size_1=params['cnn_kernel_size_1'],\n",
    "        cnn_kernels_2=params['cnn_kernels_2'],\n",
    "        cnn_dropout=float(params['cnn_dropout']),\n",
    "        cnn_dense=params['cnn_dense'],\n",
    "        lstm_hidden_size=params['lstm_hidden_size'],\n",
    "        lstm_layers=params['lstm_layers'],\n",
    "        lstm_dense=params['lstm_dense'],\n",
    "        dropout=float(params['cnn_dropout']),  # use cnn_dropout as a simple shared dropout param\n",
    "        num_classes=2\n",
    "    ).to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    if params['optimizer'] == 'adam':\n",
    "        optimizer = optim.Adam(model.parameters(), lr=params['learning_rate'], weight_decay=1e-4)\n",
    "    elif params['optimizer'] == 'rmsprop':\n",
    "        optimizer = optim.RMSprop(model.parameters(), lr=params['learning_rate'], weight_decay=1e-4)\n",
    "    else:\n",
    "        optimizer = optim.SGD(model.parameters(), lr=params['learning_rate'], momentum=0.9, weight_decay=1e-4)\n",
    "\n",
    "    # Train with modest epochs; early stopping inside fit handles rest\n",
    "    history = model.fit(\n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader,\n",
    "        epochs=60,\n",
    "        criterion=criterion,\n",
    "        optimizer=optimizer,\n",
    "        device=device,\n",
    "        patience=10,\n",
    "        is_verbose=False\n",
    "    )\n",
    "\n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in val_loader:\n",
    "            xb = xb.to(device)\n",
    "            preds = model(xb).argmax(1).cpu().numpy()\n",
    "            all_preds.append(preds)\n",
    "            all_labels.append(yb.numpy())\n",
    "    \n",
    "    all_preds = np.concatenate(all_preds)\n",
    "    all_labels = np.concatenate(all_labels)\n",
    "    \n",
    "    acc = accuracy_score(all_labels, all_preds)\n",
    "    accs.append(acc)\n",
    "    print(\"Fold Accuracy:\", acc)\n",
    "\n",
    "print(f\"\\nLOSOCV Mean Accuracy: {np.mean(accs):.4f}  {np.std(accs):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5788aec-94bd-47d3-b88a-d0782dbd7801",
   "metadata": {},
   "source": [
    "### Particle Swarm Optimization (PSO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b6c4b1-5337-4d52-a547-884d7ced7604",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c456da-ef15-4316-aded-a56e3fb179f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "bounds = {\n",
    "    'cnn_kernels_1'    : [16, 64],\n",
    "    'cnn_kernel_size_1': [3, 5],\n",
    "    'cnn_kernels_2'    : [16, 96],\n",
    "    'cnn_dropout'      : [0.0, 0.7],\n",
    "    'cnn_dense'        : [32, 256],\n",
    "    'lstm_hidden_size' : [32, 128],\n",
    "    'lstm_layers'      : [1, 3],\n",
    "    'lstm_dense'       : [32, 256],\n",
    "    'learning_rate'    : [1e-4, 1e-2],\n",
    "    'batch_size'       : [16, 64]\n",
    "}\n",
    "\n",
    "# Convert keys to list for easy indexing\n",
    "keys = list(bounds.keys())\n",
    "dim = len(keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "8cb42405-c3a6-44b5-a618-dc7c780df8b7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001 | Train Loss: 0.6815 Acc: 0.5790 | Val Loss: 0.6760 Acc: 0.5924\n",
      "Epoch 002 | Train Loss: 0.6665 Acc: 0.6027 | Val Loss: 0.6529 Acc: 0.6051\n",
      "Epoch 003 | Train Loss: 0.6300 Acc: 0.6579 | Val Loss: 0.6077 Acc: 0.6860\n",
      "Epoch 004 | Train Loss: 0.5970 Acc: 0.6958 | Val Loss: 0.6013 Acc: 0.6812\n",
      "Epoch 005 | Train Loss: 0.5693 Acc: 0.7152 | Val Loss: 0.5753 Acc: 0.7126\n",
      "Epoch 006 | Train Loss: 0.5478 Acc: 0.7308 | Val Loss: 0.5617 Acc: 0.7234\n",
      "Epoch 007 | Train Loss: 0.5313 Acc: 0.7463 | Val Loss: 0.5524 Acc: 0.7168\n",
      "Epoch 008 | Train Loss: 0.5245 Acc: 0.7469 | Val Loss: 0.5401 Acc: 0.7289\n",
      "Epoch 009 | Train Loss: 0.5081 Acc: 0.7587 | Val Loss: 0.5206 Acc: 0.7385\n",
      "Epoch 010 | Train Loss: 0.4963 Acc: 0.7706 | Val Loss: 0.5134 Acc: 0.7482\n",
      "Epoch 011 | Train Loss: 0.4972 Acc: 0.7709 | Val Loss: 0.5037 Acc: 0.7536\n",
      "Epoch 012 | Train Loss: 0.4807 Acc: 0.7758 | Val Loss: 0.5039 Acc: 0.7591\n",
      "Epoch 013 | Train Loss: 0.4689 Acc: 0.7832 | Val Loss: 0.4929 Acc: 0.7645\n",
      "Epoch 014 | Train Loss: 0.4504 Acc: 0.7969 | Val Loss: 0.4836 Acc: 0.7627\n",
      "Epoch 015 | Train Loss: 0.4490 Acc: 0.7996 | Val Loss: 0.4752 Acc: 0.7736\n",
      "Epoch 016 | Train Loss: 0.4314 Acc: 0.8060 | Val Loss: 0.4652 Acc: 0.7868\n",
      "Epoch 017 | Train Loss: 0.4199 Acc: 0.8101 | Val Loss: 0.4541 Acc: 0.7899\n",
      "Epoch 018 | Train Loss: 0.3959 Acc: 0.8233 | Val Loss: 0.4455 Acc: 0.7941\n",
      "Epoch 019 | Train Loss: 0.3840 Acc: 0.8250 | Val Loss: 0.4735 Acc: 0.7778\n",
      "Epoch 020 | Train Loss: 0.3628 Acc: 0.8398 | Val Loss: 0.4082 Acc: 0.8110\n",
      "Epoch 021 | Train Loss: 0.3468 Acc: 0.8477 | Val Loss: 0.3764 Acc: 0.8430\n",
      "Epoch 022 | Train Loss: 0.3285 Acc: 0.8579 | Val Loss: 0.3828 Acc: 0.8194\n",
      "Epoch 023 | Train Loss: 0.3079 Acc: 0.8700 | Val Loss: 0.4253 Acc: 0.8092\n",
      "Epoch 024 | Train Loss: 0.2936 Acc: 0.8745 | Val Loss: 0.3406 Acc: 0.8563\n",
      "Epoch 025 | Train Loss: 0.2794 Acc: 0.8846 | Val Loss: 0.4021 Acc: 0.8128\n",
      "Epoch 026 | Train Loss: 0.2637 Acc: 0.8920 | Val Loss: 0.3149 Acc: 0.8665\n",
      "Epoch 027 | Train Loss: 0.2483 Acc: 0.8967 | Val Loss: 0.3203 Acc: 0.8617\n",
      "Epoch 028 | Train Loss: 0.2299 Acc: 0.9068 | Val Loss: 0.2811 Acc: 0.8901\n",
      "Epoch 029 | Train Loss: 0.2216 Acc: 0.9103 | Val Loss: 0.3114 Acc: 0.8744\n",
      "Epoch 030 | Train Loss: 0.2190 Acc: 0.9083 | Val Loss: 0.2637 Acc: 0.8925\n",
      "Epoch 031 | Train Loss: 0.2104 Acc: 0.9154 | Val Loss: 0.2740 Acc: 0.8871\n",
      "Epoch 032 | Train Loss: 0.1763 Acc: 0.9284 | Val Loss: 0.2574 Acc: 0.9004\n",
      "Epoch 033 | Train Loss: 0.1749 Acc: 0.9302 | Val Loss: 0.2575 Acc: 0.9016\n",
      "Epoch 034 | Train Loss: 0.1683 Acc: 0.9346 | Val Loss: 0.2475 Acc: 0.9046\n",
      "Epoch 035 | Train Loss: 0.1588 Acc: 0.9369 | Val Loss: 0.2395 Acc: 0.9070\n",
      "Epoch 036 | Train Loss: 0.1464 Acc: 0.9392 | Val Loss: 0.2487 Acc: 0.9082\n",
      "Epoch 037 | Train Loss: 0.1521 Acc: 0.9398 | Val Loss: 0.2570 Acc: 0.9058\n",
      "Epoch 038 | Train Loss: 0.1411 Acc: 0.9472 | Val Loss: 0.2950 Acc: 0.8877\n",
      "Epoch 039 | Train Loss: 0.1349 Acc: 0.9455 | Val Loss: 0.2391 Acc: 0.9185\n",
      "Epoch 040 | Train Loss: 0.1257 Acc: 0.9509 | Val Loss: 0.2349 Acc: 0.9076\n",
      "Epoch 041 | Train Loss: 0.1314 Acc: 0.9496 | Val Loss: 0.2362 Acc: 0.9124\n",
      "Epoch 042 | Train Loss: 0.1137 Acc: 0.9579 | Val Loss: 0.2218 Acc: 0.9203\n",
      "Epoch 043 | Train Loss: 0.1192 Acc: 0.9529 | Val Loss: 0.2325 Acc: 0.9100\n",
      "Epoch 044 | Train Loss: 0.0999 Acc: 0.9613 | Val Loss: 0.2281 Acc: 0.9221\n",
      "Epoch 045 | Train Loss: 0.1105 Acc: 0.9579 | Val Loss: 0.2265 Acc: 0.9239\n",
      "Epoch 046 | Train Loss: 0.1056 Acc: 0.9565 | Val Loss: 0.1995 Acc: 0.9287\n",
      "Epoch 047 | Train Loss: 0.0982 Acc: 0.9623 | Val Loss: 0.2817 Acc: 0.9016\n",
      "Epoch 048 | Train Loss: 0.0915 Acc: 0.9642 | Val Loss: 0.2385 Acc: 0.9185\n",
      "Epoch 049 | Train Loss: 0.0891 Acc: 0.9650 | Val Loss: 0.2372 Acc: 0.9257\n",
      "Epoch 050 | Train Loss: 0.0924 Acc: 0.9629 | Val Loss: 0.2451 Acc: 0.9173\n",
      "Epoch 051 | Train Loss: 0.0888 Acc: 0.9660 | Val Loss: 0.2036 Acc: 0.9342\n",
      "Epoch 052 | Train Loss: 0.0769 Acc: 0.9709 | Val Loss: 0.2112 Acc: 0.9318\n",
      "Epoch 053 | Train Loss: 0.0898 Acc: 0.9675 | Val Loss: 0.1910 Acc: 0.9318\n",
      "Epoch 054 | Train Loss: 0.0806 Acc: 0.9704 | Val Loss: 0.1914 Acc: 0.9384\n",
      "Epoch 055 | Train Loss: 0.0698 Acc: 0.9739 | Val Loss: 0.1819 Acc: 0.9348\n",
      "Epoch 056 | Train Loss: 0.0728 Acc: 0.9724 | Val Loss: 0.2141 Acc: 0.9281\n",
      "Epoch 057 | Train Loss: 0.0666 Acc: 0.9754 | Val Loss: 0.1911 Acc: 0.9432\n",
      "Epoch 058 | Train Loss: 0.0720 Acc: 0.9751 | Val Loss: 0.2133 Acc: 0.9348\n",
      "Epoch 059 | Train Loss: 0.0719 Acc: 0.9724 | Val Loss: 0.2317 Acc: 0.9173\n",
      "Epoch 060 | Train Loss: 0.0732 Acc: 0.9712 | Val Loss: 0.1951 Acc: 0.9360\n",
      "Epoch 001 | Train Loss: 0.6890 Acc: 0.5562 | Val Loss: 0.6868 Acc: 0.5586\n",
      "Epoch 002 | Train Loss: 0.6874 Acc: 0.5582 | Val Loss: 0.6866 Acc: 0.5586\n",
      "Epoch 003 | Train Loss: 0.6868 Acc: 0.5582 | Val Loss: 0.6863 Acc: 0.5586\n",
      "Epoch 004 | Train Loss: 0.6869 Acc: 0.5582 | Val Loss: 0.6863 Acc: 0.5586\n",
      "Epoch 005 | Train Loss: 0.6868 Acc: 0.5582 | Val Loss: 0.6864 Acc: 0.5586\n",
      "Epoch 006 | Train Loss: 0.6871 Acc: 0.5582 | Val Loss: 0.6863 Acc: 0.5586\n",
      "Epoch 007 | Train Loss: 0.6867 Acc: 0.5582 | Val Loss: 0.6863 Acc: 0.5586\n",
      "Epoch 008 | Train Loss: 0.6867 Acc: 0.5582 | Val Loss: 0.6863 Acc: 0.5586\n",
      "Epoch 009 | Train Loss: 0.6867 Acc: 0.5582 | Val Loss: 0.6863 Acc: 0.5586\n",
      "Epoch 010 | Train Loss: 0.6867 Acc: 0.5582 | Val Loss: 0.6863 Acc: 0.5586\n",
      "Epoch 011 | Train Loss: 0.6866 Acc: 0.5582 | Val Loss: 0.6864 Acc: 0.5586\n",
      "Epoch 012 | Train Loss: 0.6863 Acc: 0.5582 | Val Loss: 0.6868 Acc: 0.5586\n",
      "Epoch 013 | Train Loss: 0.6866 Acc: 0.5582 | Val Loss: 0.6863 Acc: 0.5586\n",
      "Epoch 014 | Train Loss: 0.6865 Acc: 0.5582 | Val Loss: 0.6867 Acc: 0.5586\n",
      "Epoch 015 | Train Loss: 0.6866 Acc: 0.5582 | Val Loss: 0.6869 Acc: 0.5586\n",
      "Epoch 016 | Train Loss: 0.6865 Acc: 0.5582 | Val Loss: 0.6866 Acc: 0.5586\n",
      "Epoch 017 | Train Loss: 0.6866 Acc: 0.5582 | Val Loss: 0.6864 Acc: 0.5586\n",
      "Epoch 018 | Train Loss: 0.6867 Acc: 0.5582 | Val Loss: 0.6863 Acc: 0.5586\n",
      "Epoch 019 | Train Loss: 0.6867 Acc: 0.5582 | Val Loss: 0.6864 Acc: 0.5586\n",
      "Epoch 020 | Train Loss: 0.6866 Acc: 0.5582 | Val Loss: 0.6865 Acc: 0.5586\n",
      "Epoch 021 | Train Loss: 0.6867 Acc: 0.5582 | Val Loss: 0.6864 Acc: 0.5586\n",
      "Epoch 022 | Train Loss: 0.6868 Acc: 0.5582 | Val Loss: 0.6863 Acc: 0.5586\n",
      "Epoch 023 | Train Loss: 0.6867 Acc: 0.5582 | Val Loss: 0.6864 Acc: 0.5586\n",
      "Epoch 024 | Train Loss: 0.6866 Acc: 0.5582 | Val Loss: 0.6863 Acc: 0.5586\n",
      "Epoch 025 | Train Loss: 0.6867 Acc: 0.5565 | Val Loss: 0.6863 Acc: 0.5586\n",
      "Epoch 026 | Train Loss: 0.6868 Acc: 0.5582 | Val Loss: 0.6863 Acc: 0.5586\n",
      "Epoch 027 | Train Loss: 0.6865 Acc: 0.5582 | Val Loss: 0.6866 Acc: 0.5586\n",
      "Epoch 028 | Train Loss: 0.6867 Acc: 0.5582 | Val Loss: 0.6863 Acc: 0.5586\n",
      "Early stopping triggered.\n",
      "Epoch 001 | Train Loss: 0.6819 Acc: 0.5688 | Val Loss: 0.6738 Acc: 0.5864\n",
      "Epoch 002 | Train Loss: 0.6671 Acc: 0.6043 | Val Loss: 0.6637 Acc: 0.6039\n",
      "Epoch 003 | Train Loss: 0.6646 Acc: 0.6111 | Val Loss: 0.6614 Acc: 0.6105\n",
      "Epoch 004 | Train Loss: 0.6569 Acc: 0.6204 | Val Loss: 0.6576 Acc: 0.6165\n",
      "Epoch 005 | Train Loss: 0.6218 Acc: 0.6692 | Val Loss: 0.5881 Acc: 0.7023\n",
      "Epoch 006 | Train Loss: 0.5895 Acc: 0.6971 | Val Loss: 0.6000 Acc: 0.6793\n",
      "Epoch 007 | Train Loss: 0.5686 Acc: 0.7163 | Val Loss: 0.5562 Acc: 0.7240\n",
      "Epoch 008 | Train Loss: 0.5468 Acc: 0.7386 | Val Loss: 0.5434 Acc: 0.7198\n",
      "Epoch 009 | Train Loss: 0.5241 Acc: 0.7450 | Val Loss: 0.5002 Acc: 0.7536\n",
      "Epoch 010 | Train Loss: 0.5059 Acc: 0.7571 | Val Loss: 0.4974 Acc: 0.7585\n",
      "Epoch 011 | Train Loss: 0.4736 Acc: 0.7800 | Val Loss: 0.4920 Acc: 0.7536\n",
      "Epoch 012 | Train Loss: 0.4639 Acc: 0.7805 | Val Loss: 0.4558 Acc: 0.7711\n",
      "Epoch 013 | Train Loss: 0.4494 Acc: 0.7915 | Val Loss: 0.4480 Acc: 0.7766\n",
      "Epoch 014 | Train Loss: 0.4260 Acc: 0.8058 | Val Loss: 0.4482 Acc: 0.7850\n",
      "Epoch 015 | Train Loss: 0.4213 Acc: 0.8104 | Val Loss: 0.4260 Acc: 0.7983\n",
      "Epoch 016 | Train Loss: 0.3866 Acc: 0.8336 | Val Loss: 0.4089 Acc: 0.8019\n",
      "Epoch 017 | Train Loss: 0.3802 Acc: 0.8297 | Val Loss: 0.4227 Acc: 0.8043\n",
      "Epoch 018 | Train Loss: 0.3599 Acc: 0.8406 | Val Loss: 0.4196 Acc: 0.8080\n",
      "Epoch 019 | Train Loss: 0.3552 Acc: 0.8461 | Val Loss: 0.3491 Acc: 0.8388\n",
      "Epoch 020 | Train Loss: 0.3329 Acc: 0.8573 | Val Loss: 0.3496 Acc: 0.8502\n",
      "Epoch 021 | Train Loss: 0.3275 Acc: 0.8609 | Val Loss: 0.3295 Acc: 0.8508\n",
      "Epoch 022 | Train Loss: 0.3240 Acc: 0.8680 | Val Loss: 0.3376 Acc: 0.8563\n",
      "Epoch 023 | Train Loss: 0.3032 Acc: 0.8706 | Val Loss: 0.3433 Acc: 0.8442\n",
      "Epoch 024 | Train Loss: 0.2916 Acc: 0.8768 | Val Loss: 0.3221 Acc: 0.8605\n",
      "Epoch 025 | Train Loss: 0.2756 Acc: 0.8843 | Val Loss: 0.3108 Acc: 0.8605\n",
      "Epoch 026 | Train Loss: 0.2709 Acc: 0.8923 | Val Loss: 0.3029 Acc: 0.8696\n",
      "Epoch 027 | Train Loss: 0.2680 Acc: 0.8902 | Val Loss: 0.3088 Acc: 0.8641\n",
      "Epoch 028 | Train Loss: 0.2583 Acc: 0.8914 | Val Loss: 0.2723 Acc: 0.8901\n",
      "Epoch 029 | Train Loss: 0.2489 Acc: 0.9025 | Val Loss: 0.2806 Acc: 0.8853\n",
      "Epoch 030 | Train Loss: 0.2330 Acc: 0.9046 | Val Loss: 0.2771 Acc: 0.8829\n",
      "Epoch 031 | Train Loss: 0.2324 Acc: 0.9052 | Val Loss: 0.2663 Acc: 0.8961\n",
      "Epoch 032 | Train Loss: 0.2334 Acc: 0.9079 | Val Loss: 0.2536 Acc: 0.9010\n",
      "Epoch 033 | Train Loss: 0.2141 Acc: 0.9144 | Val Loss: 0.2644 Acc: 0.8865\n",
      "Epoch 034 | Train Loss: 0.2069 Acc: 0.9191 | Val Loss: 0.2930 Acc: 0.8810\n",
      "Epoch 035 | Train Loss: 0.2074 Acc: 0.9165 | Val Loss: 0.2413 Acc: 0.9124\n",
      "Epoch 036 | Train Loss: 0.2051 Acc: 0.9203 | Val Loss: 0.2388 Acc: 0.9082\n",
      "Epoch 037 | Train Loss: 0.1949 Acc: 0.9234 | Val Loss: 0.2706 Acc: 0.8955\n",
      "Epoch 038 | Train Loss: 0.1887 Acc: 0.9259 | Val Loss: 0.2278 Acc: 0.9118\n",
      "Epoch 039 | Train Loss: 0.1802 Acc: 0.9295 | Val Loss: 0.2233 Acc: 0.9197\n",
      "Epoch 040 | Train Loss: 0.1676 Acc: 0.9357 | Val Loss: 0.2551 Acc: 0.9040\n",
      "Epoch 041 | Train Loss: 0.1809 Acc: 0.9313 | Val Loss: 0.2197 Acc: 0.9173\n",
      "Epoch 042 | Train Loss: 0.1769 Acc: 0.9331 | Val Loss: 0.2834 Acc: 0.8877\n",
      "Epoch 043 | Train Loss: 0.1637 Acc: 0.9379 | Val Loss: 0.2273 Acc: 0.9124\n",
      "Epoch 044 | Train Loss: 0.1556 Acc: 0.9428 | Val Loss: 0.2985 Acc: 0.8865\n",
      "Epoch 045 | Train Loss: 0.1684 Acc: 0.9351 | Val Loss: 0.2221 Acc: 0.9130\n",
      "Epoch 046 | Train Loss: 0.1564 Acc: 0.9414 | Val Loss: 0.2198 Acc: 0.9215\n",
      "Epoch 047 | Train Loss: 0.1601 Acc: 0.9385 | Val Loss: 0.2669 Acc: 0.9046\n",
      "Epoch 048 | Train Loss: 0.1504 Acc: 0.9452 | Val Loss: 0.2695 Acc: 0.9106\n",
      "Epoch 049 | Train Loss: 0.1479 Acc: 0.9425 | Val Loss: 0.1976 Acc: 0.9233\n",
      "Epoch 050 | Train Loss: 0.1421 Acc: 0.9438 | Val Loss: 0.2250 Acc: 0.9173\n",
      "Epoch 051 | Train Loss: 0.1350 Acc: 0.9472 | Val Loss: 0.2213 Acc: 0.9239\n",
      "Epoch 052 | Train Loss: 0.1381 Acc: 0.9475 | Val Loss: 0.2112 Acc: 0.9197\n",
      "Epoch 053 | Train Loss: 0.1406 Acc: 0.9493 | Val Loss: 0.2002 Acc: 0.9203\n",
      "Epoch 054 | Train Loss: 0.1449 Acc: 0.9456 | Val Loss: 0.1884 Acc: 0.9348\n",
      "Epoch 055 | Train Loss: 0.1347 Acc: 0.9503 | Val Loss: 0.2114 Acc: 0.9293\n",
      "Epoch 056 | Train Loss: 0.1283 Acc: 0.9511 | Val Loss: 0.2282 Acc: 0.9227\n",
      "Epoch 057 | Train Loss: 0.1352 Acc: 0.9473 | Val Loss: 0.1872 Acc: 0.9287\n",
      "Epoch 058 | Train Loss: 0.1281 Acc: 0.9505 | Val Loss: 0.2033 Acc: 0.9185\n",
      "Epoch 059 | Train Loss: 0.1312 Acc: 0.9494 | Val Loss: 0.2158 Acc: 0.9221\n",
      "Epoch 060 | Train Loss: 0.1199 Acc: 0.9521 | Val Loss: 0.2480 Acc: 0.9143\n",
      "Epoch 001 | Train Loss: 0.6806 Acc: 0.5766 | Val Loss: 0.6661 Acc: 0.5990\n",
      "Epoch 002 | Train Loss: 0.6609 Acc: 0.6135 | Val Loss: 0.6688 Acc: 0.5954\n",
      "Epoch 003 | Train Loss: 0.6519 Acc: 0.6334 | Val Loss: 0.6407 Acc: 0.6534\n",
      "Epoch 004 | Train Loss: 0.6227 Acc: 0.6864 | Val Loss: 0.6380 Acc: 0.6546\n",
      "Epoch 005 | Train Loss: 0.6270 Acc: 0.6745 | Val Loss: 0.5913 Acc: 0.6993\n",
      "Epoch 006 | Train Loss: 0.5968 Acc: 0.7056 | Val Loss: 0.5769 Acc: 0.7083\n",
      "Epoch 007 | Train Loss: 0.5806 Acc: 0.7170 | Val Loss: 0.5591 Acc: 0.7150\n",
      "Epoch 008 | Train Loss: 0.5672 Acc: 0.7288 | Val Loss: 0.5629 Acc: 0.7192\n",
      "Epoch 009 | Train Loss: 0.5653 Acc: 0.7275 | Val Loss: 0.5610 Acc: 0.7192\n",
      "Epoch 010 | Train Loss: 0.5546 Acc: 0.7327 | Val Loss: 0.5444 Acc: 0.7264\n",
      "Epoch 011 | Train Loss: 0.5440 Acc: 0.7398 | Val Loss: 0.5334 Acc: 0.7271\n",
      "Epoch 012 | Train Loss: 0.5572 Acc: 0.7340 | Val Loss: 0.5325 Acc: 0.7343\n",
      "Epoch 013 | Train Loss: 0.5362 Acc: 0.7376 | Val Loss: 0.5215 Acc: 0.7349\n",
      "Epoch 014 | Train Loss: 0.5211 Acc: 0.7463 | Val Loss: 0.5242 Acc: 0.7470\n",
      "Epoch 015 | Train Loss: 0.5276 Acc: 0.7503 | Val Loss: 0.5132 Acc: 0.7391\n",
      "Epoch 016 | Train Loss: 0.5131 Acc: 0.7554 | Val Loss: 0.5097 Acc: 0.7349\n",
      "Epoch 017 | Train Loss: 0.5021 Acc: 0.7560 | Val Loss: 0.4870 Acc: 0.7494\n",
      "Epoch 018 | Train Loss: 0.5124 Acc: 0.7492 | Val Loss: 0.4855 Acc: 0.7488\n",
      "Epoch 019 | Train Loss: 0.4954 Acc: 0.7634 | Val Loss: 0.4788 Acc: 0.7645\n",
      "Epoch 020 | Train Loss: 0.4922 Acc: 0.7626 | Val Loss: 0.4910 Acc: 0.7524\n",
      "Epoch 021 | Train Loss: 0.4740 Acc: 0.7741 | Val Loss: 0.4696 Acc: 0.7675\n",
      "Epoch 022 | Train Loss: 0.4792 Acc: 0.7687 | Val Loss: 0.4799 Acc: 0.7440\n",
      "Epoch 023 | Train Loss: 0.4616 Acc: 0.7790 | Val Loss: 0.4465 Acc: 0.7736\n",
      "Epoch 024 | Train Loss: 0.4545 Acc: 0.7836 | Val Loss: 0.4604 Acc: 0.7609\n",
      "Epoch 025 | Train Loss: 0.4586 Acc: 0.7820 | Val Loss: 0.4584 Acc: 0.7657\n",
      "Epoch 026 | Train Loss: 0.4602 Acc: 0.7777 | Val Loss: 0.4448 Acc: 0.7760\n",
      "Epoch 027 | Train Loss: 0.4494 Acc: 0.7805 | Val Loss: 0.4284 Acc: 0.7905\n",
      "Epoch 028 | Train Loss: 0.4356 Acc: 0.7924 | Val Loss: 0.4526 Acc: 0.7742\n",
      "Epoch 029 | Train Loss: 0.4326 Acc: 0.7981 | Val Loss: 0.4254 Acc: 0.7941\n",
      "Epoch 030 | Train Loss: 0.4169 Acc: 0.8076 | Val Loss: 0.4151 Acc: 0.7929\n",
      "Epoch 031 | Train Loss: 0.4060 Acc: 0.8078 | Val Loss: 0.3857 Acc: 0.8164\n",
      "Epoch 032 | Train Loss: 0.4010 Acc: 0.8191 | Val Loss: 0.4042 Acc: 0.7929\n",
      "Epoch 033 | Train Loss: 0.4024 Acc: 0.8235 | Val Loss: 0.3783 Acc: 0.8200\n",
      "Epoch 034 | Train Loss: 0.4027 Acc: 0.8159 | Val Loss: 0.3817 Acc: 0.8225\n",
      "Epoch 035 | Train Loss: 0.3793 Acc: 0.8342 | Val Loss: 0.3671 Acc: 0.8279\n",
      "Epoch 036 | Train Loss: 0.3719 Acc: 0.8347 | Val Loss: 0.3679 Acc: 0.8237\n",
      "Epoch 037 | Train Loss: 0.3692 Acc: 0.8368 | Val Loss: 0.3489 Acc: 0.8406\n",
      "Epoch 038 | Train Loss: 0.3630 Acc: 0.8469 | Val Loss: 0.3354 Acc: 0.8581\n",
      "Epoch 039 | Train Loss: 0.3665 Acc: 0.8442 | Val Loss: 0.3104 Acc: 0.8653\n",
      "Epoch 040 | Train Loss: 0.3428 Acc: 0.8557 | Val Loss: 0.3155 Acc: 0.8678\n",
      "Epoch 041 | Train Loss: 0.3379 Acc: 0.8594 | Val Loss: 0.3254 Acc: 0.8593\n",
      "Epoch 042 | Train Loss: 0.3349 Acc: 0.8602 | Val Loss: 0.3378 Acc: 0.8599\n",
      "Epoch 043 | Train Loss: 0.3216 Acc: 0.8606 | Val Loss: 0.2964 Acc: 0.8822\n",
      "Epoch 044 | Train Loss: 0.3216 Acc: 0.8652 | Val Loss: 0.2784 Acc: 0.8871\n",
      "Epoch 045 | Train Loss: 0.3062 Acc: 0.8720 | Val Loss: 0.2742 Acc: 0.8907\n",
      "Epoch 046 | Train Loss: 0.3062 Acc: 0.8718 | Val Loss: 0.2969 Acc: 0.8829\n",
      "Epoch 047 | Train Loss: 0.3028 Acc: 0.8714 | Val Loss: 0.2961 Acc: 0.8708\n",
      "Epoch 048 | Train Loss: 0.2841 Acc: 0.8875 | Val Loss: 0.3011 Acc: 0.8702\n",
      "Epoch 049 | Train Loss: 0.3002 Acc: 0.8748 | Val Loss: 0.2896 Acc: 0.8810\n",
      "Epoch 050 | Train Loss: 0.2795 Acc: 0.8869 | Val Loss: 0.2681 Acc: 0.8992\n",
      "Epoch 051 | Train Loss: 0.2791 Acc: 0.8884 | Val Loss: 0.2803 Acc: 0.8780\n",
      "Epoch 052 | Train Loss: 0.2742 Acc: 0.8929 | Val Loss: 0.2621 Acc: 0.8998\n",
      "Epoch 053 | Train Loss: 0.2707 Acc: 0.8942 | Val Loss: 0.2915 Acc: 0.8804\n",
      "Epoch 054 | Train Loss: 0.2668 Acc: 0.8931 | Val Loss: 0.2415 Acc: 0.8973\n",
      "Epoch 055 | Train Loss: 0.2580 Acc: 0.8997 | Val Loss: 0.2457 Acc: 0.8925\n",
      "Epoch 056 | Train Loss: 0.2589 Acc: 0.8982 | Val Loss: 0.2502 Acc: 0.8986\n",
      "Epoch 057 | Train Loss: 0.2581 Acc: 0.8987 | Val Loss: 0.2731 Acc: 0.8895\n",
      "Epoch 058 | Train Loss: 0.2489 Acc: 0.8999 | Val Loss: 0.2359 Acc: 0.9094\n",
      "Epoch 059 | Train Loss: 0.2502 Acc: 0.8997 | Val Loss: 0.2328 Acc: 0.9070\n",
      "Epoch 060 | Train Loss: 0.2452 Acc: 0.9053 | Val Loss: 0.2271 Acc: 0.9130\n",
      "Epoch 001 | Train Loss: 0.6804 Acc: 0.5748 | Val Loss: 0.6763 Acc: 0.5797\n",
      "Epoch 002 | Train Loss: 0.6666 Acc: 0.6009 | Val Loss: 0.6596 Acc: 0.6057\n",
      "Epoch 003 | Train Loss: 0.6495 Acc: 0.6252 | Val Loss: 0.6468 Acc: 0.6479\n",
      "Epoch 004 | Train Loss: 0.6299 Acc: 0.6583 | Val Loss: 0.6227 Acc: 0.6606\n",
      "Epoch 005 | Train Loss: 0.5950 Acc: 0.6952 | Val Loss: 0.5925 Acc: 0.6987\n",
      "Epoch 006 | Train Loss: 0.5571 Acc: 0.7232 | Val Loss: 0.5720 Acc: 0.6999\n",
      "Epoch 007 | Train Loss: 0.5359 Acc: 0.7376 | Val Loss: 0.5490 Acc: 0.7114\n",
      "Epoch 008 | Train Loss: 0.5184 Acc: 0.7488 | Val Loss: 0.5265 Acc: 0.7367\n",
      "Epoch 009 | Train Loss: 0.5042 Acc: 0.7565 | Val Loss: 0.5277 Acc: 0.7385\n",
      "Epoch 010 | Train Loss: 0.4785 Acc: 0.7765 | Val Loss: 0.5189 Acc: 0.7373\n",
      "Epoch 011 | Train Loss: 0.4630 Acc: 0.7829 | Val Loss: 0.4787 Acc: 0.7621\n",
      "Epoch 012 | Train Loss: 0.4427 Acc: 0.7974 | Val Loss: 0.4748 Acc: 0.7693\n",
      "Epoch 013 | Train Loss: 0.4302 Acc: 0.8066 | Val Loss: 0.4441 Acc: 0.7917\n",
      "Epoch 014 | Train Loss: 0.4023 Acc: 0.8170 | Val Loss: 0.4528 Acc: 0.7886\n",
      "Epoch 015 | Train Loss: 0.3892 Acc: 0.8214 | Val Loss: 0.4195 Acc: 0.8031\n",
      "Epoch 016 | Train Loss: 0.3573 Acc: 0.8407 | Val Loss: 0.4248 Acc: 0.8110\n",
      "Epoch 017 | Train Loss: 0.3368 Acc: 0.8461 | Val Loss: 0.3578 Acc: 0.8478\n",
      "Epoch 018 | Train Loss: 0.3111 Acc: 0.8629 | Val Loss: 0.3606 Acc: 0.8345\n",
      "Epoch 019 | Train Loss: 0.2991 Acc: 0.8703 | Val Loss: 0.3633 Acc: 0.8297\n",
      "Epoch 020 | Train Loss: 0.2722 Acc: 0.8840 | Val Loss: 0.3368 Acc: 0.8490\n",
      "Epoch 021 | Train Loss: 0.2540 Acc: 0.8890 | Val Loss: 0.3352 Acc: 0.8460\n",
      "Epoch 022 | Train Loss: 0.2353 Acc: 0.9010 | Val Loss: 0.3193 Acc: 0.8581\n",
      "Epoch 023 | Train Loss: 0.2272 Acc: 0.9037 | Val Loss: 0.3625 Acc: 0.8508\n",
      "Epoch 024 | Train Loss: 0.2179 Acc: 0.9114 | Val Loss: 0.3030 Acc: 0.8750\n",
      "Epoch 025 | Train Loss: 0.2020 Acc: 0.9167 | Val Loss: 0.3337 Acc: 0.8647\n",
      "Epoch 026 | Train Loss: 0.1801 Acc: 0.9263 | Val Loss: 0.3517 Acc: 0.8659\n",
      "Epoch 027 | Train Loss: 0.1659 Acc: 0.9330 | Val Loss: 0.3115 Acc: 0.8810\n",
      "Epoch 028 | Train Loss: 0.1626 Acc: 0.9366 | Val Loss: 0.2877 Acc: 0.8919\n",
      "Epoch 029 | Train Loss: 0.1628 Acc: 0.9375 | Val Loss: 0.3047 Acc: 0.8865\n",
      "Epoch 030 | Train Loss: 0.1368 Acc: 0.9443 | Val Loss: 0.3752 Acc: 0.8593\n",
      "Epoch 031 | Train Loss: 0.1297 Acc: 0.9496 | Val Loss: 0.2910 Acc: 0.8835\n",
      "Epoch 032 | Train Loss: 0.1220 Acc: 0.9526 | Val Loss: 0.2978 Acc: 0.8889\n",
      "Epoch 033 | Train Loss: 0.1238 Acc: 0.9539 | Val Loss: 0.3112 Acc: 0.8859\n",
      "Epoch 034 | Train Loss: 0.0950 Acc: 0.9648 | Val Loss: 0.3244 Acc: 0.8877\n",
      "Epoch 035 | Train Loss: 0.0969 Acc: 0.9642 | Val Loss: 0.2859 Acc: 0.9040\n",
      "Epoch 036 | Train Loss: 0.1022 Acc: 0.9603 | Val Loss: 0.2703 Acc: 0.9094\n",
      "Epoch 037 | Train Loss: 0.0886 Acc: 0.9654 | Val Loss: 0.2756 Acc: 0.8949\n",
      "Epoch 038 | Train Loss: 0.0766 Acc: 0.9725 | Val Loss: 0.3240 Acc: 0.9088\n",
      "Epoch 039 | Train Loss: 0.0800 Acc: 0.9704 | Val Loss: 0.2871 Acc: 0.9040\n",
      "Epoch 040 | Train Loss: 0.0801 Acc: 0.9689 | Val Loss: 0.3101 Acc: 0.9040\n",
      "Epoch 041 | Train Loss: 0.0790 Acc: 0.9703 | Val Loss: 0.2732 Acc: 0.9028\n",
      "Epoch 042 | Train Loss: 0.0518 Acc: 0.9813 | Val Loss: 0.3142 Acc: 0.9064\n",
      "Epoch 043 | Train Loss: 0.0596 Acc: 0.9763 | Val Loss: 0.3667 Acc: 0.8986\n",
      "Overfitting detected\n",
      "Epoch 001 | Train Loss: 0.6877 Acc: 0.5541 | Val Loss: 0.7310 Acc: 0.5290\n",
      "Epoch 002 | Train Loss: 0.6868 Acc: 0.5614 | Val Loss: 0.6892 Acc: 0.5586\n",
      "Epoch 003 | Train Loss: 0.6861 Acc: 0.5597 | Val Loss: 0.6834 Acc: 0.5586\n",
      "Epoch 004 | Train Loss: 0.6857 Acc: 0.5652 | Val Loss: 0.6866 Acc: 0.5586\n",
      "Epoch 005 | Train Loss: 0.6851 Acc: 0.5620 | Val Loss: 0.6822 Acc: 0.5586\n",
      "Epoch 006 | Train Loss: 0.6804 Acc: 0.5732 | Val Loss: 0.6776 Acc: 0.5833\n",
      "Epoch 007 | Train Loss: 0.6807 Acc: 0.5766 | Val Loss: 0.6861 Acc: 0.5821\n",
      "Epoch 008 | Train Loss: 0.6868 Acc: 0.5597 | Val Loss: 0.6861 Acc: 0.5592\n",
      "Epoch 009 | Train Loss: 0.6869 Acc: 0.5571 | Val Loss: 0.6863 Acc: 0.5586\n",
      "Epoch 010 | Train Loss: 0.6871 Acc: 0.5564 | Val Loss: 0.6863 Acc: 0.5586\n",
      "Epoch 011 | Train Loss: 0.6867 Acc: 0.5582 | Val Loss: 0.6863 Acc: 0.5586\n",
      "Epoch 012 | Train Loss: 0.6869 Acc: 0.5582 | Val Loss: 0.6864 Acc: 0.5586\n",
      "Epoch 013 | Train Loss: 0.6866 Acc: 0.5582 | Val Loss: 0.6868 Acc: 0.5586\n",
      "Epoch 014 | Train Loss: 0.6867 Acc: 0.5582 | Val Loss: 0.6863 Acc: 0.5586\n",
      "Epoch 015 | Train Loss: 0.6866 Acc: 0.5582 | Val Loss: 0.6863 Acc: 0.5586\n",
      "Epoch 016 | Train Loss: 0.6867 Acc: 0.5582 | Val Loss: 0.6870 Acc: 0.5586\n",
      "Early stopping triggered.\n",
      "Epoch 001 | Train Loss: 0.6875 Acc: 0.5691 | Val Loss: 0.6717 Acc: 0.5924\n",
      "Epoch 002 | Train Loss: 0.6840 Acc: 0.5691 | Val Loss: 0.6862 Acc: 0.5586\n",
      "Epoch 003 | Train Loss: 0.6881 Acc: 0.5587 | Val Loss: 0.6863 Acc: 0.5586\n",
      "Epoch 004 | Train Loss: 0.6870 Acc: 0.5582 | Val Loss: 0.6863 Acc: 0.5586\n",
      "Epoch 005 | Train Loss: 0.6867 Acc: 0.5582 | Val Loss: 0.6863 Acc: 0.5586\n",
      "Epoch 006 | Train Loss: 0.6868 Acc: 0.5582 | Val Loss: 0.6864 Acc: 0.5586\n",
      "Epoch 007 | Train Loss: 0.6868 Acc: 0.5582 | Val Loss: 0.6863 Acc: 0.5586\n",
      "Epoch 008 | Train Loss: 0.6869 Acc: 0.5582 | Val Loss: 0.6865 Acc: 0.5586\n",
      "Epoch 009 | Train Loss: 0.6868 Acc: 0.5582 | Val Loss: 0.6863 Acc: 0.5586\n",
      "Epoch 010 | Train Loss: 0.6867 Acc: 0.5582 | Val Loss: 0.6865 Acc: 0.5586\n",
      "Epoch 011 | Train Loss: 0.6867 Acc: 0.5582 | Val Loss: 0.6869 Acc: 0.5586\n",
      "Early stopping triggered.\n",
      "Epoch 001 | Train Loss: 0.6902 Acc: 0.5502 | Val Loss: 0.6864 Acc: 0.5586\n",
      "Epoch 002 | Train Loss: 0.6869 Acc: 0.5546 | Val Loss: 0.6865 Acc: 0.5586\n",
      "Epoch 003 | Train Loss: 0.6873 Acc: 0.5582 | Val Loss: 0.6863 Acc: 0.5586\n",
      "Epoch 004 | Train Loss: 0.6869 Acc: 0.5582 | Val Loss: 0.6863 Acc: 0.5586\n",
      "Epoch 005 | Train Loss: 0.6868 Acc: 0.5582 | Val Loss: 0.6866 Acc: 0.5586\n",
      "Epoch 006 | Train Loss: 0.6869 Acc: 0.5582 | Val Loss: 0.6866 Acc: 0.5586\n",
      "Epoch 007 | Train Loss: 0.6866 Acc: 0.5582 | Val Loss: 0.6879 Acc: 0.5586\n",
      "Epoch 008 | Train Loss: 0.6867 Acc: 0.5582 | Val Loss: 0.6866 Acc: 0.5586\n",
      "Epoch 009 | Train Loss: 0.6870 Acc: 0.5582 | Val Loss: 0.6866 Acc: 0.5586\n",
      "Epoch 010 | Train Loss: 0.6871 Acc: 0.5582 | Val Loss: 0.6863 Acc: 0.5586\n",
      "Epoch 011 | Train Loss: 0.6869 Acc: 0.5582 | Val Loss: 0.6863 Acc: 0.5586\n",
      "Epoch 012 | Train Loss: 0.6866 Acc: 0.5582 | Val Loss: 0.6864 Acc: 0.5586\n",
      "Epoch 013 | Train Loss: 0.6869 Acc: 0.5576 | Val Loss: 0.6864 Acc: 0.5586\n",
      "Epoch 014 | Train Loss: 0.6867 Acc: 0.5582 | Val Loss: 0.6867 Acc: 0.5586\n",
      "Epoch 015 | Train Loss: 0.6865 Acc: 0.5582 | Val Loss: 0.6864 Acc: 0.5586\n",
      "Epoch 016 | Train Loss: 0.6867 Acc: 0.5582 | Val Loss: 0.6863 Acc: 0.5586\n",
      "Epoch 017 | Train Loss: 0.6870 Acc: 0.5582 | Val Loss: 0.6864 Acc: 0.5586\n",
      "Epoch 018 | Train Loss: 0.6868 Acc: 0.5582 | Val Loss: 0.6863 Acc: 0.5586\n",
      "Epoch 019 | Train Loss: 0.6869 Acc: 0.5582 | Val Loss: 0.6868 Acc: 0.5586\n",
      "Epoch 020 | Train Loss: 0.6871 Acc: 0.5582 | Val Loss: 0.6866 Acc: 0.5586\n",
      "Epoch 021 | Train Loss: 0.6868 Acc: 0.5582 | Val Loss: 0.6871 Acc: 0.5586\n",
      "Early stopping triggered.\n",
      "Epoch 001 | Train Loss: 0.6824 Acc: 0.5756 | Val Loss: 0.6779 Acc: 0.5755\n",
      "Epoch 002 | Train Loss: 0.6761 Acc: 0.5889 | Val Loss: 0.6704 Acc: 0.6057\n",
      "Epoch 003 | Train Loss: 0.6703 Acc: 0.5960 | Val Loss: 0.6679 Acc: 0.6087\n",
      "Epoch 004 | Train Loss: 0.6651 Acc: 0.6074 | Val Loss: 0.6653 Acc: 0.6202\n",
      "Epoch 005 | Train Loss: 0.6521 Acc: 0.6260 | Val Loss: 0.6155 Acc: 0.6733\n",
      "Epoch 006 | Train Loss: 0.6042 Acc: 0.6899 | Val Loss: 0.5640 Acc: 0.7114\n",
      "Epoch 007 | Train Loss: 0.5850 Acc: 0.7038 | Val Loss: 0.5696 Acc: 0.7107\n",
      "Epoch 008 | Train Loss: 0.5607 Acc: 0.7198 | Val Loss: 0.5367 Acc: 0.7264\n",
      "Epoch 009 | Train Loss: 0.5419 Acc: 0.7343 | Val Loss: 0.5335 Acc: 0.7319\n",
      "Epoch 010 | Train Loss: 0.5342 Acc: 0.7406 | Val Loss: 0.5309 Acc: 0.7421\n",
      "Epoch 011 | Train Loss: 0.5125 Acc: 0.7539 | Val Loss: 0.4944 Acc: 0.7663\n",
      "Epoch 012 | Train Loss: 0.4964 Acc: 0.7649 | Val Loss: 0.5095 Acc: 0.7512\n",
      "Epoch 013 | Train Loss: 0.4854 Acc: 0.7764 | Val Loss: 0.4749 Acc: 0.7796\n",
      "Epoch 014 | Train Loss: 0.4624 Acc: 0.7867 | Val Loss: 0.4670 Acc: 0.7711\n",
      "Epoch 015 | Train Loss: 0.4462 Acc: 0.7948 | Val Loss: 0.4562 Acc: 0.7729\n",
      "Epoch 016 | Train Loss: 0.4349 Acc: 0.7996 | Val Loss: 0.4262 Acc: 0.8019\n",
      "Epoch 017 | Train Loss: 0.4429 Acc: 0.7953 | Val Loss: 0.4675 Acc: 0.7729\n",
      "Epoch 018 | Train Loss: 0.4294 Acc: 0.8085 | Val Loss: 0.4242 Acc: 0.7959\n",
      "Epoch 019 | Train Loss: 0.4087 Acc: 0.8193 | Val Loss: 0.4453 Acc: 0.7983\n",
      "Epoch 020 | Train Loss: 0.4051 Acc: 0.8172 | Val Loss: 0.4075 Acc: 0.8050\n",
      "Epoch 021 | Train Loss: 0.3885 Acc: 0.8298 | Val Loss: 0.3932 Acc: 0.8122\n",
      "Epoch 022 | Train Loss: 0.3884 Acc: 0.8236 | Val Loss: 0.3906 Acc: 0.8225\n",
      "Epoch 023 | Train Loss: 0.3816 Acc: 0.8306 | Val Loss: 0.3810 Acc: 0.8279\n",
      "Epoch 024 | Train Loss: 0.3668 Acc: 0.8371 | Val Loss: 0.3960 Acc: 0.8122\n",
      "Epoch 025 | Train Loss: 0.3633 Acc: 0.8359 | Val Loss: 0.3792 Acc: 0.8237\n",
      "Epoch 026 | Train Loss: 0.3587 Acc: 0.8419 | Val Loss: 0.3625 Acc: 0.8345\n",
      "Epoch 027 | Train Loss: 0.3470 Acc: 0.8511 | Val Loss: 0.3815 Acc: 0.8249\n",
      "Epoch 028 | Train Loss: 0.3401 Acc: 0.8513 | Val Loss: 0.4029 Acc: 0.8164\n",
      "Epoch 029 | Train Loss: 0.3343 Acc: 0.8570 | Val Loss: 0.3766 Acc: 0.8237\n",
      "Epoch 030 | Train Loss: 0.3404 Acc: 0.8519 | Val Loss: 0.3362 Acc: 0.8448\n",
      "Epoch 031 | Train Loss: 0.3242 Acc: 0.8652 | Val Loss: 0.3496 Acc: 0.8382\n",
      "Epoch 032 | Train Loss: 0.3174 Acc: 0.8653 | Val Loss: 0.3562 Acc: 0.8394\n",
      "Epoch 033 | Train Loss: 0.3139 Acc: 0.8665 | Val Loss: 0.3271 Acc: 0.8545\n",
      "Epoch 034 | Train Loss: 0.3153 Acc: 0.8644 | Val Loss: 0.3411 Acc: 0.8412\n",
      "Epoch 035 | Train Loss: 0.3130 Acc: 0.8641 | Val Loss: 0.3319 Acc: 0.8406\n",
      "Epoch 036 | Train Loss: 0.2983 Acc: 0.8739 | Val Loss: 0.3173 Acc: 0.8514\n",
      "Epoch 037 | Train Loss: 0.3054 Acc: 0.8682 | Val Loss: 0.3131 Acc: 0.8527\n",
      "Epoch 038 | Train Loss: 0.2910 Acc: 0.8772 | Val Loss: 0.3028 Acc: 0.8671\n",
      "Epoch 039 | Train Loss: 0.2794 Acc: 0.8809 | Val Loss: 0.3078 Acc: 0.8629\n",
      "Epoch 040 | Train Loss: 0.2870 Acc: 0.8759 | Val Loss: 0.3263 Acc: 0.8484\n",
      "Epoch 041 | Train Loss: 0.2889 Acc: 0.8815 | Val Loss: 0.2836 Acc: 0.8690\n",
      "Epoch 042 | Train Loss: 0.2818 Acc: 0.8821 | Val Loss: 0.3002 Acc: 0.8714\n",
      "Epoch 043 | Train Loss: 0.2815 Acc: 0.8809 | Val Loss: 0.2913 Acc: 0.8659\n",
      "Epoch 044 | Train Loss: 0.2815 Acc: 0.8833 | Val Loss: 0.3225 Acc: 0.8635\n",
      "Epoch 045 | Train Loss: 0.2798 Acc: 0.8859 | Val Loss: 0.2832 Acc: 0.8702\n",
      "Epoch 046 | Train Loss: 0.2573 Acc: 0.8898 | Val Loss: 0.2834 Acc: 0.8690\n",
      "Epoch 047 | Train Loss: 0.2698 Acc: 0.8880 | Val Loss: 0.2734 Acc: 0.8786\n",
      "Epoch 048 | Train Loss: 0.2722 Acc: 0.8877 | Val Loss: 0.2892 Acc: 0.8720\n",
      "Epoch 049 | Train Loss: 0.2599 Acc: 0.8936 | Val Loss: 0.2803 Acc: 0.8780\n",
      "Epoch 050 | Train Loss: 0.2666 Acc: 0.8901 | Val Loss: 0.3032 Acc: 0.8702\n",
      "Epoch 051 | Train Loss: 0.2551 Acc: 0.8981 | Val Loss: 0.2755 Acc: 0.8780\n",
      "Epoch 052 | Train Loss: 0.2362 Acc: 0.9022 | Val Loss: 0.2562 Acc: 0.8883\n",
      "Epoch 053 | Train Loss: 0.2489 Acc: 0.9025 | Val Loss: 0.2471 Acc: 0.8931\n",
      "Epoch 054 | Train Loss: 0.2414 Acc: 0.9025 | Val Loss: 0.2931 Acc: 0.8738\n",
      "Epoch 055 | Train Loss: 0.2323 Acc: 0.9043 | Val Loss: 0.2660 Acc: 0.8907\n",
      "Epoch 056 | Train Loss: 0.2381 Acc: 0.9064 | Val Loss: 0.2651 Acc: 0.8822\n",
      "Epoch 057 | Train Loss: 0.2355 Acc: 0.9070 | Val Loss: 0.2509 Acc: 0.8949\n",
      "Epoch 058 | Train Loss: 0.2351 Acc: 0.9022 | Val Loss: 0.3129 Acc: 0.8750\n",
      "Epoch 059 | Train Loss: 0.2318 Acc: 0.9034 | Val Loss: 0.2823 Acc: 0.8798\n",
      "Epoch 060 | Train Loss: 0.2167 Acc: 0.9132 | Val Loss: 0.2610 Acc: 0.8901\n",
      "Epoch 001 | Train Loss: 0.6804 Acc: 0.5765 | Val Loss: 0.6787 Acc: 0.5737\n",
      "Epoch 002 | Train Loss: 0.6811 Acc: 0.5772 | Val Loss: 0.6799 Acc: 0.5851\n",
      "Epoch 003 | Train Loss: 0.6717 Acc: 0.5950 | Val Loss: 0.6698 Acc: 0.5930\n",
      "Epoch 004 | Train Loss: 0.6675 Acc: 0.6037 | Val Loss: 0.6627 Acc: 0.6039\n",
      "Epoch 005 | Train Loss: 0.6581 Acc: 0.6127 | Val Loss: 0.6485 Acc: 0.6153\n",
      "Epoch 006 | Train Loss: 0.6312 Acc: 0.6582 | Val Loss: 0.6492 Acc: 0.6540\n",
      "Epoch 007 | Train Loss: 0.6292 Acc: 0.6579 | Val Loss: 0.5952 Acc: 0.6975\n",
      "Epoch 008 | Train Loss: 0.5795 Acc: 0.7101 | Val Loss: 0.5710 Acc: 0.7114\n",
      "Epoch 009 | Train Loss: 0.5569 Acc: 0.7281 | Val Loss: 0.5509 Acc: 0.7204\n",
      "Epoch 010 | Train Loss: 0.5275 Acc: 0.7451 | Val Loss: 0.5327 Acc: 0.7361\n",
      "Epoch 011 | Train Loss: 0.5127 Acc: 0.7584 | Val Loss: 0.5557 Acc: 0.7222\n",
      "Epoch 012 | Train Loss: 0.4963 Acc: 0.7646 | Val Loss: 0.5124 Acc: 0.7482\n",
      "Epoch 013 | Train Loss: 0.4773 Acc: 0.7755 | Val Loss: 0.5145 Acc: 0.7506\n",
      "Epoch 014 | Train Loss: 0.4527 Acc: 0.7891 | Val Loss: 0.4798 Acc: 0.7633\n",
      "Epoch 015 | Train Loss: 0.4293 Acc: 0.8054 | Val Loss: 0.4472 Acc: 0.7886\n",
      "Epoch 016 | Train Loss: 0.4110 Acc: 0.8140 | Val Loss: 0.4271 Acc: 0.7995\n",
      "Epoch 017 | Train Loss: 0.3850 Acc: 0.8241 | Val Loss: 0.4021 Acc: 0.8152\n",
      "Epoch 018 | Train Loss: 0.3582 Acc: 0.8386 | Val Loss: 0.3887 Acc: 0.8237\n",
      "Epoch 019 | Train Loss: 0.3333 Acc: 0.8522 | Val Loss: 0.4100 Acc: 0.8134\n",
      "Epoch 020 | Train Loss: 0.3156 Acc: 0.8581 | Val Loss: 0.3862 Acc: 0.8357\n",
      "Epoch 021 | Train Loss: 0.2984 Acc: 0.8703 | Val Loss: 0.3324 Acc: 0.8533\n",
      "Epoch 022 | Train Loss: 0.2768 Acc: 0.8833 | Val Loss: 0.3359 Acc: 0.8533\n",
      "Epoch 023 | Train Loss: 0.2455 Acc: 0.9010 | Val Loss: 0.3165 Acc: 0.8605\n",
      "Epoch 024 | Train Loss: 0.2318 Acc: 0.9062 | Val Loss: 0.3200 Acc: 0.8714\n",
      "Epoch 025 | Train Loss: 0.2234 Acc: 0.9111 | Val Loss: 0.3165 Acc: 0.8708\n",
      "Epoch 026 | Train Loss: 0.1917 Acc: 0.9247 | Val Loss: 0.2754 Acc: 0.8913\n",
      "Epoch 027 | Train Loss: 0.1860 Acc: 0.9256 | Val Loss: 0.3137 Acc: 0.8792\n",
      "Epoch 028 | Train Loss: 0.1734 Acc: 0.9340 | Val Loss: 0.2789 Acc: 0.8907\n",
      "Epoch 029 | Train Loss: 0.1472 Acc: 0.9413 | Val Loss: 0.2859 Acc: 0.8895\n",
      "Epoch 030 | Train Loss: 0.1336 Acc: 0.9472 | Val Loss: 0.4332 Acc: 0.8412\n",
      "Epoch 031 | Train Loss: 0.1573 Acc: 0.9399 | Val Loss: 0.2644 Acc: 0.9040\n",
      "Epoch 032 | Train Loss: 0.1226 Acc: 0.9536 | Val Loss: 0.3217 Acc: 0.8949\n",
      "Epoch 033 | Train Loss: 0.1295 Acc: 0.9511 | Val Loss: 0.2747 Acc: 0.8883\n",
      "Epoch 034 | Train Loss: 0.1233 Acc: 0.9544 | Val Loss: 0.3211 Acc: 0.8786\n",
      "Epoch 035 | Train Loss: 0.1073 Acc: 0.9585 | Val Loss: 0.3100 Acc: 0.8901\n",
      "Epoch 036 | Train Loss: 0.0946 Acc: 0.9621 | Val Loss: 0.2572 Acc: 0.9046\n",
      "Epoch 037 | Train Loss: 0.0870 Acc: 0.9683 | Val Loss: 0.2727 Acc: 0.9076\n",
      "Epoch 038 | Train Loss: 0.0726 Acc: 0.9722 | Val Loss: 0.3493 Acc: 0.8998\n",
      "Epoch 039 | Train Loss: 0.0782 Acc: 0.9692 | Val Loss: 0.3296 Acc: 0.9010\n",
      "Epoch 040 | Train Loss: 0.0736 Acc: 0.9719 | Val Loss: 0.3454 Acc: 0.9004\n",
      "Epoch 041 | Train Loss: 0.0840 Acc: 0.9678 | Val Loss: 0.3231 Acc: 0.8889\n",
      "Epoch 042 | Train Loss: 0.0651 Acc: 0.9749 | Val Loss: 0.3428 Acc: 0.8973\n",
      "Epoch 043 | Train Loss: 0.0560 Acc: 0.9813 | Val Loss: 0.3107 Acc: 0.9124\n",
      "Epoch 044 | Train Loss: 0.0605 Acc: 0.9786 | Val Loss: 0.3057 Acc: 0.9124\n",
      "Epoch 045 | Train Loss: 0.0619 Acc: 0.9769 | Val Loss: 0.2972 Acc: 0.9064\n",
      "Epoch 046 | Train Loss: 0.0536 Acc: 0.9796 | Val Loss: 0.2848 Acc: 0.9130\n",
      "Early stopping triggered.\n",
      "Iteration 1/40 | Best Val Loss: 0.1819 | Iter Time: 316.03s | Total Time: 5.27 min\n",
      "Epoch 001 | Train Loss: 0.6789 Acc: 0.5807 | Val Loss: 0.6741 Acc: 0.5912\n",
      "Epoch 002 | Train Loss: 0.6621 Acc: 0.6050 | Val Loss: 0.6209 Acc: 0.6612\n",
      "Epoch 003 | Train Loss: 0.5873 Acc: 0.7018 | Val Loss: 0.5765 Acc: 0.6987\n",
      "Epoch 004 | Train Loss: 0.5453 Acc: 0.7338 | Val Loss: 0.5393 Acc: 0.7415\n",
      "Epoch 005 | Train Loss: 0.5236 Acc: 0.7483 | Val Loss: 0.5174 Acc: 0.7428\n",
      "Epoch 006 | Train Loss: 0.4886 Acc: 0.7694 | Val Loss: 0.5025 Acc: 0.7512\n",
      "Epoch 007 | Train Loss: 0.4678 Acc: 0.7823 | Val Loss: 0.4595 Acc: 0.7736\n",
      "Epoch 008 | Train Loss: 0.4374 Acc: 0.7957 | Val Loss: 0.4474 Acc: 0.7742\n",
      "Epoch 009 | Train Loss: 0.4059 Acc: 0.8187 | Val Loss: 0.4259 Acc: 0.7923\n",
      "Epoch 010 | Train Loss: 0.3851 Acc: 0.8288 | Val Loss: 0.3963 Acc: 0.8104\n",
      "Epoch 011 | Train Loss: 0.3658 Acc: 0.8387 | Val Loss: 0.4243 Acc: 0.8122\n",
      "Epoch 012 | Train Loss: 0.3424 Acc: 0.8529 | Val Loss: 0.3471 Acc: 0.8430\n",
      "Epoch 013 | Train Loss: 0.3156 Acc: 0.8664 | Val Loss: 0.3475 Acc: 0.8388\n",
      "Epoch 014 | Train Loss: 0.2878 Acc: 0.8757 | Val Loss: 0.2945 Acc: 0.8762\n",
      "Epoch 015 | Train Loss: 0.2750 Acc: 0.8852 | Val Loss: 0.2845 Acc: 0.8750\n",
      "Epoch 016 | Train Loss: 0.2509 Acc: 0.8978 | Val Loss: 0.2636 Acc: 0.8937\n",
      "Epoch 017 | Train Loss: 0.2393 Acc: 0.9047 | Val Loss: 0.3570 Acc: 0.8641\n",
      "Epoch 018 | Train Loss: 0.2284 Acc: 0.9065 | Val Loss: 0.2670 Acc: 0.8919\n",
      "Epoch 019 | Train Loss: 0.2153 Acc: 0.9117 | Val Loss: 0.2498 Acc: 0.8913\n",
      "Epoch 020 | Train Loss: 0.1936 Acc: 0.9207 | Val Loss: 0.2432 Acc: 0.8931\n",
      "Epoch 021 | Train Loss: 0.1905 Acc: 0.9215 | Val Loss: 0.2426 Acc: 0.9022\n",
      "Epoch 022 | Train Loss: 0.1660 Acc: 0.9351 | Val Loss: 0.2212 Acc: 0.9034\n",
      "Epoch 023 | Train Loss: 0.1695 Acc: 0.9296 | Val Loss: 0.2125 Acc: 0.9106\n",
      "Epoch 024 | Train Loss: 0.1629 Acc: 0.9384 | Val Loss: 0.2060 Acc: 0.9197\n",
      "Epoch 025 | Train Loss: 0.1478 Acc: 0.9399 | Val Loss: 0.2232 Acc: 0.9016\n",
      "Epoch 026 | Train Loss: 0.1484 Acc: 0.9440 | Val Loss: 0.2199 Acc: 0.9118\n",
      "Epoch 027 | Train Loss: 0.1396 Acc: 0.9453 | Val Loss: 0.1835 Acc: 0.9245\n",
      "Epoch 028 | Train Loss: 0.1294 Acc: 0.9494 | Val Loss: 0.2064 Acc: 0.9245\n",
      "Epoch 029 | Train Loss: 0.1239 Acc: 0.9499 | Val Loss: 0.1960 Acc: 0.9221\n",
      "Epoch 030 | Train Loss: 0.1200 Acc: 0.9520 | Val Loss: 0.2108 Acc: 0.9215\n",
      "Epoch 031 | Train Loss: 0.1079 Acc: 0.9598 | Val Loss: 0.1991 Acc: 0.9263\n",
      "Epoch 032 | Train Loss: 0.1202 Acc: 0.9520 | Val Loss: 0.1704 Acc: 0.9281\n",
      "Epoch 033 | Train Loss: 0.1125 Acc: 0.9589 | Val Loss: 0.2000 Acc: 0.9203\n",
      "Epoch 034 | Train Loss: 0.1049 Acc: 0.9579 | Val Loss: 0.1935 Acc: 0.9263\n",
      "Epoch 035 | Train Loss: 0.0942 Acc: 0.9650 | Val Loss: 0.2130 Acc: 0.9263\n",
      "Epoch 036 | Train Loss: 0.0974 Acc: 0.9650 | Val Loss: 0.1849 Acc: 0.9245\n",
      "Epoch 037 | Train Loss: 0.0982 Acc: 0.9630 | Val Loss: 0.1580 Acc: 0.9342\n",
      "Epoch 038 | Train Loss: 0.0843 Acc: 0.9668 | Val Loss: 0.1985 Acc: 0.9306\n",
      "Epoch 039 | Train Loss: 0.0866 Acc: 0.9689 | Val Loss: 0.1877 Acc: 0.9348\n",
      "Epoch 040 | Train Loss: 0.0852 Acc: 0.9674 | Val Loss: 0.1742 Acc: 0.9318\n",
      "Epoch 041 | Train Loss: 0.0901 Acc: 0.9677 | Val Loss: 0.1849 Acc: 0.9251\n",
      "Epoch 042 | Train Loss: 0.0770 Acc: 0.9709 | Val Loss: 0.1923 Acc: 0.9372\n",
      "Epoch 043 | Train Loss: 0.0766 Acc: 0.9730 | Val Loss: 0.1653 Acc: 0.9493\n",
      "Epoch 044 | Train Loss: 0.0790 Acc: 0.9710 | Val Loss: 0.1737 Acc: 0.9366\n",
      "Epoch 045 | Train Loss: 0.0745 Acc: 0.9740 | Val Loss: 0.1594 Acc: 0.9481\n",
      "Epoch 046 | Train Loss: 0.0758 Acc: 0.9725 | Val Loss: 0.1740 Acc: 0.9402\n",
      "Epoch 047 | Train Loss: 0.0680 Acc: 0.9754 | Val Loss: 0.2290 Acc: 0.9173\n",
      "Early stopping triggered.\n",
      "Epoch 001 | Train Loss: 0.6874 Acc: 0.5575 | Val Loss: 0.6892 Acc: 0.5803\n",
      "Epoch 002 | Train Loss: 0.6857 Acc: 0.5676 | Val Loss: 0.6860 Acc: 0.5586\n",
      "Epoch 003 | Train Loss: 0.6844 Acc: 0.5677 | Val Loss: 0.6810 Acc: 0.5755\n",
      "Epoch 004 | Train Loss: 0.6834 Acc: 0.5775 | Val Loss: 0.6840 Acc: 0.5713\n",
      "Epoch 005 | Train Loss: 0.6759 Acc: 0.5923 | Val Loss: 0.6662 Acc: 0.5996\n",
      "Epoch 006 | Train Loss: 0.6744 Acc: 0.5928 | Val Loss: 0.6849 Acc: 0.5682\n",
      "Epoch 007 | Train Loss: 0.6723 Acc: 0.5952 | Val Loss: 0.6682 Acc: 0.5984\n",
      "Epoch 008 | Train Loss: 0.6663 Acc: 0.6104 | Val Loss: 0.6624 Acc: 0.6111\n",
      "Epoch 009 | Train Loss: 0.6614 Acc: 0.6169 | Val Loss: 0.6575 Acc: 0.6153\n",
      "Epoch 010 | Train Loss: 0.6593 Acc: 0.6172 | Val Loss: 0.6582 Acc: 0.6153\n",
      "Epoch 011 | Train Loss: 0.6552 Acc: 0.6222 | Val Loss: 0.6606 Acc: 0.6129\n",
      "Epoch 012 | Train Loss: 0.6547 Acc: 0.6224 | Val Loss: 0.6542 Acc: 0.6165\n",
      "Epoch 013 | Train Loss: 0.6565 Acc: 0.6231 | Val Loss: 0.6602 Acc: 0.6093\n",
      "Epoch 014 | Train Loss: 0.6561 Acc: 0.6239 | Val Loss: 0.6556 Acc: 0.6220\n",
      "Epoch 015 | Train Loss: 0.6506 Acc: 0.6326 | Val Loss: 0.6538 Acc: 0.6268\n",
      "Epoch 016 | Train Loss: 0.6502 Acc: 0.6369 | Val Loss: 0.6604 Acc: 0.6238\n",
      "Epoch 017 | Train Loss: 0.6386 Acc: 0.6486 | Val Loss: 0.6244 Acc: 0.6685\n",
      "Epoch 018 | Train Loss: 0.6430 Acc: 0.6428 | Val Loss: 0.6766 Acc: 0.6214\n",
      "Epoch 019 | Train Loss: 0.6486 Acc: 0.6363 | Val Loss: 0.6461 Acc: 0.6347\n",
      "Epoch 020 | Train Loss: 0.6448 Acc: 0.6400 | Val Loss: 0.6612 Acc: 0.6135\n",
      "Epoch 021 | Train Loss: 0.6449 Acc: 0.6384 | Val Loss: 0.6524 Acc: 0.6244\n",
      "Epoch 022 | Train Loss: 0.6431 Acc: 0.6385 | Val Loss: 0.6475 Acc: 0.6401\n",
      "Epoch 023 | Train Loss: 0.6323 Acc: 0.6524 | Val Loss: 0.6571 Acc: 0.6153\n",
      "Epoch 024 | Train Loss: 0.6236 Acc: 0.6648 | Val Loss: 0.5915 Acc: 0.7059\n",
      "Epoch 025 | Train Loss: 0.6148 Acc: 0.6791 | Val Loss: 0.5932 Acc: 0.7071\n",
      "Epoch 026 | Train Loss: 0.6031 Acc: 0.6885 | Val Loss: 0.5845 Acc: 0.7035\n",
      "Epoch 027 | Train Loss: 0.5871 Acc: 0.7083 | Val Loss: 0.5485 Acc: 0.7355\n",
      "Epoch 028 | Train Loss: 0.6068 Acc: 0.6813 | Val Loss: 0.5934 Acc: 0.6969\n",
      "Epoch 029 | Train Loss: 0.5708 Acc: 0.7198 | Val Loss: 0.5915 Acc: 0.7126\n",
      "Epoch 030 | Train Loss: 0.5627 Acc: 0.7312 | Val Loss: 0.5738 Acc: 0.7222\n",
      "Epoch 031 | Train Loss: 0.5517 Acc: 0.7404 | Val Loss: 0.5425 Acc: 0.7440\n",
      "Epoch 032 | Train Loss: 0.5364 Acc: 0.7453 | Val Loss: 0.5383 Acc: 0.7397\n",
      "Epoch 033 | Train Loss: 0.5317 Acc: 0.7471 | Val Loss: 0.5373 Acc: 0.7494\n",
      "Epoch 034 | Train Loss: 0.5211 Acc: 0.7598 | Val Loss: 0.5206 Acc: 0.7603\n",
      "Epoch 035 | Train Loss: 0.5213 Acc: 0.7552 | Val Loss: 0.5254 Acc: 0.7500\n",
      "Epoch 036 | Train Loss: 0.4990 Acc: 0.7691 | Val Loss: 0.5061 Acc: 0.7615\n",
      "Epoch 037 | Train Loss: 0.5030 Acc: 0.7651 | Val Loss: 0.5049 Acc: 0.7729\n",
      "Epoch 038 | Train Loss: 0.4837 Acc: 0.7797 | Val Loss: 0.4854 Acc: 0.7760\n",
      "Epoch 039 | Train Loss: 0.4797 Acc: 0.7779 | Val Loss: 0.4752 Acc: 0.7699\n",
      "Epoch 040 | Train Loss: 0.4694 Acc: 0.7848 | Val Loss: 0.4676 Acc: 0.7754\n",
      "Epoch 041 | Train Loss: 0.4524 Acc: 0.7939 | Val Loss: 0.4334 Acc: 0.7935\n",
      "Epoch 042 | Train Loss: 0.4405 Acc: 0.7909 | Val Loss: 0.4146 Acc: 0.8086\n",
      "Epoch 043 | Train Loss: 0.4337 Acc: 0.8043 | Val Loss: 0.4193 Acc: 0.8170\n",
      "Epoch 044 | Train Loss: 0.4216 Acc: 0.8134 | Val Loss: 0.4235 Acc: 0.8086\n",
      "Epoch 045 | Train Loss: 0.4099 Acc: 0.8190 | Val Loss: 0.4163 Acc: 0.8025\n",
      "Epoch 046 | Train Loss: 0.3981 Acc: 0.8303 | Val Loss: 0.4195 Acc: 0.7971\n",
      "Epoch 047 | Train Loss: 0.3827 Acc: 0.8297 | Val Loss: 0.3805 Acc: 0.8261\n",
      "Epoch 048 | Train Loss: 0.3724 Acc: 0.8406 | Val Loss: 0.3608 Acc: 0.8364\n",
      "Epoch 049 | Train Loss: 0.3683 Acc: 0.8418 | Val Loss: 0.3586 Acc: 0.8418\n",
      "Epoch 050 | Train Loss: 0.3601 Acc: 0.8464 | Val Loss: 0.3495 Acc: 0.8508\n",
      "Epoch 051 | Train Loss: 0.3503 Acc: 0.8483 | Val Loss: 0.3438 Acc: 0.8593\n",
      "Epoch 052 | Train Loss: 0.3368 Acc: 0.8587 | Val Loss: 0.3831 Acc: 0.8364\n",
      "Epoch 053 | Train Loss: 0.3328 Acc: 0.8588 | Val Loss: 0.3777 Acc: 0.8460\n",
      "Epoch 054 | Train Loss: 0.3416 Acc: 0.8591 | Val Loss: 0.3453 Acc: 0.8418\n",
      "Epoch 055 | Train Loss: 0.3155 Acc: 0.8723 | Val Loss: 0.3566 Acc: 0.8514\n",
      "Epoch 056 | Train Loss: 0.3093 Acc: 0.8709 | Val Loss: 0.3525 Acc: 0.8502\n",
      "Epoch 057 | Train Loss: 0.3130 Acc: 0.8706 | Val Loss: 0.3235 Acc: 0.8684\n",
      "Epoch 058 | Train Loss: 0.3057 Acc: 0.8739 | Val Loss: 0.3206 Acc: 0.8665\n",
      "Epoch 059 | Train Loss: 0.2889 Acc: 0.8822 | Val Loss: 0.3211 Acc: 0.8623\n",
      "Epoch 060 | Train Loss: 0.2886 Acc: 0.8794 | Val Loss: 0.2989 Acc: 0.8720\n",
      "Epoch 001 | Train Loss: 0.6805 Acc: 0.5739 | Val Loss: 0.6786 Acc: 0.5845\n",
      "Epoch 002 | Train Loss: 0.6722 Acc: 0.5967 | Val Loss: 0.6647 Acc: 0.6014\n",
      "Epoch 003 | Train Loss: 0.6409 Acc: 0.6428 | Val Loss: 0.6181 Acc: 0.6618\n",
      "Epoch 004 | Train Loss: 0.6022 Acc: 0.6870 | Val Loss: 0.5916 Acc: 0.6957\n",
      "Epoch 005 | Train Loss: 0.5689 Acc: 0.7157 | Val Loss: 0.5663 Acc: 0.7168\n",
      "Epoch 006 | Train Loss: 0.5496 Acc: 0.7288 | Val Loss: 0.5822 Acc: 0.6993\n",
      "Epoch 007 | Train Loss: 0.5272 Acc: 0.7406 | Val Loss: 0.5290 Acc: 0.7325\n",
      "Epoch 008 | Train Loss: 0.5077 Acc: 0.7540 | Val Loss: 0.5303 Acc: 0.7397\n",
      "Epoch 009 | Train Loss: 0.4888 Acc: 0.7664 | Val Loss: 0.5072 Acc: 0.7524\n",
      "Epoch 010 | Train Loss: 0.4807 Acc: 0.7753 | Val Loss: 0.4958 Acc: 0.7591\n",
      "Epoch 011 | Train Loss: 0.4647 Acc: 0.7821 | Val Loss: 0.4735 Acc: 0.7693\n",
      "Epoch 012 | Train Loss: 0.4496 Acc: 0.7928 | Val Loss: 0.4577 Acc: 0.7868\n",
      "Epoch 013 | Train Loss: 0.4331 Acc: 0.7996 | Val Loss: 0.4301 Acc: 0.7935\n",
      "Epoch 014 | Train Loss: 0.4185 Acc: 0.8046 | Val Loss: 0.4105 Acc: 0.8074\n",
      "Epoch 015 | Train Loss: 0.3963 Acc: 0.8149 | Val Loss: 0.4209 Acc: 0.8001\n",
      "Epoch 016 | Train Loss: 0.3804 Acc: 0.8286 | Val Loss: 0.4198 Acc: 0.7995\n",
      "Epoch 017 | Train Loss: 0.3661 Acc: 0.8339 | Val Loss: 0.3846 Acc: 0.8225\n",
      "Epoch 018 | Train Loss: 0.3561 Acc: 0.8392 | Val Loss: 0.3548 Acc: 0.8412\n",
      "Epoch 019 | Train Loss: 0.3350 Acc: 0.8487 | Val Loss: 0.3365 Acc: 0.8557\n",
      "Epoch 020 | Train Loss: 0.3118 Acc: 0.8640 | Val Loss: 0.3596 Acc: 0.8442\n",
      "Epoch 021 | Train Loss: 0.2985 Acc: 0.8703 | Val Loss: 0.3203 Acc: 0.8659\n",
      "Epoch 022 | Train Loss: 0.2739 Acc: 0.8801 | Val Loss: 0.2976 Acc: 0.8786\n",
      "Epoch 023 | Train Loss: 0.2715 Acc: 0.8837 | Val Loss: 0.2950 Acc: 0.8877\n",
      "Epoch 024 | Train Loss: 0.2500 Acc: 0.8946 | Val Loss: 0.3017 Acc: 0.8720\n",
      "Epoch 025 | Train Loss: 0.2440 Acc: 0.8972 | Val Loss: 0.2955 Acc: 0.8774\n",
      "Epoch 026 | Train Loss: 0.2174 Acc: 0.9144 | Val Loss: 0.2544 Acc: 0.9016\n",
      "Epoch 027 | Train Loss: 0.2115 Acc: 0.9111 | Val Loss: 0.2366 Acc: 0.9052\n",
      "Epoch 028 | Train Loss: 0.2096 Acc: 0.9145 | Val Loss: 0.2507 Acc: 0.8967\n",
      "Epoch 029 | Train Loss: 0.2035 Acc: 0.9170 | Val Loss: 0.2282 Acc: 0.9118\n",
      "Epoch 030 | Train Loss: 0.1905 Acc: 0.9213 | Val Loss: 0.2206 Acc: 0.9124\n",
      "Epoch 031 | Train Loss: 0.1877 Acc: 0.9247 | Val Loss: 0.2736 Acc: 0.8883\n",
      "Epoch 032 | Train Loss: 0.1748 Acc: 0.9319 | Val Loss: 0.2026 Acc: 0.9239\n",
      "Epoch 033 | Train Loss: 0.1718 Acc: 0.9313 | Val Loss: 0.1886 Acc: 0.9293\n",
      "Epoch 034 | Train Loss: 0.1550 Acc: 0.9373 | Val Loss: 0.2025 Acc: 0.9203\n",
      "Epoch 035 | Train Loss: 0.1572 Acc: 0.9358 | Val Loss: 0.1995 Acc: 0.9179\n",
      "Epoch 036 | Train Loss: 0.1485 Acc: 0.9402 | Val Loss: 0.2124 Acc: 0.9161\n",
      "Epoch 037 | Train Loss: 0.1517 Acc: 0.9420 | Val Loss: 0.2024 Acc: 0.9227\n",
      "Epoch 038 | Train Loss: 0.1429 Acc: 0.9438 | Val Loss: 0.1938 Acc: 0.9227\n",
      "Epoch 039 | Train Loss: 0.1350 Acc: 0.9473 | Val Loss: 0.1745 Acc: 0.9372\n",
      "Epoch 040 | Train Loss: 0.1309 Acc: 0.9509 | Val Loss: 0.1711 Acc: 0.9366\n",
      "Epoch 041 | Train Loss: 0.1230 Acc: 0.9497 | Val Loss: 0.1621 Acc: 0.9384\n",
      "Epoch 042 | Train Loss: 0.1251 Acc: 0.9521 | Val Loss: 0.1641 Acc: 0.9378\n",
      "Epoch 043 | Train Loss: 0.1290 Acc: 0.9494 | Val Loss: 0.1722 Acc: 0.9366\n",
      "Epoch 044 | Train Loss: 0.1141 Acc: 0.9574 | Val Loss: 0.2090 Acc: 0.9227\n",
      "Epoch 045 | Train Loss: 0.1072 Acc: 0.9601 | Val Loss: 0.1656 Acc: 0.9354\n",
      "Epoch 046 | Train Loss: 0.1052 Acc: 0.9579 | Val Loss: 0.1712 Acc: 0.9384\n",
      "Epoch 047 | Train Loss: 0.1007 Acc: 0.9626 | Val Loss: 0.1817 Acc: 0.9312\n",
      "Epoch 048 | Train Loss: 0.1108 Acc: 0.9579 | Val Loss: 0.1647 Acc: 0.9324\n",
      "Epoch 049 | Train Loss: 0.1032 Acc: 0.9615 | Val Loss: 0.1831 Acc: 0.9354\n",
      "Epoch 050 | Train Loss: 0.1003 Acc: 0.9636 | Val Loss: 0.1787 Acc: 0.9348\n",
      "Epoch 051 | Train Loss: 0.0983 Acc: 0.9650 | Val Loss: 0.1691 Acc: 0.9366\n",
      "Early stopping triggered.\n",
      "Epoch 001 | Train Loss: 0.6808 Acc: 0.5703 | Val Loss: 0.6780 Acc: 0.5604\n",
      "Epoch 002 | Train Loss: 0.6642 Acc: 0.6027 | Val Loss: 0.6434 Acc: 0.6401\n",
      "Epoch 003 | Train Loss: 0.6085 Acc: 0.6864 | Val Loss: 0.6092 Acc: 0.6854\n",
      "Epoch 004 | Train Loss: 0.5728 Acc: 0.7149 | Val Loss: 0.5814 Acc: 0.7029\n",
      "Epoch 005 | Train Loss: 0.5599 Acc: 0.7234 | Val Loss: 0.5422 Acc: 0.7313\n",
      "Epoch 006 | Train Loss: 0.5290 Acc: 0.7406 | Val Loss: 0.5324 Acc: 0.7319\n",
      "Epoch 007 | Train Loss: 0.5112 Acc: 0.7580 | Val Loss: 0.4915 Acc: 0.7579\n",
      "Epoch 008 | Train Loss: 0.4919 Acc: 0.7626 | Val Loss: 0.4738 Acc: 0.7651\n",
      "Epoch 009 | Train Loss: 0.4731 Acc: 0.7723 | Val Loss: 0.4652 Acc: 0.7760\n",
      "Epoch 010 | Train Loss: 0.4525 Acc: 0.7927 | Val Loss: 0.4247 Acc: 0.7929\n",
      "Epoch 011 | Train Loss: 0.4319 Acc: 0.8011 | Val Loss: 0.4159 Acc: 0.8231\n",
      "Epoch 012 | Train Loss: 0.3986 Acc: 0.8212 | Val Loss: 0.4075 Acc: 0.8116\n",
      "Epoch 013 | Train Loss: 0.3936 Acc: 0.8258 | Val Loss: 0.3634 Acc: 0.8424\n",
      "Epoch 014 | Train Loss: 0.3664 Acc: 0.8416 | Val Loss: 0.3229 Acc: 0.8684\n",
      "Epoch 015 | Train Loss: 0.3348 Acc: 0.8593 | Val Loss: 0.3469 Acc: 0.8472\n",
      "Epoch 016 | Train Loss: 0.3403 Acc: 0.8564 | Val Loss: 0.3208 Acc: 0.8678\n",
      "Epoch 017 | Train Loss: 0.3225 Acc: 0.8682 | Val Loss: 0.3181 Acc: 0.8653\n",
      "Epoch 018 | Train Loss: 0.3012 Acc: 0.8763 | Val Loss: 0.2697 Acc: 0.8835\n",
      "Epoch 019 | Train Loss: 0.2992 Acc: 0.8744 | Val Loss: 0.2732 Acc: 0.8919\n",
      "Epoch 020 | Train Loss: 0.2755 Acc: 0.8842 | Val Loss: 0.2526 Acc: 0.8949\n",
      "Epoch 021 | Train Loss: 0.2642 Acc: 0.8933 | Val Loss: 0.2805 Acc: 0.8919\n",
      "Epoch 022 | Train Loss: 0.2644 Acc: 0.8948 | Val Loss: 0.2609 Acc: 0.8992\n",
      "Epoch 023 | Train Loss: 0.2588 Acc: 0.8939 | Val Loss: 0.2716 Acc: 0.8925\n",
      "Epoch 024 | Train Loss: 0.2406 Acc: 0.9044 | Val Loss: 0.2518 Acc: 0.9028\n",
      "Epoch 025 | Train Loss: 0.2365 Acc: 0.9082 | Val Loss: 0.2605 Acc: 0.8931\n",
      "Epoch 026 | Train Loss: 0.2323 Acc: 0.9052 | Val Loss: 0.2278 Acc: 0.9161\n",
      "Epoch 027 | Train Loss: 0.2197 Acc: 0.9121 | Val Loss: 0.2215 Acc: 0.9082\n",
      "Epoch 028 | Train Loss: 0.2269 Acc: 0.9100 | Val Loss: 0.2245 Acc: 0.9106\n",
      "Epoch 029 | Train Loss: 0.2217 Acc: 0.9151 | Val Loss: 0.2278 Acc: 0.9124\n",
      "Epoch 030 | Train Loss: 0.2099 Acc: 0.9222 | Val Loss: 0.2040 Acc: 0.9287\n",
      "Epoch 031 | Train Loss: 0.2081 Acc: 0.9200 | Val Loss: 0.2081 Acc: 0.9257\n",
      "Epoch 032 | Train Loss: 0.1929 Acc: 0.9244 | Val Loss: 0.2101 Acc: 0.9209\n",
      "Epoch 033 | Train Loss: 0.1926 Acc: 0.9260 | Val Loss: 0.2381 Acc: 0.9118\n",
      "Epoch 034 | Train Loss: 0.2014 Acc: 0.9192 | Val Loss: 0.2272 Acc: 0.9118\n",
      "Epoch 035 | Train Loss: 0.1854 Acc: 0.9262 | Val Loss: 0.2076 Acc: 0.9185\n",
      "Epoch 036 | Train Loss: 0.1894 Acc: 0.9259 | Val Loss: 0.1916 Acc: 0.9227\n",
      "Epoch 037 | Train Loss: 0.1921 Acc: 0.9251 | Val Loss: 0.1848 Acc: 0.9324\n",
      "Epoch 038 | Train Loss: 0.1730 Acc: 0.9330 | Val Loss: 0.1953 Acc: 0.9300\n",
      "Epoch 039 | Train Loss: 0.1796 Acc: 0.9348 | Val Loss: 0.1757 Acc: 0.9336\n",
      "Epoch 040 | Train Loss: 0.1835 Acc: 0.9274 | Val Loss: 0.2003 Acc: 0.9227\n",
      "Epoch 041 | Train Loss: 0.1725 Acc: 0.9313 | Val Loss: 0.1864 Acc: 0.9342\n",
      "Epoch 042 | Train Loss: 0.1538 Acc: 0.9381 | Val Loss: 0.2188 Acc: 0.9034\n",
      "Epoch 043 | Train Loss: 0.1585 Acc: 0.9392 | Val Loss: 0.2177 Acc: 0.9185\n",
      "Epoch 044 | Train Loss: 0.1760 Acc: 0.9328 | Val Loss: 0.2156 Acc: 0.9106\n",
      "Epoch 045 | Train Loss: 0.1666 Acc: 0.9358 | Val Loss: 0.1881 Acc: 0.9281\n",
      "Epoch 046 | Train Loss: 0.1805 Acc: 0.9299 | Val Loss: 0.2024 Acc: 0.9191\n",
      "Epoch 047 | Train Loss: 0.1511 Acc: 0.9455 | Val Loss: 0.1558 Acc: 0.9372\n",
      "Epoch 048 | Train Loss: 0.1445 Acc: 0.9458 | Val Loss: 0.1708 Acc: 0.9336\n",
      "Epoch 049 | Train Loss: 0.1430 Acc: 0.9458 | Val Loss: 0.5917 Acc: 0.8345\n",
      "Overfitting detected\n",
      "Epoch 001 | Train Loss: 0.6802 Acc: 0.5747 | Val Loss: 0.6746 Acc: 0.5864\n",
      "Epoch 002 | Train Loss: 0.6643 Acc: 0.6059 | Val Loss: 0.6691 Acc: 0.5888\n",
      "Epoch 003 | Train Loss: 0.6512 Acc: 0.6195 | Val Loss: 0.6263 Acc: 0.6667\n",
      "Epoch 004 | Train Loss: 0.6011 Acc: 0.6918 | Val Loss: 0.5724 Acc: 0.6987\n",
      "Epoch 005 | Train Loss: 0.5599 Acc: 0.7238 | Val Loss: 0.5551 Acc: 0.7258\n",
      "Epoch 006 | Train Loss: 0.5264 Acc: 0.7533 | Val Loss: 0.5256 Acc: 0.7379\n",
      "Epoch 007 | Train Loss: 0.4849 Acc: 0.7776 | Val Loss: 0.4929 Acc: 0.7615\n",
      "Epoch 008 | Train Loss: 0.4548 Acc: 0.7947 | Val Loss: 0.4612 Acc: 0.7826\n",
      "Epoch 009 | Train Loss: 0.4270 Acc: 0.8070 | Val Loss: 0.4439 Acc: 0.8031\n",
      "Epoch 010 | Train Loss: 0.4005 Acc: 0.8181 | Val Loss: 0.4403 Acc: 0.7959\n",
      "Epoch 011 | Train Loss: 0.3713 Acc: 0.8374 | Val Loss: 0.3966 Acc: 0.8200\n",
      "Epoch 012 | Train Loss: 0.3421 Acc: 0.8561 | Val Loss: 0.3457 Acc: 0.8514\n",
      "Epoch 013 | Train Loss: 0.3149 Acc: 0.8685 | Val Loss: 0.3308 Acc: 0.8502\n",
      "Epoch 014 | Train Loss: 0.2880 Acc: 0.8745 | Val Loss: 0.2961 Acc: 0.8774\n",
      "Epoch 015 | Train Loss: 0.2599 Acc: 0.8931 | Val Loss: 0.2907 Acc: 0.8822\n",
      "Epoch 016 | Train Loss: 0.2394 Acc: 0.9047 | Val Loss: 0.2585 Acc: 0.8949\n",
      "Epoch 017 | Train Loss: 0.2166 Acc: 0.9141 | Val Loss: 0.2749 Acc: 0.8895\n",
      "Epoch 018 | Train Loss: 0.2045 Acc: 0.9225 | Val Loss: 0.2563 Acc: 0.8973\n",
      "Epoch 019 | Train Loss: 0.1920 Acc: 0.9271 | Val Loss: 0.2163 Acc: 0.9124\n",
      "Epoch 020 | Train Loss: 0.1636 Acc: 0.9340 | Val Loss: 0.2084 Acc: 0.9149\n",
      "Epoch 021 | Train Loss: 0.1535 Acc: 0.9401 | Val Loss: 0.2285 Acc: 0.9106\n",
      "Epoch 022 | Train Loss: 0.1511 Acc: 0.9407 | Val Loss: 0.2680 Acc: 0.9070\n",
      "Epoch 023 | Train Loss: 0.1342 Acc: 0.9472 | Val Loss: 0.2351 Acc: 0.9161\n",
      "Epoch 024 | Train Loss: 0.1292 Acc: 0.9518 | Val Loss: 0.2351 Acc: 0.9100\n",
      "Epoch 025 | Train Loss: 0.1171 Acc: 0.9562 | Val Loss: 0.2416 Acc: 0.9173\n",
      "Epoch 026 | Train Loss: 0.1155 Acc: 0.9547 | Val Loss: 0.1892 Acc: 0.9318\n",
      "Epoch 027 | Train Loss: 0.1066 Acc: 0.9598 | Val Loss: 0.1780 Acc: 0.9287\n",
      "Epoch 028 | Train Loss: 0.0966 Acc: 0.9636 | Val Loss: 0.1697 Acc: 0.9402\n",
      "Epoch 029 | Train Loss: 0.0878 Acc: 0.9668 | Val Loss: 0.2048 Acc: 0.9263\n",
      "Epoch 030 | Train Loss: 0.0786 Acc: 0.9730 | Val Loss: 0.2337 Acc: 0.9197\n",
      "Epoch 031 | Train Loss: 0.0910 Acc: 0.9648 | Val Loss: 0.2108 Acc: 0.9245\n",
      "Epoch 032 | Train Loss: 0.0766 Acc: 0.9724 | Val Loss: 0.2139 Acc: 0.9318\n",
      "Epoch 033 | Train Loss: 0.0774 Acc: 0.9701 | Val Loss: 0.2265 Acc: 0.9245\n",
      "Epoch 034 | Train Loss: 0.0764 Acc: 0.9712 | Val Loss: 0.2761 Acc: 0.9064\n",
      "Epoch 035 | Train Loss: 0.0717 Acc: 0.9724 | Val Loss: 0.1910 Acc: 0.9396\n",
      "Epoch 036 | Train Loss: 0.0687 Acc: 0.9743 | Val Loss: 0.1659 Acc: 0.9450\n",
      "Epoch 037 | Train Loss: 0.0643 Acc: 0.9784 | Val Loss: 0.2355 Acc: 0.9215\n",
      "Epoch 038 | Train Loss: 0.0672 Acc: 0.9754 | Val Loss: 0.2023 Acc: 0.9402\n",
      "Epoch 039 | Train Loss: 0.0632 Acc: 0.9783 | Val Loss: 0.2522 Acc: 0.9281\n",
      "Epoch 040 | Train Loss: 0.0599 Acc: 0.9778 | Val Loss: 0.1858 Acc: 0.9414\n",
      "Epoch 041 | Train Loss: 0.0596 Acc: 0.9789 | Val Loss: 0.2184 Acc: 0.9306\n",
      "Epoch 042 | Train Loss: 0.0618 Acc: 0.9760 | Val Loss: 0.2021 Acc: 0.9354\n",
      "Epoch 043 | Train Loss: 0.0547 Acc: 0.9799 | Val Loss: 0.2131 Acc: 0.9408\n",
      "Epoch 044 | Train Loss: 0.0515 Acc: 0.9808 | Val Loss: 0.2500 Acc: 0.9354\n",
      "Epoch 045 | Train Loss: 0.0514 Acc: 0.9826 | Val Loss: 0.2264 Acc: 0.9336\n",
      "Epoch 046 | Train Loss: 0.0633 Acc: 0.9761 | Val Loss: 0.2082 Acc: 0.9378\n",
      "Early stopping triggered.\n",
      "Epoch 001 | Train Loss: 0.6890 Acc: 0.5553 | Val Loss: 0.6867 Acc: 0.5586\n",
      "Epoch 002 | Train Loss: 0.6868 Acc: 0.5597 | Val Loss: 0.6863 Acc: 0.5586\n",
      "Epoch 003 | Train Loss: 0.6871 Acc: 0.5582 | Val Loss: 0.6863 Acc: 0.5586\n",
      "Epoch 004 | Train Loss: 0.6873 Acc: 0.5582 | Val Loss: 0.6863 Acc: 0.5586\n",
      "Epoch 005 | Train Loss: 0.6868 Acc: 0.5582 | Val Loss: 0.6863 Acc: 0.5586\n",
      "Epoch 006 | Train Loss: 0.6868 Acc: 0.5582 | Val Loss: 0.6863 Acc: 0.5586\n",
      "Epoch 007 | Train Loss: 0.6868 Acc: 0.5582 | Val Loss: 0.6864 Acc: 0.5586\n",
      "Epoch 008 | Train Loss: 0.6867 Acc: 0.5582 | Val Loss: 0.6863 Acc: 0.5586\n",
      "Epoch 009 | Train Loss: 0.6868 Acc: 0.5582 | Val Loss: 0.6863 Acc: 0.5586\n",
      "Epoch 010 | Train Loss: 0.6869 Acc: 0.5582 | Val Loss: 0.6863 Acc: 0.5586\n",
      "Epoch 011 | Train Loss: 0.6865 Acc: 0.5582 | Val Loss: 0.6863 Acc: 0.5586\n",
      "Epoch 012 | Train Loss: 0.6865 Acc: 0.5582 | Val Loss: 0.6867 Acc: 0.5586\n",
      "Epoch 013 | Train Loss: 0.6869 Acc: 0.5582 | Val Loss: 0.6867 Acc: 0.5586\n",
      "Epoch 014 | Train Loss: 0.6866 Acc: 0.5582 | Val Loss: 0.6864 Acc: 0.5586\n",
      "Epoch 015 | Train Loss: 0.6866 Acc: 0.5582 | Val Loss: 0.6865 Acc: 0.5586\n",
      "Epoch 016 | Train Loss: 0.6865 Acc: 0.5582 | Val Loss: 0.6863 Acc: 0.5586\n",
      "Epoch 017 | Train Loss: 0.6867 Acc: 0.5582 | Val Loss: 0.6868 Acc: 0.5586\n",
      "Epoch 018 | Train Loss: 0.6867 Acc: 0.5582 | Val Loss: 0.6865 Acc: 0.5586\n",
      "Epoch 019 | Train Loss: 0.6866 Acc: 0.5582 | Val Loss: 0.6864 Acc: 0.5586\n",
      "Epoch 020 | Train Loss: 0.6867 Acc: 0.5582 | Val Loss: 0.6863 Acc: 0.5586\n",
      "Epoch 021 | Train Loss: 0.6870 Acc: 0.5582 | Val Loss: 0.6865 Acc: 0.5586\n",
      "Epoch 022 | Train Loss: 0.6867 Acc: 0.5582 | Val Loss: 0.6864 Acc: 0.5586\n",
      "Epoch 023 | Train Loss: 0.6868 Acc: 0.5582 | Val Loss: 0.6868 Acc: 0.5586\n",
      "Epoch 024 | Train Loss: 0.6868 Acc: 0.5582 | Val Loss: 0.6863 Acc: 0.5586\n",
      "Epoch 025 | Train Loss: 0.6876 Acc: 0.5582 | Val Loss: 0.6863 Acc: 0.5586\n",
      "Epoch 026 | Train Loss: 0.6870 Acc: 0.5582 | Val Loss: 0.6864 Acc: 0.5586\n",
      "Epoch 027 | Train Loss: 0.6872 Acc: 0.5567 | Val Loss: 0.6863 Acc: 0.5586\n",
      "Epoch 028 | Train Loss: 0.6868 Acc: 0.5582 | Val Loss: 0.6866 Acc: 0.5586\n",
      "Epoch 029 | Train Loss: 0.6867 Acc: 0.5582 | Val Loss: 0.6865 Acc: 0.5586\n",
      "Epoch 030 | Train Loss: 0.6869 Acc: 0.5582 | Val Loss: 0.6863 Acc: 0.5586\n",
      "Epoch 031 | Train Loss: 0.6865 Acc: 0.5582 | Val Loss: 0.6865 Acc: 0.5586\n",
      "Epoch 032 | Train Loss: 0.6887 Acc: 0.5561 | Val Loss: 0.6863 Acc: 0.5586\n",
      "Epoch 033 | Train Loss: 0.6873 Acc: 0.5585 | Val Loss: 0.6864 Acc: 0.5586\n",
      "Epoch 034 | Train Loss: 0.6866 Acc: 0.5582 | Val Loss: 0.6864 Acc: 0.5586\n",
      "Early stopping triggered.\n",
      "Epoch 001 | Train Loss: 0.6894 Acc: 0.5504 | Val Loss: 0.6889 Acc: 0.5586\n",
      "Epoch 002 | Train Loss: 0.6823 Acc: 0.5701 | Val Loss: 0.6572 Acc: 0.6081\n",
      "Epoch 003 | Train Loss: 0.6575 Acc: 0.6277 | Val Loss: 0.6256 Acc: 0.6649\n",
      "Epoch 004 | Train Loss: 0.6271 Acc: 0.6699 | Val Loss: 0.6003 Acc: 0.6890\n",
      "Epoch 005 | Train Loss: 0.6137 Acc: 0.6837 | Val Loss: 0.5984 Acc: 0.6812\n",
      "Epoch 006 | Train Loss: 0.6024 Acc: 0.6902 | Val Loss: 0.6114 Acc: 0.6836\n",
      "Epoch 007 | Train Loss: 0.5952 Acc: 0.6875 | Val Loss: 0.5841 Acc: 0.6938\n",
      "Epoch 008 | Train Loss: 0.5800 Acc: 0.7056 | Val Loss: 0.5754 Acc: 0.7065\n",
      "Epoch 009 | Train Loss: 0.5736 Acc: 0.7072 | Val Loss: 0.5609 Acc: 0.7180\n",
      "Epoch 010 | Train Loss: 0.5668 Acc: 0.7133 | Val Loss: 0.5600 Acc: 0.7234\n",
      "Epoch 011 | Train Loss: 0.5633 Acc: 0.7155 | Val Loss: 0.5401 Acc: 0.7289\n",
      "Epoch 012 | Train Loss: 0.5568 Acc: 0.7229 | Val Loss: 0.5730 Acc: 0.6896\n",
      "Epoch 013 | Train Loss: 0.5511 Acc: 0.7240 | Val Loss: 0.5377 Acc: 0.7277\n",
      "Epoch 014 | Train Loss: 0.5446 Acc: 0.7324 | Val Loss: 0.5358 Acc: 0.7331\n",
      "Epoch 015 | Train Loss: 0.5357 Acc: 0.7335 | Val Loss: 0.5468 Acc: 0.7222\n",
      "Epoch 016 | Train Loss: 0.5331 Acc: 0.7331 | Val Loss: 0.5093 Acc: 0.7500\n",
      "Epoch 017 | Train Loss: 0.5085 Acc: 0.7477 | Val Loss: 0.5172 Acc: 0.7512\n",
      "Epoch 018 | Train Loss: 0.5043 Acc: 0.7495 | Val Loss: 0.4866 Acc: 0.7603\n",
      "Epoch 019 | Train Loss: 0.4987 Acc: 0.7632 | Val Loss: 0.4529 Acc: 0.7808\n",
      "Epoch 020 | Train Loss: 0.4827 Acc: 0.7693 | Val Loss: 0.4381 Acc: 0.7856\n",
      "Epoch 021 | Train Loss: 0.4738 Acc: 0.7750 | Val Loss: 0.4754 Acc: 0.7591\n",
      "Epoch 022 | Train Loss: 0.4724 Acc: 0.7735 | Val Loss: 0.4306 Acc: 0.8007\n",
      "Epoch 023 | Train Loss: 0.4460 Acc: 0.7995 | Val Loss: 0.4810 Acc: 0.7699\n",
      "Epoch 024 | Train Loss: 0.4384 Acc: 0.8024 | Val Loss: 0.3901 Acc: 0.8219\n",
      "Epoch 025 | Train Loss: 0.4229 Acc: 0.8093 | Val Loss: 0.3712 Acc: 0.8237\n",
      "Epoch 026 | Train Loss: 0.4205 Acc: 0.8140 | Val Loss: 0.3851 Acc: 0.8285\n",
      "Epoch 027 | Train Loss: 0.4116 Acc: 0.8150 | Val Loss: 0.3890 Acc: 0.8158\n",
      "Epoch 028 | Train Loss: 0.3974 Acc: 0.8267 | Val Loss: 0.3767 Acc: 0.8267\n",
      "Epoch 029 | Train Loss: 0.3873 Acc: 0.8324 | Val Loss: 0.3506 Acc: 0.8351\n",
      "Epoch 030 | Train Loss: 0.3758 Acc: 0.8374 | Val Loss: 0.3537 Acc: 0.8430\n",
      "Epoch 031 | Train Loss: 0.3790 Acc: 0.8403 | Val Loss: 0.3566 Acc: 0.8376\n",
      "Epoch 032 | Train Loss: 0.3640 Acc: 0.8428 | Val Loss: 0.3277 Acc: 0.8472\n",
      "Epoch 033 | Train Loss: 0.3639 Acc: 0.8407 | Val Loss: 0.3122 Acc: 0.8623\n",
      "Epoch 034 | Train Loss: 0.3546 Acc: 0.8490 | Val Loss: 0.3198 Acc: 0.8593\n",
      "Epoch 035 | Train Loss: 0.3537 Acc: 0.8519 | Val Loss: 0.3234 Acc: 0.8665\n",
      "Epoch 036 | Train Loss: 0.3506 Acc: 0.8552 | Val Loss: 0.3336 Acc: 0.8545\n",
      "Epoch 037 | Train Loss: 0.3503 Acc: 0.8554 | Val Loss: 0.2971 Acc: 0.8768\n",
      "Epoch 038 | Train Loss: 0.3343 Acc: 0.8615 | Val Loss: 0.2895 Acc: 0.8835\n",
      "Epoch 039 | Train Loss: 0.3238 Acc: 0.8615 | Val Loss: 0.2947 Acc: 0.8750\n",
      "Epoch 040 | Train Loss: 0.3295 Acc: 0.8661 | Val Loss: 0.3316 Acc: 0.8665\n",
      "Epoch 041 | Train Loss: 0.3258 Acc: 0.8658 | Val Loss: 0.2797 Acc: 0.8822\n",
      "Epoch 042 | Train Loss: 0.3210 Acc: 0.8643 | Val Loss: 0.2977 Acc: 0.8678\n",
      "Epoch 043 | Train Loss: 0.3117 Acc: 0.8733 | Val Loss: 0.2748 Acc: 0.8895\n",
      "Epoch 044 | Train Loss: 0.3181 Acc: 0.8658 | Val Loss: 0.2883 Acc: 0.8865\n",
      "Epoch 045 | Train Loss: 0.3141 Acc: 0.8676 | Val Loss: 0.3740 Acc: 0.8182\n",
      "Epoch 046 | Train Loss: 0.3178 Acc: 0.8667 | Val Loss: 0.2743 Acc: 0.8810\n",
      "Epoch 047 | Train Loss: 0.3092 Acc: 0.8729 | Val Loss: 0.2722 Acc: 0.8883\n",
      "Epoch 048 | Train Loss: 0.3115 Acc: 0.8701 | Val Loss: 0.2678 Acc: 0.8895\n",
      "Epoch 049 | Train Loss: 0.2960 Acc: 0.8789 | Val Loss: 0.2798 Acc: 0.8744\n",
      "Epoch 050 | Train Loss: 0.2994 Acc: 0.8762 | Val Loss: 0.2649 Acc: 0.8889\n",
      "Epoch 051 | Train Loss: 0.3035 Acc: 0.8738 | Val Loss: 0.3056 Acc: 0.8659\n",
      "Epoch 052 | Train Loss: 0.2881 Acc: 0.8812 | Val Loss: 0.2769 Acc: 0.8877\n",
      "Epoch 053 | Train Loss: 0.2858 Acc: 0.8865 | Val Loss: 0.2979 Acc: 0.8810\n",
      "Epoch 054 | Train Loss: 0.2877 Acc: 0.8868 | Val Loss: 0.3058 Acc: 0.8671\n",
      "Epoch 055 | Train Loss: 0.2872 Acc: 0.8821 | Val Loss: 0.2502 Acc: 0.9022\n",
      "Epoch 056 | Train Loss: 0.2835 Acc: 0.8846 | Val Loss: 0.2332 Acc: 0.9136\n",
      "Epoch 057 | Train Loss: 0.2794 Acc: 0.8871 | Val Loss: 0.2831 Acc: 0.8780\n",
      "Epoch 058 | Train Loss: 0.2755 Acc: 0.8862 | Val Loss: 0.3067 Acc: 0.8569\n",
      "Epoch 059 | Train Loss: 0.2832 Acc: 0.8874 | Val Loss: 0.2444 Acc: 0.9034\n",
      "Epoch 060 | Train Loss: 0.2641 Acc: 0.8954 | Val Loss: 0.2265 Acc: 0.9106\n",
      "Epoch 001 | Train Loss: 0.6871 Acc: 0.5588 | Val Loss: 0.6862 Acc: 0.5586\n",
      "Epoch 002 | Train Loss: 0.6829 Acc: 0.5738 | Val Loss: 0.6577 Acc: 0.5990\n",
      "Epoch 003 | Train Loss: 0.6686 Acc: 0.5955 | Val Loss: 0.6585 Acc: 0.5894\n",
      "Epoch 004 | Train Loss: 0.6384 Acc: 0.6560 | Val Loss: 0.6016 Acc: 0.6793\n",
      "Epoch 005 | Train Loss: 0.6199 Acc: 0.6784 | Val Loss: 0.5983 Acc: 0.6763\n",
      "Epoch 006 | Train Loss: 0.6094 Acc: 0.6787 | Val Loss: 0.5933 Acc: 0.6920\n",
      "Epoch 007 | Train Loss: 0.5862 Acc: 0.7015 | Val Loss: 0.5758 Acc: 0.7017\n",
      "Epoch 008 | Train Loss: 0.5770 Acc: 0.7090 | Val Loss: 0.5729 Acc: 0.7041\n",
      "Epoch 009 | Train Loss: 0.5607 Acc: 0.7189 | Val Loss: 0.5504 Acc: 0.7240\n",
      "Epoch 010 | Train Loss: 0.5609 Acc: 0.7155 | Val Loss: 0.5523 Acc: 0.7162\n",
      "Epoch 011 | Train Loss: 0.5523 Acc: 0.7232 | Val Loss: 0.5233 Acc: 0.7343\n",
      "Epoch 012 | Train Loss: 0.5396 Acc: 0.7323 | Val Loss: 0.5066 Acc: 0.7488\n",
      "Epoch 013 | Train Loss: 0.5151 Acc: 0.7485 | Val Loss: 0.5061 Acc: 0.7506\n",
      "Epoch 014 | Train Loss: 0.5133 Acc: 0.7498 | Val Loss: 0.4845 Acc: 0.7736\n",
      "Epoch 015 | Train Loss: 0.4954 Acc: 0.7642 | Val Loss: 0.4683 Acc: 0.7808\n",
      "Epoch 016 | Train Loss: 0.4798 Acc: 0.7764 | Val Loss: 0.4572 Acc: 0.7905\n",
      "Epoch 017 | Train Loss: 0.4713 Acc: 0.7802 | Val Loss: 0.4658 Acc: 0.7808\n",
      "Epoch 018 | Train Loss: 0.4610 Acc: 0.7907 | Val Loss: 0.4178 Acc: 0.8104\n",
      "Epoch 019 | Train Loss: 0.4407 Acc: 0.7986 | Val Loss: 0.4038 Acc: 0.8122\n",
      "Epoch 020 | Train Loss: 0.4323 Acc: 0.8031 | Val Loss: 0.4210 Acc: 0.8007\n",
      "Epoch 021 | Train Loss: 0.4338 Acc: 0.8019 | Val Loss: 0.4359 Acc: 0.8188\n",
      "Epoch 022 | Train Loss: 0.4147 Acc: 0.8149 | Val Loss: 0.3872 Acc: 0.8207\n",
      "Epoch 023 | Train Loss: 0.4011 Acc: 0.8233 | Val Loss: 0.3771 Acc: 0.8339\n",
      "Epoch 024 | Train Loss: 0.4065 Acc: 0.8190 | Val Loss: 0.3917 Acc: 0.8237\n",
      "Epoch 025 | Train Loss: 0.4024 Acc: 0.8252 | Val Loss: 0.3798 Acc: 0.8297\n",
      "Epoch 026 | Train Loss: 0.3989 Acc: 0.8190 | Val Loss: 0.3940 Acc: 0.8237\n",
      "Epoch 027 | Train Loss: 0.3925 Acc: 0.8205 | Val Loss: 0.3985 Acc: 0.8219\n",
      "Epoch 028 | Train Loss: 0.3845 Acc: 0.8318 | Val Loss: 0.3829 Acc: 0.8243\n",
      "Epoch 029 | Train Loss: 0.3604 Acc: 0.8393 | Val Loss: 0.3823 Acc: 0.8291\n",
      "Epoch 030 | Train Loss: 0.3666 Acc: 0.8433 | Val Loss: 0.3436 Acc: 0.8551\n",
      "Epoch 031 | Train Loss: 0.3638 Acc: 0.8455 | Val Loss: 0.3884 Acc: 0.8424\n",
      "Epoch 032 | Train Loss: 0.3613 Acc: 0.8477 | Val Loss: 0.3556 Acc: 0.8490\n",
      "Epoch 033 | Train Loss: 0.3582 Acc: 0.8466 | Val Loss: 0.3690 Acc: 0.8436\n",
      "Epoch 034 | Train Loss: 0.3471 Acc: 0.8455 | Val Loss: 0.3318 Acc: 0.8635\n",
      "Epoch 035 | Train Loss: 0.3330 Acc: 0.8584 | Val Loss: 0.3467 Acc: 0.8551\n",
      "Epoch 036 | Train Loss: 0.3382 Acc: 0.8590 | Val Loss: 0.3536 Acc: 0.8472\n",
      "Epoch 037 | Train Loss: 0.3331 Acc: 0.8655 | Val Loss: 0.3180 Acc: 0.8690\n",
      "Epoch 038 | Train Loss: 0.3263 Acc: 0.8637 | Val Loss: 0.3385 Acc: 0.8617\n",
      "Epoch 039 | Train Loss: 0.3241 Acc: 0.8677 | Val Loss: 0.3292 Acc: 0.8714\n",
      "Epoch 040 | Train Loss: 0.3086 Acc: 0.8733 | Val Loss: 0.3602 Acc: 0.8351\n",
      "Epoch 041 | Train Loss: 0.3098 Acc: 0.8717 | Val Loss: 0.3752 Acc: 0.8412\n",
      "Epoch 042 | Train Loss: 0.3181 Acc: 0.8683 | Val Loss: 0.3203 Acc: 0.8611\n",
      "Epoch 043 | Train Loss: 0.3160 Acc: 0.8717 | Val Loss: 0.3208 Acc: 0.8563\n",
      "Epoch 044 | Train Loss: 0.3045 Acc: 0.8741 | Val Loss: 0.2998 Acc: 0.8804\n",
      "Epoch 045 | Train Loss: 0.3049 Acc: 0.8751 | Val Loss: 0.3594 Acc: 0.8521\n",
      "Epoch 046 | Train Loss: 0.3083 Acc: 0.8748 | Val Loss: 0.3145 Acc: 0.8665\n",
      "Epoch 047 | Train Loss: 0.2969 Acc: 0.8742 | Val Loss: 0.2926 Acc: 0.8810\n",
      "Epoch 048 | Train Loss: 0.3106 Acc: 0.8720 | Val Loss: 0.3039 Acc: 0.8678\n",
      "Epoch 049 | Train Loss: 0.2963 Acc: 0.8813 | Val Loss: 0.3380 Acc: 0.8557\n",
      "Epoch 050 | Train Loss: 0.3113 Acc: 0.8735 | Val Loss: 0.3310 Acc: 0.8563\n",
      "Epoch 051 | Train Loss: 0.2899 Acc: 0.8786 | Val Loss: 0.3238 Acc: 0.8593\n",
      "Epoch 052 | Train Loss: 0.2960 Acc: 0.8824 | Val Loss: 0.2948 Acc: 0.8762\n",
      "Epoch 053 | Train Loss: 0.2890 Acc: 0.8849 | Val Loss: 0.3049 Acc: 0.8720\n",
      "Epoch 054 | Train Loss: 0.2730 Acc: 0.8872 | Val Loss: 0.3529 Acc: 0.8545\n",
      "Epoch 055 | Train Loss: 0.3028 Acc: 0.8670 | Val Loss: 0.3032 Acc: 0.8822\n",
      "Epoch 056 | Train Loss: 0.2826 Acc: 0.8862 | Val Loss: 0.3186 Acc: 0.8708\n",
      "Epoch 057 | Train Loss: 0.2825 Acc: 0.8872 | Val Loss: 0.2874 Acc: 0.8774\n",
      "Epoch 058 | Train Loss: 0.2821 Acc: 0.8833 | Val Loss: 0.3444 Acc: 0.8527\n",
      "Epoch 059 | Train Loss: 0.2991 Acc: 0.8780 | Val Loss: 0.3105 Acc: 0.8678\n",
      "Epoch 060 | Train Loss: 0.2744 Acc: 0.8868 | Val Loss: 0.2894 Acc: 0.8865\n",
      "Epoch 001 | Train Loss: 0.6839 Acc: 0.5686 | Val Loss: 0.6763 Acc: 0.5900\n",
      "Epoch 002 | Train Loss: 0.6756 Acc: 0.5928 | Val Loss: 0.6745 Acc: 0.5900\n",
      "Epoch 003 | Train Loss: 0.6712 Acc: 0.5961 | Val Loss: 0.6685 Acc: 0.5972\n",
      "Epoch 004 | Train Loss: 0.6627 Acc: 0.6070 | Val Loss: 0.6626 Acc: 0.5996\n",
      "Epoch 005 | Train Loss: 0.6598 Acc: 0.6086 | Val Loss: 0.6424 Acc: 0.6540\n",
      "Epoch 006 | Train Loss: 0.6350 Acc: 0.6606 | Val Loss: 0.6181 Acc: 0.6739\n",
      "Epoch 007 | Train Loss: 0.6106 Acc: 0.6838 | Val Loss: 0.6105 Acc: 0.6860\n",
      "Epoch 008 | Train Loss: 0.5913 Acc: 0.6994 | Val Loss: 0.6042 Acc: 0.6926\n",
      "Epoch 009 | Train Loss: 0.5728 Acc: 0.7155 | Val Loss: 0.5862 Acc: 0.6896\n",
      "Epoch 010 | Train Loss: 0.5569 Acc: 0.7240 | Val Loss: 0.5513 Acc: 0.7258\n",
      "Epoch 011 | Train Loss: 0.5488 Acc: 0.7334 | Val Loss: 0.5503 Acc: 0.7228\n",
      "Epoch 012 | Train Loss: 0.5417 Acc: 0.7337 | Val Loss: 0.5494 Acc: 0.7258\n",
      "Epoch 013 | Train Loss: 0.5315 Acc: 0.7423 | Val Loss: 0.5395 Acc: 0.7307\n",
      "Epoch 014 | Train Loss: 0.5240 Acc: 0.7451 | Val Loss: 0.5562 Acc: 0.7246\n",
      "Epoch 015 | Train Loss: 0.5209 Acc: 0.7483 | Val Loss: 0.5446 Acc: 0.7367\n",
      "Epoch 016 | Train Loss: 0.5094 Acc: 0.7545 | Val Loss: 0.5208 Acc: 0.7409\n",
      "Epoch 017 | Train Loss: 0.5038 Acc: 0.7562 | Val Loss: 0.5257 Acc: 0.7355\n",
      "Epoch 018 | Train Loss: 0.4850 Acc: 0.7664 | Val Loss: 0.4945 Acc: 0.7560\n",
      "Epoch 019 | Train Loss: 0.4729 Acc: 0.7755 | Val Loss: 0.4986 Acc: 0.7554\n",
      "Epoch 020 | Train Loss: 0.4653 Acc: 0.7740 | Val Loss: 0.5034 Acc: 0.7627\n",
      "Epoch 021 | Train Loss: 0.4557 Acc: 0.7870 | Val Loss: 0.4644 Acc: 0.7754\n",
      "Epoch 022 | Train Loss: 0.4395 Acc: 0.7918 | Val Loss: 0.4715 Acc: 0.7699\n",
      "Epoch 023 | Train Loss: 0.4237 Acc: 0.8010 | Val Loss: 0.4402 Acc: 0.7935\n",
      "Epoch 024 | Train Loss: 0.4098 Acc: 0.8113 | Val Loss: 0.4279 Acc: 0.8037\n",
      "Epoch 025 | Train Loss: 0.3985 Acc: 0.8187 | Val Loss: 0.3963 Acc: 0.8164\n",
      "Epoch 026 | Train Loss: 0.3733 Acc: 0.8329 | Val Loss: 0.3845 Acc: 0.8194\n",
      "Epoch 027 | Train Loss: 0.3631 Acc: 0.8351 | Val Loss: 0.3991 Acc: 0.8134\n",
      "Epoch 028 | Train Loss: 0.3577 Acc: 0.8406 | Val Loss: 0.4093 Acc: 0.8007\n",
      "Epoch 029 | Train Loss: 0.3435 Acc: 0.8499 | Val Loss: 0.3614 Acc: 0.8309\n",
      "Epoch 030 | Train Loss: 0.3238 Acc: 0.8602 | Val Loss: 0.4109 Acc: 0.8158\n",
      "Epoch 031 | Train Loss: 0.3185 Acc: 0.8578 | Val Loss: 0.3113 Acc: 0.8690\n",
      "Epoch 032 | Train Loss: 0.3090 Acc: 0.8670 | Val Loss: 0.3151 Acc: 0.8581\n",
      "Epoch 033 | Train Loss: 0.3020 Acc: 0.8695 | Val Loss: 0.2924 Acc: 0.8726\n",
      "Epoch 034 | Train Loss: 0.2866 Acc: 0.8778 | Val Loss: 0.2956 Acc: 0.8720\n",
      "Epoch 035 | Train Loss: 0.2738 Acc: 0.8837 | Val Loss: 0.2846 Acc: 0.8762\n",
      "Epoch 036 | Train Loss: 0.2719 Acc: 0.8822 | Val Loss: 0.3379 Acc: 0.8466\n",
      "Epoch 037 | Train Loss: 0.2672 Acc: 0.8856 | Val Loss: 0.2615 Acc: 0.8949\n",
      "Epoch 038 | Train Loss: 0.2438 Acc: 0.8975 | Val Loss: 0.2775 Acc: 0.8829\n",
      "Epoch 039 | Train Loss: 0.2413 Acc: 0.8990 | Val Loss: 0.2668 Acc: 0.8816\n",
      "Epoch 040 | Train Loss: 0.2320 Acc: 0.9028 | Val Loss: 0.2668 Acc: 0.8901\n",
      "Epoch 041 | Train Loss: 0.2356 Acc: 0.9040 | Val Loss: 0.2438 Acc: 0.9052\n",
      "Epoch 042 | Train Loss: 0.2269 Acc: 0.9041 | Val Loss: 0.2482 Acc: 0.8973\n",
      "Epoch 043 | Train Loss: 0.2200 Acc: 0.9061 | Val Loss: 0.2647 Acc: 0.8822\n",
      "Epoch 044 | Train Loss: 0.2227 Acc: 0.9121 | Val Loss: 0.2434 Acc: 0.8992\n",
      "Epoch 045 | Train Loss: 0.2122 Acc: 0.9171 | Val Loss: 0.2261 Acc: 0.9094\n",
      "Epoch 046 | Train Loss: 0.2045 Acc: 0.9164 | Val Loss: 0.2286 Acc: 0.8998\n",
      "Epoch 047 | Train Loss: 0.2060 Acc: 0.9204 | Val Loss: 0.2218 Acc: 0.9034\n",
      "Epoch 048 | Train Loss: 0.1997 Acc: 0.9186 | Val Loss: 0.2377 Acc: 0.8986\n",
      "Epoch 049 | Train Loss: 0.1872 Acc: 0.9238 | Val Loss: 0.2344 Acc: 0.9058\n",
      "Epoch 050 | Train Loss: 0.1886 Acc: 0.9241 | Val Loss: 0.2076 Acc: 0.9149\n",
      "Epoch 051 | Train Loss: 0.1848 Acc: 0.9268 | Val Loss: 0.2044 Acc: 0.9173\n",
      "Epoch 052 | Train Loss: 0.1797 Acc: 0.9271 | Val Loss: 0.2172 Acc: 0.9136\n",
      "Epoch 053 | Train Loss: 0.1738 Acc: 0.9269 | Val Loss: 0.1991 Acc: 0.9179\n",
      "Epoch 054 | Train Loss: 0.1697 Acc: 0.9337 | Val Loss: 0.1966 Acc: 0.9275\n",
      "Epoch 055 | Train Loss: 0.1612 Acc: 0.9339 | Val Loss: 0.2108 Acc: 0.9185\n",
      "Epoch 056 | Train Loss: 0.1656 Acc: 0.9328 | Val Loss: 0.1970 Acc: 0.9197\n",
      "Epoch 057 | Train Loss: 0.1602 Acc: 0.9343 | Val Loss: 0.1977 Acc: 0.9245\n",
      "Epoch 058 | Train Loss: 0.1579 Acc: 0.9381 | Val Loss: 0.1916 Acc: 0.9191\n",
      "Epoch 059 | Train Loss: 0.1529 Acc: 0.9404 | Val Loss: 0.2023 Acc: 0.9293\n",
      "Epoch 060 | Train Loss: 0.1518 Acc: 0.9434 | Val Loss: 0.2052 Acc: 0.9197\n",
      "Epoch 001 | Train Loss: 0.6871 Acc: 0.5591 | Val Loss: 0.6866 Acc: 0.5586\n",
      "Epoch 002 | Train Loss: 0.6813 Acc: 0.5739 | Val Loss: 0.7328 Acc: 0.5199\n",
      "Epoch 003 | Train Loss: 0.6795 Acc: 0.5804 | Val Loss: 0.6723 Acc: 0.5876\n",
      "Epoch 004 | Train Loss: 0.6664 Acc: 0.6014 | Val Loss: 0.6761 Acc: 0.5779\n",
      "Epoch 005 | Train Loss: 0.6656 Acc: 0.6020 | Val Loss: 0.6809 Acc: 0.5719\n",
      "Epoch 006 | Train Loss: 0.6592 Acc: 0.6181 | Val Loss: 0.6488 Acc: 0.6353\n",
      "Epoch 007 | Train Loss: 0.6167 Acc: 0.6739 | Val Loss: 0.6452 Acc: 0.6256\n",
      "Epoch 008 | Train Loss: 0.5965 Acc: 0.6873 | Val Loss: 0.5819 Acc: 0.6987\n",
      "Epoch 009 | Train Loss: 0.5514 Acc: 0.7276 | Val Loss: 0.5451 Acc: 0.7307\n",
      "Epoch 010 | Train Loss: 0.5181 Acc: 0.7542 | Val Loss: 0.5275 Acc: 0.7488\n",
      "Epoch 011 | Train Loss: 0.5074 Acc: 0.7646 | Val Loss: 0.5121 Acc: 0.7597\n",
      "Epoch 012 | Train Loss: 0.4780 Acc: 0.7796 | Val Loss: 0.5226 Acc: 0.7373\n",
      "Epoch 013 | Train Loss: 0.4447 Acc: 0.7965 | Val Loss: 0.4797 Acc: 0.7790\n",
      "Epoch 014 | Train Loss: 0.4339 Acc: 0.7995 | Val Loss: 0.4587 Acc: 0.7814\n",
      "Epoch 015 | Train Loss: 0.4098 Acc: 0.8147 | Val Loss: 0.4402 Acc: 0.7886\n",
      "Epoch 016 | Train Loss: 0.3866 Acc: 0.8255 | Val Loss: 0.4915 Acc: 0.7554\n",
      "Epoch 017 | Train Loss: 0.3677 Acc: 0.8344 | Val Loss: 0.3883 Acc: 0.8261\n",
      "Epoch 018 | Train Loss: 0.3405 Acc: 0.8486 | Val Loss: 0.4119 Acc: 0.8152\n",
      "Epoch 019 | Train Loss: 0.3257 Acc: 0.8570 | Val Loss: 0.3920 Acc: 0.8273\n",
      "Epoch 020 | Train Loss: 0.2907 Acc: 0.8774 | Val Loss: 0.3939 Acc: 0.8406\n",
      "Epoch 021 | Train Loss: 0.2803 Acc: 0.8818 | Val Loss: 0.3312 Acc: 0.8647\n",
      "Epoch 022 | Train Loss: 0.2629 Acc: 0.8893 | Val Loss: 0.3097 Acc: 0.8744\n",
      "Epoch 023 | Train Loss: 0.2420 Acc: 0.8993 | Val Loss: 0.3430 Acc: 0.8653\n",
      "Epoch 024 | Train Loss: 0.2189 Acc: 0.9138 | Val Loss: 0.3204 Acc: 0.8744\n",
      "Epoch 025 | Train Loss: 0.2037 Acc: 0.9218 | Val Loss: 0.3008 Acc: 0.8913\n",
      "Epoch 026 | Train Loss: 0.2047 Acc: 0.9200 | Val Loss: 0.3208 Acc: 0.8847\n",
      "Epoch 027 | Train Loss: 0.1922 Acc: 0.9260 | Val Loss: 0.2948 Acc: 0.8901\n",
      "Epoch 028 | Train Loss: 0.1707 Acc: 0.9346 | Val Loss: 0.3111 Acc: 0.8798\n",
      "Epoch 029 | Train Loss: 0.1631 Acc: 0.9396 | Val Loss: 0.2739 Acc: 0.8949\n",
      "Epoch 030 | Train Loss: 0.1469 Acc: 0.9422 | Val Loss: 0.3218 Acc: 0.8901\n",
      "Epoch 031 | Train Loss: 0.1411 Acc: 0.9478 | Val Loss: 0.2810 Acc: 0.8931\n",
      "Epoch 032 | Train Loss: 0.1308 Acc: 0.9502 | Val Loss: 0.3711 Acc: 0.8810\n",
      "Epoch 033 | Train Loss: 0.1310 Acc: 0.9488 | Val Loss: 0.3137 Acc: 0.8853\n",
      "Epoch 034 | Train Loss: 0.1213 Acc: 0.9538 | Val Loss: 0.2996 Acc: 0.8986\n",
      "Epoch 035 | Train Loss: 0.1085 Acc: 0.9598 | Val Loss: 0.3066 Acc: 0.8931\n",
      "Epoch 036 | Train Loss: 0.0957 Acc: 0.9651 | Val Loss: 0.3438 Acc: 0.8925\n",
      "Epoch 037 | Train Loss: 0.0995 Acc: 0.9638 | Val Loss: 0.3186 Acc: 0.9016\n",
      "Epoch 038 | Train Loss: 0.0951 Acc: 0.9669 | Val Loss: 0.2945 Acc: 0.8998\n",
      "Epoch 039 | Train Loss: 0.0823 Acc: 0.9715 | Val Loss: 0.3313 Acc: 0.9010\n",
      "Early stopping triggered.\n",
      "Iteration 2/40 | Best Val Loss: 0.1558 | Iter Time: 530.14s | Total Time: 14.10 min\n",
      "Epoch 001 | Train Loss: 0.6787 Acc: 0.5819 | Val Loss: 0.6693 Acc: 0.5948\n",
      "Epoch 002 | Train Loss: 0.6696 Acc: 0.5990 | Val Loss: 0.6753 Acc: 0.5815\n",
      "Epoch 003 | Train Loss: 0.6630 Acc: 0.6032 | Val Loss: 0.6595 Acc: 0.6014\n",
      "Epoch 004 | Train Loss: 0.6315 Acc: 0.6509 | Val Loss: 0.6219 Acc: 0.6691\n",
      "Epoch 005 | Train Loss: 0.5787 Acc: 0.7103 | Val Loss: 0.5990 Acc: 0.6878\n",
      "Epoch 006 | Train Loss: 0.5556 Acc: 0.7254 | Val Loss: 0.5475 Acc: 0.7198\n",
      "Epoch 007 | Train Loss: 0.5388 Acc: 0.7346 | Val Loss: 0.5331 Acc: 0.7319\n",
      "Epoch 008 | Train Loss: 0.5153 Acc: 0.7506 | Val Loss: 0.5162 Acc: 0.7500\n",
      "Epoch 009 | Train Loss: 0.4919 Acc: 0.7696 | Val Loss: 0.4996 Acc: 0.7554\n",
      "Epoch 010 | Train Loss: 0.4655 Acc: 0.7767 | Val Loss: 0.4886 Acc: 0.7639\n",
      "Epoch 011 | Train Loss: 0.4489 Acc: 0.7859 | Val Loss: 0.4464 Acc: 0.7850\n",
      "Epoch 012 | Train Loss: 0.4196 Acc: 0.8105 | Val Loss: 0.4128 Acc: 0.8025\n",
      "Epoch 013 | Train Loss: 0.3997 Acc: 0.8235 | Val Loss: 0.3803 Acc: 0.8279\n",
      "Epoch 014 | Train Loss: 0.3643 Acc: 0.8390 | Val Loss: 0.3449 Acc: 0.8545\n",
      "Epoch 015 | Train Loss: 0.3362 Acc: 0.8579 | Val Loss: 0.3452 Acc: 0.8496\n",
      "Epoch 016 | Train Loss: 0.3295 Acc: 0.8585 | Val Loss: 0.3644 Acc: 0.8466\n",
      "Epoch 017 | Train Loss: 0.3021 Acc: 0.8730 | Val Loss: 0.3003 Acc: 0.8738\n",
      "Epoch 018 | Train Loss: 0.2872 Acc: 0.8774 | Val Loss: 0.3756 Acc: 0.8418\n",
      "Epoch 019 | Train Loss: 0.2752 Acc: 0.8836 | Val Loss: 0.3706 Acc: 0.8527\n",
      "Epoch 020 | Train Loss: 0.2707 Acc: 0.8846 | Val Loss: 0.2947 Acc: 0.8738\n",
      "Epoch 021 | Train Loss: 0.2549 Acc: 0.8942 | Val Loss: 0.2605 Acc: 0.8913\n",
      "Epoch 022 | Train Loss: 0.2384 Acc: 0.9026 | Val Loss: 0.2655 Acc: 0.8883\n",
      "Epoch 023 | Train Loss: 0.2185 Acc: 0.9087 | Val Loss: 0.2521 Acc: 0.8955\n",
      "Epoch 024 | Train Loss: 0.2285 Acc: 0.9061 | Val Loss: 0.2536 Acc: 0.9082\n",
      "Epoch 025 | Train Loss: 0.2157 Acc: 0.9136 | Val Loss: 0.2627 Acc: 0.9016\n",
      "Epoch 026 | Train Loss: 0.2234 Acc: 0.9091 | Val Loss: 0.2555 Acc: 0.8937\n",
      "Epoch 027 | Train Loss: 0.1987 Acc: 0.9197 | Val Loss: 0.2620 Acc: 0.9016\n",
      "Epoch 028 | Train Loss: 0.1947 Acc: 0.9287 | Val Loss: 0.2261 Acc: 0.9112\n",
      "Epoch 029 | Train Loss: 0.1910 Acc: 0.9236 | Val Loss: 0.2296 Acc: 0.9100\n",
      "Epoch 030 | Train Loss: 0.1720 Acc: 0.9351 | Val Loss: 0.2538 Acc: 0.9070\n",
      "Epoch 031 | Train Loss: 0.1781 Acc: 0.9310 | Val Loss: 0.2166 Acc: 0.9143\n",
      "Epoch 032 | Train Loss: 0.1702 Acc: 0.9339 | Val Loss: 0.2215 Acc: 0.9106\n",
      "Epoch 033 | Train Loss: 0.1562 Acc: 0.9385 | Val Loss: 0.2499 Acc: 0.8986\n",
      "Epoch 034 | Train Loss: 0.1541 Acc: 0.9431 | Val Loss: 0.2101 Acc: 0.9136\n",
      "Epoch 035 | Train Loss: 0.1500 Acc: 0.9414 | Val Loss: 0.2151 Acc: 0.9173\n",
      "Epoch 036 | Train Loss: 0.1459 Acc: 0.9413 | Val Loss: 0.1929 Acc: 0.9191\n",
      "Epoch 037 | Train Loss: 0.1549 Acc: 0.9363 | Val Loss: 0.1788 Acc: 0.9239\n",
      "Epoch 038 | Train Loss: 0.1517 Acc: 0.9426 | Val Loss: 0.1791 Acc: 0.9318\n",
      "Epoch 039 | Train Loss: 0.1402 Acc: 0.9462 | Val Loss: 0.1895 Acc: 0.9281\n",
      "Epoch 040 | Train Loss: 0.1367 Acc: 0.9461 | Val Loss: 0.1915 Acc: 0.9221\n",
      "Epoch 041 | Train Loss: 0.1344 Acc: 0.9481 | Val Loss: 0.2122 Acc: 0.9161\n",
      "Epoch 042 | Train Loss: 0.1256 Acc: 0.9532 | Val Loss: 0.1959 Acc: 0.9269\n",
      "Epoch 043 | Train Loss: 0.1225 Acc: 0.9535 | Val Loss: 0.2111 Acc: 0.9287\n",
      "Epoch 044 | Train Loss: 0.1225 Acc: 0.9553 | Val Loss: 0.1874 Acc: 0.9269\n",
      "Epoch 045 | Train Loss: 0.1216 Acc: 0.9532 | Val Loss: 0.1672 Acc: 0.9360\n",
      "Epoch 046 | Train Loss: 0.1153 Acc: 0.9588 | Val Loss: 0.1704 Acc: 0.9324\n",
      "Epoch 047 | Train Loss: 0.1238 Acc: 0.9552 | Val Loss: 0.1925 Acc: 0.9239\n",
      "Epoch 048 | Train Loss: 0.1212 Acc: 0.9561 | Val Loss: 0.2230 Acc: 0.9227\n",
      "Epoch 049 | Train Loss: 0.1260 Acc: 0.9543 | Val Loss: 0.1751 Acc: 0.9366\n",
      "Epoch 050 | Train Loss: 0.1066 Acc: 0.9609 | Val Loss: 0.1476 Acc: 0.9390\n",
      "Epoch 051 | Train Loss: 0.1113 Acc: 0.9603 | Val Loss: 0.1638 Acc: 0.9408\n",
      "Epoch 052 | Train Loss: 0.1059 Acc: 0.9583 | Val Loss: 0.1995 Acc: 0.9306\n",
      "Epoch 053 | Train Loss: 0.1014 Acc: 0.9641 | Val Loss: 0.1549 Acc: 0.9402\n",
      "Epoch 054 | Train Loss: 0.1124 Acc: 0.9580 | Val Loss: 0.1700 Acc: 0.9390\n",
      "Epoch 055 | Train Loss: 0.1033 Acc: 0.9603 | Val Loss: 0.1531 Acc: 0.9402\n",
      "Epoch 056 | Train Loss: 0.1021 Acc: 0.9604 | Val Loss: 0.1794 Acc: 0.9354\n",
      "Epoch 057 | Train Loss: 0.1078 Acc: 0.9597 | Val Loss: 0.1562 Acc: 0.9444\n",
      "Epoch 058 | Train Loss: 0.1010 Acc: 0.9618 | Val Loss: 0.1580 Acc: 0.9402\n",
      "Epoch 059 | Train Loss: 0.0897 Acc: 0.9675 | Val Loss: 0.1696 Acc: 0.9336\n",
      "Epoch 060 | Train Loss: 0.1015 Acc: 0.9613 | Val Loss: 0.1501 Acc: 0.9432\n",
      "Early stopping triggered.\n",
      "Epoch 001 | Train Loss: 0.6827 Acc: 0.5719 | Val Loss: 0.6753 Acc: 0.5851\n",
      "Epoch 002 | Train Loss: 0.6777 Acc: 0.5872 | Val Loss: 0.6809 Acc: 0.5713\n",
      "Epoch 003 | Train Loss: 0.6722 Acc: 0.5984 | Val Loss: 0.6705 Acc: 0.5972\n",
      "Epoch 004 | Train Loss: 0.6770 Acc: 0.5887 | Val Loss: 0.6715 Acc: 0.5972\n",
      "Epoch 005 | Train Loss: 0.6718 Acc: 0.5978 | Val Loss: 0.6493 Acc: 0.6407\n",
      "Epoch 006 | Train Loss: 0.6513 Acc: 0.6329 | Val Loss: 0.6474 Acc: 0.6377\n",
      "Epoch 007 | Train Loss: 0.6095 Acc: 0.6867 | Val Loss: 0.5954 Acc: 0.7029\n",
      "Epoch 008 | Train Loss: 0.5899 Acc: 0.7050 | Val Loss: 0.5957 Acc: 0.6963\n",
      "Epoch 009 | Train Loss: 0.5781 Acc: 0.7125 | Val Loss: 0.5563 Acc: 0.7180\n",
      "Epoch 010 | Train Loss: 0.5621 Acc: 0.7219 | Val Loss: 0.5477 Acc: 0.7283\n",
      "Epoch 011 | Train Loss: 0.5553 Acc: 0.7247 | Val Loss: 0.5338 Acc: 0.7385\n",
      "Epoch 012 | Train Loss: 0.5454 Acc: 0.7318 | Val Loss: 0.5384 Acc: 0.7391\n",
      "Epoch 013 | Train Loss: 0.5377 Acc: 0.7368 | Val Loss: 0.5381 Acc: 0.7228\n",
      "Epoch 014 | Train Loss: 0.5468 Acc: 0.7210 | Val Loss: 0.5182 Acc: 0.7476\n",
      "Epoch 015 | Train Loss: 0.5211 Acc: 0.7429 | Val Loss: 0.4998 Acc: 0.7530\n",
      "Epoch 016 | Train Loss: 0.5103 Acc: 0.7474 | Val Loss: 0.4912 Acc: 0.7536\n",
      "Epoch 017 | Train Loss: 0.5107 Acc: 0.7539 | Val Loss: 0.4850 Acc: 0.7542\n",
      "Epoch 018 | Train Loss: 0.5042 Acc: 0.7555 | Val Loss: 0.4789 Acc: 0.7699\n",
      "Epoch 019 | Train Loss: 0.4934 Acc: 0.7694 | Val Loss: 0.4793 Acc: 0.7663\n",
      "Epoch 020 | Train Loss: 0.4837 Acc: 0.7696 | Val Loss: 0.4872 Acc: 0.7579\n",
      "Epoch 021 | Train Loss: 0.4743 Acc: 0.7708 | Val Loss: 0.4730 Acc: 0.7585\n",
      "Epoch 022 | Train Loss: 0.4662 Acc: 0.7768 | Val Loss: 0.4293 Acc: 0.7929\n",
      "Epoch 023 | Train Loss: 0.4577 Acc: 0.7826 | Val Loss: 0.4320 Acc: 0.7826\n",
      "Epoch 024 | Train Loss: 0.4679 Acc: 0.7764 | Val Loss: 0.4307 Acc: 0.7880\n",
      "Epoch 025 | Train Loss: 0.4465 Acc: 0.7845 | Val Loss: 0.4424 Acc: 0.7856\n",
      "Epoch 026 | Train Loss: 0.4455 Acc: 0.7910 | Val Loss: 0.4335 Acc: 0.7941\n",
      "Epoch 027 | Train Loss: 0.4335 Acc: 0.7942 | Val Loss: 0.4418 Acc: 0.7917\n",
      "Epoch 028 | Train Loss: 0.4273 Acc: 0.8004 | Val Loss: 0.4538 Acc: 0.8001\n",
      "Epoch 029 | Train Loss: 0.4355 Acc: 0.8005 | Val Loss: 0.3910 Acc: 0.8231\n",
      "Epoch 030 | Train Loss: 0.4185 Acc: 0.8096 | Val Loss: 0.4158 Acc: 0.8200\n",
      "Epoch 031 | Train Loss: 0.4148 Acc: 0.8149 | Val Loss: 0.3951 Acc: 0.8068\n",
      "Epoch 032 | Train Loss: 0.4140 Acc: 0.8120 | Val Loss: 0.3793 Acc: 0.8267\n",
      "Epoch 033 | Train Loss: 0.4001 Acc: 0.8202 | Val Loss: 0.3822 Acc: 0.8249\n",
      "Epoch 034 | Train Loss: 0.3937 Acc: 0.8229 | Val Loss: 0.3573 Acc: 0.8406\n",
      "Epoch 035 | Train Loss: 0.3988 Acc: 0.8172 | Val Loss: 0.3685 Acc: 0.8357\n",
      "Epoch 036 | Train Loss: 0.3793 Acc: 0.8271 | Val Loss: 0.3689 Acc: 0.8364\n",
      "Epoch 037 | Train Loss: 0.3859 Acc: 0.8277 | Val Loss: 0.3777 Acc: 0.8327\n",
      "Epoch 038 | Train Loss: 0.3606 Acc: 0.8455 | Val Loss: 0.3321 Acc: 0.8581\n",
      "Epoch 039 | Train Loss: 0.3727 Acc: 0.8378 | Val Loss: 0.3519 Acc: 0.8490\n",
      "Epoch 040 | Train Loss: 0.3675 Acc: 0.8395 | Val Loss: 0.3324 Acc: 0.8732\n",
      "Epoch 041 | Train Loss: 0.3694 Acc: 0.8445 | Val Loss: 0.3418 Acc: 0.8563\n",
      "Epoch 042 | Train Loss: 0.3687 Acc: 0.8375 | Val Loss: 0.3349 Acc: 0.8478\n",
      "Epoch 043 | Train Loss: 0.3552 Acc: 0.8443 | Val Loss: 0.3170 Acc: 0.8714\n",
      "Epoch 044 | Train Loss: 0.3456 Acc: 0.8511 | Val Loss: 0.3315 Acc: 0.8671\n",
      "Epoch 045 | Train Loss: 0.3457 Acc: 0.8496 | Val Loss: 0.3281 Acc: 0.8539\n",
      "Epoch 046 | Train Loss: 0.3360 Acc: 0.8594 | Val Loss: 0.3045 Acc: 0.8726\n",
      "Epoch 047 | Train Loss: 0.3361 Acc: 0.8554 | Val Loss: 0.2751 Acc: 0.8829\n",
      "Epoch 048 | Train Loss: 0.3414 Acc: 0.8569 | Val Loss: 0.3247 Acc: 0.8551\n",
      "Epoch 049 | Train Loss: 0.3287 Acc: 0.8623 | Val Loss: 0.2968 Acc: 0.8847\n",
      "Epoch 050 | Train Loss: 0.3096 Acc: 0.8735 | Val Loss: 0.3072 Acc: 0.8684\n",
      "Epoch 051 | Train Loss: 0.3253 Acc: 0.8646 | Val Loss: 0.2826 Acc: 0.8835\n",
      "Epoch 052 | Train Loss: 0.3144 Acc: 0.8712 | Val Loss: 0.2762 Acc: 0.8853\n",
      "Epoch 053 | Train Loss: 0.3188 Acc: 0.8700 | Val Loss: 0.2619 Acc: 0.8949\n",
      "Epoch 054 | Train Loss: 0.3220 Acc: 0.8668 | Val Loss: 0.2666 Acc: 0.8925\n",
      "Epoch 055 | Train Loss: 0.3044 Acc: 0.8785 | Val Loss: 0.2911 Acc: 0.8871\n",
      "Epoch 056 | Train Loss: 0.3095 Acc: 0.8732 | Val Loss: 0.3032 Acc: 0.8786\n",
      "Epoch 057 | Train Loss: 0.3074 Acc: 0.8717 | Val Loss: 0.2913 Acc: 0.8816\n",
      "Epoch 058 | Train Loss: 0.3103 Acc: 0.8691 | Val Loss: 0.2684 Acc: 0.8865\n",
      "Epoch 059 | Train Loss: 0.3050 Acc: 0.8754 | Val Loss: 0.2796 Acc: 0.8883\n",
      "Epoch 060 | Train Loss: 0.2943 Acc: 0.8777 | Val Loss: 0.3104 Acc: 0.8611\n",
      "Epoch 001 | Train Loss: 0.6835 Acc: 0.5694 | Val Loss: 0.6766 Acc: 0.5900\n",
      "Epoch 002 | Train Loss: 0.6738 Acc: 0.5896 | Val Loss: 0.6722 Acc: 0.5876\n",
      "Epoch 003 | Train Loss: 0.6646 Acc: 0.6009 | Val Loss: 0.6620 Acc: 0.6021\n",
      "Epoch 004 | Train Loss: 0.6506 Acc: 0.6189 | Val Loss: 0.6356 Acc: 0.6528\n",
      "Epoch 005 | Train Loss: 0.6347 Acc: 0.6505 | Val Loss: 0.6189 Acc: 0.6715\n",
      "Epoch 006 | Train Loss: 0.6176 Acc: 0.6675 | Val Loss: 0.6118 Acc: 0.6679\n",
      "Epoch 007 | Train Loss: 0.6070 Acc: 0.6825 | Val Loss: 0.5977 Acc: 0.6866\n",
      "Epoch 008 | Train Loss: 0.5983 Acc: 0.6900 | Val Loss: 0.5914 Acc: 0.6975\n",
      "Epoch 009 | Train Loss: 0.5925 Acc: 0.6952 | Val Loss: 0.5856 Acc: 0.6987\n",
      "Epoch 010 | Train Loss: 0.5808 Acc: 0.7032 | Val Loss: 0.5886 Acc: 0.6950\n",
      "Epoch 011 | Train Loss: 0.5716 Acc: 0.7110 | Val Loss: 0.5699 Acc: 0.7132\n",
      "Epoch 012 | Train Loss: 0.5675 Acc: 0.7177 | Val Loss: 0.5717 Acc: 0.7077\n",
      "Epoch 013 | Train Loss: 0.5556 Acc: 0.7226 | Val Loss: 0.5583 Acc: 0.7216\n",
      "Epoch 014 | Train Loss: 0.5495 Acc: 0.7270 | Val Loss: 0.5576 Acc: 0.7192\n",
      "Epoch 015 | Train Loss: 0.5449 Acc: 0.7296 | Val Loss: 0.5509 Acc: 0.7271\n",
      "Epoch 016 | Train Loss: 0.5408 Acc: 0.7362 | Val Loss: 0.5416 Acc: 0.7295\n",
      "Epoch 017 | Train Loss: 0.5282 Acc: 0.7426 | Val Loss: 0.5387 Acc: 0.7289\n",
      "Epoch 018 | Train Loss: 0.5205 Acc: 0.7491 | Val Loss: 0.5321 Acc: 0.7325\n",
      "Epoch 019 | Train Loss: 0.5157 Acc: 0.7522 | Val Loss: 0.5365 Acc: 0.7337\n",
      "Epoch 020 | Train Loss: 0.5122 Acc: 0.7522 | Val Loss: 0.5261 Acc: 0.7415\n",
      "Epoch 021 | Train Loss: 0.4973 Acc: 0.7632 | Val Loss: 0.5170 Acc: 0.7379\n",
      "Epoch 022 | Train Loss: 0.4962 Acc: 0.7637 | Val Loss: 0.5187 Acc: 0.7409\n",
      "Epoch 023 | Train Loss: 0.4868 Acc: 0.7672 | Val Loss: 0.5117 Acc: 0.7482\n",
      "Epoch 024 | Train Loss: 0.4819 Acc: 0.7725 | Val Loss: 0.5148 Acc: 0.7512\n",
      "Epoch 025 | Train Loss: 0.4778 Acc: 0.7711 | Val Loss: 0.5139 Acc: 0.7428\n",
      "Epoch 026 | Train Loss: 0.4672 Acc: 0.7803 | Val Loss: 0.4951 Acc: 0.7621\n",
      "Epoch 027 | Train Loss: 0.4621 Acc: 0.7829 | Val Loss: 0.4853 Acc: 0.7657\n",
      "Epoch 028 | Train Loss: 0.4600 Acc: 0.7847 | Val Loss: 0.4822 Acc: 0.7633\n",
      "Epoch 029 | Train Loss: 0.4498 Acc: 0.7885 | Val Loss: 0.4748 Acc: 0.7742\n",
      "Epoch 030 | Train Loss: 0.4416 Acc: 0.7930 | Val Loss: 0.4781 Acc: 0.7723\n",
      "Epoch 031 | Train Loss: 0.4460 Acc: 0.7942 | Val Loss: 0.4815 Acc: 0.7597\n",
      "Epoch 032 | Train Loss: 0.4352 Acc: 0.7995 | Val Loss: 0.4514 Acc: 0.7850\n",
      "Epoch 033 | Train Loss: 0.4282 Acc: 0.8019 | Val Loss: 0.4511 Acc: 0.7862\n",
      "Epoch 034 | Train Loss: 0.4180 Acc: 0.8064 | Val Loss: 0.4402 Acc: 0.7893\n",
      "Epoch 035 | Train Loss: 0.4149 Acc: 0.8078 | Val Loss: 0.4392 Acc: 0.7935\n",
      "Epoch 036 | Train Loss: 0.4086 Acc: 0.8091 | Val Loss: 0.4324 Acc: 0.7971\n",
      "Epoch 037 | Train Loss: 0.3971 Acc: 0.8150 | Val Loss: 0.4423 Acc: 0.7911\n",
      "Epoch 038 | Train Loss: 0.3947 Acc: 0.8175 | Val Loss: 0.4346 Acc: 0.7965\n",
      "Epoch 039 | Train Loss: 0.3835 Acc: 0.8191 | Val Loss: 0.4097 Acc: 0.7959\n",
      "Epoch 040 | Train Loss: 0.3841 Acc: 0.8199 | Val Loss: 0.3996 Acc: 0.8128\n",
      "Epoch 041 | Train Loss: 0.3730 Acc: 0.8316 | Val Loss: 0.3968 Acc: 0.8098\n",
      "Epoch 042 | Train Loss: 0.3675 Acc: 0.8292 | Val Loss: 0.3980 Acc: 0.8182\n",
      "Epoch 043 | Train Loss: 0.3611 Acc: 0.8366 | Val Loss: 0.3806 Acc: 0.8170\n",
      "Epoch 044 | Train Loss: 0.3557 Acc: 0.8368 | Val Loss: 0.3805 Acc: 0.8261\n",
      "Epoch 045 | Train Loss: 0.3493 Acc: 0.8419 | Val Loss: 0.3818 Acc: 0.8249\n",
      "Epoch 046 | Train Loss: 0.3373 Acc: 0.8517 | Val Loss: 0.3782 Acc: 0.8285\n",
      "Epoch 047 | Train Loss: 0.3320 Acc: 0.8498 | Val Loss: 0.4209 Acc: 0.8176\n",
      "Epoch 048 | Train Loss: 0.3242 Acc: 0.8570 | Val Loss: 0.3994 Acc: 0.8285\n",
      "Epoch 049 | Train Loss: 0.3216 Acc: 0.8561 | Val Loss: 0.3497 Acc: 0.8436\n",
      "Epoch 050 | Train Loss: 0.3141 Acc: 0.8637 | Val Loss: 0.3595 Acc: 0.8418\n",
      "Epoch 051 | Train Loss: 0.3089 Acc: 0.8652 | Val Loss: 0.3390 Acc: 0.8508\n",
      "Epoch 052 | Train Loss: 0.3030 Acc: 0.8680 | Val Loss: 0.3575 Acc: 0.8466\n",
      "Epoch 053 | Train Loss: 0.3053 Acc: 0.8691 | Val Loss: 0.3439 Acc: 0.8502\n",
      "Epoch 054 | Train Loss: 0.2874 Acc: 0.8730 | Val Loss: 0.3530 Acc: 0.8388\n",
      "Epoch 055 | Train Loss: 0.2849 Acc: 0.8741 | Val Loss: 0.3374 Acc: 0.8557\n",
      "Epoch 056 | Train Loss: 0.2763 Acc: 0.8824 | Val Loss: 0.3341 Acc: 0.8587\n",
      "Epoch 057 | Train Loss: 0.2780 Acc: 0.8806 | Val Loss: 0.3088 Acc: 0.8750\n",
      "Epoch 058 | Train Loss: 0.2777 Acc: 0.8789 | Val Loss: 0.3346 Acc: 0.8599\n",
      "Epoch 059 | Train Loss: 0.2716 Acc: 0.8824 | Val Loss: 0.4100 Acc: 0.8200\n",
      "Epoch 060 | Train Loss: 0.2660 Acc: 0.8863 | Val Loss: 0.3221 Acc: 0.8587\n",
      "Epoch 001 | Train Loss: 0.6783 Acc: 0.5741 | Val Loss: 0.6698 Acc: 0.5646\n",
      "Epoch 002 | Train Loss: 0.6075 Acc: 0.6790 | Val Loss: 0.5959 Acc: 0.6854\n",
      "Epoch 003 | Train Loss: 0.5542 Acc: 0.7229 | Val Loss: 0.6005 Acc: 0.6993\n",
      "Epoch 004 | Train Loss: 0.5355 Acc: 0.7340 | Val Loss: 0.5314 Acc: 0.7331\n",
      "Epoch 005 | Train Loss: 0.5043 Acc: 0.7525 | Val Loss: 0.5068 Acc: 0.7385\n",
      "Epoch 006 | Train Loss: 0.4789 Acc: 0.7687 | Val Loss: 0.4828 Acc: 0.7560\n",
      "Epoch 007 | Train Loss: 0.4448 Acc: 0.7906 | Val Loss: 0.4310 Acc: 0.7893\n",
      "Epoch 008 | Train Loss: 0.4134 Acc: 0.8120 | Val Loss: 0.4647 Acc: 0.8086\n",
      "Epoch 009 | Train Loss: 0.3957 Acc: 0.8226 | Val Loss: 0.4062 Acc: 0.8164\n",
      "Epoch 010 | Train Loss: 0.3718 Acc: 0.8336 | Val Loss: 0.4341 Acc: 0.8068\n",
      "Epoch 011 | Train Loss: 0.3462 Acc: 0.8487 | Val Loss: 0.3414 Acc: 0.8605\n",
      "Epoch 012 | Train Loss: 0.3230 Acc: 0.8584 | Val Loss: 0.3266 Acc: 0.8671\n",
      "Epoch 013 | Train Loss: 0.2962 Acc: 0.8732 | Val Loss: 0.3840 Acc: 0.8339\n",
      "Epoch 014 | Train Loss: 0.2855 Acc: 0.8834 | Val Loss: 0.3149 Acc: 0.8569\n",
      "Epoch 015 | Train Loss: 0.2738 Acc: 0.8849 | Val Loss: 0.3222 Acc: 0.8696\n",
      "Epoch 016 | Train Loss: 0.2567 Acc: 0.8948 | Val Loss: 0.2640 Acc: 0.8931\n",
      "Epoch 017 | Train Loss: 0.2438 Acc: 0.9020 | Val Loss: 0.3054 Acc: 0.8750\n",
      "Epoch 018 | Train Loss: 0.2318 Acc: 0.9023 | Val Loss: 0.2464 Acc: 0.9022\n",
      "Epoch 019 | Train Loss: 0.2278 Acc: 0.9065 | Val Loss: 0.2668 Acc: 0.9004\n",
      "Epoch 020 | Train Loss: 0.2089 Acc: 0.9147 | Val Loss: 0.2484 Acc: 0.9052\n",
      "Epoch 021 | Train Loss: 0.2012 Acc: 0.9183 | Val Loss: 0.2328 Acc: 0.9173\n",
      "Epoch 022 | Train Loss: 0.2015 Acc: 0.9210 | Val Loss: 0.3040 Acc: 0.8659\n",
      "Epoch 023 | Train Loss: 0.1922 Acc: 0.9254 | Val Loss: 0.2279 Acc: 0.9040\n",
      "Epoch 024 | Train Loss: 0.1813 Acc: 0.9281 | Val Loss: 0.2864 Acc: 0.8889\n",
      "Epoch 025 | Train Loss: 0.1740 Acc: 0.9334 | Val Loss: 0.2549 Acc: 0.8949\n",
      "Epoch 026 | Train Loss: 0.1683 Acc: 0.9345 | Val Loss: 0.2361 Acc: 0.9088\n",
      "Epoch 027 | Train Loss: 0.1591 Acc: 0.9388 | Val Loss: 0.2545 Acc: 0.9040\n",
      "Epoch 028 | Train Loss: 0.1479 Acc: 0.9452 | Val Loss: 0.2015 Acc: 0.9227\n",
      "Epoch 029 | Train Loss: 0.1584 Acc: 0.9381 | Val Loss: 0.2438 Acc: 0.9088\n",
      "Epoch 030 | Train Loss: 0.1589 Acc: 0.9404 | Val Loss: 0.2350 Acc: 0.9136\n",
      "Epoch 031 | Train Loss: 0.1496 Acc: 0.9408 | Val Loss: 0.2336 Acc: 0.9040\n",
      "Epoch 032 | Train Loss: 0.1317 Acc: 0.9484 | Val Loss: 0.2874 Acc: 0.9010\n",
      "Epoch 033 | Train Loss: 0.1323 Acc: 0.9505 | Val Loss: 0.2502 Acc: 0.9058\n",
      "Epoch 034 | Train Loss: 0.1218 Acc: 0.9533 | Val Loss: 0.2557 Acc: 0.9173\n",
      "Epoch 035 | Train Loss: 0.1277 Acc: 0.9526 | Val Loss: 0.2415 Acc: 0.9070\n",
      "Epoch 036 | Train Loss: 0.1241 Acc: 0.9538 | Val Loss: 0.1968 Acc: 0.9263\n",
      "Epoch 037 | Train Loss: 0.1182 Acc: 0.9541 | Val Loss: 0.2838 Acc: 0.9028\n",
      "Epoch 038 | Train Loss: 0.1196 Acc: 0.9515 | Val Loss: 0.2499 Acc: 0.9124\n",
      "Epoch 039 | Train Loss: 0.1251 Acc: 0.9508 | Val Loss: 0.2146 Acc: 0.9185\n",
      "Epoch 040 | Train Loss: 0.1000 Acc: 0.9588 | Val Loss: 0.2224 Acc: 0.9239\n",
      "Epoch 041 | Train Loss: 0.1022 Acc: 0.9588 | Val Loss: 0.2266 Acc: 0.9094\n",
      "Epoch 042 | Train Loss: 0.1277 Acc: 0.9494 | Val Loss: 0.1932 Acc: 0.9330\n",
      "Epoch 043 | Train Loss: 0.1053 Acc: 0.9618 | Val Loss: 0.2062 Acc: 0.9257\n",
      "Epoch 044 | Train Loss: 0.1051 Acc: 0.9573 | Val Loss: 0.2026 Acc: 0.9263\n",
      "Epoch 045 | Train Loss: 0.1139 Acc: 0.9565 | Val Loss: 0.2236 Acc: 0.9251\n",
      "Epoch 046 | Train Loss: 0.1092 Acc: 0.9586 | Val Loss: 0.2226 Acc: 0.9269\n",
      "Epoch 047 | Train Loss: 0.0979 Acc: 0.9647 | Val Loss: 0.1962 Acc: 0.9306\n",
      "Epoch 048 | Train Loss: 0.1002 Acc: 0.9623 | Val Loss: 0.2036 Acc: 0.9263\n",
      "Epoch 049 | Train Loss: 0.0950 Acc: 0.9633 | Val Loss: 0.2737 Acc: 0.9052\n",
      "Epoch 050 | Train Loss: 0.1031 Acc: 0.9597 | Val Loss: 0.1975 Acc: 0.9330\n",
      "Epoch 051 | Train Loss: 0.0992 Acc: 0.9645 | Val Loss: 0.1790 Acc: 0.9312\n",
      "Epoch 052 | Train Loss: 0.0894 Acc: 0.9678 | Val Loss: 0.1895 Acc: 0.9342\n",
      "Epoch 053 | Train Loss: 0.0975 Acc: 0.9638 | Val Loss: 0.1955 Acc: 0.9300\n",
      "Epoch 054 | Train Loss: 0.0842 Acc: 0.9678 | Val Loss: 0.1747 Acc: 0.9390\n",
      "Epoch 055 | Train Loss: 0.0990 Acc: 0.9606 | Val Loss: 0.1715 Acc: 0.9300\n",
      "Epoch 056 | Train Loss: 0.0915 Acc: 0.9671 | Val Loss: 0.2056 Acc: 0.9306\n",
      "Epoch 057 | Train Loss: 0.0905 Acc: 0.9650 | Val Loss: 0.1691 Acc: 0.9408\n",
      "Epoch 058 | Train Loss: 0.0945 Acc: 0.9660 | Val Loss: 0.1715 Acc: 0.9342\n",
      "Epoch 059 | Train Loss: 0.0874 Acc: 0.9690 | Val Loss: 0.1816 Acc: 0.9378\n",
      "Epoch 060 | Train Loss: 0.0845 Acc: 0.9701 | Val Loss: 0.1750 Acc: 0.9402\n",
      "Epoch 001 | Train Loss: 0.6863 Acc: 0.5686 | Val Loss: 0.6796 Acc: 0.5815\n",
      "Epoch 002 | Train Loss: 0.6834 Acc: 0.5745 | Val Loss: 0.6818 Acc: 0.5755\n",
      "Epoch 003 | Train Loss: 0.6774 Acc: 0.5896 | Val Loss: 0.6910 Acc: 0.5586\n",
      "Epoch 004 | Train Loss: 0.6784 Acc: 0.5827 | Val Loss: 0.6603 Acc: 0.6202\n",
      "Epoch 005 | Train Loss: 0.6653 Acc: 0.6123 | Val Loss: 0.6555 Acc: 0.6111\n",
      "Epoch 006 | Train Loss: 0.6436 Acc: 0.6434 | Val Loss: 0.6123 Acc: 0.6818\n",
      "Epoch 007 | Train Loss: 0.6244 Acc: 0.6666 | Val Loss: 0.6331 Acc: 0.6739\n",
      "Epoch 008 | Train Loss: 0.6224 Acc: 0.6770 | Val Loss: 0.5890 Acc: 0.6950\n",
      "Epoch 009 | Train Loss: 0.6064 Acc: 0.6900 | Val Loss: 0.5868 Acc: 0.7023\n",
      "Epoch 010 | Train Loss: 0.5959 Acc: 0.6917 | Val Loss: 0.6025 Acc: 0.6697\n",
      "Epoch 011 | Train Loss: 0.5822 Acc: 0.7128 | Val Loss: 0.5585 Acc: 0.7186\n",
      "Epoch 012 | Train Loss: 0.5859 Acc: 0.7045 | Val Loss: 0.5566 Acc: 0.7240\n",
      "Epoch 013 | Train Loss: 0.5768 Acc: 0.7101 | Val Loss: 0.5633 Acc: 0.7107\n",
      "Epoch 014 | Train Loss: 0.5721 Acc: 0.7112 | Val Loss: 0.5439 Acc: 0.7271\n",
      "Epoch 015 | Train Loss: 0.5675 Acc: 0.7187 | Val Loss: 0.5619 Acc: 0.7180\n",
      "Epoch 016 | Train Loss: 0.5649 Acc: 0.7220 | Val Loss: 0.5772 Acc: 0.7240\n",
      "Epoch 017 | Train Loss: 0.5547 Acc: 0.7285 | Val Loss: 0.5468 Acc: 0.7271\n",
      "Epoch 018 | Train Loss: 0.5509 Acc: 0.7331 | Val Loss: 0.5389 Acc: 0.7349\n",
      "Epoch 019 | Train Loss: 0.5495 Acc: 0.7291 | Val Loss: 0.5382 Acc: 0.7198\n",
      "Epoch 020 | Train Loss: 0.5371 Acc: 0.7385 | Val Loss: 0.5216 Acc: 0.7397\n",
      "Epoch 021 | Train Loss: 0.5313 Acc: 0.7380 | Val Loss: 0.5281 Acc: 0.7367\n",
      "Epoch 022 | Train Loss: 0.5172 Acc: 0.7459 | Val Loss: 0.5575 Acc: 0.7301\n",
      "Epoch 023 | Train Loss: 0.5241 Acc: 0.7468 | Val Loss: 0.5129 Acc: 0.7295\n",
      "Epoch 024 | Train Loss: 0.5145 Acc: 0.7477 | Val Loss: 0.4794 Acc: 0.7597\n",
      "Epoch 025 | Train Loss: 0.5109 Acc: 0.7522 | Val Loss: 0.5116 Acc: 0.7470\n",
      "Epoch 026 | Train Loss: 0.5065 Acc: 0.7593 | Val Loss: 0.4757 Acc: 0.7621\n",
      "Epoch 027 | Train Loss: 0.4975 Acc: 0.7590 | Val Loss: 0.4717 Acc: 0.7814\n",
      "Epoch 028 | Train Loss: 0.4927 Acc: 0.7655 | Val Loss: 0.4555 Acc: 0.7959\n",
      "Epoch 029 | Train Loss: 0.4829 Acc: 0.7702 | Val Loss: 0.4436 Acc: 0.7965\n",
      "Epoch 030 | Train Loss: 0.4648 Acc: 0.7879 | Val Loss: 0.4410 Acc: 0.7935\n",
      "Epoch 031 | Train Loss: 0.4700 Acc: 0.7790 | Val Loss: 0.4323 Acc: 0.8056\n",
      "Epoch 032 | Train Loss: 0.4546 Acc: 0.7921 | Val Loss: 0.4244 Acc: 0.8176\n",
      "Epoch 033 | Train Loss: 0.4603 Acc: 0.7895 | Val Loss: 0.4351 Acc: 0.8007\n",
      "Epoch 034 | Train Loss: 0.4556 Acc: 0.7941 | Val Loss: 0.4308 Acc: 0.7959\n",
      "Epoch 035 | Train Loss: 0.4446 Acc: 0.7984 | Val Loss: 0.4073 Acc: 0.8080\n",
      "Epoch 036 | Train Loss: 0.4396 Acc: 0.8001 | Val Loss: 0.4223 Acc: 0.7947\n",
      "Epoch 037 | Train Loss: 0.4286 Acc: 0.8090 | Val Loss: 0.3918 Acc: 0.8321\n",
      "Epoch 038 | Train Loss: 0.4235 Acc: 0.8088 | Val Loss: 0.3969 Acc: 0.8128\n",
      "Epoch 039 | Train Loss: 0.4273 Acc: 0.8061 | Val Loss: 0.4039 Acc: 0.8104\n",
      "Epoch 040 | Train Loss: 0.4071 Acc: 0.8153 | Val Loss: 0.3769 Acc: 0.8339\n",
      "Epoch 041 | Train Loss: 0.4195 Acc: 0.8081 | Val Loss: 0.3947 Acc: 0.8279\n",
      "Epoch 042 | Train Loss: 0.4150 Acc: 0.8143 | Val Loss: 0.3810 Acc: 0.8370\n",
      "Epoch 043 | Train Loss: 0.4010 Acc: 0.8265 | Val Loss: 0.3687 Acc: 0.8345\n",
      "Epoch 044 | Train Loss: 0.4054 Acc: 0.8215 | Val Loss: 0.4023 Acc: 0.8068\n",
      "Epoch 045 | Train Loss: 0.4020 Acc: 0.8259 | Val Loss: 0.3602 Acc: 0.8496\n",
      "Epoch 046 | Train Loss: 0.4017 Acc: 0.8172 | Val Loss: 0.3657 Acc: 0.8291\n",
      "Epoch 047 | Train Loss: 0.4001 Acc: 0.8221 | Val Loss: 0.3554 Acc: 0.8436\n",
      "Epoch 048 | Train Loss: 0.3908 Acc: 0.8280 | Val Loss: 0.3607 Acc: 0.8466\n",
      "Epoch 049 | Train Loss: 0.3851 Acc: 0.8235 | Val Loss: 0.3931 Acc: 0.8110\n",
      "Epoch 050 | Train Loss: 0.3990 Acc: 0.8261 | Val Loss: 0.3630 Acc: 0.8466\n",
      "Epoch 051 | Train Loss: 0.3827 Acc: 0.8359 | Val Loss: 0.3622 Acc: 0.8527\n",
      "Epoch 052 | Train Loss: 0.3893 Acc: 0.8313 | Val Loss: 0.3704 Acc: 0.8279\n",
      "Epoch 053 | Train Loss: 0.3890 Acc: 0.8286 | Val Loss: 0.3439 Acc: 0.8527\n",
      "Epoch 054 | Train Loss: 0.3846 Acc: 0.8313 | Val Loss: 0.3392 Acc: 0.8430\n",
      "Epoch 055 | Train Loss: 0.3797 Acc: 0.8298 | Val Loss: 0.3304 Acc: 0.8599\n",
      "Epoch 056 | Train Loss: 0.3746 Acc: 0.8369 | Val Loss: 0.3258 Acc: 0.8599\n",
      "Epoch 057 | Train Loss: 0.3723 Acc: 0.8374 | Val Loss: 0.3659 Acc: 0.8339\n",
      "Epoch 058 | Train Loss: 0.3824 Acc: 0.8338 | Val Loss: 0.3169 Acc: 0.8629\n",
      "Epoch 059 | Train Loss: 0.3742 Acc: 0.8395 | Val Loss: 0.3491 Acc: 0.8394\n",
      "Epoch 060 | Train Loss: 0.3663 Acc: 0.8387 | Val Loss: 0.3354 Acc: 0.8514\n",
      "Epoch 001 | Train Loss: 0.6887 Acc: 0.5525 | Val Loss: 0.6886 Acc: 0.5586\n",
      "Epoch 002 | Train Loss: 0.6876 Acc: 0.5550 | Val Loss: 0.6866 Acc: 0.5586\n",
      "Epoch 003 | Train Loss: 0.6877 Acc: 0.5582 | Val Loss: 0.6865 Acc: 0.5586\n",
      "Epoch 004 | Train Loss: 0.6869 Acc: 0.5582 | Val Loss: 0.6863 Acc: 0.5586\n",
      "Epoch 005 | Train Loss: 0.6866 Acc: 0.5582 | Val Loss: 0.6864 Acc: 0.5586\n",
      "Epoch 006 | Train Loss: 0.6866 Acc: 0.5582 | Val Loss: 0.6863 Acc: 0.5586\n",
      "Epoch 007 | Train Loss: 0.6867 Acc: 0.5582 | Val Loss: 0.6863 Acc: 0.5586\n",
      "Epoch 008 | Train Loss: 0.6866 Acc: 0.5582 | Val Loss: 0.6867 Acc: 0.5586\n",
      "Epoch 009 | Train Loss: 0.6867 Acc: 0.5582 | Val Loss: 0.6865 Acc: 0.5586\n",
      "Epoch 010 | Train Loss: 0.6869 Acc: 0.5582 | Val Loss: 0.6865 Acc: 0.5586\n",
      "Epoch 011 | Train Loss: 0.6865 Acc: 0.5582 | Val Loss: 0.6867 Acc: 0.5586\n",
      "Epoch 012 | Train Loss: 0.6869 Acc: 0.5582 | Val Loss: 0.6864 Acc: 0.5586\n",
      "Epoch 013 | Train Loss: 0.6865 Acc: 0.5582 | Val Loss: 0.6863 Acc: 0.5586\n",
      "Epoch 014 | Train Loss: 0.6866 Acc: 0.5582 | Val Loss: 0.6864 Acc: 0.5586\n",
      "Epoch 015 | Train Loss: 0.6869 Acc: 0.5582 | Val Loss: 0.6864 Acc: 0.5586\n",
      "Epoch 016 | Train Loss: 0.6867 Acc: 0.5582 | Val Loss: 0.6863 Acc: 0.5586\n",
      "Early stopping triggered.\n",
      "Epoch 001 | Train Loss: 0.6839 Acc: 0.5664 | Val Loss: 0.6742 Acc: 0.5882\n",
      "Epoch 002 | Train Loss: 0.6816 Acc: 0.5747 | Val Loss: 0.6727 Acc: 0.5888\n",
      "Epoch 003 | Train Loss: 0.6661 Acc: 0.6035 | Val Loss: 0.6556 Acc: 0.6208\n",
      "Epoch 004 | Train Loss: 0.6419 Acc: 0.6461 | Val Loss: 0.6123 Acc: 0.6926\n",
      "Epoch 005 | Train Loss: 0.5927 Acc: 0.7060 | Val Loss: 0.5738 Acc: 0.7101\n",
      "Epoch 006 | Train Loss: 0.5698 Acc: 0.7195 | Val Loss: 0.5701 Acc: 0.7228\n",
      "Epoch 007 | Train Loss: 0.5511 Acc: 0.7343 | Val Loss: 0.5437 Acc: 0.7277\n",
      "Epoch 008 | Train Loss: 0.5299 Acc: 0.7530 | Val Loss: 0.5341 Acc: 0.7409\n",
      "Epoch 009 | Train Loss: 0.5229 Acc: 0.7504 | Val Loss: 0.5303 Acc: 0.7421\n",
      "Epoch 010 | Train Loss: 0.5168 Acc: 0.7442 | Val Loss: 0.5138 Acc: 0.7434\n",
      "Epoch 011 | Train Loss: 0.4958 Acc: 0.7655 | Val Loss: 0.4901 Acc: 0.7585\n",
      "Epoch 012 | Train Loss: 0.4846 Acc: 0.7649 | Val Loss: 0.5168 Acc: 0.7409\n",
      "Epoch 013 | Train Loss: 0.4719 Acc: 0.7750 | Val Loss: 0.4625 Acc: 0.7766\n",
      "Epoch 014 | Train Loss: 0.4525 Acc: 0.7815 | Val Loss: 0.4690 Acc: 0.7621\n",
      "Epoch 015 | Train Loss: 0.4441 Acc: 0.7842 | Val Loss: 0.4622 Acc: 0.7796\n",
      "Epoch 016 | Train Loss: 0.4203 Acc: 0.8052 | Val Loss: 0.4674 Acc: 0.7784\n",
      "Epoch 017 | Train Loss: 0.4092 Acc: 0.8060 | Val Loss: 0.4150 Acc: 0.8001\n",
      "Epoch 018 | Train Loss: 0.3851 Acc: 0.8226 | Val Loss: 0.4064 Acc: 0.8043\n",
      "Epoch 019 | Train Loss: 0.3843 Acc: 0.8194 | Val Loss: 0.3837 Acc: 0.8146\n",
      "Epoch 020 | Train Loss: 0.3629 Acc: 0.8303 | Val Loss: 0.3680 Acc: 0.8273\n",
      "Epoch 021 | Train Loss: 0.3487 Acc: 0.8440 | Val Loss: 0.3678 Acc: 0.8303\n",
      "Epoch 022 | Train Loss: 0.3229 Acc: 0.8606 | Val Loss: 0.3139 Acc: 0.8635\n",
      "Epoch 023 | Train Loss: 0.3075 Acc: 0.8726 | Val Loss: 0.3168 Acc: 0.8617\n",
      "Epoch 024 | Train Loss: 0.2992 Acc: 0.8727 | Val Loss: 0.3249 Acc: 0.8569\n",
      "Epoch 025 | Train Loss: 0.2658 Acc: 0.8898 | Val Loss: 0.2764 Acc: 0.8931\n",
      "Epoch 026 | Train Loss: 0.2593 Acc: 0.8920 | Val Loss: 0.2852 Acc: 0.8835\n",
      "Epoch 027 | Train Loss: 0.2449 Acc: 0.8982 | Val Loss: 0.2719 Acc: 0.8907\n",
      "Epoch 028 | Train Loss: 0.2335 Acc: 0.9068 | Val Loss: 0.2609 Acc: 0.8877\n",
      "Epoch 029 | Train Loss: 0.2206 Acc: 0.9130 | Val Loss: 0.2398 Acc: 0.9028\n",
      "Epoch 030 | Train Loss: 0.2155 Acc: 0.9139 | Val Loss: 0.2443 Acc: 0.9028\n",
      "Epoch 031 | Train Loss: 0.1991 Acc: 0.9227 | Val Loss: 0.2224 Acc: 0.9118\n",
      "Epoch 032 | Train Loss: 0.1841 Acc: 0.9227 | Val Loss: 0.2543 Acc: 0.9064\n",
      "Epoch 033 | Train Loss: 0.1940 Acc: 0.9242 | Val Loss: 0.2047 Acc: 0.9197\n",
      "Epoch 034 | Train Loss: 0.1749 Acc: 0.9334 | Val Loss: 0.2379 Acc: 0.9070\n",
      "Epoch 035 | Train Loss: 0.1643 Acc: 0.9376 | Val Loss: 0.2427 Acc: 0.9167\n",
      "Epoch 036 | Train Loss: 0.1723 Acc: 0.9304 | Val Loss: 0.2425 Acc: 0.8973\n",
      "Epoch 037 | Train Loss: 0.1669 Acc: 0.9354 | Val Loss: 0.2181 Acc: 0.9155\n",
      "Epoch 038 | Train Loss: 0.1606 Acc: 0.9401 | Val Loss: 0.2147 Acc: 0.9191\n",
      "Epoch 039 | Train Loss: 0.1546 Acc: 0.9379 | Val Loss: 0.2143 Acc: 0.9221\n",
      "Epoch 040 | Train Loss: 0.1466 Acc: 0.9455 | Val Loss: 0.2156 Acc: 0.9185\n",
      "Epoch 041 | Train Loss: 0.1305 Acc: 0.9485 | Val Loss: 0.2364 Acc: 0.9143\n",
      "Epoch 042 | Train Loss: 0.1418 Acc: 0.9450 | Val Loss: 0.2169 Acc: 0.9245\n",
      "Epoch 043 | Train Loss: 0.1307 Acc: 0.9514 | Val Loss: 0.2379 Acc: 0.9300\n",
      "Early stopping triggered.\n",
      "Epoch 001 | Train Loss: 0.6877 Acc: 0.5615 | Val Loss: 0.6800 Acc: 0.5851\n",
      "Epoch 002 | Train Loss: 0.6708 Acc: 0.5940 | Val Loss: 0.6410 Acc: 0.6486\n",
      "Epoch 003 | Train Loss: 0.6378 Acc: 0.6526 | Val Loss: 0.5923 Acc: 0.6872\n",
      "Epoch 004 | Train Loss: 0.5987 Acc: 0.6894 | Val Loss: 0.6096 Acc: 0.6763\n",
      "Epoch 005 | Train Loss: 0.5775 Acc: 0.7053 | Val Loss: 0.5758 Acc: 0.6987\n",
      "Epoch 006 | Train Loss: 0.5562 Acc: 0.7238 | Val Loss: 0.5544 Acc: 0.7216\n",
      "Epoch 007 | Train Loss: 0.5436 Acc: 0.7264 | Val Loss: 0.5894 Acc: 0.7095\n",
      "Epoch 008 | Train Loss: 0.5252 Acc: 0.7444 | Val Loss: 0.5570 Acc: 0.7180\n",
      "Epoch 009 | Train Loss: 0.5045 Acc: 0.7506 | Val Loss: 0.5004 Acc: 0.7560\n",
      "Epoch 010 | Train Loss: 0.4739 Acc: 0.7744 | Val Loss: 0.4972 Acc: 0.7609\n",
      "Epoch 011 | Train Loss: 0.4545 Acc: 0.7903 | Val Loss: 0.4699 Acc: 0.7603\n",
      "Epoch 012 | Train Loss: 0.4169 Acc: 0.8120 | Val Loss: 0.4251 Acc: 0.8092\n",
      "Epoch 013 | Train Loss: 0.3900 Acc: 0.8295 | Val Loss: 0.3827 Acc: 0.8207\n",
      "Epoch 014 | Train Loss: 0.3668 Acc: 0.8433 | Val Loss: 0.3905 Acc: 0.8194\n",
      "Epoch 015 | Train Loss: 0.3379 Acc: 0.8523 | Val Loss: 0.3855 Acc: 0.8152\n",
      "Epoch 016 | Train Loss: 0.3062 Acc: 0.8723 | Val Loss: 0.3281 Acc: 0.8521\n",
      "Epoch 017 | Train Loss: 0.2946 Acc: 0.8763 | Val Loss: 0.3376 Acc: 0.8732\n",
      "Epoch 018 | Train Loss: 0.2867 Acc: 0.8788 | Val Loss: 0.2912 Acc: 0.8798\n",
      "Epoch 019 | Train Loss: 0.2641 Acc: 0.8880 | Val Loss: 0.2940 Acc: 0.8738\n",
      "Epoch 020 | Train Loss: 0.2614 Acc: 0.8922 | Val Loss: 0.2874 Acc: 0.8829\n",
      "Epoch 021 | Train Loss: 0.2453 Acc: 0.9050 | Val Loss: 0.3051 Acc: 0.8768\n",
      "Epoch 022 | Train Loss: 0.2384 Acc: 0.9043 | Val Loss: 0.2855 Acc: 0.8877\n",
      "Epoch 023 | Train Loss: 0.2248 Acc: 0.9127 | Val Loss: 0.2861 Acc: 0.8865\n",
      "Epoch 024 | Train Loss: 0.2284 Acc: 0.9056 | Val Loss: 0.2661 Acc: 0.8992\n",
      "Epoch 025 | Train Loss: 0.2255 Acc: 0.9127 | Val Loss: 0.2565 Acc: 0.9028\n",
      "Epoch 026 | Train Loss: 0.1982 Acc: 0.9191 | Val Loss: 0.2410 Acc: 0.9070\n",
      "Epoch 027 | Train Loss: 0.1925 Acc: 0.9263 | Val Loss: 0.2669 Acc: 0.8841\n",
      "Epoch 028 | Train Loss: 0.2020 Acc: 0.9204 | Val Loss: 0.3413 Acc: 0.8756\n",
      "Epoch 029 | Train Loss: 0.1895 Acc: 0.9277 | Val Loss: 0.2782 Acc: 0.9034\n",
      "Epoch 030 | Train Loss: 0.1700 Acc: 0.9348 | Val Loss: 0.2959 Acc: 0.8847\n",
      "Epoch 031 | Train Loss: 0.1875 Acc: 0.9259 | Val Loss: 0.3073 Acc: 0.8732\n",
      "Epoch 032 | Train Loss: 0.1679 Acc: 0.9334 | Val Loss: 0.2444 Acc: 0.9112\n",
      "Epoch 033 | Train Loss: 0.1594 Acc: 0.9382 | Val Loss: 0.2438 Acc: 0.9112\n",
      "Epoch 034 | Train Loss: 0.1527 Acc: 0.9422 | Val Loss: 0.2867 Acc: 0.8937\n",
      "Epoch 035 | Train Loss: 0.1649 Acc: 0.9340 | Val Loss: 0.3025 Acc: 0.8702\n",
      "Epoch 036 | Train Loss: 0.1583 Acc: 0.9370 | Val Loss: 0.3293 Acc: 0.8702\n",
      "Early stopping triggered.\n",
      "Epoch 001 | Train Loss: 0.6784 Acc: 0.5777 | Val Loss: 0.6641 Acc: 0.5990\n",
      "Epoch 002 | Train Loss: 0.6276 Acc: 0.6606 | Val Loss: 0.6157 Acc: 0.6963\n",
      "Epoch 003 | Train Loss: 0.5759 Acc: 0.7149 | Val Loss: 0.5705 Acc: 0.6975\n",
      "Epoch 004 | Train Loss: 0.5499 Acc: 0.7303 | Val Loss: 0.5364 Acc: 0.7277\n",
      "Epoch 005 | Train Loss: 0.5314 Acc: 0.7469 | Val Loss: 0.5349 Acc: 0.7409\n",
      "Epoch 006 | Train Loss: 0.5114 Acc: 0.7566 | Val Loss: 0.5017 Acc: 0.7615\n",
      "Epoch 007 | Train Loss: 0.4796 Acc: 0.7759 | Val Loss: 0.4831 Acc: 0.7693\n",
      "Epoch 008 | Train Loss: 0.4600 Acc: 0.7857 | Val Loss: 0.4652 Acc: 0.7729\n",
      "Epoch 009 | Train Loss: 0.4410 Acc: 0.7972 | Val Loss: 0.4570 Acc: 0.7790\n",
      "Epoch 010 | Train Loss: 0.4021 Acc: 0.8203 | Val Loss: 0.4027 Acc: 0.8128\n",
      "Epoch 011 | Train Loss: 0.3716 Acc: 0.8329 | Val Loss: 0.3852 Acc: 0.8219\n",
      "Epoch 012 | Train Loss: 0.3440 Acc: 0.8501 | Val Loss: 0.3240 Acc: 0.8539\n",
      "Epoch 013 | Train Loss: 0.3344 Acc: 0.8603 | Val Loss: 0.3061 Acc: 0.8684\n",
      "Epoch 014 | Train Loss: 0.3039 Acc: 0.8726 | Val Loss: 0.3024 Acc: 0.8635\n",
      "Epoch 015 | Train Loss: 0.2832 Acc: 0.8821 | Val Loss: 0.3748 Acc: 0.8303\n",
      "Epoch 016 | Train Loss: 0.2728 Acc: 0.8896 | Val Loss: 0.2575 Acc: 0.8955\n",
      "Epoch 017 | Train Loss: 0.2540 Acc: 0.8972 | Val Loss: 0.2634 Acc: 0.8931\n",
      "Epoch 018 | Train Loss: 0.2367 Acc: 0.9043 | Val Loss: 0.2233 Acc: 0.9070\n",
      "Epoch 019 | Train Loss: 0.2319 Acc: 0.9073 | Val Loss: 0.2624 Acc: 0.8883\n",
      "Epoch 020 | Train Loss: 0.2173 Acc: 0.9129 | Val Loss: 0.2445 Acc: 0.9034\n",
      "Epoch 021 | Train Loss: 0.2133 Acc: 0.9176 | Val Loss: 0.3328 Acc: 0.8653\n",
      "Epoch 022 | Train Loss: 0.2039 Acc: 0.9197 | Val Loss: 0.2471 Acc: 0.9058\n",
      "Epoch 023 | Train Loss: 0.1894 Acc: 0.9228 | Val Loss: 0.2103 Acc: 0.9112\n",
      "Epoch 024 | Train Loss: 0.1793 Acc: 0.9287 | Val Loss: 0.1953 Acc: 0.9173\n",
      "Epoch 025 | Train Loss: 0.1749 Acc: 0.9322 | Val Loss: 0.1974 Acc: 0.9179\n",
      "Epoch 026 | Train Loss: 0.1560 Acc: 0.9408 | Val Loss: 0.1920 Acc: 0.9227\n",
      "Epoch 027 | Train Loss: 0.1618 Acc: 0.9360 | Val Loss: 0.2101 Acc: 0.9124\n",
      "Epoch 028 | Train Loss: 0.1538 Acc: 0.9351 | Val Loss: 0.1737 Acc: 0.9312\n",
      "Epoch 029 | Train Loss: 0.1412 Acc: 0.9462 | Val Loss: 0.2040 Acc: 0.9215\n",
      "Epoch 030 | Train Loss: 0.1441 Acc: 0.9410 | Val Loss: 0.2044 Acc: 0.9227\n",
      "Epoch 031 | Train Loss: 0.1399 Acc: 0.9458 | Val Loss: 0.1887 Acc: 0.9300\n",
      "Epoch 032 | Train Loss: 0.1352 Acc: 0.9511 | Val Loss: 0.1989 Acc: 0.9263\n",
      "Epoch 033 | Train Loss: 0.1406 Acc: 0.9481 | Val Loss: 0.1699 Acc: 0.9269\n",
      "Epoch 034 | Train Loss: 0.1254 Acc: 0.9532 | Val Loss: 0.1923 Acc: 0.9312\n",
      "Epoch 035 | Train Loss: 0.1264 Acc: 0.9508 | Val Loss: 0.2348 Acc: 0.9191\n",
      "Epoch 036 | Train Loss: 0.1197 Acc: 0.9518 | Val Loss: 0.1690 Acc: 0.9287\n",
      "Epoch 037 | Train Loss: 0.1234 Acc: 0.9518 | Val Loss: 0.1912 Acc: 0.9263\n",
      "Epoch 038 | Train Loss: 0.1134 Acc: 0.9553 | Val Loss: 0.2069 Acc: 0.9233\n",
      "Epoch 039 | Train Loss: 0.1180 Acc: 0.9517 | Val Loss: 0.1806 Acc: 0.9354\n",
      "Epoch 040 | Train Loss: 0.1154 Acc: 0.9552 | Val Loss: 0.1813 Acc: 0.9227\n",
      "Epoch 041 | Train Loss: 0.1168 Acc: 0.9591 | Val Loss: 0.1394 Acc: 0.9426\n",
      "Epoch 042 | Train Loss: 0.1073 Acc: 0.9594 | Val Loss: 0.1565 Acc: 0.9396\n",
      "Epoch 043 | Train Loss: 0.1140 Acc: 0.9588 | Val Loss: 0.1743 Acc: 0.9336\n",
      "Epoch 044 | Train Loss: 0.1017 Acc: 0.9612 | Val Loss: 0.1592 Acc: 0.9408\n",
      "Epoch 045 | Train Loss: 0.0891 Acc: 0.9659 | Val Loss: 0.1646 Acc: 0.9306\n",
      "Epoch 046 | Train Loss: 0.0944 Acc: 0.9645 | Val Loss: 0.1582 Acc: 0.9378\n",
      "Epoch 047 | Train Loss: 0.1026 Acc: 0.9624 | Val Loss: 0.1449 Acc: 0.9499\n",
      "Epoch 048 | Train Loss: 0.0885 Acc: 0.9659 | Val Loss: 0.1654 Acc: 0.9426\n",
      "Epoch 049 | Train Loss: 0.0990 Acc: 0.9632 | Val Loss: 0.1759 Acc: 0.9396\n",
      "Epoch 050 | Train Loss: 0.0921 Acc: 0.9650 | Val Loss: 0.1857 Acc: 0.9342\n",
      "Epoch 051 | Train Loss: 0.0930 Acc: 0.9659 | Val Loss: 0.1690 Acc: 0.9384\n",
      "Early stopping triggered.\n",
      "Epoch 001 | Train Loss: 0.6856 Acc: 0.5608 | Val Loss: 0.6875 Acc: 0.5586\n",
      "Epoch 002 | Train Loss: 0.6799 Acc: 0.5803 | Val Loss: 0.6831 Acc: 0.5700\n",
      "Epoch 003 | Train Loss: 0.6714 Acc: 0.5987 | Val Loss: 0.6582 Acc: 0.6057\n",
      "Epoch 004 | Train Loss: 0.6394 Acc: 0.6574 | Val Loss: 0.6427 Acc: 0.6606\n",
      "Epoch 005 | Train Loss: 0.6213 Acc: 0.6764 | Val Loss: 0.6047 Acc: 0.6806\n",
      "Epoch 006 | Train Loss: 0.5844 Acc: 0.7119 | Val Loss: 0.5871 Acc: 0.6957\n",
      "Epoch 007 | Train Loss: 0.5647 Acc: 0.7196 | Val Loss: 0.5724 Acc: 0.6987\n",
      "Epoch 008 | Train Loss: 0.5501 Acc: 0.7315 | Val Loss: 0.5398 Acc: 0.7307\n",
      "Epoch 009 | Train Loss: 0.5277 Acc: 0.7430 | Val Loss: 0.5105 Acc: 0.7470\n",
      "Epoch 010 | Train Loss: 0.5163 Acc: 0.7546 | Val Loss: 0.4982 Acc: 0.7633\n",
      "Epoch 011 | Train Loss: 0.4974 Acc: 0.7664 | Val Loss: 0.4799 Acc: 0.7669\n",
      "Epoch 012 | Train Loss: 0.4774 Acc: 0.7722 | Val Loss: 0.4969 Acc: 0.7645\n",
      "Epoch 013 | Train Loss: 0.4746 Acc: 0.7800 | Val Loss: 0.4928 Acc: 0.7591\n",
      "Epoch 014 | Train Loss: 0.4722 Acc: 0.7812 | Val Loss: 0.4576 Acc: 0.7802\n",
      "Epoch 015 | Train Loss: 0.4467 Acc: 0.7912 | Val Loss: 0.4264 Acc: 0.7868\n",
      "Epoch 016 | Train Loss: 0.4295 Acc: 0.8051 | Val Loss: 0.4319 Acc: 0.7959\n",
      "Epoch 017 | Train Loss: 0.4246 Acc: 0.8045 | Val Loss: 0.4070 Acc: 0.8068\n",
      "Epoch 018 | Train Loss: 0.4107 Acc: 0.8119 | Val Loss: 0.4006 Acc: 0.8110\n",
      "Epoch 019 | Train Loss: 0.4009 Acc: 0.8212 | Val Loss: 0.4033 Acc: 0.8303\n",
      "Epoch 020 | Train Loss: 0.3892 Acc: 0.8238 | Val Loss: 0.4323 Acc: 0.8213\n",
      "Epoch 021 | Train Loss: 0.3842 Acc: 0.8345 | Val Loss: 0.3548 Acc: 0.8357\n",
      "Epoch 022 | Train Loss: 0.3712 Acc: 0.8396 | Val Loss: 0.3934 Acc: 0.8062\n",
      "Epoch 023 | Train Loss: 0.3628 Acc: 0.8454 | Val Loss: 0.3474 Acc: 0.8472\n",
      "Epoch 024 | Train Loss: 0.3501 Acc: 0.8507 | Val Loss: 0.3428 Acc: 0.8496\n",
      "Epoch 025 | Train Loss: 0.3391 Acc: 0.8528 | Val Loss: 0.3486 Acc: 0.8345\n",
      "Epoch 026 | Train Loss: 0.3355 Acc: 0.8602 | Val Loss: 0.2959 Acc: 0.8732\n",
      "Epoch 027 | Train Loss: 0.3132 Acc: 0.8677 | Val Loss: 0.2791 Acc: 0.8774\n",
      "Epoch 028 | Train Loss: 0.3216 Acc: 0.8649 | Val Loss: 0.2771 Acc: 0.8810\n",
      "Epoch 029 | Train Loss: 0.3080 Acc: 0.8769 | Val Loss: 0.2650 Acc: 0.8943\n",
      "Epoch 030 | Train Loss: 0.2939 Acc: 0.8762 | Val Loss: 0.2624 Acc: 0.8889\n",
      "Epoch 031 | Train Loss: 0.2892 Acc: 0.8759 | Val Loss: 0.2917 Acc: 0.8671\n",
      "Epoch 032 | Train Loss: 0.2712 Acc: 0.8872 | Val Loss: 0.2450 Acc: 0.8998\n",
      "Epoch 033 | Train Loss: 0.2642 Acc: 0.8952 | Val Loss: 0.2925 Acc: 0.8804\n",
      "Epoch 034 | Train Loss: 0.2591 Acc: 0.8967 | Val Loss: 0.2258 Acc: 0.9058\n",
      "Epoch 035 | Train Loss: 0.2664 Acc: 0.8955 | Val Loss: 0.2493 Acc: 0.8889\n",
      "Epoch 036 | Train Loss: 0.2608 Acc: 0.8979 | Val Loss: 0.2456 Acc: 0.9010\n",
      "Epoch 037 | Train Loss: 0.2386 Acc: 0.9067 | Val Loss: 0.2474 Acc: 0.8949\n",
      "Epoch 038 | Train Loss: 0.2437 Acc: 0.9022 | Val Loss: 0.2512 Acc: 0.8943\n",
      "Epoch 039 | Train Loss: 0.2336 Acc: 0.9047 | Val Loss: 0.2370 Acc: 0.9076\n",
      "Epoch 040 | Train Loss: 0.2140 Acc: 0.9142 | Val Loss: 0.2811 Acc: 0.8847\n",
      "Epoch 041 | Train Loss: 0.2201 Acc: 0.9138 | Val Loss: 0.2280 Acc: 0.9136\n",
      "Epoch 042 | Train Loss: 0.2207 Acc: 0.9126 | Val Loss: 0.2513 Acc: 0.9034\n",
      "Epoch 043 | Train Loss: 0.2140 Acc: 0.9135 | Val Loss: 0.2161 Acc: 0.9143\n",
      "Epoch 044 | Train Loss: 0.2154 Acc: 0.9173 | Val Loss: 0.2866 Acc: 0.8979\n",
      "Epoch 045 | Train Loss: 0.2281 Acc: 0.9123 | Val Loss: 0.2121 Acc: 0.9130\n",
      "Epoch 046 | Train Loss: 0.2144 Acc: 0.9188 | Val Loss: 0.1880 Acc: 0.9197\n",
      "Epoch 047 | Train Loss: 0.2026 Acc: 0.9233 | Val Loss: 0.2052 Acc: 0.9239\n",
      "Epoch 048 | Train Loss: 0.2055 Acc: 0.9218 | Val Loss: 0.2719 Acc: 0.8919\n",
      "Epoch 049 | Train Loss: 0.1944 Acc: 0.9269 | Val Loss: 0.2149 Acc: 0.9106\n",
      "Epoch 050 | Train Loss: 0.1999 Acc: 0.9180 | Val Loss: 0.2357 Acc: 0.9016\n",
      "Epoch 051 | Train Loss: 0.2006 Acc: 0.9257 | Val Loss: 0.2348 Acc: 0.9221\n",
      "Epoch 052 | Train Loss: 0.1773 Acc: 0.9299 | Val Loss: 0.1890 Acc: 0.9185\n",
      "Epoch 053 | Train Loss: 0.1848 Acc: 0.9286 | Val Loss: 0.2043 Acc: 0.9167\n",
      "Epoch 054 | Train Loss: 0.1913 Acc: 0.9283 | Val Loss: 0.2413 Acc: 0.9016\n",
      "Epoch 055 | Train Loss: 0.1766 Acc: 0.9351 | Val Loss: 0.2008 Acc: 0.9167\n",
      "Epoch 056 | Train Loss: 0.1836 Acc: 0.9321 | Val Loss: 0.2026 Acc: 0.9239\n",
      "Early stopping triggered.\n",
      "Iteration 3/40 | Best Val Loss: 0.1394 | Iter Time: 319.55s | Total Time: 19.43 min\n",
      "Epoch 001 | Train Loss: 0.6790 Acc: 0.5852 | Val Loss: 0.6748 Acc: 0.5918\n",
      "Epoch 002 | Train Loss: 0.6702 Acc: 0.5990 | Val Loss: 0.6690 Acc: 0.6021\n",
      "Epoch 003 | Train Loss: 0.6628 Acc: 0.6121 | Val Loss: 0.6564 Acc: 0.6051\n",
      "Epoch 004 | Train Loss: 0.6354 Acc: 0.6502 | Val Loss: 0.6179 Acc: 0.6890\n",
      "Epoch 005 | Train Loss: 0.6016 Acc: 0.6887 | Val Loss: 0.5734 Acc: 0.7089\n",
      "Epoch 006 | Train Loss: 0.5801 Acc: 0.7118 | Val Loss: 0.5661 Acc: 0.7138\n",
      "Epoch 007 | Train Loss: 0.5475 Acc: 0.7296 | Val Loss: 0.5874 Acc: 0.7035\n",
      "Epoch 008 | Train Loss: 0.5274 Acc: 0.7462 | Val Loss: 0.5224 Acc: 0.7403\n",
      "Epoch 009 | Train Loss: 0.5108 Acc: 0.7515 | Val Loss: 0.5123 Acc: 0.7446\n",
      "Epoch 010 | Train Loss: 0.4934 Acc: 0.7663 | Val Loss: 0.4784 Acc: 0.7627\n",
      "Epoch 011 | Train Loss: 0.4762 Acc: 0.7738 | Val Loss: 0.4711 Acc: 0.7560\n",
      "Epoch 012 | Train Loss: 0.4530 Acc: 0.7812 | Val Loss: 0.4626 Acc: 0.7681\n",
      "Epoch 013 | Train Loss: 0.4384 Acc: 0.7959 | Val Loss: 0.4452 Acc: 0.7796\n",
      "Epoch 014 | Train Loss: 0.4323 Acc: 0.7993 | Val Loss: 0.4379 Acc: 0.7772\n",
      "Epoch 015 | Train Loss: 0.4112 Acc: 0.8087 | Val Loss: 0.3992 Acc: 0.7959\n",
      "Epoch 016 | Train Loss: 0.4143 Acc: 0.8078 | Val Loss: 0.4004 Acc: 0.8007\n",
      "Epoch 017 | Train Loss: 0.3972 Acc: 0.8199 | Val Loss: 0.4052 Acc: 0.8104\n",
      "Epoch 018 | Train Loss: 0.3685 Acc: 0.8389 | Val Loss: 0.3702 Acc: 0.8273\n",
      "Epoch 019 | Train Loss: 0.3503 Acc: 0.8427 | Val Loss: 0.3609 Acc: 0.8448\n",
      "Epoch 020 | Train Loss: 0.3369 Acc: 0.8513 | Val Loss: 0.3895 Acc: 0.8134\n",
      "Epoch 021 | Train Loss: 0.3165 Acc: 0.8656 | Val Loss: 0.3590 Acc: 0.8376\n",
      "Epoch 022 | Train Loss: 0.3088 Acc: 0.8714 | Val Loss: 0.3159 Acc: 0.8629\n",
      "Epoch 023 | Train Loss: 0.3060 Acc: 0.8665 | Val Loss: 0.3083 Acc: 0.8684\n",
      "Epoch 024 | Train Loss: 0.2838 Acc: 0.8771 | Val Loss: 0.3156 Acc: 0.8647\n",
      "Epoch 025 | Train Loss: 0.2731 Acc: 0.8881 | Val Loss: 0.2917 Acc: 0.8871\n",
      "Epoch 026 | Train Loss: 0.2503 Acc: 0.8967 | Val Loss: 0.2672 Acc: 0.9004\n",
      "Epoch 027 | Train Loss: 0.2398 Acc: 0.9025 | Val Loss: 0.2885 Acc: 0.8829\n",
      "Epoch 028 | Train Loss: 0.2352 Acc: 0.9079 | Val Loss: 0.2707 Acc: 0.8931\n",
      "Epoch 029 | Train Loss: 0.2271 Acc: 0.9068 | Val Loss: 0.3703 Acc: 0.8581\n",
      "Epoch 030 | Train Loss: 0.2293 Acc: 0.9093 | Val Loss: 0.2440 Acc: 0.9034\n",
      "Epoch 031 | Train Loss: 0.2184 Acc: 0.9173 | Val Loss: 0.2453 Acc: 0.9028\n",
      "Epoch 032 | Train Loss: 0.2056 Acc: 0.9189 | Val Loss: 0.2492 Acc: 0.9088\n",
      "Epoch 033 | Train Loss: 0.1986 Acc: 0.9219 | Val Loss: 0.2336 Acc: 0.9167\n",
      "Epoch 034 | Train Loss: 0.1961 Acc: 0.9275 | Val Loss: 0.2251 Acc: 0.9155\n",
      "Epoch 035 | Train Loss: 0.1904 Acc: 0.9265 | Val Loss: 0.2506 Acc: 0.9004\n",
      "Epoch 036 | Train Loss: 0.1831 Acc: 0.9286 | Val Loss: 0.2421 Acc: 0.9058\n",
      "Epoch 037 | Train Loss: 0.1817 Acc: 0.9304 | Val Loss: 0.2125 Acc: 0.9173\n",
      "Epoch 038 | Train Loss: 0.1771 Acc: 0.9293 | Val Loss: 0.2037 Acc: 0.9251\n",
      "Epoch 039 | Train Loss: 0.1817 Acc: 0.9352 | Val Loss: 0.2146 Acc: 0.9197\n",
      "Epoch 040 | Train Loss: 0.1667 Acc: 0.9321 | Val Loss: 0.2141 Acc: 0.9173\n",
      "Epoch 041 | Train Loss: 0.1589 Acc: 0.9370 | Val Loss: 0.2159 Acc: 0.9221\n",
      "Epoch 042 | Train Loss: 0.1618 Acc: 0.9355 | Val Loss: 0.2249 Acc: 0.9191\n",
      "Epoch 043 | Train Loss: 0.1598 Acc: 0.9370 | Val Loss: 0.1969 Acc: 0.9227\n",
      "Epoch 044 | Train Loss: 0.1543 Acc: 0.9385 | Val Loss: 0.1939 Acc: 0.9336\n",
      "Epoch 045 | Train Loss: 0.1576 Acc: 0.9379 | Val Loss: 0.2341 Acc: 0.9173\n",
      "Epoch 046 | Train Loss: 0.1547 Acc: 0.9422 | Val Loss: 0.2148 Acc: 0.9149\n",
      "Epoch 047 | Train Loss: 0.1360 Acc: 0.9473 | Val Loss: 0.1910 Acc: 0.9360\n",
      "Epoch 048 | Train Loss: 0.1549 Acc: 0.9401 | Val Loss: 0.1957 Acc: 0.9251\n",
      "Epoch 049 | Train Loss: 0.1398 Acc: 0.9478 | Val Loss: 0.2246 Acc: 0.9155\n",
      "Epoch 050 | Train Loss: 0.1372 Acc: 0.9493 | Val Loss: 0.1931 Acc: 0.9293\n",
      "Epoch 051 | Train Loss: 0.1313 Acc: 0.9496 | Val Loss: 0.2472 Acc: 0.9046\n",
      "Epoch 052 | Train Loss: 0.1369 Acc: 0.9479 | Val Loss: 0.2060 Acc: 0.9239\n",
      "Epoch 053 | Train Loss: 0.1387 Acc: 0.9496 | Val Loss: 0.1978 Acc: 0.9227\n",
      "Epoch 054 | Train Loss: 0.1157 Acc: 0.9574 | Val Loss: 0.1872 Acc: 0.9287\n",
      "Epoch 055 | Train Loss: 0.1305 Acc: 0.9505 | Val Loss: 0.2003 Acc: 0.9312\n",
      "Epoch 056 | Train Loss: 0.1308 Acc: 0.9493 | Val Loss: 0.2106 Acc: 0.9221\n",
      "Epoch 057 | Train Loss: 0.1206 Acc: 0.9577 | Val Loss: 0.2231 Acc: 0.9300\n",
      "Epoch 058 | Train Loss: 0.1257 Acc: 0.9506 | Val Loss: 0.2042 Acc: 0.9312\n",
      "Epoch 059 | Train Loss: 0.1294 Acc: 0.9505 | Val Loss: 0.1821 Acc: 0.9354\n",
      "Epoch 060 | Train Loss: 0.1182 Acc: 0.9524 | Val Loss: 0.2138 Acc: 0.9287\n",
      "Epoch 001 | Train Loss: 0.6833 Acc: 0.5710 | Val Loss: 0.6844 Acc: 0.5531\n",
      "Epoch 002 | Train Loss: 0.6770 Acc: 0.5869 | Val Loss: 0.6722 Acc: 0.5954\n",
      "Epoch 003 | Train Loss: 0.6427 Acc: 0.6381 | Val Loss: 0.6138 Acc: 0.6697\n",
      "Epoch 004 | Train Loss: 0.5933 Acc: 0.7010 | Val Loss: 0.5879 Acc: 0.6860\n",
      "Epoch 005 | Train Loss: 0.5588 Acc: 0.7222 | Val Loss: 0.5557 Acc: 0.7355\n",
      "Epoch 006 | Train Loss: 0.5406 Acc: 0.7364 | Val Loss: 0.5182 Acc: 0.7397\n",
      "Epoch 007 | Train Loss: 0.5130 Acc: 0.7571 | Val Loss: 0.4899 Acc: 0.7693\n",
      "Epoch 008 | Train Loss: 0.4760 Acc: 0.7747 | Val Loss: 0.4865 Acc: 0.7579\n",
      "Epoch 009 | Train Loss: 0.4527 Acc: 0.7865 | Val Loss: 0.4536 Acc: 0.7862\n",
      "Epoch 010 | Train Loss: 0.4257 Acc: 0.8096 | Val Loss: 0.4715 Acc: 0.7729\n",
      "Epoch 011 | Train Loss: 0.4078 Acc: 0.8176 | Val Loss: 0.4050 Acc: 0.8116\n",
      "Epoch 012 | Train Loss: 0.3832 Acc: 0.8351 | Val Loss: 0.3931 Acc: 0.8243\n",
      "Epoch 013 | Train Loss: 0.3726 Acc: 0.8369 | Val Loss: 0.3652 Acc: 0.8418\n",
      "Epoch 014 | Train Loss: 0.3396 Acc: 0.8593 | Val Loss: 0.3326 Acc: 0.8605\n",
      "Epoch 015 | Train Loss: 0.3286 Acc: 0.8628 | Val Loss: 0.3108 Acc: 0.8671\n",
      "Epoch 016 | Train Loss: 0.3189 Acc: 0.8671 | Val Loss: 0.3288 Acc: 0.8533\n",
      "Epoch 017 | Train Loss: 0.3211 Acc: 0.8653 | Val Loss: 0.3347 Acc: 0.8551\n",
      "Epoch 018 | Train Loss: 0.2992 Acc: 0.8815 | Val Loss: 0.3051 Acc: 0.8708\n",
      "Epoch 019 | Train Loss: 0.2731 Acc: 0.8872 | Val Loss: 0.2762 Acc: 0.8792\n",
      "Epoch 020 | Train Loss: 0.2695 Acc: 0.8919 | Val Loss: 0.2779 Acc: 0.8822\n",
      "Epoch 021 | Train Loss: 0.2607 Acc: 0.8931 | Val Loss: 0.2720 Acc: 0.8841\n",
      "Epoch 022 | Train Loss: 0.2473 Acc: 0.9046 | Val Loss: 0.2631 Acc: 0.8919\n",
      "Epoch 023 | Train Loss: 0.2394 Acc: 0.9031 | Val Loss: 0.2565 Acc: 0.8979\n",
      "Epoch 024 | Train Loss: 0.2384 Acc: 0.9022 | Val Loss: 0.2528 Acc: 0.8961\n",
      "Epoch 025 | Train Loss: 0.2348 Acc: 0.9037 | Val Loss: 0.2385 Acc: 0.8998\n",
      "Epoch 026 | Train Loss: 0.2209 Acc: 0.9144 | Val Loss: 0.2517 Acc: 0.8949\n",
      "Epoch 027 | Train Loss: 0.2257 Acc: 0.9079 | Val Loss: 0.2188 Acc: 0.9130\n",
      "Epoch 028 | Train Loss: 0.2262 Acc: 0.9087 | Val Loss: 0.2495 Acc: 0.8877\n",
      "Epoch 029 | Train Loss: 0.2051 Acc: 0.9224 | Val Loss: 0.2429 Acc: 0.9088\n",
      "Epoch 030 | Train Loss: 0.2065 Acc: 0.9171 | Val Loss: 0.2496 Acc: 0.9010\n",
      "Epoch 031 | Train Loss: 0.1934 Acc: 0.9213 | Val Loss: 0.2057 Acc: 0.9209\n",
      "Epoch 032 | Train Loss: 0.1846 Acc: 0.9280 | Val Loss: 0.1985 Acc: 0.9191\n",
      "Epoch 033 | Train Loss: 0.1913 Acc: 0.9281 | Val Loss: 0.2041 Acc: 0.9143\n",
      "Epoch 034 | Train Loss: 0.1873 Acc: 0.9292 | Val Loss: 0.2338 Acc: 0.9221\n",
      "Epoch 035 | Train Loss: 0.1907 Acc: 0.9296 | Val Loss: 0.2417 Acc: 0.9034\n",
      "Epoch 036 | Train Loss: 0.1729 Acc: 0.9345 | Val Loss: 0.2139 Acc: 0.9094\n",
      "Epoch 037 | Train Loss: 0.1723 Acc: 0.9360 | Val Loss: 0.2323 Acc: 0.9155\n",
      "Epoch 038 | Train Loss: 0.1744 Acc: 0.9307 | Val Loss: 0.2135 Acc: 0.9076\n",
      "Epoch 039 | Train Loss: 0.1701 Acc: 0.9331 | Val Loss: 0.2031 Acc: 0.9293\n",
      "Epoch 040 | Train Loss: 0.1690 Acc: 0.9340 | Val Loss: 0.2121 Acc: 0.9203\n",
      "Epoch 041 | Train Loss: 0.1664 Acc: 0.9367 | Val Loss: 0.2077 Acc: 0.9227\n",
      "Epoch 042 | Train Loss: 0.1598 Acc: 0.9364 | Val Loss: 0.2452 Acc: 0.9064\n",
      "Early stopping triggered.\n",
      "Epoch 001 | Train Loss: 0.6822 Acc: 0.5750 | Val Loss: 0.6703 Acc: 0.5876\n",
      "Epoch 002 | Train Loss: 0.6552 Acc: 0.6251 | Val Loss: 0.6217 Acc: 0.6594\n",
      "Epoch 003 | Train Loss: 0.6038 Acc: 0.6858 | Val Loss: 0.5799 Acc: 0.6926\n",
      "Epoch 004 | Train Loss: 0.5749 Acc: 0.7078 | Val Loss: 0.5703 Acc: 0.7114\n",
      "Epoch 005 | Train Loss: 0.5547 Acc: 0.7273 | Val Loss: 0.5321 Acc: 0.7337\n",
      "Epoch 006 | Train Loss: 0.5445 Acc: 0.7371 | Val Loss: 0.5309 Acc: 0.7301\n",
      "Epoch 007 | Train Loss: 0.5301 Acc: 0.7448 | Val Loss: 0.5380 Acc: 0.7313\n",
      "Epoch 008 | Train Loss: 0.5099 Acc: 0.7546 | Val Loss: 0.4845 Acc: 0.7693\n",
      "Epoch 009 | Train Loss: 0.4952 Acc: 0.7614 | Val Loss: 0.4845 Acc: 0.7621\n",
      "Epoch 010 | Train Loss: 0.4722 Acc: 0.7779 | Val Loss: 0.4722 Acc: 0.7748\n",
      "Epoch 011 | Train Loss: 0.4594 Acc: 0.7830 | Val Loss: 0.4434 Acc: 0.7947\n",
      "Epoch 012 | Train Loss: 0.4356 Acc: 0.8004 | Val Loss: 0.4215 Acc: 0.8068\n",
      "Epoch 013 | Train Loss: 0.4181 Acc: 0.8098 | Val Loss: 0.3948 Acc: 0.8146\n",
      "Epoch 014 | Train Loss: 0.3866 Acc: 0.8220 | Val Loss: 0.4240 Acc: 0.8001\n",
      "Epoch 015 | Train Loss: 0.4003 Acc: 0.8246 | Val Loss: 0.3815 Acc: 0.8315\n",
      "Epoch 016 | Train Loss: 0.3635 Acc: 0.8401 | Val Loss: 0.3590 Acc: 0.8357\n",
      "Epoch 017 | Train Loss: 0.3402 Acc: 0.8558 | Val Loss: 0.3217 Acc: 0.8611\n",
      "Epoch 018 | Train Loss: 0.3215 Acc: 0.8596 | Val Loss: 0.3255 Acc: 0.8551\n",
      "Epoch 019 | Train Loss: 0.3038 Acc: 0.8717 | Val Loss: 0.3087 Acc: 0.8581\n",
      "Epoch 020 | Train Loss: 0.3027 Acc: 0.8691 | Val Loss: 0.2815 Acc: 0.8798\n",
      "Epoch 021 | Train Loss: 0.2930 Acc: 0.8836 | Val Loss: 0.2599 Acc: 0.8961\n",
      "Epoch 022 | Train Loss: 0.2734 Acc: 0.8887 | Val Loss: 0.2640 Acc: 0.8907\n",
      "Epoch 023 | Train Loss: 0.2662 Acc: 0.8907 | Val Loss: 0.2383 Acc: 0.9022\n",
      "Epoch 024 | Train Loss: 0.2572 Acc: 0.8937 | Val Loss: 0.2742 Acc: 0.8967\n",
      "Epoch 025 | Train Loss: 0.2410 Acc: 0.9034 | Val Loss: 0.2533 Acc: 0.8973\n",
      "Epoch 026 | Train Loss: 0.2370 Acc: 0.9014 | Val Loss: 0.2137 Acc: 0.9215\n",
      "Epoch 027 | Train Loss: 0.2233 Acc: 0.9114 | Val Loss: 0.3251 Acc: 0.8847\n",
      "Epoch 028 | Train Loss: 0.2371 Acc: 0.9071 | Val Loss: 0.2233 Acc: 0.9185\n",
      "Epoch 029 | Train Loss: 0.2214 Acc: 0.9117 | Val Loss: 0.2361 Acc: 0.9088\n",
      "Epoch 030 | Train Loss: 0.2169 Acc: 0.9133 | Val Loss: 0.2560 Acc: 0.8986\n",
      "Epoch 031 | Train Loss: 0.2047 Acc: 0.9207 | Val Loss: 0.2480 Acc: 0.8973\n",
      "Epoch 032 | Train Loss: 0.2020 Acc: 0.9171 | Val Loss: 0.1920 Acc: 0.9269\n",
      "Epoch 033 | Train Loss: 0.2000 Acc: 0.9185 | Val Loss: 0.2070 Acc: 0.9173\n",
      "Epoch 034 | Train Loss: 0.1854 Acc: 0.9277 | Val Loss: 0.1969 Acc: 0.9251\n",
      "Epoch 035 | Train Loss: 0.1882 Acc: 0.9278 | Val Loss: 0.1981 Acc: 0.9233\n",
      "Epoch 036 | Train Loss: 0.1786 Acc: 0.9301 | Val Loss: 0.2180 Acc: 0.9088\n",
      "Epoch 037 | Train Loss: 0.1764 Acc: 0.9330 | Val Loss: 0.2065 Acc: 0.9215\n",
      "Epoch 038 | Train Loss: 0.1823 Acc: 0.9319 | Val Loss: 0.1945 Acc: 0.9203\n",
      "Epoch 039 | Train Loss: 0.1893 Acc: 0.9262 | Val Loss: 0.1970 Acc: 0.9251\n",
      "Epoch 040 | Train Loss: 0.1734 Acc: 0.9321 | Val Loss: 0.2159 Acc: 0.9136\n",
      "Epoch 041 | Train Loss: 0.1726 Acc: 0.9348 | Val Loss: 0.2274 Acc: 0.9076\n",
      "Epoch 042 | Train Loss: 0.1640 Acc: 0.9369 | Val Loss: 0.2011 Acc: 0.9227\n",
      "Early stopping triggered.\n",
      "Epoch 001 | Train Loss: 0.6780 Acc: 0.5830 | Val Loss: 0.6734 Acc: 0.5930\n",
      "Epoch 002 | Train Loss: 0.6690 Acc: 0.6017 | Val Loss: 0.6645 Acc: 0.6008\n",
      "Epoch 003 | Train Loss: 0.6630 Acc: 0.6071 | Val Loss: 0.6551 Acc: 0.6105\n",
      "Epoch 004 | Train Loss: 0.6450 Acc: 0.6284 | Val Loss: 0.6075 Acc: 0.6812\n",
      "Epoch 005 | Train Loss: 0.5831 Acc: 0.7071 | Val Loss: 0.5885 Acc: 0.7126\n",
      "Epoch 006 | Train Loss: 0.5485 Acc: 0.7323 | Val Loss: 0.5403 Acc: 0.7234\n",
      "Epoch 007 | Train Loss: 0.5211 Acc: 0.7506 | Val Loss: 0.5223 Acc: 0.7325\n",
      "Epoch 008 | Train Loss: 0.5020 Acc: 0.7611 | Val Loss: 0.4929 Acc: 0.7591\n",
      "Epoch 009 | Train Loss: 0.4738 Acc: 0.7765 | Val Loss: 0.4808 Acc: 0.7615\n",
      "Epoch 010 | Train Loss: 0.4533 Acc: 0.7931 | Val Loss: 0.4560 Acc: 0.7760\n",
      "Epoch 011 | Train Loss: 0.4235 Acc: 0.8037 | Val Loss: 0.4554 Acc: 0.7802\n",
      "Epoch 012 | Train Loss: 0.4097 Acc: 0.8132 | Val Loss: 0.4085 Acc: 0.8134\n",
      "Epoch 013 | Train Loss: 0.3836 Acc: 0.8292 | Val Loss: 0.3992 Acc: 0.8128\n",
      "Epoch 014 | Train Loss: 0.3646 Acc: 0.8344 | Val Loss: 0.3538 Acc: 0.8424\n",
      "Epoch 015 | Train Loss: 0.3412 Acc: 0.8517 | Val Loss: 0.3529 Acc: 0.8376\n",
      "Epoch 016 | Train Loss: 0.3162 Acc: 0.8628 | Val Loss: 0.3250 Acc: 0.8587\n",
      "Epoch 017 | Train Loss: 0.2998 Acc: 0.8772 | Val Loss: 0.2884 Acc: 0.8696\n",
      "Epoch 018 | Train Loss: 0.2781 Acc: 0.8833 | Val Loss: 0.2874 Acc: 0.8744\n",
      "Epoch 019 | Train Loss: 0.2719 Acc: 0.8831 | Val Loss: 0.2557 Acc: 0.8907\n",
      "Epoch 020 | Train Loss: 0.2483 Acc: 0.8996 | Val Loss: 0.2571 Acc: 0.9004\n",
      "Epoch 021 | Train Loss: 0.2261 Acc: 0.9085 | Val Loss: 0.2602 Acc: 0.8955\n",
      "Epoch 022 | Train Loss: 0.2142 Acc: 0.9121 | Val Loss: 0.2327 Acc: 0.9106\n",
      "Epoch 023 | Train Loss: 0.2044 Acc: 0.9177 | Val Loss: 0.2547 Acc: 0.8943\n",
      "Epoch 024 | Train Loss: 0.1883 Acc: 0.9262 | Val Loss: 0.2542 Acc: 0.8943\n",
      "Epoch 025 | Train Loss: 0.1949 Acc: 0.9186 | Val Loss: 0.2232 Acc: 0.9094\n",
      "Epoch 026 | Train Loss: 0.1758 Acc: 0.9296 | Val Loss: 0.1768 Acc: 0.9336\n",
      "Epoch 027 | Train Loss: 0.1667 Acc: 0.9322 | Val Loss: 0.2207 Acc: 0.9100\n",
      "Epoch 028 | Train Loss: 0.1611 Acc: 0.9395 | Val Loss: 0.1895 Acc: 0.9239\n",
      "Epoch 029 | Train Loss: 0.1621 Acc: 0.9376 | Val Loss: 0.2099 Acc: 0.9251\n",
      "Epoch 030 | Train Loss: 0.1497 Acc: 0.9423 | Val Loss: 0.1882 Acc: 0.9281\n",
      "Epoch 031 | Train Loss: 0.1461 Acc: 0.9402 | Val Loss: 0.1845 Acc: 0.9306\n",
      "Epoch 032 | Train Loss: 0.1406 Acc: 0.9452 | Val Loss: 0.2030 Acc: 0.9191\n",
      "Epoch 033 | Train Loss: 0.1445 Acc: 0.9444 | Val Loss: 0.1917 Acc: 0.9281\n",
      "Epoch 034 | Train Loss: 0.1355 Acc: 0.9475 | Val Loss: 0.1715 Acc: 0.9402\n",
      "Epoch 035 | Train Loss: 0.1212 Acc: 0.9543 | Val Loss: 0.1933 Acc: 0.9263\n",
      "Epoch 036 | Train Loss: 0.1166 Acc: 0.9553 | Val Loss: 0.1710 Acc: 0.9420\n",
      "Epoch 037 | Train Loss: 0.1308 Acc: 0.9506 | Val Loss: 0.2010 Acc: 0.9269\n",
      "Epoch 038 | Train Loss: 0.1136 Acc: 0.9582 | Val Loss: 0.1839 Acc: 0.9324\n",
      "Epoch 039 | Train Loss: 0.1092 Acc: 0.9588 | Val Loss: 0.1785 Acc: 0.9336\n",
      "Epoch 040 | Train Loss: 0.1137 Acc: 0.9562 | Val Loss: 0.1844 Acc: 0.9324\n",
      "Epoch 041 | Train Loss: 0.1041 Acc: 0.9624 | Val Loss: 0.1828 Acc: 0.9330\n",
      "Epoch 042 | Train Loss: 0.1091 Acc: 0.9570 | Val Loss: 0.1677 Acc: 0.9414\n",
      "Epoch 043 | Train Loss: 0.1069 Acc: 0.9629 | Val Loss: 0.1559 Acc: 0.9396\n",
      "Epoch 044 | Train Loss: 0.1019 Acc: 0.9623 | Val Loss: 0.1531 Acc: 0.9481\n",
      "Epoch 045 | Train Loss: 0.0966 Acc: 0.9639 | Val Loss: 0.1675 Acc: 0.9330\n",
      "Epoch 046 | Train Loss: 0.0853 Acc: 0.9689 | Val Loss: 0.1462 Acc: 0.9481\n",
      "Epoch 047 | Train Loss: 0.0838 Acc: 0.9693 | Val Loss: 0.1454 Acc: 0.9475\n",
      "Epoch 048 | Train Loss: 0.0728 Acc: 0.9748 | Val Loss: 0.1849 Acc: 0.9366\n",
      "Epoch 049 | Train Loss: 0.0921 Acc: 0.9659 | Val Loss: 0.1614 Acc: 0.9420\n",
      "Epoch 050 | Train Loss: 0.0852 Acc: 0.9701 | Val Loss: 0.1791 Acc: 0.9342\n",
      "Epoch 051 | Train Loss: 0.0836 Acc: 0.9677 | Val Loss: 0.1925 Acc: 0.9342\n",
      "Epoch 052 | Train Loss: 0.0823 Acc: 0.9680 | Val Loss: 0.1641 Acc: 0.9450\n",
      "Epoch 053 | Train Loss: 0.0867 Acc: 0.9674 | Val Loss: 0.1926 Acc: 0.9366\n",
      "Epoch 054 | Train Loss: 0.0801 Acc: 0.9687 | Val Loss: 0.1602 Acc: 0.9396\n",
      "Epoch 055 | Train Loss: 0.0760 Acc: 0.9703 | Val Loss: 0.1624 Acc: 0.9469\n",
      "Epoch 056 | Train Loss: 0.0736 Acc: 0.9700 | Val Loss: 0.1611 Acc: 0.9438\n",
      "Epoch 057 | Train Loss: 0.0717 Acc: 0.9727 | Val Loss: 0.1649 Acc: 0.9414\n",
      "Early stopping triggered.\n",
      "Epoch 001 | Train Loss: 0.6889 Acc: 0.5550 | Val Loss: 0.6863 Acc: 0.5586\n",
      "Epoch 002 | Train Loss: 0.6860 Acc: 0.5579 | Val Loss: 0.6866 Acc: 0.5586\n",
      "Epoch 003 | Train Loss: 0.6854 Acc: 0.5609 | Val Loss: 0.6868 Acc: 0.5586\n",
      "Epoch 004 | Train Loss: 0.6870 Acc: 0.5582 | Val Loss: 0.6863 Acc: 0.5586\n",
      "Epoch 005 | Train Loss: 0.6868 Acc: 0.5582 | Val Loss: 0.6863 Acc: 0.5586\n",
      "Epoch 006 | Train Loss: 0.6867 Acc: 0.5582 | Val Loss: 0.6863 Acc: 0.5586\n",
      "Epoch 007 | Train Loss: 0.6867 Acc: 0.5582 | Val Loss: 0.6863 Acc: 0.5586\n",
      "Epoch 008 | Train Loss: 0.6868 Acc: 0.5582 | Val Loss: 0.6864 Acc: 0.5586\n",
      "Epoch 009 | Train Loss: 0.6872 Acc: 0.5582 | Val Loss: 0.6867 Acc: 0.5586\n",
      "Epoch 010 | Train Loss: 0.6868 Acc: 0.5582 | Val Loss: 0.6863 Acc: 0.5586\n",
      "Epoch 011 | Train Loss: 0.6871 Acc: 0.5582 | Val Loss: 0.6863 Acc: 0.5586\n",
      "Early stopping triggered.\n",
      "Epoch 001 | Train Loss: 0.6780 Acc: 0.5818 | Val Loss: 0.6777 Acc: 0.5851\n",
      "Epoch 002 | Train Loss: 0.6808 Acc: 0.5812 | Val Loss: 0.6794 Acc: 0.5900\n",
      "Epoch 003 | Train Loss: 0.6752 Acc: 0.5881 | Val Loss: 0.6753 Acc: 0.5833\n",
      "Epoch 004 | Train Loss: 0.6639 Acc: 0.6018 | Val Loss: 0.6411 Acc: 0.6329\n",
      "Epoch 005 | Train Loss: 0.6209 Acc: 0.6749 | Val Loss: 0.5847 Acc: 0.6944\n",
      "Epoch 006 | Train Loss: 0.5799 Acc: 0.7041 | Val Loss: 0.6030 Acc: 0.6860\n",
      "Epoch 007 | Train Loss: 0.5511 Acc: 0.7284 | Val Loss: 0.5449 Acc: 0.7301\n",
      "Epoch 008 | Train Loss: 0.5203 Acc: 0.7435 | Val Loss: 0.5148 Acc: 0.7476\n",
      "Epoch 009 | Train Loss: 0.4970 Acc: 0.7649 | Val Loss: 0.4900 Acc: 0.7633\n",
      "Epoch 010 | Train Loss: 0.4712 Acc: 0.7793 | Val Loss: 0.4644 Acc: 0.7844\n",
      "Epoch 011 | Train Loss: 0.4484 Acc: 0.7956 | Val Loss: 0.4717 Acc: 0.7796\n",
      "Epoch 012 | Train Loss: 0.4344 Acc: 0.8024 | Val Loss: 0.4268 Acc: 0.8025\n",
      "Epoch 013 | Train Loss: 0.3948 Acc: 0.8270 | Val Loss: 0.4287 Acc: 0.7941\n",
      "Epoch 014 | Train Loss: 0.4011 Acc: 0.8235 | Val Loss: 0.3961 Acc: 0.8110\n",
      "Epoch 015 | Train Loss: 0.3579 Acc: 0.8439 | Val Loss: 0.3756 Acc: 0.8237\n",
      "Epoch 016 | Train Loss: 0.3352 Acc: 0.8594 | Val Loss: 0.3381 Acc: 0.8418\n",
      "Epoch 017 | Train Loss: 0.3150 Acc: 0.8643 | Val Loss: 0.3400 Acc: 0.8533\n",
      "Epoch 018 | Train Loss: 0.2999 Acc: 0.8759 | Val Loss: 0.2984 Acc: 0.8708\n",
      "Epoch 019 | Train Loss: 0.2667 Acc: 0.8916 | Val Loss: 0.2761 Acc: 0.8835\n",
      "Epoch 020 | Train Loss: 0.2586 Acc: 0.8929 | Val Loss: 0.2730 Acc: 0.8865\n",
      "Epoch 021 | Train Loss: 0.2620 Acc: 0.8920 | Val Loss: 0.2800 Acc: 0.8847\n",
      "Epoch 022 | Train Loss: 0.2451 Acc: 0.9014 | Val Loss: 0.2485 Acc: 0.8992\n",
      "Epoch 023 | Train Loss: 0.2211 Acc: 0.9114 | Val Loss: 0.2514 Acc: 0.8943\n",
      "Epoch 024 | Train Loss: 0.2180 Acc: 0.9130 | Val Loss: 0.2303 Acc: 0.9052\n",
      "Epoch 025 | Train Loss: 0.2028 Acc: 0.9207 | Val Loss: 0.2400 Acc: 0.9064\n",
      "Epoch 026 | Train Loss: 0.2001 Acc: 0.9209 | Val Loss: 0.2148 Acc: 0.9130\n",
      "Epoch 027 | Train Loss: 0.1844 Acc: 0.9284 | Val Loss: 0.2006 Acc: 0.9203\n",
      "Epoch 028 | Train Loss: 0.1788 Acc: 0.9313 | Val Loss: 0.2215 Acc: 0.9124\n",
      "Epoch 029 | Train Loss: 0.1682 Acc: 0.9361 | Val Loss: 0.2026 Acc: 0.9191\n",
      "Epoch 030 | Train Loss: 0.1688 Acc: 0.9328 | Val Loss: 0.2630 Acc: 0.9022\n",
      "Epoch 031 | Train Loss: 0.1669 Acc: 0.9339 | Val Loss: 0.2022 Acc: 0.9191\n",
      "Epoch 032 | Train Loss: 0.1528 Acc: 0.9420 | Val Loss: 0.2484 Acc: 0.9028\n",
      "Epoch 033 | Train Loss: 0.1490 Acc: 0.9429 | Val Loss: 0.2115 Acc: 0.9161\n",
      "Epoch 034 | Train Loss: 0.1458 Acc: 0.9446 | Val Loss: 0.1928 Acc: 0.9233\n",
      "Epoch 035 | Train Loss: 0.1409 Acc: 0.9475 | Val Loss: 0.2066 Acc: 0.9209\n",
      "Epoch 036 | Train Loss: 0.1262 Acc: 0.9521 | Val Loss: 0.1842 Acc: 0.9263\n",
      "Epoch 037 | Train Loss: 0.1212 Acc: 0.9547 | Val Loss: 0.2208 Acc: 0.9143\n",
      "Epoch 038 | Train Loss: 0.1188 Acc: 0.9552 | Val Loss: 0.1768 Acc: 0.9372\n",
      "Epoch 039 | Train Loss: 0.1171 Acc: 0.9552 | Val Loss: 0.2135 Acc: 0.9257\n",
      "Epoch 040 | Train Loss: 0.1232 Acc: 0.9530 | Val Loss: 0.1808 Acc: 0.9336\n",
      "Epoch 041 | Train Loss: 0.1137 Acc: 0.9601 | Val Loss: 0.1715 Acc: 0.9342\n",
      "Epoch 042 | Train Loss: 0.1134 Acc: 0.9592 | Val Loss: 0.1835 Acc: 0.9354\n",
      "Epoch 043 | Train Loss: 0.1003 Acc: 0.9632 | Val Loss: 0.1970 Acc: 0.9342\n",
      "Epoch 044 | Train Loss: 0.1016 Acc: 0.9630 | Val Loss: 0.2030 Acc: 0.9251\n",
      "Epoch 045 | Train Loss: 0.1028 Acc: 0.9600 | Val Loss: 0.1792 Acc: 0.9342\n",
      "Epoch 046 | Train Loss: 0.0989 Acc: 0.9639 | Val Loss: 0.1855 Acc: 0.9312\n",
      "Epoch 047 | Train Loss: 0.1003 Acc: 0.9613 | Val Loss: 0.1665 Acc: 0.9396\n",
      "Epoch 048 | Train Loss: 0.0968 Acc: 0.9645 | Val Loss: 0.2220 Acc: 0.9221\n",
      "Epoch 049 | Train Loss: 0.1003 Acc: 0.9607 | Val Loss: 0.1689 Acc: 0.9402\n",
      "Epoch 050 | Train Loss: 0.0895 Acc: 0.9666 | Val Loss: 0.1787 Acc: 0.9366\n",
      "Epoch 051 | Train Loss: 0.0881 Acc: 0.9678 | Val Loss: 0.1580 Acc: 0.9426\n",
      "Epoch 052 | Train Loss: 0.0843 Acc: 0.9695 | Val Loss: 0.1652 Acc: 0.9432\n",
      "Epoch 053 | Train Loss: 0.0860 Acc: 0.9674 | Val Loss: 0.1664 Acc: 0.9396\n",
      "Epoch 054 | Train Loss: 0.0898 Acc: 0.9675 | Val Loss: 0.1766 Acc: 0.9312\n",
      "Epoch 055 | Train Loss: 0.0732 Acc: 0.9716 | Val Loss: 0.1680 Acc: 0.9396\n",
      "Epoch 056 | Train Loss: 0.0792 Acc: 0.9725 | Val Loss: 0.1896 Acc: 0.9426\n",
      "Epoch 057 | Train Loss: 0.0797 Acc: 0.9692 | Val Loss: 0.1707 Acc: 0.9426\n",
      "Epoch 058 | Train Loss: 0.0783 Acc: 0.9715 | Val Loss: 0.1703 Acc: 0.9402\n",
      "Epoch 059 | Train Loss: 0.0833 Acc: 0.9701 | Val Loss: 0.1661 Acc: 0.9402\n",
      "Epoch 060 | Train Loss: 0.0764 Acc: 0.9724 | Val Loss: 0.2257 Acc: 0.9263\n",
      "Epoch 001 | Train Loss: 0.6829 Acc: 0.5707 | Val Loss: 0.6768 Acc: 0.5821\n",
      "Epoch 002 | Train Loss: 0.6731 Acc: 0.5940 | Val Loss: 0.6684 Acc: 0.5996\n",
      "Epoch 003 | Train Loss: 0.6586 Acc: 0.6147 | Val Loss: 0.6565 Acc: 0.6014\n",
      "Epoch 004 | Train Loss: 0.6597 Acc: 0.6168 | Val Loss: 0.6595 Acc: 0.6081\n",
      "Epoch 005 | Train Loss: 0.6343 Acc: 0.6523 | Val Loss: 0.6332 Acc: 0.6564\n",
      "Epoch 006 | Train Loss: 0.5882 Acc: 0.7035 | Val Loss: 0.5762 Acc: 0.7065\n",
      "Epoch 007 | Train Loss: 0.5554 Acc: 0.7257 | Val Loss: 0.5746 Acc: 0.7144\n",
      "Epoch 008 | Train Loss: 0.5463 Acc: 0.7368 | Val Loss: 0.5457 Acc: 0.7277\n",
      "Epoch 009 | Train Loss: 0.5247 Acc: 0.7463 | Val Loss: 0.5462 Acc: 0.7283\n",
      "Epoch 010 | Train Loss: 0.5140 Acc: 0.7492 | Val Loss: 0.5323 Acc: 0.7403\n",
      "Epoch 011 | Train Loss: 0.4929 Acc: 0.7631 | Val Loss: 0.5081 Acc: 0.7518\n",
      "Epoch 012 | Train Loss: 0.4760 Acc: 0.7761 | Val Loss: 0.4928 Acc: 0.7585\n",
      "Epoch 013 | Train Loss: 0.4631 Acc: 0.7836 | Val Loss: 0.5104 Acc: 0.7385\n",
      "Epoch 014 | Train Loss: 0.4453 Acc: 0.7925 | Val Loss: 0.4506 Acc: 0.7814\n",
      "Epoch 015 | Train Loss: 0.4204 Acc: 0.8125 | Val Loss: 0.4342 Acc: 0.7856\n",
      "Epoch 016 | Train Loss: 0.3940 Acc: 0.8197 | Val Loss: 0.4388 Acc: 0.7886\n",
      "Epoch 017 | Train Loss: 0.3809 Acc: 0.8310 | Val Loss: 0.4157 Acc: 0.8043\n",
      "Epoch 018 | Train Loss: 0.3669 Acc: 0.8395 | Val Loss: 0.3863 Acc: 0.8170\n",
      "Epoch 019 | Train Loss: 0.3332 Acc: 0.8570 | Val Loss: 0.4140 Acc: 0.8116\n",
      "Epoch 020 | Train Loss: 0.3162 Acc: 0.8686 | Val Loss: 0.3562 Acc: 0.8388\n",
      "Epoch 021 | Train Loss: 0.2986 Acc: 0.8727 | Val Loss: 0.3621 Acc: 0.8351\n",
      "Epoch 022 | Train Loss: 0.2828 Acc: 0.8852 | Val Loss: 0.3130 Acc: 0.8690\n",
      "Epoch 023 | Train Loss: 0.2629 Acc: 0.8923 | Val Loss: 0.3250 Acc: 0.8678\n",
      "Epoch 024 | Train Loss: 0.2501 Acc: 0.8985 | Val Loss: 0.3355 Acc: 0.8629\n",
      "Epoch 025 | Train Loss: 0.2305 Acc: 0.9070 | Val Loss: 0.3362 Acc: 0.8629\n",
      "Epoch 026 | Train Loss: 0.2202 Acc: 0.9144 | Val Loss: 0.2731 Acc: 0.8937\n",
      "Epoch 027 | Train Loss: 0.2086 Acc: 0.9171 | Val Loss: 0.3107 Acc: 0.8816\n",
      "Epoch 028 | Train Loss: 0.1968 Acc: 0.9250 | Val Loss: 0.2403 Acc: 0.9094\n",
      "Epoch 029 | Train Loss: 0.1812 Acc: 0.9281 | Val Loss: 0.2891 Acc: 0.8967\n",
      "Epoch 030 | Train Loss: 0.1829 Acc: 0.9296 | Val Loss: 0.2368 Acc: 0.9088\n",
      "Epoch 031 | Train Loss: 0.1581 Acc: 0.9385 | Val Loss: 0.2535 Acc: 0.9028\n",
      "Epoch 032 | Train Loss: 0.1531 Acc: 0.9446 | Val Loss: 0.2415 Acc: 0.9010\n",
      "Epoch 033 | Train Loss: 0.1465 Acc: 0.9423 | Val Loss: 0.2546 Acc: 0.9106\n",
      "Epoch 034 | Train Loss: 0.1469 Acc: 0.9429 | Val Loss: 0.2662 Acc: 0.8986\n",
      "Epoch 035 | Train Loss: 0.1446 Acc: 0.9437 | Val Loss: 0.2253 Acc: 0.9155\n",
      "Epoch 036 | Train Loss: 0.1286 Acc: 0.9529 | Val Loss: 0.2885 Acc: 0.8961\n",
      "Epoch 037 | Train Loss: 0.1230 Acc: 0.9553 | Val Loss: 0.2254 Acc: 0.9251\n",
      "Epoch 038 | Train Loss: 0.1088 Acc: 0.9595 | Val Loss: 0.2910 Acc: 0.8822\n",
      "Epoch 039 | Train Loss: 0.1181 Acc: 0.9558 | Val Loss: 0.2206 Acc: 0.9227\n",
      "Epoch 040 | Train Loss: 0.1016 Acc: 0.9624 | Val Loss: 0.2350 Acc: 0.9233\n",
      "Epoch 041 | Train Loss: 0.1154 Acc: 0.9580 | Val Loss: 0.2304 Acc: 0.9239\n",
      "Epoch 042 | Train Loss: 0.0906 Acc: 0.9653 | Val Loss: 0.2539 Acc: 0.9185\n",
      "Epoch 043 | Train Loss: 0.0968 Acc: 0.9657 | Val Loss: 0.2215 Acc: 0.9221\n",
      "Epoch 044 | Train Loss: 0.0904 Acc: 0.9666 | Val Loss: 0.2241 Acc: 0.9179\n",
      "Epoch 045 | Train Loss: 0.0958 Acc: 0.9633 | Val Loss: 0.2210 Acc: 0.9239\n",
      "Epoch 046 | Train Loss: 0.0883 Acc: 0.9662 | Val Loss: 0.2107 Acc: 0.9287\n",
      "Epoch 047 | Train Loss: 0.0870 Acc: 0.9697 | Val Loss: 0.2353 Acc: 0.9233\n",
      "Epoch 048 | Train Loss: 0.0962 Acc: 0.9645 | Val Loss: 0.2342 Acc: 0.9203\n",
      "Epoch 049 | Train Loss: 0.0713 Acc: 0.9748 | Val Loss: 0.2345 Acc: 0.9300\n",
      "Epoch 050 | Train Loss: 0.0721 Acc: 0.9763 | Val Loss: 0.2407 Acc: 0.9191\n",
      "Epoch 051 | Train Loss: 0.0867 Acc: 0.9681 | Val Loss: 0.2629 Acc: 0.9130\n",
      "Epoch 052 | Train Loss: 0.0733 Acc: 0.9737 | Val Loss: 0.2416 Acc: 0.9173\n",
      "Epoch 053 | Train Loss: 0.0756 Acc: 0.9724 | Val Loss: 0.2639 Acc: 0.9064\n",
      "Epoch 054 | Train Loss: 0.0779 Acc: 0.9712 | Val Loss: 0.2558 Acc: 0.9179\n",
      "Epoch 055 | Train Loss: 0.0647 Acc: 0.9770 | Val Loss: 0.2380 Acc: 0.9293\n",
      "Epoch 056 | Train Loss: 0.0619 Acc: 0.9775 | Val Loss: 0.2830 Acc: 0.9161\n",
      "Early stopping triggered.\n",
      "Epoch 001 | Train Loss: 0.6817 Acc: 0.5765 | Val Loss: 0.6740 Acc: 0.5912\n",
      "Epoch 002 | Train Loss: 0.6397 Acc: 0.6422 | Val Loss: 0.5983 Acc: 0.6914\n",
      "Epoch 003 | Train Loss: 0.5788 Acc: 0.7167 | Val Loss: 0.5868 Acc: 0.6854\n",
      "Epoch 004 | Train Loss: 0.5411 Acc: 0.7382 | Val Loss: 0.5400 Acc: 0.7331\n",
      "Epoch 005 | Train Loss: 0.5055 Acc: 0.7551 | Val Loss: 0.5105 Acc: 0.7572\n",
      "Epoch 006 | Train Loss: 0.4730 Acc: 0.7776 | Val Loss: 0.4734 Acc: 0.7693\n",
      "Epoch 007 | Train Loss: 0.4360 Acc: 0.7969 | Val Loss: 0.4800 Acc: 0.7766\n",
      "Epoch 008 | Train Loss: 0.4131 Acc: 0.8184 | Val Loss: 0.4226 Acc: 0.8104\n",
      "Epoch 009 | Train Loss: 0.3799 Acc: 0.8356 | Val Loss: 0.3648 Acc: 0.8418\n",
      "Epoch 010 | Train Loss: 0.3368 Acc: 0.8569 | Val Loss: 0.4140 Acc: 0.8134\n",
      "Epoch 011 | Train Loss: 0.3089 Acc: 0.8744 | Val Loss: 0.3197 Acc: 0.8659\n",
      "Epoch 012 | Train Loss: 0.2829 Acc: 0.8862 | Val Loss: 0.2922 Acc: 0.8798\n",
      "Epoch 013 | Train Loss: 0.2592 Acc: 0.8942 | Val Loss: 0.2902 Acc: 0.8895\n",
      "Epoch 014 | Train Loss: 0.2461 Acc: 0.8999 | Val Loss: 0.2925 Acc: 0.8774\n",
      "Epoch 015 | Train Loss: 0.2214 Acc: 0.9136 | Val Loss: 0.2680 Acc: 0.8829\n",
      "Epoch 016 | Train Loss: 0.1892 Acc: 0.9231 | Val Loss: 0.2631 Acc: 0.8967\n",
      "Epoch 017 | Train Loss: 0.1923 Acc: 0.9245 | Val Loss: 0.2924 Acc: 0.8738\n",
      "Epoch 018 | Train Loss: 0.1899 Acc: 0.9253 | Val Loss: 0.2610 Acc: 0.8949\n",
      "Epoch 019 | Train Loss: 0.1614 Acc: 0.9405 | Val Loss: 0.2533 Acc: 0.8973\n",
      "Epoch 020 | Train Loss: 0.1541 Acc: 0.9398 | Val Loss: 0.2609 Acc: 0.9064\n",
      "Epoch 021 | Train Loss: 0.1488 Acc: 0.9405 | Val Loss: 0.2634 Acc: 0.8986\n",
      "Epoch 022 | Train Loss: 0.1345 Acc: 0.9476 | Val Loss: 0.2567 Acc: 0.9028\n",
      "Epoch 023 | Train Loss: 0.1220 Acc: 0.9564 | Val Loss: 0.2377 Acc: 0.9064\n",
      "Epoch 024 | Train Loss: 0.1295 Acc: 0.9508 | Val Loss: 0.2525 Acc: 0.9161\n",
      "Epoch 025 | Train Loss: 0.1147 Acc: 0.9552 | Val Loss: 0.2239 Acc: 0.9149\n",
      "Epoch 026 | Train Loss: 0.1017 Acc: 0.9612 | Val Loss: 0.2543 Acc: 0.9076\n",
      "Epoch 027 | Train Loss: 0.1015 Acc: 0.9600 | Val Loss: 0.2734 Acc: 0.9191\n",
      "Epoch 028 | Train Loss: 0.1086 Acc: 0.9598 | Val Loss: 0.2386 Acc: 0.9034\n",
      "Epoch 029 | Train Loss: 0.0962 Acc: 0.9675 | Val Loss: 0.2772 Acc: 0.9076\n",
      "Epoch 030 | Train Loss: 0.0864 Acc: 0.9641 | Val Loss: 0.2298 Acc: 0.9209\n",
      "Epoch 031 | Train Loss: 0.0890 Acc: 0.9678 | Val Loss: 0.2390 Acc: 0.9070\n",
      "Epoch 032 | Train Loss: 0.0811 Acc: 0.9703 | Val Loss: 0.2247 Acc: 0.9221\n",
      "Epoch 033 | Train Loss: 0.0932 Acc: 0.9639 | Val Loss: 0.2523 Acc: 0.9136\n",
      "Epoch 034 | Train Loss: 0.0779 Acc: 0.9719 | Val Loss: 0.2524 Acc: 0.9179\n",
      "Epoch 035 | Train Loss: 0.0754 Acc: 0.9715 | Val Loss: 0.3395 Acc: 0.9034\n",
      "Early stopping triggered.\n",
      "Epoch 001 | Train Loss: 0.6821 Acc: 0.5754 | Val Loss: 0.6708 Acc: 0.5912\n",
      "Epoch 002 | Train Loss: 0.6823 Acc: 0.5766 | Val Loss: 0.6778 Acc: 0.5930\n",
      "Epoch 003 | Train Loss: 0.6710 Acc: 0.5960 | Val Loss: 0.6852 Acc: 0.5586\n",
      "Epoch 004 | Train Loss: 0.6839 Acc: 0.5730 | Val Loss: 0.6771 Acc: 0.5839\n",
      "Epoch 005 | Train Loss: 0.6814 Acc: 0.5819 | Val Loss: 0.6865 Acc: 0.5586\n",
      "Epoch 006 | Train Loss: 0.6845 Acc: 0.5664 | Val Loss: 0.6785 Acc: 0.5851\n",
      "Epoch 007 | Train Loss: 0.6817 Acc: 0.5735 | Val Loss: 0.6868 Acc: 0.5586\n",
      "Epoch 008 | Train Loss: 0.6847 Acc: 0.5641 | Val Loss: 0.6774 Acc: 0.5894\n",
      "Epoch 009 | Train Loss: 0.6852 Acc: 0.5638 | Val Loss: 0.6856 Acc: 0.5586\n",
      "Epoch 010 | Train Loss: 0.6817 Acc: 0.5745 | Val Loss: 0.6753 Acc: 0.5833\n",
      "Epoch 011 | Train Loss: 0.6780 Acc: 0.5878 | Val Loss: 0.6704 Acc: 0.6008\n",
      "Epoch 012 | Train Loss: 0.6654 Acc: 0.6044 | Val Loss: 0.6688 Acc: 0.5930\n",
      "Epoch 013 | Train Loss: 0.6644 Acc: 0.6073 | Val Loss: 0.6633 Acc: 0.5996\n",
      "Epoch 014 | Train Loss: 0.6648 Acc: 0.6059 | Val Loss: 0.6677 Acc: 0.6027\n",
      "Epoch 015 | Train Loss: 0.6601 Acc: 0.6126 | Val Loss: 0.6610 Acc: 0.6093\n",
      "Epoch 016 | Train Loss: 0.6577 Acc: 0.6177 | Val Loss: 0.6602 Acc: 0.6111\n",
      "Epoch 017 | Train Loss: 0.6545 Acc: 0.6262 | Val Loss: 0.6399 Acc: 0.6473\n",
      "Epoch 018 | Train Loss: 0.6461 Acc: 0.6346 | Val Loss: 0.6637 Acc: 0.6111\n",
      "Epoch 019 | Train Loss: 0.6236 Acc: 0.6684 | Val Loss: 0.6101 Acc: 0.6739\n",
      "Epoch 020 | Train Loss: 0.5807 Acc: 0.7112 | Val Loss: 0.5853 Acc: 0.6981\n",
      "Epoch 021 | Train Loss: 0.5569 Acc: 0.7303 | Val Loss: 0.5329 Acc: 0.7343\n",
      "Epoch 022 | Train Loss: 0.5257 Acc: 0.7522 | Val Loss: 0.5130 Acc: 0.7566\n",
      "Epoch 023 | Train Loss: 0.5003 Acc: 0.7670 | Val Loss: 0.4911 Acc: 0.7657\n",
      "Epoch 024 | Train Loss: 0.4807 Acc: 0.7768 | Val Loss: 0.4900 Acc: 0.7699\n",
      "Epoch 025 | Train Loss: 0.4724 Acc: 0.7865 | Val Loss: 0.4658 Acc: 0.7844\n",
      "Epoch 026 | Train Loss: 0.4628 Acc: 0.7906 | Val Loss: 0.4501 Acc: 0.7838\n",
      "Epoch 027 | Train Loss: 0.4359 Acc: 0.8070 | Val Loss: 0.4372 Acc: 0.7880\n",
      "Epoch 028 | Train Loss: 0.4178 Acc: 0.8131 | Val Loss: 0.4179 Acc: 0.7977\n",
      "Epoch 029 | Train Loss: 0.4007 Acc: 0.8208 | Val Loss: 0.3984 Acc: 0.8200\n",
      "Epoch 030 | Train Loss: 0.3919 Acc: 0.8276 | Val Loss: 0.3766 Acc: 0.8285\n",
      "Epoch 031 | Train Loss: 0.3673 Acc: 0.8377 | Val Loss: 0.3581 Acc: 0.8297\n",
      "Epoch 032 | Train Loss: 0.3525 Acc: 0.8466 | Val Loss: 0.3650 Acc: 0.8370\n",
      "Epoch 033 | Train Loss: 0.3454 Acc: 0.8493 | Val Loss: 0.3243 Acc: 0.8527\n",
      "Epoch 034 | Train Loss: 0.3270 Acc: 0.8596 | Val Loss: 0.3583 Acc: 0.8339\n",
      "Epoch 035 | Train Loss: 0.3128 Acc: 0.8688 | Val Loss: 0.2908 Acc: 0.8708\n",
      "Epoch 036 | Train Loss: 0.3030 Acc: 0.8709 | Val Loss: 0.2914 Acc: 0.8816\n",
      "Epoch 037 | Train Loss: 0.3064 Acc: 0.8738 | Val Loss: 0.3503 Acc: 0.8466\n",
      "Epoch 038 | Train Loss: 0.2792 Acc: 0.8827 | Val Loss: 0.2972 Acc: 0.8756\n",
      "Epoch 039 | Train Loss: 0.2702 Acc: 0.8908 | Val Loss: 0.3153 Acc: 0.8678\n",
      "Epoch 040 | Train Loss: 0.2722 Acc: 0.8890 | Val Loss: 0.2617 Acc: 0.8889\n",
      "Epoch 041 | Train Loss: 0.2534 Acc: 0.8985 | Val Loss: 0.2575 Acc: 0.8986\n",
      "Epoch 042 | Train Loss: 0.2559 Acc: 0.8922 | Val Loss: 0.2720 Acc: 0.8816\n",
      "Epoch 043 | Train Loss: 0.2501 Acc: 0.9008 | Val Loss: 0.2800 Acc: 0.8913\n",
      "Epoch 044 | Train Loss: 0.2416 Acc: 0.8979 | Val Loss: 0.2486 Acc: 0.9070\n",
      "Epoch 045 | Train Loss: 0.2394 Acc: 0.9064 | Val Loss: 0.2491 Acc: 0.8986\n",
      "Epoch 046 | Train Loss: 0.2338 Acc: 0.9050 | Val Loss: 0.2734 Acc: 0.8883\n",
      "Epoch 047 | Train Loss: 0.2173 Acc: 0.9151 | Val Loss: 0.2396 Acc: 0.9088\n",
      "Epoch 048 | Train Loss: 0.2230 Acc: 0.9141 | Val Loss: 0.2287 Acc: 0.9088\n",
      "Epoch 049 | Train Loss: 0.2159 Acc: 0.9100 | Val Loss: 0.2214 Acc: 0.9112\n",
      "Epoch 050 | Train Loss: 0.2114 Acc: 0.9144 | Val Loss: 0.2367 Acc: 0.9046\n",
      "Epoch 051 | Train Loss: 0.2135 Acc: 0.9194 | Val Loss: 0.2190 Acc: 0.9082\n",
      "Epoch 052 | Train Loss: 0.1892 Acc: 0.9242 | Val Loss: 0.2196 Acc: 0.9130\n",
      "Epoch 053 | Train Loss: 0.2022 Acc: 0.9204 | Val Loss: 0.2305 Acc: 0.9022\n",
      "Epoch 054 | Train Loss: 0.2029 Acc: 0.9234 | Val Loss: 0.1957 Acc: 0.9281\n",
      "Epoch 055 | Train Loss: 0.1961 Acc: 0.9230 | Val Loss: 0.2189 Acc: 0.9112\n",
      "Epoch 056 | Train Loss: 0.1811 Acc: 0.9307 | Val Loss: 0.2102 Acc: 0.9112\n",
      "Epoch 057 | Train Loss: 0.1768 Acc: 0.9284 | Val Loss: 0.2213 Acc: 0.9143\n",
      "Epoch 058 | Train Loss: 0.1900 Acc: 0.9274 | Val Loss: 0.2098 Acc: 0.9173\n",
      "Epoch 059 | Train Loss: 0.1792 Acc: 0.9280 | Val Loss: 0.2939 Acc: 0.8780\n",
      "Epoch 060 | Train Loss: 0.1733 Acc: 0.9331 | Val Loss: 0.2162 Acc: 0.9136\n",
      "Epoch 001 | Train Loss: 0.6862 Acc: 0.5686 | Val Loss: 0.6845 Acc: 0.5646\n",
      "Epoch 002 | Train Loss: 0.6860 Acc: 0.5641 | Val Loss: 0.6857 Acc: 0.5610\n",
      "Epoch 003 | Train Loss: 0.6815 Acc: 0.5775 | Val Loss: 0.6783 Acc: 0.5851\n",
      "Epoch 004 | Train Loss: 0.6798 Acc: 0.5796 | Val Loss: 0.6860 Acc: 0.5586\n",
      "Epoch 005 | Train Loss: 0.6857 Acc: 0.5609 | Val Loss: 0.6838 Acc: 0.5586\n",
      "Epoch 006 | Train Loss: 0.6863 Acc: 0.5581 | Val Loss: 0.6860 Acc: 0.5586\n",
      "Epoch 007 | Train Loss: 0.6841 Acc: 0.5670 | Val Loss: 0.6893 Acc: 0.5785\n",
      "Epoch 008 | Train Loss: 0.6835 Acc: 0.5694 | Val Loss: 0.6816 Acc: 0.5694\n",
      "Epoch 009 | Train Loss: 0.6822 Acc: 0.5709 | Val Loss: 0.6858 Acc: 0.5676\n",
      "Epoch 010 | Train Loss: 0.6807 Acc: 0.5772 | Val Loss: 0.6818 Acc: 0.5707\n",
      "Epoch 011 | Train Loss: 0.6768 Acc: 0.5937 | Val Loss: 0.6696 Acc: 0.5960\n",
      "Epoch 012 | Train Loss: 0.6836 Acc: 0.5652 | Val Loss: 0.6863 Acc: 0.5586\n",
      "Epoch 013 | Train Loss: 0.6808 Acc: 0.5777 | Val Loss: 0.6708 Acc: 0.5990\n",
      "Epoch 014 | Train Loss: 0.6738 Acc: 0.5934 | Val Loss: 0.6809 Acc: 0.5731\n",
      "Epoch 015 | Train Loss: 0.6736 Acc: 0.5990 | Val Loss: 0.6712 Acc: 0.6008\n",
      "Epoch 016 | Train Loss: 0.6707 Acc: 0.5972 | Val Loss: 0.6682 Acc: 0.6033\n",
      "Epoch 017 | Train Loss: 0.6694 Acc: 0.6059 | Val Loss: 0.6814 Acc: 0.6021\n",
      "Epoch 018 | Train Loss: 0.6728 Acc: 0.6065 | Val Loss: 0.6762 Acc: 0.6014\n",
      "Epoch 019 | Train Loss: 0.6682 Acc: 0.6049 | Val Loss: 0.6666 Acc: 0.6033\n",
      "Epoch 020 | Train Loss: 0.6642 Acc: 0.6132 | Val Loss: 0.6637 Acc: 0.6075\n",
      "Epoch 021 | Train Loss: 0.6686 Acc: 0.6064 | Val Loss: 0.6643 Acc: 0.6039\n",
      "Epoch 022 | Train Loss: 0.6713 Acc: 0.5952 | Val Loss: 0.6813 Acc: 0.5731\n",
      "Epoch 023 | Train Loss: 0.6683 Acc: 0.6011 | Val Loss: 0.6590 Acc: 0.6123\n",
      "Epoch 024 | Train Loss: 0.6742 Acc: 0.5923 | Val Loss: 0.7754 Acc: 0.6045\n",
      "Epoch 025 | Train Loss: 0.6687 Acc: 0.6062 | Val Loss: 0.6837 Acc: 0.5930\n",
      "Epoch 026 | Train Loss: 0.6680 Acc: 0.6055 | Val Loss: 0.6607 Acc: 0.6099\n",
      "Epoch 027 | Train Loss: 0.6644 Acc: 0.6124 | Val Loss: 0.6575 Acc: 0.6159\n",
      "Epoch 028 | Train Loss: 0.6855 Acc: 0.5639 | Val Loss: 0.6863 Acc: 0.5586\n",
      "Epoch 029 | Train Loss: 0.6867 Acc: 0.5576 | Val Loss: 0.6863 Acc: 0.5586\n",
      "Epoch 030 | Train Loss: 0.6867 Acc: 0.5582 | Val Loss: 0.6867 Acc: 0.5586\n",
      "Epoch 031 | Train Loss: 0.6866 Acc: 0.5576 | Val Loss: 0.6855 Acc: 0.5586\n",
      "Epoch 032 | Train Loss: 0.6752 Acc: 0.5925 | Val Loss: 0.6682 Acc: 0.6027\n",
      "Epoch 033 | Train Loss: 0.6668 Acc: 0.6083 | Val Loss: 0.6665 Acc: 0.6117\n",
      "Epoch 034 | Train Loss: 0.6630 Acc: 0.6195 | Val Loss: 0.6620 Acc: 0.6099\n",
      "Epoch 035 | Train Loss: 0.6633 Acc: 0.6171 | Val Loss: 0.6705 Acc: 0.5990\n",
      "Epoch 036 | Train Loss: 0.6676 Acc: 0.6008 | Val Loss: 0.6641 Acc: 0.6081\n",
      "Epoch 037 | Train Loss: 0.6610 Acc: 0.6180 | Val Loss: 0.6584 Acc: 0.6190\n",
      "Early stopping triggered.\n",
      "Iteration 4/40 | Best Val Loss: 0.1394 | Iter Time: 218.06s | Total Time: 23.06 min\n",
      "Epoch 001 | Train Loss: 0.6847 Acc: 0.5668 | Val Loss: 0.6802 Acc: 0.5797\n",
      "Epoch 002 | Train Loss: 0.6780 Acc: 0.5839 | Val Loss: 0.6734 Acc: 0.5876\n",
      "Epoch 003 | Train Loss: 0.6407 Acc: 0.6370 | Val Loss: 0.6189 Acc: 0.6673\n",
      "Epoch 004 | Train Loss: 0.5871 Acc: 0.7006 | Val Loss: 0.5829 Acc: 0.7011\n",
      "Epoch 005 | Train Loss: 0.5631 Acc: 0.7183 | Val Loss: 0.5739 Acc: 0.7107\n",
      "Epoch 006 | Train Loss: 0.5325 Acc: 0.7395 | Val Loss: 0.5300 Acc: 0.7397\n",
      "Epoch 007 | Train Loss: 0.5067 Acc: 0.7608 | Val Loss: 0.5022 Acc: 0.7627\n",
      "Epoch 008 | Train Loss: 0.4840 Acc: 0.7728 | Val Loss: 0.5050 Acc: 0.7621\n",
      "Epoch 009 | Train Loss: 0.4617 Acc: 0.7868 | Val Loss: 0.4530 Acc: 0.7850\n",
      "Epoch 010 | Train Loss: 0.4478 Acc: 0.7937 | Val Loss: 0.4319 Acc: 0.7935\n",
      "Epoch 011 | Train Loss: 0.4224 Acc: 0.8064 | Val Loss: 0.4095 Acc: 0.8062\n",
      "Epoch 012 | Train Loss: 0.3926 Acc: 0.8253 | Val Loss: 0.3937 Acc: 0.8098\n",
      "Epoch 013 | Train Loss: 0.3800 Acc: 0.8304 | Val Loss: 0.3855 Acc: 0.8080\n",
      "Epoch 014 | Train Loss: 0.3702 Acc: 0.8363 | Val Loss: 0.3369 Acc: 0.8508\n",
      "Epoch 015 | Train Loss: 0.3289 Acc: 0.8544 | Val Loss: 0.3185 Acc: 0.8563\n",
      "Epoch 016 | Train Loss: 0.3130 Acc: 0.8671 | Val Loss: 0.2885 Acc: 0.8732\n",
      "Epoch 017 | Train Loss: 0.2975 Acc: 0.8782 | Val Loss: 0.3086 Acc: 0.8635\n",
      "Epoch 018 | Train Loss: 0.2991 Acc: 0.8797 | Val Loss: 0.3005 Acc: 0.8877\n",
      "Epoch 019 | Train Loss: 0.2776 Acc: 0.8895 | Val Loss: 0.2779 Acc: 0.8768\n",
      "Epoch 020 | Train Loss: 0.2603 Acc: 0.8933 | Val Loss: 0.2769 Acc: 0.8798\n",
      "Epoch 021 | Train Loss: 0.2459 Acc: 0.8994 | Val Loss: 0.2490 Acc: 0.8949\n",
      "Epoch 022 | Train Loss: 0.2422 Acc: 0.9047 | Val Loss: 0.2433 Acc: 0.8992\n",
      "Epoch 023 | Train Loss: 0.2216 Acc: 0.9093 | Val Loss: 0.2332 Acc: 0.9106\n",
      "Epoch 024 | Train Loss: 0.2163 Acc: 0.9204 | Val Loss: 0.2372 Acc: 0.8973\n",
      "Epoch 025 | Train Loss: 0.2107 Acc: 0.9167 | Val Loss: 0.1855 Acc: 0.9287\n",
      "Epoch 026 | Train Loss: 0.1948 Acc: 0.9251 | Val Loss: 0.2118 Acc: 0.9155\n",
      "Epoch 027 | Train Loss: 0.1900 Acc: 0.9269 | Val Loss: 0.2334 Acc: 0.9094\n",
      "Epoch 028 | Train Loss: 0.1887 Acc: 0.9247 | Val Loss: 0.1995 Acc: 0.9215\n",
      "Epoch 029 | Train Loss: 0.1748 Acc: 0.9318 | Val Loss: 0.1994 Acc: 0.9179\n",
      "Epoch 030 | Train Loss: 0.1787 Acc: 0.9325 | Val Loss: 0.1917 Acc: 0.9197\n",
      "Epoch 031 | Train Loss: 0.1757 Acc: 0.9325 | Val Loss: 0.1727 Acc: 0.9354\n",
      "Epoch 032 | Train Loss: 0.1710 Acc: 0.9343 | Val Loss: 0.1791 Acc: 0.9324\n",
      "Epoch 033 | Train Loss: 0.1499 Acc: 0.9434 | Val Loss: 0.1945 Acc: 0.9263\n",
      "Epoch 034 | Train Loss: 0.1563 Acc: 0.9416 | Val Loss: 0.1834 Acc: 0.9336\n",
      "Epoch 035 | Train Loss: 0.1634 Acc: 0.9387 | Val Loss: 0.1758 Acc: 0.9336\n",
      "Epoch 036 | Train Loss: 0.1468 Acc: 0.9425 | Val Loss: 0.1745 Acc: 0.9330\n",
      "Epoch 037 | Train Loss: 0.1496 Acc: 0.9447 | Val Loss: 0.2101 Acc: 0.9173\n",
      "Epoch 038 | Train Loss: 0.1422 Acc: 0.9459 | Val Loss: 0.1844 Acc: 0.9275\n",
      "Epoch 039 | Train Loss: 0.1389 Acc: 0.9470 | Val Loss: 0.1683 Acc: 0.9336\n",
      "Epoch 040 | Train Loss: 0.1377 Acc: 0.9506 | Val Loss: 0.1634 Acc: 0.9390\n",
      "Epoch 041 | Train Loss: 0.1320 Acc: 0.9506 | Val Loss: 0.2098 Acc: 0.9257\n",
      "Epoch 042 | Train Loss: 0.1263 Acc: 0.9512 | Val Loss: 0.1782 Acc: 0.9300\n",
      "Epoch 043 | Train Loss: 0.1168 Acc: 0.9568 | Val Loss: 0.1844 Acc: 0.9318\n",
      "Epoch 044 | Train Loss: 0.1345 Acc: 0.9461 | Val Loss: 0.1658 Acc: 0.9438\n",
      "Epoch 045 | Train Loss: 0.1193 Acc: 0.9532 | Val Loss: 0.1858 Acc: 0.9348\n",
      "Epoch 046 | Train Loss: 0.1156 Acc: 0.9577 | Val Loss: 0.1618 Acc: 0.9420\n",
      "Epoch 047 | Train Loss: 0.1054 Acc: 0.9583 | Val Loss: 0.1808 Acc: 0.9293\n",
      "Epoch 048 | Train Loss: 0.1193 Acc: 0.9552 | Val Loss: 0.1444 Acc: 0.9450\n",
      "Epoch 049 | Train Loss: 0.1236 Acc: 0.9515 | Val Loss: 0.2050 Acc: 0.9360\n",
      "Epoch 050 | Train Loss: 0.1218 Acc: 0.9556 | Val Loss: 0.1986 Acc: 0.9209\n",
      "Epoch 051 | Train Loss: 0.1066 Acc: 0.9604 | Val Loss: 0.1638 Acc: 0.9336\n",
      "Epoch 052 | Train Loss: 0.1074 Acc: 0.9556 | Val Loss: 0.1562 Acc: 0.9420\n",
      "Epoch 053 | Train Loss: 0.1149 Acc: 0.9586 | Val Loss: 0.1988 Acc: 0.9209\n",
      "Epoch 054 | Train Loss: 0.1013 Acc: 0.9657 | Val Loss: 0.2231 Acc: 0.9221\n",
      "Epoch 055 | Train Loss: 0.1164 Acc: 0.9579 | Val Loss: 0.2016 Acc: 0.9136\n",
      "Epoch 056 | Train Loss: 0.0937 Acc: 0.9644 | Val Loss: 0.1613 Acc: 0.9517\n",
      "Epoch 057 | Train Loss: 0.0948 Acc: 0.9659 | Val Loss: 0.1471 Acc: 0.9475\n",
      "Epoch 058 | Train Loss: 0.1011 Acc: 0.9613 | Val Loss: 0.2202 Acc: 0.9227\n",
      "Early stopping triggered.\n",
      "Epoch 001 | Train Loss: 0.6782 Acc: 0.5822 | Val Loss: 0.6785 Acc: 0.5694\n",
      "Epoch 002 | Train Loss: 0.6658 Acc: 0.6040 | Val Loss: 0.6503 Acc: 0.6196\n",
      "Epoch 003 | Train Loss: 0.6518 Acc: 0.6337 | Val Loss: 0.6425 Acc: 0.6443\n",
      "Epoch 004 | Train Loss: 0.6006 Acc: 0.6891 | Val Loss: 0.5772 Acc: 0.6975\n",
      "Epoch 005 | Train Loss: 0.5593 Acc: 0.7244 | Val Loss: 0.5365 Acc: 0.7307\n",
      "Epoch 006 | Train Loss: 0.5142 Acc: 0.7557 | Val Loss: 0.5064 Acc: 0.7585\n",
      "Epoch 007 | Train Loss: 0.4926 Acc: 0.7651 | Val Loss: 0.5464 Acc: 0.7216\n",
      "Epoch 008 | Train Loss: 0.4650 Acc: 0.7859 | Val Loss: 0.4615 Acc: 0.7705\n",
      "Epoch 009 | Train Loss: 0.4447 Acc: 0.7963 | Val Loss: 0.4525 Acc: 0.7856\n",
      "Epoch 010 | Train Loss: 0.4286 Acc: 0.8030 | Val Loss: 0.4609 Acc: 0.7796\n",
      "Epoch 011 | Train Loss: 0.4106 Acc: 0.8173 | Val Loss: 0.4053 Acc: 0.8068\n",
      "Epoch 012 | Train Loss: 0.3738 Acc: 0.8327 | Val Loss: 0.3801 Acc: 0.8261\n",
      "Epoch 013 | Train Loss: 0.3589 Acc: 0.8431 | Val Loss: 0.3884 Acc: 0.8291\n",
      "Epoch 014 | Train Loss: 0.3372 Acc: 0.8532 | Val Loss: 0.3302 Acc: 0.8514\n",
      "Epoch 015 | Train Loss: 0.3092 Acc: 0.8656 | Val Loss: 0.3160 Acc: 0.8581\n",
      "Epoch 016 | Train Loss: 0.2789 Acc: 0.8878 | Val Loss: 0.3361 Acc: 0.8557\n",
      "Epoch 017 | Train Loss: 0.2671 Acc: 0.8889 | Val Loss: 0.2563 Acc: 0.8913\n",
      "Epoch 018 | Train Loss: 0.2442 Acc: 0.8991 | Val Loss: 0.2697 Acc: 0.8889\n",
      "Epoch 019 | Train Loss: 0.2195 Acc: 0.9105 | Val Loss: 0.2638 Acc: 0.8973\n",
      "Epoch 020 | Train Loss: 0.1992 Acc: 0.9201 | Val Loss: 0.2705 Acc: 0.8919\n",
      "Epoch 021 | Train Loss: 0.2015 Acc: 0.9183 | Val Loss: 0.2589 Acc: 0.8949\n",
      "Epoch 022 | Train Loss: 0.1836 Acc: 0.9281 | Val Loss: 0.2412 Acc: 0.9130\n",
      "Epoch 023 | Train Loss: 0.1569 Acc: 0.9363 | Val Loss: 0.2295 Acc: 0.9155\n",
      "Epoch 024 | Train Loss: 0.1594 Acc: 0.9370 | Val Loss: 0.2592 Acc: 0.9004\n",
      "Epoch 025 | Train Loss: 0.1548 Acc: 0.9416 | Val Loss: 0.2198 Acc: 0.9221\n",
      "Epoch 026 | Train Loss: 0.1340 Acc: 0.9467 | Val Loss: 0.2202 Acc: 0.9155\n",
      "Epoch 027 | Train Loss: 0.1330 Acc: 0.9505 | Val Loss: 0.2136 Acc: 0.9269\n",
      "Epoch 028 | Train Loss: 0.1210 Acc: 0.9541 | Val Loss: 0.2153 Acc: 0.9233\n",
      "Epoch 029 | Train Loss: 0.1116 Acc: 0.9562 | Val Loss: 0.2237 Acc: 0.9185\n",
      "Epoch 030 | Train Loss: 0.1129 Acc: 0.9568 | Val Loss: 0.2019 Acc: 0.9215\n",
      "Epoch 031 | Train Loss: 0.0938 Acc: 0.9650 | Val Loss: 0.1968 Acc: 0.9324\n",
      "Epoch 032 | Train Loss: 0.0949 Acc: 0.9663 | Val Loss: 0.1815 Acc: 0.9348\n",
      "Epoch 033 | Train Loss: 0.0896 Acc: 0.9680 | Val Loss: 0.1727 Acc: 0.9457\n",
      "Epoch 034 | Train Loss: 0.0859 Acc: 0.9697 | Val Loss: 0.1983 Acc: 0.9366\n",
      "Epoch 035 | Train Loss: 0.0847 Acc: 0.9681 | Val Loss: 0.1951 Acc: 0.9390\n",
      "Epoch 036 | Train Loss: 0.0801 Acc: 0.9725 | Val Loss: 0.2085 Acc: 0.9330\n",
      "Epoch 037 | Train Loss: 0.0812 Acc: 0.9713 | Val Loss: 0.2086 Acc: 0.9245\n",
      "Epoch 038 | Train Loss: 0.0759 Acc: 0.9721 | Val Loss: 0.1960 Acc: 0.9366\n",
      "Epoch 039 | Train Loss: 0.0690 Acc: 0.9751 | Val Loss: 0.2028 Acc: 0.9336\n",
      "Epoch 040 | Train Loss: 0.0743 Acc: 0.9698 | Val Loss: 0.1828 Acc: 0.9378\n",
      "Epoch 041 | Train Loss: 0.0674 Acc: 0.9737 | Val Loss: 0.2505 Acc: 0.9275\n",
      "Epoch 042 | Train Loss: 0.0670 Acc: 0.9733 | Val Loss: 0.2499 Acc: 0.9191\n",
      "Epoch 043 | Train Loss: 0.0646 Acc: 0.9764 | Val Loss: 0.1788 Acc: 0.9396\n",
      "Early stopping triggered.\n",
      "Epoch 001 | Train Loss: 0.6781 Acc: 0.5846 | Val Loss: 0.6774 Acc: 0.5815\n",
      "Epoch 002 | Train Loss: 0.6716 Acc: 0.5941 | Val Loss: 0.6657 Acc: 0.6081\n",
      "Epoch 003 | Train Loss: 0.6614 Acc: 0.6147 | Val Loss: 0.6561 Acc: 0.6165\n",
      "Epoch 004 | Train Loss: 0.6592 Acc: 0.6097 | Val Loss: 0.6394 Acc: 0.6425\n",
      "Epoch 005 | Train Loss: 0.6301 Acc: 0.6538 | Val Loss: 0.6054 Acc: 0.6781\n",
      "Epoch 006 | Train Loss: 0.5780 Acc: 0.7137 | Val Loss: 0.5713 Acc: 0.7041\n",
      "Epoch 007 | Train Loss: 0.5749 Acc: 0.7155 | Val Loss: 0.5856 Acc: 0.6793\n",
      "Epoch 008 | Train Loss: 0.5481 Acc: 0.7327 | Val Loss: 0.5559 Acc: 0.7126\n",
      "Epoch 009 | Train Loss: 0.5383 Acc: 0.7392 | Val Loss: 0.5386 Acc: 0.7301\n",
      "Epoch 010 | Train Loss: 0.5287 Acc: 0.7414 | Val Loss: 0.5309 Acc: 0.7349\n",
      "Epoch 011 | Train Loss: 0.5137 Acc: 0.7497 | Val Loss: 0.5104 Acc: 0.7331\n",
      "Epoch 012 | Train Loss: 0.4965 Acc: 0.7645 | Val Loss: 0.4963 Acc: 0.7488\n",
      "Epoch 013 | Train Loss: 0.4755 Acc: 0.7779 | Val Loss: 0.4596 Acc: 0.7802\n",
      "Epoch 014 | Train Loss: 0.4476 Acc: 0.7912 | Val Loss: 0.4419 Acc: 0.7844\n",
      "Epoch 015 | Train Loss: 0.4243 Acc: 0.8039 | Val Loss: 0.4619 Acc: 0.7808\n",
      "Epoch 016 | Train Loss: 0.4073 Acc: 0.8107 | Val Loss: 0.4079 Acc: 0.8122\n",
      "Epoch 017 | Train Loss: 0.3856 Acc: 0.8252 | Val Loss: 0.3911 Acc: 0.8122\n",
      "Epoch 018 | Train Loss: 0.3692 Acc: 0.8366 | Val Loss: 0.3492 Acc: 0.8376\n",
      "Epoch 019 | Train Loss: 0.3441 Acc: 0.8475 | Val Loss: 0.3792 Acc: 0.8327\n",
      "Epoch 020 | Train Loss: 0.3181 Acc: 0.8650 | Val Loss: 0.3125 Acc: 0.8527\n",
      "Epoch 021 | Train Loss: 0.3159 Acc: 0.8664 | Val Loss: 0.3285 Acc: 0.8527\n",
      "Epoch 022 | Train Loss: 0.2916 Acc: 0.8792 | Val Loss: 0.3396 Acc: 0.8394\n",
      "Epoch 023 | Train Loss: 0.2672 Acc: 0.8893 | Val Loss: 0.3241 Acc: 0.8545\n",
      "Epoch 024 | Train Loss: 0.2595 Acc: 0.8978 | Val Loss: 0.3649 Acc: 0.8442\n",
      "Epoch 025 | Train Loss: 0.2495 Acc: 0.8985 | Val Loss: 0.2752 Acc: 0.8883\n",
      "Epoch 026 | Train Loss: 0.2353 Acc: 0.9032 | Val Loss: 0.2712 Acc: 0.8883\n",
      "Epoch 027 | Train Loss: 0.2231 Acc: 0.9091 | Val Loss: 0.2472 Acc: 0.8986\n",
      "Epoch 028 | Train Loss: 0.2251 Acc: 0.9074 | Val Loss: 0.2788 Acc: 0.8756\n",
      "Epoch 029 | Train Loss: 0.2217 Acc: 0.9114 | Val Loss: 0.2278 Acc: 0.9058\n",
      "Epoch 030 | Train Loss: 0.2112 Acc: 0.9154 | Val Loss: 0.2508 Acc: 0.8949\n",
      "Epoch 031 | Train Loss: 0.1973 Acc: 0.9231 | Val Loss: 0.2489 Acc: 0.8931\n",
      "Epoch 032 | Train Loss: 0.1906 Acc: 0.9254 | Val Loss: 0.2340 Acc: 0.9082\n",
      "Epoch 033 | Train Loss: 0.1907 Acc: 0.9275 | Val Loss: 0.2540 Acc: 0.9004\n",
      "Epoch 034 | Train Loss: 0.1737 Acc: 0.9354 | Val Loss: 0.2232 Acc: 0.9082\n",
      "Epoch 035 | Train Loss: 0.1710 Acc: 0.9327 | Val Loss: 0.2120 Acc: 0.9143\n",
      "Epoch 036 | Train Loss: 0.1760 Acc: 0.9307 | Val Loss: 0.2246 Acc: 0.9070\n",
      "Epoch 037 | Train Loss: 0.1535 Acc: 0.9422 | Val Loss: 0.2004 Acc: 0.9191\n",
      "Epoch 038 | Train Loss: 0.1502 Acc: 0.9429 | Val Loss: 0.2172 Acc: 0.9167\n",
      "Epoch 039 | Train Loss: 0.1566 Acc: 0.9357 | Val Loss: 0.2155 Acc: 0.9143\n",
      "Epoch 040 | Train Loss: 0.1527 Acc: 0.9434 | Val Loss: 0.2066 Acc: 0.9197\n",
      "Epoch 041 | Train Loss: 0.1410 Acc: 0.9444 | Val Loss: 0.1803 Acc: 0.9275\n",
      "Epoch 042 | Train Loss: 0.1388 Acc: 0.9481 | Val Loss: 0.2244 Acc: 0.9106\n",
      "Epoch 043 | Train Loss: 0.1414 Acc: 0.9488 | Val Loss: 0.1939 Acc: 0.9281\n",
      "Epoch 044 | Train Loss: 0.1378 Acc: 0.9475 | Val Loss: 0.2322 Acc: 0.9100\n",
      "Epoch 045 | Train Loss: 0.1352 Acc: 0.9481 | Val Loss: 0.1976 Acc: 0.9239\n",
      "Epoch 046 | Train Loss: 0.1294 Acc: 0.9506 | Val Loss: 0.2001 Acc: 0.9239\n",
      "Epoch 047 | Train Loss: 0.1268 Acc: 0.9518 | Val Loss: 0.1866 Acc: 0.9227\n",
      "Epoch 048 | Train Loss: 0.1238 Acc: 0.9543 | Val Loss: 0.2028 Acc: 0.9185\n",
      "Epoch 049 | Train Loss: 0.1261 Acc: 0.9543 | Val Loss: 0.1832 Acc: 0.9251\n",
      "Epoch 050 | Train Loss: 0.1103 Acc: 0.9583 | Val Loss: 0.2170 Acc: 0.9263\n",
      "Epoch 051 | Train Loss: 0.1147 Acc: 0.9565 | Val Loss: 0.2053 Acc: 0.9239\n",
      "Early stopping triggered.\n",
      "Epoch 001 | Train Loss: 0.6818 Acc: 0.5744 | Val Loss: 0.6804 Acc: 0.5755\n",
      "Epoch 002 | Train Loss: 0.6703 Acc: 0.5985 | Val Loss: 0.6626 Acc: 0.6057\n",
      "Epoch 003 | Train Loss: 0.6584 Acc: 0.6079 | Val Loss: 0.6520 Acc: 0.6159\n",
      "Epoch 004 | Train Loss: 0.6368 Acc: 0.6459 | Val Loss: 0.6212 Acc: 0.6751\n",
      "Epoch 005 | Train Loss: 0.6195 Acc: 0.6757 | Val Loss: 0.6198 Acc: 0.6643\n",
      "Epoch 006 | Train Loss: 0.6030 Acc: 0.6887 | Val Loss: 0.6039 Acc: 0.6806\n",
      "Epoch 007 | Train Loss: 0.5903 Acc: 0.7012 | Val Loss: 0.5827 Acc: 0.7095\n",
      "Epoch 008 | Train Loss: 0.5765 Acc: 0.7119 | Val Loss: 0.5895 Acc: 0.6999\n",
      "Epoch 009 | Train Loss: 0.5611 Acc: 0.7234 | Val Loss: 0.5664 Acc: 0.7132\n",
      "Epoch 010 | Train Loss: 0.5482 Acc: 0.7317 | Val Loss: 0.5512 Acc: 0.7301\n",
      "Epoch 011 | Train Loss: 0.5435 Acc: 0.7368 | Val Loss: 0.5470 Acc: 0.7295\n",
      "Epoch 012 | Train Loss: 0.5304 Acc: 0.7444 | Val Loss: 0.5378 Acc: 0.7361\n",
      "Epoch 013 | Train Loss: 0.5273 Acc: 0.7459 | Val Loss: 0.5336 Acc: 0.7355\n",
      "Epoch 014 | Train Loss: 0.5113 Acc: 0.7589 | Val Loss: 0.5395 Acc: 0.7385\n",
      "Epoch 015 | Train Loss: 0.5067 Acc: 0.7642 | Val Loss: 0.5322 Acc: 0.7361\n",
      "Epoch 016 | Train Loss: 0.4974 Acc: 0.7678 | Val Loss: 0.5212 Acc: 0.7421\n",
      "Epoch 017 | Train Loss: 0.4943 Acc: 0.7688 | Val Loss: 0.5089 Acc: 0.7579\n",
      "Epoch 018 | Train Loss: 0.4853 Acc: 0.7738 | Val Loss: 0.5082 Acc: 0.7542\n",
      "Epoch 019 | Train Loss: 0.4856 Acc: 0.7755 | Val Loss: 0.5024 Acc: 0.7488\n",
      "Epoch 020 | Train Loss: 0.4679 Acc: 0.7830 | Val Loss: 0.4926 Acc: 0.7615\n",
      "Epoch 021 | Train Loss: 0.4663 Acc: 0.7856 | Val Loss: 0.4966 Acc: 0.7627\n",
      "Epoch 022 | Train Loss: 0.4591 Acc: 0.7850 | Val Loss: 0.4854 Acc: 0.7711\n",
      "Epoch 023 | Train Loss: 0.4536 Acc: 0.7880 | Val Loss: 0.4847 Acc: 0.7651\n",
      "Epoch 024 | Train Loss: 0.4467 Acc: 0.7984 | Val Loss: 0.4614 Acc: 0.7802\n",
      "Epoch 025 | Train Loss: 0.4444 Acc: 0.7939 | Val Loss: 0.4595 Acc: 0.7844\n",
      "Epoch 026 | Train Loss: 0.4276 Acc: 0.8013 | Val Loss: 0.4998 Acc: 0.7603\n",
      "Epoch 027 | Train Loss: 0.4299 Acc: 0.8027 | Val Loss: 0.4473 Acc: 0.7947\n",
      "Epoch 028 | Train Loss: 0.4169 Acc: 0.8078 | Val Loss: 0.4483 Acc: 0.7838\n",
      "Epoch 029 | Train Loss: 0.4110 Acc: 0.8099 | Val Loss: 0.4418 Acc: 0.7844\n",
      "Epoch 030 | Train Loss: 0.4014 Acc: 0.8179 | Val Loss: 0.4247 Acc: 0.8025\n",
      "Epoch 031 | Train Loss: 0.3947 Acc: 0.8200 | Val Loss: 0.4089 Acc: 0.8176\n",
      "Epoch 032 | Train Loss: 0.3794 Acc: 0.8292 | Val Loss: 0.4060 Acc: 0.8128\n",
      "Epoch 033 | Train Loss: 0.3837 Acc: 0.8232 | Val Loss: 0.4156 Acc: 0.8062\n",
      "Epoch 034 | Train Loss: 0.3632 Acc: 0.8359 | Val Loss: 0.4016 Acc: 0.8056\n",
      "Epoch 035 | Train Loss: 0.3534 Acc: 0.8416 | Val Loss: 0.3775 Acc: 0.8261\n",
      "Epoch 036 | Train Loss: 0.3408 Acc: 0.8463 | Val Loss: 0.3706 Acc: 0.8339\n",
      "Epoch 037 | Train Loss: 0.3412 Acc: 0.8487 | Val Loss: 0.3639 Acc: 0.8339\n",
      "Epoch 038 | Train Loss: 0.3213 Acc: 0.8614 | Val Loss: 0.3781 Acc: 0.8394\n",
      "Epoch 039 | Train Loss: 0.3251 Acc: 0.8543 | Val Loss: 0.3557 Acc: 0.8478\n",
      "Epoch 040 | Train Loss: 0.3177 Acc: 0.8603 | Val Loss: 0.3824 Acc: 0.8249\n",
      "Epoch 041 | Train Loss: 0.3008 Acc: 0.8706 | Val Loss: 0.3600 Acc: 0.8448\n",
      "Epoch 042 | Train Loss: 0.2935 Acc: 0.8724 | Val Loss: 0.3556 Acc: 0.8436\n",
      "Epoch 043 | Train Loss: 0.2958 Acc: 0.8723 | Val Loss: 0.3274 Acc: 0.8539\n",
      "Epoch 044 | Train Loss: 0.2847 Acc: 0.8762 | Val Loss: 0.3991 Acc: 0.8128\n",
      "Epoch 045 | Train Loss: 0.2693 Acc: 0.8815 | Val Loss: 0.3151 Acc: 0.8575\n",
      "Epoch 046 | Train Loss: 0.2770 Acc: 0.8830 | Val Loss: 0.3553 Acc: 0.8454\n",
      "Epoch 047 | Train Loss: 0.2695 Acc: 0.8845 | Val Loss: 0.3040 Acc: 0.8593\n",
      "Epoch 048 | Train Loss: 0.2536 Acc: 0.8963 | Val Loss: 0.2909 Acc: 0.8744\n",
      "Epoch 049 | Train Loss: 0.2505 Acc: 0.8963 | Val Loss: 0.3376 Acc: 0.8472\n",
      "Epoch 050 | Train Loss: 0.2394 Acc: 0.9038 | Val Loss: 0.3067 Acc: 0.8708\n",
      "Epoch 051 | Train Loss: 0.2482 Acc: 0.8978 | Val Loss: 0.2803 Acc: 0.8822\n",
      "Epoch 052 | Train Loss: 0.2320 Acc: 0.9022 | Val Loss: 0.3154 Acc: 0.8545\n",
      "Epoch 053 | Train Loss: 0.2232 Acc: 0.9090 | Val Loss: 0.2734 Acc: 0.8835\n",
      "Epoch 054 | Train Loss: 0.2226 Acc: 0.9068 | Val Loss: 0.2859 Acc: 0.8762\n",
      "Epoch 055 | Train Loss: 0.2151 Acc: 0.9093 | Val Loss: 0.2819 Acc: 0.8841\n",
      "Epoch 056 | Train Loss: 0.2105 Acc: 0.9139 | Val Loss: 0.2752 Acc: 0.8877\n",
      "Epoch 057 | Train Loss: 0.2053 Acc: 0.9162 | Val Loss: 0.2753 Acc: 0.8913\n",
      "Epoch 058 | Train Loss: 0.2001 Acc: 0.9174 | Val Loss: 0.3040 Acc: 0.8804\n",
      "Epoch 059 | Train Loss: 0.2061 Acc: 0.9106 | Val Loss: 0.2483 Acc: 0.8961\n",
      "Epoch 060 | Train Loss: 0.1844 Acc: 0.9254 | Val Loss: 0.2525 Acc: 0.8967\n",
      "Epoch 001 | Train Loss: 0.6863 Acc: 0.5629 | Val Loss: 0.6806 Acc: 0.5773\n",
      "Epoch 002 | Train Loss: 0.6771 Acc: 0.5864 | Val Loss: 0.6770 Acc: 0.5900\n",
      "Epoch 003 | Train Loss: 0.6741 Acc: 0.5931 | Val Loss: 0.6753 Acc: 0.5864\n",
      "Epoch 004 | Train Loss: 0.6720 Acc: 0.5961 | Val Loss: 0.6711 Acc: 0.5936\n",
      "Epoch 005 | Train Loss: 0.6655 Acc: 0.6006 | Val Loss: 0.6630 Acc: 0.6045\n",
      "Epoch 006 | Train Loss: 0.6549 Acc: 0.6153 | Val Loss: 0.6485 Acc: 0.6359\n",
      "Epoch 007 | Train Loss: 0.6408 Acc: 0.6471 | Val Loss: 0.6303 Acc: 0.6733\n",
      "Epoch 008 | Train Loss: 0.6252 Acc: 0.6630 | Val Loss: 0.6190 Acc: 0.6812\n",
      "Epoch 009 | Train Loss: 0.6150 Acc: 0.6716 | Val Loss: 0.6143 Acc: 0.6812\n",
      "Epoch 010 | Train Loss: 0.6069 Acc: 0.6850 | Val Loss: 0.6049 Acc: 0.6751\n",
      "Epoch 011 | Train Loss: 0.5981 Acc: 0.6917 | Val Loss: 0.5985 Acc: 0.6854\n",
      "Epoch 012 | Train Loss: 0.5911 Acc: 0.6979 | Val Loss: 0.6015 Acc: 0.6890\n",
      "Epoch 013 | Train Loss: 0.5864 Acc: 0.7047 | Val Loss: 0.5912 Acc: 0.6938\n",
      "Epoch 014 | Train Loss: 0.5854 Acc: 0.7001 | Val Loss: 0.5886 Acc: 0.6981\n",
      "Epoch 015 | Train Loss: 0.5779 Acc: 0.7093 | Val Loss: 0.5828 Acc: 0.7041\n",
      "Epoch 016 | Train Loss: 0.5738 Acc: 0.7112 | Val Loss: 0.5874 Acc: 0.7023\n",
      "Epoch 017 | Train Loss: 0.5723 Acc: 0.7125 | Val Loss: 0.5998 Acc: 0.6878\n",
      "Epoch 018 | Train Loss: 0.5702 Acc: 0.7155 | Val Loss: 0.5825 Acc: 0.7053\n",
      "Epoch 019 | Train Loss: 0.5612 Acc: 0.7244 | Val Loss: 0.5712 Acc: 0.7095\n",
      "Epoch 020 | Train Loss: 0.5605 Acc: 0.7234 | Val Loss: 0.5690 Acc: 0.7150\n",
      "Epoch 021 | Train Loss: 0.5566 Acc: 0.7249 | Val Loss: 0.5675 Acc: 0.7132\n",
      "Epoch 022 | Train Loss: 0.5519 Acc: 0.7266 | Val Loss: 0.5614 Acc: 0.7186\n",
      "Epoch 023 | Train Loss: 0.5442 Acc: 0.7341 | Val Loss: 0.5622 Acc: 0.7101\n",
      "Epoch 024 | Train Loss: 0.5412 Acc: 0.7359 | Val Loss: 0.5584 Acc: 0.7150\n",
      "Epoch 025 | Train Loss: 0.5372 Acc: 0.7391 | Val Loss: 0.5479 Acc: 0.7264\n",
      "Epoch 026 | Train Loss: 0.5343 Acc: 0.7414 | Val Loss: 0.5447 Acc: 0.7222\n",
      "Epoch 027 | Train Loss: 0.5265 Acc: 0.7450 | Val Loss: 0.5530 Acc: 0.7216\n",
      "Epoch 028 | Train Loss: 0.5227 Acc: 0.7510 | Val Loss: 0.5383 Acc: 0.7295\n",
      "Epoch 029 | Train Loss: 0.5157 Acc: 0.7545 | Val Loss: 0.5355 Acc: 0.7313\n",
      "Epoch 030 | Train Loss: 0.5251 Acc: 0.7482 | Val Loss: 0.5603 Acc: 0.7234\n",
      "Epoch 031 | Train Loss: 0.5157 Acc: 0.7540 | Val Loss: 0.5289 Acc: 0.7361\n",
      "Epoch 032 | Train Loss: 0.5050 Acc: 0.7631 | Val Loss: 0.5669 Acc: 0.7071\n",
      "Epoch 033 | Train Loss: 0.5086 Acc: 0.7592 | Val Loss: 0.5695 Acc: 0.7071\n",
      "Epoch 034 | Train Loss: 0.5049 Acc: 0.7611 | Val Loss: 0.5420 Acc: 0.7246\n",
      "Epoch 035 | Train Loss: 0.5057 Acc: 0.7626 | Val Loss: 0.5195 Acc: 0.7494\n",
      "Epoch 036 | Train Loss: 0.4951 Acc: 0.7694 | Val Loss: 0.6063 Acc: 0.7162\n",
      "Epoch 037 | Train Loss: 0.4957 Acc: 0.7693 | Val Loss: 0.5209 Acc: 0.7470\n",
      "Epoch 038 | Train Loss: 0.4904 Acc: 0.7717 | Val Loss: 0.5172 Acc: 0.7440\n",
      "Epoch 039 | Train Loss: 0.4871 Acc: 0.7728 | Val Loss: 0.5327 Acc: 0.7476\n",
      "Epoch 040 | Train Loss: 0.4854 Acc: 0.7749 | Val Loss: 0.5188 Acc: 0.7482\n",
      "Epoch 041 | Train Loss: 0.4812 Acc: 0.7809 | Val Loss: 0.5097 Acc: 0.7542\n",
      "Epoch 042 | Train Loss: 0.4790 Acc: 0.7808 | Val Loss: 0.5046 Acc: 0.7572\n",
      "Epoch 043 | Train Loss: 0.4719 Acc: 0.7864 | Val Loss: 0.5055 Acc: 0.7566\n",
      "Epoch 044 | Train Loss: 0.4724 Acc: 0.7818 | Val Loss: 0.5117 Acc: 0.7518\n",
      "Epoch 045 | Train Loss: 0.4734 Acc: 0.7818 | Val Loss: 0.5118 Acc: 0.7560\n",
      "Epoch 046 | Train Loss: 0.4702 Acc: 0.7838 | Val Loss: 0.5042 Acc: 0.7536\n",
      "Epoch 047 | Train Loss: 0.4676 Acc: 0.7862 | Val Loss: 0.5079 Acc: 0.7675\n",
      "Epoch 048 | Train Loss: 0.4590 Acc: 0.7919 | Val Loss: 0.4981 Acc: 0.7627\n",
      "Epoch 049 | Train Loss: 0.4589 Acc: 0.7924 | Val Loss: 0.4969 Acc: 0.7603\n",
      "Epoch 050 | Train Loss: 0.4549 Acc: 0.7915 | Val Loss: 0.4946 Acc: 0.7615\n",
      "Epoch 051 | Train Loss: 0.4537 Acc: 0.7930 | Val Loss: 0.5226 Acc: 0.7464\n",
      "Epoch 052 | Train Loss: 0.4519 Acc: 0.7972 | Val Loss: 0.4936 Acc: 0.7778\n",
      "Epoch 053 | Train Loss: 0.4497 Acc: 0.7981 | Val Loss: 0.4853 Acc: 0.7717\n",
      "Epoch 054 | Train Loss: 0.4472 Acc: 0.7945 | Val Loss: 0.4940 Acc: 0.7603\n",
      "Epoch 055 | Train Loss: 0.4438 Acc: 0.7995 | Val Loss: 0.4813 Acc: 0.7766\n",
      "Epoch 056 | Train Loss: 0.4418 Acc: 0.8046 | Val Loss: 0.4866 Acc: 0.7645\n",
      "Epoch 057 | Train Loss: 0.4328 Acc: 0.8045 | Val Loss: 0.4762 Acc: 0.7772\n",
      "Epoch 058 | Train Loss: 0.4371 Acc: 0.8039 | Val Loss: 0.4702 Acc: 0.7790\n",
      "Epoch 059 | Train Loss: 0.4357 Acc: 0.8076 | Val Loss: 0.4808 Acc: 0.7687\n",
      "Epoch 060 | Train Loss: 0.4292 Acc: 0.8057 | Val Loss: 0.4814 Acc: 0.7838\n",
      "Epoch 001 | Train Loss: 0.6863 Acc: 0.5620 | Val Loss: 0.6839 Acc: 0.5676\n",
      "Epoch 002 | Train Loss: 0.6805 Acc: 0.5790 | Val Loss: 0.6786 Acc: 0.5870\n",
      "Epoch 003 | Train Loss: 0.6755 Acc: 0.5884 | Val Loss: 0.6756 Acc: 0.5900\n",
      "Epoch 004 | Train Loss: 0.6730 Acc: 0.5955 | Val Loss: 0.6710 Acc: 0.5924\n",
      "Epoch 005 | Train Loss: 0.6666 Acc: 0.6020 | Val Loss: 0.6634 Acc: 0.6014\n",
      "Epoch 006 | Train Loss: 0.6558 Acc: 0.6089 | Val Loss: 0.6641 Acc: 0.5972\n",
      "Epoch 007 | Train Loss: 0.6435 Acc: 0.6326 | Val Loss: 0.6338 Acc: 0.6467\n",
      "Epoch 008 | Train Loss: 0.6358 Acc: 0.6494 | Val Loss: 0.6263 Acc: 0.6655\n",
      "Epoch 009 | Train Loss: 0.6140 Acc: 0.6758 | Val Loss: 0.6115 Acc: 0.6848\n",
      "Epoch 010 | Train Loss: 0.6040 Acc: 0.6838 | Val Loss: 0.6050 Acc: 0.6751\n",
      "Epoch 011 | Train Loss: 0.6023 Acc: 0.6870 | Val Loss: 0.5976 Acc: 0.6908\n",
      "Epoch 012 | Train Loss: 0.5958 Acc: 0.6942 | Val Loss: 0.5947 Acc: 0.6914\n",
      "Epoch 013 | Train Loss: 0.5925 Acc: 0.6974 | Val Loss: 0.5917 Acc: 0.6987\n",
      "Epoch 014 | Train Loss: 0.5856 Acc: 0.7045 | Val Loss: 0.5970 Acc: 0.6842\n",
      "Epoch 015 | Train Loss: 0.5802 Acc: 0.7077 | Val Loss: 0.5808 Acc: 0.7023\n",
      "Epoch 016 | Train Loss: 0.5823 Acc: 0.7024 | Val Loss: 0.5796 Acc: 0.7047\n",
      "Epoch 017 | Train Loss: 0.5733 Acc: 0.7160 | Val Loss: 0.5832 Acc: 0.7053\n",
      "Epoch 018 | Train Loss: 0.5712 Acc: 0.7134 | Val Loss: 0.5821 Acc: 0.7047\n",
      "Epoch 019 | Train Loss: 0.5721 Acc: 0.7133 | Val Loss: 0.5747 Acc: 0.7053\n",
      "Epoch 020 | Train Loss: 0.5662 Acc: 0.7213 | Val Loss: 0.5724 Acc: 0.7071\n",
      "Epoch 021 | Train Loss: 0.5652 Acc: 0.7216 | Val Loss: 0.5800 Acc: 0.6944\n",
      "Epoch 022 | Train Loss: 0.5592 Acc: 0.7258 | Val Loss: 0.5680 Acc: 0.7065\n",
      "Epoch 023 | Train Loss: 0.5511 Acc: 0.7278 | Val Loss: 0.5663 Acc: 0.7071\n",
      "Epoch 024 | Train Loss: 0.5522 Acc: 0.7270 | Val Loss: 0.5728 Acc: 0.7077\n",
      "Epoch 025 | Train Loss: 0.5539 Acc: 0.7284 | Val Loss: 0.5644 Acc: 0.7059\n",
      "Epoch 026 | Train Loss: 0.5503 Acc: 0.7296 | Val Loss: 0.5704 Acc: 0.7101\n",
      "Epoch 027 | Train Loss: 0.5492 Acc: 0.7276 | Val Loss: 0.5580 Acc: 0.7107\n",
      "Epoch 028 | Train Loss: 0.5379 Acc: 0.7376 | Val Loss: 0.5553 Acc: 0.7156\n",
      "Epoch 029 | Train Loss: 0.5386 Acc: 0.7356 | Val Loss: 0.5588 Acc: 0.7180\n",
      "Epoch 030 | Train Loss: 0.5384 Acc: 0.7398 | Val Loss: 0.5716 Acc: 0.7107\n",
      "Epoch 031 | Train Loss: 0.5344 Acc: 0.7395 | Val Loss: 0.5519 Acc: 0.7156\n",
      "Epoch 032 | Train Loss: 0.5327 Acc: 0.7386 | Val Loss: 0.5686 Acc: 0.7126\n",
      "Epoch 033 | Train Loss: 0.5302 Acc: 0.7448 | Val Loss: 0.5507 Acc: 0.7198\n",
      "Epoch 034 | Train Loss: 0.5278 Acc: 0.7444 | Val Loss: 0.5490 Acc: 0.7228\n",
      "Epoch 035 | Train Loss: 0.5220 Acc: 0.7494 | Val Loss: 0.5495 Acc: 0.7198\n",
      "Epoch 036 | Train Loss: 0.5185 Acc: 0.7500 | Val Loss: 0.5415 Acc: 0.7228\n",
      "Epoch 037 | Train Loss: 0.5161 Acc: 0.7463 | Val Loss: 0.5852 Acc: 0.7095\n",
      "Epoch 038 | Train Loss: 0.5225 Acc: 0.7448 | Val Loss: 0.5383 Acc: 0.7246\n",
      "Epoch 039 | Train Loss: 0.5093 Acc: 0.7527 | Val Loss: 0.5337 Acc: 0.7283\n",
      "Epoch 040 | Train Loss: 0.5079 Acc: 0.7527 | Val Loss: 0.5599 Acc: 0.7174\n",
      "Epoch 041 | Train Loss: 0.5056 Acc: 0.7549 | Val Loss: 0.5213 Acc: 0.7373\n",
      "Epoch 042 | Train Loss: 0.4963 Acc: 0.7605 | Val Loss: 0.5186 Acc: 0.7283\n",
      "Epoch 043 | Train Loss: 0.4972 Acc: 0.7622 | Val Loss: 0.5227 Acc: 0.7331\n",
      "Epoch 044 | Train Loss: 0.4995 Acc: 0.7614 | Val Loss: 0.5421 Acc: 0.7240\n",
      "Epoch 045 | Train Loss: 0.4943 Acc: 0.7637 | Val Loss: 0.5298 Acc: 0.7458\n",
      "Epoch 046 | Train Loss: 0.4819 Acc: 0.7720 | Val Loss: 0.5088 Acc: 0.7421\n",
      "Epoch 047 | Train Loss: 0.4862 Acc: 0.7697 | Val Loss: 0.5091 Acc: 0.7415\n",
      "Epoch 048 | Train Loss: 0.4751 Acc: 0.7702 | Val Loss: 0.5015 Acc: 0.7482\n",
      "Epoch 049 | Train Loss: 0.4731 Acc: 0.7726 | Val Loss: 0.5018 Acc: 0.7524\n",
      "Epoch 050 | Train Loss: 0.4775 Acc: 0.7774 | Val Loss: 0.4919 Acc: 0.7548\n",
      "Epoch 051 | Train Loss: 0.4660 Acc: 0.7821 | Val Loss: 0.4948 Acc: 0.7488\n",
      "Epoch 052 | Train Loss: 0.4610 Acc: 0.7845 | Val Loss: 0.4880 Acc: 0.7579\n",
      "Epoch 053 | Train Loss: 0.4720 Acc: 0.7790 | Val Loss: 0.4878 Acc: 0.7536\n",
      "Epoch 054 | Train Loss: 0.4627 Acc: 0.7802 | Val Loss: 0.4794 Acc: 0.7645\n",
      "Epoch 055 | Train Loss: 0.4568 Acc: 0.7826 | Val Loss: 0.4794 Acc: 0.7687\n",
      "Epoch 056 | Train Loss: 0.4516 Acc: 0.7864 | Val Loss: 0.4755 Acc: 0.7675\n",
      "Epoch 057 | Train Loss: 0.4564 Acc: 0.7862 | Val Loss: 0.4765 Acc: 0.7633\n",
      "Epoch 058 | Train Loss: 0.4464 Acc: 0.7871 | Val Loss: 0.4808 Acc: 0.7633\n",
      "Epoch 059 | Train Loss: 0.4431 Acc: 0.7883 | Val Loss: 0.4627 Acc: 0.7796\n",
      "Epoch 060 | Train Loss: 0.4431 Acc: 0.7901 | Val Loss: 0.4573 Acc: 0.7832\n",
      "Epoch 001 | Train Loss: 0.6845 Acc: 0.5709 | Val Loss: 0.6831 Acc: 0.5694\n",
      "Epoch 002 | Train Loss: 0.6747 Acc: 0.5932 | Val Loss: 0.6699 Acc: 0.5936\n",
      "Epoch 003 | Train Loss: 0.6647 Acc: 0.6151 | Val Loss: 0.6558 Acc: 0.6159\n",
      "Epoch 004 | Train Loss: 0.6788 Acc: 0.5762 | Val Loss: 0.6861 Acc: 0.5586\n",
      "Epoch 005 | Train Loss: 0.6824 Acc: 0.5671 | Val Loss: 0.6703 Acc: 0.5815\n",
      "Epoch 006 | Train Loss: 0.6492 Acc: 0.6385 | Val Loss: 0.6247 Acc: 0.6751\n",
      "Epoch 007 | Train Loss: 0.5952 Acc: 0.6950 | Val Loss: 0.5937 Acc: 0.6812\n",
      "Epoch 008 | Train Loss: 0.5691 Acc: 0.7175 | Val Loss: 0.5800 Acc: 0.7029\n",
      "Epoch 009 | Train Loss: 0.5564 Acc: 0.7318 | Val Loss: 0.5509 Acc: 0.7228\n",
      "Epoch 010 | Train Loss: 0.5478 Acc: 0.7329 | Val Loss: 0.5516 Acc: 0.7252\n",
      "Epoch 011 | Train Loss: 0.5318 Acc: 0.7448 | Val Loss: 0.5423 Acc: 0.7301\n",
      "Epoch 012 | Train Loss: 0.5164 Acc: 0.7527 | Val Loss: 0.5475 Acc: 0.7391\n",
      "Epoch 013 | Train Loss: 0.5072 Acc: 0.7583 | Val Loss: 0.5187 Acc: 0.7428\n",
      "Epoch 014 | Train Loss: 0.4937 Acc: 0.7713 | Val Loss: 0.4945 Acc: 0.7597\n",
      "Epoch 015 | Train Loss: 0.4816 Acc: 0.7734 | Val Loss: 0.4890 Acc: 0.7627\n",
      "Epoch 016 | Train Loss: 0.4616 Acc: 0.7877 | Val Loss: 0.4606 Acc: 0.7748\n",
      "Epoch 017 | Train Loss: 0.4538 Acc: 0.7915 | Val Loss: 0.4544 Acc: 0.7772\n",
      "Epoch 018 | Train Loss: 0.4382 Acc: 0.8063 | Val Loss: 0.4396 Acc: 0.7959\n",
      "Epoch 019 | Train Loss: 0.4292 Acc: 0.7986 | Val Loss: 0.4256 Acc: 0.7995\n",
      "Epoch 020 | Train Loss: 0.4220 Acc: 0.8081 | Val Loss: 0.4241 Acc: 0.7923\n",
      "Epoch 021 | Train Loss: 0.4075 Acc: 0.8107 | Val Loss: 0.4376 Acc: 0.7977\n",
      "Epoch 022 | Train Loss: 0.3928 Acc: 0.8175 | Val Loss: 0.4446 Acc: 0.7760\n",
      "Epoch 023 | Train Loss: 0.3858 Acc: 0.8258 | Val Loss: 0.4289 Acc: 0.7971\n",
      "Epoch 024 | Train Loss: 0.3687 Acc: 0.8345 | Val Loss: 0.3772 Acc: 0.8158\n",
      "Epoch 025 | Train Loss: 0.3576 Acc: 0.8404 | Val Loss: 0.3718 Acc: 0.8321\n",
      "Epoch 026 | Train Loss: 0.3395 Acc: 0.8470 | Val Loss: 0.3622 Acc: 0.8225\n",
      "Epoch 027 | Train Loss: 0.3250 Acc: 0.8581 | Val Loss: 0.3307 Acc: 0.8581\n",
      "Epoch 028 | Train Loss: 0.3341 Acc: 0.8555 | Val Loss: 0.3821 Acc: 0.8321\n",
      "Epoch 029 | Train Loss: 0.3200 Acc: 0.8661 | Val Loss: 0.3311 Acc: 0.8569\n",
      "Epoch 030 | Train Loss: 0.3063 Acc: 0.8682 | Val Loss: 0.3553 Acc: 0.8575\n",
      "Epoch 031 | Train Loss: 0.2899 Acc: 0.8774 | Val Loss: 0.3353 Acc: 0.8539\n",
      "Epoch 032 | Train Loss: 0.2872 Acc: 0.8824 | Val Loss: 0.3450 Acc: 0.8551\n",
      "Epoch 033 | Train Loss: 0.2880 Acc: 0.8848 | Val Loss: 0.3280 Acc: 0.8533\n",
      "Epoch 034 | Train Loss: 0.2616 Acc: 0.8919 | Val Loss: 0.3129 Acc: 0.8629\n",
      "Epoch 035 | Train Loss: 0.2500 Acc: 0.8981 | Val Loss: 0.2980 Acc: 0.8714\n",
      "Epoch 036 | Train Loss: 0.2468 Acc: 0.8994 | Val Loss: 0.2912 Acc: 0.8750\n",
      "Epoch 037 | Train Loss: 0.2403 Acc: 0.9034 | Val Loss: 0.3205 Acc: 0.8841\n",
      "Epoch 038 | Train Loss: 0.2353 Acc: 0.9022 | Val Loss: 0.2988 Acc: 0.8696\n",
      "Epoch 039 | Train Loss: 0.2256 Acc: 0.9071 | Val Loss: 0.2835 Acc: 0.8798\n",
      "Epoch 040 | Train Loss: 0.2032 Acc: 0.9192 | Val Loss: 0.2592 Acc: 0.8979\n",
      "Epoch 041 | Train Loss: 0.2062 Acc: 0.9165 | Val Loss: 0.2565 Acc: 0.8979\n",
      "Epoch 042 | Train Loss: 0.1929 Acc: 0.9242 | Val Loss: 0.2347 Acc: 0.8992\n",
      "Epoch 043 | Train Loss: 0.1902 Acc: 0.9260 | Val Loss: 0.2521 Acc: 0.8955\n",
      "Epoch 044 | Train Loss: 0.1775 Acc: 0.9283 | Val Loss: 0.2627 Acc: 0.8992\n",
      "Epoch 045 | Train Loss: 0.1798 Acc: 0.9302 | Val Loss: 0.2349 Acc: 0.9094\n",
      "Epoch 046 | Train Loss: 0.1777 Acc: 0.9302 | Val Loss: 0.2669 Acc: 0.8943\n",
      "Epoch 047 | Train Loss: 0.1847 Acc: 0.9290 | Val Loss: 0.2494 Acc: 0.9022\n",
      "Epoch 048 | Train Loss: 0.1711 Acc: 0.9348 | Val Loss: 0.2267 Acc: 0.9124\n",
      "Epoch 049 | Train Loss: 0.1652 Acc: 0.9349 | Val Loss: 0.2194 Acc: 0.9082\n",
      "Epoch 050 | Train Loss: 0.1613 Acc: 0.9407 | Val Loss: 0.2525 Acc: 0.8973\n",
      "Epoch 051 | Train Loss: 0.1522 Acc: 0.9426 | Val Loss: 0.2492 Acc: 0.9118\n",
      "Epoch 052 | Train Loss: 0.1527 Acc: 0.9407 | Val Loss: 0.2080 Acc: 0.9197\n",
      "Epoch 053 | Train Loss: 0.1518 Acc: 0.9416 | Val Loss: 0.2152 Acc: 0.9149\n",
      "Epoch 054 | Train Loss: 0.1506 Acc: 0.9440 | Val Loss: 0.2007 Acc: 0.9251\n",
      "Epoch 055 | Train Loss: 0.1432 Acc: 0.9450 | Val Loss: 0.2284 Acc: 0.9112\n",
      "Epoch 056 | Train Loss: 0.1359 Acc: 0.9472 | Val Loss: 0.2073 Acc: 0.9293\n",
      "Epoch 057 | Train Loss: 0.1280 Acc: 0.9536 | Val Loss: 0.2080 Acc: 0.9197\n",
      "Epoch 058 | Train Loss: 0.1227 Acc: 0.9547 | Val Loss: 0.2319 Acc: 0.9082\n",
      "Epoch 059 | Train Loss: 0.1347 Acc: 0.9511 | Val Loss: 0.1959 Acc: 0.9287\n",
      "Epoch 060 | Train Loss: 0.1313 Acc: 0.9494 | Val Loss: 0.2944 Acc: 0.8931\n",
      "Epoch 001 | Train Loss: 0.6805 Acc: 0.5760 | Val Loss: 0.6861 Acc: 0.5586\n",
      "Epoch 002 | Train Loss: 0.6770 Acc: 0.5783 | Val Loss: 0.6661 Acc: 0.5942\n",
      "Epoch 003 | Train Loss: 0.6275 Acc: 0.6585 | Val Loss: 0.5949 Acc: 0.6878\n",
      "Epoch 004 | Train Loss: 0.5834 Acc: 0.6992 | Val Loss: 0.6079 Acc: 0.6781\n",
      "Epoch 005 | Train Loss: 0.5540 Acc: 0.7291 | Val Loss: 0.5474 Acc: 0.7246\n",
      "Epoch 006 | Train Loss: 0.5374 Acc: 0.7358 | Val Loss: 0.5361 Acc: 0.7271\n",
      "Epoch 007 | Train Loss: 0.5182 Acc: 0.7507 | Val Loss: 0.5302 Acc: 0.7319\n",
      "Epoch 008 | Train Loss: 0.5008 Acc: 0.7551 | Val Loss: 0.5341 Acc: 0.7464\n",
      "Epoch 009 | Train Loss: 0.4902 Acc: 0.7640 | Val Loss: 0.4774 Acc: 0.7675\n",
      "Epoch 010 | Train Loss: 0.4659 Acc: 0.7811 | Val Loss: 0.4605 Acc: 0.7808\n",
      "Epoch 011 | Train Loss: 0.4443 Acc: 0.7941 | Val Loss: 0.4454 Acc: 0.7868\n",
      "Epoch 012 | Train Loss: 0.4264 Acc: 0.8063 | Val Loss: 0.4339 Acc: 0.7959\n",
      "Epoch 013 | Train Loss: 0.4157 Acc: 0.8122 | Val Loss: 0.4366 Acc: 0.7868\n",
      "Epoch 014 | Train Loss: 0.4004 Acc: 0.8212 | Val Loss: 0.3965 Acc: 0.8122\n",
      "Epoch 015 | Train Loss: 0.3704 Acc: 0.8321 | Val Loss: 0.3705 Acc: 0.8412\n",
      "Epoch 016 | Train Loss: 0.3625 Acc: 0.8390 | Val Loss: 0.3862 Acc: 0.8219\n",
      "Epoch 017 | Train Loss: 0.3427 Acc: 0.8495 | Val Loss: 0.3478 Acc: 0.8394\n",
      "Epoch 018 | Train Loss: 0.3260 Acc: 0.8582 | Val Loss: 0.3255 Acc: 0.8539\n",
      "Epoch 019 | Train Loss: 0.3222 Acc: 0.8641 | Val Loss: 0.3657 Acc: 0.8333\n",
      "Epoch 020 | Train Loss: 0.2925 Acc: 0.8760 | Val Loss: 0.4064 Acc: 0.8219\n",
      "Epoch 021 | Train Loss: 0.2892 Acc: 0.8792 | Val Loss: 0.2993 Acc: 0.8744\n",
      "Epoch 022 | Train Loss: 0.2662 Acc: 0.8831 | Val Loss: 0.2799 Acc: 0.8913\n",
      "Epoch 023 | Train Loss: 0.2570 Acc: 0.8905 | Val Loss: 0.2803 Acc: 0.8774\n",
      "Epoch 024 | Train Loss: 0.2573 Acc: 0.8884 | Val Loss: 0.2661 Acc: 0.8895\n",
      "Epoch 025 | Train Loss: 0.2404 Acc: 0.8985 | Val Loss: 0.2762 Acc: 0.8829\n",
      "Epoch 026 | Train Loss: 0.2282 Acc: 0.9044 | Val Loss: 0.2480 Acc: 0.9046\n",
      "Epoch 027 | Train Loss: 0.2062 Acc: 0.9182 | Val Loss: 0.2362 Acc: 0.9100\n",
      "Epoch 028 | Train Loss: 0.2131 Acc: 0.9195 | Val Loss: 0.2258 Acc: 0.9124\n",
      "Epoch 029 | Train Loss: 0.2077 Acc: 0.9162 | Val Loss: 0.2317 Acc: 0.9064\n",
      "Epoch 030 | Train Loss: 0.1969 Acc: 0.9198 | Val Loss: 0.2433 Acc: 0.9064\n",
      "Epoch 031 | Train Loss: 0.2018 Acc: 0.9198 | Val Loss: 0.2182 Acc: 0.9118\n",
      "Epoch 032 | Train Loss: 0.1891 Acc: 0.9251 | Val Loss: 0.2520 Acc: 0.8949\n",
      "Epoch 033 | Train Loss: 0.1802 Acc: 0.9289 | Val Loss: 0.2050 Acc: 0.9179\n",
      "Epoch 034 | Train Loss: 0.1734 Acc: 0.9333 | Val Loss: 0.2678 Acc: 0.8967\n",
      "Epoch 035 | Train Loss: 0.1757 Acc: 0.9333 | Val Loss: 0.2008 Acc: 0.9149\n",
      "Epoch 036 | Train Loss: 0.1609 Acc: 0.9355 | Val Loss: 0.2129 Acc: 0.9124\n",
      "Epoch 037 | Train Loss: 0.1601 Acc: 0.9373 | Val Loss: 0.2140 Acc: 0.9130\n",
      "Epoch 038 | Train Loss: 0.1539 Acc: 0.9408 | Val Loss: 0.1995 Acc: 0.9233\n",
      "Epoch 039 | Train Loss: 0.1555 Acc: 0.9399 | Val Loss: 0.1981 Acc: 0.9215\n",
      "Epoch 040 | Train Loss: 0.1467 Acc: 0.9431 | Val Loss: 0.2021 Acc: 0.9179\n",
      "Epoch 041 | Train Loss: 0.1495 Acc: 0.9420 | Val Loss: 0.1895 Acc: 0.9269\n",
      "Epoch 042 | Train Loss: 0.1377 Acc: 0.9461 | Val Loss: 0.1797 Acc: 0.9263\n",
      "Epoch 043 | Train Loss: 0.1424 Acc: 0.9452 | Val Loss: 0.2164 Acc: 0.9167\n",
      "Epoch 044 | Train Loss: 0.1307 Acc: 0.9490 | Val Loss: 0.2108 Acc: 0.9203\n",
      "Epoch 045 | Train Loss: 0.1340 Acc: 0.9488 | Val Loss: 0.1974 Acc: 0.9263\n",
      "Epoch 046 | Train Loss: 0.1271 Acc: 0.9550 | Val Loss: 0.2090 Acc: 0.9257\n",
      "Epoch 047 | Train Loss: 0.1220 Acc: 0.9527 | Val Loss: 0.2046 Acc: 0.9281\n",
      "Epoch 048 | Train Loss: 0.1189 Acc: 0.9536 | Val Loss: 0.2228 Acc: 0.9191\n",
      "Epoch 049 | Train Loss: 0.1172 Acc: 0.9555 | Val Loss: 0.1746 Acc: 0.9293\n",
      "Epoch 050 | Train Loss: 0.1299 Acc: 0.9494 | Val Loss: 0.1696 Acc: 0.9287\n",
      "Epoch 051 | Train Loss: 0.1131 Acc: 0.9559 | Val Loss: 0.2696 Acc: 0.9058\n",
      "Epoch 052 | Train Loss: 0.1168 Acc: 0.9556 | Val Loss: 0.1712 Acc: 0.9354\n",
      "Epoch 053 | Train Loss: 0.1064 Acc: 0.9580 | Val Loss: 0.2069 Acc: 0.9251\n",
      "Epoch 054 | Train Loss: 0.1122 Acc: 0.9591 | Val Loss: 0.1790 Acc: 0.9293\n",
      "Epoch 055 | Train Loss: 0.1172 Acc: 0.9523 | Val Loss: 0.1945 Acc: 0.9263\n",
      "Epoch 056 | Train Loss: 0.1152 Acc: 0.9576 | Val Loss: 0.2303 Acc: 0.9191\n",
      "Epoch 057 | Train Loss: 0.0981 Acc: 0.9629 | Val Loss: 0.2081 Acc: 0.9269\n",
      "Epoch 058 | Train Loss: 0.1010 Acc: 0.9641 | Val Loss: 0.1749 Acc: 0.9330\n",
      "Epoch 059 | Train Loss: 0.0974 Acc: 0.9648 | Val Loss: 0.1786 Acc: 0.9384\n",
      "Epoch 060 | Train Loss: 0.1009 Acc: 0.9629 | Val Loss: 0.1782 Acc: 0.9293\n",
      "Early stopping triggered.\n",
      "Epoch 001 | Train Loss: 0.6796 Acc: 0.5774 | Val Loss: 0.6742 Acc: 0.5918\n",
      "Epoch 002 | Train Loss: 0.6381 Acc: 0.6462 | Val Loss: 0.6075 Acc: 0.6667\n",
      "Epoch 003 | Train Loss: 0.5756 Acc: 0.7154 | Val Loss: 0.5498 Acc: 0.7210\n",
      "Epoch 004 | Train Loss: 0.5442 Acc: 0.7334 | Val Loss: 0.5478 Acc: 0.7222\n",
      "Epoch 005 | Train Loss: 0.5147 Acc: 0.7491 | Val Loss: 0.5461 Acc: 0.7180\n",
      "Epoch 006 | Train Loss: 0.5167 Acc: 0.7528 | Val Loss: 0.5016 Acc: 0.7572\n",
      "Epoch 007 | Train Loss: 0.4806 Acc: 0.7719 | Val Loss: 0.4695 Acc: 0.7693\n",
      "Epoch 008 | Train Loss: 0.4591 Acc: 0.7850 | Val Loss: 0.4526 Acc: 0.7754\n",
      "Epoch 009 | Train Loss: 0.4357 Acc: 0.8014 | Val Loss: 0.4134 Acc: 0.7971\n",
      "Epoch 010 | Train Loss: 0.4156 Acc: 0.8088 | Val Loss: 0.4130 Acc: 0.8098\n",
      "Epoch 011 | Train Loss: 0.4017 Acc: 0.8215 | Val Loss: 0.4012 Acc: 0.8134\n",
      "Epoch 012 | Train Loss: 0.3764 Acc: 0.8351 | Val Loss: 0.3624 Acc: 0.8273\n",
      "Epoch 013 | Train Loss: 0.3677 Acc: 0.8409 | Val Loss: 0.3410 Acc: 0.8502\n",
      "Epoch 014 | Train Loss: 0.3494 Acc: 0.8457 | Val Loss: 0.3713 Acc: 0.8333\n",
      "Epoch 015 | Train Loss: 0.3290 Acc: 0.8575 | Val Loss: 0.3287 Acc: 0.8545\n",
      "Epoch 016 | Train Loss: 0.3102 Acc: 0.8703 | Val Loss: 0.3016 Acc: 0.8684\n",
      "Epoch 017 | Train Loss: 0.3100 Acc: 0.8718 | Val Loss: 0.3392 Acc: 0.8508\n",
      "Epoch 018 | Train Loss: 0.2923 Acc: 0.8794 | Val Loss: 0.2712 Acc: 0.8841\n",
      "Epoch 019 | Train Loss: 0.2802 Acc: 0.8825 | Val Loss: 0.2727 Acc: 0.8841\n",
      "Epoch 020 | Train Loss: 0.2611 Acc: 0.8940 | Val Loss: 0.2649 Acc: 0.8877\n",
      "Epoch 021 | Train Loss: 0.2494 Acc: 0.8975 | Val Loss: 0.2517 Acc: 0.8907\n",
      "Epoch 022 | Train Loss: 0.2406 Acc: 0.8984 | Val Loss: 0.2879 Acc: 0.8792\n",
      "Epoch 023 | Train Loss: 0.2471 Acc: 0.9005 | Val Loss: 0.2864 Acc: 0.8853\n",
      "Epoch 024 | Train Loss: 0.2305 Acc: 0.9070 | Val Loss: 0.2340 Acc: 0.9004\n",
      "Epoch 025 | Train Loss: 0.2261 Acc: 0.9091 | Val Loss: 0.2452 Acc: 0.8955\n",
      "Epoch 026 | Train Loss: 0.2146 Acc: 0.9129 | Val Loss: 0.2293 Acc: 0.9040\n",
      "Epoch 027 | Train Loss: 0.2155 Acc: 0.9144 | Val Loss: 0.2520 Acc: 0.9034\n",
      "Epoch 028 | Train Loss: 0.2066 Acc: 0.9215 | Val Loss: 0.2402 Acc: 0.9100\n",
      "Epoch 029 | Train Loss: 0.1947 Acc: 0.9231 | Val Loss: 0.2323 Acc: 0.9161\n",
      "Epoch 030 | Train Loss: 0.1885 Acc: 0.9269 | Val Loss: 0.2132 Acc: 0.9106\n",
      "Epoch 031 | Train Loss: 0.1799 Acc: 0.9272 | Val Loss: 0.2172 Acc: 0.9112\n",
      "Epoch 032 | Train Loss: 0.1830 Acc: 0.9295 | Val Loss: 0.2350 Acc: 0.8943\n",
      "Epoch 033 | Train Loss: 0.1729 Acc: 0.9325 | Val Loss: 0.2213 Acc: 0.9130\n",
      "Epoch 034 | Train Loss: 0.1698 Acc: 0.9351 | Val Loss: 0.1918 Acc: 0.9209\n",
      "Epoch 035 | Train Loss: 0.1611 Acc: 0.9375 | Val Loss: 0.1983 Acc: 0.9197\n",
      "Epoch 036 | Train Loss: 0.1533 Acc: 0.9413 | Val Loss: 0.2163 Acc: 0.9167\n",
      "Epoch 037 | Train Loss: 0.1511 Acc: 0.9407 | Val Loss: 0.1918 Acc: 0.9275\n",
      "Epoch 038 | Train Loss: 0.1467 Acc: 0.9438 | Val Loss: 0.1906 Acc: 0.9179\n",
      "Epoch 039 | Train Loss: 0.1466 Acc: 0.9413 | Val Loss: 0.2165 Acc: 0.9046\n",
      "Epoch 040 | Train Loss: 0.1512 Acc: 0.9429 | Val Loss: 0.2004 Acc: 0.9209\n",
      "Epoch 041 | Train Loss: 0.1453 Acc: 0.9462 | Val Loss: 0.2420 Acc: 0.8979\n",
      "Epoch 042 | Train Loss: 0.1296 Acc: 0.9523 | Val Loss: 0.1728 Acc: 0.9336\n",
      "Epoch 043 | Train Loss: 0.1344 Acc: 0.9491 | Val Loss: 0.1842 Acc: 0.9251\n",
      "Epoch 044 | Train Loss: 0.1301 Acc: 0.9479 | Val Loss: 0.1874 Acc: 0.9300\n",
      "Epoch 045 | Train Loss: 0.1292 Acc: 0.9484 | Val Loss: 0.2238 Acc: 0.9010\n",
      "Epoch 046 | Train Loss: 0.1309 Acc: 0.9524 | Val Loss: 0.1793 Acc: 0.9300\n",
      "Epoch 047 | Train Loss: 0.1299 Acc: 0.9517 | Val Loss: 0.1844 Acc: 0.9251\n",
      "Epoch 048 | Train Loss: 0.1222 Acc: 0.9544 | Val Loss: 0.1818 Acc: 0.9318\n",
      "Epoch 049 | Train Loss: 0.1198 Acc: 0.9573 | Val Loss: 0.1752 Acc: 0.9384\n",
      "Epoch 050 | Train Loss: 0.1187 Acc: 0.9570 | Val Loss: 0.2317 Acc: 0.9070\n",
      "Epoch 051 | Train Loss: 0.1083 Acc: 0.9612 | Val Loss: 0.1780 Acc: 0.9402\n",
      "Epoch 052 | Train Loss: 0.1125 Acc: 0.9544 | Val Loss: 0.1527 Acc: 0.9438\n",
      "Epoch 053 | Train Loss: 0.1121 Acc: 0.9579 | Val Loss: 0.1663 Acc: 0.9384\n",
      "Epoch 054 | Train Loss: 0.1219 Acc: 0.9555 | Val Loss: 0.1967 Acc: 0.9239\n",
      "Epoch 055 | Train Loss: 0.1189 Acc: 0.9564 | Val Loss: 0.1940 Acc: 0.9263\n",
      "Epoch 056 | Train Loss: 0.1084 Acc: 0.9586 | Val Loss: 0.1677 Acc: 0.9402\n",
      "Epoch 057 | Train Loss: 0.1045 Acc: 0.9595 | Val Loss: 0.2231 Acc: 0.9094\n",
      "Epoch 058 | Train Loss: 0.1003 Acc: 0.9654 | Val Loss: 0.2081 Acc: 0.9336\n",
      "Epoch 059 | Train Loss: 0.1060 Acc: 0.9592 | Val Loss: 0.1582 Acc: 0.9378\n",
      "Epoch 060 | Train Loss: 0.1087 Acc: 0.9577 | Val Loss: 0.1753 Acc: 0.9396\n",
      "Epoch 001 | Train Loss: 0.6845 Acc: 0.5691 | Val Loss: 0.6797 Acc: 0.5833\n",
      "Epoch 002 | Train Loss: 0.6771 Acc: 0.5858 | Val Loss: 0.6690 Acc: 0.5948\n",
      "Epoch 003 | Train Loss: 0.6684 Acc: 0.6014 | Val Loss: 0.6569 Acc: 0.6117\n",
      "Epoch 004 | Train Loss: 0.6605 Acc: 0.6144 | Val Loss: 0.6704 Acc: 0.5888\n",
      "Epoch 005 | Train Loss: 0.6287 Acc: 0.6637 | Val Loss: 0.5930 Acc: 0.6920\n",
      "Epoch 006 | Train Loss: 0.5889 Acc: 0.7062 | Val Loss: 0.5831 Acc: 0.7023\n",
      "Epoch 007 | Train Loss: 0.5630 Acc: 0.7287 | Val Loss: 0.5628 Acc: 0.7186\n",
      "Epoch 008 | Train Loss: 0.5645 Acc: 0.7205 | Val Loss: 0.5611 Acc: 0.7005\n",
      "Epoch 009 | Train Loss: 0.5474 Acc: 0.7303 | Val Loss: 0.5350 Acc: 0.7258\n",
      "Epoch 010 | Train Loss: 0.5398 Acc: 0.7337 | Val Loss: 0.5331 Acc: 0.7421\n",
      "Epoch 011 | Train Loss: 0.5312 Acc: 0.7420 | Val Loss: 0.5136 Acc: 0.7494\n",
      "Epoch 012 | Train Loss: 0.5227 Acc: 0.7489 | Val Loss: 0.5207 Acc: 0.7446\n",
      "Epoch 013 | Train Loss: 0.5112 Acc: 0.7545 | Val Loss: 0.5369 Acc: 0.7355\n",
      "Epoch 014 | Train Loss: 0.5203 Acc: 0.7512 | Val Loss: 0.5033 Acc: 0.7560\n",
      "Epoch 015 | Train Loss: 0.5056 Acc: 0.7604 | Val Loss: 0.4940 Acc: 0.7579\n",
      "Epoch 016 | Train Loss: 0.4984 Acc: 0.7607 | Val Loss: 0.4877 Acc: 0.7675\n",
      "Epoch 017 | Train Loss: 0.4951 Acc: 0.7673 | Val Loss: 0.4779 Acc: 0.7657\n",
      "Epoch 018 | Train Loss: 0.4815 Acc: 0.7702 | Val Loss: 0.4752 Acc: 0.7669\n",
      "Epoch 019 | Train Loss: 0.4716 Acc: 0.7802 | Val Loss: 0.4523 Acc: 0.7796\n",
      "Epoch 020 | Train Loss: 0.4626 Acc: 0.7823 | Val Loss: 0.4847 Acc: 0.7675\n",
      "Epoch 021 | Train Loss: 0.4582 Acc: 0.7895 | Val Loss: 0.4454 Acc: 0.7886\n",
      "Epoch 022 | Train Loss: 0.4365 Acc: 0.7959 | Val Loss: 0.4322 Acc: 0.7941\n",
      "Epoch 023 | Train Loss: 0.4491 Acc: 0.7954 | Val Loss: 0.4295 Acc: 0.7995\n",
      "Epoch 024 | Train Loss: 0.4301 Acc: 0.8066 | Val Loss: 0.4175 Acc: 0.8152\n",
      "Epoch 025 | Train Loss: 0.4214 Acc: 0.8104 | Val Loss: 0.4207 Acc: 0.8146\n",
      "Epoch 026 | Train Loss: 0.4045 Acc: 0.8188 | Val Loss: 0.3999 Acc: 0.8170\n",
      "Epoch 027 | Train Loss: 0.3999 Acc: 0.8217 | Val Loss: 0.3926 Acc: 0.8098\n",
      "Epoch 028 | Train Loss: 0.3854 Acc: 0.8256 | Val Loss: 0.3562 Acc: 0.8484\n",
      "Epoch 029 | Train Loss: 0.3871 Acc: 0.8310 | Val Loss: 0.4080 Acc: 0.8128\n",
      "Epoch 030 | Train Loss: 0.3793 Acc: 0.8362 | Val Loss: 0.3565 Acc: 0.8460\n",
      "Epoch 031 | Train Loss: 0.3636 Acc: 0.8416 | Val Loss: 0.3632 Acc: 0.8472\n",
      "Epoch 032 | Train Loss: 0.3567 Acc: 0.8413 | Val Loss: 0.3503 Acc: 0.8508\n",
      "Epoch 033 | Train Loss: 0.3616 Acc: 0.8437 | Val Loss: 0.3781 Acc: 0.8418\n",
      "Epoch 034 | Train Loss: 0.3419 Acc: 0.8537 | Val Loss: 0.3248 Acc: 0.8659\n",
      "Epoch 035 | Train Loss: 0.3410 Acc: 0.8593 | Val Loss: 0.3300 Acc: 0.8641\n",
      "Epoch 036 | Train Loss: 0.3354 Acc: 0.8569 | Val Loss: 0.3225 Acc: 0.8629\n",
      "Epoch 037 | Train Loss: 0.3176 Acc: 0.8618 | Val Loss: 0.3010 Acc: 0.8726\n",
      "Epoch 038 | Train Loss: 0.3228 Acc: 0.8644 | Val Loss: 0.3205 Acc: 0.8696\n",
      "Epoch 039 | Train Loss: 0.3122 Acc: 0.8723 | Val Loss: 0.2974 Acc: 0.8780\n",
      "Epoch 040 | Train Loss: 0.3086 Acc: 0.8685 | Val Loss: 0.2764 Acc: 0.8865\n",
      "Epoch 041 | Train Loss: 0.3022 Acc: 0.8744 | Val Loss: 0.2822 Acc: 0.8810\n",
      "Epoch 042 | Train Loss: 0.3052 Acc: 0.8759 | Val Loss: 0.3025 Acc: 0.8738\n",
      "Epoch 043 | Train Loss: 0.3017 Acc: 0.8748 | Val Loss: 0.2900 Acc: 0.8907\n",
      "Epoch 044 | Train Loss: 0.3043 Acc: 0.8748 | Val Loss: 0.3088 Acc: 0.8798\n",
      "Epoch 045 | Train Loss: 0.2930 Acc: 0.8806 | Val Loss: 0.2814 Acc: 0.8877\n",
      "Epoch 046 | Train Loss: 0.2821 Acc: 0.8839 | Val Loss: 0.2771 Acc: 0.8847\n",
      "Epoch 047 | Train Loss: 0.2799 Acc: 0.8862 | Val Loss: 0.2882 Acc: 0.8780\n",
      "Epoch 048 | Train Loss: 0.2775 Acc: 0.8871 | Val Loss: 0.2523 Acc: 0.8986\n",
      "Epoch 049 | Train Loss: 0.2747 Acc: 0.8863 | Val Loss: 0.2865 Acc: 0.8835\n",
      "Epoch 050 | Train Loss: 0.2765 Acc: 0.8914 | Val Loss: 0.2849 Acc: 0.8816\n",
      "Epoch 051 | Train Loss: 0.2855 Acc: 0.8843 | Val Loss: 0.2598 Acc: 0.8986\n",
      "Epoch 052 | Train Loss: 0.2792 Acc: 0.8872 | Val Loss: 0.2619 Acc: 0.8895\n",
      "Epoch 053 | Train Loss: 0.2731 Acc: 0.8908 | Val Loss: 0.2485 Acc: 0.8998\n",
      "Epoch 054 | Train Loss: 0.2631 Acc: 0.8946 | Val Loss: 0.2464 Acc: 0.9028\n",
      "Epoch 055 | Train Loss: 0.2616 Acc: 0.8985 | Val Loss: 0.2550 Acc: 0.8979\n",
      "Epoch 056 | Train Loss: 0.2547 Acc: 0.8964 | Val Loss: 0.2580 Acc: 0.8961\n",
      "Epoch 057 | Train Loss: 0.2671 Acc: 0.8954 | Val Loss: 0.2734 Acc: 0.8859\n",
      "Epoch 058 | Train Loss: 0.2536 Acc: 0.8951 | Val Loss: 0.2780 Acc: 0.8901\n",
      "Epoch 059 | Train Loss: 0.2567 Acc: 0.9026 | Val Loss: 0.2460 Acc: 0.9028\n",
      "Epoch 060 | Train Loss: 0.2403 Acc: 0.9026 | Val Loss: 0.2622 Acc: 0.8901\n",
      "Iteration 5/40 | Best Val Loss: 0.1394 | Iter Time: 251.19s | Total Time: 27.25 min\n",
      "Epoch 001 | Train Loss: 0.6821 Acc: 0.5762 | Val Loss: 0.6756 Acc: 0.5924\n",
      "Epoch 002 | Train Loss: 0.6615 Acc: 0.6089 | Val Loss: 0.6305 Acc: 0.6739\n",
      "Epoch 003 | Train Loss: 0.5908 Acc: 0.6997 | Val Loss: 0.5891 Acc: 0.7071\n",
      "Epoch 004 | Train Loss: 0.5506 Acc: 0.7335 | Val Loss: 0.5534 Acc: 0.7258\n",
      "Epoch 005 | Train Loss: 0.5241 Acc: 0.7453 | Val Loss: 0.5139 Acc: 0.7428\n",
      "Epoch 006 | Train Loss: 0.4972 Acc: 0.7654 | Val Loss: 0.5102 Acc: 0.7440\n",
      "Epoch 007 | Train Loss: 0.4719 Acc: 0.7794 | Val Loss: 0.4586 Acc: 0.7784\n",
      "Epoch 008 | Train Loss: 0.4511 Acc: 0.7900 | Val Loss: 0.4120 Acc: 0.8086\n",
      "Epoch 009 | Train Loss: 0.4093 Acc: 0.8179 | Val Loss: 0.4033 Acc: 0.8128\n",
      "Epoch 010 | Train Loss: 0.3906 Acc: 0.8261 | Val Loss: 0.3832 Acc: 0.8207\n",
      "Epoch 011 | Train Loss: 0.3635 Acc: 0.8390 | Val Loss: 0.3627 Acc: 0.8273\n",
      "Epoch 012 | Train Loss: 0.3323 Acc: 0.8618 | Val Loss: 0.3318 Acc: 0.8539\n",
      "Epoch 013 | Train Loss: 0.3117 Acc: 0.8673 | Val Loss: 0.2932 Acc: 0.8750\n",
      "Epoch 014 | Train Loss: 0.2834 Acc: 0.8821 | Val Loss: 0.2903 Acc: 0.8768\n",
      "Epoch 015 | Train Loss: 0.2683 Acc: 0.8883 | Val Loss: 0.2859 Acc: 0.8883\n",
      "Epoch 016 | Train Loss: 0.2589 Acc: 0.8952 | Val Loss: 0.2747 Acc: 0.8810\n",
      "Epoch 017 | Train Loss: 0.2309 Acc: 0.9047 | Val Loss: 0.2380 Acc: 0.9112\n",
      "Epoch 018 | Train Loss: 0.2301 Acc: 0.9127 | Val Loss: 0.2581 Acc: 0.8943\n",
      "Epoch 019 | Train Loss: 0.1993 Acc: 0.9195 | Val Loss: 0.2376 Acc: 0.9100\n",
      "Epoch 020 | Train Loss: 0.1955 Acc: 0.9281 | Val Loss: 0.2228 Acc: 0.9155\n",
      "Epoch 021 | Train Loss: 0.1711 Acc: 0.9384 | Val Loss: 0.2251 Acc: 0.9143\n",
      "Epoch 022 | Train Loss: 0.1690 Acc: 0.9336 | Val Loss: 0.2090 Acc: 0.9227\n",
      "Epoch 023 | Train Loss: 0.1681 Acc: 0.9340 | Val Loss: 0.2497 Acc: 0.9143\n",
      "Epoch 024 | Train Loss: 0.1530 Acc: 0.9401 | Val Loss: 0.2300 Acc: 0.9118\n",
      "Epoch 025 | Train Loss: 0.1512 Acc: 0.9419 | Val Loss: 0.2243 Acc: 0.9143\n",
      "Epoch 026 | Train Loss: 0.1338 Acc: 0.9532 | Val Loss: 0.2608 Acc: 0.9010\n",
      "Epoch 027 | Train Loss: 0.1431 Acc: 0.9475 | Val Loss: 0.1979 Acc: 0.9300\n",
      "Epoch 028 | Train Loss: 0.1232 Acc: 0.9535 | Val Loss: 0.2376 Acc: 0.9149\n",
      "Epoch 029 | Train Loss: 0.1185 Acc: 0.9532 | Val Loss: 0.2191 Acc: 0.9221\n",
      "Epoch 030 | Train Loss: 0.1219 Acc: 0.9549 | Val Loss: 0.2183 Acc: 0.9185\n",
      "Epoch 031 | Train Loss: 0.1114 Acc: 0.9591 | Val Loss: 0.2026 Acc: 0.9239\n",
      "Epoch 032 | Train Loss: 0.1105 Acc: 0.9576 | Val Loss: 0.1775 Acc: 0.9312\n",
      "Epoch 033 | Train Loss: 0.1156 Acc: 0.9576 | Val Loss: 0.2187 Acc: 0.9191\n",
      "Epoch 034 | Train Loss: 0.1016 Acc: 0.9609 | Val Loss: 0.2193 Acc: 0.9245\n",
      "Epoch 035 | Train Loss: 0.1130 Acc: 0.9571 | Val Loss: 0.1977 Acc: 0.9300\n",
      "Epoch 036 | Train Loss: 0.1013 Acc: 0.9656 | Val Loss: 0.1982 Acc: 0.9281\n",
      "Epoch 037 | Train Loss: 0.1017 Acc: 0.9620 | Val Loss: 0.2117 Acc: 0.9269\n",
      "Epoch 038 | Train Loss: 0.0901 Acc: 0.9642 | Val Loss: 0.2110 Acc: 0.9318\n",
      "Epoch 039 | Train Loss: 0.0858 Acc: 0.9674 | Val Loss: 0.2360 Acc: 0.9251\n",
      "Epoch 040 | Train Loss: 0.0931 Acc: 0.9653 | Val Loss: 0.2141 Acc: 0.9227\n",
      "Epoch 041 | Train Loss: 0.0929 Acc: 0.9654 | Val Loss: 0.2292 Acc: 0.9221\n",
      "Epoch 042 | Train Loss: 0.0851 Acc: 0.9687 | Val Loss: 0.1769 Acc: 0.9366\n",
      "Epoch 043 | Train Loss: 0.0856 Acc: 0.9678 | Val Loss: 0.2235 Acc: 0.9336\n",
      "Epoch 044 | Train Loss: 0.0856 Acc: 0.9698 | Val Loss: 0.1886 Acc: 0.9378\n",
      "Epoch 045 | Train Loss: 0.0728 Acc: 0.9745 | Val Loss: 0.1913 Acc: 0.9324\n",
      "Epoch 046 | Train Loss: 0.0830 Acc: 0.9700 | Val Loss: 0.2289 Acc: 0.9251\n",
      "Epoch 047 | Train Loss: 0.0675 Acc: 0.9757 | Val Loss: 0.1893 Acc: 0.9366\n",
      "Epoch 048 | Train Loss: 0.0785 Acc: 0.9731 | Val Loss: 0.1790 Acc: 0.9384\n",
      "Epoch 049 | Train Loss: 0.0735 Acc: 0.9748 | Val Loss: 0.1827 Acc: 0.9342\n",
      "Epoch 050 | Train Loss: 0.0795 Acc: 0.9719 | Val Loss: 0.1697 Acc: 0.9402\n",
      "Epoch 051 | Train Loss: 0.0762 Acc: 0.9751 | Val Loss: 0.2088 Acc: 0.9281\n",
      "Epoch 052 | Train Loss: 0.0775 Acc: 0.9712 | Val Loss: 0.1804 Acc: 0.9384\n",
      "Epoch 053 | Train Loss: 0.0657 Acc: 0.9749 | Val Loss: 0.2304 Acc: 0.9293\n",
      "Epoch 054 | Train Loss: 0.0671 Acc: 0.9749 | Val Loss: 0.2068 Acc: 0.9348\n",
      "Epoch 055 | Train Loss: 0.0793 Acc: 0.9721 | Val Loss: 0.1701 Acc: 0.9348\n",
      "Epoch 056 | Train Loss: 0.0737 Acc: 0.9751 | Val Loss: 0.1947 Acc: 0.9348\n",
      "Epoch 057 | Train Loss: 0.0576 Acc: 0.9790 | Val Loss: 0.2267 Acc: 0.9366\n",
      "Epoch 058 | Train Loss: 0.0653 Acc: 0.9752 | Val Loss: 0.2046 Acc: 0.9318\n",
      "Epoch 059 | Train Loss: 0.0639 Acc: 0.9775 | Val Loss: 0.1725 Acc: 0.9384\n",
      "Epoch 060 | Train Loss: 0.0688 Acc: 0.9742 | Val Loss: 0.2223 Acc: 0.9306\n",
      "Early stopping triggered.\n",
      "Epoch 001 | Train Loss: 0.6815 Acc: 0.5727 | Val Loss: 0.6821 Acc: 0.5731\n",
      "Epoch 002 | Train Loss: 0.6750 Acc: 0.5916 | Val Loss: 0.6725 Acc: 0.5888\n",
      "Epoch 003 | Train Loss: 0.6670 Acc: 0.6005 | Val Loss: 0.6788 Acc: 0.5737\n",
      "Epoch 004 | Train Loss: 0.6767 Acc: 0.5775 | Val Loss: 0.6636 Acc: 0.5984\n",
      "Epoch 005 | Train Loss: 0.6370 Acc: 0.6432 | Val Loss: 0.6437 Acc: 0.6461\n",
      "Epoch 006 | Train Loss: 0.6091 Acc: 0.6868 | Val Loss: 0.5951 Acc: 0.6836\n",
      "Epoch 007 | Train Loss: 0.5725 Acc: 0.7098 | Val Loss: 0.5705 Acc: 0.7035\n",
      "Epoch 008 | Train Loss: 0.5584 Acc: 0.7252 | Val Loss: 0.5705 Acc: 0.7101\n",
      "Epoch 009 | Train Loss: 0.5387 Acc: 0.7337 | Val Loss: 0.5382 Acc: 0.7264\n",
      "Epoch 010 | Train Loss: 0.5247 Acc: 0.7411 | Val Loss: 0.5239 Acc: 0.7361\n",
      "Epoch 011 | Train Loss: 0.5145 Acc: 0.7503 | Val Loss: 0.5286 Acc: 0.7500\n",
      "Epoch 012 | Train Loss: 0.4929 Acc: 0.7661 | Val Loss: 0.5053 Acc: 0.7560\n",
      "Epoch 013 | Train Loss: 0.4823 Acc: 0.7729 | Val Loss: 0.4764 Acc: 0.7766\n",
      "Epoch 014 | Train Loss: 0.4570 Acc: 0.7930 | Val Loss: 0.4583 Acc: 0.7802\n",
      "Epoch 015 | Train Loss: 0.4360 Acc: 0.7974 | Val Loss: 0.4637 Acc: 0.7802\n",
      "Epoch 016 | Train Loss: 0.4050 Acc: 0.8187 | Val Loss: 0.4227 Acc: 0.8025\n",
      "Epoch 017 | Train Loss: 0.3921 Acc: 0.8259 | Val Loss: 0.4077 Acc: 0.8062\n",
      "Epoch 018 | Train Loss: 0.3667 Acc: 0.8387 | Val Loss: 0.4854 Acc: 0.7868\n",
      "Epoch 019 | Train Loss: 0.3539 Acc: 0.8499 | Val Loss: 0.3643 Acc: 0.8339\n",
      "Epoch 020 | Train Loss: 0.3270 Acc: 0.8609 | Val Loss: 0.3395 Acc: 0.8569\n",
      "Epoch 021 | Train Loss: 0.3007 Acc: 0.8748 | Val Loss: 0.3125 Acc: 0.8647\n",
      "Epoch 022 | Train Loss: 0.2858 Acc: 0.8782 | Val Loss: 0.3067 Acc: 0.8714\n",
      "Epoch 023 | Train Loss: 0.2691 Acc: 0.8890 | Val Loss: 0.2903 Acc: 0.8738\n",
      "Epoch 024 | Train Loss: 0.2613 Acc: 0.8928 | Val Loss: 0.3032 Acc: 0.8702\n",
      "Epoch 025 | Train Loss: 0.2418 Acc: 0.8973 | Val Loss: 0.3024 Acc: 0.8756\n",
      "Epoch 026 | Train Loss: 0.2315 Acc: 0.9053 | Val Loss: 0.2966 Acc: 0.8810\n",
      "Epoch 027 | Train Loss: 0.2152 Acc: 0.9090 | Val Loss: 0.2754 Acc: 0.8822\n",
      "Epoch 028 | Train Loss: 0.1943 Acc: 0.9230 | Val Loss: 0.2501 Acc: 0.9052\n",
      "Epoch 029 | Train Loss: 0.2014 Acc: 0.9194 | Val Loss: 0.3022 Acc: 0.8816\n",
      "Epoch 030 | Train Loss: 0.1859 Acc: 0.9272 | Val Loss: 0.2521 Acc: 0.9046\n",
      "Epoch 031 | Train Loss: 0.1735 Acc: 0.9311 | Val Loss: 0.2239 Acc: 0.9130\n",
      "Epoch 032 | Train Loss: 0.1883 Acc: 0.9268 | Val Loss: 0.2745 Acc: 0.8913\n",
      "Epoch 033 | Train Loss: 0.1614 Acc: 0.9363 | Val Loss: 0.2155 Acc: 0.9179\n",
      "Epoch 034 | Train Loss: 0.1525 Acc: 0.9413 | Val Loss: 0.2409 Acc: 0.9100\n",
      "Epoch 035 | Train Loss: 0.1427 Acc: 0.9443 | Val Loss: 0.2282 Acc: 0.9052\n",
      "Epoch 036 | Train Loss: 0.1376 Acc: 0.9485 | Val Loss: 0.2480 Acc: 0.9179\n",
      "Epoch 037 | Train Loss: 0.1377 Acc: 0.9476 | Val Loss: 0.2152 Acc: 0.9263\n",
      "Epoch 038 | Train Loss: 0.1370 Acc: 0.9453 | Val Loss: 0.2151 Acc: 0.9287\n",
      "Epoch 039 | Train Loss: 0.1357 Acc: 0.9461 | Val Loss: 0.2199 Acc: 0.9209\n",
      "Epoch 040 | Train Loss: 0.1127 Acc: 0.9580 | Val Loss: 0.2602 Acc: 0.9076\n",
      "Epoch 041 | Train Loss: 0.1174 Acc: 0.9555 | Val Loss: 0.2527 Acc: 0.9185\n",
      "Epoch 042 | Train Loss: 0.0980 Acc: 0.9616 | Val Loss: 0.1978 Acc: 0.9306\n",
      "Epoch 043 | Train Loss: 0.0987 Acc: 0.9642 | Val Loss: 0.2081 Acc: 0.9318\n",
      "Epoch 044 | Train Loss: 0.0889 Acc: 0.9660 | Val Loss: 0.2356 Acc: 0.9245\n",
      "Epoch 045 | Train Loss: 0.0966 Acc: 0.9642 | Val Loss: 0.2043 Acc: 0.9281\n",
      "Epoch 046 | Train Loss: 0.0946 Acc: 0.9657 | Val Loss: 0.2001 Acc: 0.9372\n",
      "Epoch 047 | Train Loss: 0.0804 Acc: 0.9707 | Val Loss: 0.2102 Acc: 0.9312\n",
      "Epoch 048 | Train Loss: 0.0858 Acc: 0.9681 | Val Loss: 0.2394 Acc: 0.9173\n",
      "Epoch 049 | Train Loss: 0.0955 Acc: 0.9641 | Val Loss: 0.2014 Acc: 0.9318\n",
      "Epoch 050 | Train Loss: 0.0766 Acc: 0.9697 | Val Loss: 0.1952 Acc: 0.9269\n",
      "Epoch 051 | Train Loss: 0.0746 Acc: 0.9742 | Val Loss: 0.2415 Acc: 0.9179\n",
      "Epoch 052 | Train Loss: 0.0724 Acc: 0.9733 | Val Loss: 0.2229 Acc: 0.9312\n",
      "Epoch 053 | Train Loss: 0.0637 Acc: 0.9761 | Val Loss: 0.2191 Acc: 0.9293\n",
      "Epoch 054 | Train Loss: 0.0815 Acc: 0.9724 | Val Loss: 0.1850 Acc: 0.9396\n",
      "Epoch 055 | Train Loss: 0.0652 Acc: 0.9781 | Val Loss: 0.2465 Acc: 0.9203\n",
      "Epoch 056 | Train Loss: 0.0786 Acc: 0.9704 | Val Loss: 0.2257 Acc: 0.9306\n",
      "Epoch 057 | Train Loss: 0.0659 Acc: 0.9754 | Val Loss: 0.1978 Acc: 0.9372\n",
      "Epoch 058 | Train Loss: 0.0565 Acc: 0.9790 | Val Loss: 0.1925 Acc: 0.9348\n",
      "Epoch 059 | Train Loss: 0.0575 Acc: 0.9778 | Val Loss: 0.1825 Acc: 0.9378\n",
      "Epoch 060 | Train Loss: 0.0588 Acc: 0.9780 | Val Loss: 0.2367 Acc: 0.9300\n",
      "Epoch 001 | Train Loss: 0.6808 Acc: 0.5750 | Val Loss: 0.6702 Acc: 0.5876\n",
      "Epoch 002 | Train Loss: 0.6499 Acc: 0.6325 | Val Loss: 0.6151 Acc: 0.6727\n",
      "Epoch 003 | Train Loss: 0.5846 Acc: 0.7036 | Val Loss: 0.5753 Acc: 0.7023\n",
      "Epoch 004 | Train Loss: 0.5496 Acc: 0.7243 | Val Loss: 0.5573 Acc: 0.7198\n",
      "Epoch 005 | Train Loss: 0.5244 Acc: 0.7427 | Val Loss: 0.5486 Acc: 0.7264\n",
      "Epoch 006 | Train Loss: 0.5014 Acc: 0.7587 | Val Loss: 0.5231 Acc: 0.7385\n",
      "Epoch 007 | Train Loss: 0.4771 Acc: 0.7722 | Val Loss: 0.4624 Acc: 0.7796\n",
      "Epoch 008 | Train Loss: 0.4427 Acc: 0.7950 | Val Loss: 0.4431 Acc: 0.7983\n",
      "Epoch 009 | Train Loss: 0.4184 Acc: 0.8070 | Val Loss: 0.3956 Acc: 0.8158\n",
      "Epoch 010 | Train Loss: 0.3841 Acc: 0.8262 | Val Loss: 0.3595 Acc: 0.8321\n",
      "Epoch 011 | Train Loss: 0.3561 Acc: 0.8431 | Val Loss: 0.3516 Acc: 0.8388\n",
      "Epoch 012 | Train Loss: 0.3289 Acc: 0.8561 | Val Loss: 0.3421 Acc: 0.8496\n",
      "Epoch 013 | Train Loss: 0.3067 Acc: 0.8718 | Val Loss: 0.3328 Acc: 0.8539\n",
      "Epoch 014 | Train Loss: 0.2820 Acc: 0.8831 | Val Loss: 0.2784 Acc: 0.8835\n",
      "Epoch 015 | Train Loss: 0.2496 Acc: 0.8966 | Val Loss: 0.3565 Acc: 0.8557\n",
      "Epoch 016 | Train Loss: 0.2541 Acc: 0.8957 | Val Loss: 0.2546 Acc: 0.9010\n",
      "Epoch 017 | Train Loss: 0.2269 Acc: 0.9108 | Val Loss: 0.2706 Acc: 0.8937\n",
      "Epoch 018 | Train Loss: 0.2155 Acc: 0.9136 | Val Loss: 0.2491 Acc: 0.8937\n",
      "Epoch 019 | Train Loss: 0.1881 Acc: 0.9281 | Val Loss: 0.2050 Acc: 0.9233\n",
      "Epoch 020 | Train Loss: 0.1890 Acc: 0.9278 | Val Loss: 0.2163 Acc: 0.9130\n",
      "Epoch 021 | Train Loss: 0.1832 Acc: 0.9266 | Val Loss: 0.2430 Acc: 0.9076\n",
      "Epoch 022 | Train Loss: 0.1790 Acc: 0.9318 | Val Loss: 0.2215 Acc: 0.9064\n",
      "Epoch 023 | Train Loss: 0.1620 Acc: 0.9342 | Val Loss: 0.2219 Acc: 0.9052\n",
      "Epoch 024 | Train Loss: 0.1524 Acc: 0.9429 | Val Loss: 0.2122 Acc: 0.9263\n",
      "Epoch 025 | Train Loss: 0.1432 Acc: 0.9423 | Val Loss: 0.2092 Acc: 0.9191\n",
      "Epoch 026 | Train Loss: 0.1302 Acc: 0.9506 | Val Loss: 0.1932 Acc: 0.9269\n",
      "Epoch 027 | Train Loss: 0.1324 Acc: 0.9506 | Val Loss: 0.1866 Acc: 0.9269\n",
      "Epoch 028 | Train Loss: 0.1240 Acc: 0.9523 | Val Loss: 0.1741 Acc: 0.9372\n",
      "Epoch 029 | Train Loss: 0.1235 Acc: 0.9514 | Val Loss: 0.1774 Acc: 0.9324\n",
      "Epoch 030 | Train Loss: 0.1157 Acc: 0.9536 | Val Loss: 0.1825 Acc: 0.9318\n",
      "Epoch 031 | Train Loss: 0.1112 Acc: 0.9580 | Val Loss: 0.2318 Acc: 0.9239\n",
      "Epoch 032 | Train Loss: 0.1076 Acc: 0.9588 | Val Loss: 0.2038 Acc: 0.9263\n",
      "Epoch 033 | Train Loss: 0.0976 Acc: 0.9618 | Val Loss: 0.1869 Acc: 0.9300\n",
      "Epoch 034 | Train Loss: 0.0989 Acc: 0.9624 | Val Loss: 0.2303 Acc: 0.9124\n",
      "Epoch 035 | Train Loss: 0.1109 Acc: 0.9592 | Val Loss: 0.1811 Acc: 0.9390\n",
      "Epoch 036 | Train Loss: 0.0851 Acc: 0.9677 | Val Loss: 0.2152 Acc: 0.9330\n",
      "Epoch 037 | Train Loss: 0.0887 Acc: 0.9672 | Val Loss: 0.1778 Acc: 0.9306\n",
      "Epoch 038 | Train Loss: 0.0946 Acc: 0.9644 | Val Loss: 0.2200 Acc: 0.9251\n",
      "Early stopping triggered.\n",
      "Epoch 001 | Train Loss: 0.6800 Acc: 0.5751 | Val Loss: 0.6759 Acc: 0.5900\n",
      "Epoch 002 | Train Loss: 0.6750 Acc: 0.5867 | Val Loss: 0.6731 Acc: 0.5888\n",
      "Epoch 003 | Train Loss: 0.6617 Acc: 0.6067 | Val Loss: 0.6540 Acc: 0.6002\n",
      "Epoch 004 | Train Loss: 0.6306 Acc: 0.6568 | Val Loss: 0.6139 Acc: 0.6655\n",
      "Epoch 005 | Train Loss: 0.5937 Acc: 0.7018 | Val Loss: 0.6045 Acc: 0.6896\n",
      "Epoch 006 | Train Loss: 0.5641 Acc: 0.7196 | Val Loss: 0.5566 Acc: 0.7156\n",
      "Epoch 007 | Train Loss: 0.5447 Acc: 0.7392 | Val Loss: 0.5514 Acc: 0.7240\n",
      "Epoch 008 | Train Loss: 0.5323 Acc: 0.7439 | Val Loss: 0.5518 Acc: 0.7204\n",
      "Epoch 009 | Train Loss: 0.5103 Acc: 0.7581 | Val Loss: 0.5297 Acc: 0.7415\n",
      "Epoch 010 | Train Loss: 0.4937 Acc: 0.7623 | Val Loss: 0.5081 Acc: 0.7579\n",
      "Epoch 011 | Train Loss: 0.4792 Acc: 0.7765 | Val Loss: 0.4827 Acc: 0.7639\n",
      "Epoch 012 | Train Loss: 0.4564 Acc: 0.7868 | Val Loss: 0.4565 Acc: 0.7886\n",
      "Epoch 013 | Train Loss: 0.4303 Acc: 0.7998 | Val Loss: 0.4663 Acc: 0.7826\n",
      "Epoch 014 | Train Loss: 0.4216 Acc: 0.8010 | Val Loss: 0.4582 Acc: 0.7778\n",
      "Epoch 015 | Train Loss: 0.4103 Acc: 0.8067 | Val Loss: 0.4067 Acc: 0.8074\n",
      "Epoch 016 | Train Loss: 0.3829 Acc: 0.8282 | Val Loss: 0.4421 Acc: 0.7820\n",
      "Epoch 017 | Train Loss: 0.3662 Acc: 0.8285 | Val Loss: 0.3752 Acc: 0.8285\n",
      "Epoch 018 | Train Loss: 0.3460 Acc: 0.8439 | Val Loss: 0.3439 Acc: 0.8345\n",
      "Epoch 019 | Train Loss: 0.3355 Acc: 0.8528 | Val Loss: 0.4113 Acc: 0.8098\n",
      "Epoch 020 | Train Loss: 0.3090 Acc: 0.8647 | Val Loss: 0.3612 Acc: 0.8351\n",
      "Epoch 021 | Train Loss: 0.2934 Acc: 0.8732 | Val Loss: 0.3438 Acc: 0.8472\n",
      "Epoch 022 | Train Loss: 0.2731 Acc: 0.8862 | Val Loss: 0.3057 Acc: 0.8641\n",
      "Epoch 023 | Train Loss: 0.2695 Acc: 0.8872 | Val Loss: 0.2672 Acc: 0.8822\n",
      "Epoch 024 | Train Loss: 0.2571 Acc: 0.8926 | Val Loss: 0.2542 Acc: 0.8949\n",
      "Epoch 025 | Train Loss: 0.2423 Acc: 0.9000 | Val Loss: 0.2539 Acc: 0.8907\n",
      "Epoch 026 | Train Loss: 0.2270 Acc: 0.9071 | Val Loss: 0.2962 Acc: 0.8708\n",
      "Epoch 027 | Train Loss: 0.2266 Acc: 0.9073 | Val Loss: 0.2540 Acc: 0.8907\n",
      "Epoch 028 | Train Loss: 0.2208 Acc: 0.9080 | Val Loss: 0.2427 Acc: 0.8949\n",
      "Epoch 029 | Train Loss: 0.1965 Acc: 0.9165 | Val Loss: 0.2541 Acc: 0.8901\n",
      "Epoch 030 | Train Loss: 0.2013 Acc: 0.9173 | Val Loss: 0.2082 Acc: 0.9167\n",
      "Epoch 031 | Train Loss: 0.1870 Acc: 0.9257 | Val Loss: 0.2130 Acc: 0.9100\n",
      "Epoch 032 | Train Loss: 0.1875 Acc: 0.9271 | Val Loss: 0.2436 Acc: 0.9040\n",
      "Epoch 033 | Train Loss: 0.1770 Acc: 0.9307 | Val Loss: 0.2015 Acc: 0.9130\n",
      "Epoch 034 | Train Loss: 0.1685 Acc: 0.9349 | Val Loss: 0.1930 Acc: 0.9191\n",
      "Epoch 035 | Train Loss: 0.1670 Acc: 0.9345 | Val Loss: 0.1888 Acc: 0.9209\n",
      "Epoch 036 | Train Loss: 0.1575 Acc: 0.9395 | Val Loss: 0.1953 Acc: 0.9197\n",
      "Epoch 037 | Train Loss: 0.1487 Acc: 0.9431 | Val Loss: 0.2227 Acc: 0.9100\n",
      "Epoch 038 | Train Loss: 0.1374 Acc: 0.9473 | Val Loss: 0.2117 Acc: 0.9203\n",
      "Epoch 039 | Train Loss: 0.1450 Acc: 0.9407 | Val Loss: 0.1670 Acc: 0.9269\n",
      "Epoch 040 | Train Loss: 0.1353 Acc: 0.9465 | Val Loss: 0.1790 Acc: 0.9336\n",
      "Epoch 041 | Train Loss: 0.1338 Acc: 0.9478 | Val Loss: 0.1720 Acc: 0.9342\n",
      "Epoch 042 | Train Loss: 0.1230 Acc: 0.9512 | Val Loss: 0.2330 Acc: 0.9082\n",
      "Epoch 043 | Train Loss: 0.1317 Acc: 0.9472 | Val Loss: 0.1772 Acc: 0.9245\n",
      "Epoch 044 | Train Loss: 0.1191 Acc: 0.9494 | Val Loss: 0.1949 Acc: 0.9257\n",
      "Epoch 045 | Train Loss: 0.1171 Acc: 0.9555 | Val Loss: 0.1667 Acc: 0.9312\n",
      "Epoch 046 | Train Loss: 0.1180 Acc: 0.9524 | Val Loss: 0.1625 Acc: 0.9336\n",
      "Epoch 047 | Train Loss: 0.1124 Acc: 0.9544 | Val Loss: 0.1833 Acc: 0.9257\n",
      "Epoch 048 | Train Loss: 0.1176 Acc: 0.9529 | Val Loss: 0.1583 Acc: 0.9330\n",
      "Epoch 049 | Train Loss: 0.1058 Acc: 0.9595 | Val Loss: 0.1686 Acc: 0.9336\n",
      "Epoch 050 | Train Loss: 0.1081 Acc: 0.9568 | Val Loss: 0.1720 Acc: 0.9263\n",
      "Epoch 051 | Train Loss: 0.0990 Acc: 0.9601 | Val Loss: 0.1850 Acc: 0.9324\n",
      "Epoch 052 | Train Loss: 0.0951 Acc: 0.9636 | Val Loss: 0.1516 Acc: 0.9444\n",
      "Epoch 053 | Train Loss: 0.0876 Acc: 0.9675 | Val Loss: 0.1512 Acc: 0.9444\n",
      "Epoch 054 | Train Loss: 0.0984 Acc: 0.9620 | Val Loss: 0.1475 Acc: 0.9457\n",
      "Epoch 055 | Train Loss: 0.0882 Acc: 0.9662 | Val Loss: 0.1721 Acc: 0.9420\n",
      "Epoch 056 | Train Loss: 0.0941 Acc: 0.9632 | Val Loss: 0.1610 Acc: 0.9372\n",
      "Epoch 057 | Train Loss: 0.0969 Acc: 0.9641 | Val Loss: 0.2110 Acc: 0.9173\n",
      "Epoch 058 | Train Loss: 0.0871 Acc: 0.9675 | Val Loss: 0.1595 Acc: 0.9463\n",
      "Epoch 059 | Train Loss: 0.0845 Acc: 0.9681 | Val Loss: 0.1509 Acc: 0.9463\n",
      "Epoch 060 | Train Loss: 0.0857 Acc: 0.9684 | Val Loss: 0.1466 Acc: 0.9444\n",
      "Epoch 001 | Train Loss: 0.6839 Acc: 0.5710 | Val Loss: 0.6774 Acc: 0.5882\n",
      "Epoch 002 | Train Loss: 0.6735 Acc: 0.5943 | Val Loss: 0.6730 Acc: 0.5960\n",
      "Epoch 003 | Train Loss: 0.6658 Acc: 0.6035 | Val Loss: 0.6628 Acc: 0.6045\n",
      "Epoch 004 | Train Loss: 0.6601 Acc: 0.6085 | Val Loss: 0.6590 Acc: 0.6099\n",
      "Epoch 005 | Train Loss: 0.6478 Acc: 0.6243 | Val Loss: 0.6470 Acc: 0.6419\n",
      "Epoch 006 | Train Loss: 0.6332 Acc: 0.6562 | Val Loss: 0.6261 Acc: 0.6606\n",
      "Epoch 007 | Train Loss: 0.6170 Acc: 0.6728 | Val Loss: 0.6050 Acc: 0.6884\n",
      "Epoch 008 | Train Loss: 0.6068 Acc: 0.6814 | Val Loss: 0.5978 Acc: 0.6920\n",
      "Epoch 009 | Train Loss: 0.5914 Acc: 0.7013 | Val Loss: 0.6087 Acc: 0.6745\n",
      "Epoch 010 | Train Loss: 0.5899 Acc: 0.7004 | Val Loss: 0.5877 Acc: 0.7011\n",
      "Epoch 011 | Train Loss: 0.5801 Acc: 0.7100 | Val Loss: 0.5862 Acc: 0.6999\n",
      "Epoch 012 | Train Loss: 0.5715 Acc: 0.7177 | Val Loss: 0.5711 Acc: 0.7126\n",
      "Epoch 013 | Train Loss: 0.5689 Acc: 0.7166 | Val Loss: 0.5789 Acc: 0.6963\n",
      "Epoch 014 | Train Loss: 0.5610 Acc: 0.7263 | Val Loss: 0.5647 Acc: 0.7168\n",
      "Epoch 015 | Train Loss: 0.5514 Acc: 0.7279 | Val Loss: 0.5564 Acc: 0.7180\n",
      "Epoch 016 | Train Loss: 0.5424 Acc: 0.7340 | Val Loss: 0.5546 Acc: 0.7210\n",
      "Epoch 017 | Train Loss: 0.5433 Acc: 0.7324 | Val Loss: 0.5493 Acc: 0.7192\n",
      "Epoch 018 | Train Loss: 0.5351 Acc: 0.7364 | Val Loss: 0.5505 Acc: 0.7246\n",
      "Epoch 019 | Train Loss: 0.5351 Acc: 0.7382 | Val Loss: 0.5448 Acc: 0.7222\n",
      "Epoch 020 | Train Loss: 0.5259 Acc: 0.7477 | Val Loss: 0.5397 Acc: 0.7277\n",
      "Epoch 021 | Train Loss: 0.5231 Acc: 0.7492 | Val Loss: 0.5671 Acc: 0.7107\n",
      "Epoch 022 | Train Loss: 0.5160 Acc: 0.7498 | Val Loss: 0.5299 Acc: 0.7343\n",
      "Epoch 023 | Train Loss: 0.5148 Acc: 0.7488 | Val Loss: 0.5256 Acc: 0.7349\n",
      "Epoch 024 | Train Loss: 0.5056 Acc: 0.7628 | Val Loss: 0.5331 Acc: 0.7289\n",
      "Epoch 025 | Train Loss: 0.4966 Acc: 0.7654 | Val Loss: 0.5189 Acc: 0.7409\n",
      "Epoch 026 | Train Loss: 0.4922 Acc: 0.7676 | Val Loss: 0.5203 Acc: 0.7409\n",
      "Epoch 027 | Train Loss: 0.4811 Acc: 0.7734 | Val Loss: 0.5478 Acc: 0.7379\n",
      "Epoch 028 | Train Loss: 0.4896 Acc: 0.7682 | Val Loss: 0.5602 Acc: 0.7071\n",
      "Epoch 029 | Train Loss: 0.4774 Acc: 0.7744 | Val Loss: 0.5436 Acc: 0.7216\n",
      "Epoch 030 | Train Loss: 0.4644 Acc: 0.7815 | Val Loss: 0.4966 Acc: 0.7542\n",
      "Epoch 031 | Train Loss: 0.4598 Acc: 0.7826 | Val Loss: 0.4993 Acc: 0.7554\n",
      "Epoch 032 | Train Loss: 0.4507 Acc: 0.7907 | Val Loss: 0.4859 Acc: 0.7639\n",
      "Epoch 033 | Train Loss: 0.4447 Acc: 0.7948 | Val Loss: 0.4988 Acc: 0.7669\n",
      "Epoch 034 | Train Loss: 0.4373 Acc: 0.7945 | Val Loss: 0.4780 Acc: 0.7729\n",
      "Epoch 035 | Train Loss: 0.4412 Acc: 0.7983 | Val Loss: 0.4654 Acc: 0.7790\n",
      "Epoch 036 | Train Loss: 0.4299 Acc: 0.7999 | Val Loss: 0.5069 Acc: 0.7482\n",
      "Epoch 037 | Train Loss: 0.4264 Acc: 0.8010 | Val Loss: 0.4663 Acc: 0.7808\n",
      "Epoch 038 | Train Loss: 0.4197 Acc: 0.8060 | Val Loss: 0.4580 Acc: 0.7844\n",
      "Epoch 039 | Train Loss: 0.4075 Acc: 0.8122 | Val Loss: 0.4620 Acc: 0.7886\n",
      "Epoch 040 | Train Loss: 0.4028 Acc: 0.8170 | Val Loss: 0.4855 Acc: 0.7736\n",
      "Epoch 041 | Train Loss: 0.3958 Acc: 0.8212 | Val Loss: 0.4424 Acc: 0.8019\n",
      "Epoch 042 | Train Loss: 0.3997 Acc: 0.8182 | Val Loss: 0.4513 Acc: 0.7983\n",
      "Epoch 043 | Train Loss: 0.3852 Acc: 0.8268 | Val Loss: 0.4373 Acc: 0.7959\n",
      "Epoch 044 | Train Loss: 0.3818 Acc: 0.8252 | Val Loss: 0.4255 Acc: 0.8007\n",
      "Epoch 045 | Train Loss: 0.3714 Acc: 0.8360 | Val Loss: 0.4202 Acc: 0.8007\n",
      "Epoch 046 | Train Loss: 0.3741 Acc: 0.8326 | Val Loss: 0.4094 Acc: 0.8104\n",
      "Epoch 047 | Train Loss: 0.3628 Acc: 0.8387 | Val Loss: 0.4171 Acc: 0.8104\n",
      "Epoch 048 | Train Loss: 0.3542 Acc: 0.8374 | Val Loss: 0.4059 Acc: 0.8146\n",
      "Epoch 049 | Train Loss: 0.3519 Acc: 0.8377 | Val Loss: 0.4007 Acc: 0.8170\n",
      "Epoch 050 | Train Loss: 0.3379 Acc: 0.8489 | Val Loss: 0.3856 Acc: 0.8255\n",
      "Epoch 051 | Train Loss: 0.3317 Acc: 0.8557 | Val Loss: 0.3829 Acc: 0.8339\n",
      "Epoch 052 | Train Loss: 0.3172 Acc: 0.8594 | Val Loss: 0.3721 Acc: 0.8351\n",
      "Epoch 053 | Train Loss: 0.3193 Acc: 0.8590 | Val Loss: 0.3970 Acc: 0.8182\n",
      "Epoch 054 | Train Loss: 0.3123 Acc: 0.8618 | Val Loss: 0.3773 Acc: 0.8376\n",
      "Epoch 055 | Train Loss: 0.2998 Acc: 0.8694 | Val Loss: 0.4035 Acc: 0.8158\n",
      "Epoch 056 | Train Loss: 0.3084 Acc: 0.8640 | Val Loss: 0.3587 Acc: 0.8400\n",
      "Epoch 057 | Train Loss: 0.2910 Acc: 0.8736 | Val Loss: 0.3638 Acc: 0.8351\n",
      "Epoch 058 | Train Loss: 0.2841 Acc: 0.8765 | Val Loss: 0.3734 Acc: 0.8400\n",
      "Epoch 059 | Train Loss: 0.2807 Acc: 0.8765 | Val Loss: 0.3720 Acc: 0.8370\n",
      "Epoch 060 | Train Loss: 0.2704 Acc: 0.8857 | Val Loss: 0.3371 Acc: 0.8599\n",
      "Epoch 001 | Train Loss: 0.6802 Acc: 0.5741 | Val Loss: 0.6768 Acc: 0.5809\n",
      "Epoch 002 | Train Loss: 0.6775 Acc: 0.5842 | Val Loss: 0.6744 Acc: 0.5906\n",
      "Epoch 003 | Train Loss: 0.6513 Acc: 0.6224 | Val Loss: 0.6366 Acc: 0.6534\n",
      "Epoch 004 | Train Loss: 0.5966 Acc: 0.6956 | Val Loss: 0.6006 Acc: 0.6926\n",
      "Epoch 005 | Train Loss: 0.5647 Acc: 0.7231 | Val Loss: 0.5563 Acc: 0.7168\n",
      "Epoch 006 | Train Loss: 0.5397 Acc: 0.7346 | Val Loss: 0.5454 Acc: 0.7379\n",
      "Epoch 007 | Train Loss: 0.5165 Acc: 0.7480 | Val Loss: 0.5528 Acc: 0.7277\n",
      "Epoch 008 | Train Loss: 0.4898 Acc: 0.7705 | Val Loss: 0.5184 Acc: 0.7391\n",
      "Epoch 009 | Train Loss: 0.4664 Acc: 0.7829 | Val Loss: 0.4749 Acc: 0.7736\n",
      "Epoch 010 | Train Loss: 0.4441 Acc: 0.7934 | Val Loss: 0.4551 Acc: 0.7754\n",
      "Epoch 011 | Train Loss: 0.4221 Acc: 0.8039 | Val Loss: 0.4170 Acc: 0.7995\n",
      "Epoch 012 | Train Loss: 0.3876 Acc: 0.8252 | Val Loss: 0.3854 Acc: 0.8207\n",
      "Epoch 013 | Train Loss: 0.3773 Acc: 0.8297 | Val Loss: 0.3757 Acc: 0.8225\n",
      "Epoch 014 | Train Loss: 0.3384 Acc: 0.8560 | Val Loss: 0.3376 Acc: 0.8424\n",
      "Epoch 015 | Train Loss: 0.3160 Acc: 0.8664 | Val Loss: 0.3271 Acc: 0.8521\n",
      "Epoch 016 | Train Loss: 0.3039 Acc: 0.8717 | Val Loss: 0.3324 Acc: 0.8587\n",
      "Epoch 017 | Train Loss: 0.2833 Acc: 0.8807 | Val Loss: 0.3220 Acc: 0.8563\n",
      "Epoch 018 | Train Loss: 0.2574 Acc: 0.8952 | Val Loss: 0.2804 Acc: 0.8841\n",
      "Epoch 019 | Train Loss: 0.2394 Acc: 0.9038 | Val Loss: 0.3272 Acc: 0.8671\n",
      "Epoch 020 | Train Loss: 0.2360 Acc: 0.9077 | Val Loss: 0.2607 Acc: 0.9004\n",
      "Epoch 021 | Train Loss: 0.2269 Acc: 0.9088 | Val Loss: 0.3454 Acc: 0.8569\n",
      "Epoch 022 | Train Loss: 0.2159 Acc: 0.9126 | Val Loss: 0.2661 Acc: 0.8810\n",
      "Epoch 023 | Train Loss: 0.1876 Acc: 0.9275 | Val Loss: 0.2380 Acc: 0.9082\n",
      "Epoch 024 | Train Loss: 0.1984 Acc: 0.9244 | Val Loss: 0.2461 Acc: 0.9034\n",
      "Epoch 025 | Train Loss: 0.1707 Acc: 0.9321 | Val Loss: 0.2274 Acc: 0.9118\n",
      "Epoch 026 | Train Loss: 0.1920 Acc: 0.9269 | Val Loss: 0.2279 Acc: 0.9094\n",
      "Epoch 027 | Train Loss: 0.1677 Acc: 0.9311 | Val Loss: 0.2151 Acc: 0.9124\n",
      "Epoch 028 | Train Loss: 0.1643 Acc: 0.9354 | Val Loss: 0.2827 Acc: 0.8925\n",
      "Epoch 029 | Train Loss: 0.1590 Acc: 0.9413 | Val Loss: 0.2211 Acc: 0.9136\n",
      "Epoch 030 | Train Loss: 0.1459 Acc: 0.9431 | Val Loss: 0.2123 Acc: 0.9167\n",
      "Epoch 031 | Train Loss: 0.1468 Acc: 0.9414 | Val Loss: 0.1939 Acc: 0.9191\n",
      "Epoch 032 | Train Loss: 0.1484 Acc: 0.9432 | Val Loss: 0.2041 Acc: 0.9155\n",
      "Epoch 033 | Train Loss: 0.1426 Acc: 0.9464 | Val Loss: 0.2162 Acc: 0.9173\n",
      "Epoch 034 | Train Loss: 0.1263 Acc: 0.9546 | Val Loss: 0.1870 Acc: 0.9342\n",
      "Epoch 035 | Train Loss: 0.1282 Acc: 0.9508 | Val Loss: 0.2233 Acc: 0.9197\n",
      "Epoch 036 | Train Loss: 0.1244 Acc: 0.9538 | Val Loss: 0.2286 Acc: 0.9155\n",
      "Epoch 037 | Train Loss: 0.1270 Acc: 0.9509 | Val Loss: 0.1972 Acc: 0.9209\n",
      "Epoch 038 | Train Loss: 0.1118 Acc: 0.9553 | Val Loss: 0.1995 Acc: 0.9287\n",
      "Epoch 039 | Train Loss: 0.1130 Acc: 0.9597 | Val Loss: 0.2135 Acc: 0.9161\n",
      "Epoch 040 | Train Loss: 0.1132 Acc: 0.9558 | Val Loss: 0.2057 Acc: 0.9191\n",
      "Epoch 041 | Train Loss: 0.1182 Acc: 0.9544 | Val Loss: 0.2052 Acc: 0.9233\n",
      "Epoch 042 | Train Loss: 0.1009 Acc: 0.9635 | Val Loss: 0.2172 Acc: 0.9275\n",
      "Epoch 043 | Train Loss: 0.1015 Acc: 0.9609 | Val Loss: 0.1744 Acc: 0.9330\n",
      "Epoch 044 | Train Loss: 0.1127 Acc: 0.9565 | Val Loss: 0.2128 Acc: 0.9281\n",
      "Epoch 045 | Train Loss: 0.1010 Acc: 0.9638 | Val Loss: 0.2102 Acc: 0.9239\n",
      "Epoch 046 | Train Loss: 0.0922 Acc: 0.9636 | Val Loss: 0.2388 Acc: 0.9185\n",
      "Epoch 047 | Train Loss: 0.0919 Acc: 0.9657 | Val Loss: 0.2634 Acc: 0.9112\n",
      "Epoch 048 | Train Loss: 0.0943 Acc: 0.9651 | Val Loss: 0.1846 Acc: 0.9324\n",
      "Epoch 049 | Train Loss: 0.0909 Acc: 0.9659 | Val Loss: 0.1689 Acc: 0.9366\n",
      "Epoch 050 | Train Loss: 0.0898 Acc: 0.9647 | Val Loss: 0.2170 Acc: 0.9330\n",
      "Epoch 051 | Train Loss: 0.0857 Acc: 0.9703 | Val Loss: 0.2411 Acc: 0.9293\n",
      "Epoch 052 | Train Loss: 0.0897 Acc: 0.9654 | Val Loss: 0.2168 Acc: 0.9233\n",
      "Epoch 053 | Train Loss: 0.0854 Acc: 0.9687 | Val Loss: 0.1781 Acc: 0.9378\n",
      "Epoch 054 | Train Loss: 0.0790 Acc: 0.9686 | Val Loss: 0.1906 Acc: 0.9275\n",
      "Epoch 055 | Train Loss: 0.0832 Acc: 0.9684 | Val Loss: 0.1998 Acc: 0.9239\n",
      "Epoch 056 | Train Loss: 0.0824 Acc: 0.9710 | Val Loss: 0.2583 Acc: 0.9239\n",
      "Epoch 057 | Train Loss: 0.0812 Acc: 0.9704 | Val Loss: 0.2223 Acc: 0.9336\n",
      "Epoch 058 | Train Loss: 0.0765 Acc: 0.9725 | Val Loss: 0.2389 Acc: 0.9239\n",
      "Epoch 059 | Train Loss: 0.0856 Acc: 0.9693 | Val Loss: 0.1921 Acc: 0.9336\n",
      "Early stopping triggered.\n",
      "Epoch 001 | Train Loss: 0.6816 Acc: 0.5729 | Val Loss: 0.6781 Acc: 0.5876\n",
      "Epoch 002 | Train Loss: 0.6823 Acc: 0.5742 | Val Loss: 0.6839 Acc: 0.5707\n",
      "Epoch 003 | Train Loss: 0.6769 Acc: 0.5870 | Val Loss: 0.6758 Acc: 0.5936\n",
      "Epoch 004 | Train Loss: 0.6754 Acc: 0.5961 | Val Loss: 0.6661 Acc: 0.6002\n",
      "Epoch 005 | Train Loss: 0.6644 Acc: 0.6112 | Val Loss: 0.6460 Acc: 0.6244\n",
      "Epoch 006 | Train Loss: 0.6457 Acc: 0.6349 | Val Loss: 0.6282 Acc: 0.6630\n",
      "Epoch 007 | Train Loss: 0.6197 Acc: 0.6692 | Val Loss: 0.5881 Acc: 0.6957\n",
      "Epoch 008 | Train Loss: 0.5767 Acc: 0.7208 | Val Loss: 0.5946 Acc: 0.7011\n",
      "Epoch 009 | Train Loss: 0.5642 Acc: 0.7186 | Val Loss: 0.5874 Acc: 0.6860\n",
      "Epoch 010 | Train Loss: 0.5508 Acc: 0.7275 | Val Loss: 0.5390 Acc: 0.7313\n",
      "Epoch 011 | Train Loss: 0.5326 Acc: 0.7471 | Val Loss: 0.5518 Acc: 0.7271\n",
      "Epoch 012 | Train Loss: 0.5281 Acc: 0.7480 | Val Loss: 0.5245 Acc: 0.7452\n",
      "Epoch 013 | Train Loss: 0.5178 Acc: 0.7580 | Val Loss: 0.5137 Acc: 0.7506\n",
      "Epoch 014 | Train Loss: 0.5057 Acc: 0.7666 | Val Loss: 0.5218 Acc: 0.7440\n",
      "Epoch 015 | Train Loss: 0.4931 Acc: 0.7732 | Val Loss: 0.4830 Acc: 0.7645\n",
      "Epoch 016 | Train Loss: 0.4860 Acc: 0.7755 | Val Loss: 0.4928 Acc: 0.7566\n",
      "Epoch 017 | Train Loss: 0.4832 Acc: 0.7762 | Val Loss: 0.4699 Acc: 0.7808\n",
      "Epoch 018 | Train Loss: 0.4591 Acc: 0.7891 | Val Loss: 0.4602 Acc: 0.7748\n",
      "Epoch 019 | Train Loss: 0.4572 Acc: 0.7897 | Val Loss: 0.4518 Acc: 0.7802\n",
      "Epoch 020 | Train Loss: 0.4435 Acc: 0.7953 | Val Loss: 0.4503 Acc: 0.7760\n",
      "Epoch 021 | Train Loss: 0.4314 Acc: 0.8073 | Val Loss: 0.4463 Acc: 0.7874\n",
      "Epoch 022 | Train Loss: 0.4149 Acc: 0.8135 | Val Loss: 0.4070 Acc: 0.7965\n",
      "Epoch 023 | Train Loss: 0.4056 Acc: 0.8185 | Val Loss: 0.4214 Acc: 0.7856\n",
      "Epoch 024 | Train Loss: 0.4015 Acc: 0.8206 | Val Loss: 0.3759 Acc: 0.8219\n",
      "Epoch 025 | Train Loss: 0.3710 Acc: 0.8330 | Val Loss: 0.3758 Acc: 0.8237\n",
      "Epoch 026 | Train Loss: 0.3570 Acc: 0.8415 | Val Loss: 0.3583 Acc: 0.8436\n",
      "Epoch 027 | Train Loss: 0.3545 Acc: 0.8467 | Val Loss: 0.3749 Acc: 0.8285\n",
      "Epoch 028 | Train Loss: 0.3375 Acc: 0.8588 | Val Loss: 0.3263 Acc: 0.8527\n",
      "Epoch 029 | Train Loss: 0.3110 Acc: 0.8671 | Val Loss: 0.3099 Acc: 0.8732\n",
      "Epoch 030 | Train Loss: 0.3080 Acc: 0.8747 | Val Loss: 0.3101 Acc: 0.8641\n",
      "Epoch 031 | Train Loss: 0.3050 Acc: 0.8748 | Val Loss: 0.3002 Acc: 0.8690\n",
      "Epoch 032 | Train Loss: 0.2893 Acc: 0.8821 | Val Loss: 0.2794 Acc: 0.8895\n",
      "Epoch 033 | Train Loss: 0.2831 Acc: 0.8824 | Val Loss: 0.2869 Acc: 0.8768\n",
      "Epoch 034 | Train Loss: 0.2765 Acc: 0.8877 | Val Loss: 0.2763 Acc: 0.8931\n",
      "Epoch 035 | Train Loss: 0.2671 Acc: 0.8970 | Val Loss: 0.2664 Acc: 0.8907\n",
      "Epoch 036 | Train Loss: 0.2567 Acc: 0.8984 | Val Loss: 0.3040 Acc: 0.8732\n",
      "Epoch 037 | Train Loss: 0.2521 Acc: 0.8955 | Val Loss: 0.2687 Acc: 0.8986\n",
      "Epoch 038 | Train Loss: 0.2443 Acc: 0.9062 | Val Loss: 0.2736 Acc: 0.8986\n",
      "Epoch 039 | Train Loss: 0.2300 Acc: 0.9082 | Val Loss: 0.2439 Acc: 0.9046\n",
      "Epoch 040 | Train Loss: 0.2327 Acc: 0.9058 | Val Loss: 0.2666 Acc: 0.8992\n",
      "Epoch 041 | Train Loss: 0.2218 Acc: 0.9188 | Val Loss: 0.2440 Acc: 0.9028\n",
      "Epoch 042 | Train Loss: 0.2293 Acc: 0.9096 | Val Loss: 0.2853 Acc: 0.8756\n",
      "Epoch 043 | Train Loss: 0.2214 Acc: 0.9142 | Val Loss: 0.2436 Acc: 0.9016\n",
      "Epoch 044 | Train Loss: 0.1978 Acc: 0.9254 | Val Loss: 0.2157 Acc: 0.9118\n",
      "Epoch 045 | Train Loss: 0.2054 Acc: 0.9221 | Val Loss: 0.2362 Acc: 0.9064\n",
      "Epoch 046 | Train Loss: 0.2038 Acc: 0.9239 | Val Loss: 0.2586 Acc: 0.8986\n",
      "Epoch 047 | Train Loss: 0.1936 Acc: 0.9257 | Val Loss: 0.2363 Acc: 0.9070\n",
      "Epoch 048 | Train Loss: 0.1813 Acc: 0.9330 | Val Loss: 0.2667 Acc: 0.9052\n",
      "Epoch 049 | Train Loss: 0.1938 Acc: 0.9262 | Val Loss: 0.2472 Acc: 0.9010\n",
      "Epoch 050 | Train Loss: 0.1930 Acc: 0.9253 | Val Loss: 0.2105 Acc: 0.9185\n",
      "Epoch 051 | Train Loss: 0.1753 Acc: 0.9354 | Val Loss: 0.2652 Acc: 0.8992\n",
      "Epoch 052 | Train Loss: 0.1698 Acc: 0.9330 | Val Loss: 0.2288 Acc: 0.9149\n",
      "Epoch 053 | Train Loss: 0.1960 Acc: 0.9233 | Val Loss: 0.2179 Acc: 0.9173\n",
      "Epoch 054 | Train Loss: 0.1691 Acc: 0.9349 | Val Loss: 0.2414 Acc: 0.9167\n",
      "Epoch 055 | Train Loss: 0.1701 Acc: 0.9367 | Val Loss: 0.2137 Acc: 0.9082\n",
      "Epoch 056 | Train Loss: 0.1675 Acc: 0.9384 | Val Loss: 0.2256 Acc: 0.9106\n",
      "Epoch 057 | Train Loss: 0.1558 Acc: 0.9419 | Val Loss: 0.2172 Acc: 0.9094\n",
      "Epoch 058 | Train Loss: 0.1639 Acc: 0.9402 | Val Loss: 0.2021 Acc: 0.9185\n",
      "Epoch 059 | Train Loss: 0.1528 Acc: 0.9452 | Val Loss: 0.2290 Acc: 0.9149\n",
      "Epoch 060 | Train Loss: 0.1531 Acc: 0.9429 | Val Loss: 0.2033 Acc: 0.9197\n",
      "Epoch 001 | Train Loss: 0.6829 Acc: 0.5718 | Val Loss: 0.6769 Acc: 0.5821\n",
      "Epoch 002 | Train Loss: 0.6722 Acc: 0.5944 | Val Loss: 0.6669 Acc: 0.5978\n",
      "Epoch 003 | Train Loss: 0.6592 Acc: 0.6133 | Val Loss: 0.6468 Acc: 0.6335\n",
      "Epoch 004 | Train Loss: 0.6205 Acc: 0.6758 | Val Loss: 0.6008 Acc: 0.6902\n",
      "Epoch 005 | Train Loss: 0.5962 Acc: 0.7021 | Val Loss: 0.5933 Acc: 0.6920\n",
      "Epoch 006 | Train Loss: 0.5855 Acc: 0.7083 | Val Loss: 0.5783 Acc: 0.7059\n",
      "Epoch 007 | Train Loss: 0.5675 Acc: 0.7210 | Val Loss: 0.5733 Acc: 0.7053\n",
      "Epoch 008 | Train Loss: 0.5652 Acc: 0.7232 | Val Loss: 0.5756 Acc: 0.7083\n",
      "Epoch 009 | Train Loss: 0.5556 Acc: 0.7284 | Val Loss: 0.5678 Acc: 0.7126\n",
      "Epoch 010 | Train Loss: 0.5502 Acc: 0.7296 | Val Loss: 0.5481 Acc: 0.7168\n",
      "Epoch 011 | Train Loss: 0.5401 Acc: 0.7404 | Val Loss: 0.5433 Acc: 0.7258\n",
      "Epoch 012 | Train Loss: 0.5486 Acc: 0.7353 | Val Loss: 0.5503 Acc: 0.7180\n",
      "Epoch 013 | Train Loss: 0.5305 Acc: 0.7435 | Val Loss: 0.5405 Acc: 0.7234\n",
      "Epoch 014 | Train Loss: 0.5205 Acc: 0.7480 | Val Loss: 0.5366 Acc: 0.7301\n",
      "Epoch 015 | Train Loss: 0.5130 Acc: 0.7559 | Val Loss: 0.5201 Acc: 0.7385\n",
      "Epoch 016 | Train Loss: 0.5072 Acc: 0.7642 | Val Loss: 0.5190 Acc: 0.7488\n",
      "Epoch 017 | Train Loss: 0.4991 Acc: 0.7648 | Val Loss: 0.5038 Acc: 0.7609\n",
      "Epoch 018 | Train Loss: 0.4875 Acc: 0.7708 | Val Loss: 0.5078 Acc: 0.7572\n",
      "Epoch 019 | Train Loss: 0.4800 Acc: 0.7747 | Val Loss: 0.4843 Acc: 0.7645\n",
      "Epoch 020 | Train Loss: 0.4709 Acc: 0.7782 | Val Loss: 0.4799 Acc: 0.7669\n",
      "Epoch 021 | Train Loss: 0.4606 Acc: 0.7833 | Val Loss: 0.4769 Acc: 0.7621\n",
      "Epoch 022 | Train Loss: 0.4590 Acc: 0.7845 | Val Loss: 0.4400 Acc: 0.7941\n",
      "Epoch 023 | Train Loss: 0.4384 Acc: 0.7971 | Val Loss: 0.4540 Acc: 0.7917\n",
      "Epoch 024 | Train Loss: 0.4341 Acc: 0.8008 | Val Loss: 0.4179 Acc: 0.8116\n",
      "Epoch 025 | Train Loss: 0.4176 Acc: 0.8107 | Val Loss: 0.4079 Acc: 0.8092\n",
      "Epoch 026 | Train Loss: 0.4080 Acc: 0.8153 | Val Loss: 0.4050 Acc: 0.8104\n",
      "Epoch 027 | Train Loss: 0.3911 Acc: 0.8238 | Val Loss: 0.3958 Acc: 0.8086\n",
      "Epoch 028 | Train Loss: 0.3777 Acc: 0.8285 | Val Loss: 0.3610 Acc: 0.8351\n",
      "Epoch 029 | Train Loss: 0.3681 Acc: 0.8359 | Val Loss: 0.3500 Acc: 0.8575\n",
      "Epoch 030 | Train Loss: 0.3530 Acc: 0.8480 | Val Loss: 0.3329 Acc: 0.8527\n",
      "Epoch 031 | Train Loss: 0.3419 Acc: 0.8498 | Val Loss: 0.3388 Acc: 0.8370\n",
      "Epoch 032 | Train Loss: 0.3345 Acc: 0.8523 | Val Loss: 0.3071 Acc: 0.8684\n",
      "Epoch 033 | Train Loss: 0.3200 Acc: 0.8643 | Val Loss: 0.3083 Acc: 0.8659\n",
      "Epoch 034 | Train Loss: 0.3043 Acc: 0.8685 | Val Loss: 0.2988 Acc: 0.8714\n",
      "Epoch 035 | Train Loss: 0.3001 Acc: 0.8769 | Val Loss: 0.2932 Acc: 0.8732\n",
      "Epoch 036 | Train Loss: 0.2895 Acc: 0.8800 | Val Loss: 0.2975 Acc: 0.8726\n",
      "Epoch 037 | Train Loss: 0.2895 Acc: 0.8750 | Val Loss: 0.2942 Acc: 0.8774\n",
      "Epoch 038 | Train Loss: 0.2785 Acc: 0.8877 | Val Loss: 0.2818 Acc: 0.8883\n",
      "Epoch 039 | Train Loss: 0.2657 Acc: 0.8895 | Val Loss: 0.2777 Acc: 0.8810\n",
      "Epoch 040 | Train Loss: 0.2686 Acc: 0.8878 | Val Loss: 0.2554 Acc: 0.8919\n",
      "Epoch 041 | Train Loss: 0.2675 Acc: 0.8890 | Val Loss: 0.2543 Acc: 0.8992\n",
      "Epoch 042 | Train Loss: 0.2469 Acc: 0.8957 | Val Loss: 0.3126 Acc: 0.8756\n",
      "Epoch 043 | Train Loss: 0.2452 Acc: 0.8981 | Val Loss: 0.2567 Acc: 0.8883\n",
      "Epoch 044 | Train Loss: 0.2417 Acc: 0.9014 | Val Loss: 0.2437 Acc: 0.8986\n",
      "Epoch 045 | Train Loss: 0.2310 Acc: 0.9043 | Val Loss: 0.2362 Acc: 0.9004\n",
      "Epoch 046 | Train Loss: 0.2240 Acc: 0.9083 | Val Loss: 0.2286 Acc: 0.9094\n",
      "Epoch 047 | Train Loss: 0.2182 Acc: 0.9133 | Val Loss: 0.2203 Acc: 0.9112\n",
      "Epoch 048 | Train Loss: 0.2175 Acc: 0.9147 | Val Loss: 0.2128 Acc: 0.9118\n",
      "Epoch 049 | Train Loss: 0.2174 Acc: 0.9120 | Val Loss: 0.2393 Acc: 0.9118\n",
      "Epoch 050 | Train Loss: 0.1995 Acc: 0.9162 | Val Loss: 0.2292 Acc: 0.9064\n",
      "Epoch 051 | Train Loss: 0.1955 Acc: 0.9241 | Val Loss: 0.2128 Acc: 0.9197\n",
      "Epoch 052 | Train Loss: 0.1981 Acc: 0.9227 | Val Loss: 0.2106 Acc: 0.9130\n",
      "Epoch 053 | Train Loss: 0.1923 Acc: 0.9225 | Val Loss: 0.2201 Acc: 0.9088\n",
      "Epoch 054 | Train Loss: 0.1855 Acc: 0.9271 | Val Loss: 0.2095 Acc: 0.9149\n",
      "Epoch 055 | Train Loss: 0.1826 Acc: 0.9299 | Val Loss: 0.2004 Acc: 0.9155\n",
      "Epoch 056 | Train Loss: 0.1876 Acc: 0.9268 | Val Loss: 0.2272 Acc: 0.8992\n",
      "Epoch 057 | Train Loss: 0.1816 Acc: 0.9287 | Val Loss: 0.2017 Acc: 0.9179\n",
      "Epoch 058 | Train Loss: 0.1873 Acc: 0.9268 | Val Loss: 0.1907 Acc: 0.9209\n",
      "Epoch 059 | Train Loss: 0.1745 Acc: 0.9316 | Val Loss: 0.1923 Acc: 0.9257\n",
      "Epoch 060 | Train Loss: 0.1737 Acc: 0.9331 | Val Loss: 0.1852 Acc: 0.9209\n",
      "Epoch 001 | Train Loss: 0.6788 Acc: 0.5836 | Val Loss: 0.6735 Acc: 0.5930\n",
      "Epoch 002 | Train Loss: 0.6515 Acc: 0.6200 | Val Loss: 0.6270 Acc: 0.6582\n",
      "Epoch 003 | Train Loss: 0.5976 Acc: 0.6935 | Val Loss: 0.5753 Acc: 0.6969\n",
      "Epoch 004 | Train Loss: 0.5597 Acc: 0.7199 | Val Loss: 0.5709 Acc: 0.7132\n",
      "Epoch 005 | Train Loss: 0.5347 Acc: 0.7334 | Val Loss: 0.5368 Acc: 0.7367\n",
      "Epoch 006 | Train Loss: 0.5233 Acc: 0.7475 | Val Loss: 0.5283 Acc: 0.7367\n",
      "Epoch 007 | Train Loss: 0.4968 Acc: 0.7562 | Val Loss: 0.4967 Acc: 0.7566\n",
      "Epoch 008 | Train Loss: 0.4739 Acc: 0.7743 | Val Loss: 0.4879 Acc: 0.7536\n",
      "Epoch 009 | Train Loss: 0.4430 Acc: 0.7925 | Val Loss: 0.4515 Acc: 0.7772\n",
      "Epoch 010 | Train Loss: 0.4290 Acc: 0.8019 | Val Loss: 0.4262 Acc: 0.7935\n",
      "Epoch 011 | Train Loss: 0.3991 Acc: 0.8149 | Val Loss: 0.3948 Acc: 0.8164\n",
      "Epoch 012 | Train Loss: 0.3761 Acc: 0.8312 | Val Loss: 0.3603 Acc: 0.8364\n",
      "Epoch 013 | Train Loss: 0.3455 Acc: 0.8461 | Val Loss: 0.3688 Acc: 0.8315\n",
      "Epoch 014 | Train Loss: 0.3194 Acc: 0.8575 | Val Loss: 0.3371 Acc: 0.8442\n",
      "Epoch 015 | Train Loss: 0.2999 Acc: 0.8756 | Val Loss: 0.2934 Acc: 0.8732\n",
      "Epoch 016 | Train Loss: 0.2789 Acc: 0.8807 | Val Loss: 0.2960 Acc: 0.8665\n",
      "Epoch 017 | Train Loss: 0.2495 Acc: 0.8990 | Val Loss: 0.2644 Acc: 0.8913\n",
      "Epoch 018 | Train Loss: 0.2418 Acc: 0.9023 | Val Loss: 0.2556 Acc: 0.8925\n",
      "Epoch 019 | Train Loss: 0.2263 Acc: 0.9056 | Val Loss: 0.2651 Acc: 0.8919\n",
      "Epoch 020 | Train Loss: 0.2239 Acc: 0.9068 | Val Loss: 0.2465 Acc: 0.8992\n",
      "Epoch 021 | Train Loss: 0.2008 Acc: 0.9191 | Val Loss: 0.2388 Acc: 0.9052\n",
      "Epoch 022 | Train Loss: 0.1907 Acc: 0.9225 | Val Loss: 0.2106 Acc: 0.9161\n",
      "Epoch 023 | Train Loss: 0.1870 Acc: 0.9259 | Val Loss: 0.2192 Acc: 0.9221\n",
      "Epoch 024 | Train Loss: 0.1762 Acc: 0.9324 | Val Loss: 0.2145 Acc: 0.9173\n",
      "Epoch 025 | Train Loss: 0.1662 Acc: 0.9330 | Val Loss: 0.2131 Acc: 0.9203\n",
      "Epoch 026 | Train Loss: 0.1598 Acc: 0.9372 | Val Loss: 0.2071 Acc: 0.9239\n",
      "Epoch 027 | Train Loss: 0.1451 Acc: 0.9420 | Val Loss: 0.1752 Acc: 0.9293\n",
      "Epoch 028 | Train Loss: 0.1480 Acc: 0.9419 | Val Loss: 0.2295 Acc: 0.9149\n",
      "Epoch 029 | Train Loss: 0.1370 Acc: 0.9464 | Val Loss: 0.1989 Acc: 0.9251\n",
      "Epoch 030 | Train Loss: 0.1398 Acc: 0.9455 | Val Loss: 0.1785 Acc: 0.9281\n",
      "Epoch 031 | Train Loss: 0.1333 Acc: 0.9462 | Val Loss: 0.2036 Acc: 0.9251\n",
      "Epoch 032 | Train Loss: 0.1205 Acc: 0.9520 | Val Loss: 0.2001 Acc: 0.9197\n",
      "Epoch 033 | Train Loss: 0.1205 Acc: 0.9523 | Val Loss: 0.2634 Acc: 0.9058\n",
      "Epoch 034 | Train Loss: 0.1259 Acc: 0.9530 | Val Loss: 0.1660 Acc: 0.9360\n",
      "Epoch 035 | Train Loss: 0.1040 Acc: 0.9570 | Val Loss: 0.2386 Acc: 0.9239\n",
      "Epoch 036 | Train Loss: 0.1130 Acc: 0.9588 | Val Loss: 0.1877 Acc: 0.9287\n",
      "Epoch 037 | Train Loss: 0.1084 Acc: 0.9573 | Val Loss: 0.1944 Acc: 0.9269\n",
      "Epoch 038 | Train Loss: 0.1116 Acc: 0.9577 | Val Loss: 0.1834 Acc: 0.9354\n",
      "Epoch 039 | Train Loss: 0.0960 Acc: 0.9627 | Val Loss: 0.1715 Acc: 0.9348\n",
      "Epoch 040 | Train Loss: 0.0973 Acc: 0.9630 | Val Loss: 0.1796 Acc: 0.9384\n",
      "Epoch 041 | Train Loss: 0.0900 Acc: 0.9660 | Val Loss: 0.1696 Acc: 0.9396\n",
      "Epoch 042 | Train Loss: 0.0918 Acc: 0.9650 | Val Loss: 0.1527 Acc: 0.9432\n",
      "Epoch 043 | Train Loss: 0.0921 Acc: 0.9659 | Val Loss: 0.1660 Acc: 0.9420\n",
      "Epoch 044 | Train Loss: 0.0818 Acc: 0.9697 | Val Loss: 0.1797 Acc: 0.9366\n",
      "Epoch 045 | Train Loss: 0.0909 Acc: 0.9642 | Val Loss: 0.1850 Acc: 0.9293\n",
      "Epoch 046 | Train Loss: 0.0877 Acc: 0.9645 | Val Loss: 0.1724 Acc: 0.9384\n",
      "Epoch 047 | Train Loss: 0.0786 Acc: 0.9709 | Val Loss: 0.2246 Acc: 0.9179\n",
      "Epoch 048 | Train Loss: 0.0845 Acc: 0.9669 | Val Loss: 0.1722 Acc: 0.9378\n",
      "Epoch 049 | Train Loss: 0.0811 Acc: 0.9693 | Val Loss: 0.1581 Acc: 0.9426\n",
      "Epoch 050 | Train Loss: 0.0820 Acc: 0.9693 | Val Loss: 0.1830 Acc: 0.9336\n",
      "Epoch 051 | Train Loss: 0.0953 Acc: 0.9666 | Val Loss: 0.1569 Acc: 0.9426\n",
      "Epoch 052 | Train Loss: 0.0803 Acc: 0.9692 | Val Loss: 0.1814 Acc: 0.9342\n",
      "Early stopping triggered.\n",
      "Epoch 001 | Train Loss: 0.6844 Acc: 0.5682 | Val Loss: 0.6843 Acc: 0.5658\n",
      "Epoch 002 | Train Loss: 0.6712 Acc: 0.5987 | Val Loss: 0.6401 Acc: 0.6516\n",
      "Epoch 003 | Train Loss: 0.5957 Acc: 0.6982 | Val Loss: 0.6035 Acc: 0.6854\n",
      "Epoch 004 | Train Loss: 0.5563 Acc: 0.7308 | Val Loss: 0.5382 Acc: 0.7295\n",
      "Epoch 005 | Train Loss: 0.5244 Acc: 0.7507 | Val Loss: 0.5252 Acc: 0.7470\n",
      "Epoch 006 | Train Loss: 0.4825 Acc: 0.7709 | Val Loss: 0.4809 Acc: 0.7693\n",
      "Epoch 007 | Train Loss: 0.4550 Acc: 0.7868 | Val Loss: 0.4683 Acc: 0.7796\n",
      "Epoch 008 | Train Loss: 0.4210 Acc: 0.8116 | Val Loss: 0.4153 Acc: 0.8116\n",
      "Epoch 009 | Train Loss: 0.3881 Acc: 0.8276 | Val Loss: 0.3998 Acc: 0.8249\n",
      "Epoch 010 | Train Loss: 0.3417 Acc: 0.8587 | Val Loss: 0.3558 Acc: 0.8376\n",
      "Epoch 011 | Train Loss: 0.3088 Acc: 0.8697 | Val Loss: 0.3628 Acc: 0.8454\n",
      "Epoch 012 | Train Loss: 0.2912 Acc: 0.8801 | Val Loss: 0.3195 Acc: 0.8629\n",
      "Epoch 013 | Train Loss: 0.2698 Acc: 0.8877 | Val Loss: 0.3410 Acc: 0.8635\n",
      "Epoch 014 | Train Loss: 0.2499 Acc: 0.8972 | Val Loss: 0.2759 Acc: 0.8847\n",
      "Epoch 015 | Train Loss: 0.2265 Acc: 0.9083 | Val Loss: 0.2921 Acc: 0.8810\n",
      "Epoch 016 | Train Loss: 0.2153 Acc: 0.9141 | Val Loss: 0.2769 Acc: 0.8871\n",
      "Epoch 017 | Train Loss: 0.1901 Acc: 0.9231 | Val Loss: 0.2435 Acc: 0.9106\n",
      "Epoch 018 | Train Loss: 0.1868 Acc: 0.9260 | Val Loss: 0.3052 Acc: 0.8756\n",
      "Epoch 019 | Train Loss: 0.1681 Acc: 0.9364 | Val Loss: 0.2452 Acc: 0.9082\n",
      "Epoch 020 | Train Loss: 0.1731 Acc: 0.9330 | Val Loss: 0.2234 Acc: 0.9124\n",
      "Epoch 021 | Train Loss: 0.1536 Acc: 0.9401 | Val Loss: 0.2260 Acc: 0.9173\n",
      "Epoch 022 | Train Loss: 0.1440 Acc: 0.9465 | Val Loss: 0.2715 Acc: 0.9016\n",
      "Epoch 023 | Train Loss: 0.1323 Acc: 0.9499 | Val Loss: 0.2467 Acc: 0.9118\n",
      "Epoch 024 | Train Loss: 0.1353 Acc: 0.9499 | Val Loss: 0.2064 Acc: 0.9197\n",
      "Epoch 025 | Train Loss: 0.1184 Acc: 0.9550 | Val Loss: 0.2184 Acc: 0.9179\n",
      "Epoch 026 | Train Loss: 0.1211 Acc: 0.9544 | Val Loss: 0.2226 Acc: 0.9197\n",
      "Epoch 027 | Train Loss: 0.1122 Acc: 0.9550 | Val Loss: 0.2521 Acc: 0.9149\n",
      "Epoch 028 | Train Loss: 0.1153 Acc: 0.9556 | Val Loss: 0.2121 Acc: 0.9251\n",
      "Epoch 029 | Train Loss: 0.1112 Acc: 0.9565 | Val Loss: 0.1991 Acc: 0.9251\n",
      "Epoch 030 | Train Loss: 0.0992 Acc: 0.9642 | Val Loss: 0.1854 Acc: 0.9251\n",
      "Epoch 031 | Train Loss: 0.0936 Acc: 0.9674 | Val Loss: 0.2309 Acc: 0.9191\n",
      "Epoch 032 | Train Loss: 0.0993 Acc: 0.9616 | Val Loss: 0.2001 Acc: 0.9269\n",
      "Epoch 033 | Train Loss: 0.0888 Acc: 0.9648 | Val Loss: 0.1880 Acc: 0.9354\n",
      "Epoch 034 | Train Loss: 0.0792 Acc: 0.9695 | Val Loss: 0.2396 Acc: 0.9130\n",
      "Epoch 035 | Train Loss: 0.0920 Acc: 0.9677 | Val Loss: 0.2206 Acc: 0.9149\n",
      "Epoch 036 | Train Loss: 0.0882 Acc: 0.9662 | Val Loss: 0.2132 Acc: 0.9233\n",
      "Epoch 037 | Train Loss: 0.0770 Acc: 0.9712 | Val Loss: 0.2123 Acc: 0.9221\n",
      "Epoch 038 | Train Loss: 0.0841 Acc: 0.9689 | Val Loss: 0.2180 Acc: 0.9233\n",
      "Epoch 039 | Train Loss: 0.0860 Acc: 0.9697 | Val Loss: 0.2166 Acc: 0.9287\n",
      "Epoch 040 | Train Loss: 0.0785 Acc: 0.9692 | Val Loss: 0.2478 Acc: 0.9251\n",
      "Early stopping triggered.\n",
      "Iteration 6/40 | Best Val Loss: 0.1394 | Iter Time: 268.83s | Total Time: 31.73 min\n",
      "Epoch 001 | Train Loss: 0.6802 Acc: 0.5716 | Val Loss: 0.6789 Acc: 0.5845\n",
      "Epoch 002 | Train Loss: 0.6829 Acc: 0.5689 | Val Loss: 0.6774 Acc: 0.5791\n",
      "Epoch 003 | Train Loss: 0.6701 Acc: 0.5966 | Val Loss: 0.6755 Acc: 0.5833\n",
      "Epoch 004 | Train Loss: 0.6664 Acc: 0.6053 | Val Loss: 0.6638 Acc: 0.6069\n",
      "Epoch 005 | Train Loss: 0.6587 Acc: 0.6195 | Val Loss: 0.6620 Acc: 0.6190\n",
      "Epoch 006 | Train Loss: 0.6365 Acc: 0.6502 | Val Loss: 0.6842 Acc: 0.6522\n",
      "Epoch 007 | Train Loss: 0.6227 Acc: 0.6677 | Val Loss: 0.5777 Acc: 0.7126\n",
      "Epoch 008 | Train Loss: 0.5654 Acc: 0.7189 | Val Loss: 0.5596 Acc: 0.7234\n",
      "Epoch 009 | Train Loss: 0.5496 Acc: 0.7294 | Val Loss: 0.5265 Acc: 0.7349\n",
      "Epoch 010 | Train Loss: 0.5084 Acc: 0.7512 | Val Loss: 0.5335 Acc: 0.7349\n",
      "Epoch 011 | Train Loss: 0.5017 Acc: 0.7589 | Val Loss: 0.4889 Acc: 0.7597\n",
      "Epoch 012 | Train Loss: 0.4740 Acc: 0.7758 | Val Loss: 0.4850 Acc: 0.7560\n",
      "Epoch 013 | Train Loss: 0.4556 Acc: 0.7838 | Val Loss: 0.4779 Acc: 0.7772\n",
      "Epoch 014 | Train Loss: 0.4495 Acc: 0.7975 | Val Loss: 0.4462 Acc: 0.7911\n",
      "Epoch 015 | Train Loss: 0.4135 Acc: 0.8119 | Val Loss: 0.4305 Acc: 0.7935\n",
      "Epoch 016 | Train Loss: 0.4079 Acc: 0.8188 | Val Loss: 0.3998 Acc: 0.8140\n",
      "Epoch 017 | Train Loss: 0.3857 Acc: 0.8313 | Val Loss: 0.3715 Acc: 0.8297\n",
      "Epoch 018 | Train Loss: 0.3689 Acc: 0.8400 | Val Loss: 0.3462 Acc: 0.8454\n",
      "Epoch 019 | Train Loss: 0.3460 Acc: 0.8493 | Val Loss: 0.3756 Acc: 0.8255\n",
      "Epoch 020 | Train Loss: 0.3344 Acc: 0.8546 | Val Loss: 0.3243 Acc: 0.8545\n",
      "Epoch 021 | Train Loss: 0.3107 Acc: 0.8659 | Val Loss: 0.3277 Acc: 0.8575\n",
      "Epoch 022 | Train Loss: 0.3063 Acc: 0.8712 | Val Loss: 0.3128 Acc: 0.8623\n",
      "Epoch 023 | Train Loss: 0.2949 Acc: 0.8748 | Val Loss: 0.3008 Acc: 0.8750\n",
      "Epoch 024 | Train Loss: 0.2779 Acc: 0.8875 | Val Loss: 0.2864 Acc: 0.8810\n",
      "Epoch 025 | Train Loss: 0.2753 Acc: 0.8856 | Val Loss: 0.2833 Acc: 0.8829\n",
      "Epoch 026 | Train Loss: 0.2518 Acc: 0.8949 | Val Loss: 0.2546 Acc: 0.8937\n",
      "Epoch 027 | Train Loss: 0.2437 Acc: 0.9016 | Val Loss: 0.2858 Acc: 0.8774\n",
      "Epoch 028 | Train Loss: 0.2371 Acc: 0.9061 | Val Loss: 0.2457 Acc: 0.8979\n",
      "Epoch 029 | Train Loss: 0.2370 Acc: 0.9028 | Val Loss: 0.2661 Acc: 0.8931\n",
      "Epoch 030 | Train Loss: 0.2227 Acc: 0.9083 | Val Loss: 0.2478 Acc: 0.9046\n",
      "Epoch 031 | Train Loss: 0.2179 Acc: 0.9127 | Val Loss: 0.2408 Acc: 0.9046\n",
      "Epoch 032 | Train Loss: 0.2045 Acc: 0.9153 | Val Loss: 0.2207 Acc: 0.9118\n",
      "Epoch 033 | Train Loss: 0.1958 Acc: 0.9198 | Val Loss: 0.2284 Acc: 0.9094\n",
      "Epoch 034 | Train Loss: 0.1916 Acc: 0.9247 | Val Loss: 0.2646 Acc: 0.9004\n",
      "Epoch 035 | Train Loss: 0.1825 Acc: 0.9275 | Val Loss: 0.2272 Acc: 0.9112\n",
      "Epoch 036 | Train Loss: 0.1731 Acc: 0.9289 | Val Loss: 0.2525 Acc: 0.8998\n",
      "Epoch 037 | Train Loss: 0.1675 Acc: 0.9351 | Val Loss: 0.2625 Acc: 0.8992\n",
      "Epoch 038 | Train Loss: 0.1658 Acc: 0.9364 | Val Loss: 0.2197 Acc: 0.9130\n",
      "Epoch 039 | Train Loss: 0.1670 Acc: 0.9370 | Val Loss: 0.2173 Acc: 0.9155\n",
      "Epoch 040 | Train Loss: 0.1534 Acc: 0.9425 | Val Loss: 0.2978 Acc: 0.8919\n",
      "Epoch 041 | Train Loss: 0.1562 Acc: 0.9399 | Val Loss: 0.2284 Acc: 0.9118\n",
      "Epoch 042 | Train Loss: 0.1418 Acc: 0.9434 | Val Loss: 0.2289 Acc: 0.9209\n",
      "Epoch 043 | Train Loss: 0.1319 Acc: 0.9475 | Val Loss: 0.2334 Acc: 0.9118\n",
      "Epoch 044 | Train Loss: 0.1450 Acc: 0.9456 | Val Loss: 0.2014 Acc: 0.9185\n",
      "Epoch 045 | Train Loss: 0.1410 Acc: 0.9447 | Val Loss: 0.2103 Acc: 0.9293\n",
      "Epoch 046 | Train Loss: 0.1378 Acc: 0.9494 | Val Loss: 0.2427 Acc: 0.9100\n",
      "Epoch 047 | Train Loss: 0.1385 Acc: 0.9458 | Val Loss: 0.2216 Acc: 0.9215\n",
      "Epoch 048 | Train Loss: 0.1383 Acc: 0.9450 | Val Loss: 0.2233 Acc: 0.9124\n",
      "Epoch 049 | Train Loss: 0.1199 Acc: 0.9546 | Val Loss: 0.1860 Acc: 0.9342\n",
      "Epoch 050 | Train Loss: 0.1192 Acc: 0.9544 | Val Loss: 0.2127 Acc: 0.9239\n",
      "Epoch 051 | Train Loss: 0.1164 Acc: 0.9556 | Val Loss: 0.1837 Acc: 0.9306\n",
      "Epoch 052 | Train Loss: 0.1139 Acc: 0.9562 | Val Loss: 0.1894 Acc: 0.9257\n",
      "Epoch 053 | Train Loss: 0.1092 Acc: 0.9579 | Val Loss: 0.2180 Acc: 0.9130\n",
      "Epoch 054 | Train Loss: 0.1179 Acc: 0.9562 | Val Loss: 0.2706 Acc: 0.9058\n",
      "Epoch 055 | Train Loss: 0.1280 Acc: 0.9536 | Val Loss: 0.1854 Acc: 0.9306\n",
      "Epoch 056 | Train Loss: 0.1169 Acc: 0.9532 | Val Loss: 0.2071 Acc: 0.9275\n",
      "Epoch 057 | Train Loss: 0.1131 Acc: 0.9579 | Val Loss: 0.1648 Acc: 0.9372\n",
      "Epoch 058 | Train Loss: 0.1035 Acc: 0.9635 | Val Loss: 0.2346 Acc: 0.9227\n",
      "Epoch 059 | Train Loss: 0.0999 Acc: 0.9621 | Val Loss: 0.2123 Acc: 0.9287\n",
      "Epoch 060 | Train Loss: 0.1017 Acc: 0.9636 | Val Loss: 0.2190 Acc: 0.9269\n",
      "Epoch 001 | Train Loss: 0.6787 Acc: 0.5821 | Val Loss: 0.6770 Acc: 0.5803\n",
      "Epoch 002 | Train Loss: 0.6624 Acc: 0.6043 | Val Loss: 0.7038 Acc: 0.5326\n",
      "Epoch 003 | Train Loss: 0.6441 Acc: 0.6437 | Val Loss: 0.6081 Acc: 0.6793\n",
      "Epoch 004 | Train Loss: 0.6137 Acc: 0.6793 | Val Loss: 0.5900 Acc: 0.7029\n",
      "Epoch 005 | Train Loss: 0.5837 Acc: 0.7096 | Val Loss: 0.5807 Acc: 0.7114\n",
      "Epoch 006 | Train Loss: 0.5683 Acc: 0.7170 | Val Loss: 0.5651 Acc: 0.7198\n",
      "Epoch 007 | Train Loss: 0.5409 Acc: 0.7398 | Val Loss: 0.5845 Acc: 0.7083\n",
      "Epoch 008 | Train Loss: 0.5336 Acc: 0.7386 | Val Loss: 0.5359 Acc: 0.7325\n",
      "Epoch 009 | Train Loss: 0.5206 Acc: 0.7519 | Val Loss: 0.5374 Acc: 0.7295\n",
      "Epoch 010 | Train Loss: 0.5193 Acc: 0.7528 | Val Loss: 0.5339 Acc: 0.7277\n",
      "Epoch 011 | Train Loss: 0.4998 Acc: 0.7640 | Val Loss: 0.5081 Acc: 0.7446\n",
      "Epoch 012 | Train Loss: 0.4912 Acc: 0.7676 | Val Loss: 0.5027 Acc: 0.7542\n",
      "Epoch 013 | Train Loss: 0.4792 Acc: 0.7783 | Val Loss: 0.4883 Acc: 0.7566\n",
      "Epoch 014 | Train Loss: 0.4613 Acc: 0.7842 | Val Loss: 0.4713 Acc: 0.7760\n",
      "Epoch 015 | Train Loss: 0.4483 Acc: 0.7903 | Val Loss: 0.4741 Acc: 0.7760\n",
      "Epoch 016 | Train Loss: 0.4403 Acc: 0.8011 | Val Loss: 0.4768 Acc: 0.7729\n",
      "Epoch 017 | Train Loss: 0.4307 Acc: 0.8021 | Val Loss: 0.4417 Acc: 0.7923\n",
      "Epoch 018 | Train Loss: 0.4079 Acc: 0.8125 | Val Loss: 0.4201 Acc: 0.8001\n",
      "Epoch 019 | Train Loss: 0.3962 Acc: 0.8178 | Val Loss: 0.4128 Acc: 0.8116\n",
      "Epoch 020 | Train Loss: 0.3770 Acc: 0.8279 | Val Loss: 0.4264 Acc: 0.8098\n",
      "Epoch 021 | Train Loss: 0.3609 Acc: 0.8336 | Val Loss: 0.3687 Acc: 0.8315\n",
      "Epoch 022 | Train Loss: 0.3580 Acc: 0.8410 | Val Loss: 0.4268 Acc: 0.8013\n",
      "Epoch 023 | Train Loss: 0.3478 Acc: 0.8445 | Val Loss: 0.3396 Acc: 0.8551\n",
      "Epoch 024 | Train Loss: 0.3362 Acc: 0.8495 | Val Loss: 0.3567 Acc: 0.8370\n",
      "Epoch 025 | Train Loss: 0.3271 Acc: 0.8558 | Val Loss: 0.3384 Acc: 0.8424\n",
      "Epoch 026 | Train Loss: 0.3019 Acc: 0.8644 | Val Loss: 0.3278 Acc: 0.8569\n",
      "Epoch 027 | Train Loss: 0.2826 Acc: 0.8825 | Val Loss: 0.3643 Acc: 0.8406\n",
      "Epoch 028 | Train Loss: 0.2754 Acc: 0.8813 | Val Loss: 0.2932 Acc: 0.8774\n",
      "Epoch 029 | Train Loss: 0.2607 Acc: 0.8917 | Val Loss: 0.2739 Acc: 0.8859\n",
      "Epoch 030 | Train Loss: 0.2449 Acc: 0.8943 | Val Loss: 0.2864 Acc: 0.8835\n",
      "Epoch 031 | Train Loss: 0.2332 Acc: 0.8978 | Val Loss: 0.2639 Acc: 0.8943\n",
      "Epoch 032 | Train Loss: 0.2404 Acc: 0.9008 | Val Loss: 0.2434 Acc: 0.8973\n",
      "Epoch 033 | Train Loss: 0.2089 Acc: 0.9144 | Val Loss: 0.2640 Acc: 0.9010\n",
      "Epoch 034 | Train Loss: 0.2079 Acc: 0.9120 | Val Loss: 0.2441 Acc: 0.8913\n",
      "Epoch 035 | Train Loss: 0.2057 Acc: 0.9129 | Val Loss: 0.2310 Acc: 0.8998\n",
      "Epoch 036 | Train Loss: 0.1842 Acc: 0.9239 | Val Loss: 0.2505 Acc: 0.8901\n",
      "Epoch 037 | Train Loss: 0.1809 Acc: 0.9259 | Val Loss: 0.2328 Acc: 0.9082\n",
      "Epoch 038 | Train Loss: 0.1713 Acc: 0.9325 | Val Loss: 0.2420 Acc: 0.9070\n",
      "Epoch 039 | Train Loss: 0.1741 Acc: 0.9299 | Val Loss: 0.2792 Acc: 0.8961\n",
      "Epoch 040 | Train Loss: 0.1483 Acc: 0.9393 | Val Loss: 0.2208 Acc: 0.9070\n",
      "Epoch 041 | Train Loss: 0.1473 Acc: 0.9429 | Val Loss: 0.1959 Acc: 0.9348\n",
      "Epoch 042 | Train Loss: 0.1470 Acc: 0.9425 | Val Loss: 0.2129 Acc: 0.9287\n",
      "Epoch 043 | Train Loss: 0.1392 Acc: 0.9455 | Val Loss: 0.1949 Acc: 0.9269\n",
      "Epoch 044 | Train Loss: 0.1345 Acc: 0.9488 | Val Loss: 0.2194 Acc: 0.9185\n",
      "Epoch 045 | Train Loss: 0.1312 Acc: 0.9505 | Val Loss: 0.1810 Acc: 0.9324\n",
      "Epoch 046 | Train Loss: 0.1263 Acc: 0.9518 | Val Loss: 0.2000 Acc: 0.9257\n",
      "Epoch 047 | Train Loss: 0.1243 Acc: 0.9505 | Val Loss: 0.1870 Acc: 0.9372\n",
      "Epoch 048 | Train Loss: 0.1201 Acc: 0.9526 | Val Loss: 0.1921 Acc: 0.9281\n",
      "Epoch 049 | Train Loss: 0.1151 Acc: 0.9597 | Val Loss: 0.2641 Acc: 0.9016\n",
      "Epoch 050 | Train Loss: 0.1170 Acc: 0.9544 | Val Loss: 0.2024 Acc: 0.9233\n",
      "Epoch 051 | Train Loss: 0.1163 Acc: 0.9579 | Val Loss: 0.1912 Acc: 0.9281\n",
      "Epoch 052 | Train Loss: 0.1076 Acc: 0.9594 | Val Loss: 0.2523 Acc: 0.9155\n",
      "Epoch 053 | Train Loss: 0.1140 Acc: 0.9562 | Val Loss: 0.1821 Acc: 0.9324\n",
      "Epoch 054 | Train Loss: 0.0952 Acc: 0.9632 | Val Loss: 0.1815 Acc: 0.9378\n",
      "Epoch 055 | Train Loss: 0.0942 Acc: 0.9635 | Val Loss: 0.1820 Acc: 0.9438\n",
      "Early stopping triggered.\n",
      "Epoch 001 | Train Loss: 0.6876 Acc: 0.5448 | Val Loss: 0.6800 Acc: 0.5761\n",
      "Epoch 002 | Train Loss: 0.6756 Acc: 0.5864 | Val Loss: 0.6773 Acc: 0.5809\n",
      "Epoch 003 | Train Loss: 0.6686 Acc: 0.5982 | Val Loss: 0.6748 Acc: 0.5749\n",
      "Epoch 004 | Train Loss: 0.6563 Acc: 0.6154 | Val Loss: 0.6426 Acc: 0.6401\n",
      "Epoch 005 | Train Loss: 0.6360 Acc: 0.6529 | Val Loss: 0.6498 Acc: 0.6117\n",
      "Epoch 006 | Train Loss: 0.6155 Acc: 0.6769 | Val Loss: 0.6235 Acc: 0.6576\n",
      "Epoch 007 | Train Loss: 0.6067 Acc: 0.6813 | Val Loss: 0.6040 Acc: 0.6872\n",
      "Epoch 008 | Train Loss: 0.5995 Acc: 0.6909 | Val Loss: 0.5929 Acc: 0.6950\n",
      "Epoch 009 | Train Loss: 0.5922 Acc: 0.6974 | Val Loss: 0.5851 Acc: 0.6993\n",
      "Epoch 010 | Train Loss: 0.5846 Acc: 0.7036 | Val Loss: 0.5823 Acc: 0.6981\n",
      "Epoch 011 | Train Loss: 0.5756 Acc: 0.7107 | Val Loss: 0.5721 Acc: 0.7162\n",
      "Epoch 012 | Train Loss: 0.5693 Acc: 0.7128 | Val Loss: 0.5920 Acc: 0.6938\n",
      "Epoch 013 | Train Loss: 0.5611 Acc: 0.7207 | Val Loss: 0.5605 Acc: 0.7186\n",
      "Epoch 014 | Train Loss: 0.5522 Acc: 0.7300 | Val Loss: 0.5566 Acc: 0.7162\n",
      "Epoch 015 | Train Loss: 0.5481 Acc: 0.7296 | Val Loss: 0.5511 Acc: 0.7216\n",
      "Epoch 016 | Train Loss: 0.5388 Acc: 0.7335 | Val Loss: 0.5462 Acc: 0.7228\n",
      "Epoch 017 | Train Loss: 0.5328 Acc: 0.7391 | Val Loss: 0.5354 Acc: 0.7319\n",
      "Epoch 018 | Train Loss: 0.5278 Acc: 0.7415 | Val Loss: 0.5341 Acc: 0.7331\n",
      "Epoch 019 | Train Loss: 0.5138 Acc: 0.7527 | Val Loss: 0.5369 Acc: 0.7313\n",
      "Epoch 020 | Train Loss: 0.5047 Acc: 0.7592 | Val Loss: 0.5191 Acc: 0.7440\n",
      "Epoch 021 | Train Loss: 0.4991 Acc: 0.7664 | Val Loss: 0.5193 Acc: 0.7397\n",
      "Epoch 022 | Train Loss: 0.4903 Acc: 0.7663 | Val Loss: 0.5264 Acc: 0.7337\n",
      "Epoch 023 | Train Loss: 0.4865 Acc: 0.7669 | Val Loss: 0.5053 Acc: 0.7524\n",
      "Epoch 024 | Train Loss: 0.4731 Acc: 0.7799 | Val Loss: 0.4984 Acc: 0.7524\n",
      "Epoch 025 | Train Loss: 0.4714 Acc: 0.7746 | Val Loss: 0.5120 Acc: 0.7458\n",
      "Epoch 026 | Train Loss: 0.4639 Acc: 0.7785 | Val Loss: 0.4908 Acc: 0.7597\n",
      "Epoch 027 | Train Loss: 0.4579 Acc: 0.7907 | Val Loss: 0.5067 Acc: 0.7476\n",
      "Epoch 028 | Train Loss: 0.4541 Acc: 0.7904 | Val Loss: 0.4807 Acc: 0.7651\n",
      "Epoch 029 | Train Loss: 0.4409 Acc: 0.7962 | Val Loss: 0.4906 Acc: 0.7585\n",
      "Epoch 030 | Train Loss: 0.4365 Acc: 0.7989 | Val Loss: 0.4813 Acc: 0.7742\n",
      "Epoch 031 | Train Loss: 0.4357 Acc: 0.8001 | Val Loss: 0.4555 Acc: 0.7826\n",
      "Epoch 032 | Train Loss: 0.4270 Acc: 0.8034 | Val Loss: 0.4618 Acc: 0.7868\n",
      "Epoch 033 | Train Loss: 0.4179 Acc: 0.8066 | Val Loss: 0.4514 Acc: 0.7856\n",
      "Epoch 034 | Train Loss: 0.4229 Acc: 0.8055 | Val Loss: 0.4409 Acc: 0.8001\n",
      "Epoch 035 | Train Loss: 0.4045 Acc: 0.8188 | Val Loss: 0.4245 Acc: 0.8025\n",
      "Epoch 036 | Train Loss: 0.4014 Acc: 0.8120 | Val Loss: 0.4297 Acc: 0.7995\n",
      "Epoch 037 | Train Loss: 0.4018 Acc: 0.8158 | Val Loss: 0.4248 Acc: 0.8086\n",
      "Epoch 038 | Train Loss: 0.3899 Acc: 0.8218 | Val Loss: 0.4085 Acc: 0.8146\n",
      "Epoch 039 | Train Loss: 0.3856 Acc: 0.8265 | Val Loss: 0.4066 Acc: 0.8146\n",
      "Epoch 040 | Train Loss: 0.3812 Acc: 0.8267 | Val Loss: 0.3933 Acc: 0.8200\n",
      "Epoch 041 | Train Loss: 0.3686 Acc: 0.8304 | Val Loss: 0.3830 Acc: 0.8261\n",
      "Epoch 042 | Train Loss: 0.3657 Acc: 0.8333 | Val Loss: 0.3817 Acc: 0.8279\n",
      "Epoch 043 | Train Loss: 0.3570 Acc: 0.8389 | Val Loss: 0.3826 Acc: 0.8279\n",
      "Epoch 044 | Train Loss: 0.3497 Acc: 0.8430 | Val Loss: 0.3714 Acc: 0.8364\n",
      "Epoch 045 | Train Loss: 0.3418 Acc: 0.8431 | Val Loss: 0.3707 Acc: 0.8309\n",
      "Epoch 046 | Train Loss: 0.3393 Acc: 0.8467 | Val Loss: 0.3677 Acc: 0.8382\n",
      "Epoch 047 | Train Loss: 0.3444 Acc: 0.8433 | Val Loss: 0.3625 Acc: 0.8424\n",
      "Epoch 048 | Train Loss: 0.3221 Acc: 0.8591 | Val Loss: 0.3988 Acc: 0.8146\n",
      "Epoch 049 | Train Loss: 0.3271 Acc: 0.8529 | Val Loss: 0.3655 Acc: 0.8333\n",
      "Epoch 050 | Train Loss: 0.3145 Acc: 0.8599 | Val Loss: 0.3415 Acc: 0.8478\n",
      "Epoch 051 | Train Loss: 0.3045 Acc: 0.8650 | Val Loss: 0.3363 Acc: 0.8539\n",
      "Epoch 052 | Train Loss: 0.2983 Acc: 0.8668 | Val Loss: 0.3371 Acc: 0.8508\n",
      "Epoch 053 | Train Loss: 0.3004 Acc: 0.8698 | Val Loss: 0.3289 Acc: 0.8575\n",
      "Epoch 054 | Train Loss: 0.2926 Acc: 0.8727 | Val Loss: 0.3262 Acc: 0.8539\n",
      "Epoch 055 | Train Loss: 0.2875 Acc: 0.8732 | Val Loss: 0.3291 Acc: 0.8623\n",
      "Epoch 056 | Train Loss: 0.2835 Acc: 0.8794 | Val Loss: 0.3078 Acc: 0.8678\n",
      "Epoch 057 | Train Loss: 0.2729 Acc: 0.8806 | Val Loss: 0.3163 Acc: 0.8629\n",
      "Epoch 058 | Train Loss: 0.2733 Acc: 0.8833 | Val Loss: 0.3189 Acc: 0.8702\n",
      "Epoch 059 | Train Loss: 0.2633 Acc: 0.8875 | Val Loss: 0.3199 Acc: 0.8629\n",
      "Epoch 060 | Train Loss: 0.2618 Acc: 0.8895 | Val Loss: 0.3659 Acc: 0.8448\n",
      "Epoch 001 | Train Loss: 0.6825 Acc: 0.5683 | Val Loss: 0.6741 Acc: 0.5936\n",
      "Epoch 002 | Train Loss: 0.6704 Acc: 0.6023 | Val Loss: 0.6769 Acc: 0.5803\n",
      "Epoch 003 | Train Loss: 0.6659 Acc: 0.6065 | Val Loss: 0.6648 Acc: 0.6008\n",
      "Epoch 004 | Train Loss: 0.6541 Acc: 0.6246 | Val Loss: 0.6731 Acc: 0.5900\n",
      "Epoch 005 | Train Loss: 0.6362 Acc: 0.6541 | Val Loss: 0.6139 Acc: 0.6800\n",
      "Epoch 006 | Train Loss: 0.5861 Acc: 0.7054 | Val Loss: 0.6166 Acc: 0.6534\n",
      "Epoch 007 | Train Loss: 0.5635 Acc: 0.7249 | Val Loss: 0.5569 Acc: 0.7192\n",
      "Epoch 008 | Train Loss: 0.5300 Acc: 0.7445 | Val Loss: 0.5346 Acc: 0.7403\n",
      "Epoch 009 | Train Loss: 0.5056 Acc: 0.7583 | Val Loss: 0.5240 Acc: 0.7554\n",
      "Epoch 010 | Train Loss: 0.4926 Acc: 0.7720 | Val Loss: 0.4830 Acc: 0.7717\n",
      "Epoch 011 | Train Loss: 0.4560 Acc: 0.7928 | Val Loss: 0.4532 Acc: 0.7838\n",
      "Epoch 012 | Train Loss: 0.4244 Acc: 0.8135 | Val Loss: 0.5048 Acc: 0.7609\n",
      "Epoch 013 | Train Loss: 0.4137 Acc: 0.8146 | Val Loss: 0.3944 Acc: 0.8182\n",
      "Epoch 014 | Train Loss: 0.3867 Acc: 0.8270 | Val Loss: 0.4066 Acc: 0.8074\n",
      "Epoch 015 | Train Loss: 0.3727 Acc: 0.8371 | Val Loss: 0.3674 Acc: 0.8406\n",
      "Epoch 016 | Train Loss: 0.3545 Acc: 0.8445 | Val Loss: 0.3466 Acc: 0.8472\n",
      "Epoch 017 | Train Loss: 0.3250 Acc: 0.8558 | Val Loss: 0.3492 Acc: 0.8521\n",
      "Epoch 018 | Train Loss: 0.3123 Acc: 0.8665 | Val Loss: 0.3083 Acc: 0.8665\n",
      "Epoch 019 | Train Loss: 0.2963 Acc: 0.8756 | Val Loss: 0.3262 Acc: 0.8551\n",
      "Epoch 020 | Train Loss: 0.3066 Acc: 0.8715 | Val Loss: 0.3020 Acc: 0.8587\n",
      "Epoch 021 | Train Loss: 0.2836 Acc: 0.8836 | Val Loss: 0.2875 Acc: 0.8816\n",
      "Epoch 022 | Train Loss: 0.2606 Acc: 0.8904 | Val Loss: 0.2684 Acc: 0.8992\n",
      "Epoch 023 | Train Loss: 0.2434 Acc: 0.8963 | Val Loss: 0.2507 Acc: 0.9082\n",
      "Epoch 024 | Train Loss: 0.2458 Acc: 0.8975 | Val Loss: 0.2593 Acc: 0.8967\n",
      "Epoch 025 | Train Loss: 0.2351 Acc: 0.9080 | Val Loss: 0.2351 Acc: 0.9112\n",
      "Epoch 026 | Train Loss: 0.2187 Acc: 0.9108 | Val Loss: 0.2573 Acc: 0.8949\n",
      "Epoch 027 | Train Loss: 0.2084 Acc: 0.9162 | Val Loss: 0.2633 Acc: 0.8949\n",
      "Epoch 028 | Train Loss: 0.2119 Acc: 0.9189 | Val Loss: 0.2268 Acc: 0.9034\n",
      "Epoch 029 | Train Loss: 0.1884 Acc: 0.9278 | Val Loss: 0.2192 Acc: 0.9118\n",
      "Epoch 030 | Train Loss: 0.1921 Acc: 0.9221 | Val Loss: 0.2127 Acc: 0.9245\n",
      "Epoch 031 | Train Loss: 0.1857 Acc: 0.9233 | Val Loss: 0.2419 Acc: 0.9124\n",
      "Epoch 032 | Train Loss: 0.1807 Acc: 0.9315 | Val Loss: 0.3173 Acc: 0.8665\n",
      "Epoch 033 | Train Loss: 0.1776 Acc: 0.9319 | Val Loss: 0.2085 Acc: 0.9257\n",
      "Epoch 034 | Train Loss: 0.1689 Acc: 0.9342 | Val Loss: 0.2162 Acc: 0.9233\n",
      "Epoch 035 | Train Loss: 0.1829 Acc: 0.9321 | Val Loss: 0.2525 Acc: 0.9010\n",
      "Epoch 036 | Train Loss: 0.1655 Acc: 0.9372 | Val Loss: 0.2092 Acc: 0.9275\n",
      "Epoch 037 | Train Loss: 0.1718 Acc: 0.9360 | Val Loss: 0.1899 Acc: 0.9306\n",
      "Epoch 038 | Train Loss: 0.1611 Acc: 0.9345 | Val Loss: 0.2286 Acc: 0.9161\n",
      "Epoch 039 | Train Loss: 0.1550 Acc: 0.9392 | Val Loss: 0.1772 Acc: 0.9287\n",
      "Epoch 040 | Train Loss: 0.1484 Acc: 0.9437 | Val Loss: 0.1914 Acc: 0.9306\n",
      "Epoch 041 | Train Loss: 0.1429 Acc: 0.9458 | Val Loss: 0.2551 Acc: 0.8998\n",
      "Epoch 042 | Train Loss: 0.1368 Acc: 0.9488 | Val Loss: 0.2066 Acc: 0.9269\n",
      "Epoch 043 | Train Loss: 0.1306 Acc: 0.9527 | Val Loss: 0.1972 Acc: 0.9287\n",
      "Epoch 044 | Train Loss: 0.1247 Acc: 0.9530 | Val Loss: 0.2177 Acc: 0.9293\n",
      "Epoch 045 | Train Loss: 0.1404 Acc: 0.9452 | Val Loss: 0.1900 Acc: 0.9342\n",
      "Epoch 046 | Train Loss: 0.1265 Acc: 0.9527 | Val Loss: 0.2369 Acc: 0.9227\n",
      "Epoch 047 | Train Loss: 0.1201 Acc: 0.9559 | Val Loss: 0.2212 Acc: 0.9215\n",
      "Epoch 048 | Train Loss: 0.1149 Acc: 0.9562 | Val Loss: 0.2486 Acc: 0.9167\n",
      "Epoch 049 | Train Loss: 0.1253 Acc: 0.9568 | Val Loss: 0.2168 Acc: 0.9112\n",
      "Early stopping triggered.\n",
      "Epoch 001 | Train Loss: 0.6883 Acc: 0.5387 | Val Loss: 0.6805 Acc: 0.5797\n",
      "Epoch 002 | Train Loss: 0.6778 Acc: 0.5851 | Val Loss: 0.6774 Acc: 0.5882\n",
      "Epoch 003 | Train Loss: 0.6754 Acc: 0.5890 | Val Loss: 0.6746 Acc: 0.5930\n",
      "Epoch 004 | Train Loss: 0.6718 Acc: 0.5972 | Val Loss: 0.6731 Acc: 0.5882\n",
      "Epoch 005 | Train Loss: 0.6679 Acc: 0.6008 | Val Loss: 0.6661 Acc: 0.5996\n",
      "Epoch 006 | Train Loss: 0.6612 Acc: 0.6095 | Val Loss: 0.6613 Acc: 0.6039\n",
      "Epoch 007 | Train Loss: 0.6561 Acc: 0.6101 | Val Loss: 0.6546 Acc: 0.6093\n",
      "Epoch 008 | Train Loss: 0.6477 Acc: 0.6231 | Val Loss: 0.6370 Acc: 0.6679\n",
      "Epoch 009 | Train Loss: 0.6354 Acc: 0.6533 | Val Loss: 0.6272 Acc: 0.6600\n",
      "Epoch 010 | Train Loss: 0.6201 Acc: 0.6690 | Val Loss: 0.6237 Acc: 0.6588\n",
      "Epoch 011 | Train Loss: 0.6231 Acc: 0.6642 | Val Loss: 0.6087 Acc: 0.6757\n",
      "Epoch 012 | Train Loss: 0.6055 Acc: 0.6876 | Val Loss: 0.5952 Acc: 0.7023\n",
      "Epoch 013 | Train Loss: 0.5957 Acc: 0.6933 | Val Loss: 0.5917 Acc: 0.6957\n",
      "Epoch 014 | Train Loss: 0.5918 Acc: 0.6973 | Val Loss: 0.5874 Acc: 0.6944\n",
      "Epoch 015 | Train Loss: 0.5884 Acc: 0.6991 | Val Loss: 0.5842 Acc: 0.7071\n",
      "Epoch 016 | Train Loss: 0.5770 Acc: 0.7096 | Val Loss: 0.5845 Acc: 0.7065\n",
      "Epoch 017 | Train Loss: 0.5782 Acc: 0.7083 | Val Loss: 0.5801 Acc: 0.7083\n",
      "Epoch 018 | Train Loss: 0.5773 Acc: 0.7063 | Val Loss: 0.5708 Acc: 0.7114\n",
      "Epoch 019 | Train Loss: 0.5728 Acc: 0.7090 | Val Loss: 0.5794 Acc: 0.7041\n",
      "Epoch 020 | Train Loss: 0.5643 Acc: 0.7204 | Val Loss: 0.6039 Acc: 0.6860\n",
      "Epoch 021 | Train Loss: 0.5643 Acc: 0.7184 | Val Loss: 0.5649 Acc: 0.7120\n",
      "Epoch 022 | Train Loss: 0.5621 Acc: 0.7183 | Val Loss: 0.5617 Acc: 0.7204\n",
      "Epoch 023 | Train Loss: 0.5582 Acc: 0.7231 | Val Loss: 0.5651 Acc: 0.7144\n",
      "Epoch 024 | Train Loss: 0.5495 Acc: 0.7285 | Val Loss: 0.5558 Acc: 0.7252\n",
      "Epoch 025 | Train Loss: 0.5526 Acc: 0.7254 | Val Loss: 0.5692 Acc: 0.7144\n",
      "Epoch 026 | Train Loss: 0.5443 Acc: 0.7318 | Val Loss: 0.5638 Acc: 0.7156\n",
      "Epoch 027 | Train Loss: 0.5427 Acc: 0.7352 | Val Loss: 0.5479 Acc: 0.7252\n",
      "Epoch 028 | Train Loss: 0.5377 Acc: 0.7379 | Val Loss: 0.5452 Acc: 0.7331\n",
      "Epoch 029 | Train Loss: 0.5296 Acc: 0.7427 | Val Loss: 0.5416 Acc: 0.7337\n",
      "Epoch 030 | Train Loss: 0.5299 Acc: 0.7432 | Val Loss: 0.5409 Acc: 0.7307\n",
      "Epoch 031 | Train Loss: 0.5305 Acc: 0.7415 | Val Loss: 0.5639 Acc: 0.7180\n",
      "Epoch 032 | Train Loss: 0.5249 Acc: 0.7453 | Val Loss: 0.5392 Acc: 0.7283\n",
      "Epoch 033 | Train Loss: 0.5206 Acc: 0.7469 | Val Loss: 0.5433 Acc: 0.7264\n",
      "Epoch 034 | Train Loss: 0.5189 Acc: 0.7512 | Val Loss: 0.5284 Acc: 0.7349\n",
      "Epoch 035 | Train Loss: 0.5113 Acc: 0.7545 | Val Loss: 0.5232 Acc: 0.7403\n",
      "Epoch 036 | Train Loss: 0.5068 Acc: 0.7572 | Val Loss: 0.5205 Acc: 0.7409\n",
      "Epoch 037 | Train Loss: 0.5004 Acc: 0.7590 | Val Loss: 0.5160 Acc: 0.7434\n",
      "Epoch 038 | Train Loss: 0.5135 Acc: 0.7486 | Val Loss: 0.5335 Acc: 0.7319\n",
      "Epoch 039 | Train Loss: 0.4939 Acc: 0.7652 | Val Loss: 0.5085 Acc: 0.7421\n",
      "Epoch 040 | Train Loss: 0.4955 Acc: 0.7672 | Val Loss: 0.5090 Acc: 0.7452\n",
      "Epoch 041 | Train Loss: 0.4879 Acc: 0.7632 | Val Loss: 0.5080 Acc: 0.7488\n",
      "Epoch 042 | Train Loss: 0.4911 Acc: 0.7622 | Val Loss: 0.5028 Acc: 0.7542\n",
      "Epoch 043 | Train Loss: 0.4746 Acc: 0.7762 | Val Loss: 0.5147 Acc: 0.7458\n",
      "Epoch 044 | Train Loss: 0.4721 Acc: 0.7758 | Val Loss: 0.4987 Acc: 0.7476\n",
      "Epoch 045 | Train Loss: 0.4780 Acc: 0.7726 | Val Loss: 0.4983 Acc: 0.7542\n",
      "Epoch 046 | Train Loss: 0.4590 Acc: 0.7870 | Val Loss: 0.4990 Acc: 0.7500\n",
      "Epoch 047 | Train Loss: 0.4630 Acc: 0.7870 | Val Loss: 0.4872 Acc: 0.7560\n",
      "Epoch 048 | Train Loss: 0.4568 Acc: 0.7851 | Val Loss: 0.4904 Acc: 0.7572\n",
      "Epoch 049 | Train Loss: 0.4487 Acc: 0.7922 | Val Loss: 0.5179 Acc: 0.7397\n",
      "Epoch 050 | Train Loss: 0.4479 Acc: 0.7895 | Val Loss: 0.4654 Acc: 0.7790\n",
      "Epoch 051 | Train Loss: 0.4412 Acc: 0.7924 | Val Loss: 0.4716 Acc: 0.7711\n",
      "Epoch 052 | Train Loss: 0.4388 Acc: 0.7942 | Val Loss: 0.4663 Acc: 0.7742\n",
      "Epoch 053 | Train Loss: 0.4353 Acc: 0.8005 | Val Loss: 0.4564 Acc: 0.7874\n",
      "Epoch 054 | Train Loss: 0.4303 Acc: 0.8034 | Val Loss: 0.4536 Acc: 0.7862\n",
      "Epoch 055 | Train Loss: 0.4295 Acc: 0.7990 | Val Loss: 0.4507 Acc: 0.7880\n",
      "Epoch 056 | Train Loss: 0.4216 Acc: 0.8051 | Val Loss: 0.4532 Acc: 0.7826\n",
      "Epoch 057 | Train Loss: 0.4216 Acc: 0.8058 | Val Loss: 0.4395 Acc: 0.7959\n",
      "Epoch 058 | Train Loss: 0.4208 Acc: 0.8091 | Val Loss: 0.4340 Acc: 0.7983\n",
      "Epoch 059 | Train Loss: 0.4048 Acc: 0.8149 | Val Loss: 0.4324 Acc: 0.8001\n",
      "Epoch 060 | Train Loss: 0.4152 Acc: 0.8101 | Val Loss: 0.4392 Acc: 0.7917\n",
      "Epoch 001 | Train Loss: 0.6833 Acc: 0.5747 | Val Loss: 0.6745 Acc: 0.5870\n",
      "Epoch 002 | Train Loss: 0.6682 Acc: 0.6083 | Val Loss: 0.6670 Acc: 0.6051\n",
      "Epoch 003 | Train Loss: 0.6640 Acc: 0.6077 | Val Loss: 0.6685 Acc: 0.6014\n",
      "Epoch 004 | Train Loss: 0.6836 Acc: 0.5630 | Val Loss: 0.6861 Acc: 0.5586\n",
      "Epoch 005 | Train Loss: 0.6870 Acc: 0.5582 | Val Loss: 0.6859 Acc: 0.5586\n",
      "Epoch 006 | Train Loss: 0.6807 Acc: 0.5757 | Val Loss: 0.6693 Acc: 0.6027\n",
      "Epoch 007 | Train Loss: 0.6692 Acc: 0.6008 | Val Loss: 0.6598 Acc: 0.6069\n",
      "Epoch 008 | Train Loss: 0.6678 Acc: 0.6021 | Val Loss: 0.6884 Acc: 0.5586\n",
      "Epoch 009 | Train Loss: 0.6829 Acc: 0.5712 | Val Loss: 0.6815 Acc: 0.5845\n",
      "Epoch 010 | Train Loss: 0.6720 Acc: 0.5953 | Val Loss: 0.6591 Acc: 0.5966\n",
      "Epoch 011 | Train Loss: 0.6364 Acc: 0.6545 | Val Loss: 0.5990 Acc: 0.6987\n",
      "Epoch 012 | Train Loss: 0.6089 Acc: 0.6834 | Val Loss: 0.5815 Acc: 0.7041\n",
      "Epoch 013 | Train Loss: 0.5676 Acc: 0.7173 | Val Loss: 0.5407 Acc: 0.7289\n",
      "Epoch 014 | Train Loss: 0.5529 Acc: 0.7332 | Val Loss: 0.5528 Acc: 0.7192\n",
      "Epoch 015 | Train Loss: 0.5331 Acc: 0.7392 | Val Loss: 0.5320 Acc: 0.7301\n",
      "Epoch 016 | Train Loss: 0.5266 Acc: 0.7474 | Val Loss: 0.5126 Acc: 0.7434\n",
      "Epoch 017 | Train Loss: 0.5015 Acc: 0.7639 | Val Loss: 0.4924 Acc: 0.7645\n",
      "Epoch 018 | Train Loss: 0.5043 Acc: 0.7574 | Val Loss: 0.5097 Acc: 0.7657\n",
      "Epoch 019 | Train Loss: 0.4833 Acc: 0.7723 | Val Loss: 0.4645 Acc: 0.7627\n",
      "Epoch 020 | Train Loss: 0.4708 Acc: 0.7830 | Val Loss: 0.4555 Acc: 0.7754\n",
      "Epoch 021 | Train Loss: 0.4578 Acc: 0.7885 | Val Loss: 0.4372 Acc: 0.7826\n",
      "Epoch 022 | Train Loss: 0.4389 Acc: 0.7941 | Val Loss: 0.4471 Acc: 0.7736\n",
      "Epoch 023 | Train Loss: 0.4283 Acc: 0.8067 | Val Loss: 0.4350 Acc: 0.7953\n",
      "Epoch 024 | Train Loss: 0.4242 Acc: 0.7989 | Val Loss: 0.4161 Acc: 0.8110\n",
      "Epoch 025 | Train Loss: 0.4023 Acc: 0.8185 | Val Loss: 0.4218 Acc: 0.7977\n",
      "Epoch 026 | Train Loss: 0.3885 Acc: 0.8274 | Val Loss: 0.3812 Acc: 0.8309\n",
      "Epoch 027 | Train Loss: 0.3821 Acc: 0.8339 | Val Loss: 0.4210 Acc: 0.8080\n",
      "Epoch 028 | Train Loss: 0.3725 Acc: 0.8384 | Val Loss: 0.3409 Acc: 0.8629\n",
      "Epoch 029 | Train Loss: 0.3474 Acc: 0.8490 | Val Loss: 0.3318 Acc: 0.8678\n",
      "Epoch 030 | Train Loss: 0.3508 Acc: 0.8489 | Val Loss: 0.3725 Acc: 0.8424\n",
      "Epoch 031 | Train Loss: 0.3423 Acc: 0.8551 | Val Loss: 0.3109 Acc: 0.8690\n",
      "Epoch 032 | Train Loss: 0.3140 Acc: 0.8685 | Val Loss: 0.3309 Acc: 0.8496\n",
      "Epoch 033 | Train Loss: 0.3063 Acc: 0.8748 | Val Loss: 0.3079 Acc: 0.8708\n",
      "Epoch 034 | Train Loss: 0.2967 Acc: 0.8794 | Val Loss: 0.3133 Acc: 0.8641\n",
      "Epoch 035 | Train Loss: 0.2923 Acc: 0.8786 | Val Loss: 0.2896 Acc: 0.8829\n",
      "Epoch 036 | Train Loss: 0.2681 Acc: 0.8913 | Val Loss: 0.3290 Acc: 0.8599\n",
      "Epoch 037 | Train Loss: 0.2782 Acc: 0.8857 | Val Loss: 0.3051 Acc: 0.8684\n",
      "Epoch 038 | Train Loss: 0.2742 Acc: 0.8895 | Val Loss: 0.2817 Acc: 0.8804\n",
      "Epoch 039 | Train Loss: 0.2548 Acc: 0.8993 | Val Loss: 0.3551 Acc: 0.8496\n",
      "Epoch 040 | Train Loss: 0.2581 Acc: 0.8925 | Val Loss: 0.2691 Acc: 0.8907\n",
      "Epoch 041 | Train Loss: 0.2413 Acc: 0.9013 | Val Loss: 0.2633 Acc: 0.8943\n",
      "Epoch 042 | Train Loss: 0.2314 Acc: 0.9093 | Val Loss: 0.2559 Acc: 0.8967\n",
      "Epoch 043 | Train Loss: 0.2447 Acc: 0.8990 | Val Loss: 0.2507 Acc: 0.8992\n",
      "Epoch 044 | Train Loss: 0.2307 Acc: 0.9083 | Val Loss: 0.2429 Acc: 0.9034\n",
      "Epoch 045 | Train Loss: 0.2215 Acc: 0.9109 | Val Loss: 0.3564 Acc: 0.8768\n",
      "Epoch 046 | Train Loss: 0.2145 Acc: 0.9162 | Val Loss: 0.2659 Acc: 0.8967\n",
      "Epoch 047 | Train Loss: 0.2216 Acc: 0.9136 | Val Loss: 0.2786 Acc: 0.8955\n",
      "Epoch 048 | Train Loss: 0.2201 Acc: 0.9165 | Val Loss: 0.2451 Acc: 0.9016\n",
      "Epoch 049 | Train Loss: 0.2053 Acc: 0.9222 | Val Loss: 0.2358 Acc: 0.9040\n",
      "Epoch 050 | Train Loss: 0.2073 Acc: 0.9161 | Val Loss: 0.2706 Acc: 0.8913\n",
      "Epoch 051 | Train Loss: 0.2049 Acc: 0.9197 | Val Loss: 0.2564 Acc: 0.9058\n",
      "Epoch 052 | Train Loss: 0.1837 Acc: 0.9287 | Val Loss: 0.2516 Acc: 0.9064\n",
      "Epoch 053 | Train Loss: 0.1839 Acc: 0.9283 | Val Loss: 0.2242 Acc: 0.9112\n",
      "Epoch 054 | Train Loss: 0.2010 Acc: 0.9228 | Val Loss: 0.2513 Acc: 0.9100\n",
      "Epoch 055 | Train Loss: 0.1829 Acc: 0.9289 | Val Loss: 0.2334 Acc: 0.9167\n",
      "Epoch 056 | Train Loss: 0.1772 Acc: 0.9307 | Val Loss: 0.2076 Acc: 0.9275\n",
      "Epoch 057 | Train Loss: 0.1611 Acc: 0.9396 | Val Loss: 0.2392 Acc: 0.9173\n",
      "Epoch 058 | Train Loss: 0.1819 Acc: 0.9295 | Val Loss: 0.2274 Acc: 0.9143\n",
      "Epoch 059 | Train Loss: 0.1712 Acc: 0.9333 | Val Loss: 0.2519 Acc: 0.9070\n",
      "Epoch 060 | Train Loss: 0.1741 Acc: 0.9357 | Val Loss: 0.1949 Acc: 0.9269\n",
      "Epoch 001 | Train Loss: 0.6841 Acc: 0.5688 | Val Loss: 0.6812 Acc: 0.5779\n",
      "Epoch 002 | Train Loss: 0.6793 Acc: 0.5827 | Val Loss: 0.6636 Acc: 0.6027\n",
      "Epoch 003 | Train Loss: 0.6568 Acc: 0.6255 | Val Loss: 0.6823 Acc: 0.5978\n",
      "Epoch 004 | Train Loss: 0.6337 Acc: 0.6615 | Val Loss: 0.6352 Acc: 0.6558\n",
      "Epoch 005 | Train Loss: 0.6154 Acc: 0.6823 | Val Loss: 0.6022 Acc: 0.6800\n",
      "Epoch 006 | Train Loss: 0.5877 Acc: 0.7075 | Val Loss: 0.5936 Acc: 0.6969\n",
      "Epoch 007 | Train Loss: 0.5803 Acc: 0.7142 | Val Loss: 0.5734 Acc: 0.7041\n",
      "Epoch 008 | Train Loss: 0.5706 Acc: 0.7161 | Val Loss: 0.5686 Acc: 0.7005\n",
      "Epoch 009 | Train Loss: 0.5601 Acc: 0.7241 | Val Loss: 0.5598 Acc: 0.7234\n",
      "Epoch 010 | Train Loss: 0.5533 Acc: 0.7293 | Val Loss: 0.5341 Acc: 0.7319\n",
      "Epoch 011 | Train Loss: 0.5409 Acc: 0.7341 | Val Loss: 0.5313 Acc: 0.7246\n",
      "Epoch 012 | Train Loss: 0.5337 Acc: 0.7401 | Val Loss: 0.5200 Acc: 0.7379\n",
      "Epoch 013 | Train Loss: 0.5155 Acc: 0.7495 | Val Loss: 0.5023 Acc: 0.7506\n",
      "Epoch 014 | Train Loss: 0.5001 Acc: 0.7614 | Val Loss: 0.5082 Acc: 0.7597\n",
      "Epoch 015 | Train Loss: 0.4821 Acc: 0.7735 | Val Loss: 0.4887 Acc: 0.7603\n",
      "Epoch 016 | Train Loss: 0.4718 Acc: 0.7780 | Val Loss: 0.4713 Acc: 0.7524\n",
      "Epoch 017 | Train Loss: 0.4521 Acc: 0.7842 | Val Loss: 0.4308 Acc: 0.7844\n",
      "Epoch 018 | Train Loss: 0.4339 Acc: 0.7990 | Val Loss: 0.4165 Acc: 0.7989\n",
      "Epoch 019 | Train Loss: 0.4180 Acc: 0.8039 | Val Loss: 0.4275 Acc: 0.7959\n",
      "Epoch 020 | Train Loss: 0.3885 Acc: 0.8205 | Val Loss: 0.3854 Acc: 0.8213\n",
      "Epoch 021 | Train Loss: 0.3735 Acc: 0.8351 | Val Loss: 0.3722 Acc: 0.8261\n",
      "Epoch 022 | Train Loss: 0.3693 Acc: 0.8338 | Val Loss: 0.3606 Acc: 0.8255\n",
      "Epoch 023 | Train Loss: 0.3406 Acc: 0.8532 | Val Loss: 0.3284 Acc: 0.8563\n",
      "Epoch 024 | Train Loss: 0.3321 Acc: 0.8551 | Val Loss: 0.3130 Acc: 0.8605\n",
      "Epoch 025 | Train Loss: 0.3106 Acc: 0.8705 | Val Loss: 0.3732 Acc: 0.8394\n",
      "Epoch 026 | Train Loss: 0.3233 Acc: 0.8631 | Val Loss: 0.2795 Acc: 0.8829\n",
      "Epoch 027 | Train Loss: 0.2976 Acc: 0.8756 | Val Loss: 0.3300 Acc: 0.8774\n",
      "Epoch 028 | Train Loss: 0.2995 Acc: 0.8724 | Val Loss: 0.2774 Acc: 0.8829\n",
      "Epoch 029 | Train Loss: 0.2758 Acc: 0.8846 | Val Loss: 0.2545 Acc: 0.8919\n",
      "Epoch 030 | Train Loss: 0.2628 Acc: 0.8937 | Val Loss: 0.2606 Acc: 0.8907\n",
      "Epoch 031 | Train Loss: 0.2618 Acc: 0.8877 | Val Loss: 0.3152 Acc: 0.8708\n",
      "Epoch 032 | Train Loss: 0.2481 Acc: 0.9025 | Val Loss: 0.2977 Acc: 0.8810\n",
      "Epoch 033 | Train Loss: 0.2339 Acc: 0.9074 | Val Loss: 0.2325 Acc: 0.9082\n",
      "Epoch 034 | Train Loss: 0.2323 Acc: 0.9040 | Val Loss: 0.2197 Acc: 0.9130\n",
      "Epoch 035 | Train Loss: 0.2231 Acc: 0.9100 | Val Loss: 0.2751 Acc: 0.8865\n",
      "Epoch 036 | Train Loss: 0.2208 Acc: 0.9111 | Val Loss: 0.2316 Acc: 0.9058\n",
      "Epoch 037 | Train Loss: 0.2213 Acc: 0.9136 | Val Loss: 0.2463 Acc: 0.9034\n",
      "Epoch 038 | Train Loss: 0.2047 Acc: 0.9185 | Val Loss: 0.2447 Acc: 0.8937\n",
      "Epoch 039 | Train Loss: 0.1900 Acc: 0.9256 | Val Loss: 0.2253 Acc: 0.9034\n",
      "Epoch 040 | Train Loss: 0.1997 Acc: 0.9238 | Val Loss: 0.2093 Acc: 0.9149\n",
      "Epoch 041 | Train Loss: 0.1833 Acc: 0.9269 | Val Loss: 0.1941 Acc: 0.9251\n",
      "Epoch 042 | Train Loss: 0.1947 Acc: 0.9247 | Val Loss: 0.1993 Acc: 0.9245\n",
      "Epoch 043 | Train Loss: 0.1847 Acc: 0.9289 | Val Loss: 0.1930 Acc: 0.9209\n",
      "Epoch 044 | Train Loss: 0.1757 Acc: 0.9339 | Val Loss: 0.2030 Acc: 0.9197\n",
      "Epoch 045 | Train Loss: 0.1595 Acc: 0.9402 | Val Loss: 0.2581 Acc: 0.9070\n",
      "Epoch 046 | Train Loss: 0.1751 Acc: 0.9304 | Val Loss: 0.2252 Acc: 0.9167\n",
      "Epoch 047 | Train Loss: 0.1622 Acc: 0.9396 | Val Loss: 0.2200 Acc: 0.9251\n",
      "Epoch 048 | Train Loss: 0.1690 Acc: 0.9331 | Val Loss: 0.2133 Acc: 0.9155\n",
      "Epoch 049 | Train Loss: 0.1629 Acc: 0.9402 | Val Loss: 0.1881 Acc: 0.9263\n",
      "Epoch 050 | Train Loss: 0.1659 Acc: 0.9367 | Val Loss: 0.2060 Acc: 0.9215\n",
      "Epoch 051 | Train Loss: 0.1489 Acc: 0.9423 | Val Loss: 0.1801 Acc: 0.9324\n",
      "Epoch 052 | Train Loss: 0.1420 Acc: 0.9481 | Val Loss: 0.1995 Acc: 0.9293\n",
      "Epoch 053 | Train Loss: 0.1790 Acc: 0.9311 | Val Loss: 0.1987 Acc: 0.9287\n",
      "Epoch 054 | Train Loss: 0.1487 Acc: 0.9422 | Val Loss: 0.2210 Acc: 0.9239\n",
      "Epoch 055 | Train Loss: 0.1397 Acc: 0.9487 | Val Loss: 0.2049 Acc: 0.9239\n",
      "Epoch 056 | Train Loss: 0.1369 Acc: 0.9479 | Val Loss: 0.1811 Acc: 0.9342\n",
      "Epoch 057 | Train Loss: 0.1380 Acc: 0.9484 | Val Loss: 0.1798 Acc: 0.9330\n",
      "Epoch 058 | Train Loss: 0.1403 Acc: 0.9470 | Val Loss: 0.1956 Acc: 0.9275\n",
      "Epoch 059 | Train Loss: 0.1304 Acc: 0.9508 | Val Loss: 0.1632 Acc: 0.9366\n",
      "Epoch 060 | Train Loss: 0.1371 Acc: 0.9512 | Val Loss: 0.1554 Acc: 0.9366\n",
      "Epoch 001 | Train Loss: 0.6781 Acc: 0.5833 | Val Loss: 0.6739 Acc: 0.5912\n",
      "Epoch 002 | Train Loss: 0.6684 Acc: 0.5994 | Val Loss: 0.6636 Acc: 0.6008\n",
      "Epoch 003 | Train Loss: 0.6595 Acc: 0.6068 | Val Loss: 0.6588 Acc: 0.6165\n",
      "Epoch 004 | Train Loss: 0.6358 Acc: 0.6500 | Val Loss: 0.6041 Acc: 0.6872\n",
      "Epoch 005 | Train Loss: 0.6134 Acc: 0.6763 | Val Loss: 0.5889 Acc: 0.6981\n",
      "Epoch 006 | Train Loss: 0.5812 Acc: 0.7090 | Val Loss: 0.5720 Acc: 0.7107\n",
      "Epoch 007 | Train Loss: 0.5585 Acc: 0.7238 | Val Loss: 0.5544 Acc: 0.7198\n",
      "Epoch 008 | Train Loss: 0.5456 Acc: 0.7306 | Val Loss: 0.5512 Acc: 0.7180\n",
      "Epoch 009 | Train Loss: 0.5335 Acc: 0.7397 | Val Loss: 0.5303 Acc: 0.7337\n",
      "Epoch 010 | Train Loss: 0.5155 Acc: 0.7524 | Val Loss: 0.5389 Acc: 0.7295\n",
      "Epoch 011 | Train Loss: 0.5086 Acc: 0.7559 | Val Loss: 0.5159 Acc: 0.7440\n",
      "Epoch 012 | Train Loss: 0.4911 Acc: 0.7657 | Val Loss: 0.5106 Acc: 0.7464\n",
      "Epoch 013 | Train Loss: 0.4782 Acc: 0.7747 | Val Loss: 0.4908 Acc: 0.7585\n",
      "Epoch 014 | Train Loss: 0.4708 Acc: 0.7740 | Val Loss: 0.4845 Acc: 0.7651\n",
      "Epoch 015 | Train Loss: 0.4559 Acc: 0.7854 | Val Loss: 0.4692 Acc: 0.7699\n",
      "Epoch 016 | Train Loss: 0.4501 Acc: 0.7873 | Val Loss: 0.4358 Acc: 0.7953\n",
      "Epoch 017 | Train Loss: 0.4300 Acc: 0.7992 | Val Loss: 0.4453 Acc: 0.7796\n",
      "Epoch 018 | Train Loss: 0.4177 Acc: 0.8034 | Val Loss: 0.4250 Acc: 0.8062\n",
      "Epoch 019 | Train Loss: 0.4099 Acc: 0.8075 | Val Loss: 0.3824 Acc: 0.8170\n",
      "Epoch 020 | Train Loss: 0.3749 Acc: 0.8286 | Val Loss: 0.3644 Acc: 0.8382\n",
      "Epoch 021 | Train Loss: 0.3673 Acc: 0.8304 | Val Loss: 0.3874 Acc: 0.8188\n",
      "Epoch 022 | Train Loss: 0.3535 Acc: 0.8427 | Val Loss: 0.3438 Acc: 0.8400\n",
      "Epoch 023 | Train Loss: 0.3336 Acc: 0.8535 | Val Loss: 0.3214 Acc: 0.8629\n",
      "Epoch 024 | Train Loss: 0.3297 Acc: 0.8558 | Val Loss: 0.3254 Acc: 0.8581\n",
      "Epoch 025 | Train Loss: 0.3074 Acc: 0.8656 | Val Loss: 0.3317 Acc: 0.8545\n",
      "Epoch 026 | Train Loss: 0.2995 Acc: 0.8662 | Val Loss: 0.3031 Acc: 0.8684\n",
      "Epoch 027 | Train Loss: 0.2977 Acc: 0.8754 | Val Loss: 0.3239 Acc: 0.8508\n",
      "Epoch 028 | Train Loss: 0.2839 Acc: 0.8774 | Val Loss: 0.2815 Acc: 0.8859\n",
      "Epoch 029 | Train Loss: 0.2630 Acc: 0.8883 | Val Loss: 0.2797 Acc: 0.8877\n",
      "Epoch 030 | Train Loss: 0.2559 Acc: 0.8949 | Val Loss: 0.2453 Acc: 0.9016\n",
      "Epoch 031 | Train Loss: 0.2502 Acc: 0.8926 | Val Loss: 0.2302 Acc: 0.9106\n",
      "Epoch 032 | Train Loss: 0.2518 Acc: 0.8942 | Val Loss: 0.2349 Acc: 0.9094\n",
      "Epoch 033 | Train Loss: 0.2340 Acc: 0.9035 | Val Loss: 0.2257 Acc: 0.9082\n",
      "Epoch 034 | Train Loss: 0.2226 Acc: 0.9114 | Val Loss: 0.2135 Acc: 0.9203\n",
      "Epoch 035 | Train Loss: 0.2096 Acc: 0.9109 | Val Loss: 0.2277 Acc: 0.9118\n",
      "Epoch 036 | Train Loss: 0.2043 Acc: 0.9157 | Val Loss: 0.2411 Acc: 0.9016\n",
      "Epoch 037 | Train Loss: 0.1980 Acc: 0.9204 | Val Loss: 0.2039 Acc: 0.9130\n",
      "Epoch 038 | Train Loss: 0.1949 Acc: 0.9201 | Val Loss: 0.2280 Acc: 0.9149\n",
      "Epoch 039 | Train Loss: 0.1895 Acc: 0.9188 | Val Loss: 0.1955 Acc: 0.9257\n",
      "Epoch 040 | Train Loss: 0.1885 Acc: 0.9239 | Val Loss: 0.1972 Acc: 0.9269\n",
      "Epoch 041 | Train Loss: 0.1800 Acc: 0.9271 | Val Loss: 0.2045 Acc: 0.9197\n",
      "Epoch 042 | Train Loss: 0.1820 Acc: 0.9295 | Val Loss: 0.1981 Acc: 0.9257\n",
      "Epoch 043 | Train Loss: 0.1650 Acc: 0.9369 | Val Loss: 0.1992 Acc: 0.9239\n",
      "Epoch 044 | Train Loss: 0.1585 Acc: 0.9396 | Val Loss: 0.2107 Acc: 0.9179\n",
      "Epoch 045 | Train Loss: 0.1613 Acc: 0.9361 | Val Loss: 0.2254 Acc: 0.9130\n",
      "Epoch 046 | Train Loss: 0.1488 Acc: 0.9426 | Val Loss: 0.1823 Acc: 0.9281\n",
      "Epoch 047 | Train Loss: 0.1552 Acc: 0.9398 | Val Loss: 0.1848 Acc: 0.9257\n",
      "Epoch 048 | Train Loss: 0.1463 Acc: 0.9428 | Val Loss: 0.1759 Acc: 0.9336\n",
      "Epoch 049 | Train Loss: 0.1541 Acc: 0.9405 | Val Loss: 0.1699 Acc: 0.9312\n",
      "Epoch 050 | Train Loss: 0.1424 Acc: 0.9431 | Val Loss: 0.1968 Acc: 0.9227\n",
      "Epoch 051 | Train Loss: 0.1354 Acc: 0.9469 | Val Loss: 0.1690 Acc: 0.9354\n",
      "Epoch 052 | Train Loss: 0.1509 Acc: 0.9408 | Val Loss: 0.1760 Acc: 0.9257\n",
      "Epoch 053 | Train Loss: 0.1286 Acc: 0.9479 | Val Loss: 0.1885 Acc: 0.9281\n",
      "Epoch 054 | Train Loss: 0.1294 Acc: 0.9521 | Val Loss: 0.1704 Acc: 0.9330\n",
      "Epoch 055 | Train Loss: 0.1273 Acc: 0.9506 | Val Loss: 0.1682 Acc: 0.9336\n",
      "Epoch 056 | Train Loss: 0.1214 Acc: 0.9523 | Val Loss: 0.1776 Acc: 0.9360\n",
      "Epoch 057 | Train Loss: 0.1227 Acc: 0.9535 | Val Loss: 0.1633 Acc: 0.9414\n",
      "Epoch 058 | Train Loss: 0.1183 Acc: 0.9523 | Val Loss: 0.1444 Acc: 0.9481\n",
      "Epoch 059 | Train Loss: 0.1244 Acc: 0.9515 | Val Loss: 0.1545 Acc: 0.9420\n",
      "Epoch 060 | Train Loss: 0.1114 Acc: 0.9595 | Val Loss: 0.1578 Acc: 0.9390\n",
      "Epoch 001 | Train Loss: 0.6796 Acc: 0.5747 | Val Loss: 0.6705 Acc: 0.5803\n",
      "Epoch 002 | Train Loss: 0.6580 Acc: 0.6148 | Val Loss: 0.6356 Acc: 0.6413\n",
      "Epoch 003 | Train Loss: 0.6047 Acc: 0.6844 | Val Loss: 0.6231 Acc: 0.6522\n",
      "Epoch 004 | Train Loss: 0.5815 Acc: 0.7104 | Val Loss: 0.5712 Acc: 0.7204\n",
      "Epoch 005 | Train Loss: 0.5702 Acc: 0.7217 | Val Loss: 0.5628 Acc: 0.7120\n",
      "Epoch 006 | Train Loss: 0.5519 Acc: 0.7261 | Val Loss: 0.5710 Acc: 0.7035\n",
      "Epoch 007 | Train Loss: 0.5402 Acc: 0.7411 | Val Loss: 0.5475 Acc: 0.7246\n",
      "Epoch 008 | Train Loss: 0.5194 Acc: 0.7565 | Val Loss: 0.5251 Acc: 0.7446\n",
      "Epoch 009 | Train Loss: 0.5065 Acc: 0.7648 | Val Loss: 0.5066 Acc: 0.7585\n",
      "Epoch 010 | Train Loss: 0.4843 Acc: 0.7811 | Val Loss: 0.4743 Acc: 0.7705\n",
      "Epoch 011 | Train Loss: 0.4624 Acc: 0.7838 | Val Loss: 0.4695 Acc: 0.7844\n",
      "Epoch 012 | Train Loss: 0.4258 Acc: 0.8090 | Val Loss: 0.4326 Acc: 0.7953\n",
      "Epoch 013 | Train Loss: 0.4075 Acc: 0.8233 | Val Loss: 0.4249 Acc: 0.8128\n",
      "Epoch 014 | Train Loss: 0.3910 Acc: 0.8319 | Val Loss: 0.3883 Acc: 0.8243\n",
      "Epoch 015 | Train Loss: 0.3609 Acc: 0.8470 | Val Loss: 0.3584 Acc: 0.8454\n",
      "Epoch 016 | Train Loss: 0.3465 Acc: 0.8538 | Val Loss: 0.3382 Acc: 0.8563\n",
      "Epoch 017 | Train Loss: 0.3313 Acc: 0.8593 | Val Loss: 0.3174 Acc: 0.8714\n",
      "Epoch 018 | Train Loss: 0.3057 Acc: 0.8750 | Val Loss: 0.3380 Acc: 0.8599\n",
      "Epoch 019 | Train Loss: 0.3068 Acc: 0.8730 | Val Loss: 0.2929 Acc: 0.8750\n",
      "Epoch 020 | Train Loss: 0.2846 Acc: 0.8862 | Val Loss: 0.3041 Acc: 0.8822\n",
      "Epoch 021 | Train Loss: 0.2721 Acc: 0.8872 | Val Loss: 0.2870 Acc: 0.8804\n",
      "Epoch 022 | Train Loss: 0.2598 Acc: 0.8976 | Val Loss: 0.2502 Acc: 0.9034\n",
      "Epoch 023 | Train Loss: 0.2528 Acc: 0.8957 | Val Loss: 0.2801 Acc: 0.8816\n",
      "Epoch 024 | Train Loss: 0.2382 Acc: 0.9077 | Val Loss: 0.2756 Acc: 0.8986\n",
      "Epoch 025 | Train Loss: 0.2406 Acc: 0.9044 | Val Loss: 0.2578 Acc: 0.8998\n",
      "Epoch 026 | Train Loss: 0.2243 Acc: 0.9097 | Val Loss: 0.2423 Acc: 0.9040\n",
      "Epoch 027 | Train Loss: 0.2186 Acc: 0.9168 | Val Loss: 0.2432 Acc: 0.9130\n",
      "Epoch 028 | Train Loss: 0.2158 Acc: 0.9147 | Val Loss: 0.2400 Acc: 0.9064\n",
      "Epoch 029 | Train Loss: 0.1986 Acc: 0.9233 | Val Loss: 0.2242 Acc: 0.9143\n",
      "Epoch 030 | Train Loss: 0.1987 Acc: 0.9203 | Val Loss: 0.2394 Acc: 0.9124\n",
      "Epoch 031 | Train Loss: 0.1950 Acc: 0.9222 | Val Loss: 0.2335 Acc: 0.9040\n",
      "Epoch 032 | Train Loss: 0.1855 Acc: 0.9283 | Val Loss: 0.2904 Acc: 0.8992\n",
      "Epoch 033 | Train Loss: 0.1913 Acc: 0.9230 | Val Loss: 0.2424 Acc: 0.8931\n",
      "Epoch 034 | Train Loss: 0.1773 Acc: 0.9301 | Val Loss: 0.2363 Acc: 0.9161\n",
      "Epoch 035 | Train Loss: 0.1845 Acc: 0.9310 | Val Loss: 0.2058 Acc: 0.9167\n",
      "Epoch 036 | Train Loss: 0.1775 Acc: 0.9370 | Val Loss: 0.2003 Acc: 0.9263\n",
      "Epoch 037 | Train Loss: 0.1721 Acc: 0.9334 | Val Loss: 0.2335 Acc: 0.9197\n",
      "Epoch 038 | Train Loss: 0.1578 Acc: 0.9416 | Val Loss: 0.2026 Acc: 0.9312\n",
      "Epoch 039 | Train Loss: 0.1701 Acc: 0.9357 | Val Loss: 0.2189 Acc: 0.9136\n",
      "Epoch 040 | Train Loss: 0.1603 Acc: 0.9411 | Val Loss: 0.2138 Acc: 0.9173\n",
      "Epoch 041 | Train Loss: 0.1482 Acc: 0.9441 | Val Loss: 0.2465 Acc: 0.9167\n",
      "Epoch 042 | Train Loss: 0.1600 Acc: 0.9405 | Val Loss: 0.2153 Acc: 0.9251\n",
      "Epoch 043 | Train Loss: 0.1645 Acc: 0.9405 | Val Loss: 0.2194 Acc: 0.9185\n",
      "Epoch 044 | Train Loss: 0.1357 Acc: 0.9472 | Val Loss: 0.2630 Acc: 0.9118\n",
      "Epoch 045 | Train Loss: 0.1320 Acc: 0.9521 | Val Loss: 0.2293 Acc: 0.9082\n",
      "Epoch 046 | Train Loss: 0.1474 Acc: 0.9438 | Val Loss: 0.1982 Acc: 0.9281\n",
      "Epoch 047 | Train Loss: 0.1347 Acc: 0.9506 | Val Loss: 0.2038 Acc: 0.9281\n",
      "Epoch 048 | Train Loss: 0.1357 Acc: 0.9473 | Val Loss: 0.2022 Acc: 0.9281\n",
      "Epoch 049 | Train Loss: 0.1294 Acc: 0.9512 | Val Loss: 0.2295 Acc: 0.9263\n",
      "Epoch 050 | Train Loss: 0.1421 Acc: 0.9470 | Val Loss: 0.1985 Acc: 0.9269\n",
      "Epoch 051 | Train Loss: 0.1343 Acc: 0.9512 | Val Loss: 0.2222 Acc: 0.9209\n",
      "Epoch 052 | Train Loss: 0.1223 Acc: 0.9530 | Val Loss: 0.2112 Acc: 0.9245\n",
      "Epoch 053 | Train Loss: 0.1337 Acc: 0.9532 | Val Loss: 0.2256 Acc: 0.9233\n",
      "Epoch 054 | Train Loss: 0.1275 Acc: 0.9547 | Val Loss: 0.2030 Acc: 0.9275\n",
      "Epoch 055 | Train Loss: 0.1278 Acc: 0.9533 | Val Loss: 0.2073 Acc: 0.9239\n",
      "Epoch 056 | Train Loss: 0.1186 Acc: 0.9564 | Val Loss: 0.1918 Acc: 0.9348\n",
      "Epoch 057 | Train Loss: 0.1308 Acc: 0.9532 | Val Loss: 0.1954 Acc: 0.9306\n",
      "Epoch 058 | Train Loss: 0.1136 Acc: 0.9601 | Val Loss: 0.2209 Acc: 0.9118\n",
      "Epoch 059 | Train Loss: 0.1146 Acc: 0.9559 | Val Loss: 0.1842 Acc: 0.9354\n",
      "Epoch 060 | Train Loss: 0.1201 Acc: 0.9553 | Val Loss: 0.2354 Acc: 0.9233\n",
      "Epoch 001 | Train Loss: 0.6818 Acc: 0.5729 | Val Loss: 0.6757 Acc: 0.5833\n",
      "Epoch 002 | Train Loss: 0.6724 Acc: 0.5950 | Val Loss: 0.6711 Acc: 0.5912\n",
      "Epoch 003 | Train Loss: 0.6656 Acc: 0.6006 | Val Loss: 0.6684 Acc: 0.5634\n",
      "Epoch 004 | Train Loss: 0.6285 Acc: 0.6532 | Val Loss: 0.6209 Acc: 0.6618\n",
      "Epoch 005 | Train Loss: 0.5805 Acc: 0.7080 | Val Loss: 0.5705 Acc: 0.7095\n",
      "Epoch 006 | Train Loss: 0.5423 Acc: 0.7329 | Val Loss: 0.5337 Acc: 0.7289\n",
      "Epoch 007 | Train Loss: 0.4972 Acc: 0.7605 | Val Loss: 0.5440 Acc: 0.7464\n",
      "Epoch 008 | Train Loss: 0.4658 Acc: 0.7845 | Val Loss: 0.4781 Acc: 0.7669\n",
      "Epoch 009 | Train Loss: 0.4325 Acc: 0.8025 | Val Loss: 0.4586 Acc: 0.7826\n",
      "Epoch 010 | Train Loss: 0.4036 Acc: 0.8218 | Val Loss: 0.4344 Acc: 0.7923\n",
      "Epoch 011 | Train Loss: 0.3685 Acc: 0.8342 | Val Loss: 0.4033 Acc: 0.8050\n",
      "Epoch 012 | Train Loss: 0.3402 Acc: 0.8538 | Val Loss: 0.3910 Acc: 0.8303\n",
      "Epoch 013 | Train Loss: 0.3108 Acc: 0.8680 | Val Loss: 0.3886 Acc: 0.8345\n",
      "Epoch 014 | Train Loss: 0.2912 Acc: 0.8783 | Val Loss: 0.3332 Acc: 0.8593\n",
      "Epoch 015 | Train Loss: 0.2683 Acc: 0.8914 | Val Loss: 0.3443 Acc: 0.8545\n",
      "Epoch 016 | Train Loss: 0.2423 Acc: 0.8994 | Val Loss: 0.3323 Acc: 0.8593\n",
      "Epoch 017 | Train Loss: 0.2315 Acc: 0.9034 | Val Loss: 0.3496 Acc: 0.8382\n",
      "Epoch 018 | Train Loss: 0.2050 Acc: 0.9168 | Val Loss: 0.2935 Acc: 0.8786\n",
      "Epoch 019 | Train Loss: 0.1840 Acc: 0.9253 | Val Loss: 0.3061 Acc: 0.8744\n",
      "Epoch 020 | Train Loss: 0.1761 Acc: 0.9305 | Val Loss: 0.3264 Acc: 0.8732\n",
      "Epoch 021 | Train Loss: 0.1568 Acc: 0.9392 | Val Loss: 0.2715 Acc: 0.8955\n",
      "Epoch 022 | Train Loss: 0.1437 Acc: 0.9437 | Val Loss: 0.2574 Acc: 0.8992\n",
      "Epoch 023 | Train Loss: 0.1309 Acc: 0.9456 | Val Loss: 0.2752 Acc: 0.9058\n",
      "Epoch 024 | Train Loss: 0.1269 Acc: 0.9475 | Val Loss: 0.2760 Acc: 0.8979\n",
      "Epoch 025 | Train Loss: 0.1129 Acc: 0.9571 | Val Loss: 0.2250 Acc: 0.9161\n",
      "Epoch 026 | Train Loss: 0.0993 Acc: 0.9630 | Val Loss: 0.2560 Acc: 0.9082\n",
      "Epoch 027 | Train Loss: 0.0991 Acc: 0.9650 | Val Loss: 0.2843 Acc: 0.9076\n",
      "Epoch 028 | Train Loss: 0.1001 Acc: 0.9629 | Val Loss: 0.3504 Acc: 0.8804\n",
      "Epoch 029 | Train Loss: 0.0969 Acc: 0.9645 | Val Loss: 0.2537 Acc: 0.9112\n",
      "Epoch 030 | Train Loss: 0.0826 Acc: 0.9707 | Val Loss: 0.2659 Acc: 0.9227\n",
      "Epoch 031 | Train Loss: 0.0783 Acc: 0.9698 | Val Loss: 0.2619 Acc: 0.9143\n",
      "Epoch 032 | Train Loss: 0.0724 Acc: 0.9731 | Val Loss: 0.2372 Acc: 0.9179\n",
      "Epoch 033 | Train Loss: 0.0663 Acc: 0.9766 | Val Loss: 0.3147 Acc: 0.9040\n",
      "Epoch 034 | Train Loss: 0.0691 Acc: 0.9745 | Val Loss: 0.2531 Acc: 0.9203\n",
      "Epoch 035 | Train Loss: 0.0533 Acc: 0.9801 | Val Loss: 0.2490 Acc: 0.9269\n",
      "Early stopping triggered.\n",
      "Iteration 7/40 | Best Val Loss: 0.1394 | Iter Time: 318.46s | Total Time: 37.04 min\n",
      "Epoch 001 | Train Loss: 0.6785 Acc: 0.5846 | Val Loss: 0.6701 Acc: 0.5960\n",
      "Epoch 002 | Train Loss: 0.6729 Acc: 0.5966 | Val Loss: 0.6623 Acc: 0.6063\n",
      "Epoch 003 | Train Loss: 0.6643 Acc: 0.6073 | Val Loss: 0.6584 Acc: 0.6063\n",
      "Epoch 004 | Train Loss: 0.6526 Acc: 0.6231 | Val Loss: 0.6338 Acc: 0.6244\n",
      "Epoch 005 | Train Loss: 0.6072 Acc: 0.6849 | Val Loss: 0.5707 Acc: 0.7156\n",
      "Epoch 006 | Train Loss: 0.5698 Acc: 0.7116 | Val Loss: 0.5785 Acc: 0.7011\n",
      "Epoch 007 | Train Loss: 0.5335 Acc: 0.7417 | Val Loss: 0.5579 Acc: 0.7234\n",
      "Epoch 008 | Train Loss: 0.5220 Acc: 0.7531 | Val Loss: 0.4899 Acc: 0.7536\n",
      "Epoch 009 | Train Loss: 0.4868 Acc: 0.7731 | Val Loss: 0.4798 Acc: 0.7675\n",
      "Epoch 010 | Train Loss: 0.4697 Acc: 0.7862 | Val Loss: 0.4692 Acc: 0.7796\n",
      "Epoch 011 | Train Loss: 0.4627 Acc: 0.7894 | Val Loss: 0.4503 Acc: 0.7886\n",
      "Epoch 012 | Train Loss: 0.4300 Acc: 0.8067 | Val Loss: 0.4117 Acc: 0.8128\n",
      "Epoch 013 | Train Loss: 0.4099 Acc: 0.8182 | Val Loss: 0.3790 Acc: 0.8237\n",
      "Epoch 014 | Train Loss: 0.3889 Acc: 0.8267 | Val Loss: 0.3654 Acc: 0.8364\n",
      "Epoch 015 | Train Loss: 0.3616 Acc: 0.8427 | Val Loss: 0.3632 Acc: 0.8418\n",
      "Epoch 016 | Train Loss: 0.3480 Acc: 0.8487 | Val Loss: 0.3460 Acc: 0.8569\n",
      "Epoch 017 | Train Loss: 0.3239 Acc: 0.8658 | Val Loss: 0.3117 Acc: 0.8732\n",
      "Epoch 018 | Train Loss: 0.3200 Acc: 0.8643 | Val Loss: 0.3182 Acc: 0.8641\n",
      "Epoch 019 | Train Loss: 0.3125 Acc: 0.8735 | Val Loss: 0.3199 Acc: 0.8629\n",
      "Epoch 020 | Train Loss: 0.3005 Acc: 0.8754 | Val Loss: 0.3067 Acc: 0.8714\n",
      "Epoch 021 | Train Loss: 0.2823 Acc: 0.8839 | Val Loss: 0.2750 Acc: 0.8943\n",
      "Epoch 022 | Train Loss: 0.2700 Acc: 0.8914 | Val Loss: 0.2963 Acc: 0.8732\n",
      "Epoch 023 | Train Loss: 0.2601 Acc: 0.8957 | Val Loss: 0.2420 Acc: 0.8992\n",
      "Epoch 024 | Train Loss: 0.2441 Acc: 0.9022 | Val Loss: 0.3181 Acc: 0.8780\n",
      "Epoch 025 | Train Loss: 0.2550 Acc: 0.8960 | Val Loss: 0.2671 Acc: 0.8955\n",
      "Epoch 026 | Train Loss: 0.2357 Acc: 0.9032 | Val Loss: 0.2658 Acc: 0.8895\n",
      "Epoch 027 | Train Loss: 0.2319 Acc: 0.9070 | Val Loss: 0.2350 Acc: 0.9016\n",
      "Epoch 028 | Train Loss: 0.2239 Acc: 0.9074 | Val Loss: 0.2420 Acc: 0.9016\n",
      "Epoch 029 | Train Loss: 0.2252 Acc: 0.9118 | Val Loss: 0.2389 Acc: 0.8986\n",
      "Epoch 030 | Train Loss: 0.2144 Acc: 0.9144 | Val Loss: 0.2200 Acc: 0.9118\n",
      "Epoch 031 | Train Loss: 0.2056 Acc: 0.9168 | Val Loss: 0.2105 Acc: 0.9155\n",
      "Epoch 032 | Train Loss: 0.2068 Acc: 0.9189 | Val Loss: 0.2660 Acc: 0.8943\n",
      "Epoch 033 | Train Loss: 0.1975 Acc: 0.9250 | Val Loss: 0.2070 Acc: 0.9239\n",
      "Epoch 034 | Train Loss: 0.1941 Acc: 0.9228 | Val Loss: 0.2194 Acc: 0.9118\n",
      "Epoch 035 | Train Loss: 0.1859 Acc: 0.9315 | Val Loss: 0.2027 Acc: 0.9233\n",
      "Epoch 036 | Train Loss: 0.1942 Acc: 0.9221 | Val Loss: 0.1874 Acc: 0.9263\n",
      "Epoch 037 | Train Loss: 0.1915 Acc: 0.9228 | Val Loss: 0.2228 Acc: 0.9161\n",
      "Epoch 038 | Train Loss: 0.1741 Acc: 0.9343 | Val Loss: 0.2360 Acc: 0.9082\n",
      "Epoch 039 | Train Loss: 0.1791 Acc: 0.9299 | Val Loss: 0.2150 Acc: 0.9191\n",
      "Epoch 040 | Train Loss: 0.1700 Acc: 0.9392 | Val Loss: 0.2122 Acc: 0.9167\n",
      "Epoch 041 | Train Loss: 0.1647 Acc: 0.9385 | Val Loss: 0.1990 Acc: 0.9269\n",
      "Epoch 042 | Train Loss: 0.1635 Acc: 0.9363 | Val Loss: 0.2116 Acc: 0.9161\n",
      "Epoch 043 | Train Loss: 0.1646 Acc: 0.9369 | Val Loss: 0.2174 Acc: 0.9185\n",
      "Epoch 044 | Train Loss: 0.1608 Acc: 0.9367 | Val Loss: 0.1741 Acc: 0.9324\n",
      "Epoch 045 | Train Loss: 0.1596 Acc: 0.9437 | Val Loss: 0.1742 Acc: 0.9348\n",
      "Epoch 046 | Train Loss: 0.1559 Acc: 0.9379 | Val Loss: 0.2196 Acc: 0.9155\n",
      "Epoch 047 | Train Loss: 0.1618 Acc: 0.9343 | Val Loss: 0.1744 Acc: 0.9354\n",
      "Epoch 048 | Train Loss: 0.1425 Acc: 0.9464 | Val Loss: 0.1898 Acc: 0.9293\n",
      "Epoch 049 | Train Loss: 0.1583 Acc: 0.9390 | Val Loss: 0.1762 Acc: 0.9330\n",
      "Epoch 050 | Train Loss: 0.1512 Acc: 0.9419 | Val Loss: 0.1666 Acc: 0.9402\n",
      "Epoch 051 | Train Loss: 0.1461 Acc: 0.9479 | Val Loss: 0.1879 Acc: 0.9269\n",
      "Epoch 052 | Train Loss: 0.1481 Acc: 0.9453 | Val Loss: 0.1696 Acc: 0.9330\n",
      "Epoch 053 | Train Loss: 0.1477 Acc: 0.9441 | Val Loss: 0.1679 Acc: 0.9354\n",
      "Epoch 054 | Train Loss: 0.1502 Acc: 0.9437 | Val Loss: 0.1910 Acc: 0.9312\n",
      "Epoch 055 | Train Loss: 0.1406 Acc: 0.9476 | Val Loss: 0.1648 Acc: 0.9396\n",
      "Epoch 056 | Train Loss: 0.1297 Acc: 0.9515 | Val Loss: 0.1795 Acc: 0.9239\n",
      "Epoch 057 | Train Loss: 0.1487 Acc: 0.9440 | Val Loss: 0.1575 Acc: 0.9372\n",
      "Epoch 058 | Train Loss: 0.1381 Acc: 0.9481 | Val Loss: 0.2148 Acc: 0.9275\n",
      "Epoch 059 | Train Loss: 0.1335 Acc: 0.9491 | Val Loss: 0.1938 Acc: 0.9233\n",
      "Epoch 060 | Train Loss: 0.1338 Acc: 0.9467 | Val Loss: 0.1717 Acc: 0.9336\n",
      "Epoch 001 | Train Loss: 0.6783 Acc: 0.5790 | Val Loss: 0.6646 Acc: 0.5827\n",
      "Epoch 002 | Train Loss: 0.6049 Acc: 0.6834 | Val Loss: 0.5834 Acc: 0.6950\n",
      "Epoch 003 | Train Loss: 0.5739 Acc: 0.7086 | Val Loss: 0.5773 Acc: 0.7011\n",
      "Epoch 004 | Train Loss: 0.5434 Acc: 0.7250 | Val Loss: 0.5505 Acc: 0.7204\n",
      "Epoch 005 | Train Loss: 0.5109 Acc: 0.7494 | Val Loss: 0.4930 Acc: 0.7645\n",
      "Epoch 006 | Train Loss: 0.4658 Acc: 0.7820 | Val Loss: 0.4599 Acc: 0.7856\n",
      "Epoch 007 | Train Loss: 0.4145 Acc: 0.8123 | Val Loss: 0.4488 Acc: 0.7947\n",
      "Epoch 008 | Train Loss: 0.3770 Acc: 0.8338 | Val Loss: 0.3979 Acc: 0.8225\n",
      "Epoch 009 | Train Loss: 0.3453 Acc: 0.8522 | Val Loss: 0.3823 Acc: 0.8357\n",
      "Epoch 010 | Train Loss: 0.3263 Acc: 0.8635 | Val Loss: 0.3561 Acc: 0.8333\n",
      "Epoch 011 | Train Loss: 0.2931 Acc: 0.8774 | Val Loss: 0.3010 Acc: 0.8810\n",
      "Epoch 012 | Train Loss: 0.2689 Acc: 0.8919 | Val Loss: 0.2880 Acc: 0.8913\n",
      "Epoch 013 | Train Loss: 0.2415 Acc: 0.9003 | Val Loss: 0.2767 Acc: 0.8780\n",
      "Epoch 014 | Train Loss: 0.2327 Acc: 0.9053 | Val Loss: 0.2632 Acc: 0.8931\n",
      "Epoch 015 | Train Loss: 0.2181 Acc: 0.9117 | Val Loss: 0.2602 Acc: 0.8901\n",
      "Epoch 016 | Train Loss: 0.1886 Acc: 0.9262 | Val Loss: 0.2325 Acc: 0.9070\n",
      "Epoch 017 | Train Loss: 0.1969 Acc: 0.9210 | Val Loss: 0.2565 Acc: 0.8986\n",
      "Epoch 018 | Train Loss: 0.1781 Acc: 0.9299 | Val Loss: 0.2625 Acc: 0.9058\n",
      "Epoch 019 | Train Loss: 0.1736 Acc: 0.9311 | Val Loss: 0.2282 Acc: 0.9094\n",
      "Epoch 020 | Train Loss: 0.1548 Acc: 0.9417 | Val Loss: 0.2372 Acc: 0.9100\n",
      "Epoch 021 | Train Loss: 0.1591 Acc: 0.9378 | Val Loss: 0.2557 Acc: 0.9004\n",
      "Epoch 022 | Train Loss: 0.1387 Acc: 0.9455 | Val Loss: 0.2232 Acc: 0.9100\n",
      "Epoch 023 | Train Loss: 0.1491 Acc: 0.9435 | Val Loss: 0.2408 Acc: 0.9106\n",
      "Epoch 024 | Train Loss: 0.1306 Acc: 0.9494 | Val Loss: 0.2947 Acc: 0.9004\n",
      "Epoch 025 | Train Loss: 0.1329 Acc: 0.9444 | Val Loss: 0.2617 Acc: 0.9046\n",
      "Epoch 026 | Train Loss: 0.1271 Acc: 0.9527 | Val Loss: 0.2103 Acc: 0.9293\n",
      "Epoch 027 | Train Loss: 0.1189 Acc: 0.9527 | Val Loss: 0.2466 Acc: 0.9167\n",
      "Epoch 028 | Train Loss: 0.1205 Acc: 0.9533 | Val Loss: 0.2200 Acc: 0.9233\n",
      "Epoch 029 | Train Loss: 0.1097 Acc: 0.9561 | Val Loss: 0.2170 Acc: 0.9269\n",
      "Epoch 030 | Train Loss: 0.1136 Acc: 0.9571 | Val Loss: 0.2351 Acc: 0.9191\n",
      "Epoch 031 | Train Loss: 0.1153 Acc: 0.9585 | Val Loss: 0.2010 Acc: 0.9312\n",
      "Epoch 032 | Train Loss: 0.1004 Acc: 0.9609 | Val Loss: 0.2364 Acc: 0.9191\n",
      "Epoch 033 | Train Loss: 0.0959 Acc: 0.9650 | Val Loss: 0.1989 Acc: 0.9293\n",
      "Epoch 034 | Train Loss: 0.0966 Acc: 0.9644 | Val Loss: 0.2008 Acc: 0.9336\n",
      "Epoch 035 | Train Loss: 0.0884 Acc: 0.9647 | Val Loss: 0.2133 Acc: 0.9257\n",
      "Epoch 036 | Train Loss: 0.1151 Acc: 0.9544 | Val Loss: 0.1958 Acc: 0.9257\n",
      "Epoch 037 | Train Loss: 0.0874 Acc: 0.9697 | Val Loss: 0.2261 Acc: 0.9245\n",
      "Epoch 038 | Train Loss: 0.0856 Acc: 0.9683 | Val Loss: 0.2273 Acc: 0.9215\n",
      "Epoch 039 | Train Loss: 0.0893 Acc: 0.9636 | Val Loss: 0.2263 Acc: 0.9233\n",
      "Epoch 040 | Train Loss: 0.0799 Acc: 0.9689 | Val Loss: 0.2424 Acc: 0.9263\n",
      "Epoch 041 | Train Loss: 0.0841 Acc: 0.9678 | Val Loss: 0.2117 Acc: 0.9287\n",
      "Epoch 042 | Train Loss: 0.0736 Acc: 0.9739 | Val Loss: 0.2508 Acc: 0.9197\n",
      "Epoch 043 | Train Loss: 0.0713 Acc: 0.9712 | Val Loss: 0.1906 Acc: 0.9300\n",
      "Epoch 044 | Train Loss: 0.0726 Acc: 0.9718 | Val Loss: 0.2096 Acc: 0.9257\n",
      "Epoch 045 | Train Loss: 0.0791 Acc: 0.9713 | Val Loss: 0.1920 Acc: 0.9372\n",
      "Epoch 046 | Train Loss: 0.0744 Acc: 0.9727 | Val Loss: 0.2405 Acc: 0.9215\n",
      "Epoch 047 | Train Loss: 0.0764 Acc: 0.9715 | Val Loss: 0.2489 Acc: 0.9263\n",
      "Epoch 048 | Train Loss: 0.0771 Acc: 0.9733 | Val Loss: 0.1786 Acc: 0.9348\n",
      "Epoch 049 | Train Loss: 0.0750 Acc: 0.9727 | Val Loss: 0.2437 Acc: 0.9233\n",
      "Epoch 050 | Train Loss: 0.0752 Acc: 0.9709 | Val Loss: 0.1980 Acc: 0.9366\n",
      "Epoch 051 | Train Loss: 0.0742 Acc: 0.9731 | Val Loss: 0.1925 Acc: 0.9354\n",
      "Epoch 052 | Train Loss: 0.0616 Acc: 0.9774 | Val Loss: 0.2246 Acc: 0.9275\n",
      "Epoch 053 | Train Loss: 0.0543 Acc: 0.9814 | Val Loss: 0.1931 Acc: 0.9336\n",
      "Epoch 054 | Train Loss: 0.0661 Acc: 0.9757 | Val Loss: 0.2678 Acc: 0.9324\n",
      "Epoch 055 | Train Loss: 0.0688 Acc: 0.9745 | Val Loss: 0.1932 Acc: 0.9378\n",
      "Epoch 056 | Train Loss: 0.0733 Acc: 0.9725 | Val Loss: 0.2622 Acc: 0.9281\n",
      "Epoch 057 | Train Loss: 0.0543 Acc: 0.9807 | Val Loss: 0.1971 Acc: 0.9402\n",
      "Epoch 058 | Train Loss: 0.0611 Acc: 0.9770 | Val Loss: 0.1753 Acc: 0.9450\n",
      "Epoch 059 | Train Loss: 0.0585 Acc: 0.9781 | Val Loss: 0.2258 Acc: 0.9366\n",
      "Epoch 060 | Train Loss: 0.0675 Acc: 0.9751 | Val Loss: 0.2727 Acc: 0.9330\n",
      "Epoch 001 | Train Loss: 0.6838 Acc: 0.5710 | Val Loss: 0.6788 Acc: 0.5797\n",
      "Epoch 002 | Train Loss: 0.6762 Acc: 0.5895 | Val Loss: 0.6753 Acc: 0.5906\n",
      "Epoch 003 | Train Loss: 0.6728 Acc: 0.5910 | Val Loss: 0.6738 Acc: 0.5912\n",
      "Epoch 004 | Train Loss: 0.6703 Acc: 0.5953 | Val Loss: 0.6687 Acc: 0.5978\n",
      "Epoch 005 | Train Loss: 0.6574 Acc: 0.6106 | Val Loss: 0.6535 Acc: 0.6075\n",
      "Epoch 006 | Train Loss: 0.6413 Acc: 0.6355 | Val Loss: 0.6230 Acc: 0.6763\n",
      "Epoch 007 | Train Loss: 0.6227 Acc: 0.6671 | Val Loss: 0.6108 Acc: 0.6721\n",
      "Epoch 008 | Train Loss: 0.6077 Acc: 0.6819 | Val Loss: 0.6004 Acc: 0.6920\n",
      "Epoch 009 | Train Loss: 0.6017 Acc: 0.6885 | Val Loss: 0.5969 Acc: 0.6878\n",
      "Epoch 010 | Train Loss: 0.5945 Acc: 0.7006 | Val Loss: 0.5885 Acc: 0.7023\n",
      "Epoch 011 | Train Loss: 0.5867 Acc: 0.7038 | Val Loss: 0.5854 Acc: 0.7107\n",
      "Epoch 012 | Train Loss: 0.5790 Acc: 0.7075 | Val Loss: 0.5824 Acc: 0.7071\n",
      "Epoch 013 | Train Loss: 0.5702 Acc: 0.7178 | Val Loss: 0.5753 Acc: 0.7035\n",
      "Epoch 014 | Train Loss: 0.5658 Acc: 0.7186 | Val Loss: 0.5739 Acc: 0.7095\n",
      "Epoch 015 | Train Loss: 0.5614 Acc: 0.7220 | Val Loss: 0.5633 Acc: 0.7228\n",
      "Epoch 016 | Train Loss: 0.5563 Acc: 0.7296 | Val Loss: 0.5778 Acc: 0.7023\n",
      "Epoch 017 | Train Loss: 0.5536 Acc: 0.7272 | Val Loss: 0.5720 Acc: 0.7156\n",
      "Epoch 018 | Train Loss: 0.5470 Acc: 0.7308 | Val Loss: 0.5518 Acc: 0.7186\n",
      "Epoch 019 | Train Loss: 0.5420 Acc: 0.7331 | Val Loss: 0.5506 Acc: 0.7252\n",
      "Epoch 020 | Train Loss: 0.5359 Acc: 0.7426 | Val Loss: 0.5475 Acc: 0.7228\n",
      "Epoch 021 | Train Loss: 0.5260 Acc: 0.7442 | Val Loss: 0.5381 Acc: 0.7258\n",
      "Epoch 022 | Train Loss: 0.5246 Acc: 0.7504 | Val Loss: 0.5328 Acc: 0.7295\n",
      "Epoch 023 | Train Loss: 0.5183 Acc: 0.7456 | Val Loss: 0.5281 Acc: 0.7337\n",
      "Epoch 024 | Train Loss: 0.5166 Acc: 0.7480 | Val Loss: 0.5301 Acc: 0.7331\n",
      "Epoch 025 | Train Loss: 0.5101 Acc: 0.7580 | Val Loss: 0.5259 Acc: 0.7440\n",
      "Epoch 026 | Train Loss: 0.5000 Acc: 0.7661 | Val Loss: 0.5150 Acc: 0.7500\n",
      "Epoch 027 | Train Loss: 0.4949 Acc: 0.7646 | Val Loss: 0.5205 Acc: 0.7403\n",
      "Epoch 028 | Train Loss: 0.4939 Acc: 0.7682 | Val Loss: 0.5066 Acc: 0.7548\n",
      "Epoch 029 | Train Loss: 0.4931 Acc: 0.7669 | Val Loss: 0.5072 Acc: 0.7524\n",
      "Epoch 030 | Train Loss: 0.4822 Acc: 0.7749 | Val Loss: 0.5010 Acc: 0.7591\n",
      "Epoch 031 | Train Loss: 0.4827 Acc: 0.7741 | Val Loss: 0.5050 Acc: 0.7542\n",
      "Epoch 032 | Train Loss: 0.4777 Acc: 0.7731 | Val Loss: 0.5045 Acc: 0.7621\n",
      "Epoch 033 | Train Loss: 0.4714 Acc: 0.7788 | Val Loss: 0.4936 Acc: 0.7597\n",
      "Epoch 034 | Train Loss: 0.4600 Acc: 0.7876 | Val Loss: 0.5134 Acc: 0.7464\n",
      "Epoch 035 | Train Loss: 0.4587 Acc: 0.7860 | Val Loss: 0.4836 Acc: 0.7699\n",
      "Epoch 036 | Train Loss: 0.4572 Acc: 0.7836 | Val Loss: 0.4752 Acc: 0.7693\n",
      "Epoch 037 | Train Loss: 0.4470 Acc: 0.7931 | Val Loss: 0.4767 Acc: 0.7729\n",
      "Epoch 038 | Train Loss: 0.4416 Acc: 0.8021 | Val Loss: 0.4621 Acc: 0.7844\n",
      "Epoch 039 | Train Loss: 0.4412 Acc: 0.7954 | Val Loss: 0.4808 Acc: 0.7814\n",
      "Epoch 040 | Train Loss: 0.4301 Acc: 0.8014 | Val Loss: 0.4676 Acc: 0.7717\n",
      "Epoch 041 | Train Loss: 0.4285 Acc: 0.8022 | Val Loss: 0.4669 Acc: 0.7778\n",
      "Epoch 042 | Train Loss: 0.4204 Acc: 0.8075 | Val Loss: 0.4369 Acc: 0.7995\n",
      "Epoch 043 | Train Loss: 0.4157 Acc: 0.8107 | Val Loss: 0.4392 Acc: 0.7995\n",
      "Epoch 044 | Train Loss: 0.4085 Acc: 0.8137 | Val Loss: 0.4493 Acc: 0.7880\n",
      "Epoch 045 | Train Loss: 0.4030 Acc: 0.8179 | Val Loss: 0.4351 Acc: 0.7953\n",
      "Epoch 046 | Train Loss: 0.3955 Acc: 0.8167 | Val Loss: 0.4279 Acc: 0.7977\n",
      "Epoch 047 | Train Loss: 0.3957 Acc: 0.8167 | Val Loss: 0.4176 Acc: 0.8062\n",
      "Epoch 048 | Train Loss: 0.3916 Acc: 0.8200 | Val Loss: 0.4220 Acc: 0.7983\n",
      "Epoch 049 | Train Loss: 0.3911 Acc: 0.8235 | Val Loss: 0.4246 Acc: 0.7941\n",
      "Epoch 050 | Train Loss: 0.3777 Acc: 0.8291 | Val Loss: 0.4032 Acc: 0.8158\n",
      "Epoch 051 | Train Loss: 0.3804 Acc: 0.8255 | Val Loss: 0.4022 Acc: 0.8116\n",
      "Epoch 052 | Train Loss: 0.3753 Acc: 0.8271 | Val Loss: 0.3900 Acc: 0.8164\n",
      "Epoch 053 | Train Loss: 0.3615 Acc: 0.8342 | Val Loss: 0.4295 Acc: 0.7971\n",
      "Epoch 054 | Train Loss: 0.3556 Acc: 0.8384 | Val Loss: 0.3880 Acc: 0.8182\n",
      "Epoch 055 | Train Loss: 0.3515 Acc: 0.8410 | Val Loss: 0.3939 Acc: 0.8164\n",
      "Epoch 056 | Train Loss: 0.3488 Acc: 0.8421 | Val Loss: 0.3782 Acc: 0.8285\n",
      "Epoch 057 | Train Loss: 0.3508 Acc: 0.8430 | Val Loss: 0.4109 Acc: 0.8074\n",
      "Epoch 058 | Train Loss: 0.3440 Acc: 0.8464 | Val Loss: 0.3665 Acc: 0.8327\n",
      "Epoch 059 | Train Loss: 0.3407 Acc: 0.8422 | Val Loss: 0.3851 Acc: 0.8255\n",
      "Epoch 060 | Train Loss: 0.3338 Acc: 0.8486 | Val Loss: 0.3735 Acc: 0.8255\n",
      "Epoch 001 | Train Loss: 0.6790 Acc: 0.5813 | Val Loss: 0.6676 Acc: 0.5906\n",
      "Epoch 002 | Train Loss: 0.6257 Acc: 0.6589 | Val Loss: 0.5898 Acc: 0.6999\n",
      "Epoch 003 | Train Loss: 0.5678 Acc: 0.7195 | Val Loss: 0.5730 Acc: 0.7107\n",
      "Epoch 004 | Train Loss: 0.5443 Acc: 0.7299 | Val Loss: 0.5521 Acc: 0.7331\n",
      "Epoch 005 | Train Loss: 0.5193 Acc: 0.7513 | Val Loss: 0.5186 Acc: 0.7391\n",
      "Epoch 006 | Train Loss: 0.4883 Acc: 0.7636 | Val Loss: 0.4795 Acc: 0.7603\n",
      "Epoch 007 | Train Loss: 0.4477 Acc: 0.7901 | Val Loss: 0.4408 Acc: 0.7874\n",
      "Epoch 008 | Train Loss: 0.4133 Acc: 0.8140 | Val Loss: 0.4060 Acc: 0.8116\n",
      "Epoch 009 | Train Loss: 0.3739 Acc: 0.8323 | Val Loss: 0.3820 Acc: 0.8158\n",
      "Epoch 010 | Train Loss: 0.3504 Acc: 0.8483 | Val Loss: 0.3571 Acc: 0.8351\n",
      "Epoch 011 | Train Loss: 0.3231 Acc: 0.8624 | Val Loss: 0.3491 Acc: 0.8514\n",
      "Epoch 012 | Train Loss: 0.2945 Acc: 0.8754 | Val Loss: 0.3429 Acc: 0.8569\n",
      "Epoch 013 | Train Loss: 0.2838 Acc: 0.8831 | Val Loss: 0.3144 Acc: 0.8708\n",
      "Epoch 014 | Train Loss: 0.2575 Acc: 0.8937 | Val Loss: 0.2843 Acc: 0.8816\n",
      "Epoch 015 | Train Loss: 0.2339 Acc: 0.9070 | Val Loss: 0.2896 Acc: 0.8714\n",
      "Epoch 016 | Train Loss: 0.2190 Acc: 0.9142 | Val Loss: 0.2941 Acc: 0.8780\n",
      "Epoch 017 | Train Loss: 0.2192 Acc: 0.9129 | Val Loss: 0.2476 Acc: 0.8925\n",
      "Epoch 018 | Train Loss: 0.2084 Acc: 0.9188 | Val Loss: 0.2353 Acc: 0.8979\n",
      "Epoch 019 | Train Loss: 0.1966 Acc: 0.9221 | Val Loss: 0.2577 Acc: 0.9028\n",
      "Epoch 020 | Train Loss: 0.1832 Acc: 0.9292 | Val Loss: 0.2170 Acc: 0.9179\n",
      "Epoch 021 | Train Loss: 0.1871 Acc: 0.9259 | Val Loss: 0.2063 Acc: 0.9191\n",
      "Epoch 022 | Train Loss: 0.1617 Acc: 0.9395 | Val Loss: 0.3081 Acc: 0.8967\n",
      "Epoch 023 | Train Loss: 0.1527 Acc: 0.9402 | Val Loss: 0.2102 Acc: 0.9124\n",
      "Epoch 024 | Train Loss: 0.1635 Acc: 0.9388 | Val Loss: 0.2137 Acc: 0.9173\n",
      "Epoch 025 | Train Loss: 0.1372 Acc: 0.9470 | Val Loss: 0.1974 Acc: 0.9209\n",
      "Epoch 026 | Train Loss: 0.1389 Acc: 0.9443 | Val Loss: 0.2245 Acc: 0.9118\n",
      "Epoch 027 | Train Loss: 0.1404 Acc: 0.9456 | Val Loss: 0.1959 Acc: 0.9251\n",
      "Epoch 028 | Train Loss: 0.1303 Acc: 0.9508 | Val Loss: 0.1889 Acc: 0.9306\n",
      "Epoch 029 | Train Loss: 0.1176 Acc: 0.9583 | Val Loss: 0.1925 Acc: 0.9318\n",
      "Epoch 030 | Train Loss: 0.1343 Acc: 0.9500 | Val Loss: 0.2102 Acc: 0.9233\n",
      "Epoch 031 | Train Loss: 0.1224 Acc: 0.9549 | Val Loss: 0.2130 Acc: 0.9215\n",
      "Epoch 032 | Train Loss: 0.1196 Acc: 0.9536 | Val Loss: 0.2375 Acc: 0.9130\n",
      "Epoch 033 | Train Loss: 0.1220 Acc: 0.9538 | Val Loss: 0.2213 Acc: 0.9167\n",
      "Epoch 034 | Train Loss: 0.1148 Acc: 0.9539 | Val Loss: 0.2033 Acc: 0.9257\n",
      "Epoch 035 | Train Loss: 0.1047 Acc: 0.9588 | Val Loss: 0.1935 Acc: 0.9287\n",
      "Epoch 036 | Train Loss: 0.1107 Acc: 0.9555 | Val Loss: 0.2182 Acc: 0.9197\n",
      "Epoch 037 | Train Loss: 0.1021 Acc: 0.9606 | Val Loss: 0.2037 Acc: 0.9306\n",
      "Epoch 038 | Train Loss: 0.1007 Acc: 0.9620 | Val Loss: 0.1824 Acc: 0.9372\n",
      "Epoch 039 | Train Loss: 0.0954 Acc: 0.9612 | Val Loss: 0.2007 Acc: 0.9275\n",
      "Epoch 040 | Train Loss: 0.1024 Acc: 0.9624 | Val Loss: 0.2021 Acc: 0.9275\n",
      "Epoch 041 | Train Loss: 0.0934 Acc: 0.9639 | Val Loss: 0.2442 Acc: 0.9179\n",
      "Epoch 042 | Train Loss: 0.0936 Acc: 0.9662 | Val Loss: 0.1853 Acc: 0.9306\n",
      "Epoch 043 | Train Loss: 0.0908 Acc: 0.9651 | Val Loss: 0.1924 Acc: 0.9245\n",
      "Epoch 044 | Train Loss: 0.0976 Acc: 0.9630 | Val Loss: 0.2089 Acc: 0.9221\n",
      "Epoch 045 | Train Loss: 0.0903 Acc: 0.9657 | Val Loss: 0.1720 Acc: 0.9402\n",
      "Epoch 046 | Train Loss: 0.0871 Acc: 0.9662 | Val Loss: 0.2201 Acc: 0.9245\n",
      "Epoch 047 | Train Loss: 0.0891 Acc: 0.9697 | Val Loss: 0.2179 Acc: 0.9281\n",
      "Epoch 048 | Train Loss: 0.0932 Acc: 0.9656 | Val Loss: 0.1799 Acc: 0.9396\n",
      "Epoch 049 | Train Loss: 0.0873 Acc: 0.9690 | Val Loss: 0.1925 Acc: 0.9281\n",
      "Epoch 050 | Train Loss: 0.0862 Acc: 0.9678 | Val Loss: 0.1967 Acc: 0.9215\n",
      "Epoch 051 | Train Loss: 0.0908 Acc: 0.9666 | Val Loss: 0.1794 Acc: 0.9293\n",
      "Epoch 052 | Train Loss: 0.0902 Acc: 0.9663 | Val Loss: 0.2345 Acc: 0.9173\n",
      "Epoch 053 | Train Loss: 0.0882 Acc: 0.9668 | Val Loss: 0.1587 Acc: 0.9408\n",
      "Epoch 054 | Train Loss: 0.0757 Acc: 0.9709 | Val Loss: 0.2211 Acc: 0.9227\n",
      "Epoch 055 | Train Loss: 0.0745 Acc: 0.9742 | Val Loss: 0.1856 Acc: 0.9420\n",
      "Epoch 056 | Train Loss: 0.0796 Acc: 0.9684 | Val Loss: 0.2416 Acc: 0.9239\n",
      "Epoch 057 | Train Loss: 0.0792 Acc: 0.9704 | Val Loss: 0.2134 Acc: 0.9239\n",
      "Epoch 058 | Train Loss: 0.0686 Acc: 0.9748 | Val Loss: 0.1770 Acc: 0.9360\n",
      "Epoch 059 | Train Loss: 0.0672 Acc: 0.9755 | Val Loss: 0.1613 Acc: 0.9469\n",
      "Epoch 060 | Train Loss: 0.0593 Acc: 0.9772 | Val Loss: 0.2279 Acc: 0.9396\n",
      "Epoch 001 | Train Loss: 0.6795 Acc: 0.5834 | Val Loss: 0.6739 Acc: 0.5942\n",
      "Epoch 002 | Train Loss: 0.6693 Acc: 0.5966 | Val Loss: 0.6599 Acc: 0.6226\n",
      "Epoch 003 | Train Loss: 0.6220 Acc: 0.6610 | Val Loss: 0.6026 Acc: 0.6812\n",
      "Epoch 004 | Train Loss: 0.5767 Acc: 0.7100 | Val Loss: 0.5783 Acc: 0.6969\n",
      "Epoch 005 | Train Loss: 0.5526 Acc: 0.7232 | Val Loss: 0.5409 Acc: 0.7325\n",
      "Epoch 006 | Train Loss: 0.5318 Acc: 0.7379 | Val Loss: 0.5368 Acc: 0.7325\n",
      "Epoch 007 | Train Loss: 0.5111 Acc: 0.7495 | Val Loss: 0.5432 Acc: 0.7222\n",
      "Epoch 008 | Train Loss: 0.4988 Acc: 0.7586 | Val Loss: 0.5158 Acc: 0.7542\n",
      "Epoch 009 | Train Loss: 0.4733 Acc: 0.7747 | Val Loss: 0.4643 Acc: 0.7778\n",
      "Epoch 010 | Train Loss: 0.4486 Acc: 0.7921 | Val Loss: 0.4385 Acc: 0.7941\n",
      "Epoch 011 | Train Loss: 0.4489 Acc: 0.7924 | Val Loss: 0.4244 Acc: 0.8037\n",
      "Epoch 012 | Train Loss: 0.4097 Acc: 0.8099 | Val Loss: 0.4533 Acc: 0.7832\n",
      "Epoch 013 | Train Loss: 0.3957 Acc: 0.8223 | Val Loss: 0.3703 Acc: 0.8279\n",
      "Epoch 014 | Train Loss: 0.3751 Acc: 0.8274 | Val Loss: 0.4032 Acc: 0.8019\n",
      "Epoch 015 | Train Loss: 0.3547 Acc: 0.8452 | Val Loss: 0.3488 Acc: 0.8472\n",
      "Epoch 016 | Train Loss: 0.3344 Acc: 0.8546 | Val Loss: 0.3363 Acc: 0.8370\n",
      "Epoch 017 | Train Loss: 0.3278 Acc: 0.8591 | Val Loss: 0.3068 Acc: 0.8575\n",
      "Epoch 018 | Train Loss: 0.3103 Acc: 0.8673 | Val Loss: 0.3144 Acc: 0.8575\n",
      "Epoch 019 | Train Loss: 0.2946 Acc: 0.8768 | Val Loss: 0.2843 Acc: 0.8732\n",
      "Epoch 020 | Train Loss: 0.2771 Acc: 0.8854 | Val Loss: 0.2519 Acc: 0.8925\n",
      "Epoch 021 | Train Loss: 0.2625 Acc: 0.8954 | Val Loss: 0.2646 Acc: 0.8907\n",
      "Epoch 022 | Train Loss: 0.2495 Acc: 0.8982 | Val Loss: 0.2340 Acc: 0.9028\n",
      "Epoch 023 | Train Loss: 0.2417 Acc: 0.9029 | Val Loss: 0.2281 Acc: 0.9046\n",
      "Epoch 024 | Train Loss: 0.2356 Acc: 0.9071 | Val Loss: 0.2286 Acc: 0.8986\n",
      "Epoch 025 | Train Loss: 0.2220 Acc: 0.9085 | Val Loss: 0.2204 Acc: 0.9088\n",
      "Epoch 026 | Train Loss: 0.2091 Acc: 0.9156 | Val Loss: 0.2078 Acc: 0.9124\n",
      "Epoch 027 | Train Loss: 0.2078 Acc: 0.9206 | Val Loss: 0.2192 Acc: 0.9088\n",
      "Epoch 028 | Train Loss: 0.1922 Acc: 0.9238 | Val Loss: 0.1877 Acc: 0.9251\n",
      "Epoch 029 | Train Loss: 0.2018 Acc: 0.9209 | Val Loss: 0.2226 Acc: 0.9155\n",
      "Epoch 030 | Train Loss: 0.1863 Acc: 0.9262 | Val Loss: 0.2025 Acc: 0.9149\n",
      "Epoch 031 | Train Loss: 0.1840 Acc: 0.9319 | Val Loss: 0.1814 Acc: 0.9300\n",
      "Epoch 032 | Train Loss: 0.1676 Acc: 0.9352 | Val Loss: 0.2066 Acc: 0.9118\n",
      "Epoch 033 | Train Loss: 0.1582 Acc: 0.9392 | Val Loss: 0.1890 Acc: 0.9239\n",
      "Epoch 034 | Train Loss: 0.1628 Acc: 0.9357 | Val Loss: 0.1889 Acc: 0.9269\n",
      "Epoch 035 | Train Loss: 0.1591 Acc: 0.9364 | Val Loss: 0.1927 Acc: 0.9227\n",
      "Epoch 036 | Train Loss: 0.1446 Acc: 0.9438 | Val Loss: 0.1793 Acc: 0.9312\n",
      "Epoch 037 | Train Loss: 0.1337 Acc: 0.9485 | Val Loss: 0.1929 Acc: 0.9233\n",
      "Epoch 038 | Train Loss: 0.1437 Acc: 0.9482 | Val Loss: 0.1622 Acc: 0.9366\n",
      "Epoch 039 | Train Loss: 0.1375 Acc: 0.9443 | Val Loss: 0.1699 Acc: 0.9281\n",
      "Epoch 040 | Train Loss: 0.1258 Acc: 0.9526 | Val Loss: 0.1713 Acc: 0.9336\n",
      "Epoch 041 | Train Loss: 0.1254 Acc: 0.9508 | Val Loss: 0.1399 Acc: 0.9420\n",
      "Epoch 042 | Train Loss: 0.1208 Acc: 0.9553 | Val Loss: 0.1388 Acc: 0.9414\n",
      "Epoch 043 | Train Loss: 0.1203 Acc: 0.9549 | Val Loss: 0.1603 Acc: 0.9396\n",
      "Epoch 044 | Train Loss: 0.1154 Acc: 0.9526 | Val Loss: 0.1564 Acc: 0.9414\n",
      "Epoch 045 | Train Loss: 0.1177 Acc: 0.9571 | Val Loss: 0.1522 Acc: 0.9408\n",
      "Epoch 046 | Train Loss: 0.1086 Acc: 0.9623 | Val Loss: 0.1690 Acc: 0.9372\n",
      "Epoch 047 | Train Loss: 0.1082 Acc: 0.9609 | Val Loss: 0.1620 Acc: 0.9378\n",
      "Epoch 048 | Train Loss: 0.1198 Acc: 0.9555 | Val Loss: 0.1420 Acc: 0.9475\n",
      "Epoch 049 | Train Loss: 0.1033 Acc: 0.9607 | Val Loss: 0.1499 Acc: 0.9414\n",
      "Epoch 050 | Train Loss: 0.1130 Acc: 0.9543 | Val Loss: 0.1464 Acc: 0.9529\n",
      "Epoch 051 | Train Loss: 0.0989 Acc: 0.9610 | Val Loss: 0.1360 Acc: 0.9481\n",
      "Epoch 052 | Train Loss: 0.1023 Acc: 0.9623 | Val Loss: 0.1425 Acc: 0.9372\n",
      "Epoch 053 | Train Loss: 0.0977 Acc: 0.9635 | Val Loss: 0.1401 Acc: 0.9444\n",
      "Epoch 054 | Train Loss: 0.0925 Acc: 0.9648 | Val Loss: 0.1441 Acc: 0.9481\n",
      "Epoch 055 | Train Loss: 0.0925 Acc: 0.9657 | Val Loss: 0.1290 Acc: 0.9493\n",
      "Epoch 056 | Train Loss: 0.0958 Acc: 0.9638 | Val Loss: 0.1352 Acc: 0.9457\n",
      "Epoch 057 | Train Loss: 0.0949 Acc: 0.9651 | Val Loss: 0.1259 Acc: 0.9535\n",
      "Epoch 058 | Train Loss: 0.0910 Acc: 0.9678 | Val Loss: 0.1273 Acc: 0.9553\n",
      "Epoch 059 | Train Loss: 0.0811 Acc: 0.9698 | Val Loss: 0.1634 Acc: 0.9457\n",
      "Epoch 060 | Train Loss: 0.0886 Acc: 0.9660 | Val Loss: 0.1666 Acc: 0.9372\n",
      "Epoch 001 | Train Loss: 0.6832 Acc: 0.5718 | Val Loss: 0.6758 Acc: 0.5930\n",
      "Epoch 002 | Train Loss: 0.6717 Acc: 0.5955 | Val Loss: 0.6811 Acc: 0.5779\n",
      "Epoch 003 | Train Loss: 0.6673 Acc: 0.6082 | Val Loss: 0.6650 Acc: 0.6075\n",
      "Epoch 004 | Train Loss: 0.6637 Acc: 0.6079 | Val Loss: 0.6898 Acc: 0.5676\n",
      "Epoch 005 | Train Loss: 0.6642 Acc: 0.6095 | Val Loss: 0.6543 Acc: 0.6202\n",
      "Epoch 006 | Train Loss: 0.6336 Acc: 0.6557 | Val Loss: 0.6247 Acc: 0.6600\n",
      "Epoch 007 | Train Loss: 0.6016 Acc: 0.6868 | Val Loss: 0.5897 Acc: 0.6872\n",
      "Epoch 008 | Train Loss: 0.5771 Acc: 0.7093 | Val Loss: 0.5676 Acc: 0.7150\n",
      "Epoch 009 | Train Loss: 0.5614 Acc: 0.7154 | Val Loss: 0.5679 Acc: 0.7017\n",
      "Epoch 010 | Train Loss: 0.5534 Acc: 0.7299 | Val Loss: 0.5462 Acc: 0.7283\n",
      "Epoch 011 | Train Loss: 0.5395 Acc: 0.7373 | Val Loss: 0.5928 Acc: 0.6920\n",
      "Epoch 012 | Train Loss: 0.5355 Acc: 0.7373 | Val Loss: 0.5372 Acc: 0.7234\n",
      "Epoch 013 | Train Loss: 0.5172 Acc: 0.7518 | Val Loss: 0.5117 Acc: 0.7403\n",
      "Epoch 014 | Train Loss: 0.5145 Acc: 0.7516 | Val Loss: 0.5228 Acc: 0.7536\n",
      "Epoch 015 | Train Loss: 0.4968 Acc: 0.7645 | Val Loss: 0.5475 Acc: 0.7246\n",
      "Epoch 016 | Train Loss: 0.4913 Acc: 0.7623 | Val Loss: 0.4995 Acc: 0.7579\n",
      "Epoch 017 | Train Loss: 0.4846 Acc: 0.7687 | Val Loss: 0.4744 Acc: 0.7711\n",
      "Epoch 018 | Train Loss: 0.4621 Acc: 0.7847 | Val Loss: 0.4923 Acc: 0.7554\n",
      "Epoch 019 | Train Loss: 0.4613 Acc: 0.7767 | Val Loss: 0.4425 Acc: 0.7941\n",
      "Epoch 020 | Train Loss: 0.4411 Acc: 0.7921 | Val Loss: 0.4655 Acc: 0.7717\n",
      "Epoch 021 | Train Loss: 0.4326 Acc: 0.8066 | Val Loss: 0.4273 Acc: 0.8043\n",
      "Epoch 022 | Train Loss: 0.4208 Acc: 0.8073 | Val Loss: 0.4357 Acc: 0.7959\n",
      "Epoch 023 | Train Loss: 0.4138 Acc: 0.8114 | Val Loss: 0.4397 Acc: 0.8031\n",
      "Epoch 024 | Train Loss: 0.4018 Acc: 0.8205 | Val Loss: 0.4194 Acc: 0.8080\n",
      "Epoch 025 | Train Loss: 0.3827 Acc: 0.8351 | Val Loss: 0.4273 Acc: 0.8158\n",
      "Epoch 026 | Train Loss: 0.3818 Acc: 0.8300 | Val Loss: 0.3762 Acc: 0.8376\n",
      "Epoch 027 | Train Loss: 0.3784 Acc: 0.8362 | Val Loss: 0.3729 Acc: 0.8164\n",
      "Epoch 028 | Train Loss: 0.3552 Acc: 0.8434 | Val Loss: 0.3993 Acc: 0.8098\n",
      "Epoch 029 | Train Loss: 0.3404 Acc: 0.8529 | Val Loss: 0.3841 Acc: 0.8357\n",
      "Epoch 030 | Train Loss: 0.3351 Acc: 0.8566 | Val Loss: 0.3318 Acc: 0.8575\n",
      "Epoch 031 | Train Loss: 0.3314 Acc: 0.8546 | Val Loss: 0.3461 Acc: 0.8400\n",
      "Epoch 032 | Train Loss: 0.3169 Acc: 0.8656 | Val Loss: 0.3245 Acc: 0.8514\n",
      "Epoch 033 | Train Loss: 0.3137 Acc: 0.8658 | Val Loss: 0.3111 Acc: 0.8533\n",
      "Epoch 034 | Train Loss: 0.3045 Acc: 0.8723 | Val Loss: 0.3426 Acc: 0.8720\n",
      "Epoch 035 | Train Loss: 0.2943 Acc: 0.8736 | Val Loss: 0.3173 Acc: 0.8623\n",
      "Epoch 036 | Train Loss: 0.3037 Acc: 0.8695 | Val Loss: 0.3199 Acc: 0.8623\n",
      "Epoch 037 | Train Loss: 0.2805 Acc: 0.8801 | Val Loss: 0.2821 Acc: 0.8744\n",
      "Epoch 038 | Train Loss: 0.2726 Acc: 0.8877 | Val Loss: 0.3047 Acc: 0.8841\n",
      "Epoch 039 | Train Loss: 0.2770 Acc: 0.8859 | Val Loss: 0.2737 Acc: 0.8786\n",
      "Epoch 040 | Train Loss: 0.2645 Acc: 0.8886 | Val Loss: 0.5247 Acc: 0.7935\n",
      "Epoch 041 | Train Loss: 0.2665 Acc: 0.8884 | Val Loss: 0.2751 Acc: 0.8810\n",
      "Epoch 042 | Train Loss: 0.2628 Acc: 0.8951 | Val Loss: 0.2591 Acc: 0.8986\n",
      "Epoch 043 | Train Loss: 0.2511 Acc: 0.8961 | Val Loss: 0.2950 Acc: 0.8877\n",
      "Epoch 044 | Train Loss: 0.2545 Acc: 0.8942 | Val Loss: 0.2680 Acc: 0.8931\n",
      "Epoch 045 | Train Loss: 0.2385 Acc: 0.9061 | Val Loss: 0.2727 Acc: 0.8798\n",
      "Epoch 046 | Train Loss: 0.2351 Acc: 0.9061 | Val Loss: 0.2443 Acc: 0.8955\n",
      "Epoch 047 | Train Loss: 0.2306 Acc: 0.9068 | Val Loss: 0.2710 Acc: 0.8883\n",
      "Epoch 048 | Train Loss: 0.2353 Acc: 0.9062 | Val Loss: 0.2592 Acc: 0.8913\n",
      "Epoch 049 | Train Loss: 0.2196 Acc: 0.9138 | Val Loss: 0.2255 Acc: 0.9088\n",
      "Epoch 050 | Train Loss: 0.2185 Acc: 0.9148 | Val Loss: 0.2500 Acc: 0.9004\n",
      "Epoch 051 | Train Loss: 0.2111 Acc: 0.9144 | Val Loss: 0.2659 Acc: 0.8967\n",
      "Epoch 052 | Train Loss: 0.2089 Acc: 0.9179 | Val Loss: 0.2088 Acc: 0.9197\n",
      "Epoch 053 | Train Loss: 0.2029 Acc: 0.9218 | Val Loss: 0.2525 Acc: 0.9004\n",
      "Epoch 054 | Train Loss: 0.1997 Acc: 0.9225 | Val Loss: 0.1950 Acc: 0.9233\n",
      "Epoch 055 | Train Loss: 0.1842 Acc: 0.9271 | Val Loss: 0.2360 Acc: 0.9088\n",
      "Epoch 056 | Train Loss: 0.1856 Acc: 0.9257 | Val Loss: 0.2259 Acc: 0.9167\n",
      "Epoch 057 | Train Loss: 0.1786 Acc: 0.9286 | Val Loss: 0.2089 Acc: 0.9233\n",
      "Epoch 058 | Train Loss: 0.1765 Acc: 0.9333 | Val Loss: 0.2280 Acc: 0.9149\n",
      "Epoch 059 | Train Loss: 0.1745 Acc: 0.9302 | Val Loss: 0.2371 Acc: 0.9136\n",
      "Epoch 060 | Train Loss: 0.1702 Acc: 0.9316 | Val Loss: 0.2399 Acc: 0.9076\n",
      "Epoch 001 | Train Loss: 0.6825 Acc: 0.5760 | Val Loss: 0.6836 Acc: 0.5664\n",
      "Epoch 002 | Train Loss: 0.6643 Acc: 0.6120 | Val Loss: 0.6612 Acc: 0.6196\n",
      "Epoch 003 | Train Loss: 0.6061 Acc: 0.6856 | Val Loss: 0.5894 Acc: 0.7029\n",
      "Epoch 004 | Train Loss: 0.5671 Acc: 0.7223 | Val Loss: 0.5696 Acc: 0.7071\n",
      "Epoch 005 | Train Loss: 0.5368 Acc: 0.7418 | Val Loss: 0.5394 Acc: 0.7349\n",
      "Epoch 006 | Train Loss: 0.5127 Acc: 0.7557 | Val Loss: 0.5103 Acc: 0.7542\n",
      "Epoch 007 | Train Loss: 0.4896 Acc: 0.7672 | Val Loss: 0.4840 Acc: 0.7663\n",
      "Epoch 008 | Train Loss: 0.4779 Acc: 0.7767 | Val Loss: 0.4865 Acc: 0.7651\n",
      "Epoch 009 | Train Loss: 0.4446 Acc: 0.7956 | Val Loss: 0.4463 Acc: 0.7905\n",
      "Epoch 010 | Train Loss: 0.4323 Acc: 0.7965 | Val Loss: 0.4406 Acc: 0.7899\n",
      "Epoch 011 | Train Loss: 0.4177 Acc: 0.8129 | Val Loss: 0.4073 Acc: 0.8080\n",
      "Epoch 012 | Train Loss: 0.3839 Acc: 0.8316 | Val Loss: 0.4320 Acc: 0.7971\n",
      "Epoch 013 | Train Loss: 0.3617 Acc: 0.8427 | Val Loss: 0.3319 Acc: 0.8418\n",
      "Epoch 014 | Train Loss: 0.3397 Acc: 0.8579 | Val Loss: 0.3488 Acc: 0.8484\n",
      "Epoch 015 | Train Loss: 0.3222 Acc: 0.8640 | Val Loss: 0.2940 Acc: 0.8690\n",
      "Epoch 016 | Train Loss: 0.2981 Acc: 0.8757 | Val Loss: 0.3236 Acc: 0.8599\n",
      "Epoch 017 | Train Loss: 0.2885 Acc: 0.8797 | Val Loss: 0.2781 Acc: 0.8835\n",
      "Epoch 018 | Train Loss: 0.2657 Acc: 0.8884 | Val Loss: 0.2576 Acc: 0.8955\n",
      "Epoch 019 | Train Loss: 0.2607 Acc: 0.8928 | Val Loss: 0.2473 Acc: 0.8919\n",
      "Epoch 020 | Train Loss: 0.2456 Acc: 0.9003 | Val Loss: 0.2905 Acc: 0.8786\n",
      "Epoch 021 | Train Loss: 0.2352 Acc: 0.9047 | Val Loss: 0.2414 Acc: 0.8967\n",
      "Epoch 022 | Train Loss: 0.2146 Acc: 0.9157 | Val Loss: 0.2362 Acc: 0.9004\n",
      "Epoch 023 | Train Loss: 0.2185 Acc: 0.9103 | Val Loss: 0.2183 Acc: 0.9118\n",
      "Epoch 024 | Train Loss: 0.2001 Acc: 0.9212 | Val Loss: 0.2259 Acc: 0.9094\n",
      "Epoch 025 | Train Loss: 0.1957 Acc: 0.9230 | Val Loss: 0.2031 Acc: 0.9191\n",
      "Epoch 026 | Train Loss: 0.1834 Acc: 0.9296 | Val Loss: 0.2067 Acc: 0.9161\n",
      "Epoch 027 | Train Loss: 0.1809 Acc: 0.9310 | Val Loss: 0.2271 Acc: 0.9076\n",
      "Epoch 028 | Train Loss: 0.1797 Acc: 0.9324 | Val Loss: 0.1872 Acc: 0.9227\n",
      "Epoch 029 | Train Loss: 0.1681 Acc: 0.9349 | Val Loss: 0.1969 Acc: 0.9179\n",
      "Epoch 030 | Train Loss: 0.1520 Acc: 0.9398 | Val Loss: 0.2097 Acc: 0.9161\n",
      "Epoch 031 | Train Loss: 0.1648 Acc: 0.9358 | Val Loss: 0.1970 Acc: 0.9197\n",
      "Epoch 032 | Train Loss: 0.1581 Acc: 0.9372 | Val Loss: 0.1882 Acc: 0.9227\n",
      "Epoch 033 | Train Loss: 0.1514 Acc: 0.9429 | Val Loss: 0.1792 Acc: 0.9324\n",
      "Epoch 034 | Train Loss: 0.1497 Acc: 0.9423 | Val Loss: 0.1793 Acc: 0.9318\n",
      "Epoch 035 | Train Loss: 0.1351 Acc: 0.9494 | Val Loss: 0.1670 Acc: 0.9330\n",
      "Epoch 036 | Train Loss: 0.1341 Acc: 0.9482 | Val Loss: 0.1748 Acc: 0.9336\n",
      "Epoch 037 | Train Loss: 0.1226 Acc: 0.9561 | Val Loss: 0.1989 Acc: 0.9257\n",
      "Epoch 038 | Train Loss: 0.1353 Acc: 0.9478 | Val Loss: 0.1717 Acc: 0.9354\n",
      "Epoch 039 | Train Loss: 0.1194 Acc: 0.9532 | Val Loss: 0.1773 Acc: 0.9293\n",
      "Epoch 040 | Train Loss: 0.1212 Acc: 0.9514 | Val Loss: 0.1592 Acc: 0.9481\n",
      "Epoch 041 | Train Loss: 0.1280 Acc: 0.9511 | Val Loss: 0.1591 Acc: 0.9378\n",
      "Epoch 042 | Train Loss: 0.1212 Acc: 0.9517 | Val Loss: 0.1850 Acc: 0.9330\n",
      "Epoch 043 | Train Loss: 0.1245 Acc: 0.9509 | Val Loss: 0.1682 Acc: 0.9396\n",
      "Epoch 044 | Train Loss: 0.1109 Acc: 0.9585 | Val Loss: 0.1756 Acc: 0.9366\n",
      "Epoch 045 | Train Loss: 0.1104 Acc: 0.9598 | Val Loss: 0.1450 Acc: 0.9444\n",
      "Epoch 046 | Train Loss: 0.1105 Acc: 0.9574 | Val Loss: 0.1544 Acc: 0.9390\n",
      "Epoch 047 | Train Loss: 0.1011 Acc: 0.9630 | Val Loss: 0.1646 Acc: 0.9402\n",
      "Epoch 048 | Train Loss: 0.1101 Acc: 0.9568 | Val Loss: 0.1646 Acc: 0.9390\n",
      "Epoch 049 | Train Loss: 0.1015 Acc: 0.9644 | Val Loss: 0.1601 Acc: 0.9463\n",
      "Epoch 050 | Train Loss: 0.0931 Acc: 0.9645 | Val Loss: 0.1528 Acc: 0.9493\n",
      "Epoch 051 | Train Loss: 0.1003 Acc: 0.9624 | Val Loss: 0.1633 Acc: 0.9444\n",
      "Epoch 052 | Train Loss: 0.1006 Acc: 0.9653 | Val Loss: 0.1992 Acc: 0.9336\n",
      "Epoch 053 | Train Loss: 0.0868 Acc: 0.9671 | Val Loss: 0.1612 Acc: 0.9469\n",
      "Epoch 054 | Train Loss: 0.0849 Acc: 0.9684 | Val Loss: 0.1656 Acc: 0.9384\n",
      "Epoch 055 | Train Loss: 0.0956 Acc: 0.9650 | Val Loss: 0.1496 Acc: 0.9450\n",
      "Early stopping triggered.\n",
      "Epoch 001 | Train Loss: 0.6810 Acc: 0.5753 | Val Loss: 0.6775 Acc: 0.5797\n",
      "Epoch 002 | Train Loss: 0.6724 Acc: 0.5985 | Val Loss: 0.6726 Acc: 0.5978\n",
      "Epoch 003 | Train Loss: 0.6622 Acc: 0.6059 | Val Loss: 0.6573 Acc: 0.6093\n",
      "Epoch 004 | Train Loss: 0.6233 Acc: 0.6666 | Val Loss: 0.6044 Acc: 0.6938\n",
      "Epoch 005 | Train Loss: 0.5933 Acc: 0.7015 | Val Loss: 0.5921 Acc: 0.6842\n",
      "Epoch 006 | Train Loss: 0.5792 Acc: 0.7112 | Val Loss: 0.5662 Acc: 0.7035\n",
      "Epoch 007 | Train Loss: 0.5546 Acc: 0.7278 | Val Loss: 0.5721 Acc: 0.6957\n",
      "Epoch 008 | Train Loss: 0.5388 Acc: 0.7395 | Val Loss: 0.5553 Acc: 0.7204\n",
      "Epoch 009 | Train Loss: 0.5258 Acc: 0.7460 | Val Loss: 0.5265 Acc: 0.7385\n",
      "Epoch 010 | Train Loss: 0.5053 Acc: 0.7555 | Val Loss: 0.5131 Acc: 0.7458\n",
      "Epoch 011 | Train Loss: 0.5016 Acc: 0.7577 | Val Loss: 0.5011 Acc: 0.7500\n",
      "Epoch 012 | Train Loss: 0.4720 Acc: 0.7752 | Val Loss: 0.4781 Acc: 0.7754\n",
      "Epoch 013 | Train Loss: 0.4662 Acc: 0.7796 | Val Loss: 0.4778 Acc: 0.7693\n",
      "Epoch 014 | Train Loss: 0.4435 Acc: 0.7924 | Val Loss: 0.4230 Acc: 0.8062\n",
      "Epoch 015 | Train Loss: 0.4122 Acc: 0.8075 | Val Loss: 0.4321 Acc: 0.7905\n",
      "Epoch 016 | Train Loss: 0.4181 Acc: 0.8095 | Val Loss: 0.4196 Acc: 0.7971\n",
      "Epoch 017 | Train Loss: 0.3929 Acc: 0.8274 | Val Loss: 0.3778 Acc: 0.8267\n",
      "Epoch 018 | Train Loss: 0.3812 Acc: 0.8350 | Val Loss: 0.3902 Acc: 0.8170\n",
      "Epoch 019 | Train Loss: 0.3666 Acc: 0.8351 | Val Loss: 0.3468 Acc: 0.8430\n",
      "Epoch 020 | Train Loss: 0.3603 Acc: 0.8409 | Val Loss: 0.3297 Acc: 0.8539\n",
      "Epoch 021 | Train Loss: 0.3480 Acc: 0.8502 | Val Loss: 0.3227 Acc: 0.8557\n",
      "Epoch 022 | Train Loss: 0.3211 Acc: 0.8665 | Val Loss: 0.3159 Acc: 0.8587\n",
      "Epoch 023 | Train Loss: 0.3227 Acc: 0.8641 | Val Loss: 0.2967 Acc: 0.8714\n",
      "Epoch 024 | Train Loss: 0.2922 Acc: 0.8798 | Val Loss: 0.2717 Acc: 0.8847\n",
      "Epoch 025 | Train Loss: 0.2809 Acc: 0.8807 | Val Loss: 0.2882 Acc: 0.8816\n",
      "Epoch 026 | Train Loss: 0.2807 Acc: 0.8830 | Val Loss: 0.2533 Acc: 0.8937\n",
      "Epoch 027 | Train Loss: 0.2783 Acc: 0.8845 | Val Loss: 0.2794 Acc: 0.8919\n",
      "Epoch 028 | Train Loss: 0.2618 Acc: 0.8923 | Val Loss: 0.2639 Acc: 0.8865\n",
      "Epoch 029 | Train Loss: 0.2542 Acc: 0.8981 | Val Loss: 0.2547 Acc: 0.8961\n",
      "Epoch 030 | Train Loss: 0.2466 Acc: 0.9003 | Val Loss: 0.2556 Acc: 0.8967\n",
      "Epoch 031 | Train Loss: 0.2409 Acc: 0.9043 | Val Loss: 0.2459 Acc: 0.8955\n",
      "Epoch 032 | Train Loss: 0.2285 Acc: 0.9108 | Val Loss: 0.2285 Acc: 0.9052\n",
      "Epoch 033 | Train Loss: 0.2326 Acc: 0.9093 | Val Loss: 0.2164 Acc: 0.9028\n",
      "Epoch 034 | Train Loss: 0.2223 Acc: 0.9118 | Val Loss: 0.2226 Acc: 0.9106\n",
      "Epoch 035 | Train Loss: 0.2137 Acc: 0.9164 | Val Loss: 0.2076 Acc: 0.9233\n",
      "Epoch 036 | Train Loss: 0.2068 Acc: 0.9168 | Val Loss: 0.2216 Acc: 0.9058\n",
      "Epoch 037 | Train Loss: 0.2033 Acc: 0.9167 | Val Loss: 0.2294 Acc: 0.9016\n",
      "Epoch 038 | Train Loss: 0.1948 Acc: 0.9274 | Val Loss: 0.2369 Acc: 0.9016\n",
      "Epoch 039 | Train Loss: 0.2015 Acc: 0.9238 | Val Loss: 0.2270 Acc: 0.9136\n",
      "Epoch 040 | Train Loss: 0.1913 Acc: 0.9274 | Val Loss: 0.1951 Acc: 0.9263\n",
      "Epoch 041 | Train Loss: 0.1797 Acc: 0.9269 | Val Loss: 0.2237 Acc: 0.9100\n",
      "Epoch 042 | Train Loss: 0.1780 Acc: 0.9299 | Val Loss: 0.1990 Acc: 0.9227\n",
      "Epoch 043 | Train Loss: 0.1705 Acc: 0.9328 | Val Loss: 0.2001 Acc: 0.9161\n",
      "Epoch 044 | Train Loss: 0.1664 Acc: 0.9375 | Val Loss: 0.2170 Acc: 0.9136\n",
      "Epoch 045 | Train Loss: 0.1736 Acc: 0.9343 | Val Loss: 0.1741 Acc: 0.9300\n",
      "Epoch 046 | Train Loss: 0.1791 Acc: 0.9284 | Val Loss: 0.1952 Acc: 0.9215\n",
      "Epoch 047 | Train Loss: 0.1563 Acc: 0.9381 | Val Loss: 0.1810 Acc: 0.9269\n",
      "Epoch 048 | Train Loss: 0.1602 Acc: 0.9378 | Val Loss: 0.1851 Acc: 0.9233\n",
      "Epoch 049 | Train Loss: 0.1583 Acc: 0.9375 | Val Loss: 0.1809 Acc: 0.9293\n",
      "Epoch 050 | Train Loss: 0.1542 Acc: 0.9419 | Val Loss: 0.1873 Acc: 0.9300\n",
      "Epoch 051 | Train Loss: 0.1549 Acc: 0.9410 | Val Loss: 0.1912 Acc: 0.9227\n",
      "Epoch 052 | Train Loss: 0.1387 Acc: 0.9464 | Val Loss: 0.1607 Acc: 0.9360\n",
      "Epoch 053 | Train Loss: 0.1426 Acc: 0.9485 | Val Loss: 0.1816 Acc: 0.9312\n",
      "Epoch 054 | Train Loss: 0.1368 Acc: 0.9469 | Val Loss: 0.1792 Acc: 0.9300\n",
      "Epoch 055 | Train Loss: 0.1474 Acc: 0.9435 | Val Loss: 0.1612 Acc: 0.9378\n",
      "Epoch 056 | Train Loss: 0.1377 Acc: 0.9475 | Val Loss: 0.1649 Acc: 0.9432\n",
      "Epoch 057 | Train Loss: 0.1333 Acc: 0.9529 | Val Loss: 0.1684 Acc: 0.9306\n",
      "Epoch 058 | Train Loss: 0.1379 Acc: 0.9515 | Val Loss: 0.1609 Acc: 0.9336\n",
      "Epoch 059 | Train Loss: 0.1312 Acc: 0.9491 | Val Loss: 0.1732 Acc: 0.9312\n",
      "Epoch 060 | Train Loss: 0.1257 Acc: 0.9541 | Val Loss: 0.1393 Acc: 0.9499\n",
      "Epoch 001 | Train Loss: 0.6803 Acc: 0.5775 | Val Loss: 0.6825 Acc: 0.5864\n",
      "Epoch 002 | Train Loss: 0.6634 Acc: 0.6030 | Val Loss: 0.6258 Acc: 0.6600\n",
      "Epoch 003 | Train Loss: 0.5956 Acc: 0.6965 | Val Loss: 0.5689 Acc: 0.7107\n",
      "Epoch 004 | Train Loss: 0.5584 Acc: 0.7261 | Val Loss: 0.5554 Acc: 0.7210\n",
      "Epoch 005 | Train Loss: 0.5282 Acc: 0.7465 | Val Loss: 0.5159 Acc: 0.7554\n",
      "Epoch 006 | Train Loss: 0.5008 Acc: 0.7626 | Val Loss: 0.4959 Acc: 0.7548\n",
      "Epoch 007 | Train Loss: 0.4947 Acc: 0.7628 | Val Loss: 0.4762 Acc: 0.7693\n",
      "Epoch 008 | Train Loss: 0.4585 Acc: 0.7867 | Val Loss: 0.4585 Acc: 0.7850\n",
      "Epoch 009 | Train Loss: 0.4261 Acc: 0.8057 | Val Loss: 0.4362 Acc: 0.8043\n",
      "Epoch 010 | Train Loss: 0.4065 Acc: 0.8169 | Val Loss: 0.4253 Acc: 0.8062\n",
      "Epoch 011 | Train Loss: 0.3707 Acc: 0.8347 | Val Loss: 0.3522 Acc: 0.8357\n",
      "Epoch 012 | Train Loss: 0.3552 Acc: 0.8436 | Val Loss: 0.3184 Acc: 0.8460\n",
      "Epoch 013 | Train Loss: 0.3231 Acc: 0.8635 | Val Loss: 0.3310 Acc: 0.8502\n",
      "Epoch 014 | Train Loss: 0.3083 Acc: 0.8703 | Val Loss: 0.2981 Acc: 0.8665\n",
      "Epoch 015 | Train Loss: 0.2824 Acc: 0.8831 | Val Loss: 0.3344 Acc: 0.8551\n",
      "Epoch 016 | Train Loss: 0.2668 Acc: 0.8889 | Val Loss: 0.3002 Acc: 0.8647\n",
      "Epoch 017 | Train Loss: 0.2626 Acc: 0.8892 | Val Loss: 0.2458 Acc: 0.8955\n",
      "Epoch 018 | Train Loss: 0.2398 Acc: 0.9050 | Val Loss: 0.2868 Acc: 0.8786\n",
      "Epoch 019 | Train Loss: 0.2399 Acc: 0.9034 | Val Loss: 0.2683 Acc: 0.8901\n",
      "Epoch 020 | Train Loss: 0.2160 Acc: 0.9106 | Val Loss: 0.2524 Acc: 0.8901\n",
      "Epoch 021 | Train Loss: 0.1997 Acc: 0.9171 | Val Loss: 0.2247 Acc: 0.8973\n",
      "Epoch 022 | Train Loss: 0.1917 Acc: 0.9253 | Val Loss: 0.2222 Acc: 0.9088\n",
      "Epoch 023 | Train Loss: 0.1956 Acc: 0.9230 | Val Loss: 0.2344 Acc: 0.9149\n",
      "Epoch 024 | Train Loss: 0.1859 Acc: 0.9269 | Val Loss: 0.2336 Acc: 0.8961\n",
      "Epoch 025 | Train Loss: 0.1726 Acc: 0.9304 | Val Loss: 0.2309 Acc: 0.9094\n",
      "Epoch 026 | Train Loss: 0.1695 Acc: 0.9333 | Val Loss: 0.1991 Acc: 0.9233\n",
      "Epoch 027 | Train Loss: 0.1704 Acc: 0.9334 | Val Loss: 0.2175 Acc: 0.9118\n",
      "Epoch 028 | Train Loss: 0.1649 Acc: 0.9355 | Val Loss: 0.2084 Acc: 0.9106\n",
      "Epoch 029 | Train Loss: 0.1491 Acc: 0.9441 | Val Loss: 0.2198 Acc: 0.9118\n",
      "Epoch 030 | Train Loss: 0.1454 Acc: 0.9437 | Val Loss: 0.2264 Acc: 0.9094\n",
      "Epoch 031 | Train Loss: 0.1403 Acc: 0.9465 | Val Loss: 0.2354 Acc: 0.9269\n",
      "Epoch 032 | Train Loss: 0.1364 Acc: 0.9475 | Val Loss: 0.2048 Acc: 0.9239\n",
      "Epoch 033 | Train Loss: 0.1298 Acc: 0.9502 | Val Loss: 0.1992 Acc: 0.9209\n",
      "Epoch 034 | Train Loss: 0.1287 Acc: 0.9490 | Val Loss: 0.1801 Acc: 0.9330\n",
      "Epoch 035 | Train Loss: 0.1231 Acc: 0.9541 | Val Loss: 0.1967 Acc: 0.9336\n",
      "Epoch 036 | Train Loss: 0.1139 Acc: 0.9573 | Val Loss: 0.2152 Acc: 0.9233\n",
      "Epoch 037 | Train Loss: 0.1178 Acc: 0.9570 | Val Loss: 0.1941 Acc: 0.9312\n",
      "Epoch 038 | Train Loss: 0.1155 Acc: 0.9558 | Val Loss: 0.2118 Acc: 0.9221\n",
      "Epoch 039 | Train Loss: 0.1096 Acc: 0.9604 | Val Loss: 0.1953 Acc: 0.9360\n",
      "Epoch 040 | Train Loss: 0.1019 Acc: 0.9629 | Val Loss: 0.2209 Acc: 0.9251\n",
      "Epoch 041 | Train Loss: 0.1211 Acc: 0.9550 | Val Loss: 0.1886 Acc: 0.9312\n",
      "Epoch 042 | Train Loss: 0.1147 Acc: 0.9595 | Val Loss: 0.2092 Acc: 0.9221\n",
      "Epoch 043 | Train Loss: 0.0979 Acc: 0.9632 | Val Loss: 0.2031 Acc: 0.9275\n",
      "Epoch 044 | Train Loss: 0.0980 Acc: 0.9613 | Val Loss: 0.1862 Acc: 0.9312\n",
      "Early stopping triggered.\n",
      "Epoch 001 | Train Loss: 0.6810 Acc: 0.5768 | Val Loss: 0.6870 Acc: 0.5586\n",
      "Epoch 002 | Train Loss: 0.6788 Acc: 0.5793 | Val Loss: 0.6729 Acc: 0.5906\n",
      "Epoch 003 | Train Loss: 0.6669 Acc: 0.6017 | Val Loss: 0.6670 Acc: 0.6033\n",
      "Epoch 004 | Train Loss: 0.6503 Acc: 0.6295 | Val Loss: 0.6058 Acc: 0.6926\n",
      "Epoch 005 | Train Loss: 0.5887 Acc: 0.7045 | Val Loss: 0.5794 Acc: 0.6981\n",
      "Epoch 006 | Train Loss: 0.5565 Acc: 0.7235 | Val Loss: 0.5487 Acc: 0.7271\n",
      "Epoch 007 | Train Loss: 0.5224 Acc: 0.7472 | Val Loss: 0.5208 Acc: 0.7446\n",
      "Epoch 008 | Train Loss: 0.4937 Acc: 0.7616 | Val Loss: 0.5107 Acc: 0.7512\n",
      "Epoch 009 | Train Loss: 0.4751 Acc: 0.7747 | Val Loss: 0.4825 Acc: 0.7633\n",
      "Epoch 010 | Train Loss: 0.4565 Acc: 0.7906 | Val Loss: 0.4414 Acc: 0.7886\n",
      "Epoch 011 | Train Loss: 0.4280 Acc: 0.7984 | Val Loss: 0.4844 Acc: 0.7796\n",
      "Epoch 012 | Train Loss: 0.3957 Acc: 0.8185 | Val Loss: 0.4232 Acc: 0.8013\n",
      "Epoch 013 | Train Loss: 0.3817 Acc: 0.8306 | Val Loss: 0.3696 Acc: 0.8382\n",
      "Epoch 014 | Train Loss: 0.3551 Acc: 0.8446 | Val Loss: 0.3687 Acc: 0.8321\n",
      "Epoch 015 | Train Loss: 0.3368 Acc: 0.8567 | Val Loss: 0.3414 Acc: 0.8527\n",
      "Epoch 016 | Train Loss: 0.3210 Acc: 0.8578 | Val Loss: 0.3812 Acc: 0.8158\n",
      "Epoch 017 | Train Loss: 0.3119 Acc: 0.8685 | Val Loss: 0.3012 Acc: 0.8732\n",
      "Epoch 018 | Train Loss: 0.2897 Acc: 0.8775 | Val Loss: 0.3112 Acc: 0.8696\n",
      "Epoch 019 | Train Loss: 0.2791 Acc: 0.8845 | Val Loss: 0.2793 Acc: 0.8804\n",
      "Epoch 020 | Train Loss: 0.2676 Acc: 0.8884 | Val Loss: 0.2570 Acc: 0.8865\n",
      "Epoch 021 | Train Loss: 0.2514 Acc: 0.8982 | Val Loss: 0.2755 Acc: 0.8762\n",
      "Epoch 022 | Train Loss: 0.2395 Acc: 0.8979 | Val Loss: 0.2895 Acc: 0.8702\n",
      "Epoch 023 | Train Loss: 0.2334 Acc: 0.9052 | Val Loss: 0.2418 Acc: 0.8901\n",
      "Epoch 024 | Train Loss: 0.2194 Acc: 0.9097 | Val Loss: 0.2458 Acc: 0.8986\n",
      "Epoch 025 | Train Loss: 0.2347 Acc: 0.9029 | Val Loss: 0.2452 Acc: 0.8877\n",
      "Epoch 026 | Train Loss: 0.2101 Acc: 0.9132 | Val Loss: 0.2572 Acc: 0.8822\n",
      "Epoch 027 | Train Loss: 0.2044 Acc: 0.9148 | Val Loss: 0.2266 Acc: 0.9088\n",
      "Epoch 028 | Train Loss: 0.1930 Acc: 0.9225 | Val Loss: 0.2351 Acc: 0.9028\n",
      "Epoch 029 | Train Loss: 0.1783 Acc: 0.9316 | Val Loss: 0.2116 Acc: 0.9088\n",
      "Epoch 030 | Train Loss: 0.1853 Acc: 0.9253 | Val Loss: 0.2273 Acc: 0.9124\n",
      "Epoch 031 | Train Loss: 0.1685 Acc: 0.9358 | Val Loss: 0.1966 Acc: 0.9191\n",
      "Epoch 032 | Train Loss: 0.1732 Acc: 0.9310 | Val Loss: 0.1965 Acc: 0.9124\n",
      "Epoch 033 | Train Loss: 0.1709 Acc: 0.9355 | Val Loss: 0.2089 Acc: 0.9064\n",
      "Epoch 034 | Train Loss: 0.1566 Acc: 0.9396 | Val Loss: 0.1990 Acc: 0.9233\n",
      "Epoch 035 | Train Loss: 0.1511 Acc: 0.9376 | Val Loss: 0.1804 Acc: 0.9269\n",
      "Epoch 036 | Train Loss: 0.1512 Acc: 0.9434 | Val Loss: 0.2252 Acc: 0.9124\n",
      "Epoch 037 | Train Loss: 0.1489 Acc: 0.9455 | Val Loss: 0.2054 Acc: 0.9130\n",
      "Epoch 038 | Train Loss: 0.1449 Acc: 0.9438 | Val Loss: 0.1708 Acc: 0.9306\n",
      "Epoch 039 | Train Loss: 0.1417 Acc: 0.9458 | Val Loss: 0.2070 Acc: 0.9112\n",
      "Epoch 040 | Train Loss: 0.1282 Acc: 0.9521 | Val Loss: 0.2069 Acc: 0.9203\n",
      "Epoch 041 | Train Loss: 0.1204 Acc: 0.9532 | Val Loss: 0.1983 Acc: 0.9275\n",
      "Epoch 042 | Train Loss: 0.1284 Acc: 0.9518 | Val Loss: 0.1903 Acc: 0.9269\n",
      "Epoch 043 | Train Loss: 0.1286 Acc: 0.9527 | Val Loss: 0.1768 Acc: 0.9300\n",
      "Epoch 044 | Train Loss: 0.1218 Acc: 0.9530 | Val Loss: 0.1940 Acc: 0.9275\n",
      "Epoch 045 | Train Loss: 0.1358 Acc: 0.9476 | Val Loss: 0.1766 Acc: 0.9300\n",
      "Epoch 046 | Train Loss: 0.1061 Acc: 0.9604 | Val Loss: 0.2003 Acc: 0.9306\n",
      "Epoch 047 | Train Loss: 0.1102 Acc: 0.9597 | Val Loss: 0.1890 Acc: 0.9257\n",
      "Epoch 048 | Train Loss: 0.1119 Acc: 0.9546 | Val Loss: 0.1519 Acc: 0.9324\n",
      "Epoch 049 | Train Loss: 0.1121 Acc: 0.9601 | Val Loss: 0.2202 Acc: 0.9173\n",
      "Epoch 050 | Train Loss: 0.1143 Acc: 0.9565 | Val Loss: 0.1908 Acc: 0.9354\n",
      "Epoch 051 | Train Loss: 0.0976 Acc: 0.9636 | Val Loss: 0.1489 Acc: 0.9396\n",
      "Epoch 052 | Train Loss: 0.1031 Acc: 0.9616 | Val Loss: 0.1558 Acc: 0.9390\n",
      "Epoch 053 | Train Loss: 0.1123 Acc: 0.9588 | Val Loss: 0.1540 Acc: 0.9450\n",
      "Epoch 054 | Train Loss: 0.0995 Acc: 0.9626 | Val Loss: 0.1801 Acc: 0.9324\n",
      "Epoch 055 | Train Loss: 0.1014 Acc: 0.9603 | Val Loss: 0.1447 Acc: 0.9438\n",
      "Epoch 056 | Train Loss: 0.0994 Acc: 0.9616 | Val Loss: 0.1428 Acc: 0.9420\n",
      "Epoch 057 | Train Loss: 0.0891 Acc: 0.9681 | Val Loss: 0.1757 Acc: 0.9336\n",
      "Epoch 058 | Train Loss: 0.0964 Acc: 0.9641 | Val Loss: 0.1910 Acc: 0.9269\n",
      "Epoch 059 | Train Loss: 0.0985 Acc: 0.9621 | Val Loss: 0.1994 Acc: 0.9245\n",
      "Epoch 060 | Train Loss: 0.0905 Acc: 0.9672 | Val Loss: 0.1801 Acc: 0.9306\n",
      "Iteration 8/40 | Best Val Loss: 0.1259 | Iter Time: 293.88s | Total Time: 41.94 min\n",
      "Epoch 001 | Train Loss: 0.6814 Acc: 0.5732 | Val Loss: 0.6740 Acc: 0.5912\n",
      "Epoch 002 | Train Loss: 0.6669 Acc: 0.5979 | Val Loss: 0.6494 Acc: 0.6051\n",
      "Epoch 003 | Train Loss: 0.6217 Acc: 0.6686 | Val Loss: 0.5984 Acc: 0.6860\n",
      "Epoch 004 | Train Loss: 0.5675 Acc: 0.7193 | Val Loss: 0.5660 Acc: 0.7192\n",
      "Epoch 005 | Train Loss: 0.5420 Acc: 0.7331 | Val Loss: 0.5529 Acc: 0.7222\n",
      "Epoch 006 | Train Loss: 0.5259 Acc: 0.7433 | Val Loss: 0.5107 Acc: 0.7524\n",
      "Epoch 007 | Train Loss: 0.5012 Acc: 0.7572 | Val Loss: 0.5009 Acc: 0.7585\n",
      "Epoch 008 | Train Loss: 0.4852 Acc: 0.7679 | Val Loss: 0.5135 Acc: 0.7470\n",
      "Epoch 009 | Train Loss: 0.4720 Acc: 0.7802 | Val Loss: 0.4795 Acc: 0.7705\n",
      "Epoch 010 | Train Loss: 0.4520 Acc: 0.7860 | Val Loss: 0.4744 Acc: 0.7838\n",
      "Epoch 011 | Train Loss: 0.4410 Acc: 0.7895 | Val Loss: 0.4386 Acc: 0.7929\n",
      "Epoch 012 | Train Loss: 0.4222 Acc: 0.8025 | Val Loss: 0.4158 Acc: 0.7971\n",
      "Epoch 013 | Train Loss: 0.4270 Acc: 0.8057 | Val Loss: 0.4023 Acc: 0.8134\n",
      "Epoch 014 | Train Loss: 0.3969 Acc: 0.8159 | Val Loss: 0.3833 Acc: 0.8182\n",
      "Epoch 015 | Train Loss: 0.3726 Acc: 0.8329 | Val Loss: 0.3811 Acc: 0.8200\n",
      "Epoch 016 | Train Loss: 0.3631 Acc: 0.8396 | Val Loss: 0.3367 Acc: 0.8478\n",
      "Epoch 017 | Train Loss: 0.3414 Acc: 0.8487 | Val Loss: 0.3510 Acc: 0.8484\n",
      "Epoch 018 | Train Loss: 0.3323 Acc: 0.8538 | Val Loss: 0.3086 Acc: 0.8659\n",
      "Epoch 019 | Train Loss: 0.2981 Acc: 0.8724 | Val Loss: 0.3441 Acc: 0.8593\n",
      "Epoch 020 | Train Loss: 0.2895 Acc: 0.8748 | Val Loss: 0.2700 Acc: 0.8847\n",
      "Epoch 021 | Train Loss: 0.2691 Acc: 0.8898 | Val Loss: 0.2757 Acc: 0.8792\n",
      "Epoch 022 | Train Loss: 0.2647 Acc: 0.8893 | Val Loss: 0.2661 Acc: 0.8871\n",
      "Epoch 023 | Train Loss: 0.2589 Acc: 0.8880 | Val Loss: 0.2451 Acc: 0.8937\n",
      "Epoch 024 | Train Loss: 0.2360 Acc: 0.9052 | Val Loss: 0.2387 Acc: 0.9106\n",
      "Epoch 025 | Train Loss: 0.2284 Acc: 0.9062 | Val Loss: 0.2432 Acc: 0.9052\n",
      "Epoch 026 | Train Loss: 0.2193 Acc: 0.9106 | Val Loss: 0.2218 Acc: 0.9106\n",
      "Epoch 027 | Train Loss: 0.2193 Acc: 0.9111 | Val Loss: 0.2398 Acc: 0.9064\n",
      "Epoch 028 | Train Loss: 0.2082 Acc: 0.9165 | Val Loss: 0.3051 Acc: 0.8714\n",
      "Epoch 029 | Train Loss: 0.2004 Acc: 0.9231 | Val Loss: 0.2087 Acc: 0.9155\n",
      "Epoch 030 | Train Loss: 0.1954 Acc: 0.9234 | Val Loss: 0.2115 Acc: 0.9209\n",
      "Epoch 031 | Train Loss: 0.1921 Acc: 0.9265 | Val Loss: 0.1999 Acc: 0.9215\n",
      "Epoch 032 | Train Loss: 0.1719 Acc: 0.9315 | Val Loss: 0.1947 Acc: 0.9287\n",
      "Epoch 033 | Train Loss: 0.1757 Acc: 0.9290 | Val Loss: 0.1942 Acc: 0.9293\n",
      "Epoch 034 | Train Loss: 0.1547 Acc: 0.9402 | Val Loss: 0.1955 Acc: 0.9293\n",
      "Epoch 035 | Train Loss: 0.1553 Acc: 0.9390 | Val Loss: 0.2083 Acc: 0.9167\n",
      "Epoch 036 | Train Loss: 0.1607 Acc: 0.9387 | Val Loss: 0.1916 Acc: 0.9269\n",
      "Epoch 037 | Train Loss: 0.1412 Acc: 0.9488 | Val Loss: 0.1682 Acc: 0.9354\n",
      "Epoch 038 | Train Loss: 0.1431 Acc: 0.9452 | Val Loss: 0.1745 Acc: 0.9384\n",
      "Epoch 039 | Train Loss: 0.1432 Acc: 0.9434 | Val Loss: 0.1840 Acc: 0.9324\n",
      "Epoch 040 | Train Loss: 0.1376 Acc: 0.9485 | Val Loss: 0.1765 Acc: 0.9354\n",
      "Epoch 041 | Train Loss: 0.1398 Acc: 0.9482 | Val Loss: 0.1571 Acc: 0.9438\n",
      "Epoch 042 | Train Loss: 0.1429 Acc: 0.9456 | Val Loss: 0.1590 Acc: 0.9444\n",
      "Epoch 043 | Train Loss: 0.1327 Acc: 0.9496 | Val Loss: 0.1838 Acc: 0.9281\n",
      "Epoch 044 | Train Loss: 0.1208 Acc: 0.9550 | Val Loss: 0.2147 Acc: 0.9227\n",
      "Epoch 045 | Train Loss: 0.1248 Acc: 0.9524 | Val Loss: 0.1680 Acc: 0.9450\n",
      "Epoch 046 | Train Loss: 0.1237 Acc: 0.9546 | Val Loss: 0.1790 Acc: 0.9257\n",
      "Epoch 047 | Train Loss: 0.1224 Acc: 0.9526 | Val Loss: 0.1499 Acc: 0.9475\n",
      "Epoch 048 | Train Loss: 0.1207 Acc: 0.9555 | Val Loss: 0.1784 Acc: 0.9360\n",
      "Epoch 049 | Train Loss: 0.1098 Acc: 0.9603 | Val Loss: 0.1643 Acc: 0.9420\n",
      "Epoch 050 | Train Loss: 0.1136 Acc: 0.9579 | Val Loss: 0.1619 Acc: 0.9390\n",
      "Epoch 051 | Train Loss: 0.1179 Acc: 0.9552 | Val Loss: 0.1722 Acc: 0.9360\n",
      "Epoch 052 | Train Loss: 0.1150 Acc: 0.9565 | Val Loss: 0.1554 Acc: 0.9457\n",
      "Epoch 053 | Train Loss: 0.1086 Acc: 0.9606 | Val Loss: 0.1595 Acc: 0.9481\n",
      "Epoch 054 | Train Loss: 0.0976 Acc: 0.9598 | Val Loss: 0.1850 Acc: 0.9384\n",
      "Epoch 055 | Train Loss: 0.1015 Acc: 0.9626 | Val Loss: 0.1429 Acc: 0.9450\n",
      "Epoch 056 | Train Loss: 0.0939 Acc: 0.9666 | Val Loss: 0.1757 Acc: 0.9396\n",
      "Epoch 057 | Train Loss: 0.0951 Acc: 0.9627 | Val Loss: 0.1404 Acc: 0.9499\n",
      "Epoch 058 | Train Loss: 0.1067 Acc: 0.9604 | Val Loss: 0.1575 Acc: 0.9475\n",
      "Epoch 059 | Train Loss: 0.0947 Acc: 0.9647 | Val Loss: 0.1468 Acc: 0.9469\n",
      "Epoch 060 | Train Loss: 0.1055 Acc: 0.9613 | Val Loss: 0.1595 Acc: 0.9378\n",
      "Epoch 001 | Train Loss: 0.6749 Acc: 0.5848 | Val Loss: 0.6681 Acc: 0.5876\n",
      "Epoch 002 | Train Loss: 0.6075 Acc: 0.6831 | Val Loss: 0.5843 Acc: 0.7005\n",
      "Epoch 003 | Train Loss: 0.5579 Acc: 0.7229 | Val Loss: 0.5584 Acc: 0.7035\n",
      "Epoch 004 | Train Loss: 0.5221 Acc: 0.7491 | Val Loss: 0.5123 Acc: 0.7572\n",
      "Epoch 005 | Train Loss: 0.4849 Acc: 0.7731 | Val Loss: 0.4705 Acc: 0.7802\n",
      "Epoch 006 | Train Loss: 0.4441 Acc: 0.8004 | Val Loss: 0.4809 Acc: 0.7748\n",
      "Epoch 007 | Train Loss: 0.4071 Acc: 0.8175 | Val Loss: 0.3721 Acc: 0.8333\n",
      "Epoch 008 | Train Loss: 0.3740 Acc: 0.8409 | Val Loss: 0.4002 Acc: 0.8140\n",
      "Epoch 009 | Train Loss: 0.3371 Acc: 0.8590 | Val Loss: 0.3062 Acc: 0.8738\n",
      "Epoch 010 | Train Loss: 0.3052 Acc: 0.8698 | Val Loss: 0.3350 Acc: 0.8653\n",
      "Epoch 011 | Train Loss: 0.3029 Acc: 0.8757 | Val Loss: 0.2962 Acc: 0.8859\n",
      "Epoch 012 | Train Loss: 0.2735 Acc: 0.8866 | Val Loss: 0.3129 Acc: 0.8708\n",
      "Epoch 013 | Train Loss: 0.2555 Acc: 0.8981 | Val Loss: 0.2529 Acc: 0.8992\n",
      "Epoch 014 | Train Loss: 0.2583 Acc: 0.8925 | Val Loss: 0.2388 Acc: 0.9076\n",
      "Epoch 015 | Train Loss: 0.2391 Acc: 0.9014 | Val Loss: 0.2255 Acc: 0.9100\n",
      "Epoch 016 | Train Loss: 0.2214 Acc: 0.9121 | Val Loss: 0.2503 Acc: 0.9010\n",
      "Epoch 017 | Train Loss: 0.2116 Acc: 0.9167 | Val Loss: 0.2320 Acc: 0.9010\n",
      "Epoch 018 | Train Loss: 0.1971 Acc: 0.9231 | Val Loss: 0.2271 Acc: 0.9094\n",
      "Epoch 019 | Train Loss: 0.1931 Acc: 0.9238 | Val Loss: 0.2596 Acc: 0.8943\n",
      "Epoch 020 | Train Loss: 0.1908 Acc: 0.9228 | Val Loss: 0.2320 Acc: 0.9082\n",
      "Epoch 021 | Train Loss: 0.1882 Acc: 0.9290 | Val Loss: 0.2438 Acc: 0.8992\n",
      "Epoch 022 | Train Loss: 0.1765 Acc: 0.9308 | Val Loss: 0.2453 Acc: 0.9028\n",
      "Epoch 023 | Train Loss: 0.1584 Acc: 0.9382 | Val Loss: 0.1983 Acc: 0.9233\n",
      "Epoch 024 | Train Loss: 0.1550 Acc: 0.9381 | Val Loss: 0.2067 Acc: 0.9221\n",
      "Epoch 025 | Train Loss: 0.1512 Acc: 0.9384 | Val Loss: 0.1919 Acc: 0.9269\n",
      "Epoch 026 | Train Loss: 0.1420 Acc: 0.9459 | Val Loss: 0.2167 Acc: 0.9167\n",
      "Epoch 027 | Train Loss: 0.1372 Acc: 0.9456 | Val Loss: 0.2152 Acc: 0.9191\n",
      "Epoch 028 | Train Loss: 0.1297 Acc: 0.9506 | Val Loss: 0.1807 Acc: 0.9287\n",
      "Epoch 029 | Train Loss: 0.1258 Acc: 0.9515 | Val Loss: 0.2015 Acc: 0.9324\n",
      "Epoch 030 | Train Loss: 0.1180 Acc: 0.9539 | Val Loss: 0.2009 Acc: 0.9281\n",
      "Epoch 031 | Train Loss: 0.1371 Acc: 0.9473 | Val Loss: 0.1850 Acc: 0.9245\n",
      "Epoch 032 | Train Loss: 0.1230 Acc: 0.9521 | Val Loss: 0.1726 Acc: 0.9330\n",
      "Epoch 033 | Train Loss: 0.1156 Acc: 0.9533 | Val Loss: 0.1762 Acc: 0.9366\n",
      "Epoch 034 | Train Loss: 0.1138 Acc: 0.9576 | Val Loss: 0.1679 Acc: 0.9396\n",
      "Epoch 035 | Train Loss: 0.1037 Acc: 0.9623 | Val Loss: 0.1840 Acc: 0.9390\n",
      "Epoch 036 | Train Loss: 0.1104 Acc: 0.9573 | Val Loss: 0.1878 Acc: 0.9300\n",
      "Epoch 037 | Train Loss: 0.1059 Acc: 0.9607 | Val Loss: 0.1841 Acc: 0.9318\n",
      "Epoch 038 | Train Loss: 0.1033 Acc: 0.9603 | Val Loss: 0.1811 Acc: 0.9360\n",
      "Epoch 039 | Train Loss: 0.0964 Acc: 0.9630 | Val Loss: 0.2215 Acc: 0.9203\n",
      "Epoch 040 | Train Loss: 0.1033 Acc: 0.9592 | Val Loss: 0.1687 Acc: 0.9384\n",
      "Epoch 041 | Train Loss: 0.0966 Acc: 0.9642 | Val Loss: 0.1786 Acc: 0.9384\n",
      "Epoch 042 | Train Loss: 0.0900 Acc: 0.9669 | Val Loss: 0.1699 Acc: 0.9366\n",
      "Epoch 043 | Train Loss: 0.1011 Acc: 0.9615 | Val Loss: 0.2227 Acc: 0.9197\n",
      "Epoch 044 | Train Loss: 0.1039 Acc: 0.9616 | Val Loss: 0.1423 Acc: 0.9463\n",
      "Epoch 045 | Train Loss: 0.0884 Acc: 0.9645 | Val Loss: 0.1829 Acc: 0.9360\n",
      "Epoch 046 | Train Loss: 0.0870 Acc: 0.9689 | Val Loss: 0.1513 Acc: 0.9438\n",
      "Epoch 047 | Train Loss: 0.0845 Acc: 0.9689 | Val Loss: 0.1475 Acc: 0.9487\n",
      "Epoch 048 | Train Loss: 0.0822 Acc: 0.9698 | Val Loss: 0.1558 Acc: 0.9457\n",
      "Epoch 049 | Train Loss: 0.0830 Acc: 0.9692 | Val Loss: 0.1418 Acc: 0.9444\n",
      "Epoch 050 | Train Loss: 0.0730 Acc: 0.9733 | Val Loss: 0.1798 Acc: 0.9402\n",
      "Epoch 051 | Train Loss: 0.0837 Acc: 0.9697 | Val Loss: 0.1603 Acc: 0.9457\n",
      "Epoch 052 | Train Loss: 0.0883 Acc: 0.9687 | Val Loss: 0.1402 Acc: 0.9487\n",
      "Epoch 053 | Train Loss: 0.0728 Acc: 0.9709 | Val Loss: 0.1583 Acc: 0.9432\n",
      "Epoch 054 | Train Loss: 0.0790 Acc: 0.9716 | Val Loss: 0.1786 Acc: 0.9396\n",
      "Epoch 055 | Train Loss: 0.0839 Acc: 0.9681 | Val Loss: 0.2045 Acc: 0.9245\n",
      "Epoch 056 | Train Loss: 0.0700 Acc: 0.9757 | Val Loss: 0.1488 Acc: 0.9457\n",
      "Epoch 057 | Train Loss: 0.0741 Acc: 0.9730 | Val Loss: 0.1504 Acc: 0.9450\n",
      "Epoch 058 | Train Loss: 0.0786 Acc: 0.9713 | Val Loss: 0.1473 Acc: 0.9481\n",
      "Epoch 059 | Train Loss: 0.0623 Acc: 0.9757 | Val Loss: 0.1700 Acc: 0.9384\n",
      "Epoch 060 | Train Loss: 0.0792 Acc: 0.9709 | Val Loss: 0.1274 Acc: 0.9523\n",
      "Epoch 001 | Train Loss: 0.6842 Acc: 0.5701 | Val Loss: 0.6788 Acc: 0.5791\n",
      "Epoch 002 | Train Loss: 0.6626 Acc: 0.6080 | Val Loss: 0.6360 Acc: 0.6534\n",
      "Epoch 003 | Train Loss: 0.6188 Acc: 0.6755 | Val Loss: 0.6311 Acc: 0.6492\n",
      "Epoch 004 | Train Loss: 0.5921 Acc: 0.6932 | Val Loss: 0.5795 Acc: 0.6950\n",
      "Epoch 005 | Train Loss: 0.5657 Acc: 0.7109 | Val Loss: 0.5610 Acc: 0.7186\n",
      "Epoch 006 | Train Loss: 0.5490 Acc: 0.7279 | Val Loss: 0.5418 Acc: 0.7246\n",
      "Epoch 007 | Train Loss: 0.5278 Acc: 0.7432 | Val Loss: 0.5127 Acc: 0.7391\n",
      "Epoch 008 | Train Loss: 0.5133 Acc: 0.7522 | Val Loss: 0.5178 Acc: 0.7470\n",
      "Epoch 009 | Train Loss: 0.4966 Acc: 0.7666 | Val Loss: 0.4841 Acc: 0.7760\n",
      "Epoch 010 | Train Loss: 0.4921 Acc: 0.7637 | Val Loss: 0.4710 Acc: 0.7627\n",
      "Epoch 011 | Train Loss: 0.4714 Acc: 0.7732 | Val Loss: 0.4700 Acc: 0.7760\n",
      "Epoch 012 | Train Loss: 0.4573 Acc: 0.7882 | Val Loss: 0.4626 Acc: 0.7838\n",
      "Epoch 013 | Train Loss: 0.4379 Acc: 0.7939 | Val Loss: 0.4081 Acc: 0.8007\n",
      "Epoch 014 | Train Loss: 0.4230 Acc: 0.7990 | Val Loss: 0.4093 Acc: 0.7965\n",
      "Epoch 015 | Train Loss: 0.4092 Acc: 0.8203 | Val Loss: 0.3706 Acc: 0.8339\n",
      "Epoch 016 | Train Loss: 0.4060 Acc: 0.8250 | Val Loss: 0.4078 Acc: 0.8001\n",
      "Epoch 017 | Train Loss: 0.3908 Acc: 0.8267 | Val Loss: 0.3687 Acc: 0.8297\n",
      "Epoch 018 | Train Loss: 0.3726 Acc: 0.8410 | Val Loss: 0.3606 Acc: 0.8442\n",
      "Epoch 019 | Train Loss: 0.3645 Acc: 0.8393 | Val Loss: 0.3298 Acc: 0.8635\n",
      "Epoch 020 | Train Loss: 0.3413 Acc: 0.8547 | Val Loss: 0.3233 Acc: 0.8671\n",
      "Epoch 021 | Train Loss: 0.3394 Acc: 0.8576 | Val Loss: 0.3093 Acc: 0.8671\n",
      "Epoch 022 | Train Loss: 0.3255 Acc: 0.8646 | Val Loss: 0.2988 Acc: 0.8762\n",
      "Epoch 023 | Train Loss: 0.3135 Acc: 0.8685 | Val Loss: 0.2914 Acc: 0.8865\n",
      "Epoch 024 | Train Loss: 0.3089 Acc: 0.8724 | Val Loss: 0.2792 Acc: 0.8889\n",
      "Epoch 025 | Train Loss: 0.2983 Acc: 0.8786 | Val Loss: 0.2924 Acc: 0.8780\n",
      "Epoch 026 | Train Loss: 0.2983 Acc: 0.8786 | Val Loss: 0.2809 Acc: 0.8871\n",
      "Epoch 027 | Train Loss: 0.2991 Acc: 0.8810 | Val Loss: 0.2721 Acc: 0.8943\n",
      "Epoch 028 | Train Loss: 0.3025 Acc: 0.8759 | Val Loss: 0.2574 Acc: 0.8961\n",
      "Epoch 029 | Train Loss: 0.2772 Acc: 0.8874 | Val Loss: 0.2732 Acc: 0.8865\n",
      "Epoch 030 | Train Loss: 0.2667 Acc: 0.8925 | Val Loss: 0.2762 Acc: 0.8853\n",
      "Epoch 031 | Train Loss: 0.2709 Acc: 0.8880 | Val Loss: 0.2467 Acc: 0.8998\n",
      "Epoch 032 | Train Loss: 0.2627 Acc: 0.8896 | Val Loss: 0.2440 Acc: 0.9088\n",
      "Epoch 033 | Train Loss: 0.2597 Acc: 0.8954 | Val Loss: 0.2290 Acc: 0.9118\n",
      "Epoch 034 | Train Loss: 0.2424 Acc: 0.9031 | Val Loss: 0.2582 Acc: 0.8937\n",
      "Epoch 035 | Train Loss: 0.2507 Acc: 0.8984 | Val Loss: 0.2228 Acc: 0.9112\n",
      "Epoch 036 | Train Loss: 0.2385 Acc: 0.9093 | Val Loss: 0.2281 Acc: 0.9233\n",
      "Epoch 037 | Train Loss: 0.2488 Acc: 0.9000 | Val Loss: 0.2482 Acc: 0.9016\n",
      "Epoch 038 | Train Loss: 0.2331 Acc: 0.9058 | Val Loss: 0.2501 Acc: 0.9028\n",
      "Epoch 039 | Train Loss: 0.2367 Acc: 0.9068 | Val Loss: 0.2220 Acc: 0.9088\n",
      "Epoch 040 | Train Loss: 0.2244 Acc: 0.9115 | Val Loss: 0.2195 Acc: 0.9143\n",
      "Epoch 041 | Train Loss: 0.2336 Acc: 0.9088 | Val Loss: 0.2178 Acc: 0.9124\n",
      "Epoch 042 | Train Loss: 0.2281 Acc: 0.9112 | Val Loss: 0.2223 Acc: 0.9070\n",
      "Epoch 043 | Train Loss: 0.2155 Acc: 0.9144 | Val Loss: 0.2189 Acc: 0.9191\n",
      "Epoch 044 | Train Loss: 0.2177 Acc: 0.9176 | Val Loss: 0.2536 Acc: 0.9034\n",
      "Epoch 045 | Train Loss: 0.2164 Acc: 0.9151 | Val Loss: 0.2144 Acc: 0.9118\n",
      "Epoch 046 | Train Loss: 0.2092 Acc: 0.9176 | Val Loss: 0.1988 Acc: 0.9227\n",
      "Epoch 047 | Train Loss: 0.2047 Acc: 0.9185 | Val Loss: 0.2080 Acc: 0.9191\n",
      "Epoch 048 | Train Loss: 0.2037 Acc: 0.9123 | Val Loss: 0.2241 Acc: 0.8986\n",
      "Epoch 049 | Train Loss: 0.2061 Acc: 0.9168 | Val Loss: 0.2116 Acc: 0.9130\n",
      "Epoch 050 | Train Loss: 0.2035 Acc: 0.9201 | Val Loss: 0.2010 Acc: 0.9197\n",
      "Epoch 051 | Train Loss: 0.2071 Acc: 0.9200 | Val Loss: 0.2620 Acc: 0.8931\n",
      "Epoch 052 | Train Loss: 0.2046 Acc: 0.9230 | Val Loss: 0.2078 Acc: 0.9155\n",
      "Epoch 053 | Train Loss: 0.1969 Acc: 0.9266 | Val Loss: 0.1856 Acc: 0.9275\n",
      "Epoch 054 | Train Loss: 0.2013 Acc: 0.9274 | Val Loss: 0.1860 Acc: 0.9281\n",
      "Epoch 055 | Train Loss: 0.1954 Acc: 0.9228 | Val Loss: 0.1866 Acc: 0.9245\n",
      "Epoch 056 | Train Loss: 0.1937 Acc: 0.9236 | Val Loss: 0.1775 Acc: 0.9293\n",
      "Epoch 057 | Train Loss: 0.1928 Acc: 0.9250 | Val Loss: 0.2132 Acc: 0.9100\n",
      "Epoch 058 | Train Loss: 0.1845 Acc: 0.9301 | Val Loss: 0.1970 Acc: 0.9281\n",
      "Epoch 059 | Train Loss: 0.1834 Acc: 0.9287 | Val Loss: 0.1774 Acc: 0.9318\n",
      "Epoch 060 | Train Loss: 0.1826 Acc: 0.9336 | Val Loss: 0.1905 Acc: 0.9227\n",
      "Epoch 001 | Train Loss: 0.6839 Acc: 0.5697 | Val Loss: 0.6781 Acc: 0.5833\n",
      "Epoch 002 | Train Loss: 0.6755 Acc: 0.5870 | Val Loss: 0.6750 Acc: 0.5930\n",
      "Epoch 003 | Train Loss: 0.6718 Acc: 0.5934 | Val Loss: 0.6716 Acc: 0.5906\n",
      "Epoch 004 | Train Loss: 0.6648 Acc: 0.6041 | Val Loss: 0.6650 Acc: 0.5966\n",
      "Epoch 005 | Train Loss: 0.6517 Acc: 0.6166 | Val Loss: 0.6546 Acc: 0.6347\n",
      "Epoch 006 | Train Loss: 0.6421 Acc: 0.6313 | Val Loss: 0.6329 Acc: 0.6371\n",
      "Epoch 007 | Train Loss: 0.6212 Acc: 0.6592 | Val Loss: 0.6089 Acc: 0.6926\n",
      "Epoch 008 | Train Loss: 0.6024 Acc: 0.6798 | Val Loss: 0.5905 Acc: 0.6902\n",
      "Epoch 009 | Train Loss: 0.5904 Acc: 0.6938 | Val Loss: 0.5857 Acc: 0.7005\n",
      "Epoch 010 | Train Loss: 0.5840 Acc: 0.6935 | Val Loss: 0.5849 Acc: 0.7126\n",
      "Epoch 011 | Train Loss: 0.5744 Acc: 0.7072 | Val Loss: 0.5737 Acc: 0.7065\n",
      "Epoch 012 | Train Loss: 0.5706 Acc: 0.7110 | Val Loss: 0.5736 Acc: 0.7186\n",
      "Epoch 013 | Train Loss: 0.5604 Acc: 0.7152 | Val Loss: 0.5640 Acc: 0.7071\n",
      "Epoch 014 | Train Loss: 0.5560 Acc: 0.7192 | Val Loss: 0.5636 Acc: 0.7198\n",
      "Epoch 015 | Train Loss: 0.5455 Acc: 0.7257 | Val Loss: 0.5704 Acc: 0.7101\n",
      "Epoch 016 | Train Loss: 0.5428 Acc: 0.7311 | Val Loss: 0.5526 Acc: 0.7192\n",
      "Epoch 017 | Train Loss: 0.5365 Acc: 0.7359 | Val Loss: 0.5474 Acc: 0.7186\n",
      "Epoch 018 | Train Loss: 0.5262 Acc: 0.7433 | Val Loss: 0.5388 Acc: 0.7301\n",
      "Epoch 019 | Train Loss: 0.5209 Acc: 0.7457 | Val Loss: 0.5382 Acc: 0.7355\n",
      "Epoch 020 | Train Loss: 0.5123 Acc: 0.7507 | Val Loss: 0.5342 Acc: 0.7343\n",
      "Epoch 021 | Train Loss: 0.5149 Acc: 0.7466 | Val Loss: 0.5243 Acc: 0.7421\n",
      "Epoch 022 | Train Loss: 0.5092 Acc: 0.7536 | Val Loss: 0.5315 Acc: 0.7289\n",
      "Epoch 023 | Train Loss: 0.5052 Acc: 0.7571 | Val Loss: 0.5121 Acc: 0.7494\n",
      "Epoch 024 | Train Loss: 0.4971 Acc: 0.7572 | Val Loss: 0.5152 Acc: 0.7409\n",
      "Epoch 025 | Train Loss: 0.4985 Acc: 0.7629 | Val Loss: 0.5049 Acc: 0.7512\n",
      "Epoch 026 | Train Loss: 0.4898 Acc: 0.7610 | Val Loss: 0.5059 Acc: 0.7566\n",
      "Epoch 027 | Train Loss: 0.4805 Acc: 0.7714 | Val Loss: 0.4960 Acc: 0.7591\n",
      "Epoch 028 | Train Loss: 0.4801 Acc: 0.7735 | Val Loss: 0.4974 Acc: 0.7603\n",
      "Epoch 029 | Train Loss: 0.4750 Acc: 0.7767 | Val Loss: 0.4894 Acc: 0.7560\n",
      "Epoch 030 | Train Loss: 0.4704 Acc: 0.7777 | Val Loss: 0.4851 Acc: 0.7579\n",
      "Epoch 031 | Train Loss: 0.4660 Acc: 0.7839 | Val Loss: 0.4770 Acc: 0.7651\n",
      "Epoch 032 | Train Loss: 0.4585 Acc: 0.7874 | Val Loss: 0.4703 Acc: 0.7705\n",
      "Epoch 033 | Train Loss: 0.4527 Acc: 0.7883 | Val Loss: 0.4830 Acc: 0.7645\n",
      "Epoch 034 | Train Loss: 0.4452 Acc: 0.7931 | Val Loss: 0.4753 Acc: 0.7699\n",
      "Epoch 035 | Train Loss: 0.4403 Acc: 0.7939 | Val Loss: 0.4582 Acc: 0.7784\n",
      "Epoch 036 | Train Loss: 0.4358 Acc: 0.7948 | Val Loss: 0.4595 Acc: 0.7766\n",
      "Epoch 037 | Train Loss: 0.4334 Acc: 0.7983 | Val Loss: 0.4433 Acc: 0.7802\n",
      "Epoch 038 | Train Loss: 0.4308 Acc: 0.7977 | Val Loss: 0.4443 Acc: 0.7911\n",
      "Epoch 039 | Train Loss: 0.4204 Acc: 0.8066 | Val Loss: 0.4376 Acc: 0.7893\n",
      "Epoch 040 | Train Loss: 0.4197 Acc: 0.8054 | Val Loss: 0.4510 Acc: 0.7856\n",
      "Epoch 041 | Train Loss: 0.4135 Acc: 0.8098 | Val Loss: 0.4277 Acc: 0.7953\n",
      "Epoch 042 | Train Loss: 0.4134 Acc: 0.8075 | Val Loss: 0.4249 Acc: 0.7953\n",
      "Epoch 043 | Train Loss: 0.4038 Acc: 0.8165 | Val Loss: 0.4187 Acc: 0.7977\n",
      "Epoch 044 | Train Loss: 0.4028 Acc: 0.8162 | Val Loss: 0.4205 Acc: 0.7959\n",
      "Epoch 045 | Train Loss: 0.3998 Acc: 0.8129 | Val Loss: 0.4097 Acc: 0.8019\n",
      "Epoch 046 | Train Loss: 0.3904 Acc: 0.8194 | Val Loss: 0.4070 Acc: 0.8050\n",
      "Epoch 047 | Train Loss: 0.3815 Acc: 0.8295 | Val Loss: 0.3930 Acc: 0.8188\n",
      "Epoch 048 | Train Loss: 0.3781 Acc: 0.8258 | Val Loss: 0.4096 Acc: 0.8050\n",
      "Epoch 049 | Train Loss: 0.3777 Acc: 0.8300 | Val Loss: 0.3965 Acc: 0.8086\n",
      "Epoch 050 | Train Loss: 0.3736 Acc: 0.8277 | Val Loss: 0.3818 Acc: 0.8194\n",
      "Epoch 051 | Train Loss: 0.3573 Acc: 0.8365 | Val Loss: 0.3760 Acc: 0.8200\n",
      "Epoch 052 | Train Loss: 0.3571 Acc: 0.8371 | Val Loss: 0.3679 Acc: 0.8243\n",
      "Epoch 053 | Train Loss: 0.3499 Acc: 0.8425 | Val Loss: 0.3664 Acc: 0.8267\n",
      "Epoch 054 | Train Loss: 0.3556 Acc: 0.8377 | Val Loss: 0.3682 Acc: 0.8273\n",
      "Epoch 055 | Train Loss: 0.3537 Acc: 0.8403 | Val Loss: 0.3681 Acc: 0.8225\n",
      "Epoch 056 | Train Loss: 0.3358 Acc: 0.8489 | Val Loss: 0.3679 Acc: 0.8291\n",
      "Epoch 057 | Train Loss: 0.3430 Acc: 0.8451 | Val Loss: 0.3425 Acc: 0.8412\n",
      "Epoch 058 | Train Loss: 0.3323 Acc: 0.8504 | Val Loss: 0.3363 Acc: 0.8448\n",
      "Epoch 059 | Train Loss: 0.3254 Acc: 0.8532 | Val Loss: 0.3362 Acc: 0.8478\n",
      "Epoch 060 | Train Loss: 0.3208 Acc: 0.8597 | Val Loss: 0.3303 Acc: 0.8466\n",
      "Epoch 001 | Train Loss: 0.6813 Acc: 0.5645 | Val Loss: 0.6665 Acc: 0.6033\n",
      "Epoch 002 | Train Loss: 0.6532 Acc: 0.6233 | Val Loss: 0.6237 Acc: 0.6624\n",
      "Epoch 003 | Train Loss: 0.6139 Acc: 0.6779 | Val Loss: 0.5897 Acc: 0.6987\n",
      "Epoch 004 | Train Loss: 0.5799 Acc: 0.7053 | Val Loss: 0.5718 Acc: 0.7071\n",
      "Epoch 005 | Train Loss: 0.5709 Acc: 0.7172 | Val Loss: 0.5630 Acc: 0.7138\n",
      "Epoch 006 | Train Loss: 0.5652 Acc: 0.7145 | Val Loss: 0.5458 Acc: 0.7246\n",
      "Epoch 007 | Train Loss: 0.5494 Acc: 0.7272 | Val Loss: 0.5358 Acc: 0.7319\n",
      "Epoch 008 | Train Loss: 0.5463 Acc: 0.7284 | Val Loss: 0.5416 Acc: 0.7252\n",
      "Epoch 009 | Train Loss: 0.5318 Acc: 0.7404 | Val Loss: 0.5389 Acc: 0.7283\n",
      "Epoch 010 | Train Loss: 0.5235 Acc: 0.7424 | Val Loss: 0.5115 Acc: 0.7530\n",
      "Epoch 011 | Train Loss: 0.5095 Acc: 0.7516 | Val Loss: 0.5014 Acc: 0.7579\n",
      "Epoch 012 | Train Loss: 0.5017 Acc: 0.7587 | Val Loss: 0.4971 Acc: 0.7506\n",
      "Epoch 013 | Train Loss: 0.4886 Acc: 0.7619 | Val Loss: 0.4740 Acc: 0.7705\n",
      "Epoch 014 | Train Loss: 0.4782 Acc: 0.7723 | Val Loss: 0.4974 Acc: 0.7500\n",
      "Epoch 015 | Train Loss: 0.4694 Acc: 0.7780 | Val Loss: 0.4987 Acc: 0.7681\n",
      "Epoch 016 | Train Loss: 0.4712 Acc: 0.7774 | Val Loss: 0.4530 Acc: 0.7808\n",
      "Epoch 017 | Train Loss: 0.4521 Acc: 0.7854 | Val Loss: 0.4325 Acc: 0.7977\n",
      "Epoch 018 | Train Loss: 0.4350 Acc: 0.7972 | Val Loss: 0.4350 Acc: 0.7953\n",
      "Epoch 019 | Train Loss: 0.4268 Acc: 0.8049 | Val Loss: 0.4072 Acc: 0.8146\n",
      "Epoch 020 | Train Loss: 0.4207 Acc: 0.8093 | Val Loss: 0.4067 Acc: 0.8110\n",
      "Epoch 021 | Train Loss: 0.4103 Acc: 0.8173 | Val Loss: 0.3809 Acc: 0.8213\n",
      "Epoch 022 | Train Loss: 0.3870 Acc: 0.8261 | Val Loss: 0.3606 Acc: 0.8418\n",
      "Epoch 023 | Train Loss: 0.3888 Acc: 0.8303 | Val Loss: 0.3592 Acc: 0.8388\n",
      "Epoch 024 | Train Loss: 0.3848 Acc: 0.8282 | Val Loss: 0.3507 Acc: 0.8424\n",
      "Epoch 025 | Train Loss: 0.3677 Acc: 0.8395 | Val Loss: 0.3343 Acc: 0.8508\n",
      "Epoch 026 | Train Loss: 0.3540 Acc: 0.8464 | Val Loss: 0.3269 Acc: 0.8545\n",
      "Epoch 027 | Train Loss: 0.3629 Acc: 0.8410 | Val Loss: 0.3335 Acc: 0.8557\n",
      "Epoch 028 | Train Loss: 0.3449 Acc: 0.8446 | Val Loss: 0.3157 Acc: 0.8665\n",
      "Epoch 029 | Train Loss: 0.3452 Acc: 0.8547 | Val Loss: 0.3114 Acc: 0.8665\n",
      "Epoch 030 | Train Loss: 0.3370 Acc: 0.8552 | Val Loss: 0.2993 Acc: 0.8774\n",
      "Epoch 031 | Train Loss: 0.3278 Acc: 0.8618 | Val Loss: 0.2961 Acc: 0.8732\n",
      "Epoch 032 | Train Loss: 0.3205 Acc: 0.8649 | Val Loss: 0.3094 Acc: 0.8647\n",
      "Epoch 033 | Train Loss: 0.3047 Acc: 0.8673 | Val Loss: 0.2774 Acc: 0.8907\n",
      "Epoch 034 | Train Loss: 0.3149 Acc: 0.8634 | Val Loss: 0.3046 Acc: 0.8726\n",
      "Epoch 035 | Train Loss: 0.3122 Acc: 0.8717 | Val Loss: 0.3056 Acc: 0.8678\n",
      "Epoch 036 | Train Loss: 0.3078 Acc: 0.8667 | Val Loss: 0.2779 Acc: 0.8901\n",
      "Epoch 037 | Train Loss: 0.3006 Acc: 0.8712 | Val Loss: 0.2606 Acc: 0.8913\n",
      "Epoch 038 | Train Loss: 0.2844 Acc: 0.8824 | Val Loss: 0.2547 Acc: 0.8949\n",
      "Epoch 039 | Train Loss: 0.2798 Acc: 0.8863 | Val Loss: 0.2557 Acc: 0.8901\n",
      "Epoch 040 | Train Loss: 0.2781 Acc: 0.8837 | Val Loss: 0.2843 Acc: 0.8829\n",
      "Epoch 041 | Train Loss: 0.2786 Acc: 0.8842 | Val Loss: 0.2547 Acc: 0.9010\n",
      "Epoch 042 | Train Loss: 0.2721 Acc: 0.8877 | Val Loss: 0.2515 Acc: 0.9010\n",
      "Epoch 043 | Train Loss: 0.2548 Acc: 0.8961 | Val Loss: 0.2420 Acc: 0.8943\n",
      "Epoch 044 | Train Loss: 0.2673 Acc: 0.8890 | Val Loss: 0.2360 Acc: 0.9010\n",
      "Epoch 045 | Train Loss: 0.2613 Acc: 0.8911 | Val Loss: 0.2559 Acc: 0.8919\n",
      "Epoch 046 | Train Loss: 0.2657 Acc: 0.8889 | Val Loss: 0.2618 Acc: 0.8931\n",
      "Epoch 047 | Train Loss: 0.2611 Acc: 0.8892 | Val Loss: 0.2711 Acc: 0.8786\n",
      "Epoch 048 | Train Loss: 0.2604 Acc: 0.8928 | Val Loss: 0.2340 Acc: 0.9124\n",
      "Epoch 049 | Train Loss: 0.2447 Acc: 0.9053 | Val Loss: 0.2196 Acc: 0.9136\n",
      "Epoch 050 | Train Loss: 0.2414 Acc: 0.9023 | Val Loss: 0.2563 Acc: 0.8967\n",
      "Epoch 051 | Train Loss: 0.2328 Acc: 0.9080 | Val Loss: 0.2694 Acc: 0.8913\n",
      "Epoch 052 | Train Loss: 0.2430 Acc: 0.9044 | Val Loss: 0.2395 Acc: 0.8998\n",
      "Epoch 053 | Train Loss: 0.2367 Acc: 0.9076 | Val Loss: 0.2218 Acc: 0.9088\n",
      "Epoch 054 | Train Loss: 0.2439 Acc: 0.9029 | Val Loss: 0.2337 Acc: 0.9022\n",
      "Epoch 055 | Train Loss: 0.2468 Acc: 0.8996 | Val Loss: 0.2237 Acc: 0.9088\n",
      "Epoch 056 | Train Loss: 0.2257 Acc: 0.9118 | Val Loss: 0.2806 Acc: 0.8786\n",
      "Epoch 057 | Train Loss: 0.2293 Acc: 0.9114 | Val Loss: 0.2910 Acc: 0.8798\n",
      "Epoch 058 | Train Loss: 0.2335 Acc: 0.9013 | Val Loss: 0.2612 Acc: 0.8871\n",
      "Epoch 059 | Train Loss: 0.2129 Acc: 0.9167 | Val Loss: 0.2271 Acc: 0.9064\n",
      "Early stopping triggered.\n",
      "Epoch 001 | Train Loss: 0.6797 Acc: 0.5806 | Val Loss: 0.6729 Acc: 0.5894\n",
      "Epoch 002 | Train Loss: 0.6678 Acc: 0.5973 | Val Loss: 0.6693 Acc: 0.5912\n",
      "Epoch 003 | Train Loss: 0.6478 Acc: 0.6260 | Val Loss: 0.6241 Acc: 0.6751\n",
      "Epoch 004 | Train Loss: 0.6162 Acc: 0.6740 | Val Loss: 0.6002 Acc: 0.6878\n",
      "Epoch 005 | Train Loss: 0.5934 Acc: 0.6953 | Val Loss: 0.5828 Acc: 0.7023\n",
      "Epoch 006 | Train Loss: 0.5630 Acc: 0.7173 | Val Loss: 0.5639 Acc: 0.7138\n",
      "Epoch 007 | Train Loss: 0.5357 Acc: 0.7401 | Val Loss: 0.5425 Acc: 0.7277\n",
      "Epoch 008 | Train Loss: 0.5260 Acc: 0.7456 | Val Loss: 0.5320 Acc: 0.7379\n",
      "Epoch 009 | Train Loss: 0.5086 Acc: 0.7552 | Val Loss: 0.5146 Acc: 0.7458\n",
      "Epoch 010 | Train Loss: 0.4934 Acc: 0.7697 | Val Loss: 0.5003 Acc: 0.7566\n",
      "Epoch 011 | Train Loss: 0.4807 Acc: 0.7747 | Val Loss: 0.5078 Acc: 0.7591\n",
      "Epoch 012 | Train Loss: 0.4708 Acc: 0.7812 | Val Loss: 0.4901 Acc: 0.7609\n",
      "Epoch 013 | Train Loss: 0.4511 Acc: 0.7927 | Val Loss: 0.4822 Acc: 0.7530\n",
      "Epoch 014 | Train Loss: 0.4361 Acc: 0.8001 | Val Loss: 0.4323 Acc: 0.8001\n",
      "Epoch 015 | Train Loss: 0.4238 Acc: 0.8014 | Val Loss: 0.4477 Acc: 0.7947\n",
      "Epoch 016 | Train Loss: 0.4022 Acc: 0.8143 | Val Loss: 0.4014 Acc: 0.8140\n",
      "Epoch 017 | Train Loss: 0.3810 Acc: 0.8226 | Val Loss: 0.3781 Acc: 0.8297\n",
      "Epoch 018 | Train Loss: 0.3729 Acc: 0.8318 | Val Loss: 0.3923 Acc: 0.8152\n",
      "Epoch 019 | Train Loss: 0.3553 Acc: 0.8416 | Val Loss: 0.3743 Acc: 0.8267\n",
      "Epoch 020 | Train Loss: 0.3164 Acc: 0.8615 | Val Loss: 0.3588 Acc: 0.8285\n",
      "Epoch 021 | Train Loss: 0.3084 Acc: 0.8670 | Val Loss: 0.3128 Acc: 0.8671\n",
      "Epoch 022 | Train Loss: 0.2902 Acc: 0.8736 | Val Loss: 0.3689 Acc: 0.8418\n",
      "Epoch 023 | Train Loss: 0.2889 Acc: 0.8760 | Val Loss: 0.2880 Acc: 0.8756\n",
      "Epoch 024 | Train Loss: 0.2640 Acc: 0.8899 | Val Loss: 0.2633 Acc: 0.8871\n",
      "Epoch 025 | Train Loss: 0.2519 Acc: 0.8957 | Val Loss: 0.2719 Acc: 0.8871\n",
      "Epoch 026 | Train Loss: 0.2399 Acc: 0.8969 | Val Loss: 0.2502 Acc: 0.9004\n",
      "Epoch 027 | Train Loss: 0.2261 Acc: 0.9062 | Val Loss: 0.3064 Acc: 0.8635\n",
      "Epoch 028 | Train Loss: 0.2228 Acc: 0.9108 | Val Loss: 0.2572 Acc: 0.8931\n",
      "Epoch 029 | Train Loss: 0.2030 Acc: 0.9162 | Val Loss: 0.2295 Acc: 0.8998\n",
      "Epoch 030 | Train Loss: 0.1901 Acc: 0.9244 | Val Loss: 0.2417 Acc: 0.9034\n",
      "Epoch 031 | Train Loss: 0.1796 Acc: 0.9272 | Val Loss: 0.2226 Acc: 0.9118\n",
      "Epoch 032 | Train Loss: 0.1725 Acc: 0.9290 | Val Loss: 0.2358 Acc: 0.9040\n",
      "Epoch 033 | Train Loss: 0.1617 Acc: 0.9351 | Val Loss: 0.2334 Acc: 0.9046\n",
      "Epoch 034 | Train Loss: 0.1582 Acc: 0.9369 | Val Loss: 0.2221 Acc: 0.9046\n",
      "Epoch 035 | Train Loss: 0.1489 Acc: 0.9410 | Val Loss: 0.2100 Acc: 0.9215\n",
      "Epoch 036 | Train Loss: 0.1363 Acc: 0.9470 | Val Loss: 0.2091 Acc: 0.9161\n",
      "Epoch 037 | Train Loss: 0.1299 Acc: 0.9497 | Val Loss: 0.1975 Acc: 0.9275\n",
      "Epoch 038 | Train Loss: 0.1203 Acc: 0.9532 | Val Loss: 0.2038 Acc: 0.9173\n",
      "Epoch 039 | Train Loss: 0.1181 Acc: 0.9530 | Val Loss: 0.1797 Acc: 0.9300\n",
      "Epoch 040 | Train Loss: 0.1087 Acc: 0.9610 | Val Loss: 0.2202 Acc: 0.9251\n",
      "Epoch 041 | Train Loss: 0.1092 Acc: 0.9577 | Val Loss: 0.1987 Acc: 0.9227\n",
      "Epoch 042 | Train Loss: 0.1100 Acc: 0.9591 | Val Loss: 0.1827 Acc: 0.9342\n",
      "Epoch 043 | Train Loss: 0.1007 Acc: 0.9607 | Val Loss: 0.2059 Acc: 0.9245\n",
      "Epoch 044 | Train Loss: 0.0877 Acc: 0.9683 | Val Loss: 0.2208 Acc: 0.9251\n",
      "Epoch 045 | Train Loss: 0.0932 Acc: 0.9654 | Val Loss: 0.1735 Acc: 0.9378\n",
      "Epoch 046 | Train Loss: 0.0863 Acc: 0.9666 | Val Loss: 0.1779 Acc: 0.9324\n",
      "Epoch 047 | Train Loss: 0.0753 Acc: 0.9731 | Val Loss: 0.1712 Acc: 0.9366\n",
      "Epoch 048 | Train Loss: 0.0791 Acc: 0.9725 | Val Loss: 0.1710 Acc: 0.9342\n",
      "Epoch 049 | Train Loss: 0.0730 Acc: 0.9733 | Val Loss: 0.2178 Acc: 0.9300\n",
      "Epoch 050 | Train Loss: 0.0746 Acc: 0.9725 | Val Loss: 0.2281 Acc: 0.9251\n",
      "Epoch 051 | Train Loss: 0.0667 Acc: 0.9722 | Val Loss: 0.1829 Acc: 0.9366\n",
      "Epoch 052 | Train Loss: 0.0671 Acc: 0.9752 | Val Loss: 0.1726 Acc: 0.9360\n",
      "Epoch 053 | Train Loss: 0.0689 Acc: 0.9763 | Val Loss: 0.1747 Acc: 0.9408\n",
      "Epoch 054 | Train Loss: 0.0625 Acc: 0.9758 | Val Loss: 0.1815 Acc: 0.9312\n",
      "Epoch 055 | Train Loss: 0.0620 Acc: 0.9790 | Val Loss: 0.2189 Acc: 0.9281\n",
      "Epoch 056 | Train Loss: 0.0592 Acc: 0.9790 | Val Loss: 0.1702 Acc: 0.9450\n",
      "Epoch 057 | Train Loss: 0.0575 Acc: 0.9792 | Val Loss: 0.2126 Acc: 0.9348\n",
      "Epoch 058 | Train Loss: 0.0501 Acc: 0.9822 | Val Loss: 0.2046 Acc: 0.9354\n",
      "Epoch 059 | Train Loss: 0.0596 Acc: 0.9781 | Val Loss: 0.1811 Acc: 0.9360\n",
      "Epoch 060 | Train Loss: 0.0614 Acc: 0.9778 | Val Loss: 0.1832 Acc: 0.9426\n",
      "Epoch 001 | Train Loss: 0.6834 Acc: 0.5676 | Val Loss: 0.6788 Acc: 0.5797\n",
      "Epoch 002 | Train Loss: 0.6765 Acc: 0.5837 | Val Loss: 0.6717 Acc: 0.5906\n",
      "Epoch 003 | Train Loss: 0.6660 Acc: 0.6034 | Val Loss: 0.6652 Acc: 0.5972\n",
      "Epoch 004 | Train Loss: 0.6317 Acc: 0.6502 | Val Loss: 0.6216 Acc: 0.6643\n",
      "Epoch 005 | Train Loss: 0.5882 Acc: 0.7003 | Val Loss: 0.5901 Acc: 0.7023\n",
      "Epoch 006 | Train Loss: 0.5704 Acc: 0.7065 | Val Loss: 0.5619 Acc: 0.7132\n",
      "Epoch 007 | Train Loss: 0.5446 Acc: 0.7347 | Val Loss: 0.5675 Acc: 0.7023\n",
      "Epoch 008 | Train Loss: 0.5354 Acc: 0.7382 | Val Loss: 0.5341 Acc: 0.7307\n",
      "Epoch 009 | Train Loss: 0.5145 Acc: 0.7516 | Val Loss: 0.5155 Acc: 0.7440\n",
      "Epoch 010 | Train Loss: 0.4993 Acc: 0.7628 | Val Loss: 0.5101 Acc: 0.7446\n",
      "Epoch 011 | Train Loss: 0.4825 Acc: 0.7737 | Val Loss: 0.4792 Acc: 0.7705\n",
      "Epoch 012 | Train Loss: 0.4533 Acc: 0.7901 | Val Loss: 0.4723 Acc: 0.7808\n",
      "Epoch 013 | Train Loss: 0.4400 Acc: 0.7974 | Val Loss: 0.4222 Acc: 0.8128\n",
      "Epoch 014 | Train Loss: 0.4178 Acc: 0.8096 | Val Loss: 0.4159 Acc: 0.8062\n",
      "Epoch 015 | Train Loss: 0.3958 Acc: 0.8223 | Val Loss: 0.4030 Acc: 0.8182\n",
      "Epoch 016 | Train Loss: 0.3802 Acc: 0.8351 | Val Loss: 0.3623 Acc: 0.8345\n",
      "Epoch 017 | Train Loss: 0.3541 Acc: 0.8461 | Val Loss: 0.3626 Acc: 0.8364\n",
      "Epoch 018 | Train Loss: 0.3382 Acc: 0.8532 | Val Loss: 0.3049 Acc: 0.8714\n",
      "Epoch 019 | Train Loss: 0.3076 Acc: 0.8754 | Val Loss: 0.3608 Acc: 0.8388\n",
      "Epoch 020 | Train Loss: 0.2937 Acc: 0.8789 | Val Loss: 0.2851 Acc: 0.8726\n",
      "Epoch 021 | Train Loss: 0.2705 Acc: 0.8860 | Val Loss: 0.2945 Acc: 0.8732\n",
      "Epoch 022 | Train Loss: 0.2625 Acc: 0.8910 | Val Loss: 0.2784 Acc: 0.8816\n",
      "Epoch 023 | Train Loss: 0.2492 Acc: 0.8987 | Val Loss: 0.2766 Acc: 0.8829\n",
      "Epoch 024 | Train Loss: 0.2302 Acc: 0.9079 | Val Loss: 0.2285 Acc: 0.9058\n",
      "Epoch 025 | Train Loss: 0.2275 Acc: 0.9085 | Val Loss: 0.2271 Acc: 0.9100\n",
      "Epoch 026 | Train Loss: 0.2167 Acc: 0.9157 | Val Loss: 0.2272 Acc: 0.9058\n",
      "Epoch 027 | Train Loss: 0.2070 Acc: 0.9188 | Val Loss: 0.2204 Acc: 0.9143\n",
      "Epoch 028 | Train Loss: 0.2063 Acc: 0.9141 | Val Loss: 0.2298 Acc: 0.9082\n",
      "Epoch 029 | Train Loss: 0.1969 Acc: 0.9212 | Val Loss: 0.2032 Acc: 0.9191\n",
      "Epoch 030 | Train Loss: 0.1827 Acc: 0.9283 | Val Loss: 0.2173 Acc: 0.9149\n",
      "Epoch 031 | Train Loss: 0.1733 Acc: 0.9334 | Val Loss: 0.2254 Acc: 0.9149\n",
      "Epoch 032 | Train Loss: 0.1704 Acc: 0.9321 | Val Loss: 0.2283 Acc: 0.9106\n",
      "Epoch 033 | Train Loss: 0.1682 Acc: 0.9328 | Val Loss: 0.2139 Acc: 0.9076\n",
      "Epoch 034 | Train Loss: 0.1666 Acc: 0.9327 | Val Loss: 0.2021 Acc: 0.9221\n",
      "Epoch 035 | Train Loss: 0.1461 Acc: 0.9435 | Val Loss: 0.2205 Acc: 0.9136\n",
      "Epoch 036 | Train Loss: 0.1508 Acc: 0.9417 | Val Loss: 0.1770 Acc: 0.9300\n",
      "Epoch 037 | Train Loss: 0.1416 Acc: 0.9461 | Val Loss: 0.1766 Acc: 0.9354\n",
      "Epoch 038 | Train Loss: 0.1432 Acc: 0.9425 | Val Loss: 0.1946 Acc: 0.9263\n",
      "Epoch 039 | Train Loss: 0.1459 Acc: 0.9452 | Val Loss: 0.1655 Acc: 0.9330\n",
      "Epoch 040 | Train Loss: 0.1332 Acc: 0.9491 | Val Loss: 0.1714 Acc: 0.9281\n",
      "Epoch 041 | Train Loss: 0.1282 Acc: 0.9524 | Val Loss: 0.1803 Acc: 0.9324\n",
      "Epoch 042 | Train Loss: 0.1232 Acc: 0.9536 | Val Loss: 0.1807 Acc: 0.9257\n",
      "Epoch 043 | Train Loss: 0.1217 Acc: 0.9496 | Val Loss: 0.1894 Acc: 0.9209\n",
      "Epoch 044 | Train Loss: 0.1150 Acc: 0.9561 | Val Loss: 0.1925 Acc: 0.9281\n",
      "Epoch 045 | Train Loss: 0.1145 Acc: 0.9585 | Val Loss: 0.1691 Acc: 0.9312\n",
      "Epoch 046 | Train Loss: 0.1090 Acc: 0.9586 | Val Loss: 0.1799 Acc: 0.9263\n",
      "Epoch 047 | Train Loss: 0.1144 Acc: 0.9580 | Val Loss: 0.1604 Acc: 0.9348\n",
      "Epoch 048 | Train Loss: 0.1136 Acc: 0.9555 | Val Loss: 0.1737 Acc: 0.9306\n",
      "Epoch 049 | Train Loss: 0.1075 Acc: 0.9559 | Val Loss: 0.1500 Acc: 0.9354\n",
      "Epoch 050 | Train Loss: 0.1117 Acc: 0.9595 | Val Loss: 0.1598 Acc: 0.9372\n",
      "Epoch 051 | Train Loss: 0.0958 Acc: 0.9638 | Val Loss: 0.1587 Acc: 0.9378\n",
      "Epoch 052 | Train Loss: 0.0939 Acc: 0.9653 | Val Loss: 0.1616 Acc: 0.9426\n",
      "Epoch 053 | Train Loss: 0.1023 Acc: 0.9633 | Val Loss: 0.1836 Acc: 0.9348\n",
      "Epoch 054 | Train Loss: 0.1026 Acc: 0.9618 | Val Loss: 0.1786 Acc: 0.9336\n",
      "Epoch 055 | Train Loss: 0.0973 Acc: 0.9648 | Val Loss: 0.1577 Acc: 0.9372\n",
      "Epoch 056 | Train Loss: 0.0972 Acc: 0.9633 | Val Loss: 0.1585 Acc: 0.9378\n",
      "Epoch 057 | Train Loss: 0.0898 Acc: 0.9657 | Val Loss: 0.1462 Acc: 0.9384\n",
      "Epoch 058 | Train Loss: 0.0923 Acc: 0.9662 | Val Loss: 0.1635 Acc: 0.9426\n",
      "Epoch 059 | Train Loss: 0.0868 Acc: 0.9671 | Val Loss: 0.1615 Acc: 0.9378\n",
      "Epoch 060 | Train Loss: 0.0825 Acc: 0.9681 | Val Loss: 0.1917 Acc: 0.9354\n",
      "Epoch 001 | Train Loss: 0.6848 Acc: 0.5568 | Val Loss: 0.6733 Acc: 0.5755\n",
      "Epoch 002 | Train Loss: 0.6453 Acc: 0.6378 | Val Loss: 0.6215 Acc: 0.6854\n",
      "Epoch 003 | Train Loss: 0.6050 Acc: 0.6887 | Val Loss: 0.6025 Acc: 0.6806\n",
      "Epoch 004 | Train Loss: 0.5725 Acc: 0.7116 | Val Loss: 0.5704 Acc: 0.7107\n",
      "Epoch 005 | Train Loss: 0.5532 Acc: 0.7260 | Val Loss: 0.5618 Acc: 0.7337\n",
      "Epoch 006 | Train Loss: 0.5389 Acc: 0.7401 | Val Loss: 0.5280 Acc: 0.7464\n",
      "Epoch 007 | Train Loss: 0.5259 Acc: 0.7465 | Val Loss: 0.5215 Acc: 0.7421\n",
      "Epoch 008 | Train Loss: 0.5062 Acc: 0.7589 | Val Loss: 0.5033 Acc: 0.7494\n",
      "Epoch 009 | Train Loss: 0.4769 Acc: 0.7755 | Val Loss: 0.4618 Acc: 0.7880\n",
      "Epoch 010 | Train Loss: 0.4521 Acc: 0.7931 | Val Loss: 0.4384 Acc: 0.7929\n",
      "Epoch 011 | Train Loss: 0.4293 Acc: 0.8058 | Val Loss: 0.3874 Acc: 0.8200\n",
      "Epoch 012 | Train Loss: 0.4049 Acc: 0.8191 | Val Loss: 0.3730 Acc: 0.8394\n",
      "Epoch 013 | Train Loss: 0.3797 Acc: 0.8330 | Val Loss: 0.3664 Acc: 0.8376\n",
      "Epoch 014 | Train Loss: 0.3665 Acc: 0.8433 | Val Loss: 0.3629 Acc: 0.8484\n",
      "Epoch 015 | Train Loss: 0.3330 Acc: 0.8599 | Val Loss: 0.3190 Acc: 0.8611\n",
      "Epoch 016 | Train Loss: 0.3151 Acc: 0.8676 | Val Loss: 0.3243 Acc: 0.8623\n",
      "Epoch 017 | Train Loss: 0.3123 Acc: 0.8676 | Val Loss: 0.3277 Acc: 0.8665\n",
      "Epoch 018 | Train Loss: 0.2910 Acc: 0.8777 | Val Loss: 0.3195 Acc: 0.8593\n",
      "Epoch 019 | Train Loss: 0.2764 Acc: 0.8874 | Val Loss: 0.2838 Acc: 0.8798\n",
      "Epoch 020 | Train Loss: 0.2790 Acc: 0.8845 | Val Loss: 0.2887 Acc: 0.8750\n",
      "Epoch 021 | Train Loss: 0.2527 Acc: 0.8955 | Val Loss: 0.2696 Acc: 0.8943\n",
      "Epoch 022 | Train Loss: 0.2501 Acc: 0.9022 | Val Loss: 0.2721 Acc: 0.8889\n",
      "Epoch 023 | Train Loss: 0.2460 Acc: 0.8985 | Val Loss: 0.2271 Acc: 0.9028\n",
      "Epoch 024 | Train Loss: 0.2374 Acc: 0.9034 | Val Loss: 0.2379 Acc: 0.9076\n",
      "Epoch 025 | Train Loss: 0.2195 Acc: 0.9121 | Val Loss: 0.2427 Acc: 0.9088\n",
      "Epoch 026 | Train Loss: 0.2203 Acc: 0.9154 | Val Loss: 0.2277 Acc: 0.9094\n",
      "Epoch 027 | Train Loss: 0.2116 Acc: 0.9162 | Val Loss: 0.2305 Acc: 0.9100\n",
      "Epoch 028 | Train Loss: 0.2094 Acc: 0.9183 | Val Loss: 0.2321 Acc: 0.9106\n",
      "Epoch 029 | Train Loss: 0.2081 Acc: 0.9195 | Val Loss: 0.2229 Acc: 0.9143\n",
      "Epoch 030 | Train Loss: 0.1935 Acc: 0.9241 | Val Loss: 0.2315 Acc: 0.9082\n",
      "Epoch 031 | Train Loss: 0.1796 Acc: 0.9331 | Val Loss: 0.2343 Acc: 0.9124\n",
      "Epoch 032 | Train Loss: 0.1944 Acc: 0.9275 | Val Loss: 0.2237 Acc: 0.9112\n",
      "Epoch 033 | Train Loss: 0.1863 Acc: 0.9259 | Val Loss: 0.1985 Acc: 0.9215\n",
      "Epoch 034 | Train Loss: 0.1747 Acc: 0.9354 | Val Loss: 0.2288 Acc: 0.9179\n",
      "Epoch 035 | Train Loss: 0.1762 Acc: 0.9307 | Val Loss: 0.1833 Acc: 0.9300\n",
      "Epoch 036 | Train Loss: 0.1626 Acc: 0.9364 | Val Loss: 0.2128 Acc: 0.9161\n",
      "Epoch 037 | Train Loss: 0.1658 Acc: 0.9325 | Val Loss: 0.1806 Acc: 0.9275\n",
      "Epoch 038 | Train Loss: 0.1586 Acc: 0.9423 | Val Loss: 0.1747 Acc: 0.9372\n",
      "Epoch 039 | Train Loss: 0.1595 Acc: 0.9388 | Val Loss: 0.1722 Acc: 0.9342\n",
      "Epoch 040 | Train Loss: 0.1518 Acc: 0.9414 | Val Loss: 0.2044 Acc: 0.9287\n",
      "Epoch 041 | Train Loss: 0.1488 Acc: 0.9426 | Val Loss: 0.1689 Acc: 0.9360\n",
      "Epoch 042 | Train Loss: 0.1465 Acc: 0.9438 | Val Loss: 0.1907 Acc: 0.9312\n",
      "Epoch 043 | Train Loss: 0.1559 Acc: 0.9447 | Val Loss: 0.1763 Acc: 0.9263\n",
      "Epoch 044 | Train Loss: 0.1424 Acc: 0.9458 | Val Loss: 0.2093 Acc: 0.9185\n",
      "Epoch 045 | Train Loss: 0.1392 Acc: 0.9473 | Val Loss: 0.1683 Acc: 0.9336\n",
      "Epoch 046 | Train Loss: 0.1340 Acc: 0.9476 | Val Loss: 0.1652 Acc: 0.9384\n",
      "Epoch 047 | Train Loss: 0.1308 Acc: 0.9511 | Val Loss: 0.1633 Acc: 0.9348\n",
      "Epoch 048 | Train Loss: 0.1212 Acc: 0.9512 | Val Loss: 0.1421 Acc: 0.9420\n",
      "Epoch 049 | Train Loss: 0.1244 Acc: 0.9524 | Val Loss: 0.1634 Acc: 0.9396\n",
      "Epoch 050 | Train Loss: 0.1350 Acc: 0.9493 | Val Loss: 0.1983 Acc: 0.9197\n",
      "Epoch 051 | Train Loss: 0.1208 Acc: 0.9543 | Val Loss: 0.1620 Acc: 0.9426\n",
      "Epoch 052 | Train Loss: 0.1177 Acc: 0.9552 | Val Loss: 0.1763 Acc: 0.9366\n",
      "Epoch 053 | Train Loss: 0.1373 Acc: 0.9482 | Val Loss: 0.1461 Acc: 0.9444\n",
      "Epoch 054 | Train Loss: 0.1156 Acc: 0.9561 | Val Loss: 0.1665 Acc: 0.9402\n",
      "Epoch 055 | Train Loss: 0.1174 Acc: 0.9561 | Val Loss: 0.1628 Acc: 0.9499\n",
      "Epoch 056 | Train Loss: 0.1263 Acc: 0.9521 | Val Loss: 0.1698 Acc: 0.9396\n",
      "Epoch 057 | Train Loss: 0.1260 Acc: 0.9552 | Val Loss: 0.1560 Acc: 0.9444\n",
      "Epoch 058 | Train Loss: 0.1160 Acc: 0.9567 | Val Loss: 0.1563 Acc: 0.9469\n",
      "Early stopping triggered.\n",
      "Epoch 001 | Train Loss: 0.6829 Acc: 0.5744 | Val Loss: 0.6779 Acc: 0.5827\n",
      "Epoch 002 | Train Loss: 0.6765 Acc: 0.5920 | Val Loss: 0.6733 Acc: 0.5954\n",
      "Epoch 003 | Train Loss: 0.6759 Acc: 0.5899 | Val Loss: 0.6736 Acc: 0.5930\n",
      "Epoch 004 | Train Loss: 0.6746 Acc: 0.5925 | Val Loss: 0.6729 Acc: 0.5924\n",
      "Epoch 005 | Train Loss: 0.6710 Acc: 0.5958 | Val Loss: 0.6681 Acc: 0.5978\n",
      "Epoch 006 | Train Loss: 0.6596 Acc: 0.6053 | Val Loss: 0.6490 Acc: 0.5978\n",
      "Epoch 007 | Train Loss: 0.6307 Acc: 0.6532 | Val Loss: 0.6187 Acc: 0.6661\n",
      "Epoch 008 | Train Loss: 0.5949 Acc: 0.6959 | Val Loss: 0.5855 Acc: 0.6884\n",
      "Epoch 009 | Train Loss: 0.5676 Acc: 0.7193 | Val Loss: 0.5438 Acc: 0.7258\n",
      "Epoch 010 | Train Loss: 0.5436 Acc: 0.7285 | Val Loss: 0.5438 Acc: 0.7283\n",
      "Epoch 011 | Train Loss: 0.5310 Acc: 0.7412 | Val Loss: 0.5266 Acc: 0.7361\n",
      "Epoch 012 | Train Loss: 0.5206 Acc: 0.7454 | Val Loss: 0.5122 Acc: 0.7421\n",
      "Epoch 013 | Train Loss: 0.5028 Acc: 0.7636 | Val Loss: 0.5127 Acc: 0.7518\n",
      "Epoch 014 | Train Loss: 0.4888 Acc: 0.7669 | Val Loss: 0.4864 Acc: 0.7591\n",
      "Epoch 015 | Train Loss: 0.4767 Acc: 0.7771 | Val Loss: 0.4725 Acc: 0.7717\n",
      "Epoch 016 | Train Loss: 0.4611 Acc: 0.7799 | Val Loss: 0.4524 Acc: 0.7868\n",
      "Epoch 017 | Train Loss: 0.4503 Acc: 0.7918 | Val Loss: 0.4363 Acc: 0.7923\n",
      "Epoch 018 | Train Loss: 0.4398 Acc: 0.7948 | Val Loss: 0.4294 Acc: 0.8086\n",
      "Epoch 019 | Train Loss: 0.4136 Acc: 0.8131 | Val Loss: 0.4110 Acc: 0.8043\n",
      "Epoch 020 | Train Loss: 0.4162 Acc: 0.8040 | Val Loss: 0.4053 Acc: 0.8146\n",
      "Epoch 021 | Train Loss: 0.3944 Acc: 0.8229 | Val Loss: 0.3738 Acc: 0.8315\n",
      "Epoch 022 | Train Loss: 0.3674 Acc: 0.8350 | Val Loss: 0.3568 Acc: 0.8357\n",
      "Epoch 023 | Train Loss: 0.3541 Acc: 0.8400 | Val Loss: 0.3580 Acc: 0.8412\n",
      "Epoch 024 | Train Loss: 0.3424 Acc: 0.8477 | Val Loss: 0.3388 Acc: 0.8400\n",
      "Epoch 025 | Train Loss: 0.3298 Acc: 0.8551 | Val Loss: 0.3301 Acc: 0.8569\n",
      "Epoch 026 | Train Loss: 0.3184 Acc: 0.8680 | Val Loss: 0.3055 Acc: 0.8653\n",
      "Epoch 027 | Train Loss: 0.3085 Acc: 0.8688 | Val Loss: 0.3137 Acc: 0.8551\n",
      "Epoch 028 | Train Loss: 0.2935 Acc: 0.8774 | Val Loss: 0.2747 Acc: 0.8877\n",
      "Epoch 029 | Train Loss: 0.2820 Acc: 0.8815 | Val Loss: 0.2711 Acc: 0.8889\n",
      "Epoch 030 | Train Loss: 0.2696 Acc: 0.8887 | Val Loss: 0.2785 Acc: 0.8708\n",
      "Epoch 031 | Train Loss: 0.2514 Acc: 0.8988 | Val Loss: 0.2625 Acc: 0.8907\n",
      "Epoch 032 | Train Loss: 0.2430 Acc: 0.8987 | Val Loss: 0.3322 Acc: 0.8490\n",
      "Epoch 033 | Train Loss: 0.2415 Acc: 0.8979 | Val Loss: 0.2464 Acc: 0.8907\n",
      "Epoch 034 | Train Loss: 0.2414 Acc: 0.9017 | Val Loss: 0.2301 Acc: 0.9034\n",
      "Epoch 035 | Train Loss: 0.2212 Acc: 0.9111 | Val Loss: 0.2299 Acc: 0.8979\n",
      "Epoch 036 | Train Loss: 0.2151 Acc: 0.9150 | Val Loss: 0.2148 Acc: 0.9124\n",
      "Epoch 037 | Train Loss: 0.2019 Acc: 0.9203 | Val Loss: 0.2182 Acc: 0.9112\n",
      "Epoch 038 | Train Loss: 0.1881 Acc: 0.9215 | Val Loss: 0.2113 Acc: 0.9124\n",
      "Epoch 039 | Train Loss: 0.1982 Acc: 0.9230 | Val Loss: 0.2167 Acc: 0.9106\n",
      "Epoch 040 | Train Loss: 0.1978 Acc: 0.9231 | Val Loss: 0.1905 Acc: 0.9245\n",
      "Epoch 041 | Train Loss: 0.1867 Acc: 0.9275 | Val Loss: 0.2060 Acc: 0.9155\n",
      "Epoch 042 | Train Loss: 0.1851 Acc: 0.9286 | Val Loss: 0.1986 Acc: 0.9215\n",
      "Epoch 043 | Train Loss: 0.1685 Acc: 0.9364 | Val Loss: 0.1793 Acc: 0.9312\n",
      "Epoch 044 | Train Loss: 0.1683 Acc: 0.9321 | Val Loss: 0.2587 Acc: 0.8967\n",
      "Epoch 045 | Train Loss: 0.1707 Acc: 0.9346 | Val Loss: 0.1933 Acc: 0.9233\n",
      "Epoch 046 | Train Loss: 0.1512 Acc: 0.9417 | Val Loss: 0.2351 Acc: 0.9070\n",
      "Epoch 047 | Train Loss: 0.1732 Acc: 0.9321 | Val Loss: 0.1738 Acc: 0.9251\n",
      "Epoch 048 | Train Loss: 0.1469 Acc: 0.9425 | Val Loss: 0.1652 Acc: 0.9312\n",
      "Epoch 049 | Train Loss: 0.1479 Acc: 0.9419 | Val Loss: 0.1844 Acc: 0.9263\n",
      "Epoch 050 | Train Loss: 0.1373 Acc: 0.9478 | Val Loss: 0.1701 Acc: 0.9342\n",
      "Epoch 051 | Train Loss: 0.1303 Acc: 0.9518 | Val Loss: 0.1665 Acc: 0.9360\n",
      "Epoch 052 | Train Loss: 0.1411 Acc: 0.9453 | Val Loss: 0.1830 Acc: 0.9293\n",
      "Epoch 053 | Train Loss: 0.1480 Acc: 0.9437 | Val Loss: 0.1674 Acc: 0.9366\n",
      "Epoch 054 | Train Loss: 0.1312 Acc: 0.9505 | Val Loss: 0.1642 Acc: 0.9408\n",
      "Epoch 055 | Train Loss: 0.1280 Acc: 0.9543 | Val Loss: 0.1687 Acc: 0.9360\n",
      "Epoch 056 | Train Loss: 0.1217 Acc: 0.9558 | Val Loss: 0.1531 Acc: 0.9438\n",
      "Epoch 057 | Train Loss: 0.1123 Acc: 0.9565 | Val Loss: 0.1485 Acc: 0.9438\n",
      "Epoch 058 | Train Loss: 0.1236 Acc: 0.9506 | Val Loss: 0.1687 Acc: 0.9384\n",
      "Epoch 059 | Train Loss: 0.1206 Acc: 0.9547 | Val Loss: 0.1578 Acc: 0.9420\n",
      "Epoch 060 | Train Loss: 0.1144 Acc: 0.9585 | Val Loss: 0.1629 Acc: 0.9444\n",
      "Epoch 001 | Train Loss: 0.6805 Acc: 0.5828 | Val Loss: 0.6776 Acc: 0.5912\n",
      "Epoch 002 | Train Loss: 0.6731 Acc: 0.5935 | Val Loss: 0.6631 Acc: 0.5978\n",
      "Epoch 003 | Train Loss: 0.6364 Acc: 0.6545 | Val Loss: 0.6181 Acc: 0.6739\n",
      "Epoch 004 | Train Loss: 0.5860 Acc: 0.7077 | Val Loss: 0.5798 Acc: 0.7053\n",
      "Epoch 005 | Train Loss: 0.5726 Acc: 0.7146 | Val Loss: 0.5758 Acc: 0.7035\n",
      "Epoch 006 | Train Loss: 0.5530 Acc: 0.7246 | Val Loss: 0.5506 Acc: 0.7289\n",
      "Epoch 007 | Train Loss: 0.5450 Acc: 0.7385 | Val Loss: 0.5374 Acc: 0.7355\n",
      "Epoch 008 | Train Loss: 0.5274 Acc: 0.7430 | Val Loss: 0.5284 Acc: 0.7307\n",
      "Epoch 009 | Train Loss: 0.5181 Acc: 0.7528 | Val Loss: 0.5108 Acc: 0.7506\n",
      "Epoch 010 | Train Loss: 0.5164 Acc: 0.7554 | Val Loss: 0.4942 Acc: 0.7627\n",
      "Epoch 011 | Train Loss: 0.4898 Acc: 0.7706 | Val Loss: 0.4925 Acc: 0.7579\n",
      "Epoch 012 | Train Loss: 0.4832 Acc: 0.7738 | Val Loss: 0.4672 Acc: 0.7778\n",
      "Epoch 013 | Train Loss: 0.4608 Acc: 0.7892 | Val Loss: 0.4423 Acc: 0.7862\n",
      "Epoch 014 | Train Loss: 0.4522 Acc: 0.7904 | Val Loss: 0.4297 Acc: 0.7989\n",
      "Epoch 015 | Train Loss: 0.4353 Acc: 0.8018 | Val Loss: 0.4011 Acc: 0.8140\n",
      "Epoch 016 | Train Loss: 0.4248 Acc: 0.8055 | Val Loss: 0.3633 Acc: 0.8400\n",
      "Epoch 017 | Train Loss: 0.4088 Acc: 0.8134 | Val Loss: 0.3596 Acc: 0.8388\n",
      "Epoch 018 | Train Loss: 0.3876 Acc: 0.8277 | Val Loss: 0.3440 Acc: 0.8436\n",
      "Epoch 019 | Train Loss: 0.3699 Acc: 0.8424 | Val Loss: 0.3862 Acc: 0.8225\n",
      "Epoch 020 | Train Loss: 0.3662 Acc: 0.8406 | Val Loss: 0.3323 Acc: 0.8502\n",
      "Epoch 021 | Train Loss: 0.3495 Acc: 0.8477 | Val Loss: 0.3166 Acc: 0.8659\n",
      "Epoch 022 | Train Loss: 0.3266 Acc: 0.8647 | Val Loss: 0.2837 Acc: 0.8816\n",
      "Epoch 023 | Train Loss: 0.3299 Acc: 0.8600 | Val Loss: 0.3147 Acc: 0.8804\n",
      "Epoch 024 | Train Loss: 0.3143 Acc: 0.8692 | Val Loss: 0.2728 Acc: 0.8925\n",
      "Epoch 025 | Train Loss: 0.3217 Acc: 0.8638 | Val Loss: 0.2829 Acc: 0.8841\n",
      "Epoch 026 | Train Loss: 0.3003 Acc: 0.8742 | Val Loss: 0.2854 Acc: 0.8726\n",
      "Epoch 027 | Train Loss: 0.3014 Acc: 0.8708 | Val Loss: 0.2577 Acc: 0.8949\n",
      "Epoch 028 | Train Loss: 0.2962 Acc: 0.8788 | Val Loss: 0.2666 Acc: 0.8859\n",
      "Epoch 029 | Train Loss: 0.2771 Acc: 0.8851 | Val Loss: 0.2541 Acc: 0.8877\n",
      "Epoch 030 | Train Loss: 0.2786 Acc: 0.8849 | Val Loss: 0.2453 Acc: 0.9004\n",
      "Epoch 031 | Train Loss: 0.2646 Acc: 0.8914 | Val Loss: 0.2431 Acc: 0.8998\n",
      "Epoch 032 | Train Loss: 0.2555 Acc: 0.8945 | Val Loss: 0.2258 Acc: 0.9106\n",
      "Epoch 033 | Train Loss: 0.2438 Acc: 0.9016 | Val Loss: 0.2406 Acc: 0.9070\n",
      "Epoch 034 | Train Loss: 0.2541 Acc: 0.8949 | Val Loss: 0.2814 Acc: 0.8798\n",
      "Epoch 035 | Train Loss: 0.2584 Acc: 0.8978 | Val Loss: 0.2660 Acc: 0.8835\n",
      "Epoch 036 | Train Loss: 0.2504 Acc: 0.8981 | Val Loss: 0.2266 Acc: 0.9130\n",
      "Epoch 037 | Train Loss: 0.2349 Acc: 0.9023 | Val Loss: 0.2167 Acc: 0.9149\n",
      "Epoch 038 | Train Loss: 0.2287 Acc: 0.9099 | Val Loss: 0.2017 Acc: 0.9275\n",
      "Epoch 039 | Train Loss: 0.2326 Acc: 0.9053 | Val Loss: 0.2090 Acc: 0.9209\n",
      "Epoch 040 | Train Loss: 0.2156 Acc: 0.9124 | Val Loss: 0.2362 Acc: 0.9028\n",
      "Epoch 041 | Train Loss: 0.2181 Acc: 0.9130 | Val Loss: 0.2025 Acc: 0.9306\n",
      "Epoch 042 | Train Loss: 0.2149 Acc: 0.9142 | Val Loss: 0.2148 Acc: 0.9106\n",
      "Epoch 043 | Train Loss: 0.2165 Acc: 0.9133 | Val Loss: 0.1954 Acc: 0.9263\n",
      "Epoch 044 | Train Loss: 0.2041 Acc: 0.9191 | Val Loss: 0.1999 Acc: 0.9300\n",
      "Epoch 045 | Train Loss: 0.2123 Acc: 0.9156 | Val Loss: 0.2326 Acc: 0.8998\n",
      "Epoch 046 | Train Loss: 0.2070 Acc: 0.9176 | Val Loss: 0.2001 Acc: 0.9185\n",
      "Epoch 047 | Train Loss: 0.2061 Acc: 0.9206 | Val Loss: 0.1832 Acc: 0.9318\n",
      "Epoch 048 | Train Loss: 0.1881 Acc: 0.9251 | Val Loss: 0.1831 Acc: 0.9300\n",
      "Epoch 049 | Train Loss: 0.1950 Acc: 0.9221 | Val Loss: 0.1695 Acc: 0.9354\n",
      "Epoch 050 | Train Loss: 0.1969 Acc: 0.9206 | Val Loss: 0.1943 Acc: 0.9227\n",
      "Epoch 051 | Train Loss: 0.1970 Acc: 0.9224 | Val Loss: 0.1899 Acc: 0.9287\n",
      "Epoch 052 | Train Loss: 0.1990 Acc: 0.9228 | Val Loss: 0.1719 Acc: 0.9354\n",
      "Epoch 053 | Train Loss: 0.1924 Acc: 0.9289 | Val Loss: 0.1704 Acc: 0.9348\n",
      "Epoch 054 | Train Loss: 0.1817 Acc: 0.9345 | Val Loss: 0.1668 Acc: 0.9384\n",
      "Epoch 055 | Train Loss: 0.1823 Acc: 0.9287 | Val Loss: 0.1727 Acc: 0.9378\n",
      "Epoch 056 | Train Loss: 0.1960 Acc: 0.9263 | Val Loss: 0.1808 Acc: 0.9354\n",
      "Epoch 057 | Train Loss: 0.1909 Acc: 0.9299 | Val Loss: 0.1757 Acc: 0.9330\n",
      "Epoch 058 | Train Loss: 0.1679 Acc: 0.9343 | Val Loss: 0.1860 Acc: 0.9354\n",
      "Epoch 059 | Train Loss: 0.1800 Acc: 0.9290 | Val Loss: 0.1758 Acc: 0.9330\n",
      "Epoch 060 | Train Loss: 0.1658 Acc: 0.9366 | Val Loss: 0.1922 Acc: 0.9269\n",
      "Iteration 9/40 | Best Val Loss: 0.1259 | Iter Time: 245.49s | Total Time: 46.03 min\n",
      "Epoch 001 | Train Loss: 0.6752 Acc: 0.5819 | Val Loss: 0.6797 Acc: 0.5779\n",
      "Epoch 002 | Train Loss: 0.6683 Acc: 0.5964 | Val Loss: 0.6581 Acc: 0.6069\n",
      "Epoch 003 | Train Loss: 0.6446 Acc: 0.6369 | Val Loss: 0.6254 Acc: 0.6498\n",
      "Epoch 004 | Train Loss: 0.6093 Acc: 0.6853 | Val Loss: 0.5970 Acc: 0.6950\n",
      "Epoch 005 | Train Loss: 0.5764 Acc: 0.7112 | Val Loss: 0.5787 Acc: 0.7065\n",
      "Epoch 006 | Train Loss: 0.5601 Acc: 0.7225 | Val Loss: 0.5677 Acc: 0.7077\n",
      "Epoch 007 | Train Loss: 0.5422 Acc: 0.7337 | Val Loss: 0.5558 Acc: 0.7107\n",
      "Epoch 008 | Train Loss: 0.5275 Acc: 0.7414 | Val Loss: 0.5405 Acc: 0.7246\n",
      "Epoch 009 | Train Loss: 0.5205 Acc: 0.7522 | Val Loss: 0.5069 Acc: 0.7560\n",
      "Epoch 010 | Train Loss: 0.4999 Acc: 0.7646 | Val Loss: 0.5006 Acc: 0.7488\n",
      "Epoch 011 | Train Loss: 0.4897 Acc: 0.7657 | Val Loss: 0.5245 Acc: 0.7343\n",
      "Epoch 012 | Train Loss: 0.4701 Acc: 0.7759 | Val Loss: 0.4546 Acc: 0.7862\n",
      "Epoch 013 | Train Loss: 0.4516 Acc: 0.7886 | Val Loss: 0.4456 Acc: 0.7838\n",
      "Epoch 014 | Train Loss: 0.4369 Acc: 0.7960 | Val Loss: 0.4375 Acc: 0.7905\n",
      "Epoch 015 | Train Loss: 0.4187 Acc: 0.8084 | Val Loss: 0.4233 Acc: 0.7989\n",
      "Epoch 016 | Train Loss: 0.4076 Acc: 0.8129 | Val Loss: 0.3956 Acc: 0.8182\n",
      "Epoch 017 | Train Loss: 0.3847 Acc: 0.8252 | Val Loss: 0.3664 Acc: 0.8333\n",
      "Epoch 018 | Train Loss: 0.3627 Acc: 0.8359 | Val Loss: 0.3583 Acc: 0.8303\n",
      "Epoch 019 | Train Loss: 0.3457 Acc: 0.8433 | Val Loss: 0.3902 Acc: 0.8164\n",
      "Epoch 020 | Train Loss: 0.3393 Acc: 0.8499 | Val Loss: 0.3409 Acc: 0.8490\n",
      "Epoch 021 | Train Loss: 0.3137 Acc: 0.8567 | Val Loss: 0.3091 Acc: 0.8617\n",
      "Epoch 022 | Train Loss: 0.3046 Acc: 0.8659 | Val Loss: 0.3177 Acc: 0.8617\n",
      "Epoch 023 | Train Loss: 0.2981 Acc: 0.8705 | Val Loss: 0.3196 Acc: 0.8539\n",
      "Epoch 024 | Train Loss: 0.2848 Acc: 0.8771 | Val Loss: 0.3042 Acc: 0.8671\n",
      "Epoch 025 | Train Loss: 0.2682 Acc: 0.8878 | Val Loss: 0.2585 Acc: 0.8847\n",
      "Epoch 026 | Train Loss: 0.2486 Acc: 0.8981 | Val Loss: 0.2666 Acc: 0.8816\n",
      "Epoch 027 | Train Loss: 0.2354 Acc: 0.9016 | Val Loss: 0.2315 Acc: 0.9076\n",
      "Epoch 028 | Train Loss: 0.2271 Acc: 0.9085 | Val Loss: 0.2284 Acc: 0.9058\n",
      "Epoch 029 | Train Loss: 0.2211 Acc: 0.9065 | Val Loss: 0.2587 Acc: 0.8798\n",
      "Epoch 030 | Train Loss: 0.2140 Acc: 0.9156 | Val Loss: 0.2399 Acc: 0.8919\n",
      "Epoch 031 | Train Loss: 0.2011 Acc: 0.9204 | Val Loss: 0.2273 Acc: 0.9088\n",
      "Epoch 032 | Train Loss: 0.1902 Acc: 0.9260 | Val Loss: 0.2638 Acc: 0.8973\n",
      "Epoch 033 | Train Loss: 0.1942 Acc: 0.9244 | Val Loss: 0.2236 Acc: 0.9112\n",
      "Epoch 034 | Train Loss: 0.1776 Acc: 0.9283 | Val Loss: 0.2050 Acc: 0.9263\n",
      "Epoch 035 | Train Loss: 0.1741 Acc: 0.9342 | Val Loss: 0.1899 Acc: 0.9227\n",
      "Epoch 036 | Train Loss: 0.1559 Acc: 0.9405 | Val Loss: 0.1967 Acc: 0.9173\n",
      "Epoch 037 | Train Loss: 0.1648 Acc: 0.9328 | Val Loss: 0.2142 Acc: 0.9179\n",
      "Epoch 038 | Train Loss: 0.1496 Acc: 0.9393 | Val Loss: 0.1977 Acc: 0.9233\n",
      "Epoch 039 | Train Loss: 0.1540 Acc: 0.9407 | Val Loss: 0.1922 Acc: 0.9209\n",
      "Epoch 040 | Train Loss: 0.1417 Acc: 0.9465 | Val Loss: 0.1870 Acc: 0.9287\n",
      "Epoch 041 | Train Loss: 0.1366 Acc: 0.9484 | Val Loss: 0.1817 Acc: 0.9275\n",
      "Epoch 042 | Train Loss: 0.1462 Acc: 0.9419 | Val Loss: 0.1840 Acc: 0.9312\n",
      "Epoch 043 | Train Loss: 0.1330 Acc: 0.9494 | Val Loss: 0.1978 Acc: 0.9281\n",
      "Epoch 044 | Train Loss: 0.1168 Acc: 0.9549 | Val Loss: 0.1720 Acc: 0.9318\n",
      "Epoch 045 | Train Loss: 0.1220 Acc: 0.9552 | Val Loss: 0.1824 Acc: 0.9360\n",
      "Epoch 046 | Train Loss: 0.1204 Acc: 0.9565 | Val Loss: 0.1965 Acc: 0.9245\n",
      "Epoch 047 | Train Loss: 0.1162 Acc: 0.9555 | Val Loss: 0.1706 Acc: 0.9372\n",
      "Epoch 048 | Train Loss: 0.1146 Acc: 0.9559 | Val Loss: 0.2456 Acc: 0.9185\n",
      "Epoch 049 | Train Loss: 0.1137 Acc: 0.9574 | Val Loss: 0.1619 Acc: 0.9384\n",
      "Epoch 050 | Train Loss: 0.1008 Acc: 0.9638 | Val Loss: 0.1766 Acc: 0.9378\n",
      "Epoch 051 | Train Loss: 0.0964 Acc: 0.9635 | Val Loss: 0.2168 Acc: 0.9239\n",
      "Epoch 052 | Train Loss: 0.1015 Acc: 0.9635 | Val Loss: 0.1569 Acc: 0.9444\n",
      "Epoch 053 | Train Loss: 0.0938 Acc: 0.9651 | Val Loss: 0.1818 Acc: 0.9324\n",
      "Epoch 054 | Train Loss: 0.0950 Acc: 0.9648 | Val Loss: 0.1622 Acc: 0.9384\n",
      "Epoch 055 | Train Loss: 0.0962 Acc: 0.9632 | Val Loss: 0.1853 Acc: 0.9336\n",
      "Epoch 056 | Train Loss: 0.0877 Acc: 0.9674 | Val Loss: 0.2147 Acc: 0.9251\n",
      "Epoch 057 | Train Loss: 0.0811 Acc: 0.9690 | Val Loss: 0.1987 Acc: 0.9366\n",
      "Epoch 058 | Train Loss: 0.0914 Acc: 0.9653 | Val Loss: 0.1778 Acc: 0.9372\n",
      "Epoch 059 | Train Loss: 0.0907 Acc: 0.9641 | Val Loss: 0.1563 Acc: 0.9444\n",
      "Epoch 060 | Train Loss: 0.0832 Acc: 0.9678 | Val Loss: 0.1909 Acc: 0.9342\n",
      "Epoch 001 | Train Loss: 0.6798 Acc: 0.5774 | Val Loss: 0.6700 Acc: 0.5900\n",
      "Epoch 002 | Train Loss: 0.6818 Acc: 0.5760 | Val Loss: 0.6728 Acc: 0.5966\n",
      "Epoch 003 | Train Loss: 0.6672 Acc: 0.6006 | Val Loss: 0.6433 Acc: 0.6274\n",
      "Epoch 004 | Train Loss: 0.6336 Acc: 0.6521 | Val Loss: 0.6145 Acc: 0.6697\n",
      "Epoch 005 | Train Loss: 0.5831 Acc: 0.7059 | Val Loss: 0.5677 Acc: 0.7132\n",
      "Epoch 006 | Train Loss: 0.5646 Acc: 0.7181 | Val Loss: 0.5675 Acc: 0.7144\n",
      "Epoch 007 | Train Loss: 0.5386 Acc: 0.7361 | Val Loss: 0.5477 Acc: 0.7222\n",
      "Epoch 008 | Train Loss: 0.5303 Acc: 0.7420 | Val Loss: 0.5268 Acc: 0.7313\n",
      "Epoch 009 | Train Loss: 0.5098 Acc: 0.7482 | Val Loss: 0.5129 Acc: 0.7536\n",
      "Epoch 010 | Train Loss: 0.4799 Acc: 0.7731 | Val Loss: 0.5007 Acc: 0.7536\n",
      "Epoch 011 | Train Loss: 0.4670 Acc: 0.7860 | Val Loss: 0.4531 Acc: 0.7862\n",
      "Epoch 012 | Train Loss: 0.4514 Acc: 0.7934 | Val Loss: 0.4322 Acc: 0.7893\n",
      "Epoch 013 | Train Loss: 0.4341 Acc: 0.7983 | Val Loss: 0.4332 Acc: 0.8001\n",
      "Epoch 014 | Train Loss: 0.4263 Acc: 0.8005 | Val Loss: 0.4190 Acc: 0.8068\n",
      "Epoch 015 | Train Loss: 0.3950 Acc: 0.8255 | Val Loss: 0.3961 Acc: 0.8080\n",
      "Epoch 016 | Train Loss: 0.3905 Acc: 0.8258 | Val Loss: 0.3788 Acc: 0.8225\n",
      "Epoch 017 | Train Loss: 0.3839 Acc: 0.8345 | Val Loss: 0.3641 Acc: 0.8357\n",
      "Epoch 018 | Train Loss: 0.3622 Acc: 0.8436 | Val Loss: 0.3689 Acc: 0.8436\n",
      "Epoch 019 | Train Loss: 0.3432 Acc: 0.8535 | Val Loss: 0.3248 Acc: 0.8611\n",
      "Epoch 020 | Train Loss: 0.3394 Acc: 0.8532 | Val Loss: 0.3296 Acc: 0.8611\n",
      "Epoch 021 | Train Loss: 0.3261 Acc: 0.8602 | Val Loss: 0.3053 Acc: 0.8762\n",
      "Epoch 022 | Train Loss: 0.3033 Acc: 0.8701 | Val Loss: 0.2887 Acc: 0.8762\n",
      "Epoch 023 | Train Loss: 0.2918 Acc: 0.8768 | Val Loss: 0.2931 Acc: 0.8720\n",
      "Epoch 024 | Train Loss: 0.2935 Acc: 0.8804 | Val Loss: 0.3026 Acc: 0.8708\n",
      "Epoch 025 | Train Loss: 0.2702 Acc: 0.8908 | Val Loss: 0.2718 Acc: 0.8907\n",
      "Epoch 026 | Train Loss: 0.2571 Acc: 0.8969 | Val Loss: 0.2517 Acc: 0.8973\n",
      "Epoch 027 | Train Loss: 0.2523 Acc: 0.8987 | Val Loss: 0.2545 Acc: 0.8979\n",
      "Epoch 028 | Train Loss: 0.2378 Acc: 0.9059 | Val Loss: 0.3073 Acc: 0.8738\n",
      "Epoch 029 | Train Loss: 0.2477 Acc: 0.8993 | Val Loss: 0.2349 Acc: 0.9058\n",
      "Epoch 030 | Train Loss: 0.2277 Acc: 0.9077 | Val Loss: 0.2648 Acc: 0.8883\n",
      "Epoch 031 | Train Loss: 0.2120 Acc: 0.9161 | Val Loss: 0.2424 Acc: 0.9052\n",
      "Epoch 032 | Train Loss: 0.2176 Acc: 0.9164 | Val Loss: 0.2026 Acc: 0.9173\n",
      "Epoch 033 | Train Loss: 0.2006 Acc: 0.9242 | Val Loss: 0.1935 Acc: 0.9281\n",
      "Epoch 034 | Train Loss: 0.1887 Acc: 0.9269 | Val Loss: 0.1779 Acc: 0.9312\n",
      "Epoch 035 | Train Loss: 0.1762 Acc: 0.9310 | Val Loss: 0.1943 Acc: 0.9227\n",
      "Epoch 036 | Train Loss: 0.1917 Acc: 0.9265 | Val Loss: 0.2158 Acc: 0.9070\n",
      "Epoch 037 | Train Loss: 0.1763 Acc: 0.9305 | Val Loss: 0.1883 Acc: 0.9197\n",
      "Epoch 038 | Train Loss: 0.1720 Acc: 0.9336 | Val Loss: 0.1825 Acc: 0.9227\n",
      "Epoch 039 | Train Loss: 0.1509 Acc: 0.9429 | Val Loss: 0.1919 Acc: 0.9233\n",
      "Epoch 040 | Train Loss: 0.1624 Acc: 0.9379 | Val Loss: 0.1991 Acc: 0.9173\n",
      "Epoch 041 | Train Loss: 0.1418 Acc: 0.9444 | Val Loss: 0.1953 Acc: 0.9215\n",
      "Epoch 042 | Train Loss: 0.1543 Acc: 0.9402 | Val Loss: 0.1660 Acc: 0.9384\n",
      "Epoch 043 | Train Loss: 0.1450 Acc: 0.9450 | Val Loss: 0.1717 Acc: 0.9318\n",
      "Epoch 044 | Train Loss: 0.1335 Acc: 0.9524 | Val Loss: 0.1894 Acc: 0.9293\n",
      "Epoch 045 | Train Loss: 0.1361 Acc: 0.9481 | Val Loss: 0.1672 Acc: 0.9408\n",
      "Epoch 046 | Train Loss: 0.1287 Acc: 0.9503 | Val Loss: 0.1980 Acc: 0.9209\n",
      "Epoch 047 | Train Loss: 0.1274 Acc: 0.9521 | Val Loss: 0.1657 Acc: 0.9336\n",
      "Epoch 048 | Train Loss: 0.1250 Acc: 0.9529 | Val Loss: 0.1754 Acc: 0.9384\n",
      "Epoch 049 | Train Loss: 0.1319 Acc: 0.9491 | Val Loss: 0.2143 Acc: 0.9058\n",
      "Epoch 050 | Train Loss: 0.1200 Acc: 0.9555 | Val Loss: 0.1690 Acc: 0.9360\n",
      "Epoch 051 | Train Loss: 0.1173 Acc: 0.9556 | Val Loss: 0.1623 Acc: 0.9408\n",
      "Epoch 052 | Train Loss: 0.1175 Acc: 0.9564 | Val Loss: 0.1739 Acc: 0.9408\n",
      "Epoch 053 | Train Loss: 0.1121 Acc: 0.9603 | Val Loss: 0.1864 Acc: 0.9348\n",
      "Epoch 054 | Train Loss: 0.1140 Acc: 0.9597 | Val Loss: 0.1704 Acc: 0.9336\n",
      "Epoch 055 | Train Loss: 0.1035 Acc: 0.9618 | Val Loss: 0.1699 Acc: 0.9408\n",
      "Epoch 056 | Train Loss: 0.0926 Acc: 0.9680 | Val Loss: 0.1514 Acc: 0.9450\n",
      "Epoch 057 | Train Loss: 0.1063 Acc: 0.9598 | Val Loss: 0.1314 Acc: 0.9463\n",
      "Epoch 058 | Train Loss: 0.0946 Acc: 0.9671 | Val Loss: 0.1412 Acc: 0.9444\n",
      "Epoch 059 | Train Loss: 0.0991 Acc: 0.9650 | Val Loss: 0.1653 Acc: 0.9378\n",
      "Epoch 060 | Train Loss: 0.1062 Acc: 0.9612 | Val Loss: 0.1402 Acc: 0.9535\n",
      "Epoch 001 | Train Loss: 0.6777 Acc: 0.5796 | Val Loss: 0.6721 Acc: 0.5924\n",
      "Epoch 002 | Train Loss: 0.6659 Acc: 0.6030 | Val Loss: 0.6637 Acc: 0.6021\n",
      "Epoch 003 | Train Loss: 0.6595 Acc: 0.6098 | Val Loss: 0.6459 Acc: 0.6359\n",
      "Epoch 004 | Train Loss: 0.6316 Acc: 0.6553 | Val Loss: 0.5995 Acc: 0.6944\n",
      "Epoch 005 | Train Loss: 0.5927 Acc: 0.6939 | Val Loss: 0.5706 Acc: 0.7156\n",
      "Epoch 006 | Train Loss: 0.5580 Acc: 0.7260 | Val Loss: 0.5446 Acc: 0.7246\n",
      "Epoch 007 | Train Loss: 0.5308 Acc: 0.7374 | Val Loss: 0.5286 Acc: 0.7379\n",
      "Epoch 008 | Train Loss: 0.5124 Acc: 0.7569 | Val Loss: 0.5111 Acc: 0.7452\n",
      "Epoch 009 | Train Loss: 0.4943 Acc: 0.7679 | Val Loss: 0.4806 Acc: 0.7633\n",
      "Epoch 010 | Train Loss: 0.4710 Acc: 0.7773 | Val Loss: 0.4814 Acc: 0.7687\n",
      "Epoch 011 | Train Loss: 0.4535 Acc: 0.7894 | Val Loss: 0.4327 Acc: 0.7911\n",
      "Epoch 012 | Train Loss: 0.4319 Acc: 0.8018 | Val Loss: 0.4514 Acc: 0.7820\n",
      "Epoch 013 | Train Loss: 0.4107 Acc: 0.8170 | Val Loss: 0.4230 Acc: 0.8001\n",
      "Epoch 014 | Train Loss: 0.3940 Acc: 0.8244 | Val Loss: 0.3817 Acc: 0.8158\n",
      "Epoch 015 | Train Loss: 0.3774 Acc: 0.8310 | Val Loss: 0.3970 Acc: 0.8170\n",
      "Epoch 016 | Train Loss: 0.3814 Acc: 0.8247 | Val Loss: 0.3908 Acc: 0.8225\n",
      "Epoch 017 | Train Loss: 0.3368 Acc: 0.8501 | Val Loss: 0.3522 Acc: 0.8418\n",
      "Epoch 018 | Train Loss: 0.3283 Acc: 0.8596 | Val Loss: 0.3514 Acc: 0.8484\n",
      "Epoch 019 | Train Loss: 0.3087 Acc: 0.8703 | Val Loss: 0.3147 Acc: 0.8653\n",
      "Epoch 020 | Train Loss: 0.3072 Acc: 0.8701 | Val Loss: 0.3075 Acc: 0.8732\n",
      "Epoch 021 | Train Loss: 0.2900 Acc: 0.8785 | Val Loss: 0.3035 Acc: 0.8702\n",
      "Epoch 022 | Train Loss: 0.2782 Acc: 0.8830 | Val Loss: 0.2787 Acc: 0.8847\n",
      "Epoch 023 | Train Loss: 0.2508 Acc: 0.8955 | Val Loss: 0.2627 Acc: 0.8967\n",
      "Epoch 024 | Train Loss: 0.2518 Acc: 0.8972 | Val Loss: 0.2521 Acc: 0.8949\n",
      "Epoch 025 | Train Loss: 0.2438 Acc: 0.8988 | Val Loss: 0.2519 Acc: 0.9034\n",
      "Epoch 026 | Train Loss: 0.2383 Acc: 0.9023 | Val Loss: 0.2461 Acc: 0.9022\n",
      "Epoch 027 | Train Loss: 0.2265 Acc: 0.9103 | Val Loss: 0.2629 Acc: 0.8967\n",
      "Epoch 028 | Train Loss: 0.2132 Acc: 0.9164 | Val Loss: 0.2354 Acc: 0.9010\n",
      "Epoch 029 | Train Loss: 0.2066 Acc: 0.9174 | Val Loss: 0.2310 Acc: 0.9016\n",
      "Epoch 030 | Train Loss: 0.1969 Acc: 0.9209 | Val Loss: 0.2352 Acc: 0.9070\n",
      "Epoch 031 | Train Loss: 0.1921 Acc: 0.9239 | Val Loss: 0.2041 Acc: 0.9191\n",
      "Epoch 032 | Train Loss: 0.1835 Acc: 0.9262 | Val Loss: 0.2027 Acc: 0.9203\n",
      "Epoch 033 | Train Loss: 0.1827 Acc: 0.9302 | Val Loss: 0.1922 Acc: 0.9197\n",
      "Epoch 034 | Train Loss: 0.1769 Acc: 0.9346 | Val Loss: 0.2197 Acc: 0.9143\n",
      "Epoch 035 | Train Loss: 0.1766 Acc: 0.9302 | Val Loss: 0.2266 Acc: 0.9076\n",
      "Epoch 036 | Train Loss: 0.1623 Acc: 0.9357 | Val Loss: 0.2012 Acc: 0.9221\n",
      "Epoch 037 | Train Loss: 0.1574 Acc: 0.9384 | Val Loss: 0.2557 Acc: 0.9064\n",
      "Epoch 038 | Train Loss: 0.1595 Acc: 0.9367 | Val Loss: 0.2720 Acc: 0.9088\n",
      "Epoch 039 | Train Loss: 0.1553 Acc: 0.9405 | Val Loss: 0.1987 Acc: 0.9185\n",
      "Epoch 040 | Train Loss: 0.1556 Acc: 0.9381 | Val Loss: 0.1807 Acc: 0.9330\n",
      "Epoch 041 | Train Loss: 0.1368 Acc: 0.9484 | Val Loss: 0.2008 Acc: 0.9336\n",
      "Epoch 042 | Train Loss: 0.1371 Acc: 0.9475 | Val Loss: 0.2117 Acc: 0.9179\n",
      "Epoch 043 | Train Loss: 0.1440 Acc: 0.9437 | Val Loss: 0.1792 Acc: 0.9336\n",
      "Epoch 044 | Train Loss: 0.1297 Acc: 0.9494 | Val Loss: 0.1868 Acc: 0.9251\n",
      "Epoch 045 | Train Loss: 0.1266 Acc: 0.9512 | Val Loss: 0.1721 Acc: 0.9318\n",
      "Epoch 046 | Train Loss: 0.1179 Acc: 0.9518 | Val Loss: 0.1829 Acc: 0.9306\n",
      "Epoch 047 | Train Loss: 0.1254 Acc: 0.9511 | Val Loss: 0.1623 Acc: 0.9293\n",
      "Epoch 048 | Train Loss: 0.1100 Acc: 0.9574 | Val Loss: 0.2020 Acc: 0.9233\n",
      "Epoch 049 | Train Loss: 0.1170 Acc: 0.9550 | Val Loss: 0.2038 Acc: 0.9263\n",
      "Epoch 050 | Train Loss: 0.1158 Acc: 0.9588 | Val Loss: 0.1546 Acc: 0.9426\n",
      "Epoch 051 | Train Loss: 0.1141 Acc: 0.9570 | Val Loss: 0.1805 Acc: 0.9342\n",
      "Epoch 052 | Train Loss: 0.1160 Acc: 0.9558 | Val Loss: 0.2146 Acc: 0.9203\n",
      "Epoch 053 | Train Loss: 0.1130 Acc: 0.9580 | Val Loss: 0.1680 Acc: 0.9420\n",
      "Epoch 054 | Train Loss: 0.0986 Acc: 0.9633 | Val Loss: 0.1865 Acc: 0.9342\n",
      "Epoch 055 | Train Loss: 0.1077 Acc: 0.9615 | Val Loss: 0.1701 Acc: 0.9414\n",
      "Epoch 056 | Train Loss: 0.1074 Acc: 0.9592 | Val Loss: 0.1803 Acc: 0.9408\n",
      "Epoch 057 | Train Loss: 0.1040 Acc: 0.9623 | Val Loss: 0.1562 Acc: 0.9372\n",
      "Epoch 058 | Train Loss: 0.0939 Acc: 0.9669 | Val Loss: 0.1950 Acc: 0.9300\n",
      "Epoch 059 | Train Loss: 0.1079 Acc: 0.9604 | Val Loss: 0.1796 Acc: 0.9318\n",
      "Epoch 060 | Train Loss: 0.0903 Acc: 0.9678 | Val Loss: 0.1583 Acc: 0.9312\n",
      "Early stopping triggered.\n",
      "Epoch 001 | Train Loss: 0.6803 Acc: 0.5753 | Val Loss: 0.6729 Acc: 0.5918\n",
      "Epoch 002 | Train Loss: 0.6589 Acc: 0.6108 | Val Loss: 0.6332 Acc: 0.6582\n",
      "Epoch 003 | Train Loss: 0.6040 Acc: 0.6870 | Val Loss: 0.5784 Acc: 0.6957\n",
      "Epoch 004 | Train Loss: 0.5535 Acc: 0.7243 | Val Loss: 0.5444 Acc: 0.7234\n",
      "Epoch 005 | Train Loss: 0.5353 Acc: 0.7356 | Val Loss: 0.5439 Acc: 0.7476\n",
      "Epoch 006 | Train Loss: 0.5132 Acc: 0.7580 | Val Loss: 0.4975 Acc: 0.7572\n",
      "Epoch 007 | Train Loss: 0.4859 Acc: 0.7623 | Val Loss: 0.4976 Acc: 0.7548\n",
      "Epoch 008 | Train Loss: 0.4710 Acc: 0.7771 | Val Loss: 0.4720 Acc: 0.7723\n",
      "Epoch 009 | Train Loss: 0.4628 Acc: 0.7853 | Val Loss: 0.4607 Acc: 0.7760\n",
      "Epoch 010 | Train Loss: 0.4283 Acc: 0.8011 | Val Loss: 0.4371 Acc: 0.7905\n",
      "Epoch 011 | Train Loss: 0.4241 Acc: 0.8058 | Val Loss: 0.4020 Acc: 0.8013\n",
      "Epoch 012 | Train Loss: 0.4092 Acc: 0.8158 | Val Loss: 0.3907 Acc: 0.8170\n",
      "Epoch 013 | Train Loss: 0.3797 Acc: 0.8298 | Val Loss: 0.3652 Acc: 0.8200\n",
      "Epoch 014 | Train Loss: 0.3678 Acc: 0.8362 | Val Loss: 0.3750 Acc: 0.8237\n",
      "Epoch 015 | Train Loss: 0.3574 Acc: 0.8437 | Val Loss: 0.3547 Acc: 0.8382\n",
      "Epoch 016 | Train Loss: 0.3465 Acc: 0.8511 | Val Loss: 0.3174 Acc: 0.8478\n",
      "Epoch 017 | Train Loss: 0.3291 Acc: 0.8575 | Val Loss: 0.3231 Acc: 0.8533\n",
      "Epoch 018 | Train Loss: 0.3197 Acc: 0.8618 | Val Loss: 0.3102 Acc: 0.8617\n",
      "Epoch 019 | Train Loss: 0.2942 Acc: 0.8742 | Val Loss: 0.3018 Acc: 0.8659\n",
      "Epoch 020 | Train Loss: 0.2842 Acc: 0.8865 | Val Loss: 0.3038 Acc: 0.8647\n",
      "Epoch 021 | Train Loss: 0.2659 Acc: 0.8878 | Val Loss: 0.2874 Acc: 0.8792\n",
      "Epoch 022 | Train Loss: 0.2668 Acc: 0.8923 | Val Loss: 0.2537 Acc: 0.8871\n",
      "Epoch 023 | Train Loss: 0.2554 Acc: 0.8960 | Val Loss: 0.2483 Acc: 0.8961\n",
      "Epoch 024 | Train Loss: 0.2412 Acc: 0.9022 | Val Loss: 0.2764 Acc: 0.8780\n",
      "Epoch 025 | Train Loss: 0.2361 Acc: 0.9035 | Val Loss: 0.2595 Acc: 0.8883\n",
      "Epoch 026 | Train Loss: 0.2313 Acc: 0.9067 | Val Loss: 0.2358 Acc: 0.9028\n",
      "Epoch 027 | Train Loss: 0.2162 Acc: 0.9156 | Val Loss: 0.2346 Acc: 0.9070\n",
      "Epoch 028 | Train Loss: 0.2217 Acc: 0.9085 | Val Loss: 0.2506 Acc: 0.8986\n",
      "Epoch 029 | Train Loss: 0.2014 Acc: 0.9171 | Val Loss: 0.2280 Acc: 0.9034\n",
      "Epoch 030 | Train Loss: 0.2106 Acc: 0.9191 | Val Loss: 0.2205 Acc: 0.9034\n",
      "Epoch 031 | Train Loss: 0.1749 Acc: 0.9302 | Val Loss: 0.2174 Acc: 0.9040\n",
      "Epoch 032 | Train Loss: 0.1857 Acc: 0.9253 | Val Loss: 0.1942 Acc: 0.9185\n",
      "Epoch 033 | Train Loss: 0.1682 Acc: 0.9339 | Val Loss: 0.2068 Acc: 0.9161\n",
      "Epoch 034 | Train Loss: 0.1813 Acc: 0.9299 | Val Loss: 0.1997 Acc: 0.9161\n",
      "Epoch 035 | Train Loss: 0.1677 Acc: 0.9348 | Val Loss: 0.2336 Acc: 0.9058\n",
      "Epoch 036 | Train Loss: 0.1613 Acc: 0.9361 | Val Loss: 0.2294 Acc: 0.9167\n",
      "Epoch 037 | Train Loss: 0.1491 Acc: 0.9410 | Val Loss: 0.1817 Acc: 0.9293\n",
      "Epoch 038 | Train Loss: 0.1548 Acc: 0.9404 | Val Loss: 0.2031 Acc: 0.9136\n",
      "Epoch 039 | Train Loss: 0.1489 Acc: 0.9434 | Val Loss: 0.1903 Acc: 0.9318\n",
      "Epoch 040 | Train Loss: 0.1404 Acc: 0.9458 | Val Loss: 0.1793 Acc: 0.9227\n",
      "Epoch 041 | Train Loss: 0.1343 Acc: 0.9502 | Val Loss: 0.1837 Acc: 0.9269\n",
      "Epoch 042 | Train Loss: 0.1416 Acc: 0.9438 | Val Loss: 0.2040 Acc: 0.9239\n",
      "Epoch 043 | Train Loss: 0.1247 Acc: 0.9521 | Val Loss: 0.1797 Acc: 0.9324\n",
      "Epoch 044 | Train Loss: 0.1231 Acc: 0.9549 | Val Loss: 0.1770 Acc: 0.9275\n",
      "Epoch 045 | Train Loss: 0.1224 Acc: 0.9553 | Val Loss: 0.1815 Acc: 0.9318\n",
      "Epoch 046 | Train Loss: 0.1195 Acc: 0.9562 | Val Loss: 0.1773 Acc: 0.9306\n",
      "Epoch 047 | Train Loss: 0.1225 Acc: 0.9552 | Val Loss: 0.1848 Acc: 0.9312\n",
      "Epoch 048 | Train Loss: 0.1171 Acc: 0.9558 | Val Loss: 0.1511 Acc: 0.9384\n",
      "Epoch 049 | Train Loss: 0.1072 Acc: 0.9585 | Val Loss: 0.1674 Acc: 0.9390\n",
      "Epoch 050 | Train Loss: 0.1195 Acc: 0.9553 | Val Loss: 0.1806 Acc: 0.9300\n",
      "Epoch 051 | Train Loss: 0.1277 Acc: 0.9509 | Val Loss: 0.1413 Acc: 0.9384\n",
      "Epoch 052 | Train Loss: 0.1196 Acc: 0.9523 | Val Loss: 0.1735 Acc: 0.9318\n",
      "Epoch 053 | Train Loss: 0.1059 Acc: 0.9598 | Val Loss: 0.1859 Acc: 0.9161\n",
      "Epoch 054 | Train Loss: 0.1080 Acc: 0.9582 | Val Loss: 0.1564 Acc: 0.9390\n",
      "Epoch 055 | Train Loss: 0.0972 Acc: 0.9645 | Val Loss: 0.1532 Acc: 0.9348\n",
      "Epoch 056 | Train Loss: 0.1018 Acc: 0.9610 | Val Loss: 0.1660 Acc: 0.9414\n",
      "Epoch 057 | Train Loss: 0.1055 Acc: 0.9630 | Val Loss: 0.1736 Acc: 0.9342\n",
      "Epoch 058 | Train Loss: 0.1094 Acc: 0.9592 | Val Loss: 0.1514 Acc: 0.9457\n",
      "Epoch 059 | Train Loss: 0.0979 Acc: 0.9630 | Val Loss: 0.1625 Acc: 0.9342\n",
      "Epoch 060 | Train Loss: 0.0948 Acc: 0.9650 | Val Loss: 0.1479 Acc: 0.9426\n",
      "Epoch 001 | Train Loss: 0.6819 Acc: 0.5799 | Val Loss: 0.6780 Acc: 0.5857\n",
      "Epoch 002 | Train Loss: 0.6770 Acc: 0.5830 | Val Loss: 0.6786 Acc: 0.5761\n",
      "Epoch 003 | Train Loss: 0.6682 Acc: 0.6000 | Val Loss: 0.6579 Acc: 0.6129\n",
      "Epoch 004 | Train Loss: 0.6509 Acc: 0.6248 | Val Loss: 0.6308 Acc: 0.6643\n",
      "Epoch 005 | Train Loss: 0.6211 Acc: 0.6730 | Val Loss: 0.6069 Acc: 0.6860\n",
      "Epoch 006 | Train Loss: 0.5964 Acc: 0.6995 | Val Loss: 0.5939 Acc: 0.6914\n",
      "Epoch 007 | Train Loss: 0.5799 Acc: 0.7054 | Val Loss: 0.5915 Acc: 0.6920\n",
      "Epoch 008 | Train Loss: 0.5719 Acc: 0.7127 | Val Loss: 0.5637 Acc: 0.7107\n",
      "Epoch 009 | Train Loss: 0.5519 Acc: 0.7216 | Val Loss: 0.5426 Acc: 0.7277\n",
      "Epoch 010 | Train Loss: 0.5386 Acc: 0.7329 | Val Loss: 0.5221 Acc: 0.7385\n",
      "Epoch 011 | Train Loss: 0.5230 Acc: 0.7474 | Val Loss: 0.5223 Acc: 0.7397\n",
      "Epoch 012 | Train Loss: 0.5104 Acc: 0.7540 | Val Loss: 0.5166 Acc: 0.7434\n",
      "Epoch 013 | Train Loss: 0.4991 Acc: 0.7586 | Val Loss: 0.4905 Acc: 0.7566\n",
      "Epoch 014 | Train Loss: 0.4876 Acc: 0.7663 | Val Loss: 0.4839 Acc: 0.7603\n",
      "Epoch 015 | Train Loss: 0.4770 Acc: 0.7713 | Val Loss: 0.4826 Acc: 0.7621\n",
      "Epoch 016 | Train Loss: 0.4596 Acc: 0.7874 | Val Loss: 0.4606 Acc: 0.7784\n",
      "Epoch 017 | Train Loss: 0.4467 Acc: 0.7975 | Val Loss: 0.4428 Acc: 0.7959\n",
      "Epoch 018 | Train Loss: 0.4414 Acc: 0.7947 | Val Loss: 0.4388 Acc: 0.8019\n",
      "Epoch 019 | Train Loss: 0.4276 Acc: 0.8049 | Val Loss: 0.4230 Acc: 0.8007\n",
      "Epoch 020 | Train Loss: 0.4155 Acc: 0.8131 | Val Loss: 0.3886 Acc: 0.8255\n",
      "Epoch 021 | Train Loss: 0.3923 Acc: 0.8289 | Val Loss: 0.3703 Acc: 0.8351\n",
      "Epoch 022 | Train Loss: 0.3867 Acc: 0.8345 | Val Loss: 0.3648 Acc: 0.8388\n",
      "Epoch 023 | Train Loss: 0.3866 Acc: 0.8310 | Val Loss: 0.3650 Acc: 0.8412\n",
      "Epoch 024 | Train Loss: 0.3883 Acc: 0.8283 | Val Loss: 0.3548 Acc: 0.8472\n",
      "Epoch 025 | Train Loss: 0.3609 Acc: 0.8505 | Val Loss: 0.3341 Acc: 0.8587\n",
      "Epoch 026 | Train Loss: 0.3552 Acc: 0.8502 | Val Loss: 0.3769 Acc: 0.8297\n",
      "Epoch 027 | Train Loss: 0.3486 Acc: 0.8502 | Val Loss: 0.3276 Acc: 0.8659\n",
      "Epoch 028 | Train Loss: 0.3285 Acc: 0.8640 | Val Loss: 0.3445 Acc: 0.8448\n",
      "Epoch 029 | Train Loss: 0.3155 Acc: 0.8720 | Val Loss: 0.3102 Acc: 0.8726\n",
      "Epoch 030 | Train Loss: 0.3090 Acc: 0.8744 | Val Loss: 0.3167 Acc: 0.8708\n",
      "Epoch 031 | Train Loss: 0.3161 Acc: 0.8640 | Val Loss: 0.2857 Acc: 0.8792\n",
      "Epoch 032 | Train Loss: 0.3038 Acc: 0.8727 | Val Loss: 0.3482 Acc: 0.8551\n",
      "Epoch 033 | Train Loss: 0.3007 Acc: 0.8795 | Val Loss: 0.2822 Acc: 0.8877\n",
      "Epoch 034 | Train Loss: 0.3015 Acc: 0.8744 | Val Loss: 0.2778 Acc: 0.8931\n",
      "Epoch 035 | Train Loss: 0.2905 Acc: 0.8783 | Val Loss: 0.2872 Acc: 0.8702\n",
      "Epoch 036 | Train Loss: 0.2857 Acc: 0.8830 | Val Loss: 0.2596 Acc: 0.9004\n",
      "Epoch 037 | Train Loss: 0.2624 Acc: 0.8923 | Val Loss: 0.2675 Acc: 0.8919\n",
      "Epoch 038 | Train Loss: 0.2695 Acc: 0.8901 | Val Loss: 0.2482 Acc: 0.8967\n",
      "Epoch 039 | Train Loss: 0.2756 Acc: 0.8901 | Val Loss: 0.2743 Acc: 0.8804\n",
      "Epoch 040 | Train Loss: 0.2606 Acc: 0.8946 | Val Loss: 0.2459 Acc: 0.9016\n",
      "Epoch 041 | Train Loss: 0.2513 Acc: 0.8979 | Val Loss: 0.2573 Acc: 0.8889\n",
      "Epoch 042 | Train Loss: 0.2587 Acc: 0.8948 | Val Loss: 0.2652 Acc: 0.8949\n",
      "Epoch 043 | Train Loss: 0.2609 Acc: 0.8988 | Val Loss: 0.2569 Acc: 0.9052\n",
      "Epoch 044 | Train Loss: 0.2398 Acc: 0.9037 | Val Loss: 0.2369 Acc: 0.9124\n",
      "Epoch 045 | Train Loss: 0.2417 Acc: 0.9025 | Val Loss: 0.2300 Acc: 0.9082\n",
      "Epoch 046 | Train Loss: 0.2296 Acc: 0.9150 | Val Loss: 0.2276 Acc: 0.9167\n",
      "Epoch 047 | Train Loss: 0.2324 Acc: 0.9094 | Val Loss: 0.2481 Acc: 0.9016\n",
      "Epoch 048 | Train Loss: 0.2307 Acc: 0.9070 | Val Loss: 0.2127 Acc: 0.9215\n",
      "Epoch 049 | Train Loss: 0.2270 Acc: 0.9091 | Val Loss: 0.2192 Acc: 0.9136\n",
      "Epoch 050 | Train Loss: 0.2213 Acc: 0.9123 | Val Loss: 0.2093 Acc: 0.9064\n",
      "Epoch 051 | Train Loss: 0.2278 Acc: 0.9115 | Val Loss: 0.2093 Acc: 0.9155\n",
      "Epoch 052 | Train Loss: 0.2254 Acc: 0.9126 | Val Loss: 0.2118 Acc: 0.9179\n",
      "Epoch 053 | Train Loss: 0.2124 Acc: 0.9147 | Val Loss: 0.2142 Acc: 0.9215\n",
      "Epoch 054 | Train Loss: 0.2073 Acc: 0.9173 | Val Loss: 0.2110 Acc: 0.9209\n",
      "Epoch 055 | Train Loss: 0.2116 Acc: 0.9109 | Val Loss: 0.2163 Acc: 0.9118\n",
      "Epoch 056 | Train Loss: 0.2104 Acc: 0.9195 | Val Loss: 0.2104 Acc: 0.9203\n",
      "Epoch 057 | Train Loss: 0.2055 Acc: 0.9189 | Val Loss: 0.1996 Acc: 0.9293\n",
      "Epoch 058 | Train Loss: 0.2026 Acc: 0.9206 | Val Loss: 0.2146 Acc: 0.9197\n",
      "Epoch 059 | Train Loss: 0.2000 Acc: 0.9224 | Val Loss: 0.1829 Acc: 0.9348\n",
      "Epoch 060 | Train Loss: 0.1970 Acc: 0.9219 | Val Loss: 0.2027 Acc: 0.9221\n",
      "Epoch 001 | Train Loss: 0.6820 Acc: 0.5694 | Val Loss: 0.6792 Acc: 0.5773\n",
      "Epoch 002 | Train Loss: 0.6751 Acc: 0.5904 | Val Loss: 0.6714 Acc: 0.5966\n",
      "Epoch 003 | Train Loss: 0.6634 Acc: 0.6056 | Val Loss: 0.6595 Acc: 0.6081\n",
      "Epoch 004 | Train Loss: 0.6535 Acc: 0.6189 | Val Loss: 0.6426 Acc: 0.6268\n",
      "Epoch 005 | Train Loss: 0.6357 Acc: 0.6490 | Val Loss: 0.6235 Acc: 0.6715\n",
      "Epoch 006 | Train Loss: 0.6191 Acc: 0.6710 | Val Loss: 0.6193 Acc: 0.6649\n",
      "Epoch 007 | Train Loss: 0.6018 Acc: 0.6921 | Val Loss: 0.5985 Acc: 0.6848\n",
      "Epoch 008 | Train Loss: 0.5819 Acc: 0.7103 | Val Loss: 0.5732 Acc: 0.7077\n",
      "Epoch 009 | Train Loss: 0.5646 Acc: 0.7208 | Val Loss: 0.5605 Acc: 0.7174\n",
      "Epoch 010 | Train Loss: 0.5431 Acc: 0.7349 | Val Loss: 0.5399 Acc: 0.7301\n",
      "Epoch 011 | Train Loss: 0.5336 Acc: 0.7430 | Val Loss: 0.5840 Acc: 0.7035\n",
      "Epoch 012 | Train Loss: 0.5157 Acc: 0.7539 | Val Loss: 0.5236 Acc: 0.7385\n",
      "Epoch 013 | Train Loss: 0.5090 Acc: 0.7592 | Val Loss: 0.5103 Acc: 0.7482\n",
      "Epoch 014 | Train Loss: 0.4922 Acc: 0.7682 | Val Loss: 0.5457 Acc: 0.7307\n",
      "Epoch 015 | Train Loss: 0.4818 Acc: 0.7740 | Val Loss: 0.4829 Acc: 0.7639\n",
      "Epoch 016 | Train Loss: 0.4753 Acc: 0.7847 | Val Loss: 0.4860 Acc: 0.7627\n",
      "Epoch 017 | Train Loss: 0.4637 Acc: 0.7806 | Val Loss: 0.4641 Acc: 0.7826\n",
      "Epoch 018 | Train Loss: 0.4490 Acc: 0.7915 | Val Loss: 0.4566 Acc: 0.7856\n",
      "Epoch 019 | Train Loss: 0.4324 Acc: 0.7986 | Val Loss: 0.4714 Acc: 0.7663\n",
      "Epoch 020 | Train Loss: 0.4186 Acc: 0.8107 | Val Loss: 0.4248 Acc: 0.7947\n",
      "Epoch 021 | Train Loss: 0.4010 Acc: 0.8164 | Val Loss: 0.4045 Acc: 0.8182\n",
      "Epoch 022 | Train Loss: 0.3896 Acc: 0.8200 | Val Loss: 0.4052 Acc: 0.8062\n",
      "Epoch 023 | Train Loss: 0.3724 Acc: 0.8326 | Val Loss: 0.3675 Acc: 0.8333\n",
      "Epoch 024 | Train Loss: 0.3602 Acc: 0.8335 | Val Loss: 0.3569 Acc: 0.8406\n",
      "Epoch 025 | Train Loss: 0.3426 Acc: 0.8478 | Val Loss: 0.3917 Acc: 0.8122\n",
      "Epoch 026 | Train Loss: 0.3244 Acc: 0.8576 | Val Loss: 0.3847 Acc: 0.8243\n",
      "Epoch 027 | Train Loss: 0.3175 Acc: 0.8615 | Val Loss: 0.3542 Acc: 0.8448\n",
      "Epoch 028 | Train Loss: 0.2964 Acc: 0.8712 | Val Loss: 0.3290 Acc: 0.8551\n",
      "Epoch 029 | Train Loss: 0.2850 Acc: 0.8782 | Val Loss: 0.3154 Acc: 0.8678\n",
      "Epoch 030 | Train Loss: 0.2653 Acc: 0.8898 | Val Loss: 0.3016 Acc: 0.8702\n",
      "Epoch 031 | Train Loss: 0.2638 Acc: 0.8877 | Val Loss: 0.2917 Acc: 0.8822\n",
      "Epoch 032 | Train Loss: 0.2396 Acc: 0.9002 | Val Loss: 0.2786 Acc: 0.8798\n",
      "Epoch 033 | Train Loss: 0.2445 Acc: 0.9029 | Val Loss: 0.2776 Acc: 0.8835\n",
      "Epoch 034 | Train Loss: 0.2354 Acc: 0.9043 | Val Loss: 0.2906 Acc: 0.8816\n",
      "Epoch 035 | Train Loss: 0.2164 Acc: 0.9135 | Val Loss: 0.3035 Acc: 0.8708\n",
      "Epoch 036 | Train Loss: 0.2097 Acc: 0.9126 | Val Loss: 0.2646 Acc: 0.8877\n",
      "Epoch 037 | Train Loss: 0.1968 Acc: 0.9227 | Val Loss: 0.2357 Acc: 0.9046\n",
      "Epoch 038 | Train Loss: 0.1833 Acc: 0.9248 | Val Loss: 0.2512 Acc: 0.9016\n",
      "Epoch 039 | Train Loss: 0.1808 Acc: 0.9307 | Val Loss: 0.2306 Acc: 0.9076\n",
      "Epoch 040 | Train Loss: 0.1710 Acc: 0.9345 | Val Loss: 0.2238 Acc: 0.9052\n",
      "Epoch 041 | Train Loss: 0.1644 Acc: 0.9336 | Val Loss: 0.2273 Acc: 0.9100\n",
      "Epoch 042 | Train Loss: 0.1479 Acc: 0.9419 | Val Loss: 0.2237 Acc: 0.9058\n",
      "Epoch 043 | Train Loss: 0.1523 Acc: 0.9414 | Val Loss: 0.2094 Acc: 0.9167\n",
      "Epoch 044 | Train Loss: 0.1478 Acc: 0.9434 | Val Loss: 0.2265 Acc: 0.9118\n",
      "Epoch 045 | Train Loss: 0.1385 Acc: 0.9464 | Val Loss: 0.2145 Acc: 0.9124\n",
      "Epoch 046 | Train Loss: 0.1364 Acc: 0.9476 | Val Loss: 0.2207 Acc: 0.9082\n",
      "Epoch 047 | Train Loss: 0.1259 Acc: 0.9526 | Val Loss: 0.2070 Acc: 0.9197\n",
      "Epoch 048 | Train Loss: 0.1171 Acc: 0.9555 | Val Loss: 0.2437 Acc: 0.9058\n",
      "Epoch 049 | Train Loss: 0.1252 Acc: 0.9532 | Val Loss: 0.2025 Acc: 0.9191\n",
      "Epoch 050 | Train Loss: 0.1083 Acc: 0.9627 | Val Loss: 0.2108 Acc: 0.9173\n",
      "Epoch 051 | Train Loss: 0.1156 Acc: 0.9571 | Val Loss: 0.1887 Acc: 0.9257\n",
      "Epoch 052 | Train Loss: 0.1047 Acc: 0.9613 | Val Loss: 0.2353 Acc: 0.9130\n",
      "Epoch 053 | Train Loss: 0.0993 Acc: 0.9623 | Val Loss: 0.2219 Acc: 0.9215\n",
      "Epoch 054 | Train Loss: 0.0903 Acc: 0.9663 | Val Loss: 0.1856 Acc: 0.9312\n",
      "Epoch 055 | Train Loss: 0.1042 Acc: 0.9612 | Val Loss: 0.1999 Acc: 0.9257\n",
      "Epoch 056 | Train Loss: 0.0973 Acc: 0.9633 | Val Loss: 0.2020 Acc: 0.9251\n",
      "Epoch 057 | Train Loss: 0.0785 Acc: 0.9707 | Val Loss: 0.2770 Acc: 0.9112\n",
      "Epoch 058 | Train Loss: 0.0863 Acc: 0.9683 | Val Loss: 0.2060 Acc: 0.9203\n",
      "Epoch 059 | Train Loss: 0.0877 Acc: 0.9675 | Val Loss: 0.2146 Acc: 0.9239\n",
      "Epoch 060 | Train Loss: 0.0918 Acc: 0.9651 | Val Loss: 0.2408 Acc: 0.9215\n",
      "Epoch 001 | Train Loss: 0.6812 Acc: 0.5792 | Val Loss: 0.6746 Acc: 0.5882\n",
      "Epoch 002 | Train Loss: 0.6560 Acc: 0.6163 | Val Loss: 0.6449 Acc: 0.6178\n",
      "Epoch 003 | Train Loss: 0.6140 Acc: 0.6787 | Val Loss: 0.5928 Acc: 0.6993\n",
      "Epoch 004 | Train Loss: 0.5832 Acc: 0.7072 | Val Loss: 0.5656 Acc: 0.7168\n",
      "Epoch 005 | Train Loss: 0.5566 Acc: 0.7266 | Val Loss: 0.5468 Acc: 0.7180\n",
      "Epoch 006 | Train Loss: 0.5314 Acc: 0.7409 | Val Loss: 0.5360 Acc: 0.7343\n",
      "Epoch 007 | Train Loss: 0.5061 Acc: 0.7593 | Val Loss: 0.5029 Acc: 0.7548\n",
      "Epoch 008 | Train Loss: 0.4940 Acc: 0.7589 | Val Loss: 0.4781 Acc: 0.7633\n",
      "Epoch 009 | Train Loss: 0.4706 Acc: 0.7716 | Val Loss: 0.5262 Acc: 0.7645\n",
      "Epoch 010 | Train Loss: 0.4531 Acc: 0.7854 | Val Loss: 0.4572 Acc: 0.7893\n",
      "Epoch 011 | Train Loss: 0.4335 Acc: 0.7966 | Val Loss: 0.3971 Acc: 0.8200\n",
      "Epoch 012 | Train Loss: 0.4052 Acc: 0.8128 | Val Loss: 0.4089 Acc: 0.8019\n",
      "Epoch 013 | Train Loss: 0.3906 Acc: 0.8226 | Val Loss: 0.3756 Acc: 0.8321\n",
      "Epoch 014 | Train Loss: 0.3565 Acc: 0.8401 | Val Loss: 0.3499 Acc: 0.8514\n",
      "Epoch 015 | Train Loss: 0.3513 Acc: 0.8470 | Val Loss: 0.3342 Acc: 0.8575\n",
      "Epoch 016 | Train Loss: 0.3213 Acc: 0.8555 | Val Loss: 0.3952 Acc: 0.8200\n",
      "Epoch 017 | Train Loss: 0.3120 Acc: 0.8682 | Val Loss: 0.2932 Acc: 0.8744\n",
      "Epoch 018 | Train Loss: 0.3017 Acc: 0.8711 | Val Loss: 0.3063 Acc: 0.8684\n",
      "Epoch 019 | Train Loss: 0.2845 Acc: 0.8801 | Val Loss: 0.3062 Acc: 0.8877\n",
      "Epoch 020 | Train Loss: 0.2820 Acc: 0.8860 | Val Loss: 0.3480 Acc: 0.8527\n",
      "Epoch 021 | Train Loss: 0.2704 Acc: 0.8856 | Val Loss: 0.2904 Acc: 0.8762\n",
      "Epoch 022 | Train Loss: 0.2524 Acc: 0.8926 | Val Loss: 0.2648 Acc: 0.8931\n",
      "Epoch 023 | Train Loss: 0.2587 Acc: 0.8943 | Val Loss: 0.2674 Acc: 0.8865\n",
      "Epoch 024 | Train Loss: 0.2383 Acc: 0.9052 | Val Loss: 0.2311 Acc: 0.9088\n",
      "Epoch 025 | Train Loss: 0.2321 Acc: 0.9053 | Val Loss: 0.2515 Acc: 0.8931\n",
      "Epoch 026 | Train Loss: 0.2160 Acc: 0.9144 | Val Loss: 0.2474 Acc: 0.8949\n",
      "Epoch 027 | Train Loss: 0.2169 Acc: 0.9148 | Val Loss: 0.2098 Acc: 0.9136\n",
      "Epoch 028 | Train Loss: 0.1968 Acc: 0.9234 | Val Loss: 0.2192 Acc: 0.9052\n",
      "Epoch 029 | Train Loss: 0.1912 Acc: 0.9253 | Val Loss: 0.2004 Acc: 0.9221\n",
      "Epoch 030 | Train Loss: 0.2034 Acc: 0.9164 | Val Loss: 0.2271 Acc: 0.9076\n",
      "Epoch 031 | Train Loss: 0.1806 Acc: 0.9281 | Val Loss: 0.2333 Acc: 0.9143\n",
      "Epoch 032 | Train Loss: 0.1818 Acc: 0.9244 | Val Loss: 0.2363 Acc: 0.9040\n",
      "Epoch 033 | Train Loss: 0.1706 Acc: 0.9325 | Val Loss: 0.1935 Acc: 0.9263\n",
      "Epoch 034 | Train Loss: 0.1603 Acc: 0.9351 | Val Loss: 0.2183 Acc: 0.9191\n",
      "Epoch 035 | Train Loss: 0.1591 Acc: 0.9364 | Val Loss: 0.2266 Acc: 0.9136\n",
      "Epoch 036 | Train Loss: 0.1670 Acc: 0.9361 | Val Loss: 0.1925 Acc: 0.9287\n",
      "Epoch 037 | Train Loss: 0.1527 Acc: 0.9387 | Val Loss: 0.1864 Acc: 0.9342\n",
      "Epoch 038 | Train Loss: 0.1476 Acc: 0.9450 | Val Loss: 0.2290 Acc: 0.9118\n",
      "Epoch 039 | Train Loss: 0.1330 Acc: 0.9490 | Val Loss: 0.2007 Acc: 0.9179\n",
      "Epoch 040 | Train Loss: 0.1399 Acc: 0.9465 | Val Loss: 0.1933 Acc: 0.9281\n",
      "Epoch 041 | Train Loss: 0.1414 Acc: 0.9443 | Val Loss: 0.1703 Acc: 0.9402\n",
      "Epoch 042 | Train Loss: 0.1358 Acc: 0.9518 | Val Loss: 0.1774 Acc: 0.9306\n",
      "Epoch 043 | Train Loss: 0.1364 Acc: 0.9485 | Val Loss: 0.1928 Acc: 0.9221\n",
      "Epoch 044 | Train Loss: 0.1253 Acc: 0.9546 | Val Loss: 0.1934 Acc: 0.9245\n",
      "Epoch 045 | Train Loss: 0.1237 Acc: 0.9529 | Val Loss: 0.1451 Acc: 0.9469\n",
      "Epoch 046 | Train Loss: 0.1216 Acc: 0.9555 | Val Loss: 0.1627 Acc: 0.9293\n",
      "Epoch 047 | Train Loss: 0.1234 Acc: 0.9549 | Val Loss: 0.1676 Acc: 0.9390\n",
      "Epoch 048 | Train Loss: 0.1200 Acc: 0.9547 | Val Loss: 0.1763 Acc: 0.9312\n",
      "Epoch 049 | Train Loss: 0.1205 Acc: 0.9543 | Val Loss: 0.1839 Acc: 0.9330\n",
      "Epoch 050 | Train Loss: 0.1072 Acc: 0.9618 | Val Loss: 0.1665 Acc: 0.9469\n",
      "Epoch 051 | Train Loss: 0.1094 Acc: 0.9603 | Val Loss: 0.1583 Acc: 0.9420\n",
      "Epoch 052 | Train Loss: 0.1053 Acc: 0.9613 | Val Loss: 0.1947 Acc: 0.9342\n",
      "Epoch 053 | Train Loss: 0.1114 Acc: 0.9583 | Val Loss: 0.1603 Acc: 0.9372\n",
      "Epoch 054 | Train Loss: 0.1054 Acc: 0.9642 | Val Loss: 0.1916 Acc: 0.9300\n",
      "Epoch 055 | Train Loss: 0.1003 Acc: 0.9627 | Val Loss: 0.1890 Acc: 0.9360\n",
      "Early stopping triggered.\n",
      "Epoch 001 | Train Loss: 0.6756 Acc: 0.5843 | Val Loss: 0.6491 Acc: 0.6431\n",
      "Epoch 002 | Train Loss: 0.6310 Acc: 0.6582 | Val Loss: 0.6098 Acc: 0.6938\n",
      "Epoch 003 | Train Loss: 0.5958 Acc: 0.6923 | Val Loss: 0.5573 Acc: 0.7228\n",
      "Epoch 004 | Train Loss: 0.5745 Acc: 0.7112 | Val Loss: 0.5708 Acc: 0.7174\n",
      "Epoch 005 | Train Loss: 0.5544 Acc: 0.7252 | Val Loss: 0.5386 Acc: 0.7325\n",
      "Epoch 006 | Train Loss: 0.5417 Acc: 0.7309 | Val Loss: 0.5403 Acc: 0.7289\n",
      "Epoch 007 | Train Loss: 0.5286 Acc: 0.7456 | Val Loss: 0.5384 Acc: 0.7301\n",
      "Epoch 008 | Train Loss: 0.5160 Acc: 0.7474 | Val Loss: 0.5162 Acc: 0.7500\n",
      "Epoch 009 | Train Loss: 0.4886 Acc: 0.7646 | Val Loss: 0.4785 Acc: 0.7711\n",
      "Epoch 010 | Train Loss: 0.4831 Acc: 0.7720 | Val Loss: 0.4693 Acc: 0.7681\n",
      "Epoch 011 | Train Loss: 0.4710 Acc: 0.7771 | Val Loss: 0.4851 Acc: 0.7729\n",
      "Epoch 012 | Train Loss: 0.4479 Acc: 0.7879 | Val Loss: 0.4470 Acc: 0.7621\n",
      "Epoch 013 | Train Loss: 0.4411 Acc: 0.7892 | Val Loss: 0.4181 Acc: 0.8025\n",
      "Epoch 014 | Train Loss: 0.4206 Acc: 0.8088 | Val Loss: 0.4469 Acc: 0.7820\n",
      "Epoch 015 | Train Loss: 0.4227 Acc: 0.8110 | Val Loss: 0.3869 Acc: 0.8382\n",
      "Epoch 016 | Train Loss: 0.3952 Acc: 0.8239 | Val Loss: 0.3738 Acc: 0.8370\n",
      "Epoch 017 | Train Loss: 0.3717 Acc: 0.8327 | Val Loss: 0.3803 Acc: 0.8388\n",
      "Epoch 018 | Train Loss: 0.3639 Acc: 0.8436 | Val Loss: 0.3625 Acc: 0.8466\n",
      "Epoch 019 | Train Loss: 0.3421 Acc: 0.8507 | Val Loss: 0.3181 Acc: 0.8696\n",
      "Epoch 020 | Train Loss: 0.3195 Acc: 0.8631 | Val Loss: 0.3351 Acc: 0.8551\n",
      "Epoch 021 | Train Loss: 0.3148 Acc: 0.8671 | Val Loss: 0.3027 Acc: 0.8762\n",
      "Epoch 022 | Train Loss: 0.3046 Acc: 0.8695 | Val Loss: 0.2806 Acc: 0.8816\n",
      "Epoch 023 | Train Loss: 0.3028 Acc: 0.8800 | Val Loss: 0.3203 Acc: 0.8726\n",
      "Epoch 024 | Train Loss: 0.2790 Acc: 0.8868 | Val Loss: 0.2703 Acc: 0.8895\n",
      "Epoch 025 | Train Loss: 0.2748 Acc: 0.8889 | Val Loss: 0.2587 Acc: 0.8913\n",
      "Epoch 026 | Train Loss: 0.2700 Acc: 0.8872 | Val Loss: 0.2420 Acc: 0.8992\n",
      "Epoch 027 | Train Loss: 0.2638 Acc: 0.8889 | Val Loss: 0.2473 Acc: 0.9028\n",
      "Epoch 028 | Train Loss: 0.2505 Acc: 0.8970 | Val Loss: 0.2574 Acc: 0.8919\n",
      "Epoch 029 | Train Loss: 0.2432 Acc: 0.9031 | Val Loss: 0.2613 Acc: 0.8853\n",
      "Epoch 030 | Train Loss: 0.2494 Acc: 0.8990 | Val Loss: 0.2852 Acc: 0.8792\n",
      "Epoch 031 | Train Loss: 0.2383 Acc: 0.9040 | Val Loss: 0.2273 Acc: 0.9149\n",
      "Epoch 032 | Train Loss: 0.2324 Acc: 0.9080 | Val Loss: 0.2335 Acc: 0.9058\n",
      "Epoch 033 | Train Loss: 0.2379 Acc: 0.9065 | Val Loss: 0.2226 Acc: 0.9088\n",
      "Epoch 034 | Train Loss: 0.2251 Acc: 0.9156 | Val Loss: 0.2043 Acc: 0.9239\n",
      "Epoch 035 | Train Loss: 0.2194 Acc: 0.9164 | Val Loss: 0.2228 Acc: 0.9173\n",
      "Epoch 036 | Train Loss: 0.2140 Acc: 0.9132 | Val Loss: 0.2633 Acc: 0.8931\n",
      "Epoch 037 | Train Loss: 0.2052 Acc: 0.9165 | Val Loss: 0.2110 Acc: 0.9155\n",
      "Epoch 038 | Train Loss: 0.2076 Acc: 0.9176 | Val Loss: 0.2064 Acc: 0.9245\n",
      "Epoch 039 | Train Loss: 0.1963 Acc: 0.9247 | Val Loss: 0.2107 Acc: 0.9197\n",
      "Epoch 040 | Train Loss: 0.2004 Acc: 0.9225 | Val Loss: 0.1889 Acc: 0.9251\n",
      "Epoch 041 | Train Loss: 0.1770 Acc: 0.9310 | Val Loss: 0.1980 Acc: 0.9269\n",
      "Epoch 042 | Train Loss: 0.1802 Acc: 0.9324 | Val Loss: 0.2118 Acc: 0.9136\n",
      "Epoch 043 | Train Loss: 0.1795 Acc: 0.9311 | Val Loss: 0.1791 Acc: 0.9318\n",
      "Epoch 044 | Train Loss: 0.1718 Acc: 0.9311 | Val Loss: 0.1877 Acc: 0.9269\n",
      "Epoch 045 | Train Loss: 0.1729 Acc: 0.9358 | Val Loss: 0.1910 Acc: 0.9227\n",
      "Epoch 046 | Train Loss: 0.1855 Acc: 0.9292 | Val Loss: 0.1872 Acc: 0.9330\n",
      "Epoch 047 | Train Loss: 0.1620 Acc: 0.9361 | Val Loss: 0.1912 Acc: 0.9245\n",
      "Epoch 048 | Train Loss: 0.1671 Acc: 0.9354 | Val Loss: 0.1810 Acc: 0.9402\n",
      "Epoch 049 | Train Loss: 0.1676 Acc: 0.9369 | Val Loss: 0.1694 Acc: 0.9378\n",
      "Epoch 050 | Train Loss: 0.1441 Acc: 0.9434 | Val Loss: 0.1927 Acc: 0.9239\n",
      "Epoch 051 | Train Loss: 0.1543 Acc: 0.9401 | Val Loss: 0.1778 Acc: 0.9336\n",
      "Epoch 052 | Train Loss: 0.1622 Acc: 0.9343 | Val Loss: 0.1698 Acc: 0.9287\n",
      "Epoch 053 | Train Loss: 0.1508 Acc: 0.9410 | Val Loss: 0.1716 Acc: 0.9384\n",
      "Epoch 054 | Train Loss: 0.1524 Acc: 0.9453 | Val Loss: 0.1644 Acc: 0.9366\n",
      "Epoch 055 | Train Loss: 0.1455 Acc: 0.9487 | Val Loss: 0.1644 Acc: 0.9354\n",
      "Epoch 056 | Train Loss: 0.1422 Acc: 0.9481 | Val Loss: 0.1995 Acc: 0.9269\n",
      "Epoch 057 | Train Loss: 0.1422 Acc: 0.9461 | Val Loss: 0.1600 Acc: 0.9360\n",
      "Epoch 058 | Train Loss: 0.1631 Acc: 0.9395 | Val Loss: 0.1777 Acc: 0.9275\n",
      "Epoch 059 | Train Loss: 0.1439 Acc: 0.9473 | Val Loss: 0.1803 Acc: 0.9287\n",
      "Epoch 060 | Train Loss: 0.1340 Acc: 0.9479 | Val Loss: 0.1938 Acc: 0.9287\n",
      "Epoch 001 | Train Loss: 0.6813 Acc: 0.5759 | Val Loss: 0.6809 Acc: 0.5779\n",
      "Epoch 002 | Train Loss: 0.6714 Acc: 0.5957 | Val Loss: 0.6633 Acc: 0.5966\n",
      "Epoch 003 | Train Loss: 0.6424 Acc: 0.6431 | Val Loss: 0.6128 Acc: 0.6739\n",
      "Epoch 004 | Train Loss: 0.5971 Acc: 0.6906 | Val Loss: 0.5749 Acc: 0.7077\n",
      "Epoch 005 | Train Loss: 0.5658 Acc: 0.7202 | Val Loss: 0.5864 Acc: 0.6981\n",
      "Epoch 006 | Train Loss: 0.5422 Acc: 0.7308 | Val Loss: 0.5403 Acc: 0.7283\n",
      "Epoch 007 | Train Loss: 0.5314 Acc: 0.7400 | Val Loss: 0.5303 Acc: 0.7313\n",
      "Epoch 008 | Train Loss: 0.5202 Acc: 0.7415 | Val Loss: 0.5224 Acc: 0.7391\n",
      "Epoch 009 | Train Loss: 0.5079 Acc: 0.7522 | Val Loss: 0.5235 Acc: 0.7446\n",
      "Epoch 010 | Train Loss: 0.4917 Acc: 0.7645 | Val Loss: 0.4817 Acc: 0.7615\n",
      "Epoch 011 | Train Loss: 0.4800 Acc: 0.7700 | Val Loss: 0.4805 Acc: 0.7784\n",
      "Epoch 012 | Train Loss: 0.4699 Acc: 0.7697 | Val Loss: 0.4584 Acc: 0.7784\n",
      "Epoch 013 | Train Loss: 0.4584 Acc: 0.7824 | Val Loss: 0.4622 Acc: 0.7742\n",
      "Epoch 014 | Train Loss: 0.4444 Acc: 0.7931 | Val Loss: 0.4258 Acc: 0.7953\n",
      "Epoch 015 | Train Loss: 0.4337 Acc: 0.7921 | Val Loss: 0.4166 Acc: 0.7989\n",
      "Epoch 016 | Train Loss: 0.4239 Acc: 0.8028 | Val Loss: 0.4021 Acc: 0.8116\n",
      "Epoch 017 | Train Loss: 0.4009 Acc: 0.8211 | Val Loss: 0.3898 Acc: 0.8152\n",
      "Epoch 018 | Train Loss: 0.3885 Acc: 0.8182 | Val Loss: 0.3795 Acc: 0.8273\n",
      "Epoch 019 | Train Loss: 0.3804 Acc: 0.8265 | Val Loss: 0.3613 Acc: 0.8285\n",
      "Epoch 020 | Train Loss: 0.3668 Acc: 0.8316 | Val Loss: 0.3552 Acc: 0.8382\n",
      "Epoch 021 | Train Loss: 0.3459 Acc: 0.8493 | Val Loss: 0.3421 Acc: 0.8436\n",
      "Epoch 022 | Train Loss: 0.3455 Acc: 0.8504 | Val Loss: 0.3028 Acc: 0.8641\n",
      "Epoch 023 | Train Loss: 0.3366 Acc: 0.8554 | Val Loss: 0.3219 Acc: 0.8539\n",
      "Epoch 024 | Train Loss: 0.3157 Acc: 0.8611 | Val Loss: 0.2822 Acc: 0.8780\n",
      "Epoch 025 | Train Loss: 0.3077 Acc: 0.8652 | Val Loss: 0.3039 Acc: 0.8774\n",
      "Epoch 026 | Train Loss: 0.2994 Acc: 0.8723 | Val Loss: 0.2805 Acc: 0.8847\n",
      "Epoch 027 | Train Loss: 0.2799 Acc: 0.8812 | Val Loss: 0.2537 Acc: 0.8967\n",
      "Epoch 028 | Train Loss: 0.2843 Acc: 0.8788 | Val Loss: 0.2685 Acc: 0.8853\n",
      "Epoch 029 | Train Loss: 0.2793 Acc: 0.8824 | Val Loss: 0.2584 Acc: 0.8955\n",
      "Epoch 030 | Train Loss: 0.2660 Acc: 0.8920 | Val Loss: 0.2572 Acc: 0.8949\n",
      "Epoch 031 | Train Loss: 0.2579 Acc: 0.8926 | Val Loss: 0.2590 Acc: 0.8901\n",
      "Epoch 032 | Train Loss: 0.2572 Acc: 0.8907 | Val Loss: 0.2442 Acc: 0.9004\n",
      "Epoch 033 | Train Loss: 0.2324 Acc: 0.9058 | Val Loss: 0.2167 Acc: 0.9173\n",
      "Epoch 034 | Train Loss: 0.2391 Acc: 0.8984 | Val Loss: 0.2213 Acc: 0.9167\n",
      "Epoch 035 | Train Loss: 0.2222 Acc: 0.9100 | Val Loss: 0.2140 Acc: 0.9191\n",
      "Epoch 036 | Train Loss: 0.2267 Acc: 0.9093 | Val Loss: 0.2342 Acc: 0.9058\n",
      "Epoch 037 | Train Loss: 0.2230 Acc: 0.9100 | Val Loss: 0.2229 Acc: 0.9088\n",
      "Epoch 038 | Train Loss: 0.2130 Acc: 0.9117 | Val Loss: 0.2229 Acc: 0.9052\n",
      "Epoch 039 | Train Loss: 0.2034 Acc: 0.9174 | Val Loss: 0.2115 Acc: 0.9173\n",
      "Epoch 040 | Train Loss: 0.2017 Acc: 0.9173 | Val Loss: 0.2114 Acc: 0.9185\n",
      "Epoch 041 | Train Loss: 0.1987 Acc: 0.9238 | Val Loss: 0.1995 Acc: 0.9209\n",
      "Epoch 042 | Train Loss: 0.1891 Acc: 0.9238 | Val Loss: 0.2568 Acc: 0.8961\n",
      "Epoch 043 | Train Loss: 0.1901 Acc: 0.9248 | Val Loss: 0.2189 Acc: 0.9100\n",
      "Epoch 044 | Train Loss: 0.1920 Acc: 0.9250 | Val Loss: 0.2008 Acc: 0.9197\n",
      "Epoch 045 | Train Loss: 0.1830 Acc: 0.9250 | Val Loss: 0.2030 Acc: 0.9227\n",
      "Epoch 046 | Train Loss: 0.1850 Acc: 0.9231 | Val Loss: 0.1981 Acc: 0.9251\n",
      "Epoch 047 | Train Loss: 0.1737 Acc: 0.9286 | Val Loss: 0.1904 Acc: 0.9306\n",
      "Epoch 048 | Train Loss: 0.1644 Acc: 0.9375 | Val Loss: 0.1717 Acc: 0.9378\n",
      "Epoch 049 | Train Loss: 0.1633 Acc: 0.9367 | Val Loss: 0.1685 Acc: 0.9360\n",
      "Epoch 050 | Train Loss: 0.1635 Acc: 0.9366 | Val Loss: 0.1817 Acc: 0.9336\n",
      "Epoch 051 | Train Loss: 0.1639 Acc: 0.9360 | Val Loss: 0.1866 Acc: 0.9324\n",
      "Epoch 052 | Train Loss: 0.1586 Acc: 0.9390 | Val Loss: 0.1528 Acc: 0.9408\n",
      "Epoch 053 | Train Loss: 0.1514 Acc: 0.9379 | Val Loss: 0.1930 Acc: 0.9269\n",
      "Epoch 054 | Train Loss: 0.1505 Acc: 0.9395 | Val Loss: 0.1604 Acc: 0.9396\n",
      "Epoch 055 | Train Loss: 0.1432 Acc: 0.9435 | Val Loss: 0.1613 Acc: 0.9372\n",
      "Epoch 056 | Train Loss: 0.1468 Acc: 0.9431 | Val Loss: 0.1597 Acc: 0.9372\n",
      "Epoch 057 | Train Loss: 0.1355 Acc: 0.9465 | Val Loss: 0.1718 Acc: 0.9348\n",
      "Epoch 058 | Train Loss: 0.1405 Acc: 0.9440 | Val Loss: 0.1743 Acc: 0.9360\n",
      "Epoch 059 | Train Loss: 0.1424 Acc: 0.9446 | Val Loss: 0.1582 Acc: 0.9390\n",
      "Epoch 060 | Train Loss: 0.1400 Acc: 0.9434 | Val Loss: 0.1700 Acc: 0.9330\n",
      "Epoch 001 | Train Loss: 0.6826 Acc: 0.5686 | Val Loss: 0.6785 Acc: 0.5809\n",
      "Epoch 002 | Train Loss: 0.6472 Acc: 0.6296 | Val Loss: 0.6311 Acc: 0.6467\n",
      "Epoch 003 | Train Loss: 0.5858 Acc: 0.7048 | Val Loss: 0.5823 Acc: 0.7029\n",
      "Epoch 004 | Train Loss: 0.5700 Acc: 0.7186 | Val Loss: 0.5640 Acc: 0.7017\n",
      "Epoch 005 | Train Loss: 0.5413 Acc: 0.7358 | Val Loss: 0.5566 Acc: 0.7198\n",
      "Epoch 006 | Train Loss: 0.5148 Acc: 0.7459 | Val Loss: 0.5013 Acc: 0.7482\n",
      "Epoch 007 | Train Loss: 0.4942 Acc: 0.7625 | Val Loss: 0.4992 Acc: 0.7524\n",
      "Epoch 008 | Train Loss: 0.4662 Acc: 0.7814 | Val Loss: 0.4575 Acc: 0.7675\n",
      "Epoch 009 | Train Loss: 0.4466 Acc: 0.7915 | Val Loss: 0.4569 Acc: 0.7905\n",
      "Epoch 010 | Train Loss: 0.4071 Acc: 0.8175 | Val Loss: 0.4535 Acc: 0.8013\n",
      "Epoch 011 | Train Loss: 0.3980 Acc: 0.8268 | Val Loss: 0.4037 Acc: 0.8188\n",
      "Epoch 012 | Train Loss: 0.3702 Acc: 0.8354 | Val Loss: 0.4043 Acc: 0.8291\n",
      "Epoch 013 | Train Loss: 0.3366 Acc: 0.8584 | Val Loss: 0.3425 Acc: 0.8466\n",
      "Epoch 014 | Train Loss: 0.3142 Acc: 0.8664 | Val Loss: 0.3111 Acc: 0.8744\n",
      "Epoch 015 | Train Loss: 0.2934 Acc: 0.8807 | Val Loss: 0.3418 Acc: 0.8448\n",
      "Epoch 016 | Train Loss: 0.2773 Acc: 0.8846 | Val Loss: 0.2750 Acc: 0.8895\n",
      "Epoch 017 | Train Loss: 0.2503 Acc: 0.8984 | Val Loss: 0.2918 Acc: 0.8798\n",
      "Epoch 018 | Train Loss: 0.2604 Acc: 0.8940 | Val Loss: 0.2475 Acc: 0.8992\n",
      "Epoch 019 | Train Loss: 0.2135 Acc: 0.9129 | Val Loss: 0.2514 Acc: 0.8979\n",
      "Epoch 020 | Train Loss: 0.2253 Acc: 0.9112 | Val Loss: 0.2336 Acc: 0.9016\n",
      "Epoch 021 | Train Loss: 0.2019 Acc: 0.9198 | Val Loss: 0.2305 Acc: 0.9112\n",
      "Epoch 022 | Train Loss: 0.2174 Acc: 0.9141 | Val Loss: 0.2104 Acc: 0.9124\n",
      "Epoch 023 | Train Loss: 0.1883 Acc: 0.9269 | Val Loss: 0.2054 Acc: 0.9143\n",
      "Epoch 024 | Train Loss: 0.1828 Acc: 0.9275 | Val Loss: 0.1932 Acc: 0.9269\n",
      "Epoch 025 | Train Loss: 0.1834 Acc: 0.9301 | Val Loss: 0.1928 Acc: 0.9221\n",
      "Epoch 026 | Train Loss: 0.1811 Acc: 0.9281 | Val Loss: 0.2109 Acc: 0.9076\n",
      "Epoch 027 | Train Loss: 0.1618 Acc: 0.9398 | Val Loss: 0.1948 Acc: 0.9179\n",
      "Epoch 028 | Train Loss: 0.1621 Acc: 0.9401 | Val Loss: 0.1998 Acc: 0.9191\n",
      "Epoch 029 | Train Loss: 0.1551 Acc: 0.9405 | Val Loss: 0.1740 Acc: 0.9330\n",
      "Epoch 030 | Train Loss: 0.1549 Acc: 0.9367 | Val Loss: 0.1841 Acc: 0.9263\n",
      "Epoch 031 | Train Loss: 0.1397 Acc: 0.9467 | Val Loss: 0.1696 Acc: 0.9348\n",
      "Epoch 032 | Train Loss: 0.1380 Acc: 0.9478 | Val Loss: 0.2122 Acc: 0.9173\n",
      "Epoch 033 | Train Loss: 0.1380 Acc: 0.9449 | Val Loss: 0.1785 Acc: 0.9336\n",
      "Epoch 034 | Train Loss: 0.1322 Acc: 0.9496 | Val Loss: 0.1847 Acc: 0.9378\n",
      "Epoch 035 | Train Loss: 0.1392 Acc: 0.9467 | Val Loss: 0.1767 Acc: 0.9300\n",
      "Epoch 036 | Train Loss: 0.1169 Acc: 0.9517 | Val Loss: 0.1938 Acc: 0.9281\n",
      "Epoch 037 | Train Loss: 0.1383 Acc: 0.9452 | Val Loss: 0.1757 Acc: 0.9293\n",
      "Epoch 038 | Train Loss: 0.1163 Acc: 0.9552 | Val Loss: 0.1914 Acc: 0.9287\n",
      "Epoch 039 | Train Loss: 0.1184 Acc: 0.9570 | Val Loss: 0.1724 Acc: 0.9300\n",
      "Epoch 040 | Train Loss: 0.1144 Acc: 0.9556 | Val Loss: 0.1822 Acc: 0.9336\n",
      "Epoch 041 | Train Loss: 0.1086 Acc: 0.9601 | Val Loss: 0.1802 Acc: 0.9300\n",
      "Early stopping triggered.\n",
      "Iteration 10/40 | Best Val Loss: 0.1259 | Iter Time: 221.94s | Total Time: 49.73 min\n",
      "Epoch 001 | Train Loss: 0.6835 Acc: 0.5726 | Val Loss: 0.6760 Acc: 0.5894\n",
      "Epoch 002 | Train Loss: 0.6722 Acc: 0.5913 | Val Loss: 0.6661 Acc: 0.5990\n",
      "Epoch 003 | Train Loss: 0.6570 Acc: 0.6123 | Val Loss: 0.6485 Acc: 0.6377\n",
      "Epoch 004 | Train Loss: 0.6381 Acc: 0.6520 | Val Loss: 0.6233 Acc: 0.6606\n",
      "Epoch 005 | Train Loss: 0.5920 Acc: 0.7009 | Val Loss: 0.5721 Acc: 0.7114\n",
      "Epoch 006 | Train Loss: 0.5599 Acc: 0.7272 | Val Loss: 0.5564 Acc: 0.7198\n",
      "Epoch 007 | Train Loss: 0.5581 Acc: 0.7228 | Val Loss: 0.5445 Acc: 0.7258\n",
      "Epoch 008 | Train Loss: 0.5308 Acc: 0.7478 | Val Loss: 0.5552 Acc: 0.7180\n",
      "Epoch 009 | Train Loss: 0.5260 Acc: 0.7460 | Val Loss: 0.5430 Acc: 0.7295\n",
      "Epoch 010 | Train Loss: 0.5105 Acc: 0.7562 | Val Loss: 0.5700 Acc: 0.7319\n",
      "Epoch 011 | Train Loss: 0.5067 Acc: 0.7586 | Val Loss: 0.5089 Acc: 0.7470\n",
      "Epoch 012 | Train Loss: 0.4794 Acc: 0.7720 | Val Loss: 0.5175 Acc: 0.7403\n",
      "Epoch 013 | Train Loss: 0.4657 Acc: 0.7818 | Val Loss: 0.4785 Acc: 0.7748\n",
      "Epoch 014 | Train Loss: 0.4537 Acc: 0.7907 | Val Loss: 0.4741 Acc: 0.7585\n",
      "Epoch 015 | Train Loss: 0.4291 Acc: 0.8022 | Val Loss: 0.4669 Acc: 0.7723\n",
      "Epoch 016 | Train Loss: 0.4257 Acc: 0.8007 | Val Loss: 0.4568 Acc: 0.7778\n",
      "Epoch 017 | Train Loss: 0.4103 Acc: 0.8132 | Val Loss: 0.4143 Acc: 0.7995\n",
      "Epoch 018 | Train Loss: 0.4002 Acc: 0.8214 | Val Loss: 0.3832 Acc: 0.8182\n",
      "Epoch 019 | Train Loss: 0.3714 Acc: 0.8277 | Val Loss: 0.4076 Acc: 0.7971\n",
      "Epoch 020 | Train Loss: 0.3597 Acc: 0.8386 | Val Loss: 0.3637 Acc: 0.8406\n",
      "Epoch 021 | Train Loss: 0.3440 Acc: 0.8499 | Val Loss: 0.3341 Acc: 0.8454\n",
      "Epoch 022 | Train Loss: 0.3372 Acc: 0.8492 | Val Loss: 0.3417 Acc: 0.8502\n",
      "Epoch 023 | Train Loss: 0.3262 Acc: 0.8608 | Val Loss: 0.3406 Acc: 0.8484\n",
      "Epoch 024 | Train Loss: 0.3063 Acc: 0.8701 | Val Loss: 0.2956 Acc: 0.8780\n",
      "Epoch 025 | Train Loss: 0.3003 Acc: 0.8732 | Val Loss: 0.3059 Acc: 0.8696\n",
      "Epoch 026 | Train Loss: 0.2822 Acc: 0.8871 | Val Loss: 0.3229 Acc: 0.8593\n",
      "Epoch 027 | Train Loss: 0.2697 Acc: 0.8895 | Val Loss: 0.2742 Acc: 0.8829\n",
      "Epoch 028 | Train Loss: 0.2606 Acc: 0.8936 | Val Loss: 0.2822 Acc: 0.8768\n",
      "Epoch 029 | Train Loss: 0.2461 Acc: 0.8940 | Val Loss: 0.2618 Acc: 0.8877\n",
      "Epoch 030 | Train Loss: 0.2383 Acc: 0.9047 | Val Loss: 0.2560 Acc: 0.8961\n",
      "Epoch 031 | Train Loss: 0.2392 Acc: 0.8988 | Val Loss: 0.2494 Acc: 0.8967\n",
      "Epoch 032 | Train Loss: 0.2146 Acc: 0.9148 | Val Loss: 0.2528 Acc: 0.8967\n",
      "Epoch 033 | Train Loss: 0.2191 Acc: 0.9123 | Val Loss: 0.2402 Acc: 0.9016\n",
      "Epoch 034 | Train Loss: 0.2008 Acc: 0.9197 | Val Loss: 0.2529 Acc: 0.8967\n",
      "Epoch 035 | Train Loss: 0.1994 Acc: 0.9245 | Val Loss: 0.2526 Acc: 0.8992\n",
      "Epoch 036 | Train Loss: 0.1945 Acc: 0.9236 | Val Loss: 0.2129 Acc: 0.9173\n",
      "Epoch 037 | Train Loss: 0.1779 Acc: 0.9290 | Val Loss: 0.2218 Acc: 0.9191\n",
      "Epoch 038 | Train Loss: 0.1769 Acc: 0.9296 | Val Loss: 0.2023 Acc: 0.9155\n",
      "Epoch 039 | Train Loss: 0.1685 Acc: 0.9336 | Val Loss: 0.2275 Acc: 0.9143\n",
      "Epoch 040 | Train Loss: 0.1668 Acc: 0.9343 | Val Loss: 0.2003 Acc: 0.9227\n",
      "Epoch 041 | Train Loss: 0.1656 Acc: 0.9349 | Val Loss: 0.1939 Acc: 0.9245\n",
      "Epoch 042 | Train Loss: 0.1556 Acc: 0.9401 | Val Loss: 0.2104 Acc: 0.9155\n",
      "Epoch 043 | Train Loss: 0.1595 Acc: 0.9348 | Val Loss: 0.2181 Acc: 0.9106\n",
      "Epoch 044 | Train Loss: 0.1510 Acc: 0.9402 | Val Loss: 0.2135 Acc: 0.9167\n",
      "Epoch 045 | Train Loss: 0.1344 Acc: 0.9490 | Val Loss: 0.1986 Acc: 0.9257\n",
      "Epoch 046 | Train Loss: 0.1442 Acc: 0.9435 | Val Loss: 0.1933 Acc: 0.9209\n",
      "Epoch 047 | Train Loss: 0.1345 Acc: 0.9447 | Val Loss: 0.1947 Acc: 0.9312\n",
      "Epoch 048 | Train Loss: 0.1315 Acc: 0.9481 | Val Loss: 0.1891 Acc: 0.9239\n",
      "Epoch 049 | Train Loss: 0.1330 Acc: 0.9503 | Val Loss: 0.1777 Acc: 0.9245\n",
      "Epoch 050 | Train Loss: 0.1283 Acc: 0.9512 | Val Loss: 0.2183 Acc: 0.9106\n",
      "Epoch 051 | Train Loss: 0.1298 Acc: 0.9506 | Val Loss: 0.1750 Acc: 0.9348\n",
      "Epoch 052 | Train Loss: 0.1193 Acc: 0.9539 | Val Loss: 0.1810 Acc: 0.9257\n",
      "Epoch 053 | Train Loss: 0.1162 Acc: 0.9555 | Val Loss: 0.1824 Acc: 0.9342\n",
      "Epoch 054 | Train Loss: 0.1171 Acc: 0.9556 | Val Loss: 0.1899 Acc: 0.9239\n",
      "Epoch 055 | Train Loss: 0.1066 Acc: 0.9607 | Val Loss: 0.1811 Acc: 0.9360\n",
      "Epoch 056 | Train Loss: 0.1137 Acc: 0.9546 | Val Loss: 0.1570 Acc: 0.9438\n",
      "Epoch 057 | Train Loss: 0.1040 Acc: 0.9621 | Val Loss: 0.1650 Acc: 0.9390\n",
      "Epoch 058 | Train Loss: 0.1078 Acc: 0.9600 | Val Loss: 0.1568 Acc: 0.9444\n",
      "Epoch 059 | Train Loss: 0.1034 Acc: 0.9638 | Val Loss: 0.1819 Acc: 0.9330\n",
      "Epoch 060 | Train Loss: 0.1191 Acc: 0.9555 | Val Loss: 0.1668 Acc: 0.9402\n",
      "Epoch 001 | Train Loss: 0.6818 Acc: 0.5735 | Val Loss: 0.6751 Acc: 0.5924\n",
      "Epoch 002 | Train Loss: 0.6815 Acc: 0.5744 | Val Loss: 0.6810 Acc: 0.5779\n",
      "Epoch 003 | Train Loss: 0.6721 Acc: 0.5925 | Val Loss: 0.6685 Acc: 0.5972\n",
      "Epoch 004 | Train Loss: 0.6679 Acc: 0.5996 | Val Loss: 0.6660 Acc: 0.6057\n",
      "Epoch 005 | Train Loss: 0.6513 Acc: 0.6274 | Val Loss: 0.6283 Acc: 0.6606\n",
      "Epoch 006 | Train Loss: 0.6054 Acc: 0.6935 | Val Loss: 0.5741 Acc: 0.7059\n",
      "Epoch 007 | Train Loss: 0.5680 Acc: 0.7134 | Val Loss: 0.5484 Acc: 0.7252\n",
      "Epoch 008 | Train Loss: 0.5550 Acc: 0.7263 | Val Loss: 0.5465 Acc: 0.7234\n",
      "Epoch 009 | Train Loss: 0.5327 Acc: 0.7447 | Val Loss: 0.5412 Acc: 0.7289\n",
      "Epoch 010 | Train Loss: 0.5263 Acc: 0.7537 | Val Loss: 0.5339 Acc: 0.7391\n",
      "Epoch 011 | Train Loss: 0.5119 Acc: 0.7548 | Val Loss: 0.5096 Acc: 0.7482\n",
      "Epoch 012 | Train Loss: 0.5041 Acc: 0.7625 | Val Loss: 0.5163 Acc: 0.7530\n",
      "Epoch 013 | Train Loss: 0.4822 Acc: 0.7696 | Val Loss: 0.4930 Acc: 0.7566\n",
      "Epoch 014 | Train Loss: 0.4650 Acc: 0.7836 | Val Loss: 0.4789 Acc: 0.7663\n",
      "Epoch 015 | Train Loss: 0.4484 Acc: 0.7924 | Val Loss: 0.4340 Acc: 0.7971\n",
      "Epoch 016 | Train Loss: 0.4313 Acc: 0.7974 | Val Loss: 0.4644 Acc: 0.7729\n",
      "Epoch 017 | Train Loss: 0.4156 Acc: 0.8132 | Val Loss: 0.4347 Acc: 0.7784\n",
      "Epoch 018 | Train Loss: 0.3859 Acc: 0.8267 | Val Loss: 0.3805 Acc: 0.8152\n",
      "Epoch 019 | Train Loss: 0.3763 Acc: 0.8286 | Val Loss: 0.4393 Acc: 0.8110\n",
      "Epoch 020 | Train Loss: 0.3584 Acc: 0.8427 | Val Loss: 0.4462 Acc: 0.7754\n",
      "Epoch 021 | Train Loss: 0.3330 Acc: 0.8560 | Val Loss: 0.3337 Acc: 0.8496\n",
      "Epoch 022 | Train Loss: 0.3177 Acc: 0.8621 | Val Loss: 0.3141 Acc: 0.8569\n",
      "Epoch 023 | Train Loss: 0.2989 Acc: 0.8717 | Val Loss: 0.3001 Acc: 0.8696\n",
      "Epoch 024 | Train Loss: 0.2847 Acc: 0.8815 | Val Loss: 0.2911 Acc: 0.8774\n",
      "Epoch 025 | Train Loss: 0.2760 Acc: 0.8830 | Val Loss: 0.2961 Acc: 0.8678\n",
      "Epoch 026 | Train Loss: 0.2614 Acc: 0.8934 | Val Loss: 0.2600 Acc: 0.8829\n",
      "Epoch 027 | Train Loss: 0.2562 Acc: 0.8945 | Val Loss: 0.2850 Acc: 0.8714\n",
      "Epoch 028 | Train Loss: 0.2356 Acc: 0.9050 | Val Loss: 0.2526 Acc: 0.8937\n",
      "Epoch 029 | Train Loss: 0.2295 Acc: 0.9087 | Val Loss: 0.2562 Acc: 0.8907\n",
      "Epoch 030 | Train Loss: 0.2157 Acc: 0.9135 | Val Loss: 0.2194 Acc: 0.9088\n",
      "Epoch 031 | Train Loss: 0.2116 Acc: 0.9144 | Val Loss: 0.2180 Acc: 0.9100\n",
      "Epoch 032 | Train Loss: 0.2025 Acc: 0.9201 | Val Loss: 0.2232 Acc: 0.9149\n",
      "Epoch 033 | Train Loss: 0.1965 Acc: 0.9222 | Val Loss: 0.2250 Acc: 0.9052\n",
      "Epoch 034 | Train Loss: 0.1819 Acc: 0.9284 | Val Loss: 0.2152 Acc: 0.9094\n",
      "Epoch 035 | Train Loss: 0.1792 Acc: 0.9296 | Val Loss: 0.1985 Acc: 0.9161\n",
      "Epoch 036 | Train Loss: 0.1684 Acc: 0.9361 | Val Loss: 0.1806 Acc: 0.9269\n",
      "Epoch 037 | Train Loss: 0.1735 Acc: 0.9331 | Val Loss: 0.1995 Acc: 0.9185\n",
      "Epoch 038 | Train Loss: 0.1597 Acc: 0.9331 | Val Loss: 0.1939 Acc: 0.9209\n",
      "Epoch 039 | Train Loss: 0.1498 Acc: 0.9426 | Val Loss: 0.2037 Acc: 0.9161\n",
      "Epoch 040 | Train Loss: 0.1467 Acc: 0.9434 | Val Loss: 0.2048 Acc: 0.9197\n",
      "Epoch 041 | Train Loss: 0.1572 Acc: 0.9388 | Val Loss: 0.1702 Acc: 0.9306\n",
      "Epoch 042 | Train Loss: 0.1422 Acc: 0.9456 | Val Loss: 0.2000 Acc: 0.9179\n",
      "Epoch 043 | Train Loss: 0.1257 Acc: 0.9541 | Val Loss: 0.1797 Acc: 0.9330\n",
      "Epoch 044 | Train Loss: 0.1282 Acc: 0.9546 | Val Loss: 0.2151 Acc: 0.9203\n",
      "Epoch 045 | Train Loss: 0.1356 Acc: 0.9476 | Val Loss: 0.1680 Acc: 0.9348\n",
      "Epoch 046 | Train Loss: 0.1369 Acc: 0.9488 | Val Loss: 0.1931 Acc: 0.9251\n",
      "Epoch 047 | Train Loss: 0.1291 Acc: 0.9518 | Val Loss: 0.1716 Acc: 0.9366\n",
      "Epoch 048 | Train Loss: 0.1199 Acc: 0.9543 | Val Loss: 0.2425 Acc: 0.9040\n",
      "Epoch 049 | Train Loss: 0.1285 Acc: 0.9520 | Val Loss: 0.1734 Acc: 0.9348\n",
      "Epoch 050 | Train Loss: 0.1142 Acc: 0.9571 | Val Loss: 0.1820 Acc: 0.9372\n",
      "Epoch 051 | Train Loss: 0.1102 Acc: 0.9589 | Val Loss: 0.1720 Acc: 0.9336\n",
      "Epoch 052 | Train Loss: 0.1002 Acc: 0.9632 | Val Loss: 0.1761 Acc: 0.9330\n",
      "Epoch 053 | Train Loss: 0.1101 Acc: 0.9586 | Val Loss: 0.1646 Acc: 0.9420\n",
      "Epoch 054 | Train Loss: 0.0919 Acc: 0.9653 | Val Loss: 0.1670 Acc: 0.9372\n",
      "Epoch 055 | Train Loss: 0.1005 Acc: 0.9620 | Val Loss: 0.1799 Acc: 0.9348\n",
      "Epoch 056 | Train Loss: 0.1013 Acc: 0.9645 | Val Loss: 0.1850 Acc: 0.9360\n",
      "Epoch 057 | Train Loss: 0.0955 Acc: 0.9651 | Val Loss: 0.2016 Acc: 0.9263\n",
      "Epoch 058 | Train Loss: 0.0975 Acc: 0.9651 | Val Loss: 0.1779 Acc: 0.9414\n",
      "Epoch 059 | Train Loss: 0.0921 Acc: 0.9669 | Val Loss: 0.1900 Acc: 0.9306\n",
      "Epoch 060 | Train Loss: 0.0876 Acc: 0.9639 | Val Loss: 0.1754 Acc: 0.9384\n",
      "Epoch 001 | Train Loss: 0.6852 Acc: 0.5670 | Val Loss: 0.6780 Acc: 0.5882\n",
      "Epoch 002 | Train Loss: 0.6746 Acc: 0.5923 | Val Loss: 0.6759 Acc: 0.5785\n",
      "Epoch 003 | Train Loss: 0.6614 Acc: 0.6070 | Val Loss: 0.6578 Acc: 0.6377\n",
      "Epoch 004 | Train Loss: 0.6143 Acc: 0.6775 | Val Loss: 0.5911 Acc: 0.7041\n",
      "Epoch 005 | Train Loss: 0.5642 Acc: 0.7151 | Val Loss: 0.5576 Acc: 0.7162\n",
      "Epoch 006 | Train Loss: 0.5309 Acc: 0.7432 | Val Loss: 0.5097 Acc: 0.7452\n",
      "Epoch 007 | Train Loss: 0.5176 Acc: 0.7524 | Val Loss: 0.5244 Acc: 0.7536\n",
      "Epoch 008 | Train Loss: 0.4929 Acc: 0.7666 | Val Loss: 0.4921 Acc: 0.7609\n",
      "Epoch 009 | Train Loss: 0.4704 Acc: 0.7799 | Val Loss: 0.4387 Acc: 0.7935\n",
      "Epoch 010 | Train Loss: 0.4413 Acc: 0.7974 | Val Loss: 0.4273 Acc: 0.8050\n",
      "Epoch 011 | Train Loss: 0.4241 Acc: 0.8096 | Val Loss: 0.4040 Acc: 0.8031\n",
      "Epoch 012 | Train Loss: 0.3997 Acc: 0.8238 | Val Loss: 0.3757 Acc: 0.8315\n",
      "Epoch 013 | Train Loss: 0.3823 Acc: 0.8280 | Val Loss: 0.3600 Acc: 0.8321\n",
      "Epoch 014 | Train Loss: 0.3608 Acc: 0.8407 | Val Loss: 0.3262 Acc: 0.8502\n",
      "Epoch 015 | Train Loss: 0.3274 Acc: 0.8554 | Val Loss: 0.3158 Acc: 0.8557\n",
      "Epoch 016 | Train Loss: 0.3102 Acc: 0.8679 | Val Loss: 0.3017 Acc: 0.8696\n",
      "Epoch 017 | Train Loss: 0.2996 Acc: 0.8751 | Val Loss: 0.2920 Acc: 0.8738\n",
      "Epoch 018 | Train Loss: 0.2700 Acc: 0.8877 | Val Loss: 0.2798 Acc: 0.8847\n",
      "Epoch 019 | Train Loss: 0.2685 Acc: 0.8884 | Val Loss: 0.2618 Acc: 0.8967\n",
      "Epoch 020 | Train Loss: 0.2515 Acc: 0.8948 | Val Loss: 0.2846 Acc: 0.8841\n",
      "Epoch 021 | Train Loss: 0.2231 Acc: 0.9061 | Val Loss: 0.2372 Acc: 0.8998\n",
      "Epoch 022 | Train Loss: 0.2263 Acc: 0.9067 | Val Loss: 0.2449 Acc: 0.8943\n",
      "Epoch 023 | Train Loss: 0.2225 Acc: 0.9090 | Val Loss: 0.2203 Acc: 0.9052\n",
      "Epoch 024 | Train Loss: 0.2004 Acc: 0.9201 | Val Loss: 0.2349 Acc: 0.9022\n",
      "Epoch 025 | Train Loss: 0.1998 Acc: 0.9188 | Val Loss: 0.2675 Acc: 0.8889\n",
      "Epoch 026 | Train Loss: 0.2014 Acc: 0.9189 | Val Loss: 0.2324 Acc: 0.9010\n",
      "Epoch 027 | Train Loss: 0.1811 Acc: 0.9321 | Val Loss: 0.2068 Acc: 0.9143\n",
      "Epoch 028 | Train Loss: 0.1618 Acc: 0.9379 | Val Loss: 0.2056 Acc: 0.9203\n",
      "Epoch 029 | Train Loss: 0.1735 Acc: 0.9321 | Val Loss: 0.1975 Acc: 0.9191\n",
      "Epoch 030 | Train Loss: 0.1674 Acc: 0.9370 | Val Loss: 0.2109 Acc: 0.9185\n",
      "Epoch 031 | Train Loss: 0.1561 Acc: 0.9372 | Val Loss: 0.1987 Acc: 0.9191\n",
      "Epoch 032 | Train Loss: 0.1497 Acc: 0.9399 | Val Loss: 0.1989 Acc: 0.9203\n",
      "Epoch 033 | Train Loss: 0.1426 Acc: 0.9453 | Val Loss: 0.1892 Acc: 0.9275\n",
      "Epoch 034 | Train Loss: 0.1366 Acc: 0.9482 | Val Loss: 0.1902 Acc: 0.9245\n",
      "Epoch 035 | Train Loss: 0.1348 Acc: 0.9487 | Val Loss: 0.1737 Acc: 0.9336\n",
      "Epoch 036 | Train Loss: 0.1334 Acc: 0.9491 | Val Loss: 0.1602 Acc: 0.9402\n",
      "Epoch 037 | Train Loss: 0.1241 Acc: 0.9520 | Val Loss: 0.1602 Acc: 0.9463\n",
      "Epoch 038 | Train Loss: 0.1162 Acc: 0.9556 | Val Loss: 0.1807 Acc: 0.9300\n",
      "Epoch 039 | Train Loss: 0.1207 Acc: 0.9538 | Val Loss: 0.1783 Acc: 0.9360\n",
      "Epoch 040 | Train Loss: 0.1296 Acc: 0.9499 | Val Loss: 0.1727 Acc: 0.9318\n",
      "Epoch 041 | Train Loss: 0.1095 Acc: 0.9592 | Val Loss: 0.1578 Acc: 0.9378\n",
      "Epoch 042 | Train Loss: 0.1071 Acc: 0.9613 | Val Loss: 0.1641 Acc: 0.9426\n",
      "Epoch 043 | Train Loss: 0.0941 Acc: 0.9663 | Val Loss: 0.1734 Acc: 0.9432\n",
      "Epoch 044 | Train Loss: 0.0980 Acc: 0.9624 | Val Loss: 0.1816 Acc: 0.9384\n",
      "Epoch 045 | Train Loss: 0.1080 Acc: 0.9588 | Val Loss: 0.1797 Acc: 0.9318\n",
      "Epoch 046 | Train Loss: 0.1031 Acc: 0.9623 | Val Loss: 0.1897 Acc: 0.9354\n",
      "Epoch 047 | Train Loss: 0.0969 Acc: 0.9641 | Val Loss: 0.1844 Acc: 0.9378\n",
      "Epoch 048 | Train Loss: 0.0987 Acc: 0.9653 | Val Loss: 0.1567 Acc: 0.9450\n",
      "Epoch 049 | Train Loss: 0.0836 Acc: 0.9675 | Val Loss: 0.1887 Acc: 0.9378\n",
      "Epoch 050 | Train Loss: 0.1001 Acc: 0.9585 | Val Loss: 0.1672 Acc: 0.9366\n",
      "Epoch 051 | Train Loss: 0.0872 Acc: 0.9684 | Val Loss: 0.1794 Acc: 0.9366\n",
      "Epoch 052 | Train Loss: 0.0848 Acc: 0.9666 | Val Loss: 0.1521 Acc: 0.9475\n",
      "Epoch 053 | Train Loss: 0.0802 Acc: 0.9697 | Val Loss: 0.1800 Acc: 0.9402\n",
      "Epoch 054 | Train Loss: 0.0825 Acc: 0.9677 | Val Loss: 0.1499 Acc: 0.9426\n",
      "Epoch 055 | Train Loss: 0.0838 Acc: 0.9689 | Val Loss: 0.1650 Acc: 0.9420\n",
      "Epoch 056 | Train Loss: 0.0825 Acc: 0.9689 | Val Loss: 0.1554 Acc: 0.9481\n",
      "Epoch 057 | Train Loss: 0.0773 Acc: 0.9716 | Val Loss: 0.1515 Acc: 0.9450\n",
      "Epoch 058 | Train Loss: 0.0865 Acc: 0.9692 | Val Loss: 0.1803 Acc: 0.9396\n",
      "Epoch 059 | Train Loss: 0.0697 Acc: 0.9766 | Val Loss: 0.1596 Acc: 0.9487\n",
      "Epoch 060 | Train Loss: 0.0774 Acc: 0.9721 | Val Loss: 0.1733 Acc: 0.9426\n",
      "Epoch 001 | Train Loss: 0.6854 Acc: 0.5617 | Val Loss: 0.6764 Acc: 0.5888\n",
      "Epoch 002 | Train Loss: 0.6787 Acc: 0.5887 | Val Loss: 0.6791 Acc: 0.5743\n",
      "Epoch 003 | Train Loss: 0.6697 Acc: 0.6008 | Val Loss: 0.6679 Acc: 0.5912\n",
      "Epoch 004 | Train Loss: 0.6629 Acc: 0.6073 | Val Loss: 0.6599 Acc: 0.6178\n",
      "Epoch 005 | Train Loss: 0.6389 Acc: 0.6447 | Val Loss: 0.6036 Acc: 0.6950\n",
      "Epoch 006 | Train Loss: 0.6057 Acc: 0.6914 | Val Loss: 0.5776 Acc: 0.7114\n",
      "Epoch 007 | Train Loss: 0.5744 Acc: 0.7177 | Val Loss: 0.5572 Acc: 0.7192\n",
      "Epoch 008 | Train Loss: 0.5586 Acc: 0.7306 | Val Loss: 0.5601 Acc: 0.7204\n",
      "Epoch 009 | Train Loss: 0.5542 Acc: 0.7276 | Val Loss: 0.5555 Acc: 0.7283\n",
      "Epoch 010 | Train Loss: 0.5358 Acc: 0.7430 | Val Loss: 0.5443 Acc: 0.7180\n",
      "Epoch 011 | Train Loss: 0.5294 Acc: 0.7456 | Val Loss: 0.5559 Acc: 0.7162\n",
      "Epoch 012 | Train Loss: 0.5247 Acc: 0.7454 | Val Loss: 0.5202 Acc: 0.7482\n",
      "Epoch 013 | Train Loss: 0.5171 Acc: 0.7530 | Val Loss: 0.5130 Acc: 0.7446\n",
      "Epoch 014 | Train Loss: 0.5004 Acc: 0.7628 | Val Loss: 0.5006 Acc: 0.7566\n",
      "Epoch 015 | Train Loss: 0.4928 Acc: 0.7640 | Val Loss: 0.4890 Acc: 0.7554\n",
      "Epoch 016 | Train Loss: 0.4832 Acc: 0.7722 | Val Loss: 0.4727 Acc: 0.7729\n",
      "Epoch 017 | Train Loss: 0.4720 Acc: 0.7776 | Val Loss: 0.4834 Acc: 0.7597\n",
      "Epoch 018 | Train Loss: 0.4692 Acc: 0.7774 | Val Loss: 0.4535 Acc: 0.7784\n",
      "Epoch 019 | Train Loss: 0.4497 Acc: 0.7933 | Val Loss: 0.4613 Acc: 0.7778\n",
      "Epoch 020 | Train Loss: 0.4456 Acc: 0.7898 | Val Loss: 0.4505 Acc: 0.7874\n",
      "Epoch 021 | Train Loss: 0.4439 Acc: 0.7909 | Val Loss: 0.4469 Acc: 0.7947\n",
      "Epoch 022 | Train Loss: 0.4260 Acc: 0.8037 | Val Loss: 0.4125 Acc: 0.8019\n",
      "Epoch 023 | Train Loss: 0.4118 Acc: 0.8128 | Val Loss: 0.4124 Acc: 0.7929\n",
      "Epoch 024 | Train Loss: 0.3938 Acc: 0.8224 | Val Loss: 0.3727 Acc: 0.8394\n",
      "Epoch 025 | Train Loss: 0.3948 Acc: 0.8273 | Val Loss: 0.3740 Acc: 0.8303\n",
      "Epoch 026 | Train Loss: 0.3817 Acc: 0.8280 | Val Loss: 0.4029 Acc: 0.8170\n",
      "Epoch 027 | Train Loss: 0.3674 Acc: 0.8401 | Val Loss: 0.3492 Acc: 0.8448\n",
      "Epoch 028 | Train Loss: 0.3491 Acc: 0.8496 | Val Loss: 0.3405 Acc: 0.8412\n",
      "Epoch 029 | Train Loss: 0.3491 Acc: 0.8505 | Val Loss: 0.3512 Acc: 0.8454\n",
      "Epoch 030 | Train Loss: 0.3315 Acc: 0.8561 | Val Loss: 0.3362 Acc: 0.8545\n",
      "Epoch 031 | Train Loss: 0.3290 Acc: 0.8614 | Val Loss: 0.3144 Acc: 0.8659\n",
      "Epoch 032 | Train Loss: 0.3126 Acc: 0.8653 | Val Loss: 0.3107 Acc: 0.8684\n",
      "Epoch 033 | Train Loss: 0.3054 Acc: 0.8748 | Val Loss: 0.2883 Acc: 0.8696\n",
      "Epoch 034 | Train Loss: 0.2907 Acc: 0.8821 | Val Loss: 0.3015 Acc: 0.8756\n",
      "Epoch 035 | Train Loss: 0.2792 Acc: 0.8843 | Val Loss: 0.3206 Acc: 0.8810\n",
      "Epoch 036 | Train Loss: 0.2805 Acc: 0.8863 | Val Loss: 0.2806 Acc: 0.8931\n",
      "Epoch 037 | Train Loss: 0.2705 Acc: 0.8901 | Val Loss: 0.2725 Acc: 0.8889\n",
      "Epoch 038 | Train Loss: 0.2535 Acc: 0.8961 | Val Loss: 0.2551 Acc: 0.8949\n",
      "Epoch 039 | Train Loss: 0.2515 Acc: 0.8973 | Val Loss: 0.2395 Acc: 0.9028\n",
      "Epoch 040 | Train Loss: 0.2424 Acc: 0.9026 | Val Loss: 0.2481 Acc: 0.8973\n",
      "Epoch 041 | Train Loss: 0.2342 Acc: 0.9043 | Val Loss: 0.2469 Acc: 0.8986\n",
      "Epoch 042 | Train Loss: 0.2252 Acc: 0.9123 | Val Loss: 0.2384 Acc: 0.9040\n",
      "Epoch 043 | Train Loss: 0.2366 Acc: 0.9040 | Val Loss: 0.2559 Acc: 0.8919\n",
      "Epoch 044 | Train Loss: 0.2164 Acc: 0.9170 | Val Loss: 0.2252 Acc: 0.9112\n",
      "Epoch 045 | Train Loss: 0.2112 Acc: 0.9188 | Val Loss: 0.2304 Acc: 0.9058\n",
      "Epoch 046 | Train Loss: 0.2056 Acc: 0.9183 | Val Loss: 0.2420 Acc: 0.9112\n",
      "Epoch 047 | Train Loss: 0.2172 Acc: 0.9173 | Val Loss: 0.2661 Acc: 0.8955\n",
      "Epoch 048 | Train Loss: 0.2096 Acc: 0.9161 | Val Loss: 0.2081 Acc: 0.9173\n",
      "Epoch 049 | Train Loss: 0.2026 Acc: 0.9186 | Val Loss: 0.2235 Acc: 0.9167\n",
      "Epoch 050 | Train Loss: 0.1968 Acc: 0.9200 | Val Loss: 0.2169 Acc: 0.9088\n",
      "Epoch 051 | Train Loss: 0.1941 Acc: 0.9254 | Val Loss: 0.2284 Acc: 0.9167\n",
      "Epoch 052 | Train Loss: 0.1785 Acc: 0.9302 | Val Loss: 0.2299 Acc: 0.9191\n",
      "Epoch 053 | Train Loss: 0.1811 Acc: 0.9298 | Val Loss: 0.2228 Acc: 0.9197\n",
      "Epoch 054 | Train Loss: 0.1874 Acc: 0.9295 | Val Loss: 0.2236 Acc: 0.9106\n",
      "Epoch 055 | Train Loss: 0.1777 Acc: 0.9342 | Val Loss: 0.2106 Acc: 0.9191\n",
      "Epoch 056 | Train Loss: 0.1839 Acc: 0.9280 | Val Loss: 0.2291 Acc: 0.9106\n",
      "Epoch 057 | Train Loss: 0.1682 Acc: 0.9370 | Val Loss: 0.1965 Acc: 0.9251\n",
      "Epoch 058 | Train Loss: 0.1693 Acc: 0.9351 | Val Loss: 0.1908 Acc: 0.9306\n",
      "Epoch 059 | Train Loss: 0.1591 Acc: 0.9369 | Val Loss: 0.2034 Acc: 0.9306\n",
      "Epoch 060 | Train Loss: 0.1620 Acc: 0.9366 | Val Loss: 0.2144 Acc: 0.9179\n",
      "Epoch 001 | Train Loss: 0.6781 Acc: 0.5828 | Val Loss: 0.6734 Acc: 0.5930\n",
      "Epoch 002 | Train Loss: 0.6724 Acc: 0.5957 | Val Loss: 0.6718 Acc: 0.5870\n",
      "Epoch 003 | Train Loss: 0.6586 Acc: 0.6065 | Val Loss: 0.6478 Acc: 0.6153\n",
      "Epoch 004 | Train Loss: 0.6412 Acc: 0.6343 | Val Loss: 0.6338 Acc: 0.6461\n",
      "Epoch 005 | Train Loss: 0.6014 Acc: 0.6941 | Val Loss: 0.5744 Acc: 0.7077\n",
      "Epoch 006 | Train Loss: 0.5641 Acc: 0.7195 | Val Loss: 0.5645 Acc: 0.7150\n",
      "Epoch 007 | Train Loss: 0.5430 Acc: 0.7327 | Val Loss: 0.5649 Acc: 0.7126\n",
      "Epoch 008 | Train Loss: 0.5259 Acc: 0.7501 | Val Loss: 0.5141 Acc: 0.7415\n",
      "Epoch 009 | Train Loss: 0.5070 Acc: 0.7616 | Val Loss: 0.5104 Acc: 0.7434\n",
      "Epoch 010 | Train Loss: 0.4860 Acc: 0.7667 | Val Loss: 0.5038 Acc: 0.7530\n",
      "Epoch 011 | Train Loss: 0.4641 Acc: 0.7796 | Val Loss: 0.4726 Acc: 0.7699\n",
      "Epoch 012 | Train Loss: 0.4499 Acc: 0.7959 | Val Loss: 0.4598 Acc: 0.7929\n",
      "Epoch 013 | Train Loss: 0.4282 Acc: 0.8057 | Val Loss: 0.4237 Acc: 0.7947\n",
      "Epoch 014 | Train Loss: 0.4085 Acc: 0.8099 | Val Loss: 0.4287 Acc: 0.7868\n",
      "Epoch 015 | Train Loss: 0.3879 Acc: 0.8182 | Val Loss: 0.3809 Acc: 0.8279\n",
      "Epoch 016 | Train Loss: 0.3754 Acc: 0.8298 | Val Loss: 0.3697 Acc: 0.8176\n",
      "Epoch 017 | Train Loss: 0.3581 Acc: 0.8422 | Val Loss: 0.3560 Acc: 0.8370\n",
      "Epoch 018 | Train Loss: 0.3363 Acc: 0.8566 | Val Loss: 0.3217 Acc: 0.8539\n",
      "Epoch 019 | Train Loss: 0.3202 Acc: 0.8547 | Val Loss: 0.3293 Acc: 0.8490\n",
      "Epoch 020 | Train Loss: 0.3150 Acc: 0.8623 | Val Loss: 0.3234 Acc: 0.8545\n",
      "Epoch 021 | Train Loss: 0.3057 Acc: 0.8643 | Val Loss: 0.2955 Acc: 0.8678\n",
      "Epoch 022 | Train Loss: 0.2724 Acc: 0.8786 | Val Loss: 0.2992 Acc: 0.8647\n",
      "Epoch 023 | Train Loss: 0.2663 Acc: 0.8866 | Val Loss: 0.2654 Acc: 0.8853\n",
      "Epoch 024 | Train Loss: 0.2657 Acc: 0.8862 | Val Loss: 0.2595 Acc: 0.8877\n",
      "Epoch 025 | Train Loss: 0.2383 Acc: 0.9008 | Val Loss: 0.2476 Acc: 0.8992\n",
      "Epoch 026 | Train Loss: 0.2404 Acc: 0.9040 | Val Loss: 0.2675 Acc: 0.8762\n",
      "Epoch 027 | Train Loss: 0.2230 Acc: 0.9088 | Val Loss: 0.2386 Acc: 0.9010\n",
      "Epoch 028 | Train Loss: 0.2261 Acc: 0.9059 | Val Loss: 0.2658 Acc: 0.8919\n",
      "Epoch 029 | Train Loss: 0.2105 Acc: 0.9162 | Val Loss: 0.2115 Acc: 0.9155\n",
      "Epoch 030 | Train Loss: 0.2009 Acc: 0.9177 | Val Loss: 0.2213 Acc: 0.9100\n",
      "Epoch 031 | Train Loss: 0.1966 Acc: 0.9198 | Val Loss: 0.2107 Acc: 0.9094\n",
      "Epoch 032 | Train Loss: 0.1853 Acc: 0.9247 | Val Loss: 0.2189 Acc: 0.9106\n",
      "Epoch 033 | Train Loss: 0.1700 Acc: 0.9299 | Val Loss: 0.2139 Acc: 0.9022\n",
      "Epoch 034 | Train Loss: 0.1678 Acc: 0.9325 | Val Loss: 0.1990 Acc: 0.9245\n",
      "Epoch 035 | Train Loss: 0.1646 Acc: 0.9337 | Val Loss: 0.1987 Acc: 0.9209\n",
      "Epoch 036 | Train Loss: 0.1496 Acc: 0.9423 | Val Loss: 0.2284 Acc: 0.9161\n",
      "Epoch 037 | Train Loss: 0.1649 Acc: 0.9318 | Val Loss: 0.2314 Acc: 0.9034\n",
      "Epoch 038 | Train Loss: 0.1441 Acc: 0.9413 | Val Loss: 0.1944 Acc: 0.9203\n",
      "Epoch 039 | Train Loss: 0.1423 Acc: 0.9449 | Val Loss: 0.2467 Acc: 0.9004\n",
      "Epoch 040 | Train Loss: 0.1328 Acc: 0.9511 | Val Loss: 0.2147 Acc: 0.9161\n",
      "Epoch 041 | Train Loss: 0.1370 Acc: 0.9459 | Val Loss: 0.2085 Acc: 0.9161\n",
      "Epoch 042 | Train Loss: 0.1300 Acc: 0.9496 | Val Loss: 0.1884 Acc: 0.9306\n",
      "Epoch 043 | Train Loss: 0.1297 Acc: 0.9496 | Val Loss: 0.2004 Acc: 0.9203\n",
      "Epoch 044 | Train Loss: 0.1246 Acc: 0.9500 | Val Loss: 0.1768 Acc: 0.9336\n",
      "Epoch 045 | Train Loss: 0.1226 Acc: 0.9567 | Val Loss: 0.1954 Acc: 0.9215\n",
      "Epoch 046 | Train Loss: 0.1240 Acc: 0.9511 | Val Loss: 0.1750 Acc: 0.9330\n",
      "Epoch 047 | Train Loss: 0.1133 Acc: 0.9571 | Val Loss: 0.1873 Acc: 0.9336\n",
      "Epoch 048 | Train Loss: 0.1073 Acc: 0.9592 | Val Loss: 0.1656 Acc: 0.9372\n",
      "Epoch 049 | Train Loss: 0.1075 Acc: 0.9606 | Val Loss: 0.1758 Acc: 0.9293\n",
      "Epoch 050 | Train Loss: 0.1088 Acc: 0.9595 | Val Loss: 0.2050 Acc: 0.9185\n",
      "Epoch 051 | Train Loss: 0.1075 Acc: 0.9597 | Val Loss: 0.1671 Acc: 0.9263\n",
      "Epoch 052 | Train Loss: 0.0964 Acc: 0.9629 | Val Loss: 0.1532 Acc: 0.9438\n",
      "Epoch 053 | Train Loss: 0.1063 Acc: 0.9592 | Val Loss: 0.1786 Acc: 0.9336\n",
      "Epoch 054 | Train Loss: 0.0931 Acc: 0.9656 | Val Loss: 0.1475 Acc: 0.9438\n",
      "Epoch 055 | Train Loss: 0.0915 Acc: 0.9663 | Val Loss: 0.1445 Acc: 0.9444\n",
      "Epoch 056 | Train Loss: 0.0890 Acc: 0.9654 | Val Loss: 0.1646 Acc: 0.9378\n",
      "Epoch 057 | Train Loss: 0.0968 Acc: 0.9654 | Val Loss: 0.1743 Acc: 0.9372\n",
      "Epoch 058 | Train Loss: 0.0869 Acc: 0.9648 | Val Loss: 0.1603 Acc: 0.9420\n",
      "Epoch 059 | Train Loss: 0.0900 Acc: 0.9657 | Val Loss: 0.1527 Acc: 0.9438\n",
      "Epoch 060 | Train Loss: 0.0819 Acc: 0.9698 | Val Loss: 0.1548 Acc: 0.9450\n",
      "Epoch 001 | Train Loss: 0.6814 Acc: 0.5783 | Val Loss: 0.6620 Acc: 0.6099\n",
      "Epoch 002 | Train Loss: 0.6523 Acc: 0.6249 | Val Loss: 0.6235 Acc: 0.6618\n",
      "Epoch 003 | Train Loss: 0.5950 Acc: 0.6933 | Val Loss: 0.5567 Acc: 0.7240\n",
      "Epoch 004 | Train Loss: 0.5617 Acc: 0.7217 | Val Loss: 0.5409 Acc: 0.7349\n",
      "Epoch 005 | Train Loss: 0.5202 Acc: 0.7504 | Val Loss: 0.5138 Acc: 0.7488\n",
      "Epoch 006 | Train Loss: 0.5123 Acc: 0.7562 | Val Loss: 0.4962 Acc: 0.7645\n",
      "Epoch 007 | Train Loss: 0.4752 Acc: 0.7793 | Val Loss: 0.4713 Acc: 0.7627\n",
      "Epoch 008 | Train Loss: 0.4550 Acc: 0.7947 | Val Loss: 0.4541 Acc: 0.7778\n",
      "Epoch 009 | Train Loss: 0.4346 Acc: 0.7998 | Val Loss: 0.4252 Acc: 0.8074\n",
      "Epoch 010 | Train Loss: 0.4185 Acc: 0.8084 | Val Loss: 0.3788 Acc: 0.8231\n",
      "Epoch 011 | Train Loss: 0.3703 Acc: 0.8403 | Val Loss: 0.3619 Acc: 0.8279\n",
      "Epoch 012 | Train Loss: 0.3652 Acc: 0.8412 | Val Loss: 0.3635 Acc: 0.8370\n",
      "Epoch 013 | Train Loss: 0.3262 Acc: 0.8637 | Val Loss: 0.3352 Acc: 0.8478\n",
      "Epoch 014 | Train Loss: 0.3239 Acc: 0.8664 | Val Loss: 0.3112 Acc: 0.8696\n",
      "Epoch 015 | Train Loss: 0.2962 Acc: 0.8759 | Val Loss: 0.2837 Acc: 0.8804\n",
      "Epoch 016 | Train Loss: 0.2880 Acc: 0.8795 | Val Loss: 0.2712 Acc: 0.8865\n",
      "Epoch 017 | Train Loss: 0.2705 Acc: 0.8898 | Val Loss: 0.2776 Acc: 0.8847\n",
      "Epoch 018 | Train Loss: 0.2594 Acc: 0.8951 | Val Loss: 0.2751 Acc: 0.8931\n",
      "Epoch 019 | Train Loss: 0.2492 Acc: 0.9010 | Val Loss: 0.2376 Acc: 0.9028\n",
      "Epoch 020 | Train Loss: 0.2308 Acc: 0.9088 | Val Loss: 0.2037 Acc: 0.9239\n",
      "Epoch 021 | Train Loss: 0.2250 Acc: 0.9108 | Val Loss: 0.2213 Acc: 0.9136\n",
      "Epoch 022 | Train Loss: 0.2219 Acc: 0.9132 | Val Loss: 0.2137 Acc: 0.9209\n",
      "Epoch 023 | Train Loss: 0.2035 Acc: 0.9230 | Val Loss: 0.2078 Acc: 0.9149\n",
      "Epoch 024 | Train Loss: 0.1938 Acc: 0.9221 | Val Loss: 0.2257 Acc: 0.9070\n",
      "Epoch 025 | Train Loss: 0.1795 Acc: 0.9293 | Val Loss: 0.2160 Acc: 0.9124\n",
      "Epoch 026 | Train Loss: 0.1902 Acc: 0.9295 | Val Loss: 0.2393 Acc: 0.8992\n",
      "Epoch 027 | Train Loss: 0.1717 Acc: 0.9325 | Val Loss: 0.2210 Acc: 0.9124\n",
      "Epoch 028 | Train Loss: 0.1787 Acc: 0.9295 | Val Loss: 0.1892 Acc: 0.9300\n",
      "Epoch 029 | Train Loss: 0.1707 Acc: 0.9360 | Val Loss: 0.2032 Acc: 0.9257\n",
      "Epoch 030 | Train Loss: 0.1562 Acc: 0.9417 | Val Loss: 0.2032 Acc: 0.9281\n",
      "Epoch 031 | Train Loss: 0.1579 Acc: 0.9388 | Val Loss: 0.1842 Acc: 0.9324\n",
      "Epoch 032 | Train Loss: 0.1530 Acc: 0.9428 | Val Loss: 0.1818 Acc: 0.9342\n",
      "Epoch 033 | Train Loss: 0.1425 Acc: 0.9472 | Val Loss: 0.1877 Acc: 0.9342\n",
      "Epoch 034 | Train Loss: 0.1536 Acc: 0.9393 | Val Loss: 0.2010 Acc: 0.9275\n",
      "Epoch 035 | Train Loss: 0.1459 Acc: 0.9461 | Val Loss: 0.1785 Acc: 0.9342\n",
      "Epoch 036 | Train Loss: 0.1344 Acc: 0.9502 | Val Loss: 0.1561 Acc: 0.9463\n",
      "Epoch 037 | Train Loss: 0.1305 Acc: 0.9529 | Val Loss: 0.1960 Acc: 0.9245\n",
      "Epoch 038 | Train Loss: 0.1292 Acc: 0.9509 | Val Loss: 0.1705 Acc: 0.9402\n",
      "Epoch 039 | Train Loss: 0.1274 Acc: 0.9543 | Val Loss: 0.1902 Acc: 0.9390\n",
      "Epoch 040 | Train Loss: 0.1362 Acc: 0.9455 | Val Loss: 0.1674 Acc: 0.9414\n",
      "Epoch 041 | Train Loss: 0.1203 Acc: 0.9544 | Val Loss: 0.1713 Acc: 0.9348\n",
      "Epoch 042 | Train Loss: 0.1214 Acc: 0.9550 | Val Loss: 0.1595 Acc: 0.9426\n",
      "Epoch 043 | Train Loss: 0.1251 Acc: 0.9527 | Val Loss: 0.1848 Acc: 0.9354\n",
      "Epoch 044 | Train Loss: 0.1152 Acc: 0.9564 | Val Loss: 0.1567 Acc: 0.9475\n",
      "Epoch 045 | Train Loss: 0.1163 Acc: 0.9580 | Val Loss: 0.1636 Acc: 0.9402\n",
      "Epoch 046 | Train Loss: 0.0992 Acc: 0.9629 | Val Loss: 0.1752 Acc: 0.9378\n",
      "Early stopping triggered.\n",
      "Epoch 001 | Train Loss: 0.6823 Acc: 0.5715 | Val Loss: 0.6740 Acc: 0.5864\n",
      "Epoch 002 | Train Loss: 0.6739 Acc: 0.5905 | Val Loss: 0.6713 Acc: 0.5936\n",
      "Epoch 003 | Train Loss: 0.6689 Acc: 0.6047 | Val Loss: 0.6684 Acc: 0.5978\n",
      "Epoch 004 | Train Loss: 0.6643 Acc: 0.6074 | Val Loss: 0.6641 Acc: 0.6033\n",
      "Epoch 005 | Train Loss: 0.6466 Acc: 0.6328 | Val Loss: 0.6352 Acc: 0.6510\n",
      "Epoch 006 | Train Loss: 0.6156 Acc: 0.6772 | Val Loss: 0.5782 Acc: 0.7035\n",
      "Epoch 007 | Train Loss: 0.5819 Acc: 0.7115 | Val Loss: 0.5796 Acc: 0.7120\n",
      "Epoch 008 | Train Loss: 0.5595 Acc: 0.7254 | Val Loss: 0.5589 Acc: 0.7222\n",
      "Epoch 009 | Train Loss: 0.5348 Acc: 0.7429 | Val Loss: 0.5244 Acc: 0.7385\n",
      "Epoch 010 | Train Loss: 0.5062 Acc: 0.7592 | Val Loss: 0.5243 Acc: 0.7403\n",
      "Epoch 011 | Train Loss: 0.5055 Acc: 0.7584 | Val Loss: 0.4985 Acc: 0.7615\n",
      "Epoch 012 | Train Loss: 0.4791 Acc: 0.7803 | Val Loss: 0.4751 Acc: 0.7784\n",
      "Epoch 013 | Train Loss: 0.4712 Acc: 0.7818 | Val Loss: 0.4631 Acc: 0.7844\n",
      "Epoch 014 | Train Loss: 0.4367 Acc: 0.8027 | Val Loss: 0.4354 Acc: 0.7947\n",
      "Epoch 015 | Train Loss: 0.4270 Acc: 0.8033 | Val Loss: 0.4159 Acc: 0.8134\n",
      "Epoch 016 | Train Loss: 0.4008 Acc: 0.8224 | Val Loss: 0.4214 Acc: 0.8170\n",
      "Epoch 017 | Train Loss: 0.3924 Acc: 0.8230 | Val Loss: 0.4030 Acc: 0.8176\n",
      "Epoch 018 | Train Loss: 0.3713 Acc: 0.8354 | Val Loss: 0.3769 Acc: 0.8303\n",
      "Epoch 019 | Train Loss: 0.3554 Acc: 0.8437 | Val Loss: 0.3574 Acc: 0.8370\n",
      "Epoch 020 | Train Loss: 0.3314 Acc: 0.8567 | Val Loss: 0.3286 Acc: 0.8557\n",
      "Epoch 021 | Train Loss: 0.3232 Acc: 0.8620 | Val Loss: 0.3387 Acc: 0.8466\n",
      "Epoch 022 | Train Loss: 0.3073 Acc: 0.8708 | Val Loss: 0.3054 Acc: 0.8678\n",
      "Epoch 023 | Train Loss: 0.2883 Acc: 0.8804 | Val Loss: 0.2905 Acc: 0.8768\n",
      "Epoch 024 | Train Loss: 0.2786 Acc: 0.8800 | Val Loss: 0.2755 Acc: 0.8822\n",
      "Epoch 025 | Train Loss: 0.2603 Acc: 0.8931 | Val Loss: 0.2528 Acc: 0.8949\n",
      "Epoch 026 | Train Loss: 0.2598 Acc: 0.8910 | Val Loss: 0.2947 Acc: 0.8726\n",
      "Epoch 027 | Train Loss: 0.2488 Acc: 0.8996 | Val Loss: 0.2602 Acc: 0.8907\n",
      "Epoch 028 | Train Loss: 0.2410 Acc: 0.9035 | Val Loss: 0.2527 Acc: 0.8931\n",
      "Epoch 029 | Train Loss: 0.2247 Acc: 0.9088 | Val Loss: 0.2737 Acc: 0.8829\n",
      "Epoch 030 | Train Loss: 0.2201 Acc: 0.9102 | Val Loss: 0.2229 Acc: 0.9112\n",
      "Epoch 031 | Train Loss: 0.2119 Acc: 0.9126 | Val Loss: 0.2197 Acc: 0.9155\n",
      "Epoch 032 | Train Loss: 0.2151 Acc: 0.9148 | Val Loss: 0.2320 Acc: 0.9118\n",
      "Epoch 033 | Train Loss: 0.2008 Acc: 0.9210 | Val Loss: 0.2267 Acc: 0.9203\n",
      "Epoch 034 | Train Loss: 0.1829 Acc: 0.9289 | Val Loss: 0.2435 Acc: 0.9034\n",
      "Epoch 035 | Train Loss: 0.1848 Acc: 0.9304 | Val Loss: 0.1971 Acc: 0.9257\n",
      "Epoch 036 | Train Loss: 0.1830 Acc: 0.9322 | Val Loss: 0.2371 Acc: 0.9058\n",
      "Epoch 037 | Train Loss: 0.1704 Acc: 0.9342 | Val Loss: 0.2000 Acc: 0.9149\n",
      "Epoch 038 | Train Loss: 0.1632 Acc: 0.9390 | Val Loss: 0.1983 Acc: 0.9257\n",
      "Epoch 039 | Train Loss: 0.1683 Acc: 0.9364 | Val Loss: 0.2541 Acc: 0.9034\n",
      "Epoch 040 | Train Loss: 0.1592 Acc: 0.9364 | Val Loss: 0.2161 Acc: 0.9130\n",
      "Epoch 041 | Train Loss: 0.1608 Acc: 0.9395 | Val Loss: 0.2029 Acc: 0.9251\n",
      "Epoch 042 | Train Loss: 0.1539 Acc: 0.9395 | Val Loss: 0.1960 Acc: 0.9263\n",
      "Epoch 043 | Train Loss: 0.1563 Acc: 0.9413 | Val Loss: 0.1866 Acc: 0.9293\n",
      "Epoch 044 | Train Loss: 0.1431 Acc: 0.9458 | Val Loss: 0.2298 Acc: 0.9281\n",
      "Epoch 045 | Train Loss: 0.1465 Acc: 0.9456 | Val Loss: 0.1966 Acc: 0.9300\n",
      "Epoch 046 | Train Loss: 0.1565 Acc: 0.9401 | Val Loss: 0.2327 Acc: 0.9106\n",
      "Epoch 047 | Train Loss: 0.1468 Acc: 0.9431 | Val Loss: 0.2028 Acc: 0.9275\n",
      "Epoch 048 | Train Loss: 0.1232 Acc: 0.9533 | Val Loss: 0.1730 Acc: 0.9366\n",
      "Epoch 049 | Train Loss: 0.1370 Acc: 0.9469 | Val Loss: 0.1838 Acc: 0.9330\n",
      "Epoch 050 | Train Loss: 0.1356 Acc: 0.9481 | Val Loss: 0.1955 Acc: 0.9300\n",
      "Epoch 051 | Train Loss: 0.1197 Acc: 0.9577 | Val Loss: 0.1766 Acc: 0.9330\n",
      "Epoch 052 | Train Loss: 0.1223 Acc: 0.9552 | Val Loss: 0.1824 Acc: 0.9245\n",
      "Epoch 053 | Train Loss: 0.1213 Acc: 0.9574 | Val Loss: 0.2373 Acc: 0.9209\n",
      "Epoch 054 | Train Loss: 0.1254 Acc: 0.9521 | Val Loss: 0.1650 Acc: 0.9390\n",
      "Epoch 055 | Train Loss: 0.1175 Acc: 0.9553 | Val Loss: 0.2096 Acc: 0.9227\n",
      "Epoch 056 | Train Loss: 0.1138 Acc: 0.9579 | Val Loss: 0.1912 Acc: 0.9275\n",
      "Epoch 057 | Train Loss: 0.1154 Acc: 0.9564 | Val Loss: 0.1913 Acc: 0.9287\n",
      "Epoch 058 | Train Loss: 0.1175 Acc: 0.9567 | Val Loss: 0.2175 Acc: 0.9209\n",
      "Epoch 059 | Train Loss: 0.1146 Acc: 0.9549 | Val Loss: 0.1540 Acc: 0.9432\n",
      "Epoch 060 | Train Loss: 0.1209 Acc: 0.9538 | Val Loss: 0.2014 Acc: 0.9275\n",
      "Epoch 001 | Train Loss: 0.6795 Acc: 0.5809 | Val Loss: 0.6833 Acc: 0.5658\n",
      "Epoch 002 | Train Loss: 0.6717 Acc: 0.5952 | Val Loss: 0.6700 Acc: 0.6087\n",
      "Epoch 003 | Train Loss: 0.6628 Acc: 0.6023 | Val Loss: 0.6584 Acc: 0.6033\n",
      "Epoch 004 | Train Loss: 0.6459 Acc: 0.6369 | Val Loss: 0.6283 Acc: 0.6709\n",
      "Epoch 005 | Train Loss: 0.6089 Acc: 0.6875 | Val Loss: 0.5864 Acc: 0.7005\n",
      "Epoch 006 | Train Loss: 0.5776 Acc: 0.7083 | Val Loss: 0.6007 Acc: 0.6793\n",
      "Epoch 007 | Train Loss: 0.5529 Acc: 0.7276 | Val Loss: 0.5571 Acc: 0.7180\n",
      "Epoch 008 | Train Loss: 0.5389 Acc: 0.7395 | Val Loss: 0.5346 Acc: 0.7337\n",
      "Epoch 009 | Train Loss: 0.5181 Acc: 0.7491 | Val Loss: 0.5180 Acc: 0.7373\n",
      "Epoch 010 | Train Loss: 0.5012 Acc: 0.7548 | Val Loss: 0.5189 Acc: 0.7325\n",
      "Epoch 011 | Train Loss: 0.4890 Acc: 0.7705 | Val Loss: 0.5282 Acc: 0.7343\n",
      "Epoch 012 | Train Loss: 0.4637 Acc: 0.7799 | Val Loss: 0.4726 Acc: 0.7760\n",
      "Epoch 013 | Train Loss: 0.4529 Acc: 0.7892 | Val Loss: 0.4315 Acc: 0.8013\n",
      "Epoch 014 | Train Loss: 0.4310 Acc: 0.8021 | Val Loss: 0.4259 Acc: 0.8068\n",
      "Epoch 015 | Train Loss: 0.4077 Acc: 0.8167 | Val Loss: 0.4171 Acc: 0.8031\n",
      "Epoch 016 | Train Loss: 0.3836 Acc: 0.8264 | Val Loss: 0.3771 Acc: 0.8309\n",
      "Epoch 017 | Train Loss: 0.3775 Acc: 0.8267 | Val Loss: 0.4191 Acc: 0.8092\n",
      "Epoch 018 | Train Loss: 0.3615 Acc: 0.8392 | Val Loss: 0.3806 Acc: 0.8351\n",
      "Epoch 019 | Train Loss: 0.3401 Acc: 0.8499 | Val Loss: 0.3414 Acc: 0.8599\n",
      "Epoch 020 | Train Loss: 0.3283 Acc: 0.8560 | Val Loss: 0.3323 Acc: 0.8563\n",
      "Epoch 021 | Train Loss: 0.3139 Acc: 0.8662 | Val Loss: 0.3293 Acc: 0.8678\n",
      "Epoch 022 | Train Loss: 0.3046 Acc: 0.8720 | Val Loss: 0.3092 Acc: 0.8696\n",
      "Epoch 023 | Train Loss: 0.2921 Acc: 0.8754 | Val Loss: 0.2854 Acc: 0.8822\n",
      "Epoch 024 | Train Loss: 0.2668 Acc: 0.8889 | Val Loss: 0.2673 Acc: 0.8877\n",
      "Epoch 025 | Train Loss: 0.2607 Acc: 0.8934 | Val Loss: 0.2622 Acc: 0.8925\n",
      "Epoch 026 | Train Loss: 0.2421 Acc: 0.9029 | Val Loss: 0.2744 Acc: 0.8949\n",
      "Epoch 027 | Train Loss: 0.2348 Acc: 0.9046 | Val Loss: 0.2570 Acc: 0.8961\n",
      "Epoch 028 | Train Loss: 0.2271 Acc: 0.9082 | Val Loss: 0.2618 Acc: 0.8859\n",
      "Epoch 029 | Train Loss: 0.2191 Acc: 0.9108 | Val Loss: 0.2355 Acc: 0.9052\n",
      "Epoch 030 | Train Loss: 0.2116 Acc: 0.9120 | Val Loss: 0.2348 Acc: 0.9094\n",
      "Epoch 031 | Train Loss: 0.2024 Acc: 0.9204 | Val Loss: 0.2236 Acc: 0.9112\n",
      "Epoch 032 | Train Loss: 0.1950 Acc: 0.9228 | Val Loss: 0.2170 Acc: 0.9179\n",
      "Epoch 033 | Train Loss: 0.1973 Acc: 0.9212 | Val Loss: 0.2060 Acc: 0.9221\n",
      "Epoch 034 | Train Loss: 0.1918 Acc: 0.9272 | Val Loss: 0.2557 Acc: 0.8913\n",
      "Epoch 035 | Train Loss: 0.1753 Acc: 0.9318 | Val Loss: 0.2457 Acc: 0.9106\n",
      "Epoch 036 | Train Loss: 0.1764 Acc: 0.9259 | Val Loss: 0.2084 Acc: 0.9245\n",
      "Epoch 037 | Train Loss: 0.1652 Acc: 0.9372 | Val Loss: 0.2068 Acc: 0.9191\n",
      "Epoch 038 | Train Loss: 0.1623 Acc: 0.9385 | Val Loss: 0.2104 Acc: 0.9197\n",
      "Epoch 039 | Train Loss: 0.1536 Acc: 0.9422 | Val Loss: 0.2211 Acc: 0.9173\n",
      "Epoch 040 | Train Loss: 0.1584 Acc: 0.9346 | Val Loss: 0.2213 Acc: 0.9191\n",
      "Epoch 041 | Train Loss: 0.1357 Acc: 0.9464 | Val Loss: 0.2004 Acc: 0.9263\n",
      "Epoch 042 | Train Loss: 0.1407 Acc: 0.9447 | Val Loss: 0.2188 Acc: 0.9203\n",
      "Epoch 043 | Train Loss: 0.1420 Acc: 0.9455 | Val Loss: 0.1816 Acc: 0.9306\n",
      "Epoch 044 | Train Loss: 0.1364 Acc: 0.9478 | Val Loss: 0.1802 Acc: 0.9384\n",
      "Epoch 045 | Train Loss: 0.1360 Acc: 0.9493 | Val Loss: 0.1859 Acc: 0.9324\n",
      "Epoch 046 | Train Loss: 0.1393 Acc: 0.9458 | Val Loss: 0.2289 Acc: 0.9197\n",
      "Epoch 047 | Train Loss: 0.1339 Acc: 0.9479 | Val Loss: 0.1974 Acc: 0.9306\n",
      "Epoch 048 | Train Loss: 0.1293 Acc: 0.9506 | Val Loss: 0.1615 Acc: 0.9408\n",
      "Epoch 049 | Train Loss: 0.1190 Acc: 0.9539 | Val Loss: 0.1711 Acc: 0.9372\n",
      "Epoch 050 | Train Loss: 0.1140 Acc: 0.9582 | Val Loss: 0.1852 Acc: 0.9336\n",
      "Epoch 051 | Train Loss: 0.1147 Acc: 0.9568 | Val Loss: 0.1695 Acc: 0.9402\n",
      "Epoch 052 | Train Loss: 0.1023 Acc: 0.9589 | Val Loss: 0.1649 Acc: 0.9396\n",
      "Epoch 053 | Train Loss: 0.1151 Acc: 0.9571 | Val Loss: 0.1895 Acc: 0.9354\n",
      "Epoch 054 | Train Loss: 0.1256 Acc: 0.9546 | Val Loss: 0.1537 Acc: 0.9463\n",
      "Epoch 055 | Train Loss: 0.1083 Acc: 0.9586 | Val Loss: 0.1657 Acc: 0.9438\n",
      "Epoch 056 | Train Loss: 0.1011 Acc: 0.9629 | Val Loss: 0.1850 Acc: 0.9336\n",
      "Epoch 057 | Train Loss: 0.1063 Acc: 0.9604 | Val Loss: 0.1914 Acc: 0.9348\n",
      "Epoch 058 | Train Loss: 0.1070 Acc: 0.9598 | Val Loss: 0.1302 Acc: 0.9481\n",
      "Epoch 059 | Train Loss: 0.0904 Acc: 0.9648 | Val Loss: 0.1798 Acc: 0.9420\n",
      "Epoch 060 | Train Loss: 0.0925 Acc: 0.9621 | Val Loss: 0.1856 Acc: 0.9426\n",
      "Epoch 001 | Train Loss: 0.6804 Acc: 0.5732 | Val Loss: 0.6665 Acc: 0.6178\n",
      "Epoch 002 | Train Loss: 0.6455 Acc: 0.6376 | Val Loss: 0.6202 Acc: 0.6612\n",
      "Epoch 003 | Train Loss: 0.6063 Acc: 0.6820 | Val Loss: 0.5789 Acc: 0.6969\n",
      "Epoch 004 | Train Loss: 0.5773 Acc: 0.7066 | Val Loss: 0.5924 Acc: 0.6957\n",
      "Epoch 005 | Train Loss: 0.5701 Acc: 0.7139 | Val Loss: 0.5580 Acc: 0.7168\n",
      "Epoch 006 | Train Loss: 0.5486 Acc: 0.7297 | Val Loss: 0.5389 Acc: 0.7192\n",
      "Epoch 007 | Train Loss: 0.5210 Acc: 0.7504 | Val Loss: 0.5059 Acc: 0.7512\n",
      "Epoch 008 | Train Loss: 0.5135 Acc: 0.7554 | Val Loss: 0.5138 Acc: 0.7409\n",
      "Epoch 009 | Train Loss: 0.4856 Acc: 0.7700 | Val Loss: 0.4860 Acc: 0.7609\n",
      "Epoch 010 | Train Loss: 0.4789 Acc: 0.7734 | Val Loss: 0.4471 Acc: 0.7880\n",
      "Epoch 011 | Train Loss: 0.4520 Acc: 0.7921 | Val Loss: 0.4322 Acc: 0.7874\n",
      "Epoch 012 | Train Loss: 0.4384 Acc: 0.8001 | Val Loss: 0.4015 Acc: 0.7983\n",
      "Epoch 013 | Train Loss: 0.4210 Acc: 0.8033 | Val Loss: 0.4040 Acc: 0.8001\n",
      "Epoch 014 | Train Loss: 0.3996 Acc: 0.8218 | Val Loss: 0.3890 Acc: 0.8056\n",
      "Epoch 015 | Train Loss: 0.3857 Acc: 0.8288 | Val Loss: 0.3540 Acc: 0.8496\n",
      "Epoch 016 | Train Loss: 0.3675 Acc: 0.8381 | Val Loss: 0.3639 Acc: 0.8309\n",
      "Epoch 017 | Train Loss: 0.3622 Acc: 0.8431 | Val Loss: 0.3132 Acc: 0.8629\n",
      "Epoch 018 | Train Loss: 0.3361 Acc: 0.8535 | Val Loss: 0.3121 Acc: 0.8684\n",
      "Epoch 019 | Train Loss: 0.3126 Acc: 0.8647 | Val Loss: 0.3211 Acc: 0.8653\n",
      "Epoch 020 | Train Loss: 0.3110 Acc: 0.8691 | Val Loss: 0.2947 Acc: 0.8665\n",
      "Epoch 021 | Train Loss: 0.3021 Acc: 0.8715 | Val Loss: 0.3025 Acc: 0.8623\n",
      "Epoch 022 | Train Loss: 0.2984 Acc: 0.8747 | Val Loss: 0.2660 Acc: 0.8895\n",
      "Epoch 023 | Train Loss: 0.2942 Acc: 0.8789 | Val Loss: 0.2739 Acc: 0.8967\n",
      "Epoch 024 | Train Loss: 0.2775 Acc: 0.8842 | Val Loss: 0.2454 Acc: 0.8979\n",
      "Epoch 025 | Train Loss: 0.2646 Acc: 0.8910 | Val Loss: 0.2580 Acc: 0.8973\n",
      "Epoch 026 | Train Loss: 0.2429 Acc: 0.9022 | Val Loss: 0.2432 Acc: 0.8901\n",
      "Epoch 027 | Train Loss: 0.2496 Acc: 0.8958 | Val Loss: 0.2261 Acc: 0.9100\n",
      "Epoch 028 | Train Loss: 0.2343 Acc: 0.9031 | Val Loss: 0.2272 Acc: 0.9100\n",
      "Epoch 029 | Train Loss: 0.2360 Acc: 0.9038 | Val Loss: 0.2250 Acc: 0.9094\n",
      "Epoch 030 | Train Loss: 0.2167 Acc: 0.9124 | Val Loss: 0.2315 Acc: 0.9082\n",
      "Epoch 031 | Train Loss: 0.2147 Acc: 0.9115 | Val Loss: 0.1935 Acc: 0.9221\n",
      "Epoch 032 | Train Loss: 0.2129 Acc: 0.9139 | Val Loss: 0.2093 Acc: 0.9112\n",
      "Epoch 033 | Train Loss: 0.2008 Acc: 0.9200 | Val Loss: 0.2097 Acc: 0.9143\n",
      "Epoch 034 | Train Loss: 0.1994 Acc: 0.9221 | Val Loss: 0.1953 Acc: 0.9287\n",
      "Epoch 035 | Train Loss: 0.1883 Acc: 0.9262 | Val Loss: 0.2139 Acc: 0.9203\n",
      "Epoch 036 | Train Loss: 0.1899 Acc: 0.9222 | Val Loss: 0.1931 Acc: 0.9275\n",
      "Epoch 037 | Train Loss: 0.1917 Acc: 0.9253 | Val Loss: 0.1764 Acc: 0.9306\n",
      "Epoch 038 | Train Loss: 0.1846 Acc: 0.9241 | Val Loss: 0.1775 Acc: 0.9287\n",
      "Epoch 039 | Train Loss: 0.1786 Acc: 0.9345 | Val Loss: 0.2068 Acc: 0.9287\n",
      "Epoch 040 | Train Loss: 0.1709 Acc: 0.9352 | Val Loss: 0.2143 Acc: 0.9191\n",
      "Epoch 041 | Train Loss: 0.1759 Acc: 0.9322 | Val Loss: 0.1997 Acc: 0.9239\n",
      "Epoch 042 | Train Loss: 0.1714 Acc: 0.9305 | Val Loss: 0.1784 Acc: 0.9348\n",
      "Epoch 043 | Train Loss: 0.1683 Acc: 0.9366 | Val Loss: 0.2067 Acc: 0.9245\n",
      "Epoch 044 | Train Loss: 0.1515 Acc: 0.9449 | Val Loss: 0.2115 Acc: 0.9227\n",
      "Epoch 045 | Train Loss: 0.1693 Acc: 0.9345 | Val Loss: 0.1857 Acc: 0.9348\n",
      "Epoch 046 | Train Loss: 0.1600 Acc: 0.9382 | Val Loss: 0.1527 Acc: 0.9444\n",
      "Epoch 047 | Train Loss: 0.1430 Acc: 0.9434 | Val Loss: 0.2342 Acc: 0.9034\n",
      "Epoch 048 | Train Loss: 0.1481 Acc: 0.9429 | Val Loss: 0.1892 Acc: 0.9324\n",
      "Epoch 049 | Train Loss: 0.1524 Acc: 0.9384 | Val Loss: 0.1556 Acc: 0.9438\n",
      "Epoch 050 | Train Loss: 0.1547 Acc: 0.9411 | Val Loss: 0.1730 Acc: 0.9306\n",
      "Epoch 051 | Train Loss: 0.1338 Acc: 0.9472 | Val Loss: 0.2080 Acc: 0.9209\n",
      "Epoch 052 | Train Loss: 0.1483 Acc: 0.9437 | Val Loss: 0.1707 Acc: 0.9444\n",
      "Epoch 053 | Train Loss: 0.1445 Acc: 0.9452 | Val Loss: 0.1789 Acc: 0.9306\n",
      "Epoch 054 | Train Loss: 0.1339 Acc: 0.9532 | Val Loss: 0.1525 Acc: 0.9457\n",
      "Epoch 055 | Train Loss: 0.1300 Acc: 0.9523 | Val Loss: 0.1633 Acc: 0.9396\n",
      "Epoch 056 | Train Loss: 0.1316 Acc: 0.9530 | Val Loss: 0.1555 Acc: 0.9396\n",
      "Epoch 057 | Train Loss: 0.1296 Acc: 0.9512 | Val Loss: 0.1520 Acc: 0.9475\n",
      "Epoch 058 | Train Loss: 0.1177 Acc: 0.9591 | Val Loss: 0.1526 Acc: 0.9444\n",
      "Epoch 059 | Train Loss: 0.1313 Acc: 0.9518 | Val Loss: 0.1498 Acc: 0.9487\n",
      "Epoch 060 | Train Loss: 0.1214 Acc: 0.9553 | Val Loss: 0.1686 Acc: 0.9360\n",
      "Epoch 001 | Train Loss: 0.6806 Acc: 0.5787 | Val Loss: 0.6760 Acc: 0.5918\n",
      "Epoch 002 | Train Loss: 0.6717 Acc: 0.5966 | Val Loss: 0.6698 Acc: 0.5936\n",
      "Epoch 003 | Train Loss: 0.6735 Acc: 0.5886 | Val Loss: 0.6555 Acc: 0.6165\n",
      "Epoch 004 | Train Loss: 0.6360 Acc: 0.6530 | Val Loss: 0.6309 Acc: 0.6540\n",
      "Epoch 005 | Train Loss: 0.6050 Acc: 0.6924 | Val Loss: 0.6185 Acc: 0.6564\n",
      "Epoch 006 | Train Loss: 0.5775 Acc: 0.7080 | Val Loss: 0.5737 Acc: 0.7053\n",
      "Epoch 007 | Train Loss: 0.5599 Acc: 0.7198 | Val Loss: 0.5647 Acc: 0.7065\n",
      "Epoch 008 | Train Loss: 0.5397 Acc: 0.7344 | Val Loss: 0.5391 Acc: 0.7264\n",
      "Epoch 009 | Train Loss: 0.5123 Acc: 0.7494 | Val Loss: 0.5396 Acc: 0.7307\n",
      "Epoch 010 | Train Loss: 0.4963 Acc: 0.7592 | Val Loss: 0.4906 Acc: 0.7597\n",
      "Epoch 011 | Train Loss: 0.4764 Acc: 0.7729 | Val Loss: 0.4841 Acc: 0.7675\n",
      "Epoch 012 | Train Loss: 0.4571 Acc: 0.7809 | Val Loss: 0.4786 Acc: 0.7729\n",
      "Epoch 013 | Train Loss: 0.4409 Acc: 0.7895 | Val Loss: 0.4533 Acc: 0.7772\n",
      "Epoch 014 | Train Loss: 0.4126 Acc: 0.8099 | Val Loss: 0.4283 Acc: 0.8007\n",
      "Epoch 015 | Train Loss: 0.3953 Acc: 0.8190 | Val Loss: 0.4130 Acc: 0.8050\n",
      "Epoch 016 | Train Loss: 0.3812 Acc: 0.8223 | Val Loss: 0.3963 Acc: 0.8207\n",
      "Epoch 017 | Train Loss: 0.3511 Acc: 0.8424 | Val Loss: 0.4013 Acc: 0.8194\n",
      "Epoch 018 | Train Loss: 0.3412 Acc: 0.8437 | Val Loss: 0.3363 Acc: 0.8581\n",
      "Epoch 019 | Train Loss: 0.3230 Acc: 0.8508 | Val Loss: 0.3178 Acc: 0.8647\n",
      "Epoch 020 | Train Loss: 0.3067 Acc: 0.8656 | Val Loss: 0.3256 Acc: 0.8599\n",
      "Epoch 021 | Train Loss: 0.2846 Acc: 0.8772 | Val Loss: 0.3032 Acc: 0.8768\n",
      "Epoch 022 | Train Loss: 0.2748 Acc: 0.8812 | Val Loss: 0.3343 Acc: 0.8587\n",
      "Epoch 023 | Train Loss: 0.2479 Acc: 0.8919 | Val Loss: 0.2647 Acc: 0.8931\n",
      "Epoch 024 | Train Loss: 0.2480 Acc: 0.8993 | Val Loss: 0.3079 Acc: 0.8653\n",
      "Epoch 025 | Train Loss: 0.2379 Acc: 0.8999 | Val Loss: 0.2723 Acc: 0.8901\n",
      "Epoch 026 | Train Loss: 0.2237 Acc: 0.9070 | Val Loss: 0.2457 Acc: 0.9052\n",
      "Epoch 027 | Train Loss: 0.2057 Acc: 0.9176 | Val Loss: 0.2339 Acc: 0.9046\n",
      "Epoch 028 | Train Loss: 0.2054 Acc: 0.9117 | Val Loss: 0.2467 Acc: 0.8931\n",
      "Epoch 029 | Train Loss: 0.1871 Acc: 0.9234 | Val Loss: 0.2280 Acc: 0.9088\n",
      "Epoch 030 | Train Loss: 0.1811 Acc: 0.9248 | Val Loss: 0.2423 Acc: 0.9100\n",
      "Epoch 031 | Train Loss: 0.1797 Acc: 0.9263 | Val Loss: 0.2216 Acc: 0.9143\n",
      "Epoch 032 | Train Loss: 0.1705 Acc: 0.9325 | Val Loss: 0.2271 Acc: 0.9143\n",
      "Epoch 033 | Train Loss: 0.1581 Acc: 0.9345 | Val Loss: 0.2458 Acc: 0.9100\n",
      "Epoch 034 | Train Loss: 0.1425 Acc: 0.9423 | Val Loss: 0.2339 Acc: 0.9173\n",
      "Epoch 035 | Train Loss: 0.1414 Acc: 0.9425 | Val Loss: 0.2175 Acc: 0.9209\n",
      "Epoch 036 | Train Loss: 0.1430 Acc: 0.9438 | Val Loss: 0.2172 Acc: 0.9173\n",
      "Epoch 037 | Train Loss: 0.1338 Acc: 0.9456 | Val Loss: 0.2094 Acc: 0.9191\n",
      "Epoch 038 | Train Loss: 0.1372 Acc: 0.9444 | Val Loss: 0.2218 Acc: 0.9179\n",
      "Epoch 039 | Train Loss: 0.1269 Acc: 0.9500 | Val Loss: 0.2157 Acc: 0.9233\n",
      "Epoch 040 | Train Loss: 0.1094 Acc: 0.9562 | Val Loss: 0.2216 Acc: 0.9167\n",
      "Epoch 041 | Train Loss: 0.1206 Acc: 0.9529 | Val Loss: 0.2126 Acc: 0.9203\n",
      "Epoch 042 | Train Loss: 0.1136 Acc: 0.9553 | Val Loss: 0.2151 Acc: 0.9257\n",
      "Epoch 043 | Train Loss: 0.1054 Acc: 0.9570 | Val Loss: 0.2116 Acc: 0.9269\n",
      "Epoch 044 | Train Loss: 0.1041 Acc: 0.9603 | Val Loss: 0.2023 Acc: 0.9263\n",
      "Epoch 045 | Train Loss: 0.1068 Acc: 0.9586 | Val Loss: 0.2313 Acc: 0.9155\n",
      "Epoch 046 | Train Loss: 0.0994 Acc: 0.9624 | Val Loss: 0.1957 Acc: 0.9348\n",
      "Epoch 047 | Train Loss: 0.0945 Acc: 0.9654 | Val Loss: 0.2008 Acc: 0.9293\n",
      "Epoch 048 | Train Loss: 0.0958 Acc: 0.9633 | Val Loss: 0.2379 Acc: 0.9227\n",
      "Epoch 049 | Train Loss: 0.0895 Acc: 0.9623 | Val Loss: 0.1889 Acc: 0.9330\n",
      "Epoch 050 | Train Loss: 0.0846 Acc: 0.9680 | Val Loss: 0.2222 Acc: 0.9209\n",
      "Epoch 051 | Train Loss: 0.0899 Acc: 0.9662 | Val Loss: 0.1993 Acc: 0.9293\n",
      "Epoch 052 | Train Loss: 0.0777 Acc: 0.9709 | Val Loss: 0.1899 Acc: 0.9318\n",
      "Epoch 053 | Train Loss: 0.0785 Acc: 0.9700 | Val Loss: 0.2131 Acc: 0.9293\n",
      "Epoch 054 | Train Loss: 0.0740 Acc: 0.9730 | Val Loss: 0.1748 Acc: 0.9378\n",
      "Epoch 055 | Train Loss: 0.0784 Acc: 0.9724 | Val Loss: 0.1777 Acc: 0.9390\n",
      "Epoch 056 | Train Loss: 0.0691 Acc: 0.9731 | Val Loss: 0.1752 Acc: 0.9396\n",
      "Epoch 057 | Train Loss: 0.0783 Acc: 0.9713 | Val Loss: 0.2007 Acc: 0.9342\n",
      "Epoch 058 | Train Loss: 0.0693 Acc: 0.9742 | Val Loss: 0.1833 Acc: 0.9378\n",
      "Epoch 059 | Train Loss: 0.0698 Acc: 0.9731 | Val Loss: 0.1948 Acc: 0.9438\n",
      "Epoch 060 | Train Loss: 0.0657 Acc: 0.9749 | Val Loss: 0.1822 Acc: 0.9444\n",
      "Iteration 11/40 | Best Val Loss: 0.1259 | Iter Time: 235.15s | Total Time: 53.65 min\n",
      "Epoch 001 | Train Loss: 0.6797 Acc: 0.5822 | Val Loss: 0.6716 Acc: 0.5942\n",
      "Epoch 002 | Train Loss: 0.6703 Acc: 0.5996 | Val Loss: 0.6687 Acc: 0.5990\n",
      "Epoch 003 | Train Loss: 0.6627 Acc: 0.6139 | Val Loss: 0.6570 Acc: 0.6039\n",
      "Epoch 004 | Train Loss: 0.6571 Acc: 0.6216 | Val Loss: 0.6441 Acc: 0.6298\n",
      "Epoch 005 | Train Loss: 0.6151 Acc: 0.6787 | Val Loss: 0.6815 Acc: 0.6021\n",
      "Epoch 006 | Train Loss: 0.5793 Acc: 0.7053 | Val Loss: 0.5564 Acc: 0.7307\n",
      "Epoch 007 | Train Loss: 0.5492 Acc: 0.7254 | Val Loss: 0.5436 Acc: 0.7325\n",
      "Epoch 008 | Train Loss: 0.5332 Acc: 0.7343 | Val Loss: 0.5088 Acc: 0.7560\n",
      "Epoch 009 | Train Loss: 0.5071 Acc: 0.7527 | Val Loss: 0.4851 Acc: 0.7663\n",
      "Epoch 010 | Train Loss: 0.4980 Acc: 0.7599 | Val Loss: 0.4789 Acc: 0.7748\n",
      "Epoch 011 | Train Loss: 0.4773 Acc: 0.7734 | Val Loss: 0.4776 Acc: 0.7681\n",
      "Epoch 012 | Train Loss: 0.4490 Acc: 0.7894 | Val Loss: 0.4499 Acc: 0.7935\n",
      "Epoch 013 | Train Loss: 0.4332 Acc: 0.7995 | Val Loss: 0.4137 Acc: 0.8068\n",
      "Epoch 014 | Train Loss: 0.4104 Acc: 0.8187 | Val Loss: 0.4052 Acc: 0.8134\n",
      "Epoch 015 | Train Loss: 0.3883 Acc: 0.8262 | Val Loss: 0.3930 Acc: 0.8273\n",
      "Epoch 016 | Train Loss: 0.3878 Acc: 0.8256 | Val Loss: 0.3684 Acc: 0.8279\n",
      "Epoch 017 | Train Loss: 0.3567 Acc: 0.8469 | Val Loss: 0.3320 Acc: 0.8430\n",
      "Epoch 018 | Train Loss: 0.3327 Acc: 0.8597 | Val Loss: 0.3204 Acc: 0.8539\n",
      "Epoch 019 | Train Loss: 0.3273 Acc: 0.8585 | Val Loss: 0.2929 Acc: 0.8774\n",
      "Epoch 020 | Train Loss: 0.3086 Acc: 0.8714 | Val Loss: 0.3033 Acc: 0.8696\n",
      "Epoch 021 | Train Loss: 0.2989 Acc: 0.8757 | Val Loss: 0.2724 Acc: 0.8810\n",
      "Epoch 022 | Train Loss: 0.2914 Acc: 0.8754 | Val Loss: 0.2593 Acc: 0.8967\n",
      "Epoch 023 | Train Loss: 0.2726 Acc: 0.8884 | Val Loss: 0.2329 Acc: 0.9046\n",
      "Epoch 024 | Train Loss: 0.2588 Acc: 0.8936 | Val Loss: 0.2593 Acc: 0.8913\n",
      "Epoch 025 | Train Loss: 0.2516 Acc: 0.8996 | Val Loss: 0.2786 Acc: 0.8804\n",
      "Epoch 026 | Train Loss: 0.2445 Acc: 0.9029 | Val Loss: 0.2137 Acc: 0.9179\n",
      "Epoch 027 | Train Loss: 0.2407 Acc: 0.9035 | Val Loss: 0.2484 Acc: 0.8925\n",
      "Epoch 028 | Train Loss: 0.2419 Acc: 0.9025 | Val Loss: 0.2133 Acc: 0.9070\n",
      "Epoch 029 | Train Loss: 0.2163 Acc: 0.9151 | Val Loss: 0.2234 Acc: 0.9088\n",
      "Epoch 030 | Train Loss: 0.2292 Acc: 0.9064 | Val Loss: 0.2126 Acc: 0.9100\n",
      "Epoch 031 | Train Loss: 0.2146 Acc: 0.9108 | Val Loss: 0.1939 Acc: 0.9167\n",
      "Epoch 032 | Train Loss: 0.2106 Acc: 0.9144 | Val Loss: 0.1941 Acc: 0.9233\n",
      "Epoch 033 | Train Loss: 0.2020 Acc: 0.9236 | Val Loss: 0.1979 Acc: 0.9191\n",
      "Epoch 034 | Train Loss: 0.1966 Acc: 0.9233 | Val Loss: 0.1804 Acc: 0.9366\n",
      "Epoch 035 | Train Loss: 0.1950 Acc: 0.9245 | Val Loss: 0.2032 Acc: 0.9203\n",
      "Epoch 036 | Train Loss: 0.1972 Acc: 0.9234 | Val Loss: 0.1775 Acc: 0.9336\n",
      "Epoch 037 | Train Loss: 0.1810 Acc: 0.9305 | Val Loss: 0.1849 Acc: 0.9257\n",
      "Epoch 038 | Train Loss: 0.1835 Acc: 0.9221 | Val Loss: 0.1805 Acc: 0.9287\n",
      "Epoch 039 | Train Loss: 0.1743 Acc: 0.9308 | Val Loss: 0.2074 Acc: 0.9185\n",
      "Epoch 040 | Train Loss: 0.1815 Acc: 0.9274 | Val Loss: 0.1792 Acc: 0.9366\n",
      "Epoch 041 | Train Loss: 0.1838 Acc: 0.9271 | Val Loss: 0.1691 Acc: 0.9324\n",
      "Epoch 042 | Train Loss: 0.1680 Acc: 0.9334 | Val Loss: 0.1822 Acc: 0.9221\n",
      "Epoch 043 | Train Loss: 0.1695 Acc: 0.9330 | Val Loss: 0.1811 Acc: 0.9306\n",
      "Epoch 044 | Train Loss: 0.1716 Acc: 0.9315 | Val Loss: 0.1722 Acc: 0.9275\n",
      "Epoch 045 | Train Loss: 0.1662 Acc: 0.9363 | Val Loss: 0.2038 Acc: 0.9251\n",
      "Epoch 046 | Train Loss: 0.1632 Acc: 0.9363 | Val Loss: 0.1723 Acc: 0.9360\n",
      "Epoch 047 | Train Loss: 0.1573 Acc: 0.9390 | Val Loss: 0.1614 Acc: 0.9378\n",
      "Epoch 048 | Train Loss: 0.1585 Acc: 0.9399 | Val Loss: 0.1726 Acc: 0.9318\n",
      "Epoch 049 | Train Loss: 0.1462 Acc: 0.9438 | Val Loss: 0.1584 Acc: 0.9372\n",
      "Epoch 050 | Train Loss: 0.1352 Acc: 0.9487 | Val Loss: 0.1654 Acc: 0.9390\n",
      "Epoch 051 | Train Loss: 0.1484 Acc: 0.9425 | Val Loss: 0.2008 Acc: 0.9233\n",
      "Epoch 052 | Train Loss: 0.1496 Acc: 0.9407 | Val Loss: 0.1964 Acc: 0.9330\n",
      "Epoch 053 | Train Loss: 0.1397 Acc: 0.9475 | Val Loss: 0.1845 Acc: 0.9293\n",
      "Epoch 054 | Train Loss: 0.1418 Acc: 0.9488 | Val Loss: 0.1659 Acc: 0.9384\n",
      "Epoch 055 | Train Loss: 0.1404 Acc: 0.9455 | Val Loss: 0.1809 Acc: 0.9372\n",
      "Epoch 056 | Train Loss: 0.1387 Acc: 0.9473 | Val Loss: 0.1691 Acc: 0.9432\n",
      "Epoch 057 | Train Loss: 0.1339 Acc: 0.9500 | Val Loss: 0.1489 Acc: 0.9432\n",
      "Epoch 058 | Train Loss: 0.1346 Acc: 0.9499 | Val Loss: 0.1504 Acc: 0.9426\n",
      "Epoch 059 | Train Loss: 0.1426 Acc: 0.9450 | Val Loss: 0.2013 Acc: 0.9275\n",
      "Epoch 060 | Train Loss: 0.1359 Acc: 0.9478 | Val Loss: 0.1595 Acc: 0.9330\n",
      "Epoch 001 | Train Loss: 0.6827 Acc: 0.5671 | Val Loss: 0.6748 Acc: 0.5785\n",
      "Epoch 002 | Train Loss: 0.6485 Acc: 0.6381 | Val Loss: 0.6094 Acc: 0.6818\n",
      "Epoch 003 | Train Loss: 0.5866 Acc: 0.7068 | Val Loss: 0.5695 Acc: 0.7041\n",
      "Epoch 004 | Train Loss: 0.5619 Acc: 0.7213 | Val Loss: 0.5538 Acc: 0.7222\n",
      "Epoch 005 | Train Loss: 0.5429 Acc: 0.7309 | Val Loss: 0.5506 Acc: 0.7126\n",
      "Epoch 006 | Train Loss: 0.5197 Acc: 0.7491 | Val Loss: 0.5319 Acc: 0.7295\n",
      "Epoch 007 | Train Loss: 0.5042 Acc: 0.7574 | Val Loss: 0.4953 Acc: 0.7458\n",
      "Epoch 008 | Train Loss: 0.4683 Acc: 0.7850 | Val Loss: 0.5082 Acc: 0.7476\n",
      "Epoch 009 | Train Loss: 0.4558 Acc: 0.7830 | Val Loss: 0.4427 Acc: 0.7856\n",
      "Epoch 010 | Train Loss: 0.4262 Acc: 0.8033 | Val Loss: 0.4188 Acc: 0.7947\n",
      "Epoch 011 | Train Loss: 0.4081 Acc: 0.8104 | Val Loss: 0.3948 Acc: 0.8104\n",
      "Epoch 012 | Train Loss: 0.3850 Acc: 0.8288 | Val Loss: 0.4133 Acc: 0.8050\n",
      "Epoch 013 | Train Loss: 0.3859 Acc: 0.8233 | Val Loss: 0.3604 Acc: 0.8382\n",
      "Epoch 014 | Train Loss: 0.3525 Acc: 0.8421 | Val Loss: 0.3465 Acc: 0.8484\n",
      "Epoch 015 | Train Loss: 0.3411 Acc: 0.8513 | Val Loss: 0.3692 Acc: 0.8388\n",
      "Epoch 016 | Train Loss: 0.3261 Acc: 0.8614 | Val Loss: 0.3236 Acc: 0.8563\n",
      "Epoch 017 | Train Loss: 0.3146 Acc: 0.8670 | Val Loss: 0.3058 Acc: 0.8659\n",
      "Epoch 018 | Train Loss: 0.2933 Acc: 0.8788 | Val Loss: 0.2924 Acc: 0.8786\n",
      "Epoch 019 | Train Loss: 0.2790 Acc: 0.8827 | Val Loss: 0.2614 Acc: 0.8931\n",
      "Epoch 020 | Train Loss: 0.2667 Acc: 0.8896 | Val Loss: 0.2742 Acc: 0.8877\n",
      "Epoch 021 | Train Loss: 0.2646 Acc: 0.8936 | Val Loss: 0.2713 Acc: 0.8859\n",
      "Epoch 022 | Train Loss: 0.2528 Acc: 0.8960 | Val Loss: 0.2604 Acc: 0.8901\n",
      "Epoch 023 | Train Loss: 0.2288 Acc: 0.9082 | Val Loss: 0.2234 Acc: 0.9100\n",
      "Epoch 024 | Train Loss: 0.2303 Acc: 0.9093 | Val Loss: 0.2180 Acc: 0.9064\n",
      "Epoch 025 | Train Loss: 0.2222 Acc: 0.9157 | Val Loss: 0.2234 Acc: 0.9143\n",
      "Epoch 026 | Train Loss: 0.2174 Acc: 0.9121 | Val Loss: 0.2262 Acc: 0.9106\n",
      "Epoch 027 | Train Loss: 0.2075 Acc: 0.9173 | Val Loss: 0.2185 Acc: 0.9106\n",
      "Epoch 028 | Train Loss: 0.1945 Acc: 0.9236 | Val Loss: 0.2000 Acc: 0.9203\n",
      "Epoch 029 | Train Loss: 0.1827 Acc: 0.9318 | Val Loss: 0.2066 Acc: 0.9209\n",
      "Epoch 030 | Train Loss: 0.1913 Acc: 0.9277 | Val Loss: 0.2053 Acc: 0.9136\n",
      "Epoch 031 | Train Loss: 0.1875 Acc: 0.9286 | Val Loss: 0.1857 Acc: 0.9312\n",
      "Epoch 032 | Train Loss: 0.1585 Acc: 0.9375 | Val Loss: 0.1810 Acc: 0.9336\n",
      "Epoch 033 | Train Loss: 0.1697 Acc: 0.9346 | Val Loss: 0.1900 Acc: 0.9233\n",
      "Epoch 034 | Train Loss: 0.1598 Acc: 0.9387 | Val Loss: 0.1975 Acc: 0.9221\n",
      "Epoch 035 | Train Loss: 0.1483 Acc: 0.9431 | Val Loss: 0.2037 Acc: 0.9293\n",
      "Epoch 036 | Train Loss: 0.1529 Acc: 0.9434 | Val Loss: 0.1702 Acc: 0.9354\n",
      "Epoch 037 | Train Loss: 0.1374 Acc: 0.9473 | Val Loss: 0.1892 Acc: 0.9348\n",
      "Epoch 038 | Train Loss: 0.1368 Acc: 0.9487 | Val Loss: 0.1632 Acc: 0.9414\n",
      "Epoch 039 | Train Loss: 0.1347 Acc: 0.9493 | Val Loss: 0.1965 Acc: 0.9287\n",
      "Epoch 040 | Train Loss: 0.1389 Acc: 0.9472 | Val Loss: 0.2257 Acc: 0.9179\n",
      "Epoch 041 | Train Loss: 0.1354 Acc: 0.9459 | Val Loss: 0.1889 Acc: 0.9300\n",
      "Epoch 042 | Train Loss: 0.1226 Acc: 0.9533 | Val Loss: 0.1532 Acc: 0.9414\n",
      "Epoch 043 | Train Loss: 0.1208 Acc: 0.9536 | Val Loss: 0.1445 Acc: 0.9432\n",
      "Epoch 044 | Train Loss: 0.1080 Acc: 0.9586 | Val Loss: 0.1854 Acc: 0.9420\n",
      "Epoch 045 | Train Loss: 0.1243 Acc: 0.9512 | Val Loss: 0.1648 Acc: 0.9318\n",
      "Epoch 046 | Train Loss: 0.1216 Acc: 0.9535 | Val Loss: 0.2120 Acc: 0.9281\n",
      "Epoch 047 | Train Loss: 0.1099 Acc: 0.9558 | Val Loss: 0.1668 Acc: 0.9318\n",
      "Epoch 048 | Train Loss: 0.1197 Acc: 0.9574 | Val Loss: 0.1494 Acc: 0.9481\n",
      "Epoch 049 | Train Loss: 0.1166 Acc: 0.9582 | Val Loss: 0.1603 Acc: 0.9444\n",
      "Epoch 050 | Train Loss: 0.1058 Acc: 0.9621 | Val Loss: 0.1536 Acc: 0.9330\n",
      "Epoch 051 | Train Loss: 0.1110 Acc: 0.9565 | Val Loss: 0.1628 Acc: 0.9414\n",
      "Epoch 052 | Train Loss: 0.1030 Acc: 0.9639 | Val Loss: 0.1530 Acc: 0.9420\n",
      "Epoch 053 | Train Loss: 0.1133 Acc: 0.9571 | Val Loss: 0.1524 Acc: 0.9420\n",
      "Early stopping triggered.\n",
      "Epoch 001 | Train Loss: 0.6809 Acc: 0.5774 | Val Loss: 0.6809 Acc: 0.5725\n",
      "Epoch 002 | Train Loss: 0.6775 Acc: 0.5860 | Val Loss: 0.6744 Acc: 0.5900\n",
      "Epoch 003 | Train Loss: 0.6731 Acc: 0.5916 | Val Loss: 0.6675 Acc: 0.6002\n",
      "Epoch 004 | Train Loss: 0.6608 Acc: 0.6062 | Val Loss: 0.6525 Acc: 0.6111\n",
      "Epoch 005 | Train Loss: 0.6364 Acc: 0.6505 | Val Loss: 0.6195 Acc: 0.6775\n",
      "Epoch 006 | Train Loss: 0.5980 Acc: 0.6994 | Val Loss: 0.5943 Acc: 0.7035\n",
      "Epoch 007 | Train Loss: 0.5748 Acc: 0.7160 | Val Loss: 0.5635 Acc: 0.7186\n",
      "Epoch 008 | Train Loss: 0.5558 Acc: 0.7299 | Val Loss: 0.5794 Acc: 0.7047\n",
      "Epoch 009 | Train Loss: 0.5454 Acc: 0.7323 | Val Loss: 0.5497 Acc: 0.7192\n",
      "Epoch 010 | Train Loss: 0.5367 Acc: 0.7368 | Val Loss: 0.5897 Acc: 0.6920\n",
      "Epoch 011 | Train Loss: 0.5190 Acc: 0.7513 | Val Loss: 0.5193 Acc: 0.7379\n",
      "Epoch 012 | Train Loss: 0.5022 Acc: 0.7605 | Val Loss: 0.5096 Acc: 0.7458\n",
      "Epoch 013 | Train Loss: 0.5016 Acc: 0.7602 | Val Loss: 0.4881 Acc: 0.7560\n",
      "Epoch 014 | Train Loss: 0.4805 Acc: 0.7661 | Val Loss: 0.5021 Acc: 0.7524\n",
      "Epoch 015 | Train Loss: 0.4704 Acc: 0.7783 | Val Loss: 0.4640 Acc: 0.7675\n",
      "Epoch 016 | Train Loss: 0.4648 Acc: 0.7821 | Val Loss: 0.4626 Acc: 0.7742\n",
      "Epoch 017 | Train Loss: 0.4523 Acc: 0.7833 | Val Loss: 0.4547 Acc: 0.7760\n",
      "Epoch 018 | Train Loss: 0.4473 Acc: 0.7877 | Val Loss: 0.4460 Acc: 0.7844\n",
      "Epoch 019 | Train Loss: 0.4271 Acc: 0.8021 | Val Loss: 0.4194 Acc: 0.8080\n",
      "Epoch 020 | Train Loss: 0.4153 Acc: 0.8069 | Val Loss: 0.4474 Acc: 0.7995\n",
      "Epoch 021 | Train Loss: 0.4214 Acc: 0.8073 | Val Loss: 0.4155 Acc: 0.8031\n",
      "Epoch 022 | Train Loss: 0.4024 Acc: 0.8088 | Val Loss: 0.3941 Acc: 0.8158\n",
      "Epoch 023 | Train Loss: 0.3909 Acc: 0.8211 | Val Loss: 0.3914 Acc: 0.8086\n",
      "Epoch 024 | Train Loss: 0.3847 Acc: 0.8267 | Val Loss: 0.3828 Acc: 0.8188\n",
      "Epoch 025 | Train Loss: 0.3781 Acc: 0.8282 | Val Loss: 0.3778 Acc: 0.8303\n",
      "Epoch 026 | Train Loss: 0.3606 Acc: 0.8362 | Val Loss: 0.3519 Acc: 0.8357\n",
      "Epoch 027 | Train Loss: 0.3564 Acc: 0.8359 | Val Loss: 0.3645 Acc: 0.8219\n",
      "Epoch 028 | Train Loss: 0.3472 Acc: 0.8460 | Val Loss: 0.3783 Acc: 0.8188\n",
      "Epoch 029 | Train Loss: 0.3351 Acc: 0.8519 | Val Loss: 0.3362 Acc: 0.8581\n",
      "Epoch 030 | Train Loss: 0.3345 Acc: 0.8570 | Val Loss: 0.3299 Acc: 0.8533\n",
      "Epoch 031 | Train Loss: 0.3229 Acc: 0.8637 | Val Loss: 0.3466 Acc: 0.8430\n",
      "Epoch 032 | Train Loss: 0.3051 Acc: 0.8658 | Val Loss: 0.3219 Acc: 0.8617\n",
      "Epoch 033 | Train Loss: 0.2967 Acc: 0.8727 | Val Loss: 0.2850 Acc: 0.8822\n",
      "Epoch 034 | Train Loss: 0.2946 Acc: 0.8692 | Val Loss: 0.2783 Acc: 0.8804\n",
      "Epoch 035 | Train Loss: 0.2793 Acc: 0.8788 | Val Loss: 0.3085 Acc: 0.8690\n",
      "Epoch 036 | Train Loss: 0.2818 Acc: 0.8771 | Val Loss: 0.2887 Acc: 0.8768\n",
      "Epoch 037 | Train Loss: 0.2745 Acc: 0.8842 | Val Loss: 0.2779 Acc: 0.8841\n",
      "Epoch 038 | Train Loss: 0.2533 Acc: 0.8942 | Val Loss: 0.2746 Acc: 0.8829\n",
      "Epoch 039 | Train Loss: 0.2671 Acc: 0.8916 | Val Loss: 0.2859 Acc: 0.8768\n",
      "Epoch 040 | Train Loss: 0.2518 Acc: 0.8948 | Val Loss: 0.2717 Acc: 0.8786\n",
      "Epoch 041 | Train Loss: 0.2493 Acc: 0.8978 | Val Loss: 0.2943 Acc: 0.8762\n",
      "Epoch 042 | Train Loss: 0.2470 Acc: 0.8943 | Val Loss: 0.3083 Acc: 0.8726\n",
      "Epoch 043 | Train Loss: 0.2495 Acc: 0.8979 | Val Loss: 0.2709 Acc: 0.8871\n",
      "Epoch 044 | Train Loss: 0.2304 Acc: 0.9056 | Val Loss: 0.2442 Acc: 0.9028\n",
      "Epoch 045 | Train Loss: 0.2407 Acc: 0.8966 | Val Loss: 0.2555 Acc: 0.8992\n",
      "Epoch 046 | Train Loss: 0.2291 Acc: 0.9055 | Val Loss: 0.2419 Acc: 0.8973\n",
      "Epoch 047 | Train Loss: 0.2308 Acc: 0.9050 | Val Loss: 0.2351 Acc: 0.9058\n",
      "Epoch 048 | Train Loss: 0.2261 Acc: 0.9087 | Val Loss: 0.2416 Acc: 0.8955\n",
      "Epoch 049 | Train Loss: 0.2124 Acc: 0.9123 | Val Loss: 0.2576 Acc: 0.8895\n",
      "Epoch 050 | Train Loss: 0.2162 Acc: 0.9099 | Val Loss: 0.2344 Acc: 0.9088\n",
      "Epoch 051 | Train Loss: 0.2124 Acc: 0.9145 | Val Loss: 0.2230 Acc: 0.9143\n",
      "Epoch 052 | Train Loss: 0.2138 Acc: 0.9133 | Val Loss: 0.2238 Acc: 0.9118\n",
      "Epoch 053 | Train Loss: 0.2056 Acc: 0.9191 | Val Loss: 0.2132 Acc: 0.9203\n",
      "Epoch 054 | Train Loss: 0.1987 Acc: 0.9222 | Val Loss: 0.2367 Acc: 0.9088\n",
      "Epoch 055 | Train Loss: 0.2139 Acc: 0.9176 | Val Loss: 0.2128 Acc: 0.9227\n",
      "Epoch 056 | Train Loss: 0.1858 Acc: 0.9275 | Val Loss: 0.2065 Acc: 0.9191\n",
      "Epoch 057 | Train Loss: 0.1953 Acc: 0.9244 | Val Loss: 0.2463 Acc: 0.9034\n",
      "Epoch 058 | Train Loss: 0.1965 Acc: 0.9224 | Val Loss: 0.2266 Acc: 0.9106\n",
      "Epoch 059 | Train Loss: 0.1884 Acc: 0.9284 | Val Loss: 0.2214 Acc: 0.9118\n",
      "Epoch 060 | Train Loss: 0.1836 Acc: 0.9272 | Val Loss: 0.1992 Acc: 0.9263\n",
      "Epoch 001 | Train Loss: 0.6802 Acc: 0.5676 | Val Loss: 0.6681 Acc: 0.5773\n",
      "Epoch 002 | Train Loss: 0.6455 Acc: 0.6343 | Val Loss: 0.6135 Acc: 0.6703\n",
      "Epoch 003 | Train Loss: 0.6003 Acc: 0.6899 | Val Loss: 0.5749 Acc: 0.7083\n",
      "Epoch 004 | Train Loss: 0.5682 Acc: 0.7139 | Val Loss: 0.5596 Acc: 0.7126\n",
      "Epoch 005 | Train Loss: 0.5387 Acc: 0.7356 | Val Loss: 0.5818 Acc: 0.7246\n",
      "Epoch 006 | Train Loss: 0.5273 Acc: 0.7497 | Val Loss: 0.5098 Acc: 0.7464\n",
      "Epoch 007 | Train Loss: 0.5034 Acc: 0.7632 | Val Loss: 0.5077 Acc: 0.7476\n",
      "Epoch 008 | Train Loss: 0.4864 Acc: 0.7690 | Val Loss: 0.5071 Acc: 0.7434\n",
      "Epoch 009 | Train Loss: 0.4667 Acc: 0.7759 | Val Loss: 0.4626 Acc: 0.7717\n",
      "Epoch 010 | Train Loss: 0.4401 Acc: 0.7978 | Val Loss: 0.4439 Acc: 0.7893\n",
      "Epoch 011 | Train Loss: 0.4302 Acc: 0.7962 | Val Loss: 0.4205 Acc: 0.7905\n",
      "Epoch 012 | Train Loss: 0.4048 Acc: 0.8194 | Val Loss: 0.3874 Acc: 0.8176\n",
      "Epoch 013 | Train Loss: 0.3853 Acc: 0.8267 | Val Loss: 0.4614 Acc: 0.7899\n",
      "Epoch 014 | Train Loss: 0.3827 Acc: 0.8335 | Val Loss: 0.3544 Acc: 0.8406\n",
      "Epoch 015 | Train Loss: 0.3579 Acc: 0.8451 | Val Loss: 0.3221 Acc: 0.8569\n",
      "Epoch 016 | Train Loss: 0.3359 Acc: 0.8578 | Val Loss: 0.3382 Acc: 0.8684\n",
      "Epoch 017 | Train Loss: 0.3253 Acc: 0.8603 | Val Loss: 0.3233 Acc: 0.8671\n",
      "Epoch 018 | Train Loss: 0.3094 Acc: 0.8688 | Val Loss: 0.2926 Acc: 0.8798\n",
      "Epoch 019 | Train Loss: 0.2877 Acc: 0.8801 | Val Loss: 0.2834 Acc: 0.8786\n",
      "Epoch 020 | Train Loss: 0.2738 Acc: 0.8868 | Val Loss: 0.3071 Acc: 0.8696\n",
      "Epoch 021 | Train Loss: 0.2706 Acc: 0.8911 | Val Loss: 0.2551 Acc: 0.8998\n",
      "Epoch 022 | Train Loss: 0.2526 Acc: 0.8942 | Val Loss: 0.2386 Acc: 0.8979\n",
      "Epoch 023 | Train Loss: 0.2420 Acc: 0.9026 | Val Loss: 0.2699 Acc: 0.8931\n",
      "Epoch 024 | Train Loss: 0.2459 Acc: 0.8987 | Val Loss: 0.2499 Acc: 0.9010\n",
      "Epoch 025 | Train Loss: 0.2358 Acc: 0.9050 | Val Loss: 0.2375 Acc: 0.9094\n",
      "Epoch 026 | Train Loss: 0.2266 Acc: 0.9117 | Val Loss: 0.2343 Acc: 0.9022\n",
      "Epoch 027 | Train Loss: 0.2116 Acc: 0.9168 | Val Loss: 0.2170 Acc: 0.9149\n",
      "Epoch 028 | Train Loss: 0.2111 Acc: 0.9195 | Val Loss: 0.2614 Acc: 0.8992\n",
      "Epoch 029 | Train Loss: 0.2052 Acc: 0.9215 | Val Loss: 0.2117 Acc: 0.9275\n",
      "Epoch 030 | Train Loss: 0.2004 Acc: 0.9216 | Val Loss: 0.2071 Acc: 0.9197\n",
      "Epoch 031 | Train Loss: 0.1924 Acc: 0.9233 | Val Loss: 0.2020 Acc: 0.9233\n",
      "Epoch 032 | Train Loss: 0.1976 Acc: 0.9239 | Val Loss: 0.2189 Acc: 0.9149\n",
      "Epoch 033 | Train Loss: 0.1817 Acc: 0.9293 | Val Loss: 0.1900 Acc: 0.9293\n",
      "Epoch 034 | Train Loss: 0.1830 Acc: 0.9283 | Val Loss: 0.1941 Acc: 0.9324\n",
      "Epoch 035 | Train Loss: 0.1712 Acc: 0.9343 | Val Loss: 0.2089 Acc: 0.9215\n",
      "Epoch 036 | Train Loss: 0.1817 Acc: 0.9302 | Val Loss: 0.1900 Acc: 0.9215\n",
      "Epoch 037 | Train Loss: 0.1695 Acc: 0.9366 | Val Loss: 0.1983 Acc: 0.9263\n",
      "Epoch 038 | Train Loss: 0.1652 Acc: 0.9349 | Val Loss: 0.1757 Acc: 0.9293\n",
      "Epoch 039 | Train Loss: 0.1644 Acc: 0.9369 | Val Loss: 0.1880 Acc: 0.9306\n",
      "Epoch 040 | Train Loss: 0.1587 Acc: 0.9390 | Val Loss: 0.1915 Acc: 0.9275\n",
      "Epoch 041 | Train Loss: 0.1541 Acc: 0.9425 | Val Loss: 0.1798 Acc: 0.9306\n",
      "Epoch 042 | Train Loss: 0.1453 Acc: 0.9446 | Val Loss: 0.1582 Acc: 0.9432\n",
      "Epoch 043 | Train Loss: 0.1403 Acc: 0.9479 | Val Loss: 0.2098 Acc: 0.9179\n",
      "Epoch 044 | Train Loss: 0.1426 Acc: 0.9441 | Val Loss: 0.1442 Acc: 0.9499\n",
      "Epoch 045 | Train Loss: 0.1404 Acc: 0.9470 | Val Loss: 0.1579 Acc: 0.9432\n",
      "Epoch 046 | Train Loss: 0.1361 Acc: 0.9499 | Val Loss: 0.1648 Acc: 0.9378\n",
      "Epoch 047 | Train Loss: 0.1412 Acc: 0.9481 | Val Loss: 0.1642 Acc: 0.9330\n",
      "Epoch 048 | Train Loss: 0.1328 Acc: 0.9505 | Val Loss: 0.1678 Acc: 0.9378\n",
      "Epoch 049 | Train Loss: 0.1288 Acc: 0.9493 | Val Loss: 0.1519 Acc: 0.9457\n",
      "Epoch 050 | Train Loss: 0.1260 Acc: 0.9553 | Val Loss: 0.1500 Acc: 0.9469\n",
      "Epoch 051 | Train Loss: 0.1358 Acc: 0.9493 | Val Loss: 0.1828 Acc: 0.9281\n",
      "Epoch 052 | Train Loss: 0.1148 Acc: 0.9585 | Val Loss: 0.1535 Acc: 0.9396\n",
      "Epoch 053 | Train Loss: 0.1264 Acc: 0.9580 | Val Loss: 0.1329 Acc: 0.9493\n",
      "Epoch 054 | Train Loss: 0.1143 Acc: 0.9568 | Val Loss: 0.1512 Acc: 0.9408\n",
      "Epoch 055 | Train Loss: 0.1276 Acc: 0.9499 | Val Loss: 0.1839 Acc: 0.9372\n",
      "Epoch 056 | Train Loss: 0.1228 Acc: 0.9503 | Val Loss: 0.1699 Acc: 0.9324\n",
      "Epoch 057 | Train Loss: 0.1079 Acc: 0.9609 | Val Loss: 0.1394 Acc: 0.9541\n",
      "Epoch 058 | Train Loss: 0.1139 Acc: 0.9570 | Val Loss: 0.1411 Acc: 0.9450\n",
      "Epoch 059 | Train Loss: 0.1174 Acc: 0.9550 | Val Loss: 0.1625 Acc: 0.9354\n",
      "Epoch 060 | Train Loss: 0.1073 Acc: 0.9588 | Val Loss: 0.1409 Acc: 0.9523\n",
      "Epoch 001 | Train Loss: 0.6855 Acc: 0.5556 | Val Loss: 0.6992 Acc: 0.5332\n",
      "Epoch 002 | Train Loss: 0.6745 Acc: 0.5925 | Val Loss: 0.6744 Acc: 0.5924\n",
      "Epoch 003 | Train Loss: 0.6560 Acc: 0.6121 | Val Loss: 0.6349 Acc: 0.6606\n",
      "Epoch 004 | Train Loss: 0.6191 Acc: 0.6727 | Val Loss: 0.6098 Acc: 0.6781\n",
      "Epoch 005 | Train Loss: 0.5737 Acc: 0.7089 | Val Loss: 0.5622 Acc: 0.7174\n",
      "Epoch 006 | Train Loss: 0.5480 Acc: 0.7299 | Val Loss: 0.5613 Acc: 0.7120\n",
      "Epoch 007 | Train Loss: 0.5344 Acc: 0.7371 | Val Loss: 0.5184 Acc: 0.7403\n",
      "Epoch 008 | Train Loss: 0.4994 Acc: 0.7571 | Val Loss: 0.4957 Acc: 0.7524\n",
      "Epoch 009 | Train Loss: 0.4931 Acc: 0.7634 | Val Loss: 0.4925 Acc: 0.7470\n",
      "Epoch 010 | Train Loss: 0.4708 Acc: 0.7806 | Val Loss: 0.4593 Acc: 0.7711\n",
      "Epoch 011 | Train Loss: 0.4373 Acc: 0.7959 | Val Loss: 0.4616 Acc: 0.7820\n",
      "Epoch 012 | Train Loss: 0.4088 Acc: 0.8102 | Val Loss: 0.4131 Acc: 0.7929\n",
      "Epoch 013 | Train Loss: 0.3904 Acc: 0.8247 | Val Loss: 0.3842 Acc: 0.8182\n",
      "Epoch 014 | Train Loss: 0.3599 Acc: 0.8380 | Val Loss: 0.3758 Acc: 0.8309\n",
      "Epoch 015 | Train Loss: 0.3508 Acc: 0.8481 | Val Loss: 0.3432 Acc: 0.8394\n",
      "Epoch 016 | Train Loss: 0.3143 Acc: 0.8661 | Val Loss: 0.3135 Acc: 0.8623\n",
      "Epoch 017 | Train Loss: 0.3021 Acc: 0.8735 | Val Loss: 0.3276 Acc: 0.8611\n",
      "Epoch 018 | Train Loss: 0.2930 Acc: 0.8778 | Val Loss: 0.3233 Acc: 0.8635\n",
      "Epoch 019 | Train Loss: 0.2612 Acc: 0.8939 | Val Loss: 0.2471 Acc: 0.8986\n",
      "Epoch 020 | Train Loss: 0.2414 Acc: 0.9058 | Val Loss: 0.2659 Acc: 0.8986\n",
      "Epoch 021 | Train Loss: 0.2364 Acc: 0.9037 | Val Loss: 0.2262 Acc: 0.9052\n",
      "Epoch 022 | Train Loss: 0.2156 Acc: 0.9117 | Val Loss: 0.2473 Acc: 0.8913\n",
      "Epoch 023 | Train Loss: 0.2140 Acc: 0.9117 | Val Loss: 0.2411 Acc: 0.9058\n",
      "Epoch 024 | Train Loss: 0.1995 Acc: 0.9212 | Val Loss: 0.2354 Acc: 0.9010\n",
      "Epoch 025 | Train Loss: 0.1803 Acc: 0.9262 | Val Loss: 0.2479 Acc: 0.9028\n",
      "Epoch 026 | Train Loss: 0.1798 Acc: 0.9296 | Val Loss: 0.2378 Acc: 0.9076\n",
      "Epoch 027 | Train Loss: 0.1645 Acc: 0.9349 | Val Loss: 0.2539 Acc: 0.9010\n",
      "Epoch 028 | Train Loss: 0.1697 Acc: 0.9357 | Val Loss: 0.1843 Acc: 0.9263\n",
      "Epoch 029 | Train Loss: 0.1618 Acc: 0.9343 | Val Loss: 0.1920 Acc: 0.9269\n",
      "Epoch 030 | Train Loss: 0.1549 Acc: 0.9379 | Val Loss: 0.1812 Acc: 0.9239\n",
      "Epoch 031 | Train Loss: 0.1476 Acc: 0.9420 | Val Loss: 0.1813 Acc: 0.9263\n",
      "Epoch 032 | Train Loss: 0.1409 Acc: 0.9467 | Val Loss: 0.1799 Acc: 0.9281\n",
      "Epoch 033 | Train Loss: 0.1364 Acc: 0.9487 | Val Loss: 0.2351 Acc: 0.9124\n",
      "Epoch 034 | Train Loss: 0.1336 Acc: 0.9481 | Val Loss: 0.1765 Acc: 0.9293\n",
      "Epoch 035 | Train Loss: 0.1278 Acc: 0.9502 | Val Loss: 0.1845 Acc: 0.9318\n",
      "Epoch 036 | Train Loss: 0.1159 Acc: 0.9565 | Val Loss: 0.1763 Acc: 0.9330\n",
      "Epoch 037 | Train Loss: 0.1166 Acc: 0.9558 | Val Loss: 0.1671 Acc: 0.9330\n",
      "Epoch 038 | Train Loss: 0.1101 Acc: 0.9597 | Val Loss: 0.1897 Acc: 0.9342\n",
      "Epoch 039 | Train Loss: 0.1016 Acc: 0.9633 | Val Loss: 0.1653 Acc: 0.9426\n",
      "Epoch 040 | Train Loss: 0.1101 Acc: 0.9580 | Val Loss: 0.1552 Acc: 0.9336\n",
      "Epoch 041 | Train Loss: 0.0973 Acc: 0.9626 | Val Loss: 0.1389 Acc: 0.9457\n",
      "Epoch 042 | Train Loss: 0.1034 Acc: 0.9629 | Val Loss: 0.1492 Acc: 0.9444\n",
      "Epoch 043 | Train Loss: 0.0964 Acc: 0.9629 | Val Loss: 0.1620 Acc: 0.9402\n",
      "Epoch 044 | Train Loss: 0.1035 Acc: 0.9600 | Val Loss: 0.1253 Acc: 0.9517\n",
      "Epoch 045 | Train Loss: 0.0969 Acc: 0.9645 | Val Loss: 0.1402 Acc: 0.9469\n",
      "Epoch 046 | Train Loss: 0.1012 Acc: 0.9633 | Val Loss: 0.1322 Acc: 0.9487\n",
      "Epoch 047 | Train Loss: 0.0878 Acc: 0.9681 | Val Loss: 0.1378 Acc: 0.9469\n",
      "Epoch 048 | Train Loss: 0.0868 Acc: 0.9684 | Val Loss: 0.1665 Acc: 0.9414\n",
      "Epoch 049 | Train Loss: 0.0872 Acc: 0.9666 | Val Loss: 0.1448 Acc: 0.9450\n",
      "Epoch 050 | Train Loss: 0.0840 Acc: 0.9701 | Val Loss: 0.1415 Acc: 0.9523\n",
      "Epoch 051 | Train Loss: 0.0812 Acc: 0.9715 | Val Loss: 0.1392 Acc: 0.9499\n",
      "Epoch 052 | Train Loss: 0.0797 Acc: 0.9700 | Val Loss: 0.1614 Acc: 0.9384\n",
      "Epoch 053 | Train Loss: 0.0804 Acc: 0.9713 | Val Loss: 0.1122 Acc: 0.9559\n",
      "Epoch 054 | Train Loss: 0.0695 Acc: 0.9746 | Val Loss: 0.1330 Acc: 0.9511\n",
      "Epoch 055 | Train Loss: 0.0729 Acc: 0.9749 | Val Loss: 0.1344 Acc: 0.9481\n",
      "Epoch 056 | Train Loss: 0.0864 Acc: 0.9707 | Val Loss: 0.1481 Acc: 0.9432\n",
      "Epoch 057 | Train Loss: 0.0804 Acc: 0.9707 | Val Loss: 0.1627 Acc: 0.9475\n",
      "Epoch 058 | Train Loss: 0.0773 Acc: 0.9698 | Val Loss: 0.1241 Acc: 0.9541\n",
      "Epoch 059 | Train Loss: 0.0598 Acc: 0.9784 | Val Loss: 0.1570 Acc: 0.9529\n",
      "Epoch 060 | Train Loss: 0.0659 Acc: 0.9755 | Val Loss: 0.1422 Acc: 0.9505\n",
      "Epoch 001 | Train Loss: 0.6858 Acc: 0.5596 | Val Loss: 0.6838 Acc: 0.5507\n",
      "Epoch 002 | Train Loss: 0.6765 Acc: 0.5834 | Val Loss: 0.6621 Acc: 0.6033\n",
      "Epoch 003 | Train Loss: 0.6400 Acc: 0.6527 | Val Loss: 0.6113 Acc: 0.6920\n",
      "Epoch 004 | Train Loss: 0.6026 Acc: 0.6865 | Val Loss: 0.5832 Acc: 0.7120\n",
      "Epoch 005 | Train Loss: 0.5872 Acc: 0.7060 | Val Loss: 0.5506 Acc: 0.7373\n",
      "Epoch 006 | Train Loss: 0.5704 Acc: 0.7211 | Val Loss: 0.5538 Acc: 0.7295\n",
      "Epoch 007 | Train Loss: 0.5498 Acc: 0.7314 | Val Loss: 0.5483 Acc: 0.7361\n",
      "Epoch 008 | Train Loss: 0.5363 Acc: 0.7423 | Val Loss: 0.5248 Acc: 0.7385\n",
      "Epoch 009 | Train Loss: 0.5170 Acc: 0.7522 | Val Loss: 0.4850 Acc: 0.7657\n",
      "Epoch 010 | Train Loss: 0.5014 Acc: 0.7607 | Val Loss: 0.4819 Acc: 0.7711\n",
      "Epoch 011 | Train Loss: 0.4951 Acc: 0.7652 | Val Loss: 0.4720 Acc: 0.7681\n",
      "Epoch 012 | Train Loss: 0.4818 Acc: 0.7708 | Val Loss: 0.4692 Acc: 0.7832\n",
      "Epoch 013 | Train Loss: 0.4699 Acc: 0.7780 | Val Loss: 0.4828 Acc: 0.7736\n",
      "Epoch 014 | Train Loss: 0.4681 Acc: 0.7848 | Val Loss: 0.4317 Acc: 0.7899\n",
      "Epoch 015 | Train Loss: 0.4452 Acc: 0.7969 | Val Loss: 0.4282 Acc: 0.8043\n",
      "Epoch 016 | Train Loss: 0.4376 Acc: 0.7959 | Val Loss: 0.4175 Acc: 0.8037\n",
      "Epoch 017 | Train Loss: 0.4426 Acc: 0.7978 | Val Loss: 0.4354 Acc: 0.7862\n",
      "Epoch 018 | Train Loss: 0.4331 Acc: 0.8027 | Val Loss: 0.4103 Acc: 0.8128\n",
      "Epoch 019 | Train Loss: 0.4116 Acc: 0.8108 | Val Loss: 0.4234 Acc: 0.8092\n",
      "Epoch 020 | Train Loss: 0.4044 Acc: 0.8173 | Val Loss: 0.3957 Acc: 0.8249\n",
      "Epoch 021 | Train Loss: 0.4005 Acc: 0.8230 | Val Loss: 0.3917 Acc: 0.8285\n",
      "Epoch 022 | Train Loss: 0.3944 Acc: 0.8214 | Val Loss: 0.3872 Acc: 0.8200\n",
      "Epoch 023 | Train Loss: 0.3889 Acc: 0.8297 | Val Loss: 0.3678 Acc: 0.8394\n",
      "Epoch 024 | Train Loss: 0.3640 Acc: 0.8357 | Val Loss: 0.3714 Acc: 0.8351\n",
      "Epoch 025 | Train Loss: 0.3796 Acc: 0.8369 | Val Loss: 0.3525 Acc: 0.8478\n",
      "Epoch 026 | Train Loss: 0.3695 Acc: 0.8434 | Val Loss: 0.3734 Acc: 0.8406\n",
      "Epoch 027 | Train Loss: 0.3512 Acc: 0.8481 | Val Loss: 0.3319 Acc: 0.8599\n",
      "Epoch 028 | Train Loss: 0.3481 Acc: 0.8514 | Val Loss: 0.3683 Acc: 0.8339\n",
      "Epoch 029 | Train Loss: 0.3349 Acc: 0.8617 | Val Loss: 0.3360 Acc: 0.8599\n",
      "Epoch 030 | Train Loss: 0.3323 Acc: 0.8594 | Val Loss: 0.3381 Acc: 0.8629\n",
      "Epoch 031 | Train Loss: 0.3279 Acc: 0.8620 | Val Loss: 0.2954 Acc: 0.8774\n",
      "Epoch 032 | Train Loss: 0.3123 Acc: 0.8712 | Val Loss: 0.3433 Acc: 0.8418\n",
      "Epoch 033 | Train Loss: 0.3288 Acc: 0.8640 | Val Loss: 0.3148 Acc: 0.8623\n",
      "Epoch 034 | Train Loss: 0.3142 Acc: 0.8682 | Val Loss: 0.2876 Acc: 0.8829\n",
      "Epoch 035 | Train Loss: 0.2941 Acc: 0.8751 | Val Loss: 0.2993 Acc: 0.8798\n",
      "Epoch 036 | Train Loss: 0.3023 Acc: 0.8741 | Val Loss: 0.2988 Acc: 0.8780\n",
      "Epoch 037 | Train Loss: 0.3108 Acc: 0.8683 | Val Loss: 0.3382 Acc: 0.8569\n",
      "Epoch 038 | Train Loss: 0.2995 Acc: 0.8791 | Val Loss: 0.2763 Acc: 0.8841\n",
      "Epoch 039 | Train Loss: 0.2924 Acc: 0.8824 | Val Loss: 0.2874 Acc: 0.8792\n",
      "Epoch 040 | Train Loss: 0.2841 Acc: 0.8831 | Val Loss: 0.2863 Acc: 0.8877\n",
      "Epoch 041 | Train Loss: 0.2792 Acc: 0.8869 | Val Loss: 0.3298 Acc: 0.8575\n",
      "Epoch 042 | Train Loss: 0.2619 Acc: 0.8934 | Val Loss: 0.2671 Acc: 0.8937\n",
      "Epoch 043 | Train Loss: 0.2703 Acc: 0.8863 | Val Loss: 0.2873 Acc: 0.8853\n",
      "Epoch 044 | Train Loss: 0.2564 Acc: 0.8963 | Val Loss: 0.2857 Acc: 0.8810\n",
      "Epoch 045 | Train Loss: 0.2667 Acc: 0.8946 | Val Loss: 0.2670 Acc: 0.8943\n",
      "Epoch 046 | Train Loss: 0.2548 Acc: 0.8990 | Val Loss: 0.2536 Acc: 0.8973\n",
      "Epoch 047 | Train Loss: 0.2505 Acc: 0.8997 | Val Loss: 0.2870 Acc: 0.8949\n",
      "Epoch 048 | Train Loss: 0.2518 Acc: 0.8997 | Val Loss: 0.2428 Acc: 0.9034\n",
      "Epoch 049 | Train Loss: 0.2401 Acc: 0.8990 | Val Loss: 0.2858 Acc: 0.8901\n",
      "Epoch 050 | Train Loss: 0.2496 Acc: 0.8969 | Val Loss: 0.2468 Acc: 0.8973\n",
      "Epoch 051 | Train Loss: 0.2361 Acc: 0.9070 | Val Loss: 0.2283 Acc: 0.9064\n",
      "Epoch 052 | Train Loss: 0.2217 Acc: 0.9100 | Val Loss: 0.2355 Acc: 0.9118\n",
      "Epoch 053 | Train Loss: 0.2324 Acc: 0.9114 | Val Loss: 0.2186 Acc: 0.9094\n",
      "Epoch 054 | Train Loss: 0.2303 Acc: 0.9103 | Val Loss: 0.2367 Acc: 0.9004\n",
      "Epoch 055 | Train Loss: 0.2292 Acc: 0.9111 | Val Loss: 0.2383 Acc: 0.8943\n",
      "Epoch 056 | Train Loss: 0.2216 Acc: 0.9141 | Val Loss: 0.2183 Acc: 0.9082\n",
      "Epoch 057 | Train Loss: 0.2299 Acc: 0.9077 | Val Loss: 0.2294 Acc: 0.9094\n",
      "Epoch 058 | Train Loss: 0.2166 Acc: 0.9162 | Val Loss: 0.1999 Acc: 0.9179\n",
      "Epoch 059 | Train Loss: 0.2099 Acc: 0.9173 | Val Loss: 0.2236 Acc: 0.9100\n",
      "Epoch 060 | Train Loss: 0.2194 Acc: 0.9127 | Val Loss: 0.2491 Acc: 0.8925\n",
      "Epoch 001 | Train Loss: 0.6780 Acc: 0.5781 | Val Loss: 0.6748 Acc: 0.5900\n",
      "Epoch 002 | Train Loss: 0.6747 Acc: 0.5913 | Val Loss: 0.6743 Acc: 0.5930\n",
      "Epoch 003 | Train Loss: 0.6699 Acc: 0.5966 | Val Loss: 0.6679 Acc: 0.6014\n",
      "Epoch 004 | Train Loss: 0.6692 Acc: 0.5972 | Val Loss: 0.6843 Acc: 0.5598\n",
      "Epoch 005 | Train Loss: 0.6795 Acc: 0.5763 | Val Loss: 0.6776 Acc: 0.5809\n",
      "Epoch 006 | Train Loss: 0.6671 Acc: 0.6055 | Val Loss: 0.6644 Acc: 0.6123\n",
      "Epoch 007 | Train Loss: 0.6587 Acc: 0.6169 | Val Loss: 0.6451 Acc: 0.6606\n",
      "Epoch 008 | Train Loss: 0.6250 Acc: 0.6644 | Val Loss: 0.6390 Acc: 0.6510\n",
      "Epoch 009 | Train Loss: 0.5957 Acc: 0.6935 | Val Loss: 0.5836 Acc: 0.7029\n",
      "Epoch 010 | Train Loss: 0.5598 Acc: 0.7284 | Val Loss: 0.5421 Acc: 0.7313\n",
      "Epoch 011 | Train Loss: 0.5446 Acc: 0.7361 | Val Loss: 0.5336 Acc: 0.7337\n",
      "Epoch 012 | Train Loss: 0.5247 Acc: 0.7504 | Val Loss: 0.5143 Acc: 0.7434\n",
      "Epoch 013 | Train Loss: 0.5013 Acc: 0.7578 | Val Loss: 0.4928 Acc: 0.7530\n",
      "Epoch 014 | Train Loss: 0.4825 Acc: 0.7731 | Val Loss: 0.4913 Acc: 0.7518\n",
      "Epoch 015 | Train Loss: 0.4685 Acc: 0.7805 | Val Loss: 0.4868 Acc: 0.7512\n",
      "Epoch 016 | Train Loss: 0.4593 Acc: 0.7836 | Val Loss: 0.4508 Acc: 0.7784\n",
      "Epoch 017 | Train Loss: 0.4352 Acc: 0.7986 | Val Loss: 0.4206 Acc: 0.7911\n",
      "Epoch 018 | Train Loss: 0.4118 Acc: 0.8153 | Val Loss: 0.3978 Acc: 0.8164\n",
      "Epoch 019 | Train Loss: 0.3916 Acc: 0.8258 | Val Loss: 0.3915 Acc: 0.8110\n",
      "Epoch 020 | Train Loss: 0.3826 Acc: 0.8250 | Val Loss: 0.3638 Acc: 0.8339\n",
      "Epoch 021 | Train Loss: 0.3729 Acc: 0.8335 | Val Loss: 0.3963 Acc: 0.8062\n",
      "Epoch 022 | Train Loss: 0.3554 Acc: 0.8451 | Val Loss: 0.3296 Acc: 0.8478\n",
      "Epoch 023 | Train Loss: 0.3336 Acc: 0.8587 | Val Loss: 0.3278 Acc: 0.8502\n",
      "Epoch 024 | Train Loss: 0.3192 Acc: 0.8652 | Val Loss: 0.3100 Acc: 0.8659\n",
      "Epoch 025 | Train Loss: 0.3096 Acc: 0.8680 | Val Loss: 0.2943 Acc: 0.8714\n",
      "Epoch 026 | Train Loss: 0.2909 Acc: 0.8739 | Val Loss: 0.2900 Acc: 0.8720\n",
      "Epoch 027 | Train Loss: 0.2935 Acc: 0.8783 | Val Loss: 0.2809 Acc: 0.8798\n",
      "Epoch 028 | Train Loss: 0.2698 Acc: 0.8851 | Val Loss: 0.2726 Acc: 0.8901\n",
      "Epoch 029 | Train Loss: 0.2562 Acc: 0.8922 | Val Loss: 0.2620 Acc: 0.8913\n",
      "Epoch 030 | Train Loss: 0.2528 Acc: 0.8939 | Val Loss: 0.2539 Acc: 0.8986\n",
      "Epoch 031 | Train Loss: 0.2434 Acc: 0.9005 | Val Loss: 0.2791 Acc: 0.8847\n",
      "Epoch 032 | Train Loss: 0.2386 Acc: 0.9068 | Val Loss: 0.2553 Acc: 0.8925\n",
      "Epoch 033 | Train Loss: 0.2283 Acc: 0.9085 | Val Loss: 0.2511 Acc: 0.9040\n",
      "Epoch 034 | Train Loss: 0.2114 Acc: 0.9156 | Val Loss: 0.2356 Acc: 0.9076\n",
      "Epoch 035 | Train Loss: 0.2258 Acc: 0.9077 | Val Loss: 0.2386 Acc: 0.9094\n",
      "Epoch 036 | Train Loss: 0.2021 Acc: 0.9197 | Val Loss: 0.2126 Acc: 0.9185\n",
      "Epoch 037 | Train Loss: 0.2034 Acc: 0.9203 | Val Loss: 0.2270 Acc: 0.9076\n",
      "Epoch 038 | Train Loss: 0.1896 Acc: 0.9250 | Val Loss: 0.2430 Acc: 0.8979\n",
      "Epoch 039 | Train Loss: 0.1862 Acc: 0.9262 | Val Loss: 0.2284 Acc: 0.9112\n",
      "Epoch 040 | Train Loss: 0.1836 Acc: 0.9311 | Val Loss: 0.2376 Acc: 0.9088\n",
      "Epoch 041 | Train Loss: 0.1948 Acc: 0.9224 | Val Loss: 0.2143 Acc: 0.9130\n",
      "Epoch 042 | Train Loss: 0.1723 Acc: 0.9324 | Val Loss: 0.2071 Acc: 0.9185\n",
      "Epoch 043 | Train Loss: 0.1710 Acc: 0.9352 | Val Loss: 0.2199 Acc: 0.9155\n",
      "Epoch 044 | Train Loss: 0.1612 Acc: 0.9373 | Val Loss: 0.2257 Acc: 0.9100\n",
      "Epoch 045 | Train Loss: 0.1635 Acc: 0.9402 | Val Loss: 0.2054 Acc: 0.9227\n",
      "Epoch 046 | Train Loss: 0.1636 Acc: 0.9355 | Val Loss: 0.2173 Acc: 0.9167\n",
      "Epoch 047 | Train Loss: 0.1651 Acc: 0.9339 | Val Loss: 0.1976 Acc: 0.9293\n",
      "Epoch 048 | Train Loss: 0.1570 Acc: 0.9407 | Val Loss: 0.1922 Acc: 0.9251\n",
      "Epoch 049 | Train Loss: 0.1451 Acc: 0.9449 | Val Loss: 0.1972 Acc: 0.9227\n",
      "Epoch 050 | Train Loss: 0.1581 Acc: 0.9398 | Val Loss: 0.2002 Acc: 0.9287\n",
      "Epoch 051 | Train Loss: 0.1465 Acc: 0.9449 | Val Loss: 0.2228 Acc: 0.9094\n",
      "Epoch 052 | Train Loss: 0.1456 Acc: 0.9473 | Val Loss: 0.2105 Acc: 0.9185\n",
      "Epoch 053 | Train Loss: 0.1426 Acc: 0.9419 | Val Loss: 0.1879 Acc: 0.9293\n",
      "Epoch 054 | Train Loss: 0.1478 Acc: 0.9450 | Val Loss: 0.1844 Acc: 0.9227\n",
      "Epoch 055 | Train Loss: 0.1355 Acc: 0.9488 | Val Loss: 0.2877 Acc: 0.8816\n",
      "Epoch 056 | Train Loss: 0.1534 Acc: 0.9416 | Val Loss: 0.2115 Acc: 0.9209\n",
      "Epoch 057 | Train Loss: 0.1368 Acc: 0.9493 | Val Loss: 0.2025 Acc: 0.9263\n",
      "Epoch 058 | Train Loss: 0.1348 Acc: 0.9497 | Val Loss: 0.2066 Acc: 0.9245\n",
      "Epoch 059 | Train Loss: 0.1322 Acc: 0.9512 | Val Loss: 0.2261 Acc: 0.9281\n",
      "Epoch 060 | Train Loss: 0.1341 Acc: 0.9481 | Val Loss: 0.1873 Acc: 0.9300\n",
      "Epoch 001 | Train Loss: 0.6885 Acc: 0.5535 | Val Loss: 0.6837 Acc: 0.5749\n",
      "Epoch 002 | Train Loss: 0.6785 Acc: 0.5858 | Val Loss: 0.6791 Acc: 0.5725\n",
      "Epoch 003 | Train Loss: 0.6746 Acc: 0.5886 | Val Loss: 0.6746 Acc: 0.5912\n",
      "Epoch 004 | Train Loss: 0.6721 Acc: 0.5937 | Val Loss: 0.6723 Acc: 0.5960\n",
      "Epoch 005 | Train Loss: 0.6697 Acc: 0.5953 | Val Loss: 0.6670 Acc: 0.5984\n",
      "Epoch 006 | Train Loss: 0.6609 Acc: 0.6046 | Val Loss: 0.6582 Acc: 0.6081\n",
      "Epoch 007 | Train Loss: 0.6544 Acc: 0.6065 | Val Loss: 0.6599 Acc: 0.6280\n",
      "Epoch 008 | Train Loss: 0.6490 Acc: 0.6239 | Val Loss: 0.6395 Acc: 0.6655\n",
      "Epoch 009 | Train Loss: 0.6408 Acc: 0.6428 | Val Loss: 0.6369 Acc: 0.6322\n",
      "Epoch 010 | Train Loss: 0.6338 Acc: 0.6506 | Val Loss: 0.6229 Acc: 0.6636\n",
      "Epoch 011 | Train Loss: 0.6225 Acc: 0.6674 | Val Loss: 0.6132 Acc: 0.6890\n",
      "Epoch 012 | Train Loss: 0.6175 Acc: 0.6699 | Val Loss: 0.6066 Acc: 0.6914\n",
      "Epoch 013 | Train Loss: 0.6158 Acc: 0.6707 | Val Loss: 0.6019 Acc: 0.6812\n",
      "Epoch 014 | Train Loss: 0.6102 Acc: 0.6773 | Val Loss: 0.5981 Acc: 0.6878\n",
      "Epoch 015 | Train Loss: 0.6053 Acc: 0.6820 | Val Loss: 0.6010 Acc: 0.6812\n",
      "Epoch 016 | Train Loss: 0.6005 Acc: 0.6914 | Val Loss: 0.5926 Acc: 0.6908\n",
      "Epoch 017 | Train Loss: 0.5970 Acc: 0.6873 | Val Loss: 0.5883 Acc: 0.7041\n",
      "Epoch 018 | Train Loss: 0.5967 Acc: 0.6900 | Val Loss: 0.5848 Acc: 0.7071\n",
      "Epoch 019 | Train Loss: 0.5884 Acc: 0.7016 | Val Loss: 0.5818 Acc: 0.6999\n",
      "Epoch 020 | Train Loss: 0.5846 Acc: 0.7001 | Val Loss: 0.5778 Acc: 0.7071\n",
      "Epoch 021 | Train Loss: 0.5782 Acc: 0.7095 | Val Loss: 0.5839 Acc: 0.7041\n",
      "Epoch 022 | Train Loss: 0.5782 Acc: 0.7069 | Val Loss: 0.5769 Acc: 0.7089\n",
      "Epoch 023 | Train Loss: 0.5755 Acc: 0.7083 | Val Loss: 0.5775 Acc: 0.7005\n",
      "Epoch 024 | Train Loss: 0.5720 Acc: 0.7118 | Val Loss: 0.5669 Acc: 0.7186\n",
      "Epoch 025 | Train Loss: 0.5677 Acc: 0.7154 | Val Loss: 0.5646 Acc: 0.7168\n",
      "Epoch 026 | Train Loss: 0.5686 Acc: 0.7173 | Val Loss: 0.5662 Acc: 0.7162\n",
      "Epoch 027 | Train Loss: 0.5654 Acc: 0.7154 | Val Loss: 0.5655 Acc: 0.7138\n",
      "Epoch 028 | Train Loss: 0.5635 Acc: 0.7207 | Val Loss: 0.5683 Acc: 0.7144\n",
      "Epoch 029 | Train Loss: 0.5635 Acc: 0.7196 | Val Loss: 0.5620 Acc: 0.7210\n",
      "Epoch 030 | Train Loss: 0.5575 Acc: 0.7220 | Val Loss: 0.5608 Acc: 0.7204\n",
      "Epoch 031 | Train Loss: 0.5568 Acc: 0.7257 | Val Loss: 0.5546 Acc: 0.7192\n",
      "Epoch 032 | Train Loss: 0.5591 Acc: 0.7214 | Val Loss: 0.5573 Acc: 0.7192\n",
      "Epoch 033 | Train Loss: 0.5463 Acc: 0.7288 | Val Loss: 0.5578 Acc: 0.7228\n",
      "Epoch 034 | Train Loss: 0.5479 Acc: 0.7302 | Val Loss: 0.5492 Acc: 0.7240\n",
      "Epoch 035 | Train Loss: 0.5466 Acc: 0.7293 | Val Loss: 0.5486 Acc: 0.7204\n",
      "Epoch 036 | Train Loss: 0.5458 Acc: 0.7311 | Val Loss: 0.5475 Acc: 0.7210\n",
      "Epoch 037 | Train Loss: 0.5397 Acc: 0.7314 | Val Loss: 0.5431 Acc: 0.7252\n",
      "Epoch 038 | Train Loss: 0.5353 Acc: 0.7347 | Val Loss: 0.5424 Acc: 0.7246\n",
      "Epoch 039 | Train Loss: 0.5337 Acc: 0.7398 | Val Loss: 0.5577 Acc: 0.7216\n",
      "Epoch 040 | Train Loss: 0.5308 Acc: 0.7409 | Val Loss: 0.5414 Acc: 0.7204\n",
      "Epoch 041 | Train Loss: 0.5249 Acc: 0.7430 | Val Loss: 0.5415 Acc: 0.7289\n",
      "Epoch 042 | Train Loss: 0.5292 Acc: 0.7404 | Val Loss: 0.5566 Acc: 0.7210\n",
      "Epoch 043 | Train Loss: 0.5203 Acc: 0.7474 | Val Loss: 0.5318 Acc: 0.7301\n",
      "Epoch 044 | Train Loss: 0.5138 Acc: 0.7543 | Val Loss: 0.5377 Acc: 0.7355\n",
      "Epoch 045 | Train Loss: 0.5175 Acc: 0.7472 | Val Loss: 0.5411 Acc: 0.7313\n",
      "Epoch 046 | Train Loss: 0.5122 Acc: 0.7559 | Val Loss: 0.5244 Acc: 0.7397\n",
      "Epoch 047 | Train Loss: 0.5154 Acc: 0.7485 | Val Loss: 0.5195 Acc: 0.7428\n",
      "Epoch 048 | Train Loss: 0.5029 Acc: 0.7565 | Val Loss: 0.5260 Acc: 0.7379\n",
      "Epoch 049 | Train Loss: 0.5032 Acc: 0.7566 | Val Loss: 0.5367 Acc: 0.7301\n",
      "Epoch 050 | Train Loss: 0.4972 Acc: 0.7628 | Val Loss: 0.5075 Acc: 0.7464\n",
      "Epoch 051 | Train Loss: 0.4946 Acc: 0.7660 | Val Loss: 0.5308 Acc: 0.7367\n",
      "Epoch 052 | Train Loss: 0.4888 Acc: 0.7642 | Val Loss: 0.5017 Acc: 0.7530\n",
      "Epoch 053 | Train Loss: 0.4941 Acc: 0.7648 | Val Loss: 0.5084 Acc: 0.7506\n",
      "Epoch 054 | Train Loss: 0.4880 Acc: 0.7640 | Val Loss: 0.4991 Acc: 0.7560\n",
      "Epoch 055 | Train Loss: 0.4825 Acc: 0.7667 | Val Loss: 0.4948 Acc: 0.7591\n",
      "Epoch 056 | Train Loss: 0.4852 Acc: 0.7735 | Val Loss: 0.4999 Acc: 0.7639\n",
      "Epoch 057 | Train Loss: 0.4770 Acc: 0.7722 | Val Loss: 0.4923 Acc: 0.7579\n",
      "Epoch 058 | Train Loss: 0.4684 Acc: 0.7780 | Val Loss: 0.4820 Acc: 0.7639\n",
      "Epoch 059 | Train Loss: 0.4683 Acc: 0.7814 | Val Loss: 0.4823 Acc: 0.7609\n",
      "Epoch 060 | Train Loss: 0.4615 Acc: 0.7842 | Val Loss: 0.4843 Acc: 0.7669\n",
      "Epoch 001 | Train Loss: 0.6847 Acc: 0.5729 | Val Loss: 0.6793 Acc: 0.5815\n",
      "Epoch 002 | Train Loss: 0.6732 Acc: 0.5987 | Val Loss: 0.6717 Acc: 0.5845\n",
      "Epoch 003 | Train Loss: 0.6177 Acc: 0.6778 | Val Loss: 0.5933 Acc: 0.6763\n",
      "Epoch 004 | Train Loss: 0.5941 Acc: 0.7057 | Val Loss: 0.5684 Acc: 0.7041\n",
      "Epoch 005 | Train Loss: 0.5532 Acc: 0.7299 | Val Loss: 0.5383 Acc: 0.7337\n",
      "Epoch 006 | Train Loss: 0.5273 Acc: 0.7412 | Val Loss: 0.5255 Acc: 0.7397\n",
      "Epoch 007 | Train Loss: 0.4869 Acc: 0.7694 | Val Loss: 0.4968 Acc: 0.7536\n",
      "Epoch 008 | Train Loss: 0.4561 Acc: 0.7877 | Val Loss: 0.4584 Acc: 0.7838\n",
      "Epoch 009 | Train Loss: 0.4238 Acc: 0.8036 | Val Loss: 0.4127 Acc: 0.8043\n",
      "Epoch 010 | Train Loss: 0.3838 Acc: 0.8253 | Val Loss: 0.3928 Acc: 0.8321\n",
      "Epoch 011 | Train Loss: 0.3781 Acc: 0.8319 | Val Loss: 0.4103 Acc: 0.8285\n",
      "Epoch 012 | Train Loss: 0.3412 Acc: 0.8541 | Val Loss: 0.3358 Acc: 0.8472\n",
      "Epoch 013 | Train Loss: 0.3254 Acc: 0.8631 | Val Loss: 0.3225 Acc: 0.8527\n",
      "Epoch 014 | Train Loss: 0.2990 Acc: 0.8762 | Val Loss: 0.3370 Acc: 0.8382\n",
      "Epoch 015 | Train Loss: 0.2878 Acc: 0.8816 | Val Loss: 0.2916 Acc: 0.8780\n",
      "Epoch 016 | Train Loss: 0.2728 Acc: 0.8840 | Val Loss: 0.2763 Acc: 0.8835\n",
      "Epoch 017 | Train Loss: 0.2624 Acc: 0.8940 | Val Loss: 0.3091 Acc: 0.8629\n",
      "Epoch 018 | Train Loss: 0.2404 Acc: 0.9005 | Val Loss: 0.2860 Acc: 0.8865\n",
      "Epoch 019 | Train Loss: 0.2338 Acc: 0.9090 | Val Loss: 0.2641 Acc: 0.8871\n",
      "Epoch 020 | Train Loss: 0.2145 Acc: 0.9132 | Val Loss: 0.2981 Acc: 0.8877\n",
      "Epoch 021 | Train Loss: 0.2170 Acc: 0.9129 | Val Loss: 0.2283 Acc: 0.9100\n",
      "Epoch 022 | Train Loss: 0.2160 Acc: 0.9154 | Val Loss: 0.2298 Acc: 0.9058\n",
      "Epoch 023 | Train Loss: 0.1969 Acc: 0.9224 | Val Loss: 0.2621 Acc: 0.8877\n",
      "Epoch 024 | Train Loss: 0.2050 Acc: 0.9182 | Val Loss: 0.2367 Acc: 0.9046\n",
      "Epoch 025 | Train Loss: 0.1771 Acc: 0.9289 | Val Loss: 0.2425 Acc: 0.9040\n",
      "Epoch 026 | Train Loss: 0.1932 Acc: 0.9272 | Val Loss: 0.2079 Acc: 0.9094\n",
      "Epoch 027 | Train Loss: 0.1635 Acc: 0.9375 | Val Loss: 0.2027 Acc: 0.9185\n",
      "Epoch 028 | Train Loss: 0.1609 Acc: 0.9370 | Val Loss: 0.2478 Acc: 0.8955\n",
      "Epoch 029 | Train Loss: 0.1576 Acc: 0.9402 | Val Loss: 0.2848 Acc: 0.8998\n",
      "Epoch 030 | Train Loss: 0.1570 Acc: 0.9407 | Val Loss: 0.2081 Acc: 0.9203\n",
      "Epoch 031 | Train Loss: 0.1530 Acc: 0.9373 | Val Loss: 0.2193 Acc: 0.9167\n",
      "Epoch 032 | Train Loss: 0.1483 Acc: 0.9431 | Val Loss: 0.2191 Acc: 0.9203\n",
      "Epoch 033 | Train Loss: 0.1306 Acc: 0.9511 | Val Loss: 0.2119 Acc: 0.9306\n",
      "Epoch 034 | Train Loss: 0.1351 Acc: 0.9467 | Val Loss: 0.1983 Acc: 0.9269\n",
      "Epoch 035 | Train Loss: 0.1333 Acc: 0.9470 | Val Loss: 0.1930 Acc: 0.9209\n",
      "Epoch 036 | Train Loss: 0.1287 Acc: 0.9535 | Val Loss: 0.1862 Acc: 0.9324\n",
      "Epoch 037 | Train Loss: 0.1265 Acc: 0.9521 | Val Loss: 0.2300 Acc: 0.9130\n",
      "Epoch 038 | Train Loss: 0.1297 Acc: 0.9512 | Val Loss: 0.2229 Acc: 0.9209\n",
      "Epoch 039 | Train Loss: 0.1229 Acc: 0.9524 | Val Loss: 0.2066 Acc: 0.9215\n",
      "Epoch 040 | Train Loss: 0.1137 Acc: 0.9588 | Val Loss: 0.3001 Acc: 0.9022\n",
      "Epoch 041 | Train Loss: 0.1247 Acc: 0.9521 | Val Loss: 0.2018 Acc: 0.9227\n",
      "Epoch 042 | Train Loss: 0.1016 Acc: 0.9630 | Val Loss: 0.2530 Acc: 0.9136\n",
      "Epoch 043 | Train Loss: 0.1108 Acc: 0.9577 | Val Loss: 0.2094 Acc: 0.9269\n",
      "Epoch 044 | Train Loss: 0.1084 Acc: 0.9606 | Val Loss: 0.3389 Acc: 0.8889\n",
      "Epoch 045 | Train Loss: 0.1029 Acc: 0.9630 | Val Loss: 0.1989 Acc: 0.9330\n",
      "Epoch 046 | Train Loss: 0.1040 Acc: 0.9609 | Val Loss: 0.2280 Acc: 0.9149\n",
      "Early stopping triggered.\n",
      "Epoch 001 | Train Loss: 0.6837 Acc: 0.5597 | Val Loss: 0.6776 Acc: 0.5821\n",
      "Epoch 002 | Train Loss: 0.6753 Acc: 0.5929 | Val Loss: 0.6730 Acc: 0.5912\n",
      "Epoch 003 | Train Loss: 0.6673 Acc: 0.5967 | Val Loss: 0.6597 Acc: 0.6057\n",
      "Epoch 004 | Train Loss: 0.6488 Acc: 0.6262 | Val Loss: 0.6319 Acc: 0.6558\n",
      "Epoch 005 | Train Loss: 0.6322 Acc: 0.6615 | Val Loss: 0.6158 Acc: 0.6824\n",
      "Epoch 006 | Train Loss: 0.6182 Acc: 0.6724 | Val Loss: 0.6107 Acc: 0.6878\n",
      "Epoch 007 | Train Loss: 0.6080 Acc: 0.6852 | Val Loss: 0.6065 Acc: 0.6830\n",
      "Epoch 008 | Train Loss: 0.5991 Acc: 0.6955 | Val Loss: 0.6092 Acc: 0.6769\n",
      "Epoch 009 | Train Loss: 0.5897 Acc: 0.6988 | Val Loss: 0.5898 Acc: 0.6993\n",
      "Epoch 010 | Train Loss: 0.5815 Acc: 0.7081 | Val Loss: 0.6381 Acc: 0.6534\n",
      "Epoch 011 | Train Loss: 0.5741 Acc: 0.7122 | Val Loss: 0.5653 Acc: 0.7210\n",
      "Epoch 012 | Train Loss: 0.5601 Acc: 0.7279 | Val Loss: 0.5629 Acc: 0.7210\n",
      "Epoch 013 | Train Loss: 0.5528 Acc: 0.7278 | Val Loss: 0.5580 Acc: 0.7228\n",
      "Epoch 014 | Train Loss: 0.5483 Acc: 0.7346 | Val Loss: 0.5490 Acc: 0.7283\n",
      "Epoch 015 | Train Loss: 0.5335 Acc: 0.7430 | Val Loss: 0.5390 Acc: 0.7271\n",
      "Epoch 016 | Train Loss: 0.5221 Acc: 0.7521 | Val Loss: 0.5496 Acc: 0.7283\n",
      "Epoch 017 | Train Loss: 0.5221 Acc: 0.7445 | Val Loss: 0.5244 Acc: 0.7440\n",
      "Epoch 018 | Train Loss: 0.5101 Acc: 0.7563 | Val Loss: 0.5163 Acc: 0.7440\n",
      "Epoch 019 | Train Loss: 0.5018 Acc: 0.7620 | Val Loss: 0.5278 Acc: 0.7403\n",
      "Epoch 020 | Train Loss: 0.4910 Acc: 0.7697 | Val Loss: 0.5263 Acc: 0.7373\n",
      "Epoch 021 | Train Loss: 0.4826 Acc: 0.7711 | Val Loss: 0.5062 Acc: 0.7597\n",
      "Epoch 022 | Train Loss: 0.4831 Acc: 0.7744 | Val Loss: 0.4973 Acc: 0.7627\n",
      "Epoch 023 | Train Loss: 0.4728 Acc: 0.7811 | Val Loss: 0.4838 Acc: 0.7681\n",
      "Epoch 024 | Train Loss: 0.4678 Acc: 0.7824 | Val Loss: 0.4850 Acc: 0.7633\n",
      "Epoch 025 | Train Loss: 0.4680 Acc: 0.7811 | Val Loss: 0.5006 Acc: 0.7542\n",
      "Epoch 026 | Train Loss: 0.4584 Acc: 0.7877 | Val Loss: 0.4774 Acc: 0.7711\n",
      "Epoch 027 | Train Loss: 0.4475 Acc: 0.7942 | Val Loss: 0.4565 Acc: 0.7874\n",
      "Epoch 028 | Train Loss: 0.4516 Acc: 0.7877 | Val Loss: 0.4607 Acc: 0.7802\n",
      "Epoch 029 | Train Loss: 0.4431 Acc: 0.7951 | Val Loss: 0.4597 Acc: 0.7820\n",
      "Epoch 030 | Train Loss: 0.4308 Acc: 0.8013 | Val Loss: 0.4567 Acc: 0.7826\n",
      "Epoch 031 | Train Loss: 0.4291 Acc: 0.8016 | Val Loss: 0.4565 Acc: 0.7778\n",
      "Epoch 032 | Train Loss: 0.4263 Acc: 0.8005 | Val Loss: 0.4636 Acc: 0.7681\n",
      "Epoch 033 | Train Loss: 0.4171 Acc: 0.8055 | Val Loss: 0.4320 Acc: 0.7953\n",
      "Epoch 034 | Train Loss: 0.4131 Acc: 0.8117 | Val Loss: 0.4180 Acc: 0.8056\n",
      "Epoch 035 | Train Loss: 0.4062 Acc: 0.8141 | Val Loss: 0.4097 Acc: 0.8122\n",
      "Epoch 036 | Train Loss: 0.3999 Acc: 0.8170 | Val Loss: 0.4038 Acc: 0.8086\n",
      "Epoch 037 | Train Loss: 0.3928 Acc: 0.8155 | Val Loss: 0.4137 Acc: 0.8037\n",
      "Epoch 038 | Train Loss: 0.3831 Acc: 0.8283 | Val Loss: 0.4033 Acc: 0.8152\n",
      "Epoch 039 | Train Loss: 0.3739 Acc: 0.8268 | Val Loss: 0.3951 Acc: 0.8207\n",
      "Epoch 040 | Train Loss: 0.3776 Acc: 0.8246 | Val Loss: 0.3882 Acc: 0.8243\n",
      "Epoch 041 | Train Loss: 0.3645 Acc: 0.8362 | Val Loss: 0.4042 Acc: 0.8056\n",
      "Epoch 042 | Train Loss: 0.3607 Acc: 0.8366 | Val Loss: 0.3640 Acc: 0.8412\n",
      "Epoch 043 | Train Loss: 0.3509 Acc: 0.8421 | Val Loss: 0.3845 Acc: 0.8188\n",
      "Epoch 044 | Train Loss: 0.3567 Acc: 0.8381 | Val Loss: 0.3593 Acc: 0.8364\n",
      "Epoch 045 | Train Loss: 0.3470 Acc: 0.8457 | Val Loss: 0.3776 Acc: 0.8225\n",
      "Epoch 046 | Train Loss: 0.3388 Acc: 0.8478 | Val Loss: 0.3494 Acc: 0.8424\n",
      "Epoch 047 | Train Loss: 0.3369 Acc: 0.8474 | Val Loss: 0.3404 Acc: 0.8484\n",
      "Epoch 048 | Train Loss: 0.3343 Acc: 0.8552 | Val Loss: 0.3407 Acc: 0.8400\n",
      "Epoch 049 | Train Loss: 0.3281 Acc: 0.8552 | Val Loss: 0.3301 Acc: 0.8599\n",
      "Epoch 050 | Train Loss: 0.3137 Acc: 0.8590 | Val Loss: 0.3302 Acc: 0.8569\n",
      "Epoch 051 | Train Loss: 0.3020 Acc: 0.8680 | Val Loss: 0.3289 Acc: 0.8563\n",
      "Epoch 052 | Train Loss: 0.3137 Acc: 0.8650 | Val Loss: 0.3139 Acc: 0.8653\n",
      "Epoch 053 | Train Loss: 0.3015 Acc: 0.8676 | Val Loss: 0.3067 Acc: 0.8605\n",
      "Epoch 054 | Train Loss: 0.3054 Acc: 0.8695 | Val Loss: 0.3105 Acc: 0.8702\n",
      "Epoch 055 | Train Loss: 0.2893 Acc: 0.8712 | Val Loss: 0.3155 Acc: 0.8611\n",
      "Epoch 056 | Train Loss: 0.2876 Acc: 0.8733 | Val Loss: 0.3286 Acc: 0.8563\n",
      "Epoch 057 | Train Loss: 0.2941 Acc: 0.8748 | Val Loss: 0.2927 Acc: 0.8738\n",
      "Epoch 058 | Train Loss: 0.2745 Acc: 0.8828 | Val Loss: 0.2957 Acc: 0.8702\n",
      "Epoch 059 | Train Loss: 0.2777 Acc: 0.8795 | Val Loss: 0.3233 Acc: 0.8617\n",
      "Epoch 060 | Train Loss: 0.2767 Acc: 0.8810 | Val Loss: 0.2917 Acc: 0.8798\n",
      "Iteration 12/40 | Best Val Loss: 0.1122 | Iter Time: 233.10s | Total Time: 57.53 min\n",
      "Epoch 001 | Train Loss: 0.6821 Acc: 0.5766 | Val Loss: 0.6745 Acc: 0.5918\n",
      "Epoch 002 | Train Loss: 0.6531 Acc: 0.6242 | Val Loss: 0.6123 Acc: 0.6673\n",
      "Epoch 003 | Train Loss: 0.5950 Acc: 0.6964 | Val Loss: 0.5735 Acc: 0.7126\n",
      "Epoch 004 | Train Loss: 0.5648 Acc: 0.7244 | Val Loss: 0.5627 Acc: 0.7114\n",
      "Epoch 005 | Train Loss: 0.5424 Acc: 0.7367 | Val Loss: 0.5269 Acc: 0.7355\n",
      "Epoch 006 | Train Loss: 0.5267 Acc: 0.7469 | Val Loss: 0.5004 Acc: 0.7603\n",
      "Epoch 007 | Train Loss: 0.5107 Acc: 0.7590 | Val Loss: 0.5088 Acc: 0.7446\n",
      "Epoch 008 | Train Loss: 0.4944 Acc: 0.7640 | Val Loss: 0.4716 Acc: 0.7627\n",
      "Epoch 009 | Train Loss: 0.4624 Acc: 0.7812 | Val Loss: 0.4514 Acc: 0.7826\n",
      "Epoch 010 | Train Loss: 0.4632 Acc: 0.7845 | Val Loss: 0.4326 Acc: 0.7874\n",
      "Epoch 011 | Train Loss: 0.4302 Acc: 0.8018 | Val Loss: 0.4304 Acc: 0.7905\n",
      "Epoch 012 | Train Loss: 0.4162 Acc: 0.8057 | Val Loss: 0.3809 Acc: 0.8194\n",
      "Epoch 013 | Train Loss: 0.4042 Acc: 0.8150 | Val Loss: 0.4283 Acc: 0.7899\n",
      "Epoch 014 | Train Loss: 0.3858 Acc: 0.8241 | Val Loss: 0.3655 Acc: 0.8249\n",
      "Epoch 015 | Train Loss: 0.3846 Acc: 0.8313 | Val Loss: 0.3663 Acc: 0.8225\n",
      "Epoch 016 | Train Loss: 0.3614 Acc: 0.8407 | Val Loss: 0.3557 Acc: 0.8370\n",
      "Epoch 017 | Train Loss: 0.3516 Acc: 0.8442 | Val Loss: 0.3465 Acc: 0.8424\n",
      "Epoch 018 | Train Loss: 0.3291 Acc: 0.8572 | Val Loss: 0.3165 Acc: 0.8629\n",
      "Epoch 019 | Train Loss: 0.3128 Acc: 0.8683 | Val Loss: 0.3173 Acc: 0.8557\n",
      "Epoch 020 | Train Loss: 0.3119 Acc: 0.8676 | Val Loss: 0.3124 Acc: 0.8629\n",
      "Epoch 021 | Train Loss: 0.2973 Acc: 0.8742 | Val Loss: 0.2887 Acc: 0.8702\n",
      "Epoch 022 | Train Loss: 0.2853 Acc: 0.8785 | Val Loss: 0.2890 Acc: 0.8786\n",
      "Epoch 023 | Train Loss: 0.2807 Acc: 0.8851 | Val Loss: 0.2795 Acc: 0.8816\n",
      "Epoch 024 | Train Loss: 0.2758 Acc: 0.8845 | Val Loss: 0.2649 Acc: 0.8859\n",
      "Epoch 025 | Train Loss: 0.2671 Acc: 0.8923 | Val Loss: 0.2575 Acc: 0.8955\n",
      "Epoch 026 | Train Loss: 0.2535 Acc: 0.8928 | Val Loss: 0.2509 Acc: 0.8931\n",
      "Epoch 027 | Train Loss: 0.2515 Acc: 0.8982 | Val Loss: 0.2384 Acc: 0.8979\n",
      "Epoch 028 | Train Loss: 0.2507 Acc: 0.9005 | Val Loss: 0.2582 Acc: 0.8883\n",
      "Epoch 029 | Train Loss: 0.2303 Acc: 0.9094 | Val Loss: 0.2258 Acc: 0.9088\n",
      "Epoch 030 | Train Loss: 0.2298 Acc: 0.9106 | Val Loss: 0.2324 Acc: 0.9004\n",
      "Epoch 031 | Train Loss: 0.2262 Acc: 0.9111 | Val Loss: 0.2306 Acc: 0.9028\n",
      "Epoch 032 | Train Loss: 0.2267 Acc: 0.9071 | Val Loss: 0.2060 Acc: 0.9239\n",
      "Epoch 033 | Train Loss: 0.2119 Acc: 0.9142 | Val Loss: 0.2249 Acc: 0.9130\n",
      "Epoch 034 | Train Loss: 0.2112 Acc: 0.9145 | Val Loss: 0.2085 Acc: 0.9227\n",
      "Epoch 035 | Train Loss: 0.1940 Acc: 0.9245 | Val Loss: 0.1975 Acc: 0.9227\n",
      "Epoch 036 | Train Loss: 0.1914 Acc: 0.9244 | Val Loss: 0.1844 Acc: 0.9306\n",
      "Epoch 037 | Train Loss: 0.1948 Acc: 0.9242 | Val Loss: 0.2069 Acc: 0.9106\n",
      "Epoch 038 | Train Loss: 0.1741 Acc: 0.9337 | Val Loss: 0.2677 Acc: 0.9016\n",
      "Epoch 039 | Train Loss: 0.1802 Acc: 0.9307 | Val Loss: 0.2444 Acc: 0.9022\n",
      "Epoch 040 | Train Loss: 0.1716 Acc: 0.9336 | Val Loss: 0.2122 Acc: 0.9185\n",
      "Epoch 041 | Train Loss: 0.1812 Acc: 0.9305 | Val Loss: 0.1810 Acc: 0.9318\n",
      "Epoch 042 | Train Loss: 0.1778 Acc: 0.9307 | Val Loss: 0.1929 Acc: 0.9233\n",
      "Epoch 043 | Train Loss: 0.1617 Acc: 0.9375 | Val Loss: 0.2093 Acc: 0.9197\n",
      "Epoch 044 | Train Loss: 0.1646 Acc: 0.9395 | Val Loss: 0.1855 Acc: 0.9257\n",
      "Epoch 045 | Train Loss: 0.1656 Acc: 0.9373 | Val Loss: 0.1631 Acc: 0.9336\n",
      "Epoch 046 | Train Loss: 0.1596 Acc: 0.9375 | Val Loss: 0.2300 Acc: 0.9064\n",
      "Epoch 047 | Train Loss: 0.1520 Acc: 0.9405 | Val Loss: 0.2016 Acc: 0.9263\n",
      "Epoch 048 | Train Loss: 0.1529 Acc: 0.9420 | Val Loss: 0.1816 Acc: 0.9318\n",
      "Epoch 049 | Train Loss: 0.1476 Acc: 0.9420 | Val Loss: 0.1535 Acc: 0.9432\n",
      "Epoch 050 | Train Loss: 0.1543 Acc: 0.9402 | Val Loss: 0.1893 Acc: 0.9263\n",
      "Epoch 051 | Train Loss: 0.1567 Acc: 0.9422 | Val Loss: 0.1569 Acc: 0.9354\n",
      "Epoch 052 | Train Loss: 0.1519 Acc: 0.9395 | Val Loss: 0.1708 Acc: 0.9354\n",
      "Epoch 053 | Train Loss: 0.1521 Acc: 0.9426 | Val Loss: 0.1597 Acc: 0.9390\n",
      "Epoch 054 | Train Loss: 0.1421 Acc: 0.9446 | Val Loss: 0.1690 Acc: 0.9324\n",
      "Epoch 055 | Train Loss: 0.1405 Acc: 0.9475 | Val Loss: 0.1680 Acc: 0.9402\n",
      "Epoch 056 | Train Loss: 0.1318 Acc: 0.9491 | Val Loss: 0.2138 Acc: 0.9203\n",
      "Epoch 057 | Train Loss: 0.1507 Acc: 0.9437 | Val Loss: 0.1725 Acc: 0.9324\n",
      "Epoch 058 | Train Loss: 0.1350 Acc: 0.9487 | Val Loss: 0.1821 Acc: 0.9281\n",
      "Epoch 059 | Train Loss: 0.1307 Acc: 0.9515 | Val Loss: 0.1843 Acc: 0.9227\n",
      "Early stopping triggered.\n",
      "Epoch 001 | Train Loss: 0.6816 Acc: 0.5780 | Val Loss: 0.6773 Acc: 0.5870\n",
      "Epoch 002 | Train Loss: 0.6535 Acc: 0.6289 | Val Loss: 0.6157 Acc: 0.6697\n",
      "Epoch 003 | Train Loss: 0.5817 Acc: 0.7090 | Val Loss: 0.5508 Acc: 0.7144\n",
      "Epoch 004 | Train Loss: 0.5397 Acc: 0.7347 | Val Loss: 0.5454 Acc: 0.7204\n",
      "Epoch 005 | Train Loss: 0.5083 Acc: 0.7571 | Val Loss: 0.5242 Acc: 0.7385\n",
      "Epoch 006 | Train Loss: 0.4772 Acc: 0.7738 | Val Loss: 0.4787 Acc: 0.7669\n",
      "Epoch 007 | Train Loss: 0.4304 Acc: 0.8008 | Val Loss: 0.4486 Acc: 0.7880\n",
      "Epoch 008 | Train Loss: 0.3977 Acc: 0.8250 | Val Loss: 0.3795 Acc: 0.8261\n",
      "Epoch 009 | Train Loss: 0.3578 Acc: 0.8383 | Val Loss: 0.3389 Acc: 0.8496\n",
      "Epoch 010 | Train Loss: 0.3327 Acc: 0.8544 | Val Loss: 0.3517 Acc: 0.8412\n",
      "Epoch 011 | Train Loss: 0.3072 Acc: 0.8695 | Val Loss: 0.2951 Acc: 0.8792\n",
      "Epoch 012 | Train Loss: 0.2628 Acc: 0.8877 | Val Loss: 0.3020 Acc: 0.8684\n",
      "Epoch 013 | Train Loss: 0.2532 Acc: 0.8960 | Val Loss: 0.2792 Acc: 0.8853\n",
      "Epoch 014 | Train Loss: 0.2295 Acc: 0.9059 | Val Loss: 0.2697 Acc: 0.8841\n",
      "Epoch 015 | Train Loss: 0.2232 Acc: 0.9120 | Val Loss: 0.2495 Acc: 0.9052\n",
      "Epoch 016 | Train Loss: 0.2134 Acc: 0.9161 | Val Loss: 0.2392 Acc: 0.9022\n",
      "Epoch 017 | Train Loss: 0.1939 Acc: 0.9233 | Val Loss: 0.2767 Acc: 0.8883\n",
      "Epoch 018 | Train Loss: 0.1866 Acc: 0.9262 | Val Loss: 0.2288 Acc: 0.9215\n",
      "Epoch 019 | Train Loss: 0.1728 Acc: 0.9292 | Val Loss: 0.2309 Acc: 0.9118\n",
      "Epoch 020 | Train Loss: 0.1612 Acc: 0.9364 | Val Loss: 0.2552 Acc: 0.9094\n",
      "Epoch 021 | Train Loss: 0.1555 Acc: 0.9382 | Val Loss: 0.2173 Acc: 0.9130\n",
      "Epoch 022 | Train Loss: 0.1509 Acc: 0.9437 | Val Loss: 0.1964 Acc: 0.9245\n",
      "Epoch 023 | Train Loss: 0.1393 Acc: 0.9438 | Val Loss: 0.2044 Acc: 0.9215\n",
      "Epoch 024 | Train Loss: 0.1425 Acc: 0.9432 | Val Loss: 0.1942 Acc: 0.9306\n",
      "Epoch 025 | Train Loss: 0.1279 Acc: 0.9484 | Val Loss: 0.2005 Acc: 0.9173\n",
      "Epoch 026 | Train Loss: 0.1247 Acc: 0.9544 | Val Loss: 0.2047 Acc: 0.9287\n",
      "Epoch 027 | Train Loss: 0.1226 Acc: 0.9538 | Val Loss: 0.2163 Acc: 0.9155\n",
      "Epoch 028 | Train Loss: 0.1168 Acc: 0.9555 | Val Loss: 0.1790 Acc: 0.9354\n",
      "Epoch 029 | Train Loss: 0.1150 Acc: 0.9597 | Val Loss: 0.2223 Acc: 0.9185\n",
      "Epoch 030 | Train Loss: 0.1169 Acc: 0.9561 | Val Loss: 0.1988 Acc: 0.9233\n",
      "Epoch 031 | Train Loss: 0.0968 Acc: 0.9636 | Val Loss: 0.2121 Acc: 0.9257\n",
      "Epoch 032 | Train Loss: 0.1092 Acc: 0.9591 | Val Loss: 0.2159 Acc: 0.9275\n",
      "Epoch 033 | Train Loss: 0.1033 Acc: 0.9604 | Val Loss: 0.1948 Acc: 0.9336\n",
      "Epoch 034 | Train Loss: 0.0879 Acc: 0.9668 | Val Loss: 0.2016 Acc: 0.9348\n",
      "Epoch 035 | Train Loss: 0.0999 Acc: 0.9603 | Val Loss: 0.1998 Acc: 0.9312\n",
      "Epoch 036 | Train Loss: 0.0910 Acc: 0.9675 | Val Loss: 0.1883 Acc: 0.9312\n",
      "Epoch 037 | Train Loss: 0.0973 Acc: 0.9645 | Val Loss: 0.2412 Acc: 0.9239\n",
      "Epoch 038 | Train Loss: 0.0988 Acc: 0.9615 | Val Loss: 0.2210 Acc: 0.9245\n",
      "Early stopping triggered.\n",
      "Epoch 001 | Train Loss: 0.6783 Acc: 0.5845 | Val Loss: 0.6718 Acc: 0.5870\n",
      "Epoch 002 | Train Loss: 0.6664 Acc: 0.6032 | Val Loss: 0.6623 Acc: 0.5990\n",
      "Epoch 003 | Train Loss: 0.6607 Acc: 0.6086 | Val Loss: 0.6435 Acc: 0.6184\n",
      "Epoch 004 | Train Loss: 0.6299 Acc: 0.6610 | Val Loss: 0.6118 Acc: 0.6824\n",
      "Epoch 005 | Train Loss: 0.5911 Acc: 0.6994 | Val Loss: 0.5823 Acc: 0.6987\n",
      "Epoch 006 | Train Loss: 0.5675 Acc: 0.7161 | Val Loss: 0.5658 Acc: 0.7126\n",
      "Epoch 007 | Train Loss: 0.5504 Acc: 0.7273 | Val Loss: 0.5799 Acc: 0.6787\n",
      "Epoch 008 | Train Loss: 0.5342 Acc: 0.7364 | Val Loss: 0.5387 Acc: 0.7240\n",
      "Epoch 009 | Train Loss: 0.5058 Acc: 0.7534 | Val Loss: 0.5053 Acc: 0.7530\n",
      "Epoch 010 | Train Loss: 0.4841 Acc: 0.7676 | Val Loss: 0.5091 Acc: 0.7446\n",
      "Epoch 011 | Train Loss: 0.4850 Acc: 0.7669 | Val Loss: 0.4906 Acc: 0.7711\n",
      "Epoch 012 | Train Loss: 0.4739 Acc: 0.7762 | Val Loss: 0.4942 Acc: 0.7657\n",
      "Epoch 013 | Train Loss: 0.4541 Acc: 0.7848 | Val Loss: 0.4713 Acc: 0.7790\n",
      "Epoch 014 | Train Loss: 0.4301 Acc: 0.7963 | Val Loss: 0.4626 Acc: 0.7784\n",
      "Epoch 015 | Train Loss: 0.4102 Acc: 0.8049 | Val Loss: 0.4377 Acc: 0.7935\n",
      "Epoch 016 | Train Loss: 0.4004 Acc: 0.8138 | Val Loss: 0.3948 Acc: 0.8207\n",
      "Epoch 017 | Train Loss: 0.3888 Acc: 0.8206 | Val Loss: 0.3954 Acc: 0.8237\n",
      "Epoch 018 | Train Loss: 0.3840 Acc: 0.8258 | Val Loss: 0.3908 Acc: 0.8219\n",
      "Epoch 019 | Train Loss: 0.3607 Acc: 0.8368 | Val Loss: 0.3526 Acc: 0.8448\n",
      "Epoch 020 | Train Loss: 0.3412 Acc: 0.8528 | Val Loss: 0.3357 Acc: 0.8569\n",
      "Epoch 021 | Train Loss: 0.3225 Acc: 0.8628 | Val Loss: 0.3342 Acc: 0.8514\n",
      "Epoch 022 | Train Loss: 0.3127 Acc: 0.8686 | Val Loss: 0.3207 Acc: 0.8623\n",
      "Epoch 023 | Train Loss: 0.2927 Acc: 0.8769 | Val Loss: 0.3269 Acc: 0.8635\n",
      "Epoch 024 | Train Loss: 0.2817 Acc: 0.8828 | Val Loss: 0.2878 Acc: 0.8732\n",
      "Epoch 025 | Train Loss: 0.2699 Acc: 0.8878 | Val Loss: 0.3034 Acc: 0.8744\n",
      "Epoch 026 | Train Loss: 0.2562 Acc: 0.8934 | Val Loss: 0.2579 Acc: 0.8998\n",
      "Epoch 027 | Train Loss: 0.2418 Acc: 0.8994 | Val Loss: 0.3040 Acc: 0.8696\n",
      "Epoch 028 | Train Loss: 0.2416 Acc: 0.8981 | Val Loss: 0.2592 Acc: 0.8901\n",
      "Epoch 029 | Train Loss: 0.2279 Acc: 0.9085 | Val Loss: 0.2452 Acc: 0.9064\n",
      "Epoch 030 | Train Loss: 0.2274 Acc: 0.9073 | Val Loss: 0.2612 Acc: 0.8925\n",
      "Epoch 031 | Train Loss: 0.2210 Acc: 0.9079 | Val Loss: 0.2157 Acc: 0.9191\n",
      "Epoch 032 | Train Loss: 0.2050 Acc: 0.9212 | Val Loss: 0.2867 Acc: 0.8931\n",
      "Epoch 033 | Train Loss: 0.1989 Acc: 0.9219 | Val Loss: 0.2225 Acc: 0.9136\n",
      "Epoch 034 | Train Loss: 0.1939 Acc: 0.9247 | Val Loss: 0.2286 Acc: 0.9076\n",
      "Epoch 035 | Train Loss: 0.1862 Acc: 0.9260 | Val Loss: 0.2104 Acc: 0.9227\n",
      "Epoch 036 | Train Loss: 0.1840 Acc: 0.9251 | Val Loss: 0.2037 Acc: 0.9191\n",
      "Epoch 037 | Train Loss: 0.1741 Acc: 0.9330 | Val Loss: 0.2785 Acc: 0.8979\n",
      "Epoch 038 | Train Loss: 0.1632 Acc: 0.9375 | Val Loss: 0.2199 Acc: 0.9161\n",
      "Epoch 039 | Train Loss: 0.1801 Acc: 0.9290 | Val Loss: 0.2167 Acc: 0.9100\n",
      "Epoch 040 | Train Loss: 0.1637 Acc: 0.9346 | Val Loss: 0.1845 Acc: 0.9281\n",
      "Epoch 041 | Train Loss: 0.1542 Acc: 0.9388 | Val Loss: 0.1952 Acc: 0.9233\n",
      "Epoch 042 | Train Loss: 0.1428 Acc: 0.9455 | Val Loss: 0.2281 Acc: 0.9251\n",
      "Epoch 043 | Train Loss: 0.1475 Acc: 0.9410 | Val Loss: 0.1894 Acc: 0.9269\n",
      "Epoch 044 | Train Loss: 0.1388 Acc: 0.9494 | Val Loss: 0.1807 Acc: 0.9336\n",
      "Epoch 045 | Train Loss: 0.1372 Acc: 0.9497 | Val Loss: 0.1662 Acc: 0.9372\n",
      "Epoch 046 | Train Loss: 0.1344 Acc: 0.9490 | Val Loss: 0.1744 Acc: 0.9293\n",
      "Epoch 047 | Train Loss: 0.1344 Acc: 0.9469 | Val Loss: 0.1736 Acc: 0.9324\n",
      "Epoch 048 | Train Loss: 0.1229 Acc: 0.9502 | Val Loss: 0.1739 Acc: 0.9372\n",
      "Epoch 049 | Train Loss: 0.1239 Acc: 0.9527 | Val Loss: 0.1733 Acc: 0.9402\n",
      "Epoch 050 | Train Loss: 0.1057 Acc: 0.9592 | Val Loss: 0.1997 Acc: 0.9300\n",
      "Epoch 051 | Train Loss: 0.1194 Acc: 0.9527 | Val Loss: 0.1601 Acc: 0.9378\n",
      "Epoch 052 | Train Loss: 0.1167 Acc: 0.9539 | Val Loss: 0.1693 Acc: 0.9372\n",
      "Epoch 053 | Train Loss: 0.1179 Acc: 0.9558 | Val Loss: 0.2117 Acc: 0.9227\n",
      "Epoch 054 | Train Loss: 0.1067 Acc: 0.9624 | Val Loss: 0.2010 Acc: 0.9245\n",
      "Epoch 055 | Train Loss: 0.1111 Acc: 0.9567 | Val Loss: 0.1985 Acc: 0.9227\n",
      "Epoch 056 | Train Loss: 0.1175 Acc: 0.9549 | Val Loss: 0.2324 Acc: 0.9185\n",
      "Epoch 057 | Train Loss: 0.1077 Acc: 0.9609 | Val Loss: 0.2389 Acc: 0.9173\n",
      "Epoch 058 | Train Loss: 0.1102 Acc: 0.9583 | Val Loss: 0.1633 Acc: 0.9420\n",
      "Epoch 059 | Train Loss: 0.0957 Acc: 0.9630 | Val Loss: 0.1613 Acc: 0.9372\n",
      "Epoch 060 | Train Loss: 0.1006 Acc: 0.9644 | Val Loss: 0.1611 Acc: 0.9354\n",
      "Epoch 001 | Train Loss: 0.6832 Acc: 0.5671 | Val Loss: 0.6756 Acc: 0.5888\n",
      "Epoch 002 | Train Loss: 0.6620 Acc: 0.6086 | Val Loss: 0.6276 Acc: 0.6667\n",
      "Epoch 003 | Train Loss: 0.6212 Acc: 0.6675 | Val Loss: 0.5987 Acc: 0.6902\n",
      "Epoch 004 | Train Loss: 0.5788 Acc: 0.7029 | Val Loss: 0.5678 Acc: 0.7077\n",
      "Epoch 005 | Train Loss: 0.5502 Acc: 0.7276 | Val Loss: 0.5471 Acc: 0.7264\n",
      "Epoch 006 | Train Loss: 0.5351 Acc: 0.7353 | Val Loss: 0.5309 Acc: 0.7385\n",
      "Epoch 007 | Train Loss: 0.5189 Acc: 0.7498 | Val Loss: 0.5114 Acc: 0.7415\n",
      "Epoch 008 | Train Loss: 0.5049 Acc: 0.7578 | Val Loss: 0.5001 Acc: 0.7488\n",
      "Epoch 009 | Train Loss: 0.4875 Acc: 0.7632 | Val Loss: 0.4805 Acc: 0.7603\n",
      "Epoch 010 | Train Loss: 0.4760 Acc: 0.7773 | Val Loss: 0.4966 Acc: 0.7494\n",
      "Epoch 011 | Train Loss: 0.4646 Acc: 0.7815 | Val Loss: 0.4731 Acc: 0.7699\n",
      "Epoch 012 | Train Loss: 0.4513 Acc: 0.7856 | Val Loss: 0.4308 Acc: 0.7935\n",
      "Epoch 013 | Train Loss: 0.4217 Acc: 0.7977 | Val Loss: 0.4006 Acc: 0.8043\n",
      "Epoch 014 | Train Loss: 0.4084 Acc: 0.8137 | Val Loss: 0.3939 Acc: 0.8128\n",
      "Epoch 015 | Train Loss: 0.3842 Acc: 0.8246 | Val Loss: 0.4088 Acc: 0.7947\n",
      "Epoch 016 | Train Loss: 0.3794 Acc: 0.8291 | Val Loss: 0.3437 Acc: 0.8376\n",
      "Epoch 017 | Train Loss: 0.3505 Acc: 0.8480 | Val Loss: 0.3668 Acc: 0.8357\n",
      "Epoch 018 | Train Loss: 0.3424 Acc: 0.8449 | Val Loss: 0.3368 Acc: 0.8442\n",
      "Epoch 019 | Train Loss: 0.3332 Acc: 0.8570 | Val Loss: 0.3275 Acc: 0.8551\n",
      "Epoch 020 | Train Loss: 0.3166 Acc: 0.8658 | Val Loss: 0.2872 Acc: 0.8744\n",
      "Epoch 021 | Train Loss: 0.3062 Acc: 0.8683 | Val Loss: 0.2813 Acc: 0.8798\n",
      "Epoch 022 | Train Loss: 0.2916 Acc: 0.8771 | Val Loss: 0.2511 Acc: 0.9016\n",
      "Epoch 023 | Train Loss: 0.2773 Acc: 0.8828 | Val Loss: 0.2659 Acc: 0.8877\n",
      "Epoch 024 | Train Loss: 0.2638 Acc: 0.8898 | Val Loss: 0.2210 Acc: 0.9106\n",
      "Epoch 025 | Train Loss: 0.2653 Acc: 0.8874 | Val Loss: 0.2234 Acc: 0.9058\n",
      "Epoch 026 | Train Loss: 0.2363 Acc: 0.9019 | Val Loss: 0.2250 Acc: 0.9088\n",
      "Epoch 027 | Train Loss: 0.2539 Acc: 0.8966 | Val Loss: 0.2050 Acc: 0.9221\n",
      "Epoch 028 | Train Loss: 0.2356 Acc: 0.9002 | Val Loss: 0.2260 Acc: 0.9130\n",
      "Epoch 029 | Train Loss: 0.2236 Acc: 0.9088 | Val Loss: 0.2117 Acc: 0.9173\n",
      "Epoch 030 | Train Loss: 0.2197 Acc: 0.9094 | Val Loss: 0.2314 Acc: 0.9070\n",
      "Epoch 031 | Train Loss: 0.2006 Acc: 0.9204 | Val Loss: 0.2003 Acc: 0.9209\n",
      "Epoch 032 | Train Loss: 0.2136 Acc: 0.9112 | Val Loss: 0.2452 Acc: 0.8949\n",
      "Epoch 033 | Train Loss: 0.1900 Acc: 0.9231 | Val Loss: 0.1998 Acc: 0.9173\n",
      "Epoch 034 | Train Loss: 0.1936 Acc: 0.9212 | Val Loss: 0.1839 Acc: 0.9300\n",
      "Epoch 035 | Train Loss: 0.1888 Acc: 0.9239 | Val Loss: 0.1828 Acc: 0.9318\n",
      "Epoch 036 | Train Loss: 0.1798 Acc: 0.9295 | Val Loss: 0.1993 Acc: 0.9227\n",
      "Epoch 037 | Train Loss: 0.1748 Acc: 0.9315 | Val Loss: 0.2100 Acc: 0.9173\n",
      "Epoch 038 | Train Loss: 0.1761 Acc: 0.9298 | Val Loss: 0.1680 Acc: 0.9372\n",
      "Epoch 039 | Train Loss: 0.1570 Acc: 0.9361 | Val Loss: 0.1823 Acc: 0.9306\n",
      "Epoch 040 | Train Loss: 0.1580 Acc: 0.9376 | Val Loss: 0.1582 Acc: 0.9402\n",
      "Epoch 041 | Train Loss: 0.1645 Acc: 0.9340 | Val Loss: 0.1688 Acc: 0.9348\n",
      "Epoch 042 | Train Loss: 0.1573 Acc: 0.9372 | Val Loss: 0.1626 Acc: 0.9378\n",
      "Epoch 043 | Train Loss: 0.1532 Acc: 0.9413 | Val Loss: 0.1561 Acc: 0.9372\n",
      "Epoch 044 | Train Loss: 0.1500 Acc: 0.9420 | Val Loss: 0.1822 Acc: 0.9269\n",
      "Epoch 045 | Train Loss: 0.1425 Acc: 0.9447 | Val Loss: 0.1548 Acc: 0.9372\n",
      "Epoch 046 | Train Loss: 0.1440 Acc: 0.9455 | Val Loss: 0.1527 Acc: 0.9384\n",
      "Epoch 047 | Train Loss: 0.1375 Acc: 0.9461 | Val Loss: 0.1562 Acc: 0.9438\n",
      "Epoch 048 | Train Loss: 0.1427 Acc: 0.9472 | Val Loss: 0.1897 Acc: 0.9281\n",
      "Epoch 049 | Train Loss: 0.1334 Acc: 0.9481 | Val Loss: 0.1582 Acc: 0.9396\n",
      "Epoch 050 | Train Loss: 0.1319 Acc: 0.9505 | Val Loss: 0.1479 Acc: 0.9420\n",
      "Epoch 051 | Train Loss: 0.1257 Acc: 0.9503 | Val Loss: 0.1395 Acc: 0.9499\n",
      "Epoch 052 | Train Loss: 0.1265 Acc: 0.9521 | Val Loss: 0.1502 Acc: 0.9493\n",
      "Epoch 053 | Train Loss: 0.1222 Acc: 0.9556 | Val Loss: 0.1483 Acc: 0.9487\n",
      "Epoch 054 | Train Loss: 0.1151 Acc: 0.9562 | Val Loss: 0.1606 Acc: 0.9426\n",
      "Epoch 055 | Train Loss: 0.1102 Acc: 0.9559 | Val Loss: 0.1373 Acc: 0.9523\n",
      "Epoch 056 | Train Loss: 0.1120 Acc: 0.9580 | Val Loss: 0.1447 Acc: 0.9487\n",
      "Epoch 057 | Train Loss: 0.1291 Acc: 0.9509 | Val Loss: 0.1436 Acc: 0.9444\n",
      "Epoch 058 | Train Loss: 0.1222 Acc: 0.9562 | Val Loss: 0.1430 Acc: 0.9487\n",
      "Epoch 059 | Train Loss: 0.1053 Acc: 0.9621 | Val Loss: 0.1523 Acc: 0.9481\n",
      "Epoch 060 | Train Loss: 0.1029 Acc: 0.9633 | Val Loss: 0.1341 Acc: 0.9529\n",
      "Epoch 001 | Train Loss: 0.6785 Acc: 0.5852 | Val Loss: 0.6734 Acc: 0.5894\n",
      "Epoch 002 | Train Loss: 0.6565 Acc: 0.6206 | Val Loss: 0.6419 Acc: 0.6389\n",
      "Epoch 003 | Train Loss: 0.5950 Acc: 0.6982 | Val Loss: 0.5753 Acc: 0.7120\n",
      "Epoch 004 | Train Loss: 0.5608 Acc: 0.7241 | Val Loss: 0.5588 Acc: 0.7252\n",
      "Epoch 005 | Train Loss: 0.5320 Acc: 0.7398 | Val Loss: 0.5811 Acc: 0.7059\n",
      "Epoch 006 | Train Loss: 0.5124 Acc: 0.7557 | Val Loss: 0.5218 Acc: 0.7476\n",
      "Epoch 007 | Train Loss: 0.4869 Acc: 0.7728 | Val Loss: 0.4776 Acc: 0.7748\n",
      "Epoch 008 | Train Loss: 0.4598 Acc: 0.7835 | Val Loss: 0.4577 Acc: 0.7772\n",
      "Epoch 009 | Train Loss: 0.4246 Acc: 0.8082 | Val Loss: 0.4153 Acc: 0.8110\n",
      "Epoch 010 | Train Loss: 0.4051 Acc: 0.8205 | Val Loss: 0.4113 Acc: 0.8122\n",
      "Epoch 011 | Train Loss: 0.3608 Acc: 0.8392 | Val Loss: 0.3612 Acc: 0.8466\n",
      "Epoch 012 | Train Loss: 0.3390 Acc: 0.8551 | Val Loss: 0.3472 Acc: 0.8490\n",
      "Epoch 013 | Train Loss: 0.3055 Acc: 0.8720 | Val Loss: 0.3058 Acc: 0.8678\n",
      "Epoch 014 | Train Loss: 0.2857 Acc: 0.8778 | Val Loss: 0.2866 Acc: 0.8750\n",
      "Epoch 015 | Train Loss: 0.2878 Acc: 0.8813 | Val Loss: 0.2727 Acc: 0.8883\n",
      "Epoch 016 | Train Loss: 0.2503 Acc: 0.8996 | Val Loss: 0.2854 Acc: 0.8786\n",
      "Epoch 017 | Train Loss: 0.2385 Acc: 0.9032 | Val Loss: 0.2511 Acc: 0.9010\n",
      "Epoch 018 | Train Loss: 0.2407 Acc: 0.9065 | Val Loss: 0.2338 Acc: 0.9130\n",
      "Epoch 019 | Train Loss: 0.2112 Acc: 0.9159 | Val Loss: 0.2308 Acc: 0.9010\n",
      "Epoch 020 | Train Loss: 0.1988 Acc: 0.9203 | Val Loss: 0.2206 Acc: 0.9088\n",
      "Epoch 021 | Train Loss: 0.1851 Acc: 0.9256 | Val Loss: 0.2210 Acc: 0.9143\n",
      "Epoch 022 | Train Loss: 0.1727 Acc: 0.9299 | Val Loss: 0.2178 Acc: 0.9040\n",
      "Epoch 023 | Train Loss: 0.1729 Acc: 0.9321 | Val Loss: 0.2355 Acc: 0.9076\n",
      "Epoch 024 | Train Loss: 0.1572 Acc: 0.9369 | Val Loss: 0.2721 Acc: 0.8853\n",
      "Epoch 025 | Train Loss: 0.1447 Acc: 0.9443 | Val Loss: 0.1918 Acc: 0.9191\n",
      "Epoch 026 | Train Loss: 0.1419 Acc: 0.9464 | Val Loss: 0.1847 Acc: 0.9233\n",
      "Epoch 027 | Train Loss: 0.1365 Acc: 0.9493 | Val Loss: 0.1940 Acc: 0.9239\n",
      "Epoch 028 | Train Loss: 0.1321 Acc: 0.9518 | Val Loss: 0.1746 Acc: 0.9372\n",
      "Epoch 029 | Train Loss: 0.1271 Acc: 0.9526 | Val Loss: 0.1858 Acc: 0.9227\n",
      "Epoch 030 | Train Loss: 0.1204 Acc: 0.9530 | Val Loss: 0.1887 Acc: 0.9227\n",
      "Epoch 031 | Train Loss: 0.1025 Acc: 0.9626 | Val Loss: 0.2070 Acc: 0.9287\n",
      "Epoch 032 | Train Loss: 0.1106 Acc: 0.9568 | Val Loss: 0.1938 Acc: 0.9336\n",
      "Epoch 033 | Train Loss: 0.0987 Acc: 0.9648 | Val Loss: 0.2131 Acc: 0.9318\n",
      "Epoch 034 | Train Loss: 0.1060 Acc: 0.9597 | Val Loss: 0.1747 Acc: 0.9293\n",
      "Epoch 035 | Train Loss: 0.0924 Acc: 0.9653 | Val Loss: 0.1956 Acc: 0.9293\n",
      "Epoch 036 | Train Loss: 0.0995 Acc: 0.9642 | Val Loss: 0.1865 Acc: 0.9318\n",
      "Epoch 037 | Train Loss: 0.0913 Acc: 0.9651 | Val Loss: 0.1932 Acc: 0.9360\n",
      "Epoch 038 | Train Loss: 0.0919 Acc: 0.9662 | Val Loss: 0.1749 Acc: 0.9390\n",
      "Early stopping triggered.\n",
      "Epoch 001 | Train Loss: 0.6766 Acc: 0.5816 | Val Loss: 0.6713 Acc: 0.5900\n",
      "Epoch 002 | Train Loss: 0.6655 Acc: 0.5958 | Val Loss: 0.6609 Acc: 0.6021\n",
      "Epoch 003 | Train Loss: 0.6502 Acc: 0.6154 | Val Loss: 0.6276 Acc: 0.6643\n",
      "Epoch 004 | Train Loss: 0.6162 Acc: 0.6714 | Val Loss: 0.6086 Acc: 0.6812\n",
      "Epoch 005 | Train Loss: 0.5727 Acc: 0.7134 | Val Loss: 0.5829 Acc: 0.6896\n",
      "Epoch 006 | Train Loss: 0.5402 Acc: 0.7344 | Val Loss: 0.5565 Acc: 0.7186\n",
      "Epoch 007 | Train Loss: 0.5213 Acc: 0.7451 | Val Loss: 0.5241 Acc: 0.7331\n",
      "Epoch 008 | Train Loss: 0.4962 Acc: 0.7632 | Val Loss: 0.4989 Acc: 0.7603\n",
      "Epoch 009 | Train Loss: 0.4686 Acc: 0.7787 | Val Loss: 0.5152 Acc: 0.7500\n",
      "Epoch 010 | Train Loss: 0.4443 Acc: 0.7936 | Val Loss: 0.4406 Acc: 0.7880\n",
      "Epoch 011 | Train Loss: 0.4110 Acc: 0.8144 | Val Loss: 0.4225 Acc: 0.8043\n",
      "Epoch 012 | Train Loss: 0.3890 Acc: 0.8239 | Val Loss: 0.3799 Acc: 0.8267\n",
      "Epoch 013 | Train Loss: 0.3619 Acc: 0.8357 | Val Loss: 0.3732 Acc: 0.8364\n",
      "Epoch 014 | Train Loss: 0.3415 Acc: 0.8492 | Val Loss: 0.3756 Acc: 0.8273\n",
      "Epoch 015 | Train Loss: 0.3124 Acc: 0.8665 | Val Loss: 0.3429 Acc: 0.8424\n",
      "Epoch 016 | Train Loss: 0.2891 Acc: 0.8769 | Val Loss: 0.3059 Acc: 0.8684\n",
      "Epoch 017 | Train Loss: 0.2653 Acc: 0.8910 | Val Loss: 0.2593 Acc: 0.8925\n",
      "Epoch 018 | Train Loss: 0.2476 Acc: 0.8954 | Val Loss: 0.2947 Acc: 0.8768\n",
      "Epoch 019 | Train Loss: 0.2482 Acc: 0.8981 | Val Loss: 0.3493 Acc: 0.8665\n",
      "Epoch 020 | Train Loss: 0.2479 Acc: 0.8946 | Val Loss: 0.2902 Acc: 0.8822\n",
      "Epoch 021 | Train Loss: 0.2090 Acc: 0.9182 | Val Loss: 0.2378 Acc: 0.9052\n",
      "Epoch 022 | Train Loss: 0.1892 Acc: 0.9218 | Val Loss: 0.2267 Acc: 0.9040\n",
      "Epoch 023 | Train Loss: 0.1866 Acc: 0.9259 | Val Loss: 0.2280 Acc: 0.8961\n",
      "Epoch 024 | Train Loss: 0.1697 Acc: 0.9334 | Val Loss: 0.2533 Acc: 0.8949\n",
      "Epoch 025 | Train Loss: 0.1726 Acc: 0.9296 | Val Loss: 0.2354 Acc: 0.9112\n",
      "Epoch 026 | Train Loss: 0.1543 Acc: 0.9395 | Val Loss: 0.2066 Acc: 0.9155\n",
      "Epoch 027 | Train Loss: 0.1469 Acc: 0.9449 | Val Loss: 0.2043 Acc: 0.9251\n",
      "Epoch 028 | Train Loss: 0.1319 Acc: 0.9499 | Val Loss: 0.2246 Acc: 0.9112\n",
      "Epoch 029 | Train Loss: 0.1325 Acc: 0.9476 | Val Loss: 0.2279 Acc: 0.9088\n",
      "Epoch 030 | Train Loss: 0.1220 Acc: 0.9532 | Val Loss: 0.2117 Acc: 0.9173\n",
      "Epoch 031 | Train Loss: 0.1150 Acc: 0.9562 | Val Loss: 0.1936 Acc: 0.9281\n",
      "Epoch 032 | Train Loss: 0.1149 Acc: 0.9579 | Val Loss: 0.1852 Acc: 0.9293\n",
      "Epoch 033 | Train Loss: 0.1128 Acc: 0.9570 | Val Loss: 0.1733 Acc: 0.9300\n",
      "Epoch 034 | Train Loss: 0.1100 Acc: 0.9570 | Val Loss: 0.1800 Acc: 0.9324\n",
      "Epoch 035 | Train Loss: 0.1018 Acc: 0.9609 | Val Loss: 0.1648 Acc: 0.9354\n",
      "Epoch 036 | Train Loss: 0.0992 Acc: 0.9651 | Val Loss: 0.1900 Acc: 0.9330\n",
      "Epoch 037 | Train Loss: 0.0901 Acc: 0.9654 | Val Loss: 0.1845 Acc: 0.9408\n",
      "Epoch 038 | Train Loss: 0.0861 Acc: 0.9672 | Val Loss: 0.1920 Acc: 0.9312\n",
      "Epoch 039 | Train Loss: 0.0847 Acc: 0.9684 | Val Loss: 0.2040 Acc: 0.9300\n",
      "Epoch 040 | Train Loss: 0.0799 Acc: 0.9701 | Val Loss: 0.2406 Acc: 0.9173\n",
      "Epoch 041 | Train Loss: 0.0754 Acc: 0.9700 | Val Loss: 0.1852 Acc: 0.9306\n",
      "Epoch 042 | Train Loss: 0.0858 Acc: 0.9698 | Val Loss: 0.1702 Acc: 0.9342\n",
      "Epoch 043 | Train Loss: 0.0821 Acc: 0.9693 | Val Loss: 0.1703 Acc: 0.9408\n",
      "Epoch 044 | Train Loss: 0.0653 Acc: 0.9769 | Val Loss: 0.1904 Acc: 0.9360\n",
      "Epoch 045 | Train Loss: 0.0691 Acc: 0.9736 | Val Loss: 0.1654 Acc: 0.9463\n",
      "Early stopping triggered.\n",
      "Epoch 001 | Train Loss: 0.6789 Acc: 0.5812 | Val Loss: 0.6741 Acc: 0.5900\n",
      "Epoch 002 | Train Loss: 0.6799 Acc: 0.5756 | Val Loss: 0.6794 Acc: 0.5743\n",
      "Epoch 003 | Train Loss: 0.6732 Acc: 0.5969 | Val Loss: 0.6568 Acc: 0.6051\n",
      "Epoch 004 | Train Loss: 0.6377 Acc: 0.6425 | Val Loss: 0.6059 Acc: 0.6830\n",
      "Epoch 005 | Train Loss: 0.5987 Acc: 0.6906 | Val Loss: 0.5788 Acc: 0.6999\n",
      "Epoch 006 | Train Loss: 0.5576 Acc: 0.7258 | Val Loss: 0.5501 Acc: 0.7240\n",
      "Epoch 007 | Train Loss: 0.5243 Acc: 0.7469 | Val Loss: 0.5282 Acc: 0.7379\n",
      "Epoch 008 | Train Loss: 0.5016 Acc: 0.7583 | Val Loss: 0.5150 Acc: 0.7542\n",
      "Epoch 009 | Train Loss: 0.4848 Acc: 0.7684 | Val Loss: 0.5203 Acc: 0.7446\n",
      "Epoch 010 | Train Loss: 0.4783 Acc: 0.7679 | Val Loss: 0.4704 Acc: 0.7579\n",
      "Epoch 011 | Train Loss: 0.4354 Acc: 0.7927 | Val Loss: 0.4402 Acc: 0.7905\n",
      "Epoch 012 | Train Loss: 0.4118 Acc: 0.8033 | Val Loss: 0.4206 Acc: 0.8092\n",
      "Epoch 013 | Train Loss: 0.3995 Acc: 0.8128 | Val Loss: 0.3943 Acc: 0.8098\n",
      "Epoch 014 | Train Loss: 0.3769 Acc: 0.8309 | Val Loss: 0.3804 Acc: 0.8152\n",
      "Epoch 015 | Train Loss: 0.3636 Acc: 0.8374 | Val Loss: 0.3665 Acc: 0.8255\n",
      "Epoch 016 | Train Loss: 0.3327 Acc: 0.8538 | Val Loss: 0.3597 Acc: 0.8382\n",
      "Epoch 017 | Train Loss: 0.3159 Acc: 0.8602 | Val Loss: 0.3576 Acc: 0.8466\n",
      "Epoch 018 | Train Loss: 0.2974 Acc: 0.8705 | Val Loss: 0.3035 Acc: 0.8684\n",
      "Epoch 019 | Train Loss: 0.2851 Acc: 0.8797 | Val Loss: 0.2882 Acc: 0.8804\n",
      "Epoch 020 | Train Loss: 0.2800 Acc: 0.8845 | Val Loss: 0.2854 Acc: 0.8708\n",
      "Epoch 021 | Train Loss: 0.2597 Acc: 0.8899 | Val Loss: 0.2750 Acc: 0.8768\n",
      "Epoch 022 | Train Loss: 0.2347 Acc: 0.9025 | Val Loss: 0.3089 Acc: 0.8810\n",
      "Epoch 023 | Train Loss: 0.2351 Acc: 0.9002 | Val Loss: 0.2660 Acc: 0.8889\n",
      "Epoch 024 | Train Loss: 0.2276 Acc: 0.9065 | Val Loss: 0.2435 Acc: 0.8913\n",
      "Epoch 025 | Train Loss: 0.2048 Acc: 0.9156 | Val Loss: 0.2315 Acc: 0.9046\n",
      "Epoch 026 | Train Loss: 0.2061 Acc: 0.9185 | Val Loss: 0.2487 Acc: 0.8986\n",
      "Epoch 027 | Train Loss: 0.2030 Acc: 0.9174 | Val Loss: 0.2236 Acc: 0.9058\n",
      "Epoch 028 | Train Loss: 0.1934 Acc: 0.9236 | Val Loss: 0.2186 Acc: 0.9028\n",
      "Epoch 029 | Train Loss: 0.1839 Acc: 0.9244 | Val Loss: 0.1863 Acc: 0.9281\n",
      "Epoch 030 | Train Loss: 0.1722 Acc: 0.9327 | Val Loss: 0.2069 Acc: 0.9130\n",
      "Epoch 031 | Train Loss: 0.1638 Acc: 0.9360 | Val Loss: 0.2238 Acc: 0.9070\n",
      "Epoch 032 | Train Loss: 0.1523 Acc: 0.9414 | Val Loss: 0.2170 Acc: 0.9136\n",
      "Epoch 033 | Train Loss: 0.1506 Acc: 0.9449 | Val Loss: 0.2430 Acc: 0.8992\n",
      "Epoch 034 | Train Loss: 0.1469 Acc: 0.9416 | Val Loss: 0.1837 Acc: 0.9251\n",
      "Epoch 035 | Train Loss: 0.1407 Acc: 0.9481 | Val Loss: 0.1767 Acc: 0.9366\n",
      "Epoch 036 | Train Loss: 0.1367 Acc: 0.9487 | Val Loss: 0.2045 Acc: 0.9221\n",
      "Epoch 037 | Train Loss: 0.1330 Acc: 0.9467 | Val Loss: 0.1755 Acc: 0.9287\n",
      "Epoch 038 | Train Loss: 0.1236 Acc: 0.9546 | Val Loss: 0.1650 Acc: 0.9360\n",
      "Epoch 039 | Train Loss: 0.1330 Acc: 0.9478 | Val Loss: 0.1709 Acc: 0.9372\n",
      "Epoch 040 | Train Loss: 0.1161 Acc: 0.9556 | Val Loss: 0.1725 Acc: 0.9372\n",
      "Epoch 041 | Train Loss: 0.1152 Acc: 0.9555 | Val Loss: 0.1838 Acc: 0.9287\n",
      "Epoch 042 | Train Loss: 0.1057 Acc: 0.9597 | Val Loss: 0.1871 Acc: 0.9378\n",
      "Epoch 043 | Train Loss: 0.1042 Acc: 0.9613 | Val Loss: 0.1748 Acc: 0.9348\n",
      "Epoch 044 | Train Loss: 0.1060 Acc: 0.9597 | Val Loss: 0.1607 Acc: 0.9378\n",
      "Epoch 045 | Train Loss: 0.1068 Acc: 0.9607 | Val Loss: 0.1733 Acc: 0.9426\n",
      "Epoch 046 | Train Loss: 0.0925 Acc: 0.9648 | Val Loss: 0.1413 Acc: 0.9499\n",
      "Epoch 047 | Train Loss: 0.1052 Acc: 0.9594 | Val Loss: 0.1496 Acc: 0.9463\n",
      "Epoch 048 | Train Loss: 0.1022 Acc: 0.9600 | Val Loss: 0.1934 Acc: 0.9354\n",
      "Epoch 049 | Train Loss: 0.0999 Acc: 0.9621 | Val Loss: 0.1472 Acc: 0.9457\n",
      "Epoch 050 | Train Loss: 0.0918 Acc: 0.9663 | Val Loss: 0.1992 Acc: 0.9281\n",
      "Epoch 051 | Train Loss: 0.0893 Acc: 0.9666 | Val Loss: 0.2592 Acc: 0.9173\n",
      "Epoch 052 | Train Loss: 0.0852 Acc: 0.9672 | Val Loss: 0.1547 Acc: 0.9450\n",
      "Epoch 053 | Train Loss: 0.0874 Acc: 0.9671 | Val Loss: 0.1498 Acc: 0.9463\n",
      "Epoch 054 | Train Loss: 0.0764 Acc: 0.9715 | Val Loss: 0.1480 Acc: 0.9432\n",
      "Epoch 055 | Train Loss: 0.0776 Acc: 0.9727 | Val Loss: 0.1814 Acc: 0.9420\n",
      "Epoch 056 | Train Loss: 0.0811 Acc: 0.9687 | Val Loss: 0.1545 Acc: 0.9469\n",
      "Early stopping triggered.\n",
      "Epoch 001 | Train Loss: 0.6805 Acc: 0.5789 | Val Loss: 0.6741 Acc: 0.5900\n",
      "Epoch 002 | Train Loss: 0.6708 Acc: 0.5946 | Val Loss: 0.6758 Acc: 0.5839\n",
      "Epoch 003 | Train Loss: 0.6528 Acc: 0.6163 | Val Loss: 0.6291 Acc: 0.6685\n",
      "Epoch 004 | Train Loss: 0.6311 Acc: 0.6509 | Val Loss: 0.6193 Acc: 0.6739\n",
      "Epoch 005 | Train Loss: 0.6116 Acc: 0.6764 | Val Loss: 0.6025 Acc: 0.6860\n",
      "Epoch 006 | Train Loss: 0.6058 Acc: 0.6788 | Val Loss: 0.5879 Acc: 0.6999\n",
      "Epoch 007 | Train Loss: 0.5861 Acc: 0.7007 | Val Loss: 0.5876 Acc: 0.6969\n",
      "Epoch 008 | Train Loss: 0.5702 Acc: 0.7152 | Val Loss: 0.5602 Acc: 0.7156\n",
      "Epoch 009 | Train Loss: 0.5508 Acc: 0.7257 | Val Loss: 0.5650 Acc: 0.7156\n",
      "Epoch 010 | Train Loss: 0.5307 Acc: 0.7448 | Val Loss: 0.5507 Acc: 0.7210\n",
      "Epoch 011 | Train Loss: 0.5202 Acc: 0.7531 | Val Loss: 0.5442 Acc: 0.7277\n",
      "Epoch 012 | Train Loss: 0.5135 Acc: 0.7560 | Val Loss: 0.5328 Acc: 0.7313\n",
      "Epoch 013 | Train Loss: 0.5059 Acc: 0.7580 | Val Loss: 0.5263 Acc: 0.7428\n",
      "Epoch 014 | Train Loss: 0.4877 Acc: 0.7681 | Val Loss: 0.5224 Acc: 0.7440\n",
      "Epoch 015 | Train Loss: 0.4948 Acc: 0.7666 | Val Loss: 0.5010 Acc: 0.7524\n",
      "Epoch 016 | Train Loss: 0.4688 Acc: 0.7818 | Val Loss: 0.4876 Acc: 0.7627\n",
      "Epoch 017 | Train Loss: 0.4619 Acc: 0.7842 | Val Loss: 0.4710 Acc: 0.7705\n",
      "Epoch 018 | Train Loss: 0.4552 Acc: 0.7888 | Val Loss: 0.5111 Acc: 0.7428\n",
      "Epoch 019 | Train Loss: 0.4374 Acc: 0.8010 | Val Loss: 0.4538 Acc: 0.7820\n",
      "Epoch 020 | Train Loss: 0.4274 Acc: 0.8052 | Val Loss: 0.4511 Acc: 0.7814\n",
      "Epoch 021 | Train Loss: 0.4165 Acc: 0.8067 | Val Loss: 0.4216 Acc: 0.8056\n",
      "Epoch 022 | Train Loss: 0.3983 Acc: 0.8203 | Val Loss: 0.4759 Acc: 0.7669\n",
      "Epoch 023 | Train Loss: 0.3973 Acc: 0.8194 | Val Loss: 0.4102 Acc: 0.8225\n",
      "Epoch 024 | Train Loss: 0.3751 Acc: 0.8318 | Val Loss: 0.3665 Acc: 0.8279\n",
      "Epoch 025 | Train Loss: 0.3583 Acc: 0.8390 | Val Loss: 0.3869 Acc: 0.8158\n",
      "Epoch 026 | Train Loss: 0.3459 Acc: 0.8357 | Val Loss: 0.3410 Acc: 0.8472\n",
      "Epoch 027 | Train Loss: 0.3313 Acc: 0.8519 | Val Loss: 0.3341 Acc: 0.8557\n",
      "Epoch 028 | Train Loss: 0.3202 Acc: 0.8603 | Val Loss: 0.3175 Acc: 0.8708\n",
      "Epoch 029 | Train Loss: 0.3069 Acc: 0.8664 | Val Loss: 0.3130 Acc: 0.8641\n",
      "Epoch 030 | Train Loss: 0.2886 Acc: 0.8756 | Val Loss: 0.3108 Acc: 0.8702\n",
      "Epoch 031 | Train Loss: 0.2783 Acc: 0.8780 | Val Loss: 0.3050 Acc: 0.8702\n",
      "Epoch 032 | Train Loss: 0.2629 Acc: 0.8890 | Val Loss: 0.3182 Acc: 0.8678\n",
      "Epoch 033 | Train Loss: 0.2658 Acc: 0.8863 | Val Loss: 0.2937 Acc: 0.8822\n",
      "Epoch 034 | Train Loss: 0.2435 Acc: 0.8957 | Val Loss: 0.2715 Acc: 0.8883\n",
      "Epoch 035 | Train Loss: 0.2363 Acc: 0.9017 | Val Loss: 0.2746 Acc: 0.8768\n",
      "Epoch 036 | Train Loss: 0.2206 Acc: 0.9079 | Val Loss: 0.2770 Acc: 0.8859\n",
      "Epoch 037 | Train Loss: 0.2143 Acc: 0.9091 | Val Loss: 0.2505 Acc: 0.8973\n",
      "Epoch 038 | Train Loss: 0.2240 Acc: 0.9085 | Val Loss: 0.2354 Acc: 0.9046\n",
      "Epoch 039 | Train Loss: 0.1932 Acc: 0.9238 | Val Loss: 0.2470 Acc: 0.8986\n",
      "Epoch 040 | Train Loss: 0.1967 Acc: 0.9188 | Val Loss: 0.2450 Acc: 0.9058\n",
      "Epoch 041 | Train Loss: 0.1903 Acc: 0.9225 | Val Loss: 0.2688 Acc: 0.8919\n",
      "Epoch 042 | Train Loss: 0.1752 Acc: 0.9262 | Val Loss: 0.2438 Acc: 0.9058\n",
      "Epoch 043 | Train Loss: 0.1756 Acc: 0.9295 | Val Loss: 0.2236 Acc: 0.9088\n",
      "Epoch 044 | Train Loss: 0.1594 Acc: 0.9366 | Val Loss: 0.2418 Acc: 0.9100\n",
      "Epoch 045 | Train Loss: 0.1549 Acc: 0.9375 | Val Loss: 0.2429 Acc: 0.9022\n",
      "Epoch 046 | Train Loss: 0.1466 Acc: 0.9444 | Val Loss: 0.2163 Acc: 0.9179\n",
      "Epoch 047 | Train Loss: 0.1493 Acc: 0.9382 | Val Loss: 0.2166 Acc: 0.9112\n",
      "Epoch 048 | Train Loss: 0.1344 Acc: 0.9485 | Val Loss: 0.2095 Acc: 0.9251\n",
      "Epoch 049 | Train Loss: 0.1360 Acc: 0.9459 | Val Loss: 0.2647 Acc: 0.9004\n",
      "Epoch 050 | Train Loss: 0.1287 Acc: 0.9493 | Val Loss: 0.2085 Acc: 0.9215\n",
      "Epoch 051 | Train Loss: 0.1248 Acc: 0.9514 | Val Loss: 0.2292 Acc: 0.9106\n",
      "Epoch 052 | Train Loss: 0.1313 Acc: 0.9494 | Val Loss: 0.2103 Acc: 0.9173\n",
      "Epoch 053 | Train Loss: 0.1099 Acc: 0.9591 | Val Loss: 0.2007 Acc: 0.9251\n",
      "Epoch 054 | Train Loss: 0.1164 Acc: 0.9555 | Val Loss: 0.1940 Acc: 0.9257\n",
      "Epoch 055 | Train Loss: 0.1175 Acc: 0.9536 | Val Loss: 0.2697 Acc: 0.9028\n",
      "Epoch 056 | Train Loss: 0.1066 Acc: 0.9589 | Val Loss: 0.1890 Acc: 0.9287\n",
      "Epoch 057 | Train Loss: 0.0980 Acc: 0.9635 | Val Loss: 0.1808 Acc: 0.9318\n",
      "Epoch 058 | Train Loss: 0.1008 Acc: 0.9638 | Val Loss: 0.1758 Acc: 0.9324\n",
      "Epoch 059 | Train Loss: 0.0965 Acc: 0.9647 | Val Loss: 0.2060 Acc: 0.9306\n",
      "Epoch 060 | Train Loss: 0.0958 Acc: 0.9621 | Val Loss: 0.2816 Acc: 0.9046\n",
      "Epoch 001 | Train Loss: 0.6829 Acc: 0.5700 | Val Loss: 0.6772 Acc: 0.5827\n",
      "Epoch 002 | Train Loss: 0.6748 Acc: 0.5929 | Val Loss: 0.6757 Acc: 0.5815\n",
      "Epoch 003 | Train Loss: 0.6636 Acc: 0.6101 | Val Loss: 0.6613 Acc: 0.6027\n",
      "Epoch 004 | Train Loss: 0.6356 Acc: 0.6491 | Val Loss: 0.6036 Acc: 0.6920\n",
      "Epoch 005 | Train Loss: 0.5991 Acc: 0.6974 | Val Loss: 0.5911 Acc: 0.7083\n",
      "Epoch 006 | Train Loss: 0.5651 Acc: 0.7264 | Val Loss: 0.5583 Acc: 0.7180\n",
      "Epoch 007 | Train Loss: 0.5385 Acc: 0.7424 | Val Loss: 0.5402 Acc: 0.7313\n",
      "Epoch 008 | Train Loss: 0.5252 Acc: 0.7469 | Val Loss: 0.5363 Acc: 0.7403\n",
      "Epoch 009 | Train Loss: 0.5157 Acc: 0.7584 | Val Loss: 0.5140 Acc: 0.7506\n",
      "Epoch 010 | Train Loss: 0.5194 Acc: 0.7489 | Val Loss: 0.5172 Acc: 0.7421\n",
      "Epoch 011 | Train Loss: 0.4845 Acc: 0.7684 | Val Loss: 0.4860 Acc: 0.7711\n",
      "Epoch 012 | Train Loss: 0.4771 Acc: 0.7762 | Val Loss: 0.4711 Acc: 0.7766\n",
      "Epoch 013 | Train Loss: 0.4602 Acc: 0.7823 | Val Loss: 0.4874 Acc: 0.7663\n",
      "Epoch 014 | Train Loss: 0.4658 Acc: 0.7761 | Val Loss: 0.4632 Acc: 0.7856\n",
      "Epoch 015 | Train Loss: 0.4375 Acc: 0.7945 | Val Loss: 0.4817 Acc: 0.7814\n",
      "Epoch 016 | Train Loss: 0.4326 Acc: 0.7975 | Val Loss: 0.4423 Acc: 0.7893\n",
      "Epoch 017 | Train Loss: 0.4206 Acc: 0.8072 | Val Loss: 0.4216 Acc: 0.8104\n",
      "Epoch 018 | Train Loss: 0.4010 Acc: 0.8165 | Val Loss: 0.4108 Acc: 0.8152\n",
      "Epoch 019 | Train Loss: 0.4033 Acc: 0.8158 | Val Loss: 0.4132 Acc: 0.8128\n",
      "Epoch 020 | Train Loss: 0.3858 Acc: 0.8253 | Val Loss: 0.3883 Acc: 0.8321\n",
      "Epoch 021 | Train Loss: 0.3766 Acc: 0.8298 | Val Loss: 0.3800 Acc: 0.8400\n",
      "Epoch 022 | Train Loss: 0.3624 Acc: 0.8409 | Val Loss: 0.3619 Acc: 0.8484\n",
      "Epoch 023 | Train Loss: 0.3573 Acc: 0.8416 | Val Loss: 0.3629 Acc: 0.8370\n",
      "Epoch 024 | Train Loss: 0.3378 Acc: 0.8480 | Val Loss: 0.3264 Acc: 0.8611\n",
      "Epoch 025 | Train Loss: 0.3326 Acc: 0.8519 | Val Loss: 0.3561 Acc: 0.8521\n",
      "Epoch 026 | Train Loss: 0.3185 Acc: 0.8603 | Val Loss: 0.3130 Acc: 0.8690\n",
      "Epoch 027 | Train Loss: 0.3056 Acc: 0.8705 | Val Loss: 0.2868 Acc: 0.8822\n",
      "Epoch 028 | Train Loss: 0.3013 Acc: 0.8708 | Val Loss: 0.2991 Acc: 0.8732\n",
      "Epoch 029 | Train Loss: 0.2917 Acc: 0.8777 | Val Loss: 0.2775 Acc: 0.8883\n",
      "Epoch 030 | Train Loss: 0.2695 Acc: 0.8875 | Val Loss: 0.2844 Acc: 0.8768\n",
      "Epoch 031 | Train Loss: 0.2623 Acc: 0.8934 | Val Loss: 0.2715 Acc: 0.8877\n",
      "Epoch 032 | Train Loss: 0.2577 Acc: 0.8945 | Val Loss: 0.2783 Acc: 0.8829\n",
      "Epoch 033 | Train Loss: 0.2550 Acc: 0.8969 | Val Loss: 0.2566 Acc: 0.8919\n",
      "Epoch 034 | Train Loss: 0.2399 Acc: 0.8999 | Val Loss: 0.2324 Acc: 0.9118\n",
      "Epoch 035 | Train Loss: 0.2389 Acc: 0.8991 | Val Loss: 0.2566 Acc: 0.8901\n",
      "Epoch 036 | Train Loss: 0.2314 Acc: 0.9087 | Val Loss: 0.2156 Acc: 0.9100\n",
      "Epoch 037 | Train Loss: 0.2282 Acc: 0.9088 | Val Loss: 0.2312 Acc: 0.9058\n",
      "Epoch 038 | Train Loss: 0.2202 Acc: 0.9133 | Val Loss: 0.2174 Acc: 0.9185\n",
      "Epoch 039 | Train Loss: 0.2123 Acc: 0.9171 | Val Loss: 0.2346 Acc: 0.9004\n",
      "Epoch 040 | Train Loss: 0.2021 Acc: 0.9200 | Val Loss: 0.2219 Acc: 0.9143\n",
      "Epoch 041 | Train Loss: 0.2030 Acc: 0.9198 | Val Loss: 0.2382 Acc: 0.9130\n",
      "Epoch 042 | Train Loss: 0.1986 Acc: 0.9197 | Val Loss: 0.2078 Acc: 0.9257\n",
      "Epoch 043 | Train Loss: 0.1863 Acc: 0.9274 | Val Loss: 0.2254 Acc: 0.9227\n",
      "Epoch 044 | Train Loss: 0.1975 Acc: 0.9251 | Val Loss: 0.2146 Acc: 0.9185\n",
      "Epoch 045 | Train Loss: 0.1874 Acc: 0.9215 | Val Loss: 0.2183 Acc: 0.9118\n",
      "Epoch 046 | Train Loss: 0.1886 Acc: 0.9251 | Val Loss: 0.2357 Acc: 0.9028\n",
      "Epoch 047 | Train Loss: 0.1797 Acc: 0.9277 | Val Loss: 0.2628 Acc: 0.9016\n",
      "Epoch 048 | Train Loss: 0.1728 Acc: 0.9331 | Val Loss: 0.1967 Acc: 0.9173\n",
      "Epoch 049 | Train Loss: 0.1747 Acc: 0.9310 | Val Loss: 0.1780 Acc: 0.9293\n",
      "Epoch 050 | Train Loss: 0.1559 Acc: 0.9402 | Val Loss: 0.1874 Acc: 0.9293\n",
      "Epoch 051 | Train Loss: 0.1616 Acc: 0.9369 | Val Loss: 0.2596 Acc: 0.8998\n",
      "Epoch 052 | Train Loss: 0.1732 Acc: 0.9345 | Val Loss: 0.1671 Acc: 0.9360\n",
      "Epoch 053 | Train Loss: 0.1554 Acc: 0.9408 | Val Loss: 0.1829 Acc: 0.9281\n",
      "Epoch 054 | Train Loss: 0.1556 Acc: 0.9413 | Val Loss: 0.1791 Acc: 0.9281\n",
      "Epoch 055 | Train Loss: 0.1484 Acc: 0.9440 | Val Loss: 0.1750 Acc: 0.9257\n",
      "Epoch 056 | Train Loss: 0.1380 Acc: 0.9475 | Val Loss: 0.1719 Acc: 0.9378\n",
      "Epoch 057 | Train Loss: 0.1412 Acc: 0.9452 | Val Loss: 0.1572 Acc: 0.9378\n",
      "Epoch 058 | Train Loss: 0.1406 Acc: 0.9469 | Val Loss: 0.2052 Acc: 0.9179\n",
      "Epoch 059 | Train Loss: 0.1448 Acc: 0.9420 | Val Loss: 0.1792 Acc: 0.9378\n",
      "Epoch 060 | Train Loss: 0.1350 Acc: 0.9497 | Val Loss: 0.1706 Acc: 0.9342\n",
      "Epoch 001 | Train Loss: 0.6828 Acc: 0.5694 | Val Loss: 0.6606 Acc: 0.6087\n",
      "Epoch 002 | Train Loss: 0.6487 Acc: 0.6406 | Val Loss: 0.6228 Acc: 0.6600\n",
      "Epoch 003 | Train Loss: 0.5959 Acc: 0.6920 | Val Loss: 0.5769 Acc: 0.7053\n",
      "Epoch 004 | Train Loss: 0.5583 Acc: 0.7244 | Val Loss: 0.5567 Acc: 0.7101\n",
      "Epoch 005 | Train Loss: 0.5384 Acc: 0.7335 | Val Loss: 0.5251 Acc: 0.7307\n",
      "Epoch 006 | Train Loss: 0.5278 Acc: 0.7424 | Val Loss: 0.5052 Acc: 0.7403\n",
      "Epoch 007 | Train Loss: 0.4981 Acc: 0.7599 | Val Loss: 0.4882 Acc: 0.7500\n",
      "Epoch 008 | Train Loss: 0.4754 Acc: 0.7687 | Val Loss: 0.4889 Acc: 0.7572\n",
      "Epoch 009 | Train Loss: 0.4558 Acc: 0.7761 | Val Loss: 0.4615 Acc: 0.7693\n",
      "Epoch 010 | Train Loss: 0.4370 Acc: 0.7931 | Val Loss: 0.4225 Acc: 0.8092\n",
      "Epoch 011 | Train Loss: 0.4177 Acc: 0.8082 | Val Loss: 0.4275 Acc: 0.7965\n",
      "Epoch 012 | Train Loss: 0.4051 Acc: 0.8126 | Val Loss: 0.3963 Acc: 0.8194\n",
      "Epoch 013 | Train Loss: 0.3874 Acc: 0.8217 | Val Loss: 0.3595 Acc: 0.8321\n",
      "Epoch 014 | Train Loss: 0.3647 Acc: 0.8350 | Val Loss: 0.3698 Acc: 0.8394\n",
      "Epoch 015 | Train Loss: 0.3405 Acc: 0.8480 | Val Loss: 0.3106 Acc: 0.8545\n",
      "Epoch 016 | Train Loss: 0.3381 Acc: 0.8537 | Val Loss: 0.3459 Acc: 0.8490\n",
      "Epoch 017 | Train Loss: 0.3141 Acc: 0.8653 | Val Loss: 0.2939 Acc: 0.8756\n",
      "Epoch 018 | Train Loss: 0.2977 Acc: 0.8720 | Val Loss: 0.3086 Acc: 0.8635\n",
      "Epoch 019 | Train Loss: 0.2879 Acc: 0.8801 | Val Loss: 0.2739 Acc: 0.8774\n",
      "Epoch 020 | Train Loss: 0.2776 Acc: 0.8815 | Val Loss: 0.2790 Acc: 0.8871\n",
      "Epoch 021 | Train Loss: 0.2634 Acc: 0.8914 | Val Loss: 0.2875 Acc: 0.8792\n",
      "Epoch 022 | Train Loss: 0.2544 Acc: 0.8931 | Val Loss: 0.2777 Acc: 0.8871\n",
      "Epoch 023 | Train Loss: 0.2516 Acc: 0.8946 | Val Loss: 0.2455 Acc: 0.9058\n",
      "Epoch 024 | Train Loss: 0.2382 Acc: 0.8993 | Val Loss: 0.2403 Acc: 0.9022\n",
      "Epoch 025 | Train Loss: 0.2307 Acc: 0.9064 | Val Loss: 0.2433 Acc: 0.8998\n",
      "Epoch 026 | Train Loss: 0.2206 Acc: 0.9088 | Val Loss: 0.2303 Acc: 0.9034\n",
      "Epoch 027 | Train Loss: 0.2026 Acc: 0.9203 | Val Loss: 0.2791 Acc: 0.8859\n",
      "Epoch 028 | Train Loss: 0.2096 Acc: 0.9151 | Val Loss: 0.2337 Acc: 0.9046\n",
      "Epoch 029 | Train Loss: 0.1980 Acc: 0.9195 | Val Loss: 0.2318 Acc: 0.9046\n",
      "Epoch 030 | Train Loss: 0.1989 Acc: 0.9186 | Val Loss: 0.2157 Acc: 0.9136\n",
      "Epoch 031 | Train Loss: 0.1817 Acc: 0.9289 | Val Loss: 0.2347 Acc: 0.9028\n",
      "Epoch 032 | Train Loss: 0.1961 Acc: 0.9238 | Val Loss: 0.1942 Acc: 0.9179\n",
      "Epoch 033 | Train Loss: 0.1809 Acc: 0.9301 | Val Loss: 0.2304 Acc: 0.9070\n",
      "Epoch 034 | Train Loss: 0.1697 Acc: 0.9354 | Val Loss: 0.2560 Acc: 0.9022\n",
      "Epoch 035 | Train Loss: 0.1847 Acc: 0.9292 | Val Loss: 0.2049 Acc: 0.9203\n",
      "Epoch 036 | Train Loss: 0.1591 Acc: 0.9399 | Val Loss: 0.1782 Acc: 0.9306\n",
      "Epoch 037 | Train Loss: 0.1608 Acc: 0.9364 | Val Loss: 0.1886 Acc: 0.9251\n",
      "Epoch 038 | Train Loss: 0.1642 Acc: 0.9382 | Val Loss: 0.1837 Acc: 0.9233\n",
      "Epoch 039 | Train Loss: 0.1488 Acc: 0.9420 | Val Loss: 0.1863 Acc: 0.9287\n",
      "Epoch 040 | Train Loss: 0.1427 Acc: 0.9464 | Val Loss: 0.1720 Acc: 0.9330\n",
      "Epoch 041 | Train Loss: 0.1343 Acc: 0.9502 | Val Loss: 0.1977 Acc: 0.9330\n",
      "Epoch 042 | Train Loss: 0.1483 Acc: 0.9425 | Val Loss: 0.1808 Acc: 0.9263\n",
      "Epoch 043 | Train Loss: 0.1426 Acc: 0.9450 | Val Loss: 0.1960 Acc: 0.9221\n",
      "Epoch 044 | Train Loss: 0.1392 Acc: 0.9479 | Val Loss: 0.1755 Acc: 0.9390\n",
      "Epoch 045 | Train Loss: 0.1332 Acc: 0.9508 | Val Loss: 0.1601 Acc: 0.9408\n",
      "Epoch 046 | Train Loss: 0.1300 Acc: 0.9512 | Val Loss: 0.1628 Acc: 0.9396\n",
      "Epoch 047 | Train Loss: 0.1344 Acc: 0.9491 | Val Loss: 0.1810 Acc: 0.9287\n",
      "Epoch 048 | Train Loss: 0.1330 Acc: 0.9500 | Val Loss: 0.1698 Acc: 0.9306\n",
      "Epoch 049 | Train Loss: 0.1167 Acc: 0.9553 | Val Loss: 0.1708 Acc: 0.9438\n",
      "Epoch 050 | Train Loss: 0.1296 Acc: 0.9491 | Val Loss: 0.1972 Acc: 0.9306\n",
      "Epoch 051 | Train Loss: 0.1138 Acc: 0.9561 | Val Loss: 0.1685 Acc: 0.9414\n",
      "Epoch 052 | Train Loss: 0.1300 Acc: 0.9511 | Val Loss: 0.1829 Acc: 0.9354\n",
      "Epoch 053 | Train Loss: 0.1217 Acc: 0.9544 | Val Loss: 0.1655 Acc: 0.9324\n",
      "Epoch 054 | Train Loss: 0.1213 Acc: 0.9518 | Val Loss: 0.1937 Acc: 0.9239\n",
      "Epoch 055 | Train Loss: 0.1296 Acc: 0.9521 | Val Loss: 0.1814 Acc: 0.9336\n",
      "Early stopping triggered.\n",
      "Iteration 13/40 | Best Val Loss: 0.1122 | Iter Time: 200.90s | Total Time: 60.88 min\n",
      "Epoch 001 | Train Loss: 0.6801 Acc: 0.5819 | Val Loss: 0.6785 Acc: 0.5815\n",
      "Epoch 002 | Train Loss: 0.6712 Acc: 0.5961 | Val Loss: 0.6619 Acc: 0.6027\n",
      "Epoch 003 | Train Loss: 0.6349 Acc: 0.6447 | Val Loss: 0.5935 Acc: 0.7011\n",
      "Epoch 004 | Train Loss: 0.5643 Acc: 0.7193 | Val Loss: 0.5600 Acc: 0.7150\n",
      "Epoch 005 | Train Loss: 0.5233 Acc: 0.7439 | Val Loss: 0.5144 Acc: 0.7470\n",
      "Epoch 006 | Train Loss: 0.5040 Acc: 0.7587 | Val Loss: 0.4907 Acc: 0.7645\n",
      "Epoch 007 | Train Loss: 0.4731 Acc: 0.7783 | Val Loss: 0.4878 Acc: 0.7524\n",
      "Epoch 008 | Train Loss: 0.4468 Acc: 0.7909 | Val Loss: 0.4198 Acc: 0.7983\n",
      "Epoch 009 | Train Loss: 0.4102 Acc: 0.8067 | Val Loss: 0.4432 Acc: 0.7802\n",
      "Epoch 010 | Train Loss: 0.3906 Acc: 0.8221 | Val Loss: 0.3657 Acc: 0.8327\n",
      "Epoch 011 | Train Loss: 0.3645 Acc: 0.8386 | Val Loss: 0.3889 Acc: 0.8134\n",
      "Epoch 012 | Train Loss: 0.3531 Acc: 0.8445 | Val Loss: 0.3440 Acc: 0.8508\n",
      "Epoch 013 | Train Loss: 0.3187 Acc: 0.8628 | Val Loss: 0.2901 Acc: 0.8744\n",
      "Epoch 014 | Train Loss: 0.3030 Acc: 0.8745 | Val Loss: 0.2863 Acc: 0.8816\n",
      "Epoch 015 | Train Loss: 0.2690 Acc: 0.8869 | Val Loss: 0.2600 Acc: 0.8919\n",
      "Epoch 016 | Train Loss: 0.2580 Acc: 0.8976 | Val Loss: 0.2484 Acc: 0.8979\n",
      "Epoch 017 | Train Loss: 0.2447 Acc: 0.8985 | Val Loss: 0.2426 Acc: 0.9010\n",
      "Epoch 018 | Train Loss: 0.2215 Acc: 0.9123 | Val Loss: 0.2405 Acc: 0.8986\n",
      "Epoch 019 | Train Loss: 0.2134 Acc: 0.9118 | Val Loss: 0.2177 Acc: 0.9100\n",
      "Epoch 020 | Train Loss: 0.1952 Acc: 0.9186 | Val Loss: 0.2073 Acc: 0.9124\n",
      "Epoch 021 | Train Loss: 0.1819 Acc: 0.9272 | Val Loss: 0.2231 Acc: 0.9046\n",
      "Epoch 022 | Train Loss: 0.1803 Acc: 0.9283 | Val Loss: 0.1879 Acc: 0.9221\n",
      "Epoch 023 | Train Loss: 0.1623 Acc: 0.9348 | Val Loss: 0.1982 Acc: 0.9239\n",
      "Epoch 024 | Train Loss: 0.1606 Acc: 0.9385 | Val Loss: 0.1843 Acc: 0.9287\n",
      "Epoch 025 | Train Loss: 0.1464 Acc: 0.9425 | Val Loss: 0.2021 Acc: 0.9203\n",
      "Epoch 026 | Train Loss: 0.1370 Acc: 0.9465 | Val Loss: 0.1955 Acc: 0.9251\n",
      "Epoch 027 | Train Loss: 0.1358 Acc: 0.9464 | Val Loss: 0.1954 Acc: 0.9263\n",
      "Epoch 028 | Train Loss: 0.1189 Acc: 0.9562 | Val Loss: 0.1704 Acc: 0.9330\n",
      "Epoch 029 | Train Loss: 0.1219 Acc: 0.9514 | Val Loss: 0.2242 Acc: 0.9209\n",
      "Epoch 030 | Train Loss: 0.1246 Acc: 0.9533 | Val Loss: 0.1857 Acc: 0.9275\n",
      "Epoch 031 | Train Loss: 0.1200 Acc: 0.9535 | Val Loss: 0.1762 Acc: 0.9281\n",
      "Epoch 032 | Train Loss: 0.1077 Acc: 0.9576 | Val Loss: 0.2033 Acc: 0.9269\n",
      "Epoch 033 | Train Loss: 0.1082 Acc: 0.9577 | Val Loss: 0.1780 Acc: 0.9263\n",
      "Epoch 034 | Train Loss: 0.1054 Acc: 0.9571 | Val Loss: 0.1585 Acc: 0.9384\n",
      "Epoch 035 | Train Loss: 0.0963 Acc: 0.9612 | Val Loss: 0.1685 Acc: 0.9330\n",
      "Epoch 036 | Train Loss: 0.0989 Acc: 0.9635 | Val Loss: 0.1734 Acc: 0.9372\n",
      "Epoch 037 | Train Loss: 0.0998 Acc: 0.9609 | Val Loss: 0.1524 Acc: 0.9390\n",
      "Epoch 038 | Train Loss: 0.0962 Acc: 0.9635 | Val Loss: 0.1667 Acc: 0.9420\n",
      "Epoch 039 | Train Loss: 0.0812 Acc: 0.9698 | Val Loss: 0.1534 Acc: 0.9414\n",
      "Epoch 040 | Train Loss: 0.0820 Acc: 0.9690 | Val Loss: 0.1561 Acc: 0.9390\n",
      "Epoch 041 | Train Loss: 0.0832 Acc: 0.9700 | Val Loss: 0.1738 Acc: 0.9378\n",
      "Epoch 042 | Train Loss: 0.0787 Acc: 0.9700 | Val Loss: 0.1660 Acc: 0.9402\n",
      "Epoch 043 | Train Loss: 0.0786 Acc: 0.9695 | Val Loss: 0.1755 Acc: 0.9342\n",
      "Epoch 044 | Train Loss: 0.0728 Acc: 0.9727 | Val Loss: 0.1866 Acc: 0.9396\n",
      "Epoch 045 | Train Loss: 0.0764 Acc: 0.9719 | Val Loss: 0.1746 Acc: 0.9360\n",
      "Epoch 046 | Train Loss: 0.0779 Acc: 0.9698 | Val Loss: 0.1472 Acc: 0.9438\n",
      "Epoch 047 | Train Loss: 0.0690 Acc: 0.9740 | Val Loss: 0.1677 Acc: 0.9396\n",
      "Epoch 048 | Train Loss: 0.0719 Acc: 0.9719 | Val Loss: 0.1522 Acc: 0.9450\n",
      "Epoch 049 | Train Loss: 0.0679 Acc: 0.9760 | Val Loss: 0.1497 Acc: 0.9493\n",
      "Epoch 050 | Train Loss: 0.0706 Acc: 0.9742 | Val Loss: 0.1298 Acc: 0.9499\n",
      "Epoch 051 | Train Loss: 0.0605 Acc: 0.9781 | Val Loss: 0.1228 Acc: 0.9547\n",
      "Epoch 052 | Train Loss: 0.0639 Acc: 0.9764 | Val Loss: 0.1766 Acc: 0.9414\n",
      "Epoch 053 | Train Loss: 0.0674 Acc: 0.9760 | Val Loss: 0.1764 Acc: 0.9420\n",
      "Epoch 054 | Train Loss: 0.0647 Acc: 0.9792 | Val Loss: 0.1494 Acc: 0.9469\n",
      "Epoch 055 | Train Loss: 0.0619 Acc: 0.9769 | Val Loss: 0.1444 Acc: 0.9487\n",
      "Epoch 056 | Train Loss: 0.0629 Acc: 0.9761 | Val Loss: 0.1450 Acc: 0.9499\n",
      "Epoch 057 | Train Loss: 0.0581 Acc: 0.9801 | Val Loss: 0.1578 Acc: 0.9432\n",
      "Epoch 058 | Train Loss: 0.0550 Acc: 0.9793 | Val Loss: 0.1245 Acc: 0.9517\n",
      "Epoch 059 | Train Loss: 0.0474 Acc: 0.9837 | Val Loss: 0.1510 Acc: 0.9535\n",
      "Epoch 060 | Train Loss: 0.0749 Acc: 0.9751 | Val Loss: 0.1496 Acc: 0.9463\n",
      "Epoch 001 | Train Loss: 0.6783 Acc: 0.5834 | Val Loss: 0.6764 Acc: 0.5767\n",
      "Epoch 002 | Train Loss: 0.6389 Acc: 0.6375 | Val Loss: 0.6208 Acc: 0.6751\n",
      "Epoch 003 | Train Loss: 0.5819 Acc: 0.7086 | Val Loss: 0.5749 Acc: 0.7114\n",
      "Epoch 004 | Train Loss: 0.5480 Acc: 0.7320 | Val Loss: 0.5394 Acc: 0.7283\n",
      "Epoch 005 | Train Loss: 0.5213 Acc: 0.7453 | Val Loss: 0.5439 Acc: 0.7240\n",
      "Epoch 006 | Train Loss: 0.4899 Acc: 0.7617 | Val Loss: 0.4683 Acc: 0.7808\n",
      "Epoch 007 | Train Loss: 0.4422 Acc: 0.7909 | Val Loss: 0.4499 Acc: 0.7905\n",
      "Epoch 008 | Train Loss: 0.3992 Acc: 0.8209 | Val Loss: 0.3837 Acc: 0.8219\n",
      "Epoch 009 | Train Loss: 0.3585 Acc: 0.8347 | Val Loss: 0.4010 Acc: 0.8074\n",
      "Epoch 010 | Train Loss: 0.3227 Acc: 0.8631 | Val Loss: 0.3375 Acc: 0.8557\n",
      "Epoch 011 | Train Loss: 0.2927 Acc: 0.8795 | Val Loss: 0.3093 Acc: 0.8720\n",
      "Epoch 012 | Train Loss: 0.2692 Acc: 0.8846 | Val Loss: 0.2670 Acc: 0.8792\n",
      "Epoch 013 | Train Loss: 0.2250 Acc: 0.9022 | Val Loss: 0.2662 Acc: 0.8925\n",
      "Epoch 014 | Train Loss: 0.2041 Acc: 0.9179 | Val Loss: 0.2831 Acc: 0.8907\n",
      "Epoch 015 | Train Loss: 0.1877 Acc: 0.9257 | Val Loss: 0.2342 Acc: 0.9028\n",
      "Epoch 016 | Train Loss: 0.1842 Acc: 0.9256 | Val Loss: 0.3052 Acc: 0.8774\n",
      "Epoch 017 | Train Loss: 0.1661 Acc: 0.9364 | Val Loss: 0.2349 Acc: 0.9106\n",
      "Epoch 018 | Train Loss: 0.1602 Acc: 0.9360 | Val Loss: 0.2421 Acc: 0.9064\n",
      "Epoch 019 | Train Loss: 0.1434 Acc: 0.9449 | Val Loss: 0.2265 Acc: 0.9130\n",
      "Epoch 020 | Train Loss: 0.1469 Acc: 0.9425 | Val Loss: 0.2472 Acc: 0.9028\n",
      "Epoch 021 | Train Loss: 0.1322 Acc: 0.9467 | Val Loss: 0.2369 Acc: 0.9130\n",
      "Epoch 022 | Train Loss: 0.1165 Acc: 0.9564 | Val Loss: 0.1981 Acc: 0.9245\n",
      "Epoch 023 | Train Loss: 0.1284 Acc: 0.9491 | Val Loss: 0.1895 Acc: 0.9215\n",
      "Epoch 024 | Train Loss: 0.1174 Acc: 0.9570 | Val Loss: 0.1748 Acc: 0.9227\n",
      "Epoch 025 | Train Loss: 0.1062 Acc: 0.9607 | Val Loss: 0.1820 Acc: 0.9227\n",
      "Epoch 026 | Train Loss: 0.1034 Acc: 0.9636 | Val Loss: 0.1645 Acc: 0.9269\n",
      "Epoch 027 | Train Loss: 0.0911 Acc: 0.9651 | Val Loss: 0.1739 Acc: 0.9360\n",
      "Epoch 028 | Train Loss: 0.0866 Acc: 0.9672 | Val Loss: 0.2090 Acc: 0.9281\n",
      "Epoch 029 | Train Loss: 0.0837 Acc: 0.9698 | Val Loss: 0.1895 Acc: 0.9312\n",
      "Epoch 030 | Train Loss: 0.0909 Acc: 0.9638 | Val Loss: 0.2156 Acc: 0.9155\n",
      "Epoch 031 | Train Loss: 0.0828 Acc: 0.9695 | Val Loss: 0.2267 Acc: 0.9197\n",
      "Epoch 032 | Train Loss: 0.0809 Acc: 0.9709 | Val Loss: 0.1616 Acc: 0.9366\n",
      "Epoch 033 | Train Loss: 0.0814 Acc: 0.9698 | Val Loss: 0.2426 Acc: 0.9293\n",
      "Epoch 034 | Train Loss: 0.0677 Acc: 0.9748 | Val Loss: 0.2271 Acc: 0.9161\n",
      "Epoch 035 | Train Loss: 0.0709 Acc: 0.9746 | Val Loss: 0.1985 Acc: 0.9306\n",
      "Epoch 036 | Train Loss: 0.0631 Acc: 0.9769 | Val Loss: 0.2150 Acc: 0.9300\n",
      "Epoch 037 | Train Loss: 0.0666 Acc: 0.9770 | Val Loss: 0.2101 Acc: 0.9300\n",
      "Epoch 038 | Train Loss: 0.0640 Acc: 0.9749 | Val Loss: 0.2434 Acc: 0.9239\n",
      "Epoch 039 | Train Loss: 0.0565 Acc: 0.9783 | Val Loss: 0.2232 Acc: 0.9269\n",
      "Epoch 040 | Train Loss: 0.0673 Acc: 0.9757 | Val Loss: 0.1909 Acc: 0.9306\n",
      "Epoch 041 | Train Loss: 0.0587 Acc: 0.9802 | Val Loss: 0.2273 Acc: 0.9161\n",
      "Epoch 042 | Train Loss: 0.0644 Acc: 0.9763 | Val Loss: 0.2127 Acc: 0.9300\n",
      "Early stopping triggered.\n",
      "Epoch 001 | Train Loss: 0.6826 Acc: 0.5768 | Val Loss: 0.6879 Acc: 0.5586\n",
      "Epoch 002 | Train Loss: 0.6836 Acc: 0.5777 | Val Loss: 0.6786 Acc: 0.5821\n",
      "Epoch 003 | Train Loss: 0.6636 Acc: 0.6037 | Val Loss: 0.6697 Acc: 0.5870\n",
      "Epoch 004 | Train Loss: 0.6532 Acc: 0.6236 | Val Loss: 0.6480 Acc: 0.6135\n",
      "Epoch 005 | Train Loss: 0.6099 Acc: 0.6829 | Val Loss: 0.6001 Acc: 0.6914\n",
      "Epoch 006 | Train Loss: 0.5707 Acc: 0.7173 | Val Loss: 0.5603 Acc: 0.7162\n",
      "Epoch 007 | Train Loss: 0.5412 Acc: 0.7395 | Val Loss: 0.5398 Acc: 0.7228\n",
      "Epoch 008 | Train Loss: 0.5261 Acc: 0.7457 | Val Loss: 0.5274 Acc: 0.7434\n",
      "Epoch 009 | Train Loss: 0.4989 Acc: 0.7629 | Val Loss: 0.5120 Acc: 0.7470\n",
      "Epoch 010 | Train Loss: 0.4725 Acc: 0.7762 | Val Loss: 0.4751 Acc: 0.7711\n",
      "Epoch 011 | Train Loss: 0.4501 Acc: 0.7864 | Val Loss: 0.4457 Acc: 0.7917\n",
      "Epoch 012 | Train Loss: 0.4325 Acc: 0.7948 | Val Loss: 0.4417 Acc: 0.7862\n",
      "Epoch 013 | Train Loss: 0.4236 Acc: 0.8054 | Val Loss: 0.3960 Acc: 0.8243\n",
      "Epoch 014 | Train Loss: 0.3810 Acc: 0.8258 | Val Loss: 0.3891 Acc: 0.8315\n",
      "Epoch 015 | Train Loss: 0.3688 Acc: 0.8348 | Val Loss: 0.3543 Acc: 0.8400\n",
      "Epoch 016 | Train Loss: 0.3444 Acc: 0.8507 | Val Loss: 0.3293 Acc: 0.8521\n",
      "Epoch 017 | Train Loss: 0.3228 Acc: 0.8579 | Val Loss: 0.3529 Acc: 0.8388\n",
      "Epoch 018 | Train Loss: 0.3041 Acc: 0.8738 | Val Loss: 0.3136 Acc: 0.8653\n",
      "Epoch 019 | Train Loss: 0.2819 Acc: 0.8822 | Val Loss: 0.2752 Acc: 0.8853\n",
      "Epoch 020 | Train Loss: 0.2673 Acc: 0.8865 | Val Loss: 0.2633 Acc: 0.8841\n",
      "Epoch 021 | Train Loss: 0.2453 Acc: 0.8967 | Val Loss: 0.2560 Acc: 0.8943\n",
      "Epoch 022 | Train Loss: 0.2402 Acc: 0.9020 | Val Loss: 0.2498 Acc: 0.8998\n",
      "Epoch 023 | Train Loss: 0.2201 Acc: 0.9126 | Val Loss: 0.2418 Acc: 0.9016\n",
      "Epoch 024 | Train Loss: 0.2384 Acc: 0.9011 | Val Loss: 0.2245 Acc: 0.9100\n",
      "Epoch 025 | Train Loss: 0.2078 Acc: 0.9164 | Val Loss: 0.2194 Acc: 0.9088\n",
      "Epoch 026 | Train Loss: 0.1849 Acc: 0.9277 | Val Loss: 0.2513 Acc: 0.9016\n",
      "Epoch 027 | Train Loss: 0.1896 Acc: 0.9230 | Val Loss: 0.2209 Acc: 0.9082\n",
      "Epoch 028 | Train Loss: 0.1757 Acc: 0.9325 | Val Loss: 0.1996 Acc: 0.9215\n",
      "Epoch 029 | Train Loss: 0.1676 Acc: 0.9358 | Val Loss: 0.2197 Acc: 0.9155\n",
      "Epoch 030 | Train Loss: 0.1554 Acc: 0.9411 | Val Loss: 0.2649 Acc: 0.8919\n",
      "Epoch 031 | Train Loss: 0.1539 Acc: 0.9413 | Val Loss: 0.2123 Acc: 0.9167\n",
      "Epoch 032 | Train Loss: 0.1442 Acc: 0.9432 | Val Loss: 0.1804 Acc: 0.9245\n",
      "Epoch 033 | Train Loss: 0.1472 Acc: 0.9452 | Val Loss: 0.1952 Acc: 0.9239\n",
      "Epoch 034 | Train Loss: 0.1397 Acc: 0.9435 | Val Loss: 0.1944 Acc: 0.9215\n",
      "Epoch 035 | Train Loss: 0.1364 Acc: 0.9479 | Val Loss: 0.1833 Acc: 0.9318\n",
      "Epoch 036 | Train Loss: 0.1294 Acc: 0.9496 | Val Loss: 0.1799 Acc: 0.9318\n",
      "Epoch 037 | Train Loss: 0.1244 Acc: 0.9514 | Val Loss: 0.1606 Acc: 0.9414\n",
      "Epoch 038 | Train Loss: 0.1153 Acc: 0.9550 | Val Loss: 0.1792 Acc: 0.9300\n",
      "Epoch 039 | Train Loss: 0.1098 Acc: 0.9594 | Val Loss: 0.2221 Acc: 0.9143\n",
      "Epoch 040 | Train Loss: 0.1126 Acc: 0.9583 | Val Loss: 0.1931 Acc: 0.9281\n",
      "Epoch 041 | Train Loss: 0.1034 Acc: 0.9616 | Val Loss: 0.1722 Acc: 0.9390\n",
      "Epoch 042 | Train Loss: 0.0960 Acc: 0.9654 | Val Loss: 0.1896 Acc: 0.9318\n",
      "Epoch 043 | Train Loss: 0.0938 Acc: 0.9642 | Val Loss: 0.2004 Acc: 0.9330\n",
      "Epoch 044 | Train Loss: 0.0923 Acc: 0.9632 | Val Loss: 0.1649 Acc: 0.9378\n",
      "Epoch 045 | Train Loss: 0.1061 Acc: 0.9594 | Val Loss: 0.1562 Acc: 0.9384\n",
      "Epoch 046 | Train Loss: 0.0843 Acc: 0.9681 | Val Loss: 0.1767 Acc: 0.9342\n",
      "Epoch 047 | Train Loss: 0.0875 Acc: 0.9675 | Val Loss: 0.1538 Acc: 0.9469\n",
      "Epoch 048 | Train Loss: 0.0925 Acc: 0.9650 | Val Loss: 0.1578 Acc: 0.9372\n",
      "Epoch 049 | Train Loss: 0.0760 Acc: 0.9739 | Val Loss: 0.1597 Acc: 0.9432\n",
      "Epoch 050 | Train Loss: 0.0810 Acc: 0.9716 | Val Loss: 0.1417 Acc: 0.9450\n",
      "Epoch 051 | Train Loss: 0.0759 Acc: 0.9731 | Val Loss: 0.1500 Acc: 0.9481\n",
      "Epoch 052 | Train Loss: 0.0912 Acc: 0.9663 | Val Loss: 0.1725 Acc: 0.9420\n",
      "Epoch 053 | Train Loss: 0.0771 Acc: 0.9715 | Val Loss: 0.1677 Acc: 0.9384\n",
      "Epoch 054 | Train Loss: 0.0774 Acc: 0.9724 | Val Loss: 0.1487 Acc: 0.9475\n",
      "Epoch 055 | Train Loss: 0.0654 Acc: 0.9774 | Val Loss: 0.1724 Acc: 0.9348\n",
      "Epoch 056 | Train Loss: 0.0661 Acc: 0.9754 | Val Loss: 0.1589 Acc: 0.9450\n",
      "Epoch 057 | Train Loss: 0.0610 Acc: 0.9786 | Val Loss: 0.1705 Acc: 0.9390\n",
      "Epoch 058 | Train Loss: 0.0702 Acc: 0.9737 | Val Loss: 0.1914 Acc: 0.9420\n",
      "Epoch 059 | Train Loss: 0.0687 Acc: 0.9739 | Val Loss: 0.1817 Acc: 0.9372\n",
      "Epoch 060 | Train Loss: 0.0666 Acc: 0.9751 | Val Loss: 0.1763 Acc: 0.9414\n",
      "Early stopping triggered.\n",
      "Epoch 001 | Train Loss: 0.6801 Acc: 0.5822 | Val Loss: 0.6743 Acc: 0.5930\n",
      "Epoch 002 | Train Loss: 0.6699 Acc: 0.5976 | Val Loss: 0.6754 Acc: 0.6063\n",
      "Epoch 003 | Train Loss: 0.6550 Acc: 0.6248 | Val Loss: 0.6301 Acc: 0.6479\n",
      "Epoch 004 | Train Loss: 0.6204 Acc: 0.6689 | Val Loss: 0.5927 Acc: 0.6908\n",
      "Epoch 005 | Train Loss: 0.5920 Acc: 0.6971 | Val Loss: 0.5719 Acc: 0.7101\n",
      "Epoch 006 | Train Loss: 0.5617 Acc: 0.7202 | Val Loss: 0.5478 Acc: 0.7240\n",
      "Epoch 007 | Train Loss: 0.5421 Acc: 0.7340 | Val Loss: 0.5414 Acc: 0.7283\n",
      "Epoch 008 | Train Loss: 0.5181 Acc: 0.7459 | Val Loss: 0.5088 Acc: 0.7470\n",
      "Epoch 009 | Train Loss: 0.5053 Acc: 0.7518 | Val Loss: 0.4988 Acc: 0.7470\n",
      "Epoch 010 | Train Loss: 0.4922 Acc: 0.7655 | Val Loss: 0.5566 Acc: 0.7343\n",
      "Epoch 011 | Train Loss: 0.4803 Acc: 0.7741 | Val Loss: 0.4874 Acc: 0.7669\n",
      "Epoch 012 | Train Loss: 0.4547 Acc: 0.7883 | Val Loss: 0.4510 Acc: 0.7820\n",
      "Epoch 013 | Train Loss: 0.4588 Acc: 0.7901 | Val Loss: 0.4361 Acc: 0.7959\n",
      "Epoch 014 | Train Loss: 0.4283 Acc: 0.8048 | Val Loss: 0.4527 Acc: 0.7893\n",
      "Epoch 015 | Train Loss: 0.4227 Acc: 0.8058 | Val Loss: 0.3980 Acc: 0.8068\n",
      "Epoch 016 | Train Loss: 0.3838 Acc: 0.8212 | Val Loss: 0.3905 Acc: 0.8116\n",
      "Epoch 017 | Train Loss: 0.3726 Acc: 0.8276 | Val Loss: 0.3721 Acc: 0.8207\n",
      "Epoch 018 | Train Loss: 0.3610 Acc: 0.8372 | Val Loss: 0.3506 Acc: 0.8351\n",
      "Epoch 019 | Train Loss: 0.3460 Acc: 0.8431 | Val Loss: 0.3199 Acc: 0.8569\n",
      "Epoch 020 | Train Loss: 0.3378 Acc: 0.8496 | Val Loss: 0.3277 Acc: 0.8521\n",
      "Epoch 021 | Train Loss: 0.3152 Acc: 0.8612 | Val Loss: 0.3490 Acc: 0.8412\n",
      "Epoch 022 | Train Loss: 0.3006 Acc: 0.8711 | Val Loss: 0.2874 Acc: 0.8732\n",
      "Epoch 023 | Train Loss: 0.2861 Acc: 0.8795 | Val Loss: 0.2994 Acc: 0.8678\n",
      "Epoch 024 | Train Loss: 0.2912 Acc: 0.8745 | Val Loss: 0.2958 Acc: 0.8665\n",
      "Epoch 025 | Train Loss: 0.2610 Acc: 0.8902 | Val Loss: 0.2567 Acc: 0.8877\n",
      "Epoch 026 | Train Loss: 0.2612 Acc: 0.8916 | Val Loss: 0.2399 Acc: 0.8967\n",
      "Epoch 027 | Train Loss: 0.2367 Acc: 0.9008 | Val Loss: 0.2321 Acc: 0.9028\n",
      "Epoch 028 | Train Loss: 0.2188 Acc: 0.9083 | Val Loss: 0.2525 Acc: 0.8937\n",
      "Epoch 029 | Train Loss: 0.2254 Acc: 0.9105 | Val Loss: 0.2313 Acc: 0.9046\n",
      "Epoch 030 | Train Loss: 0.2029 Acc: 0.9171 | Val Loss: 0.2296 Acc: 0.9046\n",
      "Epoch 031 | Train Loss: 0.2039 Acc: 0.9195 | Val Loss: 0.3038 Acc: 0.8768\n",
      "Epoch 032 | Train Loss: 0.1904 Acc: 0.9257 | Val Loss: 0.2387 Acc: 0.9010\n",
      "Epoch 033 | Train Loss: 0.1821 Acc: 0.9308 | Val Loss: 0.2015 Acc: 0.9191\n",
      "Epoch 034 | Train Loss: 0.1712 Acc: 0.9304 | Val Loss: 0.1880 Acc: 0.9233\n",
      "Epoch 035 | Train Loss: 0.1648 Acc: 0.9352 | Val Loss: 0.2324 Acc: 0.9022\n",
      "Epoch 036 | Train Loss: 0.1778 Acc: 0.9292 | Val Loss: 0.1970 Acc: 0.9167\n",
      "Epoch 037 | Train Loss: 0.1580 Acc: 0.9392 | Val Loss: 0.2169 Acc: 0.9082\n",
      "Epoch 038 | Train Loss: 0.1613 Acc: 0.9385 | Val Loss: 0.1984 Acc: 0.9227\n",
      "Epoch 039 | Train Loss: 0.1500 Acc: 0.9405 | Val Loss: 0.1976 Acc: 0.9130\n",
      "Epoch 040 | Train Loss: 0.1353 Acc: 0.9473 | Val Loss: 0.1675 Acc: 0.9360\n",
      "Epoch 041 | Train Loss: 0.1442 Acc: 0.9458 | Val Loss: 0.1856 Acc: 0.9245\n",
      "Epoch 042 | Train Loss: 0.1355 Acc: 0.9458 | Val Loss: 0.2116 Acc: 0.9143\n",
      "Epoch 043 | Train Loss: 0.1226 Acc: 0.9508 | Val Loss: 0.1853 Acc: 0.9318\n",
      "Epoch 044 | Train Loss: 0.1322 Acc: 0.9493 | Val Loss: 0.1711 Acc: 0.9354\n",
      "Epoch 045 | Train Loss: 0.1237 Acc: 0.9523 | Val Loss: 0.1872 Acc: 0.9300\n",
      "Epoch 046 | Train Loss: 0.1291 Acc: 0.9506 | Val Loss: 0.1685 Acc: 0.9390\n",
      "Epoch 047 | Train Loss: 0.1131 Acc: 0.9574 | Val Loss: 0.1633 Acc: 0.9426\n",
      "Epoch 048 | Train Loss: 0.1198 Acc: 0.9553 | Val Loss: 0.1647 Acc: 0.9444\n",
      "Epoch 049 | Train Loss: 0.1107 Acc: 0.9556 | Val Loss: 0.1796 Acc: 0.9360\n",
      "Epoch 050 | Train Loss: 0.1102 Acc: 0.9567 | Val Loss: 0.1606 Acc: 0.9414\n",
      "Epoch 051 | Train Loss: 0.1001 Acc: 0.9624 | Val Loss: 0.1862 Acc: 0.9378\n",
      "Epoch 052 | Train Loss: 0.0974 Acc: 0.9603 | Val Loss: 0.1481 Acc: 0.9487\n",
      "Epoch 053 | Train Loss: 0.0977 Acc: 0.9653 | Val Loss: 0.1521 Acc: 0.9432\n",
      "Epoch 054 | Train Loss: 0.1007 Acc: 0.9642 | Val Loss: 0.2147 Acc: 0.9245\n",
      "Epoch 055 | Train Loss: 0.0988 Acc: 0.9648 | Val Loss: 0.2051 Acc: 0.9263\n",
      "Epoch 056 | Train Loss: 0.0946 Acc: 0.9650 | Val Loss: 0.1681 Acc: 0.9444\n",
      "Epoch 057 | Train Loss: 0.0979 Acc: 0.9624 | Val Loss: 0.1674 Acc: 0.9438\n",
      "Epoch 058 | Train Loss: 0.0927 Acc: 0.9657 | Val Loss: 0.1486 Acc: 0.9444\n",
      "Epoch 059 | Train Loss: 0.0946 Acc: 0.9641 | Val Loss: 0.1505 Acc: 0.9469\n",
      "Epoch 060 | Train Loss: 0.0817 Acc: 0.9701 | Val Loss: 0.1547 Acc: 0.9408\n",
      "Epoch 001 | Train Loss: 0.6818 Acc: 0.5754 | Val Loss: 0.6745 Acc: 0.5888\n",
      "Epoch 002 | Train Loss: 0.6710 Acc: 0.5937 | Val Loss: 0.6612 Acc: 0.6039\n",
      "Epoch 003 | Train Loss: 0.6346 Acc: 0.6450 | Val Loss: 0.6353 Acc: 0.6335\n",
      "Epoch 004 | Train Loss: 0.5986 Acc: 0.6939 | Val Loss: 0.5777 Acc: 0.6944\n",
      "Epoch 005 | Train Loss: 0.5635 Acc: 0.7151 | Val Loss: 0.5544 Acc: 0.7210\n",
      "Epoch 006 | Train Loss: 0.5252 Acc: 0.7456 | Val Loss: 0.5357 Acc: 0.7307\n",
      "Epoch 007 | Train Loss: 0.5124 Acc: 0.7516 | Val Loss: 0.5233 Acc: 0.7379\n",
      "Epoch 008 | Train Loss: 0.4823 Acc: 0.7655 | Val Loss: 0.4793 Acc: 0.7723\n",
      "Epoch 009 | Train Loss: 0.4561 Acc: 0.7856 | Val Loss: 0.4431 Acc: 0.7959\n",
      "Epoch 010 | Train Loss: 0.4341 Acc: 0.7957 | Val Loss: 0.4219 Acc: 0.8037\n",
      "Epoch 011 | Train Loss: 0.4008 Acc: 0.8194 | Val Loss: 0.4034 Acc: 0.8104\n",
      "Epoch 012 | Train Loss: 0.3770 Acc: 0.8312 | Val Loss: 0.3628 Acc: 0.8339\n",
      "Epoch 013 | Train Loss: 0.3574 Acc: 0.8404 | Val Loss: 0.3653 Acc: 0.8357\n",
      "Epoch 014 | Train Loss: 0.3285 Acc: 0.8531 | Val Loss: 0.3311 Acc: 0.8641\n",
      "Epoch 015 | Train Loss: 0.3011 Acc: 0.8708 | Val Loss: 0.2957 Acc: 0.8774\n",
      "Epoch 016 | Train Loss: 0.2771 Acc: 0.8857 | Val Loss: 0.3025 Acc: 0.8684\n",
      "Epoch 017 | Train Loss: 0.2747 Acc: 0.8868 | Val Loss: 0.3019 Acc: 0.8738\n",
      "Epoch 018 | Train Loss: 0.2521 Acc: 0.8960 | Val Loss: 0.2599 Acc: 0.8931\n",
      "Epoch 019 | Train Loss: 0.2365 Acc: 0.9031 | Val Loss: 0.3318 Acc: 0.8605\n",
      "Epoch 020 | Train Loss: 0.2254 Acc: 0.9088 | Val Loss: 0.2573 Acc: 0.8961\n",
      "Epoch 021 | Train Loss: 0.2167 Acc: 0.9127 | Val Loss: 0.2792 Acc: 0.8822\n",
      "Epoch 022 | Train Loss: 0.2031 Acc: 0.9176 | Val Loss: 0.2498 Acc: 0.9004\n",
      "Epoch 023 | Train Loss: 0.1908 Acc: 0.9241 | Val Loss: 0.2428 Acc: 0.9040\n",
      "Epoch 024 | Train Loss: 0.1768 Acc: 0.9311 | Val Loss: 0.2062 Acc: 0.9209\n",
      "Epoch 025 | Train Loss: 0.1763 Acc: 0.9295 | Val Loss: 0.2469 Acc: 0.9022\n",
      "Epoch 026 | Train Loss: 0.1675 Acc: 0.9325 | Val Loss: 0.2386 Acc: 0.9130\n",
      "Epoch 027 | Train Loss: 0.1625 Acc: 0.9373 | Val Loss: 0.2251 Acc: 0.9082\n",
      "Epoch 028 | Train Loss: 0.1550 Acc: 0.9385 | Val Loss: 0.2416 Acc: 0.9064\n",
      "Epoch 029 | Train Loss: 0.1431 Acc: 0.9435 | Val Loss: 0.2452 Acc: 0.9076\n",
      "Epoch 030 | Train Loss: 0.1452 Acc: 0.9435 | Val Loss: 0.2096 Acc: 0.9203\n",
      "Epoch 031 | Train Loss: 0.1358 Acc: 0.9453 | Val Loss: 0.2049 Acc: 0.9227\n",
      "Epoch 032 | Train Loss: 0.1383 Acc: 0.9443 | Val Loss: 0.1777 Acc: 0.9378\n",
      "Epoch 033 | Train Loss: 0.1256 Acc: 0.9533 | Val Loss: 0.1902 Acc: 0.9263\n",
      "Epoch 034 | Train Loss: 0.1230 Acc: 0.9520 | Val Loss: 0.1911 Acc: 0.9287\n",
      "Epoch 035 | Train Loss: 0.1100 Acc: 0.9594 | Val Loss: 0.2198 Acc: 0.9185\n",
      "Epoch 036 | Train Loss: 0.1187 Acc: 0.9570 | Val Loss: 0.2107 Acc: 0.9215\n",
      "Epoch 037 | Train Loss: 0.0945 Acc: 0.9627 | Val Loss: 0.2099 Acc: 0.9209\n",
      "Epoch 038 | Train Loss: 0.1093 Acc: 0.9595 | Val Loss: 0.1753 Acc: 0.9432\n",
      "Epoch 039 | Train Loss: 0.1119 Acc: 0.9603 | Val Loss: 0.1637 Acc: 0.9330\n",
      "Epoch 040 | Train Loss: 0.0983 Acc: 0.9612 | Val Loss: 0.1649 Acc: 0.9384\n",
      "Epoch 041 | Train Loss: 0.1003 Acc: 0.9632 | Val Loss: 0.1665 Acc: 0.9342\n",
      "Epoch 042 | Train Loss: 0.0971 Acc: 0.9635 | Val Loss: 0.1927 Acc: 0.9221\n",
      "Epoch 043 | Train Loss: 0.0993 Acc: 0.9639 | Val Loss: 0.1887 Acc: 0.9396\n",
      "Epoch 044 | Train Loss: 0.0929 Acc: 0.9648 | Val Loss: 0.1836 Acc: 0.9414\n",
      "Epoch 045 | Train Loss: 0.0861 Acc: 0.9703 | Val Loss: 0.1752 Acc: 0.9336\n",
      "Epoch 046 | Train Loss: 0.0898 Acc: 0.9668 | Val Loss: 0.1756 Acc: 0.9300\n",
      "Epoch 047 | Train Loss: 0.0752 Acc: 0.9725 | Val Loss: 0.1862 Acc: 0.9312\n",
      "Epoch 048 | Train Loss: 0.0935 Acc: 0.9663 | Val Loss: 0.1545 Acc: 0.9426\n",
      "Epoch 049 | Train Loss: 0.0804 Acc: 0.9712 | Val Loss: 0.1726 Acc: 0.9432\n",
      "Epoch 050 | Train Loss: 0.0817 Acc: 0.9704 | Val Loss: 0.1348 Acc: 0.9420\n",
      "Epoch 051 | Train Loss: 0.0685 Acc: 0.9734 | Val Loss: 0.2072 Acc: 0.9360\n",
      "Epoch 052 | Train Loss: 0.0752 Acc: 0.9721 | Val Loss: 0.1846 Acc: 0.9348\n",
      "Epoch 053 | Train Loss: 0.0659 Acc: 0.9755 | Val Loss: 0.1772 Acc: 0.9426\n",
      "Epoch 054 | Train Loss: 0.0724 Acc: 0.9755 | Val Loss: 0.1613 Acc: 0.9408\n",
      "Epoch 055 | Train Loss: 0.0712 Acc: 0.9754 | Val Loss: 0.1578 Acc: 0.9463\n",
      "Epoch 056 | Train Loss: 0.0669 Acc: 0.9760 | Val Loss: 0.1420 Acc: 0.9487\n",
      "Epoch 057 | Train Loss: 0.0701 Acc: 0.9745 | Val Loss: 0.1301 Acc: 0.9535\n",
      "Epoch 058 | Train Loss: 0.0632 Acc: 0.9789 | Val Loss: 0.1482 Acc: 0.9511\n",
      "Epoch 059 | Train Loss: 0.0625 Acc: 0.9778 | Val Loss: 0.1522 Acc: 0.9457\n",
      "Epoch 060 | Train Loss: 0.0682 Acc: 0.9758 | Val Loss: 0.1708 Acc: 0.9366\n",
      "Epoch 001 | Train Loss: 0.6875 Acc: 0.5454 | Val Loss: 0.6816 Acc: 0.5725\n",
      "Epoch 002 | Train Loss: 0.6787 Acc: 0.5830 | Val Loss: 0.6772 Acc: 0.5870\n",
      "Epoch 003 | Train Loss: 0.6754 Acc: 0.5914 | Val Loss: 0.6754 Acc: 0.5906\n",
      "Epoch 004 | Train Loss: 0.6736 Acc: 0.5952 | Val Loss: 0.6745 Acc: 0.5894\n",
      "Epoch 005 | Train Loss: 0.6705 Acc: 0.5967 | Val Loss: 0.6728 Acc: 0.5960\n",
      "Epoch 006 | Train Loss: 0.6660 Acc: 0.6026 | Val Loss: 0.6657 Acc: 0.5942\n",
      "Epoch 007 | Train Loss: 0.6585 Acc: 0.6100 | Val Loss: 0.6572 Acc: 0.6014\n",
      "Epoch 008 | Train Loss: 0.6500 Acc: 0.6236 | Val Loss: 0.6657 Acc: 0.5906\n",
      "Epoch 009 | Train Loss: 0.6382 Acc: 0.6450 | Val Loss: 0.6546 Acc: 0.6045\n",
      "Epoch 010 | Train Loss: 0.6235 Acc: 0.6642 | Val Loss: 0.6169 Acc: 0.6806\n",
      "Epoch 011 | Train Loss: 0.6152 Acc: 0.6734 | Val Loss: 0.6069 Acc: 0.6818\n",
      "Epoch 012 | Train Loss: 0.6113 Acc: 0.6781 | Val Loss: 0.6249 Acc: 0.6636\n",
      "Epoch 013 | Train Loss: 0.6067 Acc: 0.6844 | Val Loss: 0.6021 Acc: 0.6957\n",
      "Epoch 014 | Train Loss: 0.6051 Acc: 0.6804 | Val Loss: 0.5934 Acc: 0.6932\n",
      "Epoch 015 | Train Loss: 0.5924 Acc: 0.6961 | Val Loss: 0.5881 Acc: 0.6926\n",
      "Epoch 016 | Train Loss: 0.5876 Acc: 0.6985 | Val Loss: 0.5829 Acc: 0.7059\n",
      "Epoch 017 | Train Loss: 0.5827 Acc: 0.7022 | Val Loss: 0.5766 Acc: 0.7071\n",
      "Epoch 018 | Train Loss: 0.5820 Acc: 0.7059 | Val Loss: 0.5759 Acc: 0.7107\n",
      "Epoch 019 | Train Loss: 0.5721 Acc: 0.7125 | Val Loss: 0.5764 Acc: 0.7089\n",
      "Epoch 020 | Train Loss: 0.5743 Acc: 0.7133 | Val Loss: 0.5782 Acc: 0.7126\n",
      "Epoch 021 | Train Loss: 0.5732 Acc: 0.7115 | Val Loss: 0.5667 Acc: 0.7168\n",
      "Epoch 022 | Train Loss: 0.5591 Acc: 0.7254 | Val Loss: 0.5629 Acc: 0.7180\n",
      "Epoch 023 | Train Loss: 0.5564 Acc: 0.7254 | Val Loss: 0.5649 Acc: 0.7174\n",
      "Epoch 024 | Train Loss: 0.5588 Acc: 0.7261 | Val Loss: 0.5684 Acc: 0.7156\n",
      "Epoch 025 | Train Loss: 0.5473 Acc: 0.7276 | Val Loss: 0.5567 Acc: 0.7168\n",
      "Epoch 026 | Train Loss: 0.5521 Acc: 0.7288 | Val Loss: 0.5577 Acc: 0.7180\n",
      "Epoch 027 | Train Loss: 0.5523 Acc: 0.7266 | Val Loss: 0.5673 Acc: 0.7126\n",
      "Epoch 028 | Train Loss: 0.5545 Acc: 0.7211 | Val Loss: 0.5591 Acc: 0.7216\n",
      "Epoch 029 | Train Loss: 0.5421 Acc: 0.7392 | Val Loss: 0.5528 Acc: 0.7234\n",
      "Epoch 030 | Train Loss: 0.5463 Acc: 0.7350 | Val Loss: 0.5642 Acc: 0.7132\n",
      "Epoch 031 | Train Loss: 0.5414 Acc: 0.7365 | Val Loss: 0.5583 Acc: 0.7180\n",
      "Epoch 032 | Train Loss: 0.5369 Acc: 0.7367 | Val Loss: 0.5471 Acc: 0.7258\n",
      "Epoch 033 | Train Loss: 0.5354 Acc: 0.7427 | Val Loss: 0.5460 Acc: 0.7295\n",
      "Epoch 034 | Train Loss: 0.5313 Acc: 0.7421 | Val Loss: 0.5454 Acc: 0.7301\n",
      "Epoch 035 | Train Loss: 0.5319 Acc: 0.7382 | Val Loss: 0.5457 Acc: 0.7216\n",
      "Epoch 036 | Train Loss: 0.5270 Acc: 0.7433 | Val Loss: 0.5587 Acc: 0.7162\n",
      "Epoch 037 | Train Loss: 0.5249 Acc: 0.7480 | Val Loss: 0.5416 Acc: 0.7228\n",
      "Epoch 038 | Train Loss: 0.5199 Acc: 0.7463 | Val Loss: 0.5450 Acc: 0.7295\n",
      "Epoch 039 | Train Loss: 0.5294 Acc: 0.7406 | Val Loss: 0.5382 Acc: 0.7307\n",
      "Epoch 040 | Train Loss: 0.5194 Acc: 0.7491 | Val Loss: 0.5323 Acc: 0.7313\n",
      "Epoch 041 | Train Loss: 0.5186 Acc: 0.7483 | Val Loss: 0.5346 Acc: 0.7264\n",
      "Epoch 042 | Train Loss: 0.5153 Acc: 0.7524 | Val Loss: 0.5282 Acc: 0.7319\n",
      "Epoch 043 | Train Loss: 0.5157 Acc: 0.7492 | Val Loss: 0.5355 Acc: 0.7379\n",
      "Epoch 044 | Train Loss: 0.5068 Acc: 0.7590 | Val Loss: 0.5233 Acc: 0.7397\n",
      "Epoch 045 | Train Loss: 0.5076 Acc: 0.7552 | Val Loss: 0.5557 Acc: 0.7156\n",
      "Epoch 046 | Train Loss: 0.5039 Acc: 0.7569 | Val Loss: 0.5250 Acc: 0.7361\n",
      "Epoch 047 | Train Loss: 0.4939 Acc: 0.7598 | Val Loss: 0.5332 Acc: 0.7295\n",
      "Epoch 048 | Train Loss: 0.4942 Acc: 0.7628 | Val Loss: 0.5139 Acc: 0.7464\n",
      "Epoch 049 | Train Loss: 0.4969 Acc: 0.7631 | Val Loss: 0.5197 Acc: 0.7421\n",
      "Epoch 050 | Train Loss: 0.4927 Acc: 0.7628 | Val Loss: 0.5097 Acc: 0.7470\n",
      "Epoch 051 | Train Loss: 0.4913 Acc: 0.7679 | Val Loss: 0.5085 Acc: 0.7500\n",
      "Epoch 052 | Train Loss: 0.4868 Acc: 0.7694 | Val Loss: 0.5093 Acc: 0.7452\n",
      "Epoch 053 | Train Loss: 0.4785 Acc: 0.7764 | Val Loss: 0.4981 Acc: 0.7536\n",
      "Epoch 054 | Train Loss: 0.4778 Acc: 0.7764 | Val Loss: 0.4965 Acc: 0.7566\n",
      "Epoch 055 | Train Loss: 0.4740 Acc: 0.7785 | Val Loss: 0.5059 Acc: 0.7482\n",
      "Epoch 056 | Train Loss: 0.4740 Acc: 0.7771 | Val Loss: 0.4971 Acc: 0.7572\n",
      "Epoch 057 | Train Loss: 0.4583 Acc: 0.7844 | Val Loss: 0.4861 Acc: 0.7633\n",
      "Epoch 058 | Train Loss: 0.4585 Acc: 0.7892 | Val Loss: 0.4854 Acc: 0.7669\n",
      "Epoch 059 | Train Loss: 0.4518 Acc: 0.7895 | Val Loss: 0.4826 Acc: 0.7633\n",
      "Epoch 060 | Train Loss: 0.4552 Acc: 0.7859 | Val Loss: 0.4763 Acc: 0.7663\n",
      "Epoch 001 | Train Loss: 0.6798 Acc: 0.5819 | Val Loss: 0.6758 Acc: 0.5894\n",
      "Epoch 002 | Train Loss: 0.6749 Acc: 0.5899 | Val Loss: 0.6737 Acc: 0.5851\n",
      "Epoch 003 | Train Loss: 0.6669 Acc: 0.6015 | Val Loss: 0.6628 Acc: 0.6057\n",
      "Epoch 004 | Train Loss: 0.6437 Acc: 0.6363 | Val Loss: 0.6366 Acc: 0.6540\n",
      "Epoch 005 | Train Loss: 0.6160 Acc: 0.6713 | Val Loss: 0.5955 Acc: 0.6854\n",
      "Epoch 006 | Train Loss: 0.5784 Acc: 0.7051 | Val Loss: 0.5720 Acc: 0.7089\n",
      "Epoch 007 | Train Loss: 0.5638 Acc: 0.7195 | Val Loss: 0.5597 Acc: 0.7168\n",
      "Epoch 008 | Train Loss: 0.5412 Acc: 0.7326 | Val Loss: 0.5483 Acc: 0.7210\n",
      "Epoch 009 | Train Loss: 0.5313 Acc: 0.7404 | Val Loss: 0.5620 Acc: 0.7210\n",
      "Epoch 010 | Train Loss: 0.5067 Acc: 0.7530 | Val Loss: 0.5179 Acc: 0.7391\n",
      "Epoch 011 | Train Loss: 0.4809 Acc: 0.7634 | Val Loss: 0.4928 Acc: 0.7669\n",
      "Epoch 012 | Train Loss: 0.4708 Acc: 0.7720 | Val Loss: 0.4855 Acc: 0.7645\n",
      "Epoch 013 | Train Loss: 0.4571 Acc: 0.7779 | Val Loss: 0.4513 Acc: 0.7862\n",
      "Epoch 014 | Train Loss: 0.4267 Acc: 0.7947 | Val Loss: 0.4271 Acc: 0.8025\n",
      "Epoch 015 | Train Loss: 0.4090 Acc: 0.8111 | Val Loss: 0.4011 Acc: 0.8194\n",
      "Epoch 016 | Train Loss: 0.3952 Acc: 0.8155 | Val Loss: 0.3832 Acc: 0.8285\n",
      "Epoch 017 | Train Loss: 0.3736 Acc: 0.8300 | Val Loss: 0.3888 Acc: 0.8255\n",
      "Epoch 018 | Train Loss: 0.3511 Acc: 0.8412 | Val Loss: 0.4313 Acc: 0.8098\n",
      "Epoch 019 | Train Loss: 0.3431 Acc: 0.8427 | Val Loss: 0.3318 Acc: 0.8587\n",
      "Epoch 020 | Train Loss: 0.3096 Acc: 0.8620 | Val Loss: 0.3330 Acc: 0.8545\n",
      "Epoch 021 | Train Loss: 0.3058 Acc: 0.8641 | Val Loss: 0.3369 Acc: 0.8539\n",
      "Epoch 022 | Train Loss: 0.2822 Acc: 0.8824 | Val Loss: 0.3196 Acc: 0.8659\n",
      "Epoch 023 | Train Loss: 0.2697 Acc: 0.8825 | Val Loss: 0.3134 Acc: 0.8690\n",
      "Epoch 024 | Train Loss: 0.2500 Acc: 0.8919 | Val Loss: 0.2901 Acc: 0.8835\n",
      "Epoch 025 | Train Loss: 0.2352 Acc: 0.9032 | Val Loss: 0.2455 Acc: 0.8967\n",
      "Epoch 026 | Train Loss: 0.2324 Acc: 0.9043 | Val Loss: 0.2346 Acc: 0.9004\n",
      "Epoch 027 | Train Loss: 0.2141 Acc: 0.9103 | Val Loss: 0.2195 Acc: 0.9118\n",
      "Epoch 028 | Train Loss: 0.2016 Acc: 0.9203 | Val Loss: 0.2486 Acc: 0.8973\n",
      "Epoch 029 | Train Loss: 0.1852 Acc: 0.9234 | Val Loss: 0.2480 Acc: 0.8949\n",
      "Epoch 030 | Train Loss: 0.1771 Acc: 0.9269 | Val Loss: 0.2330 Acc: 0.9106\n",
      "Epoch 031 | Train Loss: 0.1746 Acc: 0.9301 | Val Loss: 0.2092 Acc: 0.9185\n",
      "Epoch 032 | Train Loss: 0.1694 Acc: 0.9337 | Val Loss: 0.1872 Acc: 0.9312\n",
      "Epoch 033 | Train Loss: 0.1598 Acc: 0.9363 | Val Loss: 0.2052 Acc: 0.9185\n",
      "Epoch 034 | Train Loss: 0.1454 Acc: 0.9441 | Val Loss: 0.2197 Acc: 0.9179\n",
      "Epoch 035 | Train Loss: 0.1430 Acc: 0.9438 | Val Loss: 0.2036 Acc: 0.9263\n",
      "Epoch 036 | Train Loss: 0.1358 Acc: 0.9476 | Val Loss: 0.1886 Acc: 0.9239\n",
      "Epoch 037 | Train Loss: 0.1216 Acc: 0.9511 | Val Loss: 0.1910 Acc: 0.9300\n",
      "Epoch 038 | Train Loss: 0.1304 Acc: 0.9481 | Val Loss: 0.1739 Acc: 0.9354\n",
      "Epoch 039 | Train Loss: 0.1228 Acc: 0.9535 | Val Loss: 0.1941 Acc: 0.9239\n",
      "Epoch 040 | Train Loss: 0.1225 Acc: 0.9502 | Val Loss: 0.2235 Acc: 0.9203\n",
      "Epoch 041 | Train Loss: 0.1078 Acc: 0.9606 | Val Loss: 0.1919 Acc: 0.9251\n",
      "Epoch 042 | Train Loss: 0.1058 Acc: 0.9604 | Val Loss: 0.2068 Acc: 0.9179\n",
      "Epoch 043 | Train Loss: 0.1040 Acc: 0.9610 | Val Loss: 0.1954 Acc: 0.9287\n",
      "Epoch 044 | Train Loss: 0.0940 Acc: 0.9663 | Val Loss: 0.1718 Acc: 0.9372\n",
      "Epoch 045 | Train Loss: 0.0923 Acc: 0.9657 | Val Loss: 0.1586 Acc: 0.9432\n",
      "Epoch 046 | Train Loss: 0.0824 Acc: 0.9687 | Val Loss: 0.2422 Acc: 0.9203\n",
      "Epoch 047 | Train Loss: 0.0829 Acc: 0.9660 | Val Loss: 0.1474 Acc: 0.9469\n",
      "Epoch 048 | Train Loss: 0.0711 Acc: 0.9748 | Val Loss: 0.1686 Acc: 0.9402\n",
      "Epoch 049 | Train Loss: 0.0771 Acc: 0.9715 | Val Loss: 0.1647 Acc: 0.9384\n",
      "Epoch 050 | Train Loss: 0.0821 Acc: 0.9690 | Val Loss: 0.2146 Acc: 0.9227\n",
      "Epoch 051 | Train Loss: 0.0775 Acc: 0.9697 | Val Loss: 0.1985 Acc: 0.9287\n",
      "Epoch 052 | Train Loss: 0.0660 Acc: 0.9757 | Val Loss: 0.1454 Acc: 0.9463\n",
      "Epoch 053 | Train Loss: 0.0742 Acc: 0.9721 | Val Loss: 0.1403 Acc: 0.9541\n",
      "Epoch 054 | Train Loss: 0.0635 Acc: 0.9777 | Val Loss: 0.1825 Acc: 0.9384\n",
      "Epoch 055 | Train Loss: 0.0659 Acc: 0.9774 | Val Loss: 0.1407 Acc: 0.9517\n",
      "Epoch 056 | Train Loss: 0.0653 Acc: 0.9742 | Val Loss: 0.1512 Acc: 0.9457\n",
      "Epoch 057 | Train Loss: 0.0643 Acc: 0.9778 | Val Loss: 0.1694 Acc: 0.9372\n",
      "Epoch 058 | Train Loss: 0.0611 Acc: 0.9764 | Val Loss: 0.1811 Acc: 0.9432\n",
      "Epoch 059 | Train Loss: 0.0672 Acc: 0.9749 | Val Loss: 0.1368 Acc: 0.9565\n",
      "Epoch 060 | Train Loss: 0.0529 Acc: 0.9801 | Val Loss: 0.2017 Acc: 0.9342\n",
      "Epoch 001 | Train Loss: 0.6808 Acc: 0.5757 | Val Loss: 0.6988 Acc: 0.5598\n",
      "Epoch 002 | Train Loss: 0.6497 Acc: 0.6283 | Val Loss: 0.6296 Acc: 0.6425\n",
      "Epoch 003 | Train Loss: 0.5957 Acc: 0.6962 | Val Loss: 0.5644 Acc: 0.7283\n",
      "Epoch 004 | Train Loss: 0.5597 Acc: 0.7254 | Val Loss: 0.5342 Acc: 0.7391\n",
      "Epoch 005 | Train Loss: 0.5318 Acc: 0.7421 | Val Loss: 0.5113 Acc: 0.7542\n",
      "Epoch 006 | Train Loss: 0.5139 Acc: 0.7542 | Val Loss: 0.5094 Acc: 0.7512\n",
      "Epoch 007 | Train Loss: 0.5063 Acc: 0.7605 | Val Loss: 0.5133 Acc: 0.7488\n",
      "Epoch 008 | Train Loss: 0.4907 Acc: 0.7642 | Val Loss: 0.4750 Acc: 0.7657\n",
      "Epoch 009 | Train Loss: 0.4775 Acc: 0.7728 | Val Loss: 0.4644 Acc: 0.7905\n",
      "Epoch 010 | Train Loss: 0.4441 Acc: 0.7981 | Val Loss: 0.4527 Acc: 0.7675\n",
      "Epoch 011 | Train Loss: 0.4389 Acc: 0.7931 | Val Loss: 0.4549 Acc: 0.7820\n",
      "Epoch 012 | Train Loss: 0.4147 Acc: 0.8162 | Val Loss: 0.4361 Acc: 0.7911\n",
      "Epoch 013 | Train Loss: 0.4087 Acc: 0.8187 | Val Loss: 0.4083 Acc: 0.8225\n",
      "Epoch 014 | Train Loss: 0.3806 Acc: 0.8297 | Val Loss: 0.3466 Acc: 0.8527\n",
      "Epoch 015 | Train Loss: 0.3596 Acc: 0.8434 | Val Loss: 0.3615 Acc: 0.8394\n",
      "Epoch 016 | Train Loss: 0.3594 Acc: 0.8427 | Val Loss: 0.3413 Acc: 0.8557\n",
      "Epoch 017 | Train Loss: 0.3401 Acc: 0.8516 | Val Loss: 0.3771 Acc: 0.8339\n",
      "Epoch 018 | Train Loss: 0.3346 Acc: 0.8532 | Val Loss: 0.3036 Acc: 0.8786\n",
      "Epoch 019 | Train Loss: 0.3081 Acc: 0.8691 | Val Loss: 0.2894 Acc: 0.8792\n",
      "Epoch 020 | Train Loss: 0.3159 Acc: 0.8691 | Val Loss: 0.2888 Acc: 0.8732\n",
      "Epoch 021 | Train Loss: 0.2931 Acc: 0.8827 | Val Loss: 0.2818 Acc: 0.8810\n",
      "Epoch 022 | Train Loss: 0.2931 Acc: 0.8766 | Val Loss: 0.2739 Acc: 0.8943\n",
      "Epoch 023 | Train Loss: 0.2647 Acc: 0.8871 | Val Loss: 0.2588 Acc: 0.8979\n",
      "Epoch 024 | Train Loss: 0.2618 Acc: 0.8851 | Val Loss: 0.2745 Acc: 0.8883\n",
      "Epoch 025 | Train Loss: 0.2578 Acc: 0.8961 | Val Loss: 0.2795 Acc: 0.8810\n",
      "Epoch 026 | Train Loss: 0.2589 Acc: 0.8948 | Val Loss: 0.2503 Acc: 0.8992\n",
      "Epoch 027 | Train Loss: 0.2589 Acc: 0.8936 | Val Loss: 0.2604 Acc: 0.8943\n",
      "Epoch 028 | Train Loss: 0.2381 Acc: 0.9041 | Val Loss: 0.2389 Acc: 0.9022\n",
      "Epoch 029 | Train Loss: 0.2259 Acc: 0.9103 | Val Loss: 0.2265 Acc: 0.9167\n",
      "Epoch 030 | Train Loss: 0.2237 Acc: 0.9079 | Val Loss: 0.2215 Acc: 0.9064\n",
      "Epoch 031 | Train Loss: 0.2246 Acc: 0.9099 | Val Loss: 0.2760 Acc: 0.8937\n",
      "Epoch 032 | Train Loss: 0.2219 Acc: 0.9105 | Val Loss: 0.2344 Acc: 0.9124\n",
      "Epoch 033 | Train Loss: 0.2103 Acc: 0.9126 | Val Loss: 0.2006 Acc: 0.9185\n",
      "Epoch 034 | Train Loss: 0.2112 Acc: 0.9129 | Val Loss: 0.2129 Acc: 0.9191\n",
      "Epoch 035 | Train Loss: 0.1913 Acc: 0.9256 | Val Loss: 0.2487 Acc: 0.9094\n",
      "Epoch 036 | Train Loss: 0.2043 Acc: 0.9176 | Val Loss: 0.2729 Acc: 0.8889\n",
      "Epoch 037 | Train Loss: 0.1941 Acc: 0.9248 | Val Loss: 0.2072 Acc: 0.9233\n",
      "Epoch 038 | Train Loss: 0.1948 Acc: 0.9247 | Val Loss: 0.1948 Acc: 0.9269\n",
      "Epoch 039 | Train Loss: 0.1825 Acc: 0.9289 | Val Loss: 0.2142 Acc: 0.9203\n",
      "Epoch 040 | Train Loss: 0.1833 Acc: 0.9299 | Val Loss: 0.1923 Acc: 0.9275\n",
      "Epoch 041 | Train Loss: 0.1887 Acc: 0.9269 | Val Loss: 0.1806 Acc: 0.9306\n",
      "Epoch 042 | Train Loss: 0.1847 Acc: 0.9265 | Val Loss: 0.1880 Acc: 0.9233\n",
      "Epoch 043 | Train Loss: 0.1668 Acc: 0.9357 | Val Loss: 0.1938 Acc: 0.9318\n",
      "Epoch 044 | Train Loss: 0.1675 Acc: 0.9357 | Val Loss: 0.1819 Acc: 0.9300\n",
      "Epoch 045 | Train Loss: 0.1853 Acc: 0.9268 | Val Loss: 0.2076 Acc: 0.9161\n",
      "Epoch 046 | Train Loss: 0.1589 Acc: 0.9414 | Val Loss: 0.2452 Acc: 0.9064\n",
      "Epoch 047 | Train Loss: 0.1640 Acc: 0.9366 | Val Loss: 0.1761 Acc: 0.9318\n",
      "Epoch 048 | Train Loss: 0.1525 Acc: 0.9395 | Val Loss: 0.1951 Acc: 0.9275\n",
      "Epoch 049 | Train Loss: 0.1534 Acc: 0.9401 | Val Loss: 0.1988 Acc: 0.9251\n",
      "Epoch 050 | Train Loss: 0.1557 Acc: 0.9426 | Val Loss: 0.1649 Acc: 0.9384\n",
      "Epoch 051 | Train Loss: 0.1467 Acc: 0.9443 | Val Loss: 0.2015 Acc: 0.9281\n",
      "Epoch 052 | Train Loss: 0.1552 Acc: 0.9401 | Val Loss: 0.1857 Acc: 0.9281\n",
      "Epoch 053 | Train Loss: 0.1492 Acc: 0.9419 | Val Loss: 0.1823 Acc: 0.9348\n",
      "Epoch 054 | Train Loss: 0.1486 Acc: 0.9414 | Val Loss: 0.1590 Acc: 0.9366\n",
      "Epoch 055 | Train Loss: 0.1432 Acc: 0.9449 | Val Loss: 0.1616 Acc: 0.9396\n",
      "Epoch 056 | Train Loss: 0.1495 Acc: 0.9434 | Val Loss: 0.1651 Acc: 0.9390\n",
      "Epoch 057 | Train Loss: 0.1360 Acc: 0.9478 | Val Loss: 0.1936 Acc: 0.9269\n",
      "Epoch 058 | Train Loss: 0.1487 Acc: 0.9450 | Val Loss: 0.1681 Acc: 0.9420\n",
      "Epoch 059 | Train Loss: 0.1381 Acc: 0.9511 | Val Loss: 0.1604 Acc: 0.9366\n",
      "Epoch 060 | Train Loss: 0.1427 Acc: 0.9462 | Val Loss: 0.1705 Acc: 0.9312\n",
      "Epoch 001 | Train Loss: 0.6790 Acc: 0.5766 | Val Loss: 0.6717 Acc: 0.5936\n",
      "Epoch 002 | Train Loss: 0.6633 Acc: 0.6038 | Val Loss: 0.7204 Acc: 0.5133\n",
      "Epoch 003 | Train Loss: 0.6581 Acc: 0.6053 | Val Loss: 0.6631 Acc: 0.5857\n",
      "Epoch 004 | Train Loss: 0.6394 Acc: 0.6393 | Val Loss: 0.6119 Acc: 0.6806\n",
      "Epoch 005 | Train Loss: 0.5967 Acc: 0.6942 | Val Loss: 0.6046 Acc: 0.6860\n",
      "Epoch 006 | Train Loss: 0.5613 Acc: 0.7181 | Val Loss: 0.5586 Acc: 0.7101\n",
      "Epoch 007 | Train Loss: 0.5475 Acc: 0.7293 | Val Loss: 0.5514 Acc: 0.7246\n",
      "Epoch 008 | Train Loss: 0.5273 Acc: 0.7436 | Val Loss: 0.5524 Acc: 0.7101\n",
      "Epoch 009 | Train Loss: 0.5142 Acc: 0.7492 | Val Loss: 0.5145 Acc: 0.7421\n",
      "Epoch 010 | Train Loss: 0.4903 Acc: 0.7639 | Val Loss: 0.4938 Acc: 0.7645\n",
      "Epoch 011 | Train Loss: 0.4762 Acc: 0.7723 | Val Loss: 0.4795 Acc: 0.7603\n",
      "Epoch 012 | Train Loss: 0.4612 Acc: 0.7839 | Val Loss: 0.5054 Acc: 0.7566\n",
      "Epoch 013 | Train Loss: 0.4517 Acc: 0.7856 | Val Loss: 0.4627 Acc: 0.7675\n",
      "Epoch 014 | Train Loss: 0.4346 Acc: 0.7974 | Val Loss: 0.4454 Acc: 0.7862\n",
      "Epoch 015 | Train Loss: 0.4180 Acc: 0.8125 | Val Loss: 0.4585 Acc: 0.7905\n",
      "Epoch 016 | Train Loss: 0.4037 Acc: 0.8138 | Val Loss: 0.4102 Acc: 0.8068\n",
      "Epoch 017 | Train Loss: 0.3827 Acc: 0.8256 | Val Loss: 0.3938 Acc: 0.8249\n",
      "Epoch 018 | Train Loss: 0.3642 Acc: 0.8380 | Val Loss: 0.4538 Acc: 0.7880\n",
      "Epoch 019 | Train Loss: 0.3623 Acc: 0.8400 | Val Loss: 0.4055 Acc: 0.8050\n",
      "Epoch 020 | Train Loss: 0.3416 Acc: 0.8483 | Val Loss: 0.4053 Acc: 0.8188\n",
      "Epoch 021 | Train Loss: 0.3210 Acc: 0.8626 | Val Loss: 0.3532 Acc: 0.8412\n",
      "Epoch 022 | Train Loss: 0.3031 Acc: 0.8685 | Val Loss: 0.3150 Acc: 0.8641\n",
      "Epoch 023 | Train Loss: 0.2988 Acc: 0.8732 | Val Loss: 0.3155 Acc: 0.8653\n",
      "Epoch 024 | Train Loss: 0.2937 Acc: 0.8703 | Val Loss: 0.3034 Acc: 0.8587\n",
      "Epoch 025 | Train Loss: 0.2749 Acc: 0.8877 | Val Loss: 0.2949 Acc: 0.8678\n",
      "Epoch 026 | Train Loss: 0.2690 Acc: 0.8874 | Val Loss: 0.2656 Acc: 0.8835\n",
      "Epoch 027 | Train Loss: 0.2443 Acc: 0.8975 | Val Loss: 0.2803 Acc: 0.8816\n",
      "Epoch 028 | Train Loss: 0.2379 Acc: 0.9070 | Val Loss: 0.2750 Acc: 0.8835\n",
      "Epoch 029 | Train Loss: 0.2390 Acc: 0.9019 | Val Loss: 0.2580 Acc: 0.8865\n",
      "Epoch 030 | Train Loss: 0.2400 Acc: 0.9038 | Val Loss: 0.3014 Acc: 0.8756\n",
      "Epoch 031 | Train Loss: 0.2264 Acc: 0.9070 | Val Loss: 0.2480 Acc: 0.8901\n",
      "Epoch 032 | Train Loss: 0.2008 Acc: 0.9219 | Val Loss: 0.2499 Acc: 0.9016\n",
      "Epoch 033 | Train Loss: 0.2007 Acc: 0.9204 | Val Loss: 0.2149 Acc: 0.9100\n",
      "Epoch 034 | Train Loss: 0.1828 Acc: 0.9251 | Val Loss: 0.2297 Acc: 0.9064\n",
      "Epoch 035 | Train Loss: 0.1912 Acc: 0.9224 | Val Loss: 0.2208 Acc: 0.9167\n",
      "Epoch 036 | Train Loss: 0.1754 Acc: 0.9302 | Val Loss: 0.2287 Acc: 0.9028\n",
      "Epoch 037 | Train Loss: 0.1822 Acc: 0.9263 | Val Loss: 0.1968 Acc: 0.9209\n",
      "Epoch 038 | Train Loss: 0.1673 Acc: 0.9351 | Val Loss: 0.2342 Acc: 0.9004\n",
      "Epoch 039 | Train Loss: 0.1689 Acc: 0.9349 | Val Loss: 0.1939 Acc: 0.9191\n",
      "Epoch 040 | Train Loss: 0.1579 Acc: 0.9354 | Val Loss: 0.1803 Acc: 0.9233\n",
      "Epoch 041 | Train Loss: 0.1570 Acc: 0.9375 | Val Loss: 0.1784 Acc: 0.9342\n",
      "Epoch 042 | Train Loss: 0.1452 Acc: 0.9453 | Val Loss: 0.1867 Acc: 0.9324\n",
      "Epoch 043 | Train Loss: 0.1439 Acc: 0.9434 | Val Loss: 0.1821 Acc: 0.9275\n",
      "Epoch 044 | Train Loss: 0.1407 Acc: 0.9464 | Val Loss: 0.1783 Acc: 0.9281\n",
      "Epoch 045 | Train Loss: 0.1381 Acc: 0.9499 | Val Loss: 0.1689 Acc: 0.9408\n",
      "Epoch 046 | Train Loss: 0.1380 Acc: 0.9459 | Val Loss: 0.2113 Acc: 0.9221\n",
      "Epoch 047 | Train Loss: 0.1430 Acc: 0.9437 | Val Loss: 0.1630 Acc: 0.9354\n",
      "Epoch 048 | Train Loss: 0.1319 Acc: 0.9488 | Val Loss: 0.1732 Acc: 0.9402\n",
      "Epoch 049 | Train Loss: 0.1346 Acc: 0.9491 | Val Loss: 0.1705 Acc: 0.9281\n",
      "Epoch 050 | Train Loss: 0.1193 Acc: 0.9553 | Val Loss: 0.1678 Acc: 0.9318\n",
      "Epoch 051 | Train Loss: 0.1228 Acc: 0.9515 | Val Loss: 0.1675 Acc: 0.9354\n",
      "Epoch 052 | Train Loss: 0.1203 Acc: 0.9543 | Val Loss: 0.1539 Acc: 0.9469\n",
      "Epoch 053 | Train Loss: 0.1123 Acc: 0.9562 | Val Loss: 0.1832 Acc: 0.9300\n",
      "Epoch 054 | Train Loss: 0.1096 Acc: 0.9570 | Val Loss: 0.1745 Acc: 0.9348\n",
      "Epoch 055 | Train Loss: 0.1095 Acc: 0.9573 | Val Loss: 0.1482 Acc: 0.9469\n",
      "Epoch 056 | Train Loss: 0.1115 Acc: 0.9601 | Val Loss: 0.1475 Acc: 0.9414\n",
      "Epoch 057 | Train Loss: 0.0948 Acc: 0.9627 | Val Loss: 0.1686 Acc: 0.9372\n",
      "Epoch 058 | Train Loss: 0.1096 Acc: 0.9570 | Val Loss: 0.1474 Acc: 0.9493\n",
      "Epoch 059 | Train Loss: 0.1102 Acc: 0.9549 | Val Loss: 0.1542 Acc: 0.9384\n",
      "Epoch 060 | Train Loss: 0.0872 Acc: 0.9680 | Val Loss: 0.1852 Acc: 0.9372\n",
      "Epoch 001 | Train Loss: 0.6831 Acc: 0.5753 | Val Loss: 0.6796 Acc: 0.5851\n",
      "Epoch 002 | Train Loss: 0.6775 Acc: 0.5905 | Val Loss: 0.6896 Acc: 0.5936\n",
      "Epoch 003 | Train Loss: 0.6477 Acc: 0.6342 | Val Loss: 0.6174 Acc: 0.6757\n",
      "Epoch 004 | Train Loss: 0.5972 Acc: 0.7093 | Val Loss: 0.5804 Acc: 0.7017\n",
      "Epoch 005 | Train Loss: 0.5574 Acc: 0.7226 | Val Loss: 0.6016 Acc: 0.6957\n",
      "Epoch 006 | Train Loss: 0.5274 Acc: 0.7451 | Val Loss: 0.5521 Acc: 0.7252\n",
      "Epoch 007 | Train Loss: 0.4840 Acc: 0.7747 | Val Loss: 0.4942 Acc: 0.7663\n",
      "Epoch 008 | Train Loss: 0.4522 Acc: 0.7928 | Val Loss: 0.4385 Acc: 0.7880\n",
      "Epoch 009 | Train Loss: 0.4295 Acc: 0.8072 | Val Loss: 0.4541 Acc: 0.7838\n",
      "Epoch 010 | Train Loss: 0.4015 Acc: 0.8239 | Val Loss: 0.3697 Acc: 0.8267\n",
      "Epoch 011 | Train Loss: 0.3680 Acc: 0.8380 | Val Loss: 0.3869 Acc: 0.8237\n",
      "Epoch 012 | Train Loss: 0.3482 Acc: 0.8505 | Val Loss: 0.3495 Acc: 0.8412\n",
      "Epoch 013 | Train Loss: 0.3267 Acc: 0.8631 | Val Loss: 0.3338 Acc: 0.8581\n",
      "Epoch 014 | Train Loss: 0.3052 Acc: 0.8706 | Val Loss: 0.3048 Acc: 0.8653\n",
      "Epoch 015 | Train Loss: 0.2809 Acc: 0.8831 | Val Loss: 0.2870 Acc: 0.8750\n",
      "Epoch 016 | Train Loss: 0.2666 Acc: 0.8920 | Val Loss: 0.2698 Acc: 0.8865\n",
      "Epoch 017 | Train Loss: 0.2389 Acc: 0.9020 | Val Loss: 0.2630 Acc: 0.8955\n",
      "Epoch 018 | Train Loss: 0.2384 Acc: 0.9068 | Val Loss: 0.2950 Acc: 0.8774\n",
      "Epoch 019 | Train Loss: 0.2236 Acc: 0.9124 | Val Loss: 0.2648 Acc: 0.8853\n",
      "Epoch 020 | Train Loss: 0.2058 Acc: 0.9170 | Val Loss: 0.2517 Acc: 0.8889\n",
      "Epoch 021 | Train Loss: 0.1945 Acc: 0.9209 | Val Loss: 0.2405 Acc: 0.8943\n",
      "Epoch 022 | Train Loss: 0.2003 Acc: 0.9201 | Val Loss: 0.2250 Acc: 0.9106\n",
      "Epoch 023 | Train Loss: 0.1739 Acc: 0.9336 | Val Loss: 0.2423 Acc: 0.9088\n",
      "Epoch 024 | Train Loss: 0.1708 Acc: 0.9343 | Val Loss: 0.2912 Acc: 0.8907\n",
      "Epoch 025 | Train Loss: 0.1733 Acc: 0.9349 | Val Loss: 0.2182 Acc: 0.9161\n",
      "Epoch 026 | Train Loss: 0.1522 Acc: 0.9422 | Val Loss: 0.2508 Acc: 0.9028\n",
      "Epoch 027 | Train Loss: 0.1599 Acc: 0.9399 | Val Loss: 0.2496 Acc: 0.8913\n",
      "Epoch 028 | Train Loss: 0.1655 Acc: 0.9343 | Val Loss: 0.2296 Acc: 0.9088\n",
      "Epoch 029 | Train Loss: 0.1535 Acc: 0.9428 | Val Loss: 0.2356 Acc: 0.9010\n",
      "Epoch 030 | Train Loss: 0.1355 Acc: 0.9479 | Val Loss: 0.2013 Acc: 0.9124\n",
      "Epoch 031 | Train Loss: 0.1271 Acc: 0.9511 | Val Loss: 0.2298 Acc: 0.9209\n",
      "Epoch 032 | Train Loss: 0.1169 Acc: 0.9535 | Val Loss: 0.2351 Acc: 0.9215\n",
      "Epoch 033 | Train Loss: 0.1355 Acc: 0.9481 | Val Loss: 0.2356 Acc: 0.9191\n",
      "Epoch 034 | Train Loss: 0.1258 Acc: 0.9521 | Val Loss: 0.2095 Acc: 0.9179\n",
      "Epoch 035 | Train Loss: 0.1272 Acc: 0.9547 | Val Loss: 0.2111 Acc: 0.9191\n",
      "Epoch 036 | Train Loss: 0.1127 Acc: 0.9591 | Val Loss: 0.2132 Acc: 0.9167\n",
      "Epoch 037 | Train Loss: 0.1096 Acc: 0.9589 | Val Loss: 0.2209 Acc: 0.9094\n",
      "Epoch 038 | Train Loss: 0.1040 Acc: 0.9612 | Val Loss: 0.1920 Acc: 0.9300\n",
      "Epoch 039 | Train Loss: 0.1079 Acc: 0.9598 | Val Loss: 0.2024 Acc: 0.9263\n",
      "Epoch 040 | Train Loss: 0.1034 Acc: 0.9610 | Val Loss: 0.2007 Acc: 0.9227\n",
      "Epoch 041 | Train Loss: 0.1036 Acc: 0.9624 | Val Loss: 0.1981 Acc: 0.9275\n",
      "Epoch 042 | Train Loss: 0.0989 Acc: 0.9636 | Val Loss: 0.2639 Acc: 0.9161\n",
      "Epoch 043 | Train Loss: 0.1025 Acc: 0.9589 | Val Loss: 0.1874 Acc: 0.9257\n",
      "Epoch 044 | Train Loss: 0.1017 Acc: 0.9607 | Val Loss: 0.1951 Acc: 0.9287\n",
      "Epoch 045 | Train Loss: 0.0892 Acc: 0.9681 | Val Loss: 0.1729 Acc: 0.9336\n",
      "Epoch 046 | Train Loss: 0.0816 Acc: 0.9715 | Val Loss: 0.2127 Acc: 0.9293\n",
      "Epoch 047 | Train Loss: 0.0853 Acc: 0.9677 | Val Loss: 0.1810 Acc: 0.9342\n",
      "Epoch 048 | Train Loss: 0.0822 Acc: 0.9719 | Val Loss: 0.1958 Acc: 0.9312\n",
      "Epoch 049 | Train Loss: 0.0915 Acc: 0.9666 | Val Loss: 0.1877 Acc: 0.9318\n",
      "Epoch 050 | Train Loss: 0.0888 Acc: 0.9684 | Val Loss: 0.2083 Acc: 0.9215\n",
      "Epoch 051 | Train Loss: 0.0885 Acc: 0.9666 | Val Loss: 0.2058 Acc: 0.9293\n",
      "Epoch 052 | Train Loss: 0.0771 Acc: 0.9716 | Val Loss: 0.1954 Acc: 0.9336\n",
      "Epoch 053 | Train Loss: 0.0792 Acc: 0.9706 | Val Loss: 0.1932 Acc: 0.9354\n",
      "Epoch 054 | Train Loss: 0.0827 Acc: 0.9695 | Val Loss: 0.1996 Acc: 0.9354\n",
      "Epoch 055 | Train Loss: 0.0724 Acc: 0.9725 | Val Loss: 0.2079 Acc: 0.9287\n",
      "Early stopping triggered.\n",
      "Iteration 14/40 | Best Val Loss: 0.1122 | Iter Time: 222.62s | Total Time: 64.59 min\n",
      "Epoch 001 | Train Loss: 0.6786 Acc: 0.5759 | Val Loss: 0.6743 Acc: 0.5827\n",
      "Epoch 002 | Train Loss: 0.6643 Acc: 0.6038 | Val Loss: 0.6659 Acc: 0.5652\n",
      "Epoch 003 | Train Loss: 0.6405 Acc: 0.6361 | Val Loss: 0.6266 Acc: 0.6576\n",
      "Epoch 004 | Train Loss: 0.5926 Acc: 0.6997 | Val Loss: 0.5802 Acc: 0.6950\n",
      "Epoch 005 | Train Loss: 0.5691 Acc: 0.7157 | Val Loss: 0.5680 Acc: 0.7029\n",
      "Epoch 006 | Train Loss: 0.5440 Acc: 0.7335 | Val Loss: 0.5544 Acc: 0.7252\n",
      "Epoch 007 | Train Loss: 0.5178 Acc: 0.7542 | Val Loss: 0.5276 Acc: 0.7391\n",
      "Epoch 008 | Train Loss: 0.5092 Acc: 0.7545 | Val Loss: 0.5098 Acc: 0.7506\n",
      "Epoch 009 | Train Loss: 0.4862 Acc: 0.7672 | Val Loss: 0.4900 Acc: 0.7615\n",
      "Epoch 010 | Train Loss: 0.4641 Acc: 0.7900 | Val Loss: 0.4658 Acc: 0.7772\n",
      "Epoch 011 | Train Loss: 0.4459 Acc: 0.7930 | Val Loss: 0.4653 Acc: 0.7711\n",
      "Epoch 012 | Train Loss: 0.4132 Acc: 0.8107 | Val Loss: 0.4306 Acc: 0.7941\n",
      "Epoch 013 | Train Loss: 0.3984 Acc: 0.8202 | Val Loss: 0.4590 Acc: 0.8019\n",
      "Epoch 014 | Train Loss: 0.3782 Acc: 0.8323 | Val Loss: 0.4290 Acc: 0.8068\n",
      "Epoch 015 | Train Loss: 0.3501 Acc: 0.8474 | Val Loss: 0.3515 Acc: 0.8496\n",
      "Epoch 016 | Train Loss: 0.3288 Acc: 0.8552 | Val Loss: 0.3379 Acc: 0.8539\n",
      "Epoch 017 | Train Loss: 0.2998 Acc: 0.8689 | Val Loss: 0.3074 Acc: 0.8696\n",
      "Epoch 018 | Train Loss: 0.2693 Acc: 0.8907 | Val Loss: 0.2971 Acc: 0.8671\n",
      "Epoch 019 | Train Loss: 0.2546 Acc: 0.8958 | Val Loss: 0.2818 Acc: 0.8744\n",
      "Epoch 020 | Train Loss: 0.2352 Acc: 0.9041 | Val Loss: 0.2912 Acc: 0.8877\n",
      "Epoch 021 | Train Loss: 0.2204 Acc: 0.9076 | Val Loss: 0.2542 Acc: 0.8992\n",
      "Epoch 022 | Train Loss: 0.2022 Acc: 0.9185 | Val Loss: 0.2510 Acc: 0.8967\n",
      "Epoch 023 | Train Loss: 0.1752 Acc: 0.9290 | Val Loss: 0.2481 Acc: 0.9034\n",
      "Epoch 024 | Train Loss: 0.1796 Acc: 0.9251 | Val Loss: 0.2198 Acc: 0.9155\n",
      "Epoch 025 | Train Loss: 0.1494 Acc: 0.9402 | Val Loss: 0.2493 Acc: 0.9070\n",
      "Epoch 026 | Train Loss: 0.1430 Acc: 0.9437 | Val Loss: 0.2311 Acc: 0.9124\n",
      "Epoch 027 | Train Loss: 0.1348 Acc: 0.9487 | Val Loss: 0.2312 Acc: 0.9088\n",
      "Epoch 028 | Train Loss: 0.1202 Acc: 0.9549 | Val Loss: 0.2564 Acc: 0.9106\n",
      "Epoch 029 | Train Loss: 0.1222 Acc: 0.9523 | Val Loss: 0.2022 Acc: 0.9263\n",
      "Epoch 030 | Train Loss: 0.1134 Acc: 0.9559 | Val Loss: 0.2019 Acc: 0.9306\n",
      "Epoch 031 | Train Loss: 0.1079 Acc: 0.9586 | Val Loss: 0.2450 Acc: 0.9094\n",
      "Epoch 032 | Train Loss: 0.1062 Acc: 0.9576 | Val Loss: 0.2005 Acc: 0.9239\n",
      "Epoch 033 | Train Loss: 0.0907 Acc: 0.9662 | Val Loss: 0.2505 Acc: 0.9155\n",
      "Epoch 034 | Train Loss: 0.0935 Acc: 0.9660 | Val Loss: 0.2016 Acc: 0.9257\n",
      "Epoch 035 | Train Loss: 0.0850 Acc: 0.9677 | Val Loss: 0.2671 Acc: 0.9016\n",
      "Epoch 036 | Train Loss: 0.0979 Acc: 0.9647 | Val Loss: 0.1901 Acc: 0.9330\n",
      "Epoch 037 | Train Loss: 0.0936 Acc: 0.9632 | Val Loss: 0.2341 Acc: 0.9130\n",
      "Epoch 038 | Train Loss: 0.0749 Acc: 0.9722 | Val Loss: 0.2419 Acc: 0.9263\n",
      "Epoch 039 | Train Loss: 0.0842 Acc: 0.9693 | Val Loss: 0.1731 Acc: 0.9342\n",
      "Epoch 040 | Train Loss: 0.0636 Acc: 0.9755 | Val Loss: 0.1782 Acc: 0.9414\n",
      "Epoch 041 | Train Loss: 0.0629 Acc: 0.9781 | Val Loss: 0.1992 Acc: 0.9348\n",
      "Epoch 042 | Train Loss: 0.0599 Acc: 0.9796 | Val Loss: 0.1532 Acc: 0.9414\n",
      "Epoch 043 | Train Loss: 0.0646 Acc: 0.9754 | Val Loss: 0.2112 Acc: 0.9330\n",
      "Epoch 044 | Train Loss: 0.0560 Acc: 0.9787 | Val Loss: 0.2151 Acc: 0.9306\n",
      "Epoch 045 | Train Loss: 0.0524 Acc: 0.9804 | Val Loss: 0.1869 Acc: 0.9432\n",
      "Epoch 046 | Train Loss: 0.0600 Acc: 0.9783 | Val Loss: 0.1745 Acc: 0.9426\n",
      "Epoch 047 | Train Loss: 0.0509 Acc: 0.9825 | Val Loss: 0.1632 Acc: 0.9469\n",
      "Epoch 048 | Train Loss: 0.0600 Acc: 0.9780 | Val Loss: 0.1903 Acc: 0.9360\n",
      "Epoch 049 | Train Loss: 0.0459 Acc: 0.9828 | Val Loss: 0.1938 Acc: 0.9426\n",
      "Epoch 050 | Train Loss: 0.0594 Acc: 0.9774 | Val Loss: 0.1767 Acc: 0.9372\n",
      "Epoch 051 | Train Loss: 0.0433 Acc: 0.9851 | Val Loss: 0.2042 Acc: 0.9293\n",
      "Epoch 052 | Train Loss: 0.0397 Acc: 0.9861 | Val Loss: 0.2666 Acc: 0.9275\n",
      "Early stopping triggered.\n",
      "Epoch 001 | Train Loss: 0.6801 Acc: 0.5774 | Val Loss: 0.6698 Acc: 0.5900\n",
      "Epoch 002 | Train Loss: 0.6263 Acc: 0.6582 | Val Loss: 0.5968 Acc: 0.6938\n",
      "Epoch 003 | Train Loss: 0.5595 Acc: 0.7216 | Val Loss: 0.5426 Acc: 0.7301\n",
      "Epoch 004 | Train Loss: 0.5295 Acc: 0.7409 | Val Loss: 0.5207 Acc: 0.7397\n",
      "Epoch 005 | Train Loss: 0.5131 Acc: 0.7519 | Val Loss: 0.5282 Acc: 0.7367\n",
      "Epoch 006 | Train Loss: 0.4812 Acc: 0.7658 | Val Loss: 0.4822 Acc: 0.7651\n",
      "Epoch 007 | Train Loss: 0.4395 Acc: 0.7916 | Val Loss: 0.4355 Acc: 0.7886\n",
      "Epoch 008 | Train Loss: 0.3910 Acc: 0.8223 | Val Loss: 0.3893 Acc: 0.8225\n",
      "Epoch 009 | Train Loss: 0.3606 Acc: 0.8421 | Val Loss: 0.3948 Acc: 0.8249\n",
      "Epoch 010 | Train Loss: 0.3400 Acc: 0.8507 | Val Loss: 0.3472 Acc: 0.8388\n",
      "Epoch 011 | Train Loss: 0.3023 Acc: 0.8694 | Val Loss: 0.3108 Acc: 0.8629\n",
      "Epoch 012 | Train Loss: 0.2727 Acc: 0.8883 | Val Loss: 0.2995 Acc: 0.8720\n",
      "Epoch 013 | Train Loss: 0.2579 Acc: 0.8946 | Val Loss: 0.2787 Acc: 0.8841\n",
      "Epoch 014 | Train Loss: 0.2413 Acc: 0.8978 | Val Loss: 0.2978 Acc: 0.8720\n",
      "Epoch 015 | Train Loss: 0.2099 Acc: 0.9132 | Val Loss: 0.2461 Acc: 0.8943\n",
      "Epoch 016 | Train Loss: 0.1965 Acc: 0.9247 | Val Loss: 0.2630 Acc: 0.8841\n",
      "Epoch 017 | Train Loss: 0.1904 Acc: 0.9225 | Val Loss: 0.2431 Acc: 0.9034\n",
      "Epoch 018 | Train Loss: 0.1708 Acc: 0.9302 | Val Loss: 0.2184 Acc: 0.9130\n",
      "Epoch 019 | Train Loss: 0.1589 Acc: 0.9366 | Val Loss: 0.2080 Acc: 0.9136\n",
      "Epoch 020 | Train Loss: 0.1501 Acc: 0.9370 | Val Loss: 0.2037 Acc: 0.9130\n",
      "Epoch 021 | Train Loss: 0.1399 Acc: 0.9458 | Val Loss: 0.2109 Acc: 0.9221\n",
      "Epoch 022 | Train Loss: 0.1248 Acc: 0.9524 | Val Loss: 0.2057 Acc: 0.9239\n",
      "Epoch 023 | Train Loss: 0.1133 Acc: 0.9555 | Val Loss: 0.2114 Acc: 0.9185\n",
      "Epoch 024 | Train Loss: 0.1234 Acc: 0.9502 | Val Loss: 0.2238 Acc: 0.9149\n",
      "Epoch 025 | Train Loss: 0.1149 Acc: 0.9558 | Val Loss: 0.1829 Acc: 0.9306\n",
      "Epoch 026 | Train Loss: 0.1040 Acc: 0.9585 | Val Loss: 0.2010 Acc: 0.9179\n",
      "Epoch 027 | Train Loss: 0.0985 Acc: 0.9651 | Val Loss: 0.2669 Acc: 0.9112\n",
      "Epoch 028 | Train Loss: 0.1075 Acc: 0.9618 | Val Loss: 0.1949 Acc: 0.9269\n",
      "Epoch 029 | Train Loss: 0.0881 Acc: 0.9671 | Val Loss: 0.1832 Acc: 0.9324\n",
      "Epoch 030 | Train Loss: 0.0839 Acc: 0.9689 | Val Loss: 0.2072 Acc: 0.9215\n",
      "Epoch 031 | Train Loss: 0.0793 Acc: 0.9692 | Val Loss: 0.1588 Acc: 0.9414\n",
      "Epoch 032 | Train Loss: 0.0818 Acc: 0.9698 | Val Loss: 0.1746 Acc: 0.9342\n",
      "Epoch 033 | Train Loss: 0.0771 Acc: 0.9713 | Val Loss: 0.1677 Acc: 0.9342\n",
      "Epoch 034 | Train Loss: 0.0743 Acc: 0.9719 | Val Loss: 0.1831 Acc: 0.9360\n",
      "Epoch 035 | Train Loss: 0.0570 Acc: 0.9784 | Val Loss: 0.2622 Acc: 0.9179\n",
      "Epoch 036 | Train Loss: 0.0636 Acc: 0.9755 | Val Loss: 0.1832 Acc: 0.9306\n",
      "Epoch 037 | Train Loss: 0.0630 Acc: 0.9764 | Val Loss: 0.1923 Acc: 0.9287\n",
      "Epoch 038 | Train Loss: 0.0641 Acc: 0.9763 | Val Loss: 0.2200 Acc: 0.9263\n",
      "Epoch 039 | Train Loss: 0.0664 Acc: 0.9754 | Val Loss: 0.1880 Acc: 0.9348\n",
      "Epoch 040 | Train Loss: 0.0498 Acc: 0.9810 | Val Loss: 0.1631 Acc: 0.9463\n",
      "Epoch 041 | Train Loss: 0.0606 Acc: 0.9766 | Val Loss: 0.1794 Acc: 0.9366\n",
      "Early stopping triggered.\n",
      "Epoch 001 | Train Loss: 0.6792 Acc: 0.5819 | Val Loss: 0.6749 Acc: 0.5894\n",
      "Epoch 002 | Train Loss: 0.6699 Acc: 0.5975 | Val Loss: 0.6737 Acc: 0.5815\n",
      "Epoch 003 | Train Loss: 0.6613 Acc: 0.6034 | Val Loss: 0.6561 Acc: 0.6057\n",
      "Epoch 004 | Train Loss: 0.6387 Acc: 0.6385 | Val Loss: 0.6286 Acc: 0.6618\n",
      "Epoch 005 | Train Loss: 0.5978 Acc: 0.6923 | Val Loss: 0.5749 Acc: 0.7029\n",
      "Epoch 006 | Train Loss: 0.5678 Acc: 0.7157 | Val Loss: 0.5569 Acc: 0.7180\n",
      "Epoch 007 | Train Loss: 0.5549 Acc: 0.7237 | Val Loss: 0.5484 Acc: 0.7198\n",
      "Epoch 008 | Train Loss: 0.5301 Acc: 0.7400 | Val Loss: 0.5178 Acc: 0.7349\n",
      "Epoch 009 | Train Loss: 0.5226 Acc: 0.7415 | Val Loss: 0.5297 Acc: 0.7264\n",
      "Epoch 010 | Train Loss: 0.5072 Acc: 0.7531 | Val Loss: 0.5210 Acc: 0.7488\n",
      "Epoch 011 | Train Loss: 0.4747 Acc: 0.7729 | Val Loss: 0.4866 Acc: 0.7579\n",
      "Epoch 012 | Train Loss: 0.4495 Acc: 0.7877 | Val Loss: 0.4315 Acc: 0.7995\n",
      "Epoch 013 | Train Loss: 0.4218 Acc: 0.8063 | Val Loss: 0.4342 Acc: 0.7983\n",
      "Epoch 014 | Train Loss: 0.3879 Acc: 0.8217 | Val Loss: 0.3891 Acc: 0.8225\n",
      "Epoch 015 | Train Loss: 0.3583 Acc: 0.8428 | Val Loss: 0.3773 Acc: 0.8309\n",
      "Epoch 016 | Train Loss: 0.3450 Acc: 0.8463 | Val Loss: 0.3463 Acc: 0.8460\n",
      "Epoch 017 | Train Loss: 0.3280 Acc: 0.8600 | Val Loss: 0.3123 Acc: 0.8641\n",
      "Epoch 018 | Train Loss: 0.2993 Acc: 0.8735 | Val Loss: 0.2900 Acc: 0.8847\n",
      "Epoch 019 | Train Loss: 0.2787 Acc: 0.8840 | Val Loss: 0.3019 Acc: 0.8647\n",
      "Epoch 020 | Train Loss: 0.2600 Acc: 0.8949 | Val Loss: 0.3038 Acc: 0.8762\n",
      "Epoch 021 | Train Loss: 0.2438 Acc: 0.8985 | Val Loss: 0.2563 Acc: 0.8919\n",
      "Epoch 022 | Train Loss: 0.2226 Acc: 0.9080 | Val Loss: 0.2762 Acc: 0.8841\n",
      "Epoch 023 | Train Loss: 0.2178 Acc: 0.9153 | Val Loss: 0.2227 Acc: 0.9118\n",
      "Epoch 024 | Train Loss: 0.2213 Acc: 0.9079 | Val Loss: 0.2399 Acc: 0.9028\n",
      "Epoch 025 | Train Loss: 0.1939 Acc: 0.9244 | Val Loss: 0.2163 Acc: 0.9118\n",
      "Epoch 026 | Train Loss: 0.1883 Acc: 0.9280 | Val Loss: 0.2470 Acc: 0.8925\n",
      "Epoch 027 | Train Loss: 0.1674 Acc: 0.9348 | Val Loss: 0.1928 Acc: 0.9245\n",
      "Epoch 028 | Train Loss: 0.1792 Acc: 0.9299 | Val Loss: 0.2084 Acc: 0.9191\n",
      "Epoch 029 | Train Loss: 0.1600 Acc: 0.9401 | Val Loss: 0.1968 Acc: 0.9173\n",
      "Epoch 030 | Train Loss: 0.1474 Acc: 0.9441 | Val Loss: 0.2383 Acc: 0.9070\n",
      "Epoch 031 | Train Loss: 0.1376 Acc: 0.9465 | Val Loss: 0.1816 Acc: 0.9330\n",
      "Epoch 032 | Train Loss: 0.1422 Acc: 0.9422 | Val Loss: 0.2050 Acc: 0.9197\n",
      "Epoch 033 | Train Loss: 0.1490 Acc: 0.9438 | Val Loss: 0.1707 Acc: 0.9408\n",
      "Epoch 034 | Train Loss: 0.1183 Acc: 0.9539 | Val Loss: 0.1741 Acc: 0.9300\n",
      "Epoch 035 | Train Loss: 0.1165 Acc: 0.9535 | Val Loss: 0.1731 Acc: 0.9287\n",
      "Epoch 036 | Train Loss: 0.1230 Acc: 0.9529 | Val Loss: 0.1913 Acc: 0.9233\n",
      "Epoch 037 | Train Loss: 0.1273 Acc: 0.9478 | Val Loss: 0.1785 Acc: 0.9287\n",
      "Epoch 038 | Train Loss: 0.1120 Acc: 0.9579 | Val Loss: 0.1800 Acc: 0.9390\n",
      "Epoch 039 | Train Loss: 0.1047 Acc: 0.9598 | Val Loss: 0.2050 Acc: 0.9287\n",
      "Epoch 040 | Train Loss: 0.1024 Acc: 0.9638 | Val Loss: 0.1840 Acc: 0.9372\n",
      "Epoch 041 | Train Loss: 0.1093 Acc: 0.9577 | Val Loss: 0.1568 Acc: 0.9438\n",
      "Epoch 042 | Train Loss: 0.0980 Acc: 0.9647 | Val Loss: 0.1569 Acc: 0.9426\n",
      "Epoch 043 | Train Loss: 0.0960 Acc: 0.9639 | Val Loss: 0.1523 Acc: 0.9499\n",
      "Epoch 044 | Train Loss: 0.0898 Acc: 0.9668 | Val Loss: 0.1958 Acc: 0.9342\n",
      "Epoch 045 | Train Loss: 0.0996 Acc: 0.9615 | Val Loss: 0.1924 Acc: 0.9390\n",
      "Epoch 046 | Train Loss: 0.0857 Acc: 0.9662 | Val Loss: 0.1625 Acc: 0.9450\n",
      "Epoch 047 | Train Loss: 0.0807 Acc: 0.9698 | Val Loss: 0.1585 Acc: 0.9457\n",
      "Epoch 048 | Train Loss: 0.0878 Acc: 0.9681 | Val Loss: 0.1509 Acc: 0.9432\n",
      "Epoch 049 | Train Loss: 0.0804 Acc: 0.9706 | Val Loss: 0.1591 Acc: 0.9438\n",
      "Epoch 050 | Train Loss: 0.0761 Acc: 0.9707 | Val Loss: 0.1645 Acc: 0.9390\n",
      "Epoch 051 | Train Loss: 0.0832 Acc: 0.9686 | Val Loss: 0.1689 Acc: 0.9432\n",
      "Epoch 052 | Train Loss: 0.0782 Acc: 0.9690 | Val Loss: 0.2487 Acc: 0.9155\n",
      "Epoch 053 | Train Loss: 0.0830 Acc: 0.9690 | Val Loss: 0.1465 Acc: 0.9571\n",
      "Epoch 054 | Train Loss: 0.0690 Acc: 0.9764 | Val Loss: 0.1982 Acc: 0.9414\n",
      "Epoch 055 | Train Loss: 0.0708 Acc: 0.9731 | Val Loss: 0.1490 Acc: 0.9511\n",
      "Epoch 056 | Train Loss: 0.0661 Acc: 0.9749 | Val Loss: 0.1639 Acc: 0.9438\n",
      "Epoch 057 | Train Loss: 0.0776 Acc: 0.9730 | Val Loss: 0.1321 Acc: 0.9505\n",
      "Epoch 058 | Train Loss: 0.0611 Acc: 0.9769 | Val Loss: 0.1447 Acc: 0.9487\n",
      "Epoch 059 | Train Loss: 0.0661 Acc: 0.9731 | Val Loss: 0.1588 Acc: 0.9487\n",
      "Epoch 060 | Train Loss: 0.0711 Acc: 0.9751 | Val Loss: 0.1570 Acc: 0.9414\n",
      "Epoch 001 | Train Loss: 0.6843 Acc: 0.5706 | Val Loss: 0.6791 Acc: 0.5882\n",
      "Epoch 002 | Train Loss: 0.6793 Acc: 0.5790 | Val Loss: 0.6872 Acc: 0.5586\n",
      "Epoch 003 | Train Loss: 0.6808 Acc: 0.5756 | Val Loss: 0.6757 Acc: 0.6093\n",
      "Epoch 004 | Train Loss: 0.6504 Acc: 0.6358 | Val Loss: 0.6196 Acc: 0.6661\n",
      "Epoch 005 | Train Loss: 0.6049 Acc: 0.6864 | Val Loss: 0.5855 Acc: 0.6993\n",
      "Epoch 006 | Train Loss: 0.5846 Acc: 0.7065 | Val Loss: 0.5723 Acc: 0.7071\n",
      "Epoch 007 | Train Loss: 0.5601 Acc: 0.7195 | Val Loss: 0.5588 Acc: 0.7138\n",
      "Epoch 008 | Train Loss: 0.5409 Acc: 0.7317 | Val Loss: 0.5363 Acc: 0.7277\n",
      "Epoch 009 | Train Loss: 0.5325 Acc: 0.7395 | Val Loss: 0.5191 Acc: 0.7452\n",
      "Epoch 010 | Train Loss: 0.5124 Acc: 0.7525 | Val Loss: 0.5027 Acc: 0.7470\n",
      "Epoch 011 | Train Loss: 0.4948 Acc: 0.7648 | Val Loss: 0.5026 Acc: 0.7518\n",
      "Epoch 012 | Train Loss: 0.4788 Acc: 0.7717 | Val Loss: 0.4757 Acc: 0.7760\n",
      "Epoch 013 | Train Loss: 0.4745 Acc: 0.7761 | Val Loss: 0.4681 Acc: 0.7760\n",
      "Epoch 014 | Train Loss: 0.4598 Acc: 0.7906 | Val Loss: 0.4382 Acc: 0.7814\n",
      "Epoch 015 | Train Loss: 0.4587 Acc: 0.7847 | Val Loss: 0.4446 Acc: 0.7826\n",
      "Epoch 016 | Train Loss: 0.4386 Acc: 0.7992 | Val Loss: 0.4284 Acc: 0.7965\n",
      "Epoch 017 | Train Loss: 0.4301 Acc: 0.8067 | Val Loss: 0.4085 Acc: 0.8152\n",
      "Epoch 018 | Train Loss: 0.4182 Acc: 0.8078 | Val Loss: 0.4423 Acc: 0.7729\n",
      "Epoch 019 | Train Loss: 0.4070 Acc: 0.8159 | Val Loss: 0.3961 Acc: 0.8213\n",
      "Epoch 020 | Train Loss: 0.3911 Acc: 0.8280 | Val Loss: 0.3758 Acc: 0.8309\n",
      "Epoch 021 | Train Loss: 0.3815 Acc: 0.8286 | Val Loss: 0.3650 Acc: 0.8333\n",
      "Epoch 022 | Train Loss: 0.3659 Acc: 0.8398 | Val Loss: 0.3806 Acc: 0.8170\n",
      "Epoch 023 | Train Loss: 0.3551 Acc: 0.8445 | Val Loss: 0.3406 Acc: 0.8551\n",
      "Epoch 024 | Train Loss: 0.3420 Acc: 0.8514 | Val Loss: 0.3386 Acc: 0.8557\n",
      "Epoch 025 | Train Loss: 0.3334 Acc: 0.8602 | Val Loss: 0.3834 Acc: 0.8297\n",
      "Epoch 026 | Train Loss: 0.3197 Acc: 0.8667 | Val Loss: 0.3071 Acc: 0.8690\n",
      "Epoch 027 | Train Loss: 0.3114 Acc: 0.8723 | Val Loss: 0.3130 Acc: 0.8659\n",
      "Epoch 028 | Train Loss: 0.2805 Acc: 0.8801 | Val Loss: 0.2798 Acc: 0.8871\n",
      "Epoch 029 | Train Loss: 0.2867 Acc: 0.8828 | Val Loss: 0.2813 Acc: 0.8816\n",
      "Epoch 030 | Train Loss: 0.2769 Acc: 0.8837 | Val Loss: 0.2627 Acc: 0.8955\n",
      "Epoch 031 | Train Loss: 0.2658 Acc: 0.8926 | Val Loss: 0.2683 Acc: 0.8901\n",
      "Epoch 032 | Train Loss: 0.2594 Acc: 0.8936 | Val Loss: 0.2651 Acc: 0.8979\n",
      "Epoch 033 | Train Loss: 0.2590 Acc: 0.8954 | Val Loss: 0.2520 Acc: 0.8973\n",
      "Epoch 034 | Train Loss: 0.2397 Acc: 0.9014 | Val Loss: 0.2513 Acc: 0.8889\n",
      "Epoch 035 | Train Loss: 0.2440 Acc: 0.9031 | Val Loss: 0.2377 Acc: 0.9070\n",
      "Epoch 036 | Train Loss: 0.2371 Acc: 0.9064 | Val Loss: 0.2687 Acc: 0.8907\n",
      "Epoch 037 | Train Loss: 0.2296 Acc: 0.9118 | Val Loss: 0.2222 Acc: 0.9118\n",
      "Epoch 038 | Train Loss: 0.2122 Acc: 0.9173 | Val Loss: 0.2253 Acc: 0.9100\n",
      "Epoch 039 | Train Loss: 0.2240 Acc: 0.9162 | Val Loss: 0.2052 Acc: 0.9215\n",
      "Epoch 040 | Train Loss: 0.2015 Acc: 0.9233 | Val Loss: 0.2305 Acc: 0.9155\n",
      "Epoch 041 | Train Loss: 0.2016 Acc: 0.9194 | Val Loss: 0.2095 Acc: 0.9185\n",
      "Epoch 042 | Train Loss: 0.2017 Acc: 0.9238 | Val Loss: 0.1995 Acc: 0.9227\n",
      "Epoch 043 | Train Loss: 0.1959 Acc: 0.9234 | Val Loss: 0.1945 Acc: 0.9281\n",
      "Epoch 044 | Train Loss: 0.1792 Acc: 0.9296 | Val Loss: 0.2121 Acc: 0.9209\n",
      "Epoch 045 | Train Loss: 0.1846 Acc: 0.9271 | Val Loss: 0.2091 Acc: 0.9215\n",
      "Epoch 046 | Train Loss: 0.1829 Acc: 0.9268 | Val Loss: 0.2066 Acc: 0.9227\n",
      "Epoch 047 | Train Loss: 0.1726 Acc: 0.9339 | Val Loss: 0.2034 Acc: 0.9239\n",
      "Epoch 048 | Train Loss: 0.1640 Acc: 0.9402 | Val Loss: 0.2243 Acc: 0.9173\n",
      "Epoch 049 | Train Loss: 0.1716 Acc: 0.9301 | Val Loss: 0.1814 Acc: 0.9287\n",
      "Epoch 050 | Train Loss: 0.1696 Acc: 0.9337 | Val Loss: 0.2215 Acc: 0.9082\n",
      "Epoch 051 | Train Loss: 0.1656 Acc: 0.9384 | Val Loss: 0.2224 Acc: 0.9136\n",
      "Epoch 052 | Train Loss: 0.1594 Acc: 0.9398 | Val Loss: 0.1720 Acc: 0.9372\n",
      "Epoch 053 | Train Loss: 0.1571 Acc: 0.9398 | Val Loss: 0.2164 Acc: 0.9167\n",
      "Epoch 054 | Train Loss: 0.1580 Acc: 0.9367 | Val Loss: 0.1757 Acc: 0.9372\n",
      "Epoch 055 | Train Loss: 0.1476 Acc: 0.9428 | Val Loss: 0.1629 Acc: 0.9384\n",
      "Epoch 056 | Train Loss: 0.1485 Acc: 0.9422 | Val Loss: 0.1604 Acc: 0.9336\n",
      "Epoch 057 | Train Loss: 0.1484 Acc: 0.9432 | Val Loss: 0.1484 Acc: 0.9366\n",
      "Epoch 058 | Train Loss: 0.1331 Acc: 0.9493 | Val Loss: 0.1711 Acc: 0.9324\n",
      "Epoch 059 | Train Loss: 0.1466 Acc: 0.9441 | Val Loss: 0.1554 Acc: 0.9402\n",
      "Epoch 060 | Train Loss: 0.1372 Acc: 0.9479 | Val Loss: 0.1666 Acc: 0.9469\n",
      "Epoch 001 | Train Loss: 0.6784 Acc: 0.5816 | Val Loss: 0.6752 Acc: 0.5827\n",
      "Epoch 002 | Train Loss: 0.6666 Acc: 0.6043 | Val Loss: 0.6471 Acc: 0.6329\n",
      "Epoch 003 | Train Loss: 0.6166 Acc: 0.6717 | Val Loss: 0.6058 Acc: 0.6878\n",
      "Epoch 004 | Train Loss: 0.5674 Acc: 0.7193 | Val Loss: 0.5465 Acc: 0.7246\n",
      "Epoch 005 | Train Loss: 0.5437 Acc: 0.7359 | Val Loss: 0.5390 Acc: 0.7379\n",
      "Epoch 006 | Train Loss: 0.5253 Acc: 0.7469 | Val Loss: 0.5176 Acc: 0.7506\n",
      "Epoch 007 | Train Loss: 0.5074 Acc: 0.7598 | Val Loss: 0.5123 Acc: 0.7554\n",
      "Epoch 008 | Train Loss: 0.4810 Acc: 0.7747 | Val Loss: 0.4666 Acc: 0.7748\n",
      "Epoch 009 | Train Loss: 0.4650 Acc: 0.7814 | Val Loss: 0.4716 Acc: 0.7711\n",
      "Epoch 010 | Train Loss: 0.4355 Acc: 0.8010 | Val Loss: 0.4243 Acc: 0.8043\n",
      "Epoch 011 | Train Loss: 0.4054 Acc: 0.8164 | Val Loss: 0.4163 Acc: 0.8050\n",
      "Epoch 012 | Train Loss: 0.3982 Acc: 0.8239 | Val Loss: 0.3981 Acc: 0.8056\n",
      "Epoch 013 | Train Loss: 0.3598 Acc: 0.8389 | Val Loss: 0.3734 Acc: 0.8200\n",
      "Epoch 014 | Train Loss: 0.3353 Acc: 0.8507 | Val Loss: 0.3260 Acc: 0.8442\n",
      "Epoch 015 | Train Loss: 0.3256 Acc: 0.8597 | Val Loss: 0.3176 Acc: 0.8508\n",
      "Epoch 016 | Train Loss: 0.2993 Acc: 0.8772 | Val Loss: 0.3117 Acc: 0.8702\n",
      "Epoch 017 | Train Loss: 0.2869 Acc: 0.8775 | Val Loss: 0.2740 Acc: 0.8714\n",
      "Epoch 018 | Train Loss: 0.2741 Acc: 0.8818 | Val Loss: 0.2473 Acc: 0.8931\n",
      "Epoch 019 | Train Loss: 0.2458 Acc: 0.9029 | Val Loss: 0.2644 Acc: 0.8883\n",
      "Epoch 020 | Train Loss: 0.2358 Acc: 0.9056 | Val Loss: 0.2576 Acc: 0.8829\n",
      "Epoch 021 | Train Loss: 0.2184 Acc: 0.9115 | Val Loss: 0.2336 Acc: 0.9046\n",
      "Epoch 022 | Train Loss: 0.2153 Acc: 0.9148 | Val Loss: 0.2115 Acc: 0.9118\n",
      "Epoch 023 | Train Loss: 0.1967 Acc: 0.9215 | Val Loss: 0.2287 Acc: 0.9016\n",
      "Epoch 024 | Train Loss: 0.2005 Acc: 0.9157 | Val Loss: 0.2031 Acc: 0.9161\n",
      "Epoch 025 | Train Loss: 0.1787 Acc: 0.9298 | Val Loss: 0.2000 Acc: 0.9143\n",
      "Epoch 026 | Train Loss: 0.1714 Acc: 0.9316 | Val Loss: 0.1670 Acc: 0.9336\n",
      "Epoch 027 | Train Loss: 0.1606 Acc: 0.9401 | Val Loss: 0.1762 Acc: 0.9306\n",
      "Epoch 028 | Train Loss: 0.1569 Acc: 0.9363 | Val Loss: 0.1876 Acc: 0.9318\n",
      "Epoch 029 | Train Loss: 0.1575 Acc: 0.9372 | Val Loss: 0.1687 Acc: 0.9312\n",
      "Epoch 030 | Train Loss: 0.1366 Acc: 0.9481 | Val Loss: 0.2064 Acc: 0.9209\n",
      "Epoch 031 | Train Loss: 0.1387 Acc: 0.9444 | Val Loss: 0.1526 Acc: 0.9414\n",
      "Epoch 032 | Train Loss: 0.1405 Acc: 0.9462 | Val Loss: 0.1689 Acc: 0.9372\n",
      "Epoch 033 | Train Loss: 0.1228 Acc: 0.9544 | Val Loss: 0.1726 Acc: 0.9342\n",
      "Epoch 034 | Train Loss: 0.1249 Acc: 0.9533 | Val Loss: 0.2083 Acc: 0.9221\n",
      "Epoch 035 | Train Loss: 0.1144 Acc: 0.9570 | Val Loss: 0.1676 Acc: 0.9348\n",
      "Epoch 036 | Train Loss: 0.1115 Acc: 0.9582 | Val Loss: 0.1646 Acc: 0.9336\n",
      "Epoch 037 | Train Loss: 0.1101 Acc: 0.9588 | Val Loss: 0.1364 Acc: 0.9469\n",
      "Epoch 038 | Train Loss: 0.1029 Acc: 0.9600 | Val Loss: 0.1334 Acc: 0.9505\n",
      "Epoch 039 | Train Loss: 0.1055 Acc: 0.9597 | Val Loss: 0.1579 Acc: 0.9457\n",
      "Epoch 040 | Train Loss: 0.1032 Acc: 0.9616 | Val Loss: 0.1638 Acc: 0.9300\n",
      "Epoch 041 | Train Loss: 0.0908 Acc: 0.9663 | Val Loss: 0.1693 Acc: 0.9372\n",
      "Epoch 042 | Train Loss: 0.0954 Acc: 0.9644 | Val Loss: 0.1755 Acc: 0.9402\n",
      "Epoch 043 | Train Loss: 0.0926 Acc: 0.9659 | Val Loss: 0.1432 Acc: 0.9438\n",
      "Epoch 044 | Train Loss: 0.0966 Acc: 0.9659 | Val Loss: 0.1348 Acc: 0.9541\n",
      "Epoch 045 | Train Loss: 0.0826 Acc: 0.9704 | Val Loss: 0.1623 Acc: 0.9469\n",
      "Epoch 046 | Train Loss: 0.0866 Acc: 0.9638 | Val Loss: 0.1598 Acc: 0.9390\n",
      "Epoch 047 | Train Loss: 0.0780 Acc: 0.9686 | Val Loss: 0.1450 Acc: 0.9481\n",
      "Epoch 048 | Train Loss: 0.0830 Acc: 0.9684 | Val Loss: 0.1376 Acc: 0.9511\n",
      "Early stopping triggered.\n",
      "Epoch 001 | Train Loss: 0.6858 Acc: 0.5617 | Val Loss: 0.6836 Acc: 0.5634\n",
      "Epoch 002 | Train Loss: 0.6789 Acc: 0.5857 | Val Loss: 0.6816 Acc: 0.5731\n",
      "Epoch 003 | Train Loss: 0.6741 Acc: 0.5950 | Val Loss: 0.6697 Acc: 0.5948\n",
      "Epoch 004 | Train Loss: 0.6710 Acc: 0.5928 | Val Loss: 0.6756 Acc: 0.5942\n",
      "Epoch 005 | Train Loss: 0.6647 Acc: 0.6064 | Val Loss: 0.6271 Acc: 0.6606\n",
      "Epoch 006 | Train Loss: 0.6094 Acc: 0.6879 | Val Loss: 0.5845 Acc: 0.7005\n",
      "Epoch 007 | Train Loss: 0.5751 Acc: 0.7119 | Val Loss: 0.5571 Acc: 0.7210\n",
      "Epoch 008 | Train Loss: 0.5586 Acc: 0.7303 | Val Loss: 0.5394 Acc: 0.7391\n",
      "Epoch 009 | Train Loss: 0.5359 Acc: 0.7409 | Val Loss: 0.5362 Acc: 0.7391\n",
      "Epoch 010 | Train Loss: 0.5088 Acc: 0.7608 | Val Loss: 0.4971 Acc: 0.7657\n",
      "Epoch 011 | Train Loss: 0.4924 Acc: 0.7682 | Val Loss: 0.4852 Acc: 0.7736\n",
      "Epoch 012 | Train Loss: 0.4693 Acc: 0.7836 | Val Loss: 0.4471 Acc: 0.7995\n",
      "Epoch 013 | Train Loss: 0.4382 Acc: 0.8082 | Val Loss: 0.4386 Acc: 0.7953\n",
      "Epoch 014 | Train Loss: 0.4290 Acc: 0.8132 | Val Loss: 0.4421 Acc: 0.7947\n",
      "Epoch 015 | Train Loss: 0.4167 Acc: 0.8104 | Val Loss: 0.3967 Acc: 0.8128\n",
      "Epoch 016 | Train Loss: 0.3974 Acc: 0.8295 | Val Loss: 0.3898 Acc: 0.8255\n",
      "Epoch 017 | Train Loss: 0.3767 Acc: 0.8424 | Val Loss: 0.3717 Acc: 0.8279\n",
      "Epoch 018 | Train Loss: 0.3638 Acc: 0.8380 | Val Loss: 0.3481 Acc: 0.8430\n",
      "Epoch 019 | Train Loss: 0.3503 Acc: 0.8428 | Val Loss: 0.3589 Acc: 0.8442\n",
      "Epoch 020 | Train Loss: 0.3450 Acc: 0.8495 | Val Loss: 0.3404 Acc: 0.8599\n",
      "Epoch 021 | Train Loss: 0.3216 Acc: 0.8662 | Val Loss: 0.3358 Acc: 0.8563\n",
      "Epoch 022 | Train Loss: 0.3149 Acc: 0.8673 | Val Loss: 0.3470 Acc: 0.8521\n",
      "Epoch 023 | Train Loss: 0.3083 Acc: 0.8705 | Val Loss: 0.3208 Acc: 0.8563\n",
      "Epoch 024 | Train Loss: 0.3030 Acc: 0.8683 | Val Loss: 0.3032 Acc: 0.8804\n",
      "Epoch 025 | Train Loss: 0.2876 Acc: 0.8833 | Val Loss: 0.3058 Acc: 0.8744\n",
      "Epoch 026 | Train Loss: 0.2760 Acc: 0.8859 | Val Loss: 0.3075 Acc: 0.8696\n",
      "Epoch 027 | Train Loss: 0.2738 Acc: 0.8884 | Val Loss: 0.2849 Acc: 0.8829\n",
      "Epoch 028 | Train Loss: 0.2687 Acc: 0.8875 | Val Loss: 0.3002 Acc: 0.8732\n",
      "Epoch 029 | Train Loss: 0.2653 Acc: 0.8905 | Val Loss: 0.2664 Acc: 0.8889\n",
      "Epoch 030 | Train Loss: 0.2526 Acc: 0.8976 | Val Loss: 0.2623 Acc: 0.8925\n",
      "Epoch 031 | Train Loss: 0.2460 Acc: 0.9035 | Val Loss: 0.2913 Acc: 0.8816\n",
      "Epoch 032 | Train Loss: 0.2495 Acc: 0.8999 | Val Loss: 0.2699 Acc: 0.8835\n",
      "Epoch 033 | Train Loss: 0.2345 Acc: 0.9088 | Val Loss: 0.2518 Acc: 0.8998\n",
      "Epoch 034 | Train Loss: 0.2353 Acc: 0.9061 | Val Loss: 0.2431 Acc: 0.9022\n",
      "Epoch 035 | Train Loss: 0.2321 Acc: 0.9037 | Val Loss: 0.2504 Acc: 0.8979\n",
      "Epoch 036 | Train Loss: 0.2267 Acc: 0.9099 | Val Loss: 0.2384 Acc: 0.9052\n",
      "Epoch 037 | Train Loss: 0.2192 Acc: 0.9105 | Val Loss: 0.2386 Acc: 0.9016\n",
      "Epoch 038 | Train Loss: 0.2194 Acc: 0.9162 | Val Loss: 0.2434 Acc: 0.9028\n",
      "Epoch 039 | Train Loss: 0.2151 Acc: 0.9153 | Val Loss: 0.2695 Acc: 0.8883\n",
      "Epoch 040 | Train Loss: 0.2153 Acc: 0.9126 | Val Loss: 0.2253 Acc: 0.9052\n",
      "Epoch 041 | Train Loss: 0.2028 Acc: 0.9174 | Val Loss: 0.2146 Acc: 0.9149\n",
      "Epoch 042 | Train Loss: 0.2033 Acc: 0.9216 | Val Loss: 0.2415 Acc: 0.9016\n",
      "Epoch 043 | Train Loss: 0.2086 Acc: 0.9189 | Val Loss: 0.2009 Acc: 0.9209\n",
      "Epoch 044 | Train Loss: 0.1968 Acc: 0.9230 | Val Loss: 0.2179 Acc: 0.9052\n",
      "Epoch 045 | Train Loss: 0.1951 Acc: 0.9224 | Val Loss: 0.2309 Acc: 0.9088\n",
      "Epoch 046 | Train Loss: 0.1831 Acc: 0.9242 | Val Loss: 0.2018 Acc: 0.9161\n",
      "Epoch 047 | Train Loss: 0.2024 Acc: 0.9206 | Val Loss: 0.2175 Acc: 0.9161\n",
      "Epoch 048 | Train Loss: 0.1939 Acc: 0.9254 | Val Loss: 0.2492 Acc: 0.8943\n",
      "Epoch 049 | Train Loss: 0.1803 Acc: 0.9272 | Val Loss: 0.1921 Acc: 0.9233\n",
      "Epoch 050 | Train Loss: 0.1737 Acc: 0.9307 | Val Loss: 0.2304 Acc: 0.9155\n",
      "Epoch 051 | Train Loss: 0.1761 Acc: 0.9324 | Val Loss: 0.2178 Acc: 0.9100\n",
      "Epoch 052 | Train Loss: 0.1681 Acc: 0.9336 | Val Loss: 0.2545 Acc: 0.9130\n",
      "Epoch 053 | Train Loss: 0.1636 Acc: 0.9354 | Val Loss: 0.1910 Acc: 0.9251\n",
      "Epoch 054 | Train Loss: 0.1667 Acc: 0.9360 | Val Loss: 0.2178 Acc: 0.9106\n",
      "Epoch 055 | Train Loss: 0.1595 Acc: 0.9384 | Val Loss: 0.2381 Acc: 0.9040\n",
      "Epoch 056 | Train Loss: 0.1689 Acc: 0.9322 | Val Loss: 0.2166 Acc: 0.9221\n",
      "Epoch 057 | Train Loss: 0.1661 Acc: 0.9343 | Val Loss: 0.2641 Acc: 0.8931\n",
      "Epoch 058 | Train Loss: 0.1551 Acc: 0.9417 | Val Loss: 0.2362 Acc: 0.8986\n",
      "Epoch 059 | Train Loss: 0.1542 Acc: 0.9407 | Val Loss: 0.2225 Acc: 0.9209\n",
      "Epoch 060 | Train Loss: 0.1679 Acc: 0.9342 | Val Loss: 0.2100 Acc: 0.9173\n",
      "Epoch 001 | Train Loss: 0.6793 Acc: 0.5815 | Val Loss: 0.6792 Acc: 0.5785\n",
      "Epoch 002 | Train Loss: 0.6759 Acc: 0.5858 | Val Loss: 0.6686 Acc: 0.5948\n",
      "Epoch 003 | Train Loss: 0.6646 Acc: 0.6046 | Val Loss: 0.7011 Acc: 0.5556\n",
      "Epoch 004 | Train Loss: 0.6414 Acc: 0.6397 | Val Loss: 0.6151 Acc: 0.6715\n",
      "Epoch 005 | Train Loss: 0.6096 Acc: 0.6758 | Val Loss: 0.5955 Acc: 0.6963\n",
      "Epoch 006 | Train Loss: 0.5893 Acc: 0.6932 | Val Loss: 0.6024 Acc: 0.6546\n",
      "Epoch 007 | Train Loss: 0.5571 Acc: 0.7216 | Val Loss: 0.5537 Acc: 0.7180\n",
      "Epoch 008 | Train Loss: 0.5445 Acc: 0.7314 | Val Loss: 0.5545 Acc: 0.7228\n",
      "Epoch 009 | Train Loss: 0.5203 Acc: 0.7474 | Val Loss: 0.5443 Acc: 0.7343\n",
      "Epoch 010 | Train Loss: 0.5208 Acc: 0.7501 | Val Loss: 0.5261 Acc: 0.7397\n",
      "Epoch 011 | Train Loss: 0.4995 Acc: 0.7645 | Val Loss: 0.5174 Acc: 0.7458\n",
      "Epoch 012 | Train Loss: 0.4872 Acc: 0.7734 | Val Loss: 0.5072 Acc: 0.7452\n",
      "Epoch 013 | Train Loss: 0.4667 Acc: 0.7800 | Val Loss: 0.4998 Acc: 0.7506\n",
      "Epoch 014 | Train Loss: 0.4606 Acc: 0.7820 | Val Loss: 0.5098 Acc: 0.7639\n",
      "Epoch 015 | Train Loss: 0.4503 Acc: 0.7892 | Val Loss: 0.4518 Acc: 0.7778\n",
      "Epoch 016 | Train Loss: 0.4277 Acc: 0.8028 | Val Loss: 0.4240 Acc: 0.7941\n",
      "Epoch 017 | Train Loss: 0.4034 Acc: 0.8193 | Val Loss: 0.3955 Acc: 0.8158\n",
      "Epoch 018 | Train Loss: 0.3927 Acc: 0.8184 | Val Loss: 0.3968 Acc: 0.8043\n",
      "Epoch 019 | Train Loss: 0.3614 Acc: 0.8389 | Val Loss: 0.4189 Acc: 0.7941\n",
      "Epoch 020 | Train Loss: 0.3511 Acc: 0.8421 | Val Loss: 0.3269 Acc: 0.8551\n",
      "Epoch 021 | Train Loss: 0.3359 Acc: 0.8540 | Val Loss: 0.3526 Acc: 0.8357\n",
      "Epoch 022 | Train Loss: 0.3079 Acc: 0.8670 | Val Loss: 0.3191 Acc: 0.8581\n",
      "Epoch 023 | Train Loss: 0.2927 Acc: 0.8763 | Val Loss: 0.3019 Acc: 0.8635\n",
      "Epoch 024 | Train Loss: 0.2666 Acc: 0.8854 | Val Loss: 0.3123 Acc: 0.8708\n",
      "Epoch 025 | Train Loss: 0.2547 Acc: 0.8902 | Val Loss: 0.2838 Acc: 0.8690\n",
      "Epoch 026 | Train Loss: 0.2450 Acc: 0.8985 | Val Loss: 0.2803 Acc: 0.8804\n",
      "Epoch 027 | Train Loss: 0.2405 Acc: 0.9000 | Val Loss: 0.2576 Acc: 0.8847\n",
      "Epoch 028 | Train Loss: 0.2234 Acc: 0.9074 | Val Loss: 0.2498 Acc: 0.8943\n",
      "Epoch 029 | Train Loss: 0.2111 Acc: 0.9093 | Val Loss: 0.2344 Acc: 0.8973\n",
      "Epoch 030 | Train Loss: 0.1962 Acc: 0.9189 | Val Loss: 0.2372 Acc: 0.9058\n",
      "Epoch 031 | Train Loss: 0.1897 Acc: 0.9227 | Val Loss: 0.2168 Acc: 0.9088\n",
      "Epoch 032 | Train Loss: 0.1809 Acc: 0.9278 | Val Loss: 0.2323 Acc: 0.9094\n",
      "Epoch 033 | Train Loss: 0.1643 Acc: 0.9349 | Val Loss: 0.2068 Acc: 0.9221\n",
      "Epoch 034 | Train Loss: 0.1651 Acc: 0.9337 | Val Loss: 0.2355 Acc: 0.9022\n",
      "Epoch 035 | Train Loss: 0.1488 Acc: 0.9396 | Val Loss: 0.2118 Acc: 0.9149\n",
      "Epoch 036 | Train Loss: 0.1509 Acc: 0.9382 | Val Loss: 0.2189 Acc: 0.9155\n",
      "Epoch 037 | Train Loss: 0.1339 Acc: 0.9484 | Val Loss: 0.2175 Acc: 0.9227\n",
      "Epoch 038 | Train Loss: 0.1372 Acc: 0.9447 | Val Loss: 0.2061 Acc: 0.9173\n",
      "Epoch 039 | Train Loss: 0.1320 Acc: 0.9497 | Val Loss: 0.1964 Acc: 0.9239\n",
      "Epoch 040 | Train Loss: 0.1249 Acc: 0.9524 | Val Loss: 0.2073 Acc: 0.9191\n",
      "Epoch 041 | Train Loss: 0.1262 Acc: 0.9532 | Val Loss: 0.1947 Acc: 0.9275\n",
      "Epoch 042 | Train Loss: 0.1152 Acc: 0.9558 | Val Loss: 0.1923 Acc: 0.9275\n",
      "Epoch 043 | Train Loss: 0.1101 Acc: 0.9561 | Val Loss: 0.1933 Acc: 0.9239\n",
      "Epoch 044 | Train Loss: 0.1123 Acc: 0.9567 | Val Loss: 0.2281 Acc: 0.9215\n",
      "Epoch 045 | Train Loss: 0.1022 Acc: 0.9604 | Val Loss: 0.1906 Acc: 0.9293\n",
      "Epoch 046 | Train Loss: 0.0930 Acc: 0.9663 | Val Loss: 0.1924 Acc: 0.9318\n",
      "Epoch 047 | Train Loss: 0.1009 Acc: 0.9606 | Val Loss: 0.2528 Acc: 0.9094\n",
      "Epoch 048 | Train Loss: 0.0890 Acc: 0.9674 | Val Loss: 0.1647 Acc: 0.9444\n",
      "Epoch 049 | Train Loss: 0.0820 Acc: 0.9690 | Val Loss: 0.1776 Acc: 0.9324\n",
      "Epoch 050 | Train Loss: 0.0897 Acc: 0.9654 | Val Loss: 0.1939 Acc: 0.9324\n",
      "Epoch 051 | Train Loss: 0.0754 Acc: 0.9713 | Val Loss: 0.1913 Acc: 0.9330\n",
      "Epoch 052 | Train Loss: 0.0756 Acc: 0.9722 | Val Loss: 0.1539 Acc: 0.9414\n",
      "Epoch 053 | Train Loss: 0.0818 Acc: 0.9700 | Val Loss: 0.1527 Acc: 0.9499\n",
      "Epoch 054 | Train Loss: 0.0827 Acc: 0.9692 | Val Loss: 0.1687 Acc: 0.9396\n",
      "Epoch 055 | Train Loss: 0.0741 Acc: 0.9718 | Val Loss: 0.1743 Acc: 0.9408\n",
      "Epoch 056 | Train Loss: 0.0611 Acc: 0.9761 | Val Loss: 0.1624 Acc: 0.9475\n",
      "Epoch 057 | Train Loss: 0.0764 Acc: 0.9716 | Val Loss: 0.2005 Acc: 0.9287\n",
      "Epoch 058 | Train Loss: 0.0682 Acc: 0.9761 | Val Loss: 0.1436 Acc: 0.9475\n",
      "Epoch 059 | Train Loss: 0.0649 Acc: 0.9754 | Val Loss: 0.1669 Acc: 0.9372\n",
      "Epoch 060 | Train Loss: 0.0568 Acc: 0.9792 | Val Loss: 0.1755 Acc: 0.9396\n",
      "Epoch 001 | Train Loss: 0.6803 Acc: 0.5806 | Val Loss: 0.6752 Acc: 0.5954\n",
      "Epoch 002 | Train Loss: 0.6718 Acc: 0.5976 | Val Loss: 0.6662 Acc: 0.6033\n",
      "Epoch 003 | Train Loss: 0.6628 Acc: 0.6083 | Val Loss: 0.6578 Acc: 0.6069\n",
      "Epoch 004 | Train Loss: 0.6173 Acc: 0.6674 | Val Loss: 0.5927 Acc: 0.6975\n",
      "Epoch 005 | Train Loss: 0.5632 Acc: 0.7187 | Val Loss: 0.5648 Acc: 0.7150\n",
      "Epoch 006 | Train Loss: 0.5465 Acc: 0.7337 | Val Loss: 0.5364 Acc: 0.7301\n",
      "Epoch 007 | Train Loss: 0.5173 Acc: 0.7468 | Val Loss: 0.5227 Acc: 0.7379\n",
      "Epoch 008 | Train Loss: 0.4908 Acc: 0.7667 | Val Loss: 0.5016 Acc: 0.7591\n",
      "Epoch 009 | Train Loss: 0.4789 Acc: 0.7783 | Val Loss: 0.4857 Acc: 0.7609\n",
      "Epoch 010 | Train Loss: 0.4542 Acc: 0.7897 | Val Loss: 0.4449 Acc: 0.7814\n",
      "Epoch 011 | Train Loss: 0.4139 Acc: 0.8081 | Val Loss: 0.4301 Acc: 0.7880\n",
      "Epoch 012 | Train Loss: 0.4012 Acc: 0.8159 | Val Loss: 0.3902 Acc: 0.8261\n",
      "Epoch 013 | Train Loss: 0.3754 Acc: 0.8323 | Val Loss: 0.3476 Acc: 0.8442\n",
      "Epoch 014 | Train Loss: 0.3573 Acc: 0.8446 | Val Loss: 0.3344 Acc: 0.8490\n",
      "Epoch 015 | Train Loss: 0.3313 Acc: 0.8582 | Val Loss: 0.3175 Acc: 0.8659\n",
      "Epoch 016 | Train Loss: 0.3181 Acc: 0.8620 | Val Loss: 0.3005 Acc: 0.8659\n",
      "Epoch 017 | Train Loss: 0.2974 Acc: 0.8757 | Val Loss: 0.2811 Acc: 0.8780\n",
      "Epoch 018 | Train Loss: 0.2950 Acc: 0.8774 | Val Loss: 0.2931 Acc: 0.8738\n",
      "Epoch 019 | Train Loss: 0.2739 Acc: 0.8916 | Val Loss: 0.2631 Acc: 0.8883\n",
      "Epoch 020 | Train Loss: 0.2528 Acc: 0.9013 | Val Loss: 0.2506 Acc: 0.8961\n",
      "Epoch 021 | Train Loss: 0.2390 Acc: 0.9056 | Val Loss: 0.2415 Acc: 0.9022\n",
      "Epoch 022 | Train Loss: 0.2318 Acc: 0.9059 | Val Loss: 0.2227 Acc: 0.9046\n",
      "Epoch 023 | Train Loss: 0.2222 Acc: 0.9138 | Val Loss: 0.2211 Acc: 0.9070\n",
      "Epoch 024 | Train Loss: 0.2126 Acc: 0.9142 | Val Loss: 0.2311 Acc: 0.9130\n",
      "Epoch 025 | Train Loss: 0.2045 Acc: 0.9194 | Val Loss: 0.2287 Acc: 0.9010\n",
      "Epoch 026 | Train Loss: 0.1925 Acc: 0.9238 | Val Loss: 0.2174 Acc: 0.9088\n",
      "Epoch 027 | Train Loss: 0.2053 Acc: 0.9179 | Val Loss: 0.2273 Acc: 0.9052\n",
      "Epoch 028 | Train Loss: 0.1942 Acc: 0.9253 | Val Loss: 0.1880 Acc: 0.9209\n",
      "Epoch 029 | Train Loss: 0.1805 Acc: 0.9299 | Val Loss: 0.1872 Acc: 0.9221\n",
      "Epoch 030 | Train Loss: 0.1725 Acc: 0.9327 | Val Loss: 0.1666 Acc: 0.9330\n",
      "Epoch 031 | Train Loss: 0.1694 Acc: 0.9355 | Val Loss: 0.1741 Acc: 0.9275\n",
      "Epoch 032 | Train Loss: 0.1601 Acc: 0.9360 | Val Loss: 0.2066 Acc: 0.9239\n",
      "Epoch 033 | Train Loss: 0.1568 Acc: 0.9411 | Val Loss: 0.1736 Acc: 0.9330\n",
      "Epoch 034 | Train Loss: 0.1539 Acc: 0.9393 | Val Loss: 0.1945 Acc: 0.9275\n",
      "Epoch 035 | Train Loss: 0.1500 Acc: 0.9444 | Val Loss: 0.1678 Acc: 0.9372\n",
      "Epoch 036 | Train Loss: 0.1377 Acc: 0.9485 | Val Loss: 0.1580 Acc: 0.9354\n",
      "Epoch 037 | Train Loss: 0.1370 Acc: 0.9493 | Val Loss: 0.2222 Acc: 0.9239\n",
      "Epoch 038 | Train Loss: 0.1443 Acc: 0.9428 | Val Loss: 0.1725 Acc: 0.9330\n",
      "Epoch 039 | Train Loss: 0.1227 Acc: 0.9524 | Val Loss: 0.1997 Acc: 0.9239\n",
      "Epoch 040 | Train Loss: 0.1339 Acc: 0.9503 | Val Loss: 0.1614 Acc: 0.9372\n",
      "Epoch 041 | Train Loss: 0.1355 Acc: 0.9476 | Val Loss: 0.1584 Acc: 0.9360\n",
      "Epoch 042 | Train Loss: 0.1177 Acc: 0.9567 | Val Loss: 0.1692 Acc: 0.9354\n",
      "Epoch 043 | Train Loss: 0.1309 Acc: 0.9496 | Val Loss: 0.1550 Acc: 0.9372\n",
      "Epoch 044 | Train Loss: 0.1157 Acc: 0.9544 | Val Loss: 0.1790 Acc: 0.9348\n",
      "Epoch 045 | Train Loss: 0.1182 Acc: 0.9574 | Val Loss: 0.1583 Acc: 0.9390\n",
      "Epoch 046 | Train Loss: 0.1231 Acc: 0.9515 | Val Loss: 0.1680 Acc: 0.9287\n",
      "Epoch 047 | Train Loss: 0.1057 Acc: 0.9597 | Val Loss: 0.1764 Acc: 0.9384\n",
      "Epoch 048 | Train Loss: 0.1119 Acc: 0.9573 | Val Loss: 0.1458 Acc: 0.9444\n",
      "Epoch 049 | Train Loss: 0.1196 Acc: 0.9559 | Val Loss: 0.1943 Acc: 0.9221\n",
      "Epoch 050 | Train Loss: 0.1101 Acc: 0.9583 | Val Loss: 0.1587 Acc: 0.9372\n",
      "Epoch 051 | Train Loss: 0.1143 Acc: 0.9576 | Val Loss: 0.1473 Acc: 0.9469\n",
      "Epoch 052 | Train Loss: 0.1014 Acc: 0.9629 | Val Loss: 0.1368 Acc: 0.9553\n",
      "Epoch 053 | Train Loss: 0.1075 Acc: 0.9606 | Val Loss: 0.1474 Acc: 0.9463\n",
      "Epoch 054 | Train Loss: 0.1067 Acc: 0.9636 | Val Loss: 0.1418 Acc: 0.9438\n",
      "Epoch 055 | Train Loss: 0.1031 Acc: 0.9601 | Val Loss: 0.1353 Acc: 0.9450\n",
      "Epoch 056 | Train Loss: 0.0901 Acc: 0.9660 | Val Loss: 0.1531 Acc: 0.9408\n",
      "Epoch 057 | Train Loss: 0.0977 Acc: 0.9642 | Val Loss: 0.1396 Acc: 0.9414\n",
      "Epoch 058 | Train Loss: 0.0969 Acc: 0.9624 | Val Loss: 0.1537 Acc: 0.9414\n",
      "Epoch 059 | Train Loss: 0.1008 Acc: 0.9604 | Val Loss: 0.1276 Acc: 0.9505\n",
      "Epoch 060 | Train Loss: 0.1002 Acc: 0.9629 | Val Loss: 0.1423 Acc: 0.9487\n",
      "Epoch 001 | Train Loss: 0.6805 Acc: 0.5757 | Val Loss: 0.6757 Acc: 0.5882\n",
      "Epoch 002 | Train Loss: 0.6679 Acc: 0.6043 | Val Loss: 0.6800 Acc: 0.5731\n",
      "Epoch 003 | Train Loss: 0.6602 Acc: 0.6127 | Val Loss: 0.6301 Acc: 0.6618\n",
      "Epoch 004 | Train Loss: 0.6323 Acc: 0.6551 | Val Loss: 0.6087 Acc: 0.6926\n",
      "Epoch 005 | Train Loss: 0.5866 Acc: 0.7059 | Val Loss: 0.5732 Acc: 0.7168\n",
      "Epoch 006 | Train Loss: 0.5592 Acc: 0.7238 | Val Loss: 0.5638 Acc: 0.7162\n",
      "Epoch 007 | Train Loss: 0.5412 Acc: 0.7383 | Val Loss: 0.5423 Acc: 0.7246\n",
      "Epoch 008 | Train Loss: 0.5093 Acc: 0.7527 | Val Loss: 0.5368 Acc: 0.7271\n",
      "Epoch 009 | Train Loss: 0.4959 Acc: 0.7713 | Val Loss: 0.4937 Acc: 0.7566\n",
      "Epoch 010 | Train Loss: 0.4721 Acc: 0.7833 | Val Loss: 0.4788 Acc: 0.7669\n",
      "Epoch 011 | Train Loss: 0.4574 Acc: 0.7897 | Val Loss: 0.4399 Acc: 0.7941\n",
      "Epoch 012 | Train Loss: 0.4309 Acc: 0.8016 | Val Loss: 0.4179 Acc: 0.8092\n",
      "Epoch 013 | Train Loss: 0.4133 Acc: 0.8111 | Val Loss: 0.3986 Acc: 0.8146\n",
      "Epoch 014 | Train Loss: 0.3966 Acc: 0.8229 | Val Loss: 0.3732 Acc: 0.8394\n",
      "Epoch 015 | Train Loss: 0.3584 Acc: 0.8422 | Val Loss: 0.3972 Acc: 0.8213\n",
      "Epoch 016 | Train Loss: 0.3449 Acc: 0.8489 | Val Loss: 0.3263 Acc: 0.8557\n",
      "Epoch 017 | Train Loss: 0.3138 Acc: 0.8596 | Val Loss: 0.3074 Acc: 0.8653\n",
      "Epoch 018 | Train Loss: 0.2889 Acc: 0.8782 | Val Loss: 0.2820 Acc: 0.8798\n",
      "Epoch 019 | Train Loss: 0.2753 Acc: 0.8834 | Val Loss: 0.2902 Acc: 0.8708\n",
      "Epoch 020 | Train Loss: 0.2597 Acc: 0.8908 | Val Loss: 0.2846 Acc: 0.8841\n",
      "Epoch 021 | Train Loss: 0.2314 Acc: 0.9064 | Val Loss: 0.2657 Acc: 0.8859\n",
      "Epoch 022 | Train Loss: 0.2162 Acc: 0.9121 | Val Loss: 0.2312 Acc: 0.9082\n",
      "Epoch 023 | Train Loss: 0.2164 Acc: 0.9093 | Val Loss: 0.2424 Acc: 0.8992\n",
      "Epoch 024 | Train Loss: 0.1984 Acc: 0.9192 | Val Loss: 0.2147 Acc: 0.9185\n",
      "Epoch 025 | Train Loss: 0.1814 Acc: 0.9250 | Val Loss: 0.2155 Acc: 0.9106\n",
      "Epoch 026 | Train Loss: 0.1771 Acc: 0.9289 | Val Loss: 0.2200 Acc: 0.9118\n",
      "Epoch 027 | Train Loss: 0.1694 Acc: 0.9330 | Val Loss: 0.2038 Acc: 0.9233\n",
      "Epoch 028 | Train Loss: 0.1553 Acc: 0.9381 | Val Loss: 0.1987 Acc: 0.9227\n",
      "Epoch 029 | Train Loss: 0.1491 Acc: 0.9432 | Val Loss: 0.2207 Acc: 0.9124\n",
      "Epoch 030 | Train Loss: 0.1414 Acc: 0.9465 | Val Loss: 0.2499 Acc: 0.9010\n",
      "Epoch 031 | Train Loss: 0.1405 Acc: 0.9472 | Val Loss: 0.1891 Acc: 0.9275\n",
      "Epoch 032 | Train Loss: 0.1335 Acc: 0.9465 | Val Loss: 0.1913 Acc: 0.9300\n",
      "Epoch 033 | Train Loss: 0.1315 Acc: 0.9527 | Val Loss: 0.1643 Acc: 0.9324\n",
      "Epoch 034 | Train Loss: 0.1167 Acc: 0.9570 | Val Loss: 0.2309 Acc: 0.9149\n",
      "Epoch 035 | Train Loss: 0.1211 Acc: 0.9511 | Val Loss: 0.2299 Acc: 0.9143\n",
      "Epoch 036 | Train Loss: 0.1132 Acc: 0.9574 | Val Loss: 0.2011 Acc: 0.9227\n",
      "Epoch 037 | Train Loss: 0.1186 Acc: 0.9556 | Val Loss: 0.2188 Acc: 0.9203\n",
      "Epoch 038 | Train Loss: 0.1041 Acc: 0.9633 | Val Loss: 0.1728 Acc: 0.9372\n",
      "Epoch 039 | Train Loss: 0.0990 Acc: 0.9607 | Val Loss: 0.2183 Acc: 0.9233\n",
      "Epoch 040 | Train Loss: 0.0998 Acc: 0.9620 | Val Loss: 0.2380 Acc: 0.9136\n",
      "Epoch 041 | Train Loss: 0.1018 Acc: 0.9595 | Val Loss: 0.1874 Acc: 0.9390\n",
      "Epoch 042 | Train Loss: 0.0997 Acc: 0.9600 | Val Loss: 0.1671 Acc: 0.9372\n",
      "Epoch 043 | Train Loss: 0.0921 Acc: 0.9644 | Val Loss: 0.1991 Acc: 0.9263\n",
      "Early stopping triggered.\n",
      "Epoch 001 | Train Loss: 0.6808 Acc: 0.5803 | Val Loss: 0.6758 Acc: 0.5833\n",
      "Epoch 002 | Train Loss: 0.6700 Acc: 0.5961 | Val Loss: 0.6696 Acc: 0.5954\n",
      "Epoch 003 | Train Loss: 0.6788 Acc: 0.5756 | Val Loss: 0.6736 Acc: 0.5815\n",
      "Epoch 004 | Train Loss: 0.6447 Acc: 0.6379 | Val Loss: 0.6189 Acc: 0.6594\n",
      "Epoch 005 | Train Loss: 0.6008 Acc: 0.6909 | Val Loss: 0.5907 Acc: 0.6848\n",
      "Epoch 006 | Train Loss: 0.5838 Acc: 0.7059 | Val Loss: 0.5854 Acc: 0.6890\n",
      "Epoch 007 | Train Loss: 0.5717 Acc: 0.7178 | Val Loss: 0.5605 Acc: 0.7162\n",
      "Epoch 008 | Train Loss: 0.5475 Acc: 0.7273 | Val Loss: 0.5394 Acc: 0.7343\n",
      "Epoch 009 | Train Loss: 0.5325 Acc: 0.7412 | Val Loss: 0.5454 Acc: 0.7319\n",
      "Epoch 010 | Train Loss: 0.5223 Acc: 0.7465 | Val Loss: 0.5436 Acc: 0.7283\n",
      "Epoch 011 | Train Loss: 0.5071 Acc: 0.7521 | Val Loss: 0.5062 Acc: 0.7524\n",
      "Epoch 012 | Train Loss: 0.4876 Acc: 0.7646 | Val Loss: 0.5007 Acc: 0.7591\n",
      "Epoch 013 | Train Loss: 0.4736 Acc: 0.7749 | Val Loss: 0.4832 Acc: 0.7687\n",
      "Epoch 014 | Train Loss: 0.4625 Acc: 0.7847 | Val Loss: 0.4608 Acc: 0.7911\n",
      "Epoch 015 | Train Loss: 0.4416 Acc: 0.7904 | Val Loss: 0.4285 Acc: 0.7971\n",
      "Epoch 016 | Train Loss: 0.4255 Acc: 0.8073 | Val Loss: 0.4206 Acc: 0.8080\n",
      "Epoch 017 | Train Loss: 0.4194 Acc: 0.8093 | Val Loss: 0.3940 Acc: 0.8122\n",
      "Epoch 018 | Train Loss: 0.4005 Acc: 0.8149 | Val Loss: 0.3852 Acc: 0.8303\n",
      "Epoch 019 | Train Loss: 0.3911 Acc: 0.8238 | Val Loss: 0.3754 Acc: 0.8357\n",
      "Epoch 020 | Train Loss: 0.3637 Acc: 0.8384 | Val Loss: 0.3177 Acc: 0.8647\n",
      "Epoch 021 | Train Loss: 0.3558 Acc: 0.8421 | Val Loss: 0.3956 Acc: 0.8146\n",
      "Epoch 022 | Train Loss: 0.3417 Acc: 0.8520 | Val Loss: 0.3030 Acc: 0.8732\n",
      "Epoch 023 | Train Loss: 0.3295 Acc: 0.8621 | Val Loss: 0.3031 Acc: 0.8678\n",
      "Epoch 024 | Train Loss: 0.3182 Acc: 0.8641 | Val Loss: 0.3196 Acc: 0.8635\n",
      "Epoch 025 | Train Loss: 0.3089 Acc: 0.8701 | Val Loss: 0.2876 Acc: 0.8762\n",
      "Epoch 026 | Train Loss: 0.2980 Acc: 0.8783 | Val Loss: 0.2733 Acc: 0.8853\n",
      "Epoch 027 | Train Loss: 0.2928 Acc: 0.8782 | Val Loss: 0.2530 Acc: 0.8925\n",
      "Epoch 028 | Train Loss: 0.2798 Acc: 0.8895 | Val Loss: 0.2492 Acc: 0.8955\n",
      "Epoch 029 | Train Loss: 0.2672 Acc: 0.8922 | Val Loss: 0.2577 Acc: 0.8907\n",
      "Epoch 030 | Train Loss: 0.2667 Acc: 0.8933 | Val Loss: 0.2422 Acc: 0.9016\n",
      "Epoch 031 | Train Loss: 0.2670 Acc: 0.8919 | Val Loss: 0.2557 Acc: 0.8931\n",
      "Epoch 032 | Train Loss: 0.2530 Acc: 0.8969 | Val Loss: 0.2415 Acc: 0.8979\n",
      "Epoch 033 | Train Loss: 0.2492 Acc: 0.8985 | Val Loss: 0.2451 Acc: 0.9046\n",
      "Epoch 034 | Train Loss: 0.2404 Acc: 0.9035 | Val Loss: 0.2302 Acc: 0.9136\n",
      "Epoch 035 | Train Loss: 0.2424 Acc: 0.9035 | Val Loss: 0.2256 Acc: 0.9058\n",
      "Epoch 036 | Train Loss: 0.2270 Acc: 0.9083 | Val Loss: 0.2854 Acc: 0.8774\n",
      "Epoch 037 | Train Loss: 0.2323 Acc: 0.9034 | Val Loss: 0.2473 Acc: 0.9022\n",
      "Epoch 038 | Train Loss: 0.2161 Acc: 0.9136 | Val Loss: 0.2110 Acc: 0.9143\n",
      "Epoch 039 | Train Loss: 0.2197 Acc: 0.9099 | Val Loss: 0.2345 Acc: 0.8973\n",
      "Epoch 040 | Train Loss: 0.2185 Acc: 0.9114 | Val Loss: 0.2328 Acc: 0.9070\n",
      "Epoch 041 | Train Loss: 0.2076 Acc: 0.9167 | Val Loss: 0.2277 Acc: 0.9088\n",
      "Epoch 042 | Train Loss: 0.2088 Acc: 0.9197 | Val Loss: 0.2349 Acc: 0.9064\n",
      "Epoch 043 | Train Loss: 0.1957 Acc: 0.9253 | Val Loss: 0.2054 Acc: 0.9215\n",
      "Epoch 044 | Train Loss: 0.2092 Acc: 0.9183 | Val Loss: 0.2087 Acc: 0.9209\n",
      "Epoch 045 | Train Loss: 0.1847 Acc: 0.9268 | Val Loss: 0.2107 Acc: 0.9203\n",
      "Epoch 046 | Train Loss: 0.1926 Acc: 0.9247 | Val Loss: 0.1869 Acc: 0.9269\n",
      "Epoch 047 | Train Loss: 0.1887 Acc: 0.9296 | Val Loss: 0.1931 Acc: 0.9263\n",
      "Epoch 048 | Train Loss: 0.1887 Acc: 0.9233 | Val Loss: 0.1976 Acc: 0.9191\n",
      "Epoch 049 | Train Loss: 0.1861 Acc: 0.9272 | Val Loss: 0.2214 Acc: 0.9058\n",
      "Epoch 050 | Train Loss: 0.1758 Acc: 0.9311 | Val Loss: 0.1947 Acc: 0.9269\n",
      "Epoch 051 | Train Loss: 0.1768 Acc: 0.9316 | Val Loss: 0.1838 Acc: 0.9281\n",
      "Epoch 052 | Train Loss: 0.1655 Acc: 0.9390 | Val Loss: 0.1975 Acc: 0.9215\n",
      "Epoch 053 | Train Loss: 0.1731 Acc: 0.9360 | Val Loss: 0.2146 Acc: 0.9136\n",
      "Epoch 054 | Train Loss: 0.1566 Acc: 0.9425 | Val Loss: 0.1586 Acc: 0.9390\n",
      "Epoch 055 | Train Loss: 0.1560 Acc: 0.9387 | Val Loss: 0.1616 Acc: 0.9372\n",
      "Epoch 056 | Train Loss: 0.1599 Acc: 0.9375 | Val Loss: 0.1745 Acc: 0.9318\n",
      "Epoch 057 | Train Loss: 0.1717 Acc: 0.9354 | Val Loss: 0.1747 Acc: 0.9384\n",
      "Epoch 058 | Train Loss: 0.1485 Acc: 0.9441 | Val Loss: 0.1659 Acc: 0.9372\n",
      "Epoch 059 | Train Loss: 0.1445 Acc: 0.9426 | Val Loss: 0.1734 Acc: 0.9348\n",
      "Epoch 060 | Train Loss: 0.1602 Acc: 0.9396 | Val Loss: 0.2088 Acc: 0.9173\n",
      "Iteration 15/40 | Best Val Loss: 0.1122 | Iter Time: 212.18s | Total Time: 68.13 min\n",
      "Epoch 001 | Train Loss: 0.6801 Acc: 0.5753 | Val Loss: 0.6780 Acc: 0.5845\n",
      "Epoch 002 | Train Loss: 0.6739 Acc: 0.5907 | Val Loss: 0.6697 Acc: 0.5978\n",
      "Epoch 003 | Train Loss: 0.6636 Acc: 0.6038 | Val Loss: 0.6685 Acc: 0.5851\n",
      "Epoch 004 | Train Loss: 0.6547 Acc: 0.6153 | Val Loss: 0.6424 Acc: 0.6425\n",
      "Epoch 005 | Train Loss: 0.6168 Acc: 0.6764 | Val Loss: 0.5933 Acc: 0.6950\n",
      "Epoch 006 | Train Loss: 0.5749 Acc: 0.7090 | Val Loss: 0.5673 Acc: 0.7144\n",
      "Epoch 007 | Train Loss: 0.5519 Acc: 0.7308 | Val Loss: 0.5391 Acc: 0.7283\n",
      "Epoch 008 | Train Loss: 0.5299 Acc: 0.7448 | Val Loss: 0.5431 Acc: 0.7313\n",
      "Epoch 009 | Train Loss: 0.5039 Acc: 0.7598 | Val Loss: 0.5278 Acc: 0.7325\n",
      "Epoch 010 | Train Loss: 0.4796 Acc: 0.7765 | Val Loss: 0.4700 Acc: 0.7796\n",
      "Epoch 011 | Train Loss: 0.4583 Acc: 0.7874 | Val Loss: 0.4587 Acc: 0.7784\n",
      "Epoch 012 | Train Loss: 0.4313 Acc: 0.8049 | Val Loss: 0.4451 Acc: 0.7850\n",
      "Epoch 013 | Train Loss: 0.4142 Acc: 0.8147 | Val Loss: 0.3966 Acc: 0.8207\n",
      "Epoch 014 | Train Loss: 0.3790 Acc: 0.8330 | Val Loss: 0.3901 Acc: 0.8243\n",
      "Epoch 015 | Train Loss: 0.3630 Acc: 0.8419 | Val Loss: 0.3491 Acc: 0.8442\n",
      "Epoch 016 | Train Loss: 0.3317 Acc: 0.8501 | Val Loss: 0.3440 Acc: 0.8424\n",
      "Epoch 017 | Train Loss: 0.3077 Acc: 0.8703 | Val Loss: 0.3306 Acc: 0.8527\n",
      "Epoch 018 | Train Loss: 0.2915 Acc: 0.8792 | Val Loss: 0.3066 Acc: 0.8696\n",
      "Epoch 019 | Train Loss: 0.2829 Acc: 0.8833 | Val Loss: 0.2820 Acc: 0.8744\n",
      "Epoch 020 | Train Loss: 0.2436 Acc: 0.8996 | Val Loss: 0.2485 Acc: 0.9016\n",
      "Epoch 021 | Train Loss: 0.2188 Acc: 0.9112 | Val Loss: 0.2794 Acc: 0.8865\n",
      "Epoch 022 | Train Loss: 0.2068 Acc: 0.9213 | Val Loss: 0.2245 Acc: 0.9112\n",
      "Epoch 023 | Train Loss: 0.1857 Acc: 0.9263 | Val Loss: 0.2063 Acc: 0.9215\n",
      "Epoch 024 | Train Loss: 0.1749 Acc: 0.9272 | Val Loss: 0.2118 Acc: 0.9167\n",
      "Epoch 025 | Train Loss: 0.1542 Acc: 0.9419 | Val Loss: 0.3037 Acc: 0.8871\n",
      "Epoch 026 | Train Loss: 0.1556 Acc: 0.9401 | Val Loss: 0.1862 Acc: 0.9306\n",
      "Epoch 027 | Train Loss: 0.1419 Acc: 0.9447 | Val Loss: 0.1901 Acc: 0.9330\n",
      "Epoch 028 | Train Loss: 0.1348 Acc: 0.9473 | Val Loss: 0.1886 Acc: 0.9318\n",
      "Epoch 029 | Train Loss: 0.1254 Acc: 0.9524 | Val Loss: 0.1836 Acc: 0.9287\n",
      "Epoch 030 | Train Loss: 0.1225 Acc: 0.9538 | Val Loss: 0.1843 Acc: 0.9318\n",
      "Epoch 031 | Train Loss: 0.1206 Acc: 0.9555 | Val Loss: 0.2113 Acc: 0.9136\n",
      "Epoch 032 | Train Loss: 0.1013 Acc: 0.9624 | Val Loss: 0.2007 Acc: 0.9215\n",
      "Epoch 033 | Train Loss: 0.1021 Acc: 0.9624 | Val Loss: 0.1689 Acc: 0.9402\n",
      "Epoch 034 | Train Loss: 0.0870 Acc: 0.9674 | Val Loss: 0.1784 Acc: 0.9372\n",
      "Epoch 035 | Train Loss: 0.0948 Acc: 0.9651 | Val Loss: 0.1677 Acc: 0.9426\n",
      "Epoch 036 | Train Loss: 0.0790 Acc: 0.9719 | Val Loss: 0.1777 Acc: 0.9360\n",
      "Epoch 037 | Train Loss: 0.0833 Acc: 0.9703 | Val Loss: 0.1702 Acc: 0.9438\n",
      "Epoch 038 | Train Loss: 0.0780 Acc: 0.9701 | Val Loss: 0.1794 Acc: 0.9366\n",
      "Epoch 039 | Train Loss: 0.0789 Acc: 0.9713 | Val Loss: 0.1690 Acc: 0.9432\n",
      "Epoch 040 | Train Loss: 0.0775 Acc: 0.9724 | Val Loss: 0.1560 Acc: 0.9457\n",
      "Epoch 041 | Train Loss: 0.0727 Acc: 0.9724 | Val Loss: 0.1749 Acc: 0.9426\n",
      "Epoch 042 | Train Loss: 0.0761 Acc: 0.9707 | Val Loss: 0.1585 Acc: 0.9463\n",
      "Epoch 043 | Train Loss: 0.0549 Acc: 0.9798 | Val Loss: 0.1576 Acc: 0.9487\n",
      "Epoch 044 | Train Loss: 0.0680 Acc: 0.9751 | Val Loss: 0.1648 Acc: 0.9505\n",
      "Epoch 045 | Train Loss: 0.0610 Acc: 0.9767 | Val Loss: 0.1560 Acc: 0.9505\n",
      "Epoch 046 | Train Loss: 0.0604 Acc: 0.9777 | Val Loss: 0.1574 Acc: 0.9505\n",
      "Epoch 047 | Train Loss: 0.0569 Acc: 0.9790 | Val Loss: 0.1981 Acc: 0.9438\n",
      "Epoch 048 | Train Loss: 0.0515 Acc: 0.9798 | Val Loss: 0.1768 Acc: 0.9438\n",
      "Epoch 049 | Train Loss: 0.0607 Acc: 0.9781 | Val Loss: 0.1869 Acc: 0.9402\n",
      "Epoch 050 | Train Loss: 0.0589 Acc: 0.9777 | Val Loss: 0.1956 Acc: 0.9438\n",
      "Early stopping triggered.\n",
      "Epoch 001 | Train Loss: 0.6806 Acc: 0.5756 | Val Loss: 0.6757 Acc: 0.5839\n",
      "Epoch 002 | Train Loss: 0.6709 Acc: 0.6009 | Val Loss: 0.7050 Acc: 0.5580\n",
      "Epoch 003 | Train Loss: 0.6605 Acc: 0.6109 | Val Loss: 0.6351 Acc: 0.6473\n",
      "Epoch 004 | Train Loss: 0.6401 Acc: 0.6539 | Val Loss: 0.6775 Acc: 0.5737\n",
      "Epoch 005 | Train Loss: 0.6343 Acc: 0.6628 | Val Loss: 0.6467 Acc: 0.6449\n",
      "Epoch 006 | Train Loss: 0.5981 Acc: 0.7013 | Val Loss: 0.5685 Acc: 0.7174\n",
      "Epoch 007 | Train Loss: 0.5636 Acc: 0.7264 | Val Loss: 0.5563 Acc: 0.7264\n",
      "Epoch 008 | Train Loss: 0.5526 Acc: 0.7290 | Val Loss: 0.5578 Acc: 0.7325\n",
      "Epoch 009 | Train Loss: 0.5354 Acc: 0.7436 | Val Loss: 0.5404 Acc: 0.7337\n",
      "Epoch 010 | Train Loss: 0.5241 Acc: 0.7507 | Val Loss: 0.5317 Acc: 0.7349\n",
      "Epoch 011 | Train Loss: 0.5174 Acc: 0.7552 | Val Loss: 0.5257 Acc: 0.7440\n",
      "Epoch 012 | Train Loss: 0.5253 Acc: 0.7471 | Val Loss: 0.5693 Acc: 0.7132\n",
      "Epoch 013 | Train Loss: 0.5021 Acc: 0.7629 | Val Loss: 0.5034 Acc: 0.7548\n",
      "Epoch 014 | Train Loss: 0.4872 Acc: 0.7640 | Val Loss: 0.4817 Acc: 0.7651\n",
      "Epoch 015 | Train Loss: 0.4854 Acc: 0.7753 | Val Loss: 0.4883 Acc: 0.7711\n",
      "Epoch 016 | Train Loss: 0.4634 Acc: 0.7909 | Val Loss: 0.4493 Acc: 0.7856\n",
      "Epoch 017 | Train Loss: 0.4575 Acc: 0.7877 | Val Loss: 0.4550 Acc: 0.7874\n",
      "Epoch 018 | Train Loss: 0.4370 Acc: 0.7986 | Val Loss: 0.4300 Acc: 0.7965\n",
      "Epoch 019 | Train Loss: 0.4353 Acc: 0.7966 | Val Loss: 0.4413 Acc: 0.8031\n",
      "Epoch 020 | Train Loss: 0.4178 Acc: 0.8123 | Val Loss: 0.4543 Acc: 0.8037\n",
      "Epoch 021 | Train Loss: 0.4136 Acc: 0.8140 | Val Loss: 0.3813 Acc: 0.8255\n",
      "Epoch 022 | Train Loss: 0.3896 Acc: 0.8253 | Val Loss: 0.3818 Acc: 0.8237\n",
      "Epoch 023 | Train Loss: 0.3782 Acc: 0.8319 | Val Loss: 0.3682 Acc: 0.8291\n",
      "Epoch 024 | Train Loss: 0.3745 Acc: 0.8357 | Val Loss: 0.3565 Acc: 0.8309\n",
      "Epoch 025 | Train Loss: 0.3612 Acc: 0.8430 | Val Loss: 0.3525 Acc: 0.8370\n",
      "Epoch 026 | Train Loss: 0.3463 Acc: 0.8496 | Val Loss: 0.3407 Acc: 0.8490\n",
      "Epoch 027 | Train Loss: 0.3278 Acc: 0.8593 | Val Loss: 0.3072 Acc: 0.8684\n",
      "Epoch 028 | Train Loss: 0.3266 Acc: 0.8635 | Val Loss: 0.3258 Acc: 0.8617\n",
      "Epoch 029 | Train Loss: 0.3077 Acc: 0.8744 | Val Loss: 0.2710 Acc: 0.8889\n",
      "Epoch 030 | Train Loss: 0.3005 Acc: 0.8748 | Val Loss: 0.2929 Acc: 0.8786\n",
      "Epoch 031 | Train Loss: 0.2914 Acc: 0.8831 | Val Loss: 0.2753 Acc: 0.8865\n",
      "Epoch 032 | Train Loss: 0.2788 Acc: 0.8837 | Val Loss: 0.2733 Acc: 0.8853\n",
      "Epoch 033 | Train Loss: 0.2670 Acc: 0.8937 | Val Loss: 0.2797 Acc: 0.8865\n",
      "Epoch 034 | Train Loss: 0.2544 Acc: 0.8961 | Val Loss: 0.2626 Acc: 0.9016\n",
      "Epoch 035 | Train Loss: 0.2620 Acc: 0.8973 | Val Loss: 0.2642 Acc: 0.8901\n",
      "Epoch 036 | Train Loss: 0.2492 Acc: 0.8978 | Val Loss: 0.2323 Acc: 0.9070\n",
      "Epoch 037 | Train Loss: 0.2361 Acc: 0.9074 | Val Loss: 0.2220 Acc: 0.9100\n",
      "Epoch 038 | Train Loss: 0.2278 Acc: 0.9091 | Val Loss: 0.2353 Acc: 0.9046\n",
      "Epoch 039 | Train Loss: 0.2450 Acc: 0.9019 | Val Loss: 0.2280 Acc: 0.9118\n",
      "Epoch 040 | Train Loss: 0.2309 Acc: 0.9074 | Val Loss: 0.2712 Acc: 0.8877\n",
      "Epoch 041 | Train Loss: 0.2336 Acc: 0.9077 | Val Loss: 0.2134 Acc: 0.9149\n",
      "Epoch 042 | Train Loss: 0.2094 Acc: 0.9180 | Val Loss: 0.2074 Acc: 0.9155\n",
      "Epoch 043 | Train Loss: 0.2089 Acc: 0.9194 | Val Loss: 0.2192 Acc: 0.9118\n",
      "Epoch 044 | Train Loss: 0.1901 Acc: 0.9256 | Val Loss: 0.1979 Acc: 0.9221\n",
      "Epoch 045 | Train Loss: 0.1976 Acc: 0.9286 | Val Loss: 0.2278 Acc: 0.9124\n",
      "Epoch 046 | Train Loss: 0.1783 Acc: 0.9298 | Val Loss: 0.2071 Acc: 0.9185\n",
      "Epoch 047 | Train Loss: 0.1873 Acc: 0.9284 | Val Loss: 0.1889 Acc: 0.9336\n",
      "Epoch 048 | Train Loss: 0.1776 Acc: 0.9293 | Val Loss: 0.1740 Acc: 0.9324\n",
      "Epoch 049 | Train Loss: 0.1769 Acc: 0.9334 | Val Loss: 0.1784 Acc: 0.9336\n",
      "Epoch 050 | Train Loss: 0.1683 Acc: 0.9355 | Val Loss: 0.1892 Acc: 0.9251\n",
      "Epoch 051 | Train Loss: 0.1666 Acc: 0.9361 | Val Loss: 0.1911 Acc: 0.9306\n",
      "Epoch 052 | Train Loss: 0.1626 Acc: 0.9373 | Val Loss: 0.2120 Acc: 0.9227\n",
      "Epoch 053 | Train Loss: 0.1703 Acc: 0.9342 | Val Loss: 0.1944 Acc: 0.9197\n",
      "Epoch 054 | Train Loss: 0.1761 Acc: 0.9330 | Val Loss: 0.1868 Acc: 0.9372\n",
      "Epoch 055 | Train Loss: 0.1596 Acc: 0.9429 | Val Loss: 0.1830 Acc: 0.9330\n",
      "Epoch 056 | Train Loss: 0.1612 Acc: 0.9372 | Val Loss: 0.1984 Acc: 0.9209\n",
      "Epoch 057 | Train Loss: 0.1518 Acc: 0.9447 | Val Loss: 0.1780 Acc: 0.9336\n",
      "Epoch 058 | Train Loss: 0.1485 Acc: 0.9450 | Val Loss: 0.1976 Acc: 0.9269\n",
      "Early stopping triggered.\n",
      "Epoch 001 | Train Loss: 0.6820 Acc: 0.5772 | Val Loss: 0.6779 Acc: 0.5870\n",
      "Epoch 002 | Train Loss: 0.6732 Acc: 0.5890 | Val Loss: 0.6801 Acc: 0.5785\n",
      "Epoch 003 | Train Loss: 0.6715 Acc: 0.5932 | Val Loss: 0.6833 Acc: 0.5713\n",
      "Epoch 004 | Train Loss: 0.6646 Acc: 0.5938 | Val Loss: 0.6425 Acc: 0.6449\n",
      "Epoch 005 | Train Loss: 0.6235 Acc: 0.6719 | Val Loss: 0.6154 Acc: 0.6793\n",
      "Epoch 006 | Train Loss: 0.5863 Acc: 0.6997 | Val Loss: 0.6072 Acc: 0.6697\n",
      "Epoch 007 | Train Loss: 0.5711 Acc: 0.7115 | Val Loss: 0.5697 Acc: 0.6981\n",
      "Epoch 008 | Train Loss: 0.5474 Acc: 0.7290 | Val Loss: 0.5564 Acc: 0.7168\n",
      "Epoch 009 | Train Loss: 0.5319 Acc: 0.7412 | Val Loss: 0.5353 Acc: 0.7385\n",
      "Epoch 010 | Train Loss: 0.5235 Acc: 0.7474 | Val Loss: 0.5068 Acc: 0.7530\n",
      "Epoch 011 | Train Loss: 0.4901 Acc: 0.7679 | Val Loss: 0.4883 Acc: 0.7609\n",
      "Epoch 012 | Train Loss: 0.4845 Acc: 0.7670 | Val Loss: 0.4810 Acc: 0.7657\n",
      "Epoch 013 | Train Loss: 0.4660 Acc: 0.7782 | Val Loss: 0.5065 Acc: 0.7506\n",
      "Epoch 014 | Train Loss: 0.4462 Acc: 0.7928 | Val Loss: 0.4305 Acc: 0.7971\n",
      "Epoch 015 | Train Loss: 0.4210 Acc: 0.8051 | Val Loss: 0.4061 Acc: 0.8116\n",
      "Epoch 016 | Train Loss: 0.4017 Acc: 0.8158 | Val Loss: 0.3987 Acc: 0.8213\n",
      "Epoch 017 | Train Loss: 0.3868 Acc: 0.8262 | Val Loss: 0.3930 Acc: 0.8043\n",
      "Epoch 018 | Train Loss: 0.3586 Acc: 0.8437 | Val Loss: 0.3415 Acc: 0.8478\n",
      "Epoch 019 | Train Loss: 0.3326 Acc: 0.8560 | Val Loss: 0.3211 Acc: 0.8575\n",
      "Epoch 020 | Train Loss: 0.3268 Acc: 0.8582 | Val Loss: 0.3122 Acc: 0.8605\n",
      "Epoch 021 | Train Loss: 0.3038 Acc: 0.8691 | Val Loss: 0.2990 Acc: 0.8780\n",
      "Epoch 022 | Train Loss: 0.2828 Acc: 0.8851 | Val Loss: 0.2858 Acc: 0.8822\n",
      "Epoch 023 | Train Loss: 0.2784 Acc: 0.8837 | Val Loss: 0.2883 Acc: 0.8659\n",
      "Epoch 024 | Train Loss: 0.2648 Acc: 0.8874 | Val Loss: 0.2904 Acc: 0.8804\n",
      "Epoch 025 | Train Loss: 0.2437 Acc: 0.8957 | Val Loss: 0.2481 Acc: 0.8967\n",
      "Epoch 026 | Train Loss: 0.2376 Acc: 0.9034 | Val Loss: 0.2713 Acc: 0.8925\n",
      "Epoch 027 | Train Loss: 0.2255 Acc: 0.9074 | Val Loss: 0.2673 Acc: 0.8877\n",
      "Epoch 028 | Train Loss: 0.2194 Acc: 0.9097 | Val Loss: 0.2378 Acc: 0.9052\n",
      "Epoch 029 | Train Loss: 0.2047 Acc: 0.9182 | Val Loss: 0.2121 Acc: 0.9082\n",
      "Epoch 030 | Train Loss: 0.2005 Acc: 0.9189 | Val Loss: 0.2244 Acc: 0.9149\n",
      "Epoch 031 | Train Loss: 0.1914 Acc: 0.9257 | Val Loss: 0.2568 Acc: 0.8961\n",
      "Epoch 032 | Train Loss: 0.1827 Acc: 0.9319 | Val Loss: 0.1970 Acc: 0.9245\n",
      "Epoch 033 | Train Loss: 0.1693 Acc: 0.9346 | Val Loss: 0.2049 Acc: 0.9082\n",
      "Epoch 034 | Train Loss: 0.1714 Acc: 0.9330 | Val Loss: 0.1993 Acc: 0.9227\n",
      "Epoch 035 | Train Loss: 0.1621 Acc: 0.9364 | Val Loss: 0.2222 Acc: 0.9155\n",
      "Epoch 036 | Train Loss: 0.1609 Acc: 0.9343 | Val Loss: 0.1952 Acc: 0.9257\n",
      "Epoch 037 | Train Loss: 0.1531 Acc: 0.9423 | Val Loss: 0.1851 Acc: 0.9263\n",
      "Epoch 038 | Train Loss: 0.1446 Acc: 0.9443 | Val Loss: 0.1787 Acc: 0.9354\n",
      "Epoch 039 | Train Loss: 0.1308 Acc: 0.9543 | Val Loss: 0.1997 Acc: 0.9185\n",
      "Epoch 040 | Train Loss: 0.1435 Acc: 0.9440 | Val Loss: 0.1812 Acc: 0.9300\n",
      "Epoch 041 | Train Loss: 0.1297 Acc: 0.9523 | Val Loss: 0.1897 Acc: 0.9245\n",
      "Epoch 042 | Train Loss: 0.1346 Acc: 0.9482 | Val Loss: 0.2058 Acc: 0.9239\n",
      "Epoch 043 | Train Loss: 0.1267 Acc: 0.9506 | Val Loss: 0.1927 Acc: 0.9245\n",
      "Epoch 044 | Train Loss: 0.1290 Acc: 0.9496 | Val Loss: 0.1741 Acc: 0.9390\n",
      "Epoch 045 | Train Loss: 0.1058 Acc: 0.9604 | Val Loss: 0.1780 Acc: 0.9293\n",
      "Epoch 046 | Train Loss: 0.1165 Acc: 0.9541 | Val Loss: 0.1799 Acc: 0.9372\n",
      "Epoch 047 | Train Loss: 0.1073 Acc: 0.9595 | Val Loss: 0.1422 Acc: 0.9450\n",
      "Epoch 048 | Train Loss: 0.1092 Acc: 0.9592 | Val Loss: 0.1638 Acc: 0.9384\n",
      "Epoch 049 | Train Loss: 0.1067 Acc: 0.9585 | Val Loss: 0.1824 Acc: 0.9366\n",
      "Epoch 050 | Train Loss: 0.1068 Acc: 0.9598 | Val Loss: 0.1600 Acc: 0.9438\n",
      "Epoch 051 | Train Loss: 0.1018 Acc: 0.9618 | Val Loss: 0.1876 Acc: 0.9330\n",
      "Epoch 052 | Train Loss: 0.0961 Acc: 0.9626 | Val Loss: 0.1434 Acc: 0.9475\n",
      "Epoch 053 | Train Loss: 0.0939 Acc: 0.9644 | Val Loss: 0.1762 Acc: 0.9420\n",
      "Epoch 054 | Train Loss: 0.0983 Acc: 0.9616 | Val Loss: 0.1508 Acc: 0.9408\n",
      "Epoch 055 | Train Loss: 0.0883 Acc: 0.9671 | Val Loss: 0.1436 Acc: 0.9481\n",
      "Epoch 056 | Train Loss: 0.0892 Acc: 0.9659 | Val Loss: 0.1670 Acc: 0.9438\n",
      "Epoch 057 | Train Loss: 0.0993 Acc: 0.9607 | Val Loss: 0.1562 Acc: 0.9493\n",
      "Early stopping triggered.\n",
      "Epoch 001 | Train Loss: 0.6826 Acc: 0.5715 | Val Loss: 0.6785 Acc: 0.5707\n",
      "Epoch 002 | Train Loss: 0.6650 Acc: 0.6062 | Val Loss: 0.6630 Acc: 0.6002\n",
      "Epoch 003 | Train Loss: 0.6343 Acc: 0.6591 | Val Loss: 0.6280 Acc: 0.6709\n",
      "Epoch 004 | Train Loss: 0.6014 Acc: 0.6843 | Val Loss: 0.5893 Acc: 0.6999\n",
      "Epoch 005 | Train Loss: 0.5829 Acc: 0.7044 | Val Loss: 0.5467 Acc: 0.7198\n",
      "Epoch 006 | Train Loss: 0.5697 Acc: 0.7143 | Val Loss: 0.5500 Acc: 0.7186\n",
      "Epoch 007 | Train Loss: 0.5536 Acc: 0.7238 | Val Loss: 0.5392 Acc: 0.7240\n",
      "Epoch 008 | Train Loss: 0.5386 Acc: 0.7427 | Val Loss: 0.5225 Acc: 0.7343\n",
      "Epoch 009 | Train Loss: 0.5339 Acc: 0.7379 | Val Loss: 0.5120 Acc: 0.7494\n",
      "Epoch 010 | Train Loss: 0.5145 Acc: 0.7498 | Val Loss: 0.5231 Acc: 0.7373\n",
      "Epoch 011 | Train Loss: 0.4961 Acc: 0.7617 | Val Loss: 0.4977 Acc: 0.7657\n",
      "Epoch 012 | Train Loss: 0.4967 Acc: 0.7634 | Val Loss: 0.4883 Acc: 0.7609\n",
      "Epoch 013 | Train Loss: 0.4695 Acc: 0.7812 | Val Loss: 0.4421 Acc: 0.7856\n",
      "Epoch 014 | Train Loss: 0.4580 Acc: 0.7847 | Val Loss: 0.4374 Acc: 0.7983\n",
      "Epoch 015 | Train Loss: 0.4411 Acc: 0.7901 | Val Loss: 0.4092 Acc: 0.8043\n",
      "Epoch 016 | Train Loss: 0.4204 Acc: 0.8022 | Val Loss: 0.4110 Acc: 0.7977\n",
      "Epoch 017 | Train Loss: 0.4059 Acc: 0.8147 | Val Loss: 0.3842 Acc: 0.8104\n",
      "Epoch 018 | Train Loss: 0.3827 Acc: 0.8226 | Val Loss: 0.3735 Acc: 0.8285\n",
      "Epoch 019 | Train Loss: 0.3720 Acc: 0.8333 | Val Loss: 0.3620 Acc: 0.8309\n",
      "Epoch 020 | Train Loss: 0.3439 Acc: 0.8454 | Val Loss: 0.3658 Acc: 0.8388\n",
      "Epoch 021 | Train Loss: 0.3458 Acc: 0.8516 | Val Loss: 0.3470 Acc: 0.8376\n",
      "Epoch 022 | Train Loss: 0.3309 Acc: 0.8537 | Val Loss: 0.2961 Acc: 0.8732\n",
      "Epoch 023 | Train Loss: 0.3180 Acc: 0.8662 | Val Loss: 0.3422 Acc: 0.8478\n",
      "Epoch 024 | Train Loss: 0.3060 Acc: 0.8748 | Val Loss: 0.2931 Acc: 0.8720\n",
      "Epoch 025 | Train Loss: 0.2900 Acc: 0.8763 | Val Loss: 0.2737 Acc: 0.8835\n",
      "Epoch 026 | Train Loss: 0.2793 Acc: 0.8837 | Val Loss: 0.2649 Acc: 0.8919\n",
      "Epoch 027 | Train Loss: 0.2725 Acc: 0.8869 | Val Loss: 0.2676 Acc: 0.8931\n",
      "Epoch 028 | Train Loss: 0.2595 Acc: 0.8925 | Val Loss: 0.3296 Acc: 0.8726\n",
      "Epoch 029 | Train Loss: 0.2589 Acc: 0.8988 | Val Loss: 0.2531 Acc: 0.8913\n",
      "Epoch 030 | Train Loss: 0.2299 Acc: 0.9061 | Val Loss: 0.2354 Acc: 0.8949\n",
      "Epoch 031 | Train Loss: 0.2358 Acc: 0.9055 | Val Loss: 0.2200 Acc: 0.9070\n",
      "Epoch 032 | Train Loss: 0.2211 Acc: 0.9097 | Val Loss: 0.2196 Acc: 0.9118\n",
      "Epoch 033 | Train Loss: 0.2163 Acc: 0.9106 | Val Loss: 0.2384 Acc: 0.8992\n",
      "Epoch 034 | Train Loss: 0.2034 Acc: 0.9179 | Val Loss: 0.2307 Acc: 0.9034\n",
      "Epoch 035 | Train Loss: 0.2137 Acc: 0.9162 | Val Loss: 0.2267 Acc: 0.9004\n",
      "Epoch 036 | Train Loss: 0.2095 Acc: 0.9212 | Val Loss: 0.2246 Acc: 0.9076\n",
      "Epoch 037 | Train Loss: 0.1981 Acc: 0.9241 | Val Loss: 0.2404 Acc: 0.8998\n",
      "Epoch 038 | Train Loss: 0.1924 Acc: 0.9224 | Val Loss: 0.1946 Acc: 0.9185\n",
      "Epoch 039 | Train Loss: 0.1949 Acc: 0.9239 | Val Loss: 0.2411 Acc: 0.8986\n",
      "Epoch 040 | Train Loss: 0.1915 Acc: 0.9253 | Val Loss: 0.2099 Acc: 0.9167\n",
      "Epoch 041 | Train Loss: 0.1738 Acc: 0.9342 | Val Loss: 0.1866 Acc: 0.9209\n",
      "Epoch 042 | Train Loss: 0.1741 Acc: 0.9355 | Val Loss: 0.2816 Acc: 0.9058\n",
      "Epoch 043 | Train Loss: 0.1704 Acc: 0.9367 | Val Loss: 0.1844 Acc: 0.9239\n",
      "Epoch 044 | Train Loss: 0.1611 Acc: 0.9398 | Val Loss: 0.2240 Acc: 0.9112\n",
      "Epoch 045 | Train Loss: 0.1622 Acc: 0.9384 | Val Loss: 0.1882 Acc: 0.9300\n",
      "Epoch 046 | Train Loss: 0.1683 Acc: 0.9372 | Val Loss: 0.2032 Acc: 0.9118\n",
      "Epoch 047 | Train Loss: 0.1579 Acc: 0.9387 | Val Loss: 0.1740 Acc: 0.9318\n",
      "Epoch 048 | Train Loss: 0.1422 Acc: 0.9440 | Val Loss: 0.1942 Acc: 0.9312\n",
      "Epoch 049 | Train Loss: 0.1505 Acc: 0.9426 | Val Loss: 0.1741 Acc: 0.9306\n",
      "Epoch 050 | Train Loss: 0.1447 Acc: 0.9459 | Val Loss: 0.1780 Acc: 0.9293\n",
      "Epoch 051 | Train Loss: 0.1472 Acc: 0.9452 | Val Loss: 0.1986 Acc: 0.9233\n",
      "Epoch 052 | Train Loss: 0.1460 Acc: 0.9461 | Val Loss: 0.1662 Acc: 0.9354\n",
      "Epoch 053 | Train Loss: 0.1404 Acc: 0.9478 | Val Loss: 0.1781 Acc: 0.9318\n",
      "Epoch 054 | Train Loss: 0.1350 Acc: 0.9499 | Val Loss: 0.1666 Acc: 0.9348\n",
      "Epoch 055 | Train Loss: 0.1419 Acc: 0.9462 | Val Loss: 0.1969 Acc: 0.9221\n",
      "Epoch 056 | Train Loss: 0.1241 Acc: 0.9521 | Val Loss: 0.1645 Acc: 0.9360\n",
      "Epoch 057 | Train Loss: 0.1387 Acc: 0.9481 | Val Loss: 0.1712 Acc: 0.9378\n",
      "Epoch 058 | Train Loss: 0.1394 Acc: 0.9493 | Val Loss: 0.1525 Acc: 0.9378\n",
      "Epoch 059 | Train Loss: 0.1142 Acc: 0.9570 | Val Loss: 0.1823 Acc: 0.9293\n",
      "Epoch 060 | Train Loss: 0.1266 Acc: 0.9511 | Val Loss: 0.2096 Acc: 0.9161\n",
      "Epoch 001 | Train Loss: 0.6807 Acc: 0.5738 | Val Loss: 0.6848 Acc: 0.5785\n",
      "Epoch 002 | Train Loss: 0.6718 Acc: 0.5928 | Val Loss: 0.6570 Acc: 0.6202\n",
      "Epoch 003 | Train Loss: 0.6181 Acc: 0.6733 | Val Loss: 0.5782 Acc: 0.7071\n",
      "Epoch 004 | Train Loss: 0.5733 Acc: 0.7137 | Val Loss: 0.5615 Acc: 0.7138\n",
      "Epoch 005 | Train Loss: 0.5409 Acc: 0.7403 | Val Loss: 0.5389 Acc: 0.7271\n",
      "Epoch 006 | Train Loss: 0.5193 Acc: 0.7515 | Val Loss: 0.5264 Acc: 0.7373\n",
      "Epoch 007 | Train Loss: 0.5093 Acc: 0.7539 | Val Loss: 0.5015 Acc: 0.7560\n",
      "Epoch 008 | Train Loss: 0.4868 Acc: 0.7708 | Val Loss: 0.4792 Acc: 0.7711\n",
      "Epoch 009 | Train Loss: 0.4685 Acc: 0.7830 | Val Loss: 0.4809 Acc: 0.7711\n",
      "Epoch 010 | Train Loss: 0.4386 Acc: 0.7951 | Val Loss: 0.4571 Acc: 0.7766\n",
      "Epoch 011 | Train Loss: 0.4147 Acc: 0.8085 | Val Loss: 0.4043 Acc: 0.8019\n",
      "Epoch 012 | Train Loss: 0.4022 Acc: 0.8190 | Val Loss: 0.3881 Acc: 0.8225\n",
      "Epoch 013 | Train Loss: 0.3806 Acc: 0.8321 | Val Loss: 0.3617 Acc: 0.8285\n",
      "Epoch 014 | Train Loss: 0.3569 Acc: 0.8400 | Val Loss: 0.3977 Acc: 0.8146\n",
      "Epoch 015 | Train Loss: 0.3350 Acc: 0.8525 | Val Loss: 0.3091 Acc: 0.8653\n",
      "Epoch 016 | Train Loss: 0.3101 Acc: 0.8667 | Val Loss: 0.2945 Acc: 0.8804\n",
      "Epoch 017 | Train Loss: 0.2924 Acc: 0.8757 | Val Loss: 0.3282 Acc: 0.8454\n",
      "Epoch 018 | Train Loss: 0.2728 Acc: 0.8872 | Val Loss: 0.2648 Acc: 0.8871\n",
      "Epoch 019 | Train Loss: 0.2598 Acc: 0.8914 | Val Loss: 0.2573 Acc: 0.9010\n",
      "Epoch 020 | Train Loss: 0.2383 Acc: 0.8999 | Val Loss: 0.2804 Acc: 0.8738\n",
      "Epoch 021 | Train Loss: 0.2385 Acc: 0.9023 | Val Loss: 0.2460 Acc: 0.8925\n",
      "Epoch 022 | Train Loss: 0.2161 Acc: 0.9147 | Val Loss: 0.2406 Acc: 0.8961\n",
      "Epoch 023 | Train Loss: 0.1980 Acc: 0.9204 | Val Loss: 0.2466 Acc: 0.9022\n",
      "Epoch 024 | Train Loss: 0.1947 Acc: 0.9212 | Val Loss: 0.2168 Acc: 0.9136\n",
      "Epoch 025 | Train Loss: 0.1977 Acc: 0.9227 | Val Loss: 0.2253 Acc: 0.9064\n",
      "Epoch 026 | Train Loss: 0.1812 Acc: 0.9268 | Val Loss: 0.2026 Acc: 0.9257\n",
      "Epoch 027 | Train Loss: 0.1709 Acc: 0.9318 | Val Loss: 0.2097 Acc: 0.9179\n",
      "Epoch 028 | Train Loss: 0.1624 Acc: 0.9351 | Val Loss: 0.2284 Acc: 0.9082\n",
      "Epoch 029 | Train Loss: 0.1581 Acc: 0.9360 | Val Loss: 0.2032 Acc: 0.9094\n",
      "Epoch 030 | Train Loss: 0.1438 Acc: 0.9443 | Val Loss: 0.2140 Acc: 0.9197\n",
      "Epoch 031 | Train Loss: 0.1493 Acc: 0.9437 | Val Loss: 0.2081 Acc: 0.9203\n",
      "Epoch 032 | Train Loss: 0.1445 Acc: 0.9456 | Val Loss: 0.1742 Acc: 0.9324\n",
      "Epoch 033 | Train Loss: 0.1300 Acc: 0.9505 | Val Loss: 0.1778 Acc: 0.9281\n",
      "Epoch 034 | Train Loss: 0.1310 Acc: 0.9499 | Val Loss: 0.2788 Acc: 0.8937\n",
      "Epoch 035 | Train Loss: 0.1208 Acc: 0.9539 | Val Loss: 0.1581 Acc: 0.9420\n",
      "Epoch 036 | Train Loss: 0.1203 Acc: 0.9533 | Val Loss: 0.1614 Acc: 0.9366\n",
      "Epoch 037 | Train Loss: 0.1041 Acc: 0.9597 | Val Loss: 0.1819 Acc: 0.9342\n",
      "Epoch 038 | Train Loss: 0.1092 Acc: 0.9583 | Val Loss: 0.1711 Acc: 0.9336\n",
      "Epoch 039 | Train Loss: 0.0982 Acc: 0.9610 | Val Loss: 0.1655 Acc: 0.9318\n",
      "Epoch 040 | Train Loss: 0.0998 Acc: 0.9632 | Val Loss: 0.2174 Acc: 0.9293\n",
      "Epoch 041 | Train Loss: 0.1001 Acc: 0.9588 | Val Loss: 0.1609 Acc: 0.9378\n",
      "Epoch 042 | Train Loss: 0.0949 Acc: 0.9663 | Val Loss: 0.1636 Acc: 0.9414\n",
      "Epoch 043 | Train Loss: 0.0833 Acc: 0.9701 | Val Loss: 0.1872 Acc: 0.9390\n",
      "Epoch 044 | Train Loss: 0.1014 Acc: 0.9612 | Val Loss: 0.2834 Acc: 0.9028\n",
      "Epoch 045 | Train Loss: 0.0893 Acc: 0.9645 | Val Loss: 0.1755 Acc: 0.9275\n",
      "Early stopping triggered.\n",
      "Epoch 001 | Train Loss: 0.6798 Acc: 0.5715 | Val Loss: 0.6553 Acc: 0.6111\n",
      "Epoch 002 | Train Loss: 0.6384 Acc: 0.6539 | Val Loss: 0.5962 Acc: 0.6896\n",
      "Epoch 003 | Train Loss: 0.5953 Acc: 0.6933 | Val Loss: 0.5955 Acc: 0.6872\n",
      "Epoch 004 | Train Loss: 0.5675 Acc: 0.7148 | Val Loss: 0.5780 Acc: 0.6926\n",
      "Epoch 005 | Train Loss: 0.5476 Acc: 0.7279 | Val Loss: 0.5610 Acc: 0.7228\n",
      "Epoch 006 | Train Loss: 0.5318 Acc: 0.7329 | Val Loss: 0.5457 Acc: 0.7343\n",
      "Epoch 007 | Train Loss: 0.5137 Acc: 0.7494 | Val Loss: 0.5005 Acc: 0.7554\n",
      "Epoch 008 | Train Loss: 0.4963 Acc: 0.7598 | Val Loss: 0.5493 Acc: 0.7488\n",
      "Epoch 009 | Train Loss: 0.4738 Acc: 0.7699 | Val Loss: 0.4777 Acc: 0.7615\n",
      "Epoch 010 | Train Loss: 0.4575 Acc: 0.7780 | Val Loss: 0.4394 Acc: 0.7790\n",
      "Epoch 011 | Train Loss: 0.4231 Acc: 0.8054 | Val Loss: 0.4107 Acc: 0.8080\n",
      "Epoch 012 | Train Loss: 0.4109 Acc: 0.8167 | Val Loss: 0.3939 Acc: 0.8207\n",
      "Epoch 013 | Train Loss: 0.3739 Acc: 0.8329 | Val Loss: 0.3599 Acc: 0.8351\n",
      "Epoch 014 | Train Loss: 0.3630 Acc: 0.8406 | Val Loss: 0.3790 Acc: 0.8309\n",
      "Epoch 015 | Train Loss: 0.3504 Acc: 0.8446 | Val Loss: 0.3427 Acc: 0.8460\n",
      "Epoch 016 | Train Loss: 0.3098 Acc: 0.8732 | Val Loss: 0.2974 Acc: 0.8762\n",
      "Epoch 017 | Train Loss: 0.2895 Acc: 0.8848 | Val Loss: 0.2782 Acc: 0.8859\n",
      "Epoch 018 | Train Loss: 0.2972 Acc: 0.8798 | Val Loss: 0.3379 Acc: 0.8466\n",
      "Epoch 019 | Train Loss: 0.2809 Acc: 0.8852 | Val Loss: 0.3232 Acc: 0.8575\n",
      "Epoch 020 | Train Loss: 0.2652 Acc: 0.8937 | Val Loss: 0.3052 Acc: 0.8696\n",
      "Epoch 021 | Train Loss: 0.2514 Acc: 0.8945 | Val Loss: 0.2811 Acc: 0.8816\n",
      "Epoch 022 | Train Loss: 0.2441 Acc: 0.9026 | Val Loss: 0.2185 Acc: 0.9112\n",
      "Epoch 023 | Train Loss: 0.2282 Acc: 0.9083 | Val Loss: 0.2611 Acc: 0.8931\n",
      "Epoch 024 | Train Loss: 0.2142 Acc: 0.9174 | Val Loss: 0.2291 Acc: 0.9070\n",
      "Epoch 025 | Train Loss: 0.2191 Acc: 0.9129 | Val Loss: 0.2333 Acc: 0.9064\n",
      "Epoch 026 | Train Loss: 0.2111 Acc: 0.9164 | Val Loss: 0.2230 Acc: 0.9118\n",
      "Epoch 027 | Train Loss: 0.1975 Acc: 0.9213 | Val Loss: 0.2231 Acc: 0.9082\n",
      "Epoch 028 | Train Loss: 0.1977 Acc: 0.9245 | Val Loss: 0.2331 Acc: 0.9046\n",
      "Epoch 029 | Train Loss: 0.1932 Acc: 0.9227 | Val Loss: 0.1958 Acc: 0.9251\n",
      "Epoch 030 | Train Loss: 0.1739 Acc: 0.9322 | Val Loss: 0.1977 Acc: 0.9215\n",
      "Epoch 031 | Train Loss: 0.1745 Acc: 0.9318 | Val Loss: 0.2068 Acc: 0.9221\n",
      "Epoch 032 | Train Loss: 0.1704 Acc: 0.9345 | Val Loss: 0.1855 Acc: 0.9293\n",
      "Epoch 033 | Train Loss: 0.1752 Acc: 0.9363 | Val Loss: 0.2189 Acc: 0.9058\n",
      "Epoch 034 | Train Loss: 0.1578 Acc: 0.9387 | Val Loss: 0.2060 Acc: 0.9306\n",
      "Epoch 035 | Train Loss: 0.1598 Acc: 0.9392 | Val Loss: 0.2587 Acc: 0.9040\n",
      "Epoch 036 | Train Loss: 0.1616 Acc: 0.9388 | Val Loss: 0.2248 Acc: 0.9185\n",
      "Epoch 037 | Train Loss: 0.1653 Acc: 0.9364 | Val Loss: 0.2281 Acc: 0.9149\n",
      "Epoch 038 | Train Loss: 0.1573 Acc: 0.9435 | Val Loss: 0.2309 Acc: 0.8998\n",
      "Epoch 039 | Train Loss: 0.1470 Acc: 0.9469 | Val Loss: 0.2140 Acc: 0.9143\n",
      "Epoch 040 | Train Loss: 0.1442 Acc: 0.9456 | Val Loss: 0.1902 Acc: 0.9251\n",
      "Epoch 041 | Train Loss: 0.1389 Acc: 0.9482 | Val Loss: 0.1853 Acc: 0.9366\n",
      "Epoch 042 | Train Loss: 0.1375 Acc: 0.9500 | Val Loss: 0.1976 Acc: 0.9257\n",
      "Epoch 043 | Train Loss: 0.1328 Acc: 0.9518 | Val Loss: 0.1819 Acc: 0.9384\n",
      "Epoch 044 | Train Loss: 0.1270 Acc: 0.9479 | Val Loss: 0.1796 Acc: 0.9324\n",
      "Epoch 045 | Train Loss: 0.1324 Acc: 0.9496 | Val Loss: 0.1861 Acc: 0.9336\n",
      "Epoch 046 | Train Loss: 0.1257 Acc: 0.9509 | Val Loss: 0.2483 Acc: 0.9215\n",
      "Epoch 047 | Train Loss: 0.1388 Acc: 0.9487 | Val Loss: 0.2137 Acc: 0.9221\n",
      "Epoch 048 | Train Loss: 0.1216 Acc: 0.9570 | Val Loss: 0.2290 Acc: 0.9179\n",
      "Epoch 049 | Train Loss: 0.1291 Acc: 0.9570 | Val Loss: 0.1649 Acc: 0.9420\n",
      "Epoch 050 | Train Loss: 0.1331 Acc: 0.9473 | Val Loss: 0.1544 Acc: 0.9493\n",
      "Epoch 051 | Train Loss: 0.1306 Acc: 0.9544 | Val Loss: 0.1829 Acc: 0.9287\n",
      "Epoch 052 | Train Loss: 0.1166 Acc: 0.9601 | Val Loss: 0.2290 Acc: 0.9324\n",
      "Epoch 053 | Train Loss: 0.1121 Acc: 0.9600 | Val Loss: 0.1691 Acc: 0.9438\n",
      "Epoch 054 | Train Loss: 0.1162 Acc: 0.9568 | Val Loss: 0.1683 Acc: 0.9312\n",
      "Epoch 055 | Train Loss: 0.1136 Acc: 0.9582 | Val Loss: 0.1728 Acc: 0.9336\n",
      "Epoch 056 | Train Loss: 0.1241 Acc: 0.9562 | Val Loss: 0.2204 Acc: 0.9070\n",
      "Epoch 057 | Train Loss: 0.1162 Acc: 0.9585 | Val Loss: 0.1730 Acc: 0.9426\n",
      "Epoch 058 | Train Loss: 0.1092 Acc: 0.9644 | Val Loss: 0.1846 Acc: 0.9348\n",
      "Epoch 059 | Train Loss: 0.1119 Acc: 0.9592 | Val Loss: 0.1941 Acc: 0.9342\n",
      "Epoch 060 | Train Loss: 0.1035 Acc: 0.9638 | Val Loss: 0.1606 Acc: 0.9402\n",
      "Early stopping triggered.\n",
      "Epoch 001 | Train Loss: 0.6796 Acc: 0.5769 | Val Loss: 0.6777 Acc: 0.5870\n",
      "Epoch 002 | Train Loss: 0.6689 Acc: 0.6005 | Val Loss: 0.6477 Acc: 0.6123\n",
      "Epoch 003 | Train Loss: 0.6235 Acc: 0.6672 | Val Loss: 0.5880 Acc: 0.6872\n",
      "Epoch 004 | Train Loss: 0.5704 Acc: 0.7173 | Val Loss: 0.5501 Acc: 0.7258\n",
      "Epoch 005 | Train Loss: 0.5399 Acc: 0.7324 | Val Loss: 0.5407 Acc: 0.7271\n",
      "Epoch 006 | Train Loss: 0.5187 Acc: 0.7462 | Val Loss: 0.5035 Acc: 0.7591\n",
      "Epoch 007 | Train Loss: 0.4951 Acc: 0.7657 | Val Loss: 0.5041 Acc: 0.7500\n",
      "Epoch 008 | Train Loss: 0.4694 Acc: 0.7850 | Val Loss: 0.4634 Acc: 0.7729\n",
      "Epoch 009 | Train Loss: 0.4451 Acc: 0.7971 | Val Loss: 0.4612 Acc: 0.7844\n",
      "Epoch 010 | Train Loss: 0.4182 Acc: 0.8111 | Val Loss: 0.4485 Acc: 0.7935\n",
      "Epoch 011 | Train Loss: 0.3906 Acc: 0.8265 | Val Loss: 0.3948 Acc: 0.8128\n",
      "Epoch 012 | Train Loss: 0.3636 Acc: 0.8400 | Val Loss: 0.3642 Acc: 0.8364\n",
      "Epoch 013 | Train Loss: 0.3302 Acc: 0.8602 | Val Loss: 0.3232 Acc: 0.8599\n",
      "Epoch 014 | Train Loss: 0.3048 Acc: 0.8735 | Val Loss: 0.3052 Acc: 0.8665\n",
      "Epoch 015 | Train Loss: 0.2923 Acc: 0.8768 | Val Loss: 0.2816 Acc: 0.8744\n",
      "Epoch 016 | Train Loss: 0.2591 Acc: 0.8961 | Val Loss: 0.2803 Acc: 0.8853\n",
      "Epoch 017 | Train Loss: 0.2500 Acc: 0.8969 | Val Loss: 0.2561 Acc: 0.8919\n",
      "Epoch 018 | Train Loss: 0.2287 Acc: 0.9067 | Val Loss: 0.2329 Acc: 0.9106\n",
      "Epoch 019 | Train Loss: 0.2096 Acc: 0.9164 | Val Loss: 0.2620 Acc: 0.8798\n",
      "Epoch 020 | Train Loss: 0.2034 Acc: 0.9194 | Val Loss: 0.2632 Acc: 0.8816\n",
      "Epoch 021 | Train Loss: 0.1834 Acc: 0.9277 | Val Loss: 0.1988 Acc: 0.9143\n",
      "Epoch 022 | Train Loss: 0.1626 Acc: 0.9363 | Val Loss: 0.2027 Acc: 0.9143\n",
      "Epoch 023 | Train Loss: 0.1593 Acc: 0.9379 | Val Loss: 0.1886 Acc: 0.9257\n",
      "Epoch 024 | Train Loss: 0.1500 Acc: 0.9431 | Val Loss: 0.1841 Acc: 0.9312\n",
      "Epoch 025 | Train Loss: 0.1430 Acc: 0.9449 | Val Loss: 0.1989 Acc: 0.9185\n",
      "Epoch 026 | Train Loss: 0.1419 Acc: 0.9462 | Val Loss: 0.1906 Acc: 0.9227\n",
      "Epoch 027 | Train Loss: 0.1317 Acc: 0.9529 | Val Loss: 0.1717 Acc: 0.9300\n",
      "Epoch 028 | Train Loss: 0.1242 Acc: 0.9532 | Val Loss: 0.1962 Acc: 0.9263\n",
      "Epoch 029 | Train Loss: 0.1110 Acc: 0.9594 | Val Loss: 0.1892 Acc: 0.9306\n",
      "Epoch 030 | Train Loss: 0.1191 Acc: 0.9529 | Val Loss: 0.1735 Acc: 0.9318\n",
      "Epoch 031 | Train Loss: 0.1008 Acc: 0.9616 | Val Loss: 0.1853 Acc: 0.9263\n",
      "Epoch 032 | Train Loss: 0.0943 Acc: 0.9653 | Val Loss: 0.1658 Acc: 0.9342\n",
      "Epoch 033 | Train Loss: 0.1026 Acc: 0.9600 | Val Loss: 0.1460 Acc: 0.9372\n",
      "Epoch 034 | Train Loss: 0.0832 Acc: 0.9677 | Val Loss: 0.1658 Acc: 0.9354\n",
      "Epoch 035 | Train Loss: 0.1015 Acc: 0.9624 | Val Loss: 0.1567 Acc: 0.9372\n",
      "Epoch 036 | Train Loss: 0.0782 Acc: 0.9709 | Val Loss: 0.2011 Acc: 0.9318\n",
      "Epoch 037 | Train Loss: 0.0848 Acc: 0.9675 | Val Loss: 0.2039 Acc: 0.9263\n",
      "Epoch 038 | Train Loss: 0.0749 Acc: 0.9712 | Val Loss: 0.1462 Acc: 0.9432\n",
      "Epoch 039 | Train Loss: 0.0809 Acc: 0.9695 | Val Loss: 0.2193 Acc: 0.9155\n",
      "Epoch 040 | Train Loss: 0.0688 Acc: 0.9737 | Val Loss: 0.1566 Acc: 0.9475\n",
      "Epoch 041 | Train Loss: 0.0620 Acc: 0.9763 | Val Loss: 0.1820 Acc: 0.9384\n",
      "Epoch 042 | Train Loss: 0.0711 Acc: 0.9743 | Val Loss: 0.1884 Acc: 0.9342\n",
      "Epoch 043 | Train Loss: 0.0806 Acc: 0.9701 | Val Loss: 0.1929 Acc: 0.9354\n",
      "Early stopping triggered.\n",
      "Epoch 001 | Train Loss: 0.6786 Acc: 0.5804 | Val Loss: 0.6771 Acc: 0.5833\n",
      "Epoch 002 | Train Loss: 0.6705 Acc: 0.5976 | Val Loss: 0.6692 Acc: 0.5906\n",
      "Epoch 003 | Train Loss: 0.6587 Acc: 0.6150 | Val Loss: 0.6592 Acc: 0.6099\n",
      "Epoch 004 | Train Loss: 0.6420 Acc: 0.6369 | Val Loss: 0.6098 Acc: 0.6800\n",
      "Epoch 005 | Train Loss: 0.5933 Acc: 0.7035 | Val Loss: 0.5717 Acc: 0.7041\n",
      "Epoch 006 | Train Loss: 0.5637 Acc: 0.7226 | Val Loss: 0.5574 Acc: 0.7156\n",
      "Epoch 007 | Train Loss: 0.5421 Acc: 0.7346 | Val Loss: 0.5389 Acc: 0.7295\n",
      "Epoch 008 | Train Loss: 0.5268 Acc: 0.7429 | Val Loss: 0.5253 Acc: 0.7355\n",
      "Epoch 009 | Train Loss: 0.5049 Acc: 0.7571 | Val Loss: 0.4995 Acc: 0.7566\n",
      "Epoch 010 | Train Loss: 0.4868 Acc: 0.7702 | Val Loss: 0.4846 Acc: 0.7591\n",
      "Epoch 011 | Train Loss: 0.4655 Acc: 0.7814 | Val Loss: 0.4851 Acc: 0.7530\n",
      "Epoch 012 | Train Loss: 0.4550 Acc: 0.7848 | Val Loss: 0.4772 Acc: 0.7729\n",
      "Epoch 013 | Train Loss: 0.4319 Acc: 0.8021 | Val Loss: 0.4771 Acc: 0.7633\n",
      "Epoch 014 | Train Loss: 0.4101 Acc: 0.8125 | Val Loss: 0.4079 Acc: 0.8001\n",
      "Epoch 015 | Train Loss: 0.3910 Acc: 0.8224 | Val Loss: 0.4220 Acc: 0.7832\n",
      "Epoch 016 | Train Loss: 0.3702 Acc: 0.8329 | Val Loss: 0.3723 Acc: 0.8231\n",
      "Epoch 017 | Train Loss: 0.3426 Acc: 0.8457 | Val Loss: 0.3435 Acc: 0.8460\n",
      "Epoch 018 | Train Loss: 0.3366 Acc: 0.8551 | Val Loss: 0.3209 Acc: 0.8521\n",
      "Epoch 019 | Train Loss: 0.3252 Acc: 0.8560 | Val Loss: 0.3205 Acc: 0.8521\n",
      "Epoch 020 | Train Loss: 0.2922 Acc: 0.8785 | Val Loss: 0.3818 Acc: 0.8339\n",
      "Epoch 021 | Train Loss: 0.2812 Acc: 0.8804 | Val Loss: 0.2830 Acc: 0.8768\n",
      "Epoch 022 | Train Loss: 0.2614 Acc: 0.8899 | Val Loss: 0.2816 Acc: 0.8841\n",
      "Epoch 023 | Train Loss: 0.2490 Acc: 0.8966 | Val Loss: 0.2778 Acc: 0.8726\n",
      "Epoch 024 | Train Loss: 0.2341 Acc: 0.9085 | Val Loss: 0.2697 Acc: 0.8822\n",
      "Epoch 025 | Train Loss: 0.2167 Acc: 0.9109 | Val Loss: 0.2462 Acc: 0.9070\n",
      "Epoch 026 | Train Loss: 0.2069 Acc: 0.9171 | Val Loss: 0.2845 Acc: 0.8774\n",
      "Epoch 027 | Train Loss: 0.1948 Acc: 0.9200 | Val Loss: 0.2568 Acc: 0.8931\n",
      "Epoch 028 | Train Loss: 0.2196 Acc: 0.9100 | Val Loss: 0.2518 Acc: 0.9028\n",
      "Epoch 029 | Train Loss: 0.1875 Acc: 0.9265 | Val Loss: 0.2166 Acc: 0.9124\n",
      "Epoch 030 | Train Loss: 0.1766 Acc: 0.9284 | Val Loss: 0.2036 Acc: 0.9287\n",
      "Epoch 031 | Train Loss: 0.1680 Acc: 0.9348 | Val Loss: 0.2077 Acc: 0.9185\n",
      "Epoch 032 | Train Loss: 0.1566 Acc: 0.9388 | Val Loss: 0.2049 Acc: 0.9155\n",
      "Epoch 033 | Train Loss: 0.1511 Acc: 0.9437 | Val Loss: 0.2161 Acc: 0.9106\n",
      "Epoch 034 | Train Loss: 0.1367 Acc: 0.9458 | Val Loss: 0.2183 Acc: 0.9130\n",
      "Epoch 035 | Train Loss: 0.1379 Acc: 0.9456 | Val Loss: 0.1870 Acc: 0.9275\n",
      "Epoch 036 | Train Loss: 0.1329 Acc: 0.9491 | Val Loss: 0.1852 Acc: 0.9287\n",
      "Epoch 037 | Train Loss: 0.1263 Acc: 0.9517 | Val Loss: 0.1823 Acc: 0.9239\n",
      "Epoch 038 | Train Loss: 0.1277 Acc: 0.9500 | Val Loss: 0.1978 Acc: 0.9263\n",
      "Epoch 039 | Train Loss: 0.1050 Acc: 0.9597 | Val Loss: 0.1858 Acc: 0.9342\n",
      "Epoch 040 | Train Loss: 0.1158 Acc: 0.9552 | Val Loss: 0.1972 Acc: 0.9275\n",
      "Epoch 041 | Train Loss: 0.1113 Acc: 0.9570 | Val Loss: 0.1761 Acc: 0.9342\n",
      "Epoch 042 | Train Loss: 0.1044 Acc: 0.9591 | Val Loss: 0.2425 Acc: 0.9136\n",
      "Epoch 043 | Train Loss: 0.1033 Acc: 0.9621 | Val Loss: 0.2092 Acc: 0.9336\n",
      "Epoch 044 | Train Loss: 0.1091 Acc: 0.9598 | Val Loss: 0.1850 Acc: 0.9366\n",
      "Epoch 045 | Train Loss: 0.1007 Acc: 0.9610 | Val Loss: 0.1711 Acc: 0.9330\n",
      "Epoch 046 | Train Loss: 0.0907 Acc: 0.9678 | Val Loss: 0.1718 Acc: 0.9408\n",
      "Epoch 047 | Train Loss: 0.0984 Acc: 0.9627 | Val Loss: 0.1580 Acc: 0.9372\n",
      "Epoch 048 | Train Loss: 0.0881 Acc: 0.9684 | Val Loss: 0.1639 Acc: 0.9354\n",
      "Epoch 049 | Train Loss: 0.0880 Acc: 0.9677 | Val Loss: 0.1846 Acc: 0.9336\n",
      "Epoch 050 | Train Loss: 0.0909 Acc: 0.9663 | Val Loss: 0.1834 Acc: 0.9354\n",
      "Epoch 051 | Train Loss: 0.0820 Acc: 0.9706 | Val Loss: 0.1836 Acc: 0.9336\n",
      "Epoch 052 | Train Loss: 0.0787 Acc: 0.9728 | Val Loss: 0.1768 Acc: 0.9390\n",
      "Epoch 053 | Train Loss: 0.0812 Acc: 0.9695 | Val Loss: 0.2107 Acc: 0.9275\n",
      "Epoch 054 | Train Loss: 0.0772 Acc: 0.9728 | Val Loss: 0.1721 Acc: 0.9426\n",
      "Epoch 055 | Train Loss: 0.0797 Acc: 0.9739 | Val Loss: 0.1790 Acc: 0.9372\n",
      "Epoch 056 | Train Loss: 0.0709 Acc: 0.9728 | Val Loss: 0.2172 Acc: 0.9257\n",
      "Epoch 057 | Train Loss: 0.0767 Acc: 0.9712 | Val Loss: 0.2115 Acc: 0.9251\n",
      "Early stopping triggered.\n",
      "Epoch 001 | Train Loss: 0.6840 Acc: 0.5655 | Val Loss: 0.6755 Acc: 0.5918\n",
      "Epoch 002 | Train Loss: 0.6795 Acc: 0.5828 | Val Loss: 0.6740 Acc: 0.5888\n",
      "Epoch 003 | Train Loss: 0.6690 Acc: 0.6030 | Val Loss: 0.6675 Acc: 0.6002\n",
      "Epoch 004 | Train Loss: 0.6655 Acc: 0.6092 | Val Loss: 0.6659 Acc: 0.6069\n",
      "Epoch 005 | Train Loss: 0.6625 Acc: 0.6138 | Val Loss: 0.6644 Acc: 0.6069\n",
      "Epoch 006 | Train Loss: 0.6538 Acc: 0.6277 | Val Loss: 0.6562 Acc: 0.6105\n",
      "Epoch 007 | Train Loss: 0.6296 Acc: 0.6695 | Val Loss: 0.6130 Acc: 0.6866\n",
      "Epoch 008 | Train Loss: 0.6173 Acc: 0.6767 | Val Loss: 0.5908 Acc: 0.7029\n",
      "Epoch 009 | Train Loss: 0.5585 Acc: 0.7214 | Val Loss: 0.5465 Acc: 0.7379\n",
      "Epoch 010 | Train Loss: 0.5360 Acc: 0.7401 | Val Loss: 0.5325 Acc: 0.7295\n",
      "Epoch 011 | Train Loss: 0.5047 Acc: 0.7640 | Val Loss: 0.5084 Acc: 0.7506\n",
      "Epoch 012 | Train Loss: 0.4892 Acc: 0.7732 | Val Loss: 0.4907 Acc: 0.7566\n",
      "Epoch 013 | Train Loss: 0.4781 Acc: 0.7836 | Val Loss: 0.4982 Acc: 0.7518\n",
      "Epoch 014 | Train Loss: 0.4601 Acc: 0.7919 | Val Loss: 0.4440 Acc: 0.7953\n",
      "Epoch 015 | Train Loss: 0.4366 Acc: 0.8007 | Val Loss: 0.4515 Acc: 0.7862\n",
      "Epoch 016 | Train Loss: 0.4284 Acc: 0.8055 | Val Loss: 0.4670 Acc: 0.7699\n",
      "Epoch 017 | Train Loss: 0.4118 Acc: 0.8169 | Val Loss: 0.4579 Acc: 0.7874\n",
      "Epoch 018 | Train Loss: 0.3982 Acc: 0.8282 | Val Loss: 0.4080 Acc: 0.8062\n",
      "Epoch 019 | Train Loss: 0.3808 Acc: 0.8336 | Val Loss: 0.3900 Acc: 0.8122\n",
      "Epoch 020 | Train Loss: 0.3582 Acc: 0.8449 | Val Loss: 0.3544 Acc: 0.8388\n",
      "Epoch 021 | Train Loss: 0.3508 Acc: 0.8492 | Val Loss: 0.3595 Acc: 0.8382\n",
      "Epoch 022 | Train Loss: 0.3294 Acc: 0.8549 | Val Loss: 0.3369 Acc: 0.8678\n",
      "Epoch 023 | Train Loss: 0.3295 Acc: 0.8563 | Val Loss: 0.3887 Acc: 0.8182\n",
      "Epoch 024 | Train Loss: 0.3050 Acc: 0.8665 | Val Loss: 0.3207 Acc: 0.8599\n",
      "Epoch 025 | Train Loss: 0.2930 Acc: 0.8735 | Val Loss: 0.3058 Acc: 0.8738\n",
      "Epoch 026 | Train Loss: 0.2791 Acc: 0.8833 | Val Loss: 0.3242 Acc: 0.8575\n",
      "Epoch 027 | Train Loss: 0.2674 Acc: 0.8880 | Val Loss: 0.2978 Acc: 0.8780\n",
      "Epoch 028 | Train Loss: 0.2578 Acc: 0.8937 | Val Loss: 0.2549 Acc: 0.8919\n",
      "Epoch 029 | Train Loss: 0.2349 Acc: 0.9043 | Val Loss: 0.3120 Acc: 0.8756\n",
      "Epoch 030 | Train Loss: 0.2353 Acc: 0.9035 | Val Loss: 0.2452 Acc: 0.9016\n",
      "Epoch 031 | Train Loss: 0.2279 Acc: 0.9071 | Val Loss: 0.2734 Acc: 0.8822\n",
      "Epoch 032 | Train Loss: 0.2146 Acc: 0.9164 | Val Loss: 0.2472 Acc: 0.8943\n",
      "Epoch 033 | Train Loss: 0.2031 Acc: 0.9183 | Val Loss: 0.2468 Acc: 0.8979\n",
      "Epoch 034 | Train Loss: 0.1952 Acc: 0.9248 | Val Loss: 0.2690 Acc: 0.8919\n",
      "Epoch 035 | Train Loss: 0.1978 Acc: 0.9212 | Val Loss: 0.2869 Acc: 0.8738\n",
      "Epoch 036 | Train Loss: 0.1902 Acc: 0.9247 | Val Loss: 0.2550 Acc: 0.9064\n",
      "Epoch 037 | Train Loss: 0.1784 Acc: 0.9305 | Val Loss: 0.2246 Acc: 0.9185\n",
      "Epoch 038 | Train Loss: 0.1779 Acc: 0.9283 | Val Loss: 0.2129 Acc: 0.9082\n",
      "Epoch 039 | Train Loss: 0.1609 Acc: 0.9399 | Val Loss: 0.1859 Acc: 0.9233\n",
      "Epoch 040 | Train Loss: 0.1646 Acc: 0.9384 | Val Loss: 0.1869 Acc: 0.9300\n",
      "Epoch 041 | Train Loss: 0.1466 Acc: 0.9432 | Val Loss: 0.2507 Acc: 0.9010\n",
      "Epoch 042 | Train Loss: 0.1653 Acc: 0.9379 | Val Loss: 0.2136 Acc: 0.9076\n",
      "Epoch 043 | Train Loss: 0.1468 Acc: 0.9405 | Val Loss: 0.1912 Acc: 0.9312\n",
      "Epoch 044 | Train Loss: 0.1504 Acc: 0.9408 | Val Loss: 0.2025 Acc: 0.9173\n",
      "Epoch 045 | Train Loss: 0.1494 Acc: 0.9440 | Val Loss: 0.2028 Acc: 0.9149\n",
      "Epoch 046 | Train Loss: 0.1400 Acc: 0.9499 | Val Loss: 0.2105 Acc: 0.9167\n",
      "Epoch 047 | Train Loss: 0.1324 Acc: 0.9481 | Val Loss: 0.1965 Acc: 0.9233\n",
      "Epoch 048 | Train Loss: 0.1318 Acc: 0.9512 | Val Loss: 0.2332 Acc: 0.9191\n",
      "Epoch 049 | Train Loss: 0.1236 Acc: 0.9533 | Val Loss: 0.1919 Acc: 0.9300\n",
      "Early stopping triggered.\n",
      "Epoch 001 | Train Loss: 0.6772 Acc: 0.5813 | Val Loss: 0.6727 Acc: 0.5731\n",
      "Epoch 002 | Train Loss: 0.6625 Acc: 0.6112 | Val Loss: 0.6500 Acc: 0.6196\n",
      "Epoch 003 | Train Loss: 0.6376 Acc: 0.6488 | Val Loss: 0.6109 Acc: 0.6842\n",
      "Epoch 004 | Train Loss: 0.5975 Acc: 0.6979 | Val Loss: 0.5712 Acc: 0.7114\n",
      "Epoch 005 | Train Loss: 0.5743 Acc: 0.7161 | Val Loss: 0.5621 Acc: 0.7107\n",
      "Epoch 006 | Train Loss: 0.5510 Acc: 0.7320 | Val Loss: 0.5392 Acc: 0.7367\n",
      "Epoch 007 | Train Loss: 0.5274 Acc: 0.7463 | Val Loss: 0.5231 Acc: 0.7440\n",
      "Epoch 008 | Train Loss: 0.5223 Acc: 0.7498 | Val Loss: 0.5020 Acc: 0.7560\n",
      "Epoch 009 | Train Loss: 0.5069 Acc: 0.7575 | Val Loss: 0.4943 Acc: 0.7591\n",
      "Epoch 010 | Train Loss: 0.4819 Acc: 0.7728 | Val Loss: 0.4855 Acc: 0.7591\n",
      "Epoch 011 | Train Loss: 0.4732 Acc: 0.7788 | Val Loss: 0.4640 Acc: 0.7850\n",
      "Epoch 012 | Train Loss: 0.4449 Acc: 0.7936 | Val Loss: 0.4439 Acc: 0.7905\n",
      "Epoch 013 | Train Loss: 0.4227 Acc: 0.8091 | Val Loss: 0.4331 Acc: 0.7989\n",
      "Epoch 014 | Train Loss: 0.4144 Acc: 0.8134 | Val Loss: 0.3945 Acc: 0.8182\n",
      "Epoch 015 | Train Loss: 0.3992 Acc: 0.8212 | Val Loss: 0.4047 Acc: 0.8068\n",
      "Epoch 016 | Train Loss: 0.3792 Acc: 0.8327 | Val Loss: 0.3797 Acc: 0.8231\n",
      "Epoch 017 | Train Loss: 0.3602 Acc: 0.8448 | Val Loss: 0.4228 Acc: 0.8025\n",
      "Epoch 018 | Train Loss: 0.3504 Acc: 0.8481 | Val Loss: 0.3687 Acc: 0.8327\n",
      "Epoch 019 | Train Loss: 0.3340 Acc: 0.8540 | Val Loss: 0.3242 Acc: 0.8557\n",
      "Epoch 020 | Train Loss: 0.3179 Acc: 0.8679 | Val Loss: 0.3221 Acc: 0.8569\n",
      "Epoch 021 | Train Loss: 0.3077 Acc: 0.8697 | Val Loss: 0.2999 Acc: 0.8593\n",
      "Epoch 022 | Train Loss: 0.2854 Acc: 0.8812 | Val Loss: 0.3100 Acc: 0.8659\n",
      "Epoch 023 | Train Loss: 0.2784 Acc: 0.8836 | Val Loss: 0.2810 Acc: 0.8762\n",
      "Epoch 024 | Train Loss: 0.2630 Acc: 0.8905 | Val Loss: 0.3121 Acc: 0.8659\n",
      "Epoch 025 | Train Loss: 0.2578 Acc: 0.8931 | Val Loss: 0.2725 Acc: 0.8853\n",
      "Epoch 026 | Train Loss: 0.2405 Acc: 0.9014 | Val Loss: 0.2790 Acc: 0.8810\n",
      "Epoch 027 | Train Loss: 0.2480 Acc: 0.8979 | Val Loss: 0.2289 Acc: 0.9016\n",
      "Epoch 028 | Train Loss: 0.2258 Acc: 0.9088 | Val Loss: 0.2598 Acc: 0.8889\n",
      "Epoch 029 | Train Loss: 0.2193 Acc: 0.9109 | Val Loss: 0.2497 Acc: 0.8913\n",
      "Epoch 030 | Train Loss: 0.2139 Acc: 0.9147 | Val Loss: 0.2242 Acc: 0.9028\n",
      "Epoch 031 | Train Loss: 0.2017 Acc: 0.9192 | Val Loss: 0.2232 Acc: 0.9016\n",
      "Epoch 032 | Train Loss: 0.1933 Acc: 0.9236 | Val Loss: 0.2096 Acc: 0.9179\n",
      "Epoch 033 | Train Loss: 0.1778 Acc: 0.9311 | Val Loss: 0.2638 Acc: 0.8973\n",
      "Epoch 034 | Train Loss: 0.1853 Acc: 0.9280 | Val Loss: 0.1900 Acc: 0.9167\n",
      "Epoch 035 | Train Loss: 0.1669 Acc: 0.9361 | Val Loss: 0.1683 Acc: 0.9281\n",
      "Epoch 036 | Train Loss: 0.1684 Acc: 0.9363 | Val Loss: 0.2368 Acc: 0.8961\n",
      "Epoch 037 | Train Loss: 0.1643 Acc: 0.9367 | Val Loss: 0.2061 Acc: 0.9215\n",
      "Epoch 038 | Train Loss: 0.1501 Acc: 0.9422 | Val Loss: 0.1860 Acc: 0.9245\n",
      "Epoch 039 | Train Loss: 0.1558 Acc: 0.9373 | Val Loss: 0.1847 Acc: 0.9263\n",
      "Epoch 040 | Train Loss: 0.1432 Acc: 0.9450 | Val Loss: 0.1971 Acc: 0.9149\n",
      "Epoch 041 | Train Loss: 0.1452 Acc: 0.9440 | Val Loss: 0.2118 Acc: 0.9076\n",
      "Epoch 042 | Train Loss: 0.1304 Acc: 0.9487 | Val Loss: 0.1790 Acc: 0.9263\n",
      "Epoch 043 | Train Loss: 0.1254 Acc: 0.9514 | Val Loss: 0.1756 Acc: 0.9281\n",
      "Epoch 044 | Train Loss: 0.1319 Acc: 0.9496 | Val Loss: 0.1675 Acc: 0.9293\n",
      "Epoch 045 | Train Loss: 0.1169 Acc: 0.9556 | Val Loss: 0.1644 Acc: 0.9378\n",
      "Epoch 046 | Train Loss: 0.1295 Acc: 0.9496 | Val Loss: 0.1675 Acc: 0.9306\n",
      "Epoch 047 | Train Loss: 0.1176 Acc: 0.9526 | Val Loss: 0.1697 Acc: 0.9318\n",
      "Epoch 048 | Train Loss: 0.1060 Acc: 0.9585 | Val Loss: 0.1523 Acc: 0.9414\n",
      "Epoch 049 | Train Loss: 0.1132 Acc: 0.9592 | Val Loss: 0.1519 Acc: 0.9390\n",
      "Epoch 050 | Train Loss: 0.1146 Acc: 0.9562 | Val Loss: 0.1546 Acc: 0.9372\n",
      "Epoch 051 | Train Loss: 0.1064 Acc: 0.9591 | Val Loss: 0.1714 Acc: 0.9336\n",
      "Epoch 052 | Train Loss: 0.1051 Acc: 0.9601 | Val Loss: 0.1535 Acc: 0.9450\n",
      "Epoch 053 | Train Loss: 0.0947 Acc: 0.9627 | Val Loss: 0.1668 Acc: 0.9390\n",
      "Epoch 054 | Train Loss: 0.1018 Acc: 0.9595 | Val Loss: 0.1496 Acc: 0.9457\n",
      "Epoch 055 | Train Loss: 0.0839 Acc: 0.9684 | Val Loss: 0.1367 Acc: 0.9511\n",
      "Epoch 056 | Train Loss: 0.0884 Acc: 0.9657 | Val Loss: 0.1626 Acc: 0.9366\n",
      "Epoch 057 | Train Loss: 0.0940 Acc: 0.9645 | Val Loss: 0.1614 Acc: 0.9450\n",
      "Epoch 058 | Train Loss: 0.0894 Acc: 0.9675 | Val Loss: 0.1427 Acc: 0.9426\n",
      "Epoch 059 | Train Loss: 0.0857 Acc: 0.9697 | Val Loss: 0.1462 Acc: 0.9438\n",
      "Epoch 060 | Train Loss: 0.0781 Acc: 0.9700 | Val Loss: 0.1653 Acc: 0.9457\n",
      "Iteration 16/40 | Best Val Loss: 0.1122 | Iter Time: 212.68s | Total Time: 71.67 min\n",
      "Epoch 001 | Train Loss: 0.6824 Acc: 0.5680 | Val Loss: 0.6731 Acc: 0.5821\n",
      "Epoch 002 | Train Loss: 0.6540 Acc: 0.6251 | Val Loss: 0.6241 Acc: 0.6558\n",
      "Epoch 003 | Train Loss: 0.5969 Acc: 0.6920 | Val Loss: 0.5829 Acc: 0.6999\n",
      "Epoch 004 | Train Loss: 0.5625 Acc: 0.7167 | Val Loss: 0.5603 Acc: 0.7228\n",
      "Epoch 005 | Train Loss: 0.5368 Acc: 0.7406 | Val Loss: 0.5240 Acc: 0.7355\n",
      "Epoch 006 | Train Loss: 0.5134 Acc: 0.7522 | Val Loss: 0.5160 Acc: 0.7415\n",
      "Epoch 007 | Train Loss: 0.4960 Acc: 0.7629 | Val Loss: 0.4809 Acc: 0.7591\n",
      "Epoch 008 | Train Loss: 0.4732 Acc: 0.7756 | Val Loss: 0.4913 Acc: 0.7585\n",
      "Epoch 009 | Train Loss: 0.4483 Acc: 0.7942 | Val Loss: 0.4900 Acc: 0.7554\n",
      "Epoch 010 | Train Loss: 0.4342 Acc: 0.7966 | Val Loss: 0.3954 Acc: 0.8134\n",
      "Epoch 011 | Train Loss: 0.4196 Acc: 0.8095 | Val Loss: 0.3738 Acc: 0.8225\n",
      "Epoch 012 | Train Loss: 0.3823 Acc: 0.8294 | Val Loss: 0.3829 Acc: 0.8261\n",
      "Epoch 013 | Train Loss: 0.3697 Acc: 0.8362 | Val Loss: 0.4086 Acc: 0.7947\n",
      "Epoch 014 | Train Loss: 0.3466 Acc: 0.8472 | Val Loss: 0.3603 Acc: 0.8406\n",
      "Epoch 015 | Train Loss: 0.3337 Acc: 0.8567 | Val Loss: 0.3347 Acc: 0.8569\n",
      "Epoch 016 | Train Loss: 0.3145 Acc: 0.8640 | Val Loss: 0.3076 Acc: 0.8696\n",
      "Epoch 017 | Train Loss: 0.2927 Acc: 0.8789 | Val Loss: 0.2768 Acc: 0.8859\n",
      "Epoch 018 | Train Loss: 0.2848 Acc: 0.8782 | Val Loss: 0.2830 Acc: 0.8768\n",
      "Epoch 019 | Train Loss: 0.2567 Acc: 0.8948 | Val Loss: 0.3541 Acc: 0.8545\n",
      "Epoch 020 | Train Loss: 0.2571 Acc: 0.8922 | Val Loss: 0.2550 Acc: 0.8919\n",
      "Epoch 021 | Train Loss: 0.2428 Acc: 0.9005 | Val Loss: 0.2351 Acc: 0.9034\n",
      "Epoch 022 | Train Loss: 0.2380 Acc: 0.9038 | Val Loss: 0.2518 Acc: 0.8961\n",
      "Epoch 023 | Train Loss: 0.2242 Acc: 0.9076 | Val Loss: 0.2341 Acc: 0.9094\n",
      "Epoch 024 | Train Loss: 0.2135 Acc: 0.9115 | Val Loss: 0.2388 Acc: 0.8986\n",
      "Epoch 025 | Train Loss: 0.2088 Acc: 0.9167 | Val Loss: 0.2274 Acc: 0.9070\n",
      "Epoch 026 | Train Loss: 0.1933 Acc: 0.9222 | Val Loss: 0.3004 Acc: 0.8738\n",
      "Epoch 027 | Train Loss: 0.1983 Acc: 0.9221 | Val Loss: 0.2233 Acc: 0.9094\n",
      "Epoch 028 | Train Loss: 0.1876 Acc: 0.9283 | Val Loss: 0.1885 Acc: 0.9287\n",
      "Epoch 029 | Train Loss: 0.1773 Acc: 0.9290 | Val Loss: 0.2102 Acc: 0.9149\n",
      "Epoch 030 | Train Loss: 0.1783 Acc: 0.9295 | Val Loss: 0.2011 Acc: 0.9143\n",
      "Epoch 031 | Train Loss: 0.1642 Acc: 0.9357 | Val Loss: 0.1649 Acc: 0.9426\n",
      "Epoch 032 | Train Loss: 0.1609 Acc: 0.9392 | Val Loss: 0.1915 Acc: 0.9203\n",
      "Epoch 033 | Train Loss: 0.1489 Acc: 0.9426 | Val Loss: 0.1966 Acc: 0.9203\n",
      "Epoch 034 | Train Loss: 0.1546 Acc: 0.9407 | Val Loss: 0.1648 Acc: 0.9360\n",
      "Epoch 035 | Train Loss: 0.1463 Acc: 0.9431 | Val Loss: 0.1631 Acc: 0.9354\n",
      "Epoch 036 | Train Loss: 0.1397 Acc: 0.9449 | Val Loss: 0.1641 Acc: 0.9336\n",
      "Epoch 037 | Train Loss: 0.1618 Acc: 0.9388 | Val Loss: 0.1681 Acc: 0.9360\n",
      "Epoch 038 | Train Loss: 0.1368 Acc: 0.9462 | Val Loss: 0.1611 Acc: 0.9408\n",
      "Epoch 039 | Train Loss: 0.1439 Acc: 0.9423 | Val Loss: 0.1719 Acc: 0.9330\n",
      "Epoch 040 | Train Loss: 0.1281 Acc: 0.9530 | Val Loss: 0.1591 Acc: 0.9366\n",
      "Epoch 041 | Train Loss: 0.1258 Acc: 0.9530 | Val Loss: 0.1488 Acc: 0.9457\n",
      "Epoch 042 | Train Loss: 0.1228 Acc: 0.9515 | Val Loss: 0.1549 Acc: 0.9378\n",
      "Epoch 043 | Train Loss: 0.1281 Acc: 0.9512 | Val Loss: 0.1413 Acc: 0.9463\n",
      "Epoch 044 | Train Loss: 0.1100 Acc: 0.9603 | Val Loss: 0.1405 Acc: 0.9463\n",
      "Epoch 045 | Train Loss: 0.1148 Acc: 0.9589 | Val Loss: 0.1580 Acc: 0.9396\n",
      "Epoch 046 | Train Loss: 0.1122 Acc: 0.9555 | Val Loss: 0.1527 Acc: 0.9432\n",
      "Epoch 047 | Train Loss: 0.1048 Acc: 0.9610 | Val Loss: 0.1612 Acc: 0.9402\n",
      "Epoch 048 | Train Loss: 0.1247 Acc: 0.9515 | Val Loss: 0.1339 Acc: 0.9499\n",
      "Epoch 049 | Train Loss: 0.1045 Acc: 0.9632 | Val Loss: 0.1611 Acc: 0.9372\n",
      "Epoch 050 | Train Loss: 0.0974 Acc: 0.9632 | Val Loss: 0.1946 Acc: 0.9306\n",
      "Epoch 051 | Train Loss: 0.1085 Acc: 0.9601 | Val Loss: 0.1256 Acc: 0.9601\n",
      "Epoch 052 | Train Loss: 0.0998 Acc: 0.9612 | Val Loss: 0.1286 Acc: 0.9559\n",
      "Epoch 053 | Train Loss: 0.0990 Acc: 0.9663 | Val Loss: 0.1314 Acc: 0.9553\n",
      "Epoch 054 | Train Loss: 0.1028 Acc: 0.9618 | Val Loss: 0.1418 Acc: 0.9511\n",
      "Epoch 055 | Train Loss: 0.0993 Acc: 0.9638 | Val Loss: 0.1266 Acc: 0.9493\n",
      "Epoch 056 | Train Loss: 0.0952 Acc: 0.9663 | Val Loss: 0.1301 Acc: 0.9535\n",
      "Epoch 057 | Train Loss: 0.0936 Acc: 0.9654 | Val Loss: 0.1271 Acc: 0.9559\n",
      "Epoch 058 | Train Loss: 0.0966 Acc: 0.9636 | Val Loss: 0.1549 Acc: 0.9372\n",
      "Epoch 059 | Train Loss: 0.0913 Acc: 0.9684 | Val Loss: 0.1405 Acc: 0.9481\n",
      "Epoch 060 | Train Loss: 0.0856 Acc: 0.9692 | Val Loss: 0.1274 Acc: 0.9523\n",
      "Epoch 001 | Train Loss: 0.6777 Acc: 0.5798 | Val Loss: 0.6728 Acc: 0.5906\n",
      "Epoch 002 | Train Loss: 0.6615 Acc: 0.6061 | Val Loss: 0.6584 Acc: 0.5936\n",
      "Epoch 003 | Train Loss: 0.6229 Acc: 0.6653 | Val Loss: 0.6156 Acc: 0.6763\n",
      "Epoch 004 | Train Loss: 0.5652 Acc: 0.7189 | Val Loss: 0.5454 Acc: 0.7397\n",
      "Epoch 005 | Train Loss: 0.5280 Acc: 0.7433 | Val Loss: 0.5040 Acc: 0.7560\n",
      "Epoch 006 | Train Loss: 0.4991 Acc: 0.7678 | Val Loss: 0.5097 Acc: 0.7603\n",
      "Epoch 007 | Train Loss: 0.4618 Acc: 0.7841 | Val Loss: 0.4709 Acc: 0.7729\n",
      "Epoch 008 | Train Loss: 0.4266 Acc: 0.8021 | Val Loss: 0.4258 Acc: 0.8062\n",
      "Epoch 009 | Train Loss: 0.4063 Acc: 0.8202 | Val Loss: 0.3745 Acc: 0.8303\n",
      "Epoch 010 | Train Loss: 0.3647 Acc: 0.8386 | Val Loss: 0.3701 Acc: 0.8279\n",
      "Epoch 011 | Train Loss: 0.3491 Acc: 0.8481 | Val Loss: 0.3592 Acc: 0.8351\n",
      "Epoch 012 | Train Loss: 0.3310 Acc: 0.8564 | Val Loss: 0.3033 Acc: 0.8623\n",
      "Epoch 013 | Train Loss: 0.2951 Acc: 0.8763 | Val Loss: 0.3065 Acc: 0.8659\n",
      "Epoch 014 | Train Loss: 0.2850 Acc: 0.8804 | Val Loss: 0.2852 Acc: 0.8853\n",
      "Epoch 015 | Train Loss: 0.2704 Acc: 0.8837 | Val Loss: 0.2487 Acc: 0.8937\n",
      "Epoch 016 | Train Loss: 0.2475 Acc: 0.9011 | Val Loss: 0.2575 Acc: 0.8955\n",
      "Epoch 017 | Train Loss: 0.2398 Acc: 0.8988 | Val Loss: 0.2456 Acc: 0.8937\n",
      "Epoch 018 | Train Loss: 0.2104 Acc: 0.9132 | Val Loss: 0.2264 Acc: 0.9149\n",
      "Epoch 019 | Train Loss: 0.2180 Acc: 0.9100 | Val Loss: 0.2297 Acc: 0.9100\n",
      "Epoch 020 | Train Loss: 0.2031 Acc: 0.9167 | Val Loss: 0.2335 Acc: 0.9082\n",
      "Epoch 021 | Train Loss: 0.2001 Acc: 0.9176 | Val Loss: 0.2013 Acc: 0.9215\n",
      "Epoch 022 | Train Loss: 0.1831 Acc: 0.9296 | Val Loss: 0.2113 Acc: 0.9203\n",
      "Epoch 023 | Train Loss: 0.1859 Acc: 0.9253 | Val Loss: 0.2247 Acc: 0.9088\n",
      "Epoch 024 | Train Loss: 0.1632 Acc: 0.9385 | Val Loss: 0.1858 Acc: 0.9245\n",
      "Epoch 025 | Train Loss: 0.1569 Acc: 0.9387 | Val Loss: 0.2112 Acc: 0.9203\n",
      "Epoch 026 | Train Loss: 0.1584 Acc: 0.9372 | Val Loss: 0.1955 Acc: 0.9197\n",
      "Epoch 027 | Train Loss: 0.1575 Acc: 0.9404 | Val Loss: 0.2348 Acc: 0.9136\n",
      "Epoch 028 | Train Loss: 0.1366 Acc: 0.9443 | Val Loss: 0.1725 Acc: 0.9312\n",
      "Epoch 029 | Train Loss: 0.1422 Acc: 0.9453 | Val Loss: 0.1681 Acc: 0.9366\n",
      "Epoch 030 | Train Loss: 0.1353 Acc: 0.9487 | Val Loss: 0.1915 Acc: 0.9257\n",
      "Epoch 031 | Train Loss: 0.1292 Acc: 0.9484 | Val Loss: 0.1801 Acc: 0.9330\n",
      "Epoch 032 | Train Loss: 0.1256 Acc: 0.9526 | Val Loss: 0.1920 Acc: 0.9263\n",
      "Epoch 033 | Train Loss: 0.1303 Acc: 0.9484 | Val Loss: 0.1857 Acc: 0.9366\n",
      "Epoch 034 | Train Loss: 0.1218 Acc: 0.9535 | Val Loss: 0.1979 Acc: 0.9239\n",
      "Epoch 035 | Train Loss: 0.1153 Acc: 0.9565 | Val Loss: 0.1691 Acc: 0.9330\n",
      "Epoch 036 | Train Loss: 0.1195 Acc: 0.9541 | Val Loss: 0.1600 Acc: 0.9384\n",
      "Epoch 037 | Train Loss: 0.1002 Acc: 0.9642 | Val Loss: 0.1817 Acc: 0.9312\n",
      "Epoch 038 | Train Loss: 0.1064 Acc: 0.9601 | Val Loss: 0.1695 Acc: 0.9354\n",
      "Epoch 039 | Train Loss: 0.1086 Acc: 0.9564 | Val Loss: 0.1641 Acc: 0.9342\n",
      "Epoch 040 | Train Loss: 0.0966 Acc: 0.9612 | Val Loss: 0.1826 Acc: 0.9360\n",
      "Epoch 041 | Train Loss: 0.1002 Acc: 0.9624 | Val Loss: 0.1560 Acc: 0.9384\n",
      "Epoch 042 | Train Loss: 0.0982 Acc: 0.9648 | Val Loss: 0.1612 Acc: 0.9420\n",
      "Epoch 043 | Train Loss: 0.0959 Acc: 0.9618 | Val Loss: 0.1876 Acc: 0.9233\n",
      "Epoch 044 | Train Loss: 0.0956 Acc: 0.9657 | Val Loss: 0.1840 Acc: 0.9354\n",
      "Epoch 045 | Train Loss: 0.0962 Acc: 0.9633 | Val Loss: 0.1577 Acc: 0.9420\n",
      "Epoch 046 | Train Loss: 0.0974 Acc: 0.9630 | Val Loss: 0.1533 Acc: 0.9444\n",
      "Epoch 047 | Train Loss: 0.0865 Acc: 0.9665 | Val Loss: 0.1958 Acc: 0.9354\n",
      "Epoch 048 | Train Loss: 0.0983 Acc: 0.9613 | Val Loss: 0.2160 Acc: 0.9245\n",
      "Epoch 049 | Train Loss: 0.0904 Acc: 0.9653 | Val Loss: 0.1873 Acc: 0.9366\n",
      "Epoch 050 | Train Loss: 0.0886 Acc: 0.9680 | Val Loss: 0.1959 Acc: 0.9372\n",
      "Epoch 051 | Train Loss: 0.0885 Acc: 0.9668 | Val Loss: 0.1619 Acc: 0.9402\n",
      "Epoch 052 | Train Loss: 0.0816 Acc: 0.9707 | Val Loss: 0.1988 Acc: 0.9306\n",
      "Epoch 053 | Train Loss: 0.0899 Acc: 0.9639 | Val Loss: 0.1622 Acc: 0.9342\n",
      "Epoch 054 | Train Loss: 0.0820 Acc: 0.9703 | Val Loss: 0.1515 Acc: 0.9493\n",
      "Epoch 055 | Train Loss: 0.0762 Acc: 0.9719 | Val Loss: 0.1669 Acc: 0.9450\n",
      "Epoch 056 | Train Loss: 0.0778 Acc: 0.9715 | Val Loss: 0.1567 Acc: 0.9426\n",
      "Epoch 057 | Train Loss: 0.0858 Acc: 0.9681 | Val Loss: 0.2092 Acc: 0.9251\n",
      "Epoch 058 | Train Loss: 0.0805 Acc: 0.9698 | Val Loss: 0.1429 Acc: 0.9505\n",
      "Epoch 059 | Train Loss: 0.0757 Acc: 0.9709 | Val Loss: 0.1674 Acc: 0.9390\n",
      "Epoch 060 | Train Loss: 0.0714 Acc: 0.9746 | Val Loss: 0.1558 Acc: 0.9450\n",
      "Epoch 001 | Train Loss: 0.6822 Acc: 0.5719 | Val Loss: 0.6778 Acc: 0.5851\n",
      "Epoch 002 | Train Loss: 0.6708 Acc: 0.5947 | Val Loss: 0.6534 Acc: 0.6286\n",
      "Epoch 003 | Train Loss: 0.6350 Acc: 0.6499 | Val Loss: 0.6010 Acc: 0.6884\n",
      "Epoch 004 | Train Loss: 0.5835 Acc: 0.7033 | Val Loss: 0.5670 Acc: 0.7107\n",
      "Epoch 005 | Train Loss: 0.5582 Acc: 0.7178 | Val Loss: 0.5512 Acc: 0.7240\n",
      "Epoch 006 | Train Loss: 0.5325 Acc: 0.7414 | Val Loss: 0.5524 Acc: 0.7283\n",
      "Epoch 007 | Train Loss: 0.5249 Acc: 0.7430 | Val Loss: 0.5242 Acc: 0.7440\n",
      "Epoch 008 | Train Loss: 0.5047 Acc: 0.7577 | Val Loss: 0.4996 Acc: 0.7603\n",
      "Epoch 009 | Train Loss: 0.4869 Acc: 0.7696 | Val Loss: 0.4810 Acc: 0.7579\n",
      "Epoch 010 | Train Loss: 0.4707 Acc: 0.7774 | Val Loss: 0.4972 Acc: 0.7603\n",
      "Epoch 011 | Train Loss: 0.4513 Acc: 0.7915 | Val Loss: 0.4436 Acc: 0.7717\n",
      "Epoch 012 | Train Loss: 0.4280 Acc: 0.7984 | Val Loss: 0.4205 Acc: 0.7929\n",
      "Epoch 013 | Train Loss: 0.4167 Acc: 0.8113 | Val Loss: 0.3982 Acc: 0.8092\n",
      "Epoch 014 | Train Loss: 0.3935 Acc: 0.8212 | Val Loss: 0.3667 Acc: 0.8315\n",
      "Epoch 015 | Train Loss: 0.3559 Acc: 0.8433 | Val Loss: 0.3780 Acc: 0.8267\n",
      "Epoch 016 | Train Loss: 0.3531 Acc: 0.8443 | Val Loss: 0.3364 Acc: 0.8527\n",
      "Epoch 017 | Train Loss: 0.3310 Acc: 0.8544 | Val Loss: 0.3133 Acc: 0.8635\n",
      "Epoch 018 | Train Loss: 0.3286 Acc: 0.8612 | Val Loss: 0.3106 Acc: 0.8605\n",
      "Epoch 019 | Train Loss: 0.3087 Acc: 0.8665 | Val Loss: 0.2798 Acc: 0.8810\n",
      "Epoch 020 | Train Loss: 0.3069 Acc: 0.8703 | Val Loss: 0.2756 Acc: 0.8798\n",
      "Epoch 021 | Train Loss: 0.2985 Acc: 0.8769 | Val Loss: 0.3063 Acc: 0.8659\n",
      "Epoch 022 | Train Loss: 0.2679 Acc: 0.8931 | Val Loss: 0.2816 Acc: 0.8871\n",
      "Epoch 023 | Train Loss: 0.2545 Acc: 0.8920 | Val Loss: 0.2443 Acc: 0.8986\n",
      "Epoch 024 | Train Loss: 0.2440 Acc: 0.8997 | Val Loss: 0.2341 Acc: 0.9016\n",
      "Epoch 025 | Train Loss: 0.2337 Acc: 0.9080 | Val Loss: 0.2302 Acc: 0.9082\n",
      "Epoch 026 | Train Loss: 0.2348 Acc: 0.9073 | Val Loss: 0.2444 Acc: 0.8998\n",
      "Epoch 027 | Train Loss: 0.2119 Acc: 0.9153 | Val Loss: 0.2257 Acc: 0.9100\n",
      "Epoch 028 | Train Loss: 0.2183 Acc: 0.9151 | Val Loss: 0.2265 Acc: 0.9070\n",
      "Epoch 029 | Train Loss: 0.2067 Acc: 0.9186 | Val Loss: 0.2145 Acc: 0.9173\n",
      "Epoch 030 | Train Loss: 0.1995 Acc: 0.9200 | Val Loss: 0.2466 Acc: 0.8979\n",
      "Epoch 031 | Train Loss: 0.1978 Acc: 0.9212 | Val Loss: 0.1938 Acc: 0.9275\n",
      "Epoch 032 | Train Loss: 0.1878 Acc: 0.9284 | Val Loss: 0.1789 Acc: 0.9293\n",
      "Epoch 033 | Train Loss: 0.1728 Acc: 0.9307 | Val Loss: 0.2008 Acc: 0.9233\n",
      "Epoch 034 | Train Loss: 0.1745 Acc: 0.9296 | Val Loss: 0.1830 Acc: 0.9312\n",
      "Epoch 035 | Train Loss: 0.1739 Acc: 0.9307 | Val Loss: 0.1956 Acc: 0.9227\n",
      "Epoch 036 | Train Loss: 0.1675 Acc: 0.9355 | Val Loss: 0.1818 Acc: 0.9293\n",
      "Epoch 037 | Train Loss: 0.1632 Acc: 0.9372 | Val Loss: 0.1757 Acc: 0.9269\n",
      "Epoch 038 | Train Loss: 0.1470 Acc: 0.9399 | Val Loss: 0.1792 Acc: 0.9366\n",
      "Epoch 039 | Train Loss: 0.1618 Acc: 0.9401 | Val Loss: 0.1748 Acc: 0.9336\n",
      "Epoch 040 | Train Loss: 0.1422 Acc: 0.9447 | Val Loss: 0.1652 Acc: 0.9336\n",
      "Epoch 041 | Train Loss: 0.1405 Acc: 0.9452 | Val Loss: 0.1571 Acc: 0.9378\n",
      "Epoch 042 | Train Loss: 0.1400 Acc: 0.9478 | Val Loss: 0.1570 Acc: 0.9390\n",
      "Epoch 043 | Train Loss: 0.1226 Acc: 0.9536 | Val Loss: 0.1735 Acc: 0.9312\n",
      "Epoch 044 | Train Loss: 0.1312 Acc: 0.9500 | Val Loss: 0.1634 Acc: 0.9312\n",
      "Epoch 045 | Train Loss: 0.1243 Acc: 0.9500 | Val Loss: 0.1608 Acc: 0.9354\n",
      "Epoch 046 | Train Loss: 0.1193 Acc: 0.9535 | Val Loss: 0.1556 Acc: 0.9426\n",
      "Epoch 047 | Train Loss: 0.1294 Acc: 0.9494 | Val Loss: 0.1733 Acc: 0.9287\n",
      "Epoch 048 | Train Loss: 0.1104 Acc: 0.9556 | Val Loss: 0.1664 Acc: 0.9384\n",
      "Epoch 049 | Train Loss: 0.1102 Acc: 0.9565 | Val Loss: 0.1539 Acc: 0.9432\n",
      "Epoch 050 | Train Loss: 0.1065 Acc: 0.9597 | Val Loss: 0.1577 Acc: 0.9493\n",
      "Epoch 051 | Train Loss: 0.1123 Acc: 0.9556 | Val Loss: 0.1756 Acc: 0.9384\n",
      "Epoch 052 | Train Loss: 0.1113 Acc: 0.9585 | Val Loss: 0.1631 Acc: 0.9390\n",
      "Epoch 053 | Train Loss: 0.1020 Acc: 0.9606 | Val Loss: 0.1522 Acc: 0.9469\n",
      "Epoch 054 | Train Loss: 0.1048 Acc: 0.9583 | Val Loss: 0.1453 Acc: 0.9505\n",
      "Epoch 055 | Train Loss: 0.0987 Acc: 0.9603 | Val Loss: 0.1451 Acc: 0.9469\n",
      "Epoch 056 | Train Loss: 0.1167 Acc: 0.9556 | Val Loss: 0.1341 Acc: 0.9475\n",
      "Epoch 057 | Train Loss: 0.0958 Acc: 0.9657 | Val Loss: 0.1577 Acc: 0.9438\n",
      "Epoch 058 | Train Loss: 0.0992 Acc: 0.9609 | Val Loss: 0.1398 Acc: 0.9438\n",
      "Epoch 059 | Train Loss: 0.0980 Acc: 0.9633 | Val Loss: 0.1523 Acc: 0.9475\n",
      "Epoch 060 | Train Loss: 0.0941 Acc: 0.9647 | Val Loss: 0.1282 Acc: 0.9529\n",
      "Epoch 001 | Train Loss: 0.6850 Acc: 0.5671 | Val Loss: 0.6882 Acc: 0.5616\n",
      "Epoch 002 | Train Loss: 0.6782 Acc: 0.5857 | Val Loss: 0.6781 Acc: 0.5791\n",
      "Epoch 003 | Train Loss: 0.6704 Acc: 0.6035 | Val Loss: 0.6709 Acc: 0.5936\n",
      "Epoch 004 | Train Loss: 0.6626 Acc: 0.6076 | Val Loss: 0.6512 Acc: 0.6214\n",
      "Epoch 005 | Train Loss: 0.6524 Acc: 0.6219 | Val Loss: 0.6206 Acc: 0.6800\n",
      "Epoch 006 | Train Loss: 0.6110 Acc: 0.6856 | Val Loss: 0.6119 Acc: 0.6697\n",
      "Epoch 007 | Train Loss: 0.6024 Acc: 0.7009 | Val Loss: 0.5741 Acc: 0.7107\n",
      "Epoch 008 | Train Loss: 0.5783 Acc: 0.7124 | Val Loss: 0.5716 Acc: 0.7107\n",
      "Epoch 009 | Train Loss: 0.5635 Acc: 0.7225 | Val Loss: 0.5720 Acc: 0.6975\n",
      "Epoch 010 | Train Loss: 0.5530 Acc: 0.7308 | Val Loss: 0.5494 Acc: 0.7240\n",
      "Epoch 011 | Train Loss: 0.5380 Acc: 0.7433 | Val Loss: 0.5607 Acc: 0.7271\n",
      "Epoch 012 | Train Loss: 0.5427 Acc: 0.7370 | Val Loss: 0.5428 Acc: 0.7307\n",
      "Epoch 013 | Train Loss: 0.5354 Acc: 0.7391 | Val Loss: 0.5627 Acc: 0.7198\n",
      "Epoch 014 | Train Loss: 0.5193 Acc: 0.7474 | Val Loss: 0.5499 Acc: 0.7258\n",
      "Epoch 015 | Train Loss: 0.5145 Acc: 0.7548 | Val Loss: 0.5258 Acc: 0.7452\n",
      "Epoch 016 | Train Loss: 0.5112 Acc: 0.7524 | Val Loss: 0.5094 Acc: 0.7512\n",
      "Epoch 017 | Train Loss: 0.4944 Acc: 0.7658 | Val Loss: 0.4994 Acc: 0.7566\n",
      "Epoch 018 | Train Loss: 0.4859 Acc: 0.7672 | Val Loss: 0.5206 Acc: 0.7488\n",
      "Epoch 019 | Train Loss: 0.4779 Acc: 0.7780 | Val Loss: 0.4825 Acc: 0.7723\n",
      "Epoch 020 | Train Loss: 0.4721 Acc: 0.7782 | Val Loss: 0.4777 Acc: 0.7723\n",
      "Epoch 021 | Train Loss: 0.4618 Acc: 0.7808 | Val Loss: 0.4742 Acc: 0.7802\n",
      "Epoch 022 | Train Loss: 0.4453 Acc: 0.7900 | Val Loss: 0.4426 Acc: 0.7814\n",
      "Epoch 023 | Train Loss: 0.4350 Acc: 0.7969 | Val Loss: 0.4497 Acc: 0.7772\n",
      "Epoch 024 | Train Loss: 0.4248 Acc: 0.8070 | Val Loss: 0.4345 Acc: 0.7917\n",
      "Epoch 025 | Train Loss: 0.4124 Acc: 0.8120 | Val Loss: 0.4161 Acc: 0.8110\n",
      "Epoch 026 | Train Loss: 0.4074 Acc: 0.8172 | Val Loss: 0.4031 Acc: 0.8134\n",
      "Epoch 027 | Train Loss: 0.3880 Acc: 0.8235 | Val Loss: 0.3989 Acc: 0.8164\n",
      "Epoch 028 | Train Loss: 0.3768 Acc: 0.8246 | Val Loss: 0.3814 Acc: 0.8249\n",
      "Epoch 029 | Train Loss: 0.3611 Acc: 0.8442 | Val Loss: 0.3477 Acc: 0.8460\n",
      "Epoch 030 | Train Loss: 0.3521 Acc: 0.8410 | Val Loss: 0.3454 Acc: 0.8508\n",
      "Epoch 031 | Train Loss: 0.3355 Acc: 0.8517 | Val Loss: 0.3807 Acc: 0.8315\n",
      "Epoch 032 | Train Loss: 0.3198 Acc: 0.8612 | Val Loss: 0.2947 Acc: 0.8738\n",
      "Epoch 033 | Train Loss: 0.3156 Acc: 0.8646 | Val Loss: 0.3063 Acc: 0.8684\n",
      "Epoch 034 | Train Loss: 0.3047 Acc: 0.8688 | Val Loss: 0.2886 Acc: 0.8762\n",
      "Epoch 035 | Train Loss: 0.2941 Acc: 0.8812 | Val Loss: 0.2797 Acc: 0.8841\n",
      "Epoch 036 | Train Loss: 0.2890 Acc: 0.8813 | Val Loss: 0.2724 Acc: 0.8853\n",
      "Epoch 037 | Train Loss: 0.2754 Acc: 0.8874 | Val Loss: 0.2411 Acc: 0.9046\n",
      "Epoch 038 | Train Loss: 0.2763 Acc: 0.8840 | Val Loss: 0.2373 Acc: 0.9022\n",
      "Epoch 039 | Train Loss: 0.2650 Acc: 0.8936 | Val Loss: 0.2758 Acc: 0.8937\n",
      "Epoch 040 | Train Loss: 0.2530 Acc: 0.8978 | Val Loss: 0.2727 Acc: 0.8865\n",
      "Epoch 041 | Train Loss: 0.2512 Acc: 0.8948 | Val Loss: 0.2659 Acc: 0.8931\n",
      "Epoch 042 | Train Loss: 0.2397 Acc: 0.9029 | Val Loss: 0.2643 Acc: 0.8919\n",
      "Epoch 043 | Train Loss: 0.2425 Acc: 0.9041 | Val Loss: 0.2525 Acc: 0.8937\n",
      "Epoch 044 | Train Loss: 0.2267 Acc: 0.9073 | Val Loss: 0.2296 Acc: 0.9100\n",
      "Epoch 045 | Train Loss: 0.2181 Acc: 0.9182 | Val Loss: 0.2298 Acc: 0.9149\n",
      "Epoch 046 | Train Loss: 0.2136 Acc: 0.9142 | Val Loss: 0.2512 Acc: 0.9143\n",
      "Epoch 047 | Train Loss: 0.2272 Acc: 0.9106 | Val Loss: 0.2250 Acc: 0.9106\n",
      "Epoch 048 | Train Loss: 0.2211 Acc: 0.9121 | Val Loss: 0.2332 Acc: 0.9106\n",
      "Epoch 049 | Train Loss: 0.2174 Acc: 0.9151 | Val Loss: 0.2191 Acc: 0.9185\n",
      "Epoch 050 | Train Loss: 0.1989 Acc: 0.9215 | Val Loss: 0.2181 Acc: 0.9124\n",
      "Epoch 051 | Train Loss: 0.1998 Acc: 0.9231 | Val Loss: 0.2035 Acc: 0.9239\n",
      "Epoch 052 | Train Loss: 0.1913 Acc: 0.9257 | Val Loss: 0.1922 Acc: 0.9324\n",
      "Epoch 053 | Train Loss: 0.1935 Acc: 0.9265 | Val Loss: 0.2017 Acc: 0.9293\n",
      "Epoch 054 | Train Loss: 0.2048 Acc: 0.9215 | Val Loss: 0.1975 Acc: 0.9227\n",
      "Epoch 055 | Train Loss: 0.1836 Acc: 0.9322 | Val Loss: 0.1928 Acc: 0.9287\n",
      "Epoch 056 | Train Loss: 0.1789 Acc: 0.9293 | Val Loss: 0.1891 Acc: 0.9275\n",
      "Epoch 057 | Train Loss: 0.1683 Acc: 0.9395 | Val Loss: 0.1980 Acc: 0.9281\n",
      "Epoch 058 | Train Loss: 0.1710 Acc: 0.9348 | Val Loss: 0.2168 Acc: 0.9221\n",
      "Epoch 059 | Train Loss: 0.1629 Acc: 0.9388 | Val Loss: 0.1909 Acc: 0.9293\n",
      "Epoch 060 | Train Loss: 0.1752 Acc: 0.9343 | Val Loss: 0.1864 Acc: 0.9287\n",
      "Epoch 001 | Train Loss: 0.6817 Acc: 0.5668 | Val Loss: 0.6756 Acc: 0.5815\n",
      "Epoch 002 | Train Loss: 0.6614 Acc: 0.6095 | Val Loss: 0.6369 Acc: 0.6431\n",
      "Epoch 003 | Train Loss: 0.6180 Acc: 0.6813 | Val Loss: 0.6010 Acc: 0.6848\n",
      "Epoch 004 | Train Loss: 0.5902 Acc: 0.7016 | Val Loss: 0.5782 Acc: 0.7059\n",
      "Epoch 005 | Train Loss: 0.5578 Acc: 0.7241 | Val Loss: 0.5524 Acc: 0.7144\n",
      "Epoch 006 | Train Loss: 0.5370 Acc: 0.7377 | Val Loss: 0.5726 Acc: 0.7168\n",
      "Epoch 007 | Train Loss: 0.5164 Acc: 0.7515 | Val Loss: 0.5104 Acc: 0.7446\n",
      "Epoch 008 | Train Loss: 0.4941 Acc: 0.7611 | Val Loss: 0.4959 Acc: 0.7669\n",
      "Epoch 009 | Train Loss: 0.4639 Acc: 0.7847 | Val Loss: 0.4583 Acc: 0.7736\n",
      "Epoch 010 | Train Loss: 0.4353 Acc: 0.7965 | Val Loss: 0.4246 Acc: 0.8037\n",
      "Epoch 011 | Train Loss: 0.4232 Acc: 0.8082 | Val Loss: 0.3701 Acc: 0.8303\n",
      "Epoch 012 | Train Loss: 0.3811 Acc: 0.8306 | Val Loss: 0.3713 Acc: 0.8364\n",
      "Epoch 013 | Train Loss: 0.3553 Acc: 0.8425 | Val Loss: 0.3176 Acc: 0.8502\n",
      "Epoch 014 | Train Loss: 0.3283 Acc: 0.8606 | Val Loss: 0.3588 Acc: 0.8382\n",
      "Epoch 015 | Train Loss: 0.3050 Acc: 0.8712 | Val Loss: 0.2957 Acc: 0.8671\n",
      "Epoch 016 | Train Loss: 0.2767 Acc: 0.8833 | Val Loss: 0.2844 Acc: 0.8822\n",
      "Epoch 017 | Train Loss: 0.2590 Acc: 0.8926 | Val Loss: 0.2803 Acc: 0.8780\n",
      "Epoch 018 | Train Loss: 0.2384 Acc: 0.9047 | Val Loss: 0.2554 Acc: 0.8919\n",
      "Epoch 019 | Train Loss: 0.2359 Acc: 0.9049 | Val Loss: 0.2370 Acc: 0.8955\n",
      "Epoch 020 | Train Loss: 0.2136 Acc: 0.9168 | Val Loss: 0.2741 Acc: 0.8871\n",
      "Epoch 021 | Train Loss: 0.2015 Acc: 0.9206 | Val Loss: 0.2267 Acc: 0.9130\n",
      "Epoch 022 | Train Loss: 0.1983 Acc: 0.9242 | Val Loss: 0.2348 Acc: 0.9112\n",
      "Epoch 023 | Train Loss: 0.1887 Acc: 0.9238 | Val Loss: 0.1902 Acc: 0.9257\n",
      "Epoch 024 | Train Loss: 0.1619 Acc: 0.9370 | Val Loss: 0.2394 Acc: 0.9136\n",
      "Epoch 025 | Train Loss: 0.1704 Acc: 0.9363 | Val Loss: 0.2029 Acc: 0.9215\n",
      "Epoch 026 | Train Loss: 0.1545 Acc: 0.9385 | Val Loss: 0.2156 Acc: 0.9124\n",
      "Epoch 027 | Train Loss: 0.1615 Acc: 0.9388 | Val Loss: 0.2251 Acc: 0.9100\n",
      "Epoch 028 | Train Loss: 0.1424 Acc: 0.9462 | Val Loss: 0.2404 Acc: 0.9070\n",
      "Epoch 029 | Train Loss: 0.1381 Acc: 0.9478 | Val Loss: 0.1712 Acc: 0.9408\n",
      "Epoch 030 | Train Loss: 0.1317 Acc: 0.9479 | Val Loss: 0.1717 Acc: 0.9366\n",
      "Epoch 031 | Train Loss: 0.1236 Acc: 0.9524 | Val Loss: 0.1609 Acc: 0.9342\n",
      "Epoch 032 | Train Loss: 0.1188 Acc: 0.9530 | Val Loss: 0.1926 Acc: 0.9275\n",
      "Epoch 033 | Train Loss: 0.1167 Acc: 0.9573 | Val Loss: 0.1547 Acc: 0.9487\n",
      "Epoch 034 | Train Loss: 0.1168 Acc: 0.9555 | Val Loss: 0.1809 Acc: 0.9366\n",
      "Epoch 035 | Train Loss: 0.1143 Acc: 0.9558 | Val Loss: 0.1574 Acc: 0.9457\n",
      "Epoch 036 | Train Loss: 0.1095 Acc: 0.9589 | Val Loss: 0.1674 Acc: 0.9450\n",
      "Epoch 037 | Train Loss: 0.0952 Acc: 0.9645 | Val Loss: 0.1911 Acc: 0.9366\n",
      "Epoch 038 | Train Loss: 0.1010 Acc: 0.9629 | Val Loss: 0.1734 Acc: 0.9390\n",
      "Epoch 039 | Train Loss: 0.0921 Acc: 0.9656 | Val Loss: 0.1936 Acc: 0.9287\n",
      "Epoch 040 | Train Loss: 0.0977 Acc: 0.9630 | Val Loss: 0.1703 Acc: 0.9390\n",
      "Epoch 041 | Train Loss: 0.1023 Acc: 0.9601 | Val Loss: 0.1584 Acc: 0.9402\n",
      "Epoch 042 | Train Loss: 0.0846 Acc: 0.9695 | Val Loss: 0.2086 Acc: 0.9293\n",
      "Epoch 043 | Train Loss: 0.0936 Acc: 0.9687 | Val Loss: 0.1408 Acc: 0.9523\n",
      "Epoch 044 | Train Loss: 0.0846 Acc: 0.9695 | Val Loss: 0.1551 Acc: 0.9450\n",
      "Epoch 045 | Train Loss: 0.0902 Acc: 0.9677 | Val Loss: 0.1549 Acc: 0.9426\n",
      "Epoch 046 | Train Loss: 0.0774 Acc: 0.9715 | Val Loss: 0.1452 Acc: 0.9469\n",
      "Epoch 047 | Train Loss: 0.0616 Acc: 0.9783 | Val Loss: 0.1425 Acc: 0.9565\n",
      "Epoch 048 | Train Loss: 0.0733 Acc: 0.9736 | Val Loss: 0.1559 Acc: 0.9463\n",
      "Epoch 049 | Train Loss: 0.0740 Acc: 0.9749 | Val Loss: 0.1833 Acc: 0.9414\n",
      "Epoch 050 | Train Loss: 0.0843 Acc: 0.9697 | Val Loss: 0.1490 Acc: 0.9505\n",
      "Epoch 051 | Train Loss: 0.0673 Acc: 0.9769 | Val Loss: 0.1571 Acc: 0.9444\n",
      "Epoch 052 | Train Loss: 0.0659 Acc: 0.9775 | Val Loss: 0.1724 Acc: 0.9444\n",
      "Epoch 053 | Train Loss: 0.0754 Acc: 0.9748 | Val Loss: 0.1631 Acc: 0.9432\n",
      "Early stopping triggered.\n",
      "Epoch 001 | Train Loss: 0.6763 Acc: 0.5846 | Val Loss: 0.6737 Acc: 0.5851\n",
      "Epoch 002 | Train Loss: 0.6348 Acc: 0.6551 | Val Loss: 0.6085 Acc: 0.6703\n",
      "Epoch 003 | Train Loss: 0.5847 Acc: 0.6992 | Val Loss: 0.5862 Acc: 0.6824\n",
      "Epoch 004 | Train Loss: 0.5544 Acc: 0.7237 | Val Loss: 0.5805 Acc: 0.7065\n",
      "Epoch 005 | Train Loss: 0.5392 Acc: 0.7371 | Val Loss: 0.5300 Acc: 0.7385\n",
      "Epoch 006 | Train Loss: 0.5227 Acc: 0.7420 | Val Loss: 0.5349 Acc: 0.7277\n",
      "Epoch 007 | Train Loss: 0.5051 Acc: 0.7562 | Val Loss: 0.5128 Acc: 0.7403\n",
      "Epoch 008 | Train Loss: 0.4770 Acc: 0.7746 | Val Loss: 0.4745 Acc: 0.7693\n",
      "Epoch 009 | Train Loss: 0.4801 Acc: 0.7700 | Val Loss: 0.4695 Acc: 0.7681\n",
      "Epoch 010 | Train Loss: 0.4609 Acc: 0.7844 | Val Loss: 0.4447 Acc: 0.7856\n",
      "Epoch 011 | Train Loss: 0.4315 Acc: 0.7987 | Val Loss: 0.4361 Acc: 0.7826\n",
      "Epoch 012 | Train Loss: 0.4051 Acc: 0.8116 | Val Loss: 0.4442 Acc: 0.7971\n",
      "Epoch 013 | Train Loss: 0.4026 Acc: 0.8193 | Val Loss: 0.3812 Acc: 0.8285\n",
      "Epoch 014 | Train Loss: 0.3842 Acc: 0.8289 | Val Loss: 0.3603 Acc: 0.8351\n",
      "Epoch 015 | Train Loss: 0.3657 Acc: 0.8384 | Val Loss: 0.3354 Acc: 0.8521\n",
      "Epoch 016 | Train Loss: 0.3371 Acc: 0.8549 | Val Loss: 0.3342 Acc: 0.8575\n",
      "Epoch 017 | Train Loss: 0.3134 Acc: 0.8670 | Val Loss: 0.2853 Acc: 0.8804\n",
      "Epoch 018 | Train Loss: 0.2918 Acc: 0.8745 | Val Loss: 0.2837 Acc: 0.8804\n",
      "Epoch 019 | Train Loss: 0.2895 Acc: 0.8783 | Val Loss: 0.2768 Acc: 0.8877\n",
      "Epoch 020 | Train Loss: 0.2744 Acc: 0.8859 | Val Loss: 0.2791 Acc: 0.8792\n",
      "Epoch 021 | Train Loss: 0.2531 Acc: 0.8942 | Val Loss: 0.2569 Acc: 0.8907\n",
      "Epoch 022 | Train Loss: 0.2509 Acc: 0.8952 | Val Loss: 0.2622 Acc: 0.8883\n",
      "Epoch 023 | Train Loss: 0.2364 Acc: 0.9065 | Val Loss: 0.2355 Acc: 0.9034\n",
      "Epoch 024 | Train Loss: 0.2252 Acc: 0.9099 | Val Loss: 0.2098 Acc: 0.9112\n",
      "Epoch 025 | Train Loss: 0.2130 Acc: 0.9165 | Val Loss: 0.2083 Acc: 0.9185\n",
      "Epoch 026 | Train Loss: 0.2118 Acc: 0.9145 | Val Loss: 0.2043 Acc: 0.9215\n",
      "Epoch 027 | Train Loss: 0.2011 Acc: 0.9176 | Val Loss: 0.2676 Acc: 0.9016\n",
      "Epoch 028 | Train Loss: 0.2067 Acc: 0.9179 | Val Loss: 0.2340 Acc: 0.9058\n",
      "Epoch 029 | Train Loss: 0.1973 Acc: 0.9183 | Val Loss: 0.1997 Acc: 0.9191\n",
      "Epoch 030 | Train Loss: 0.1890 Acc: 0.9283 | Val Loss: 0.1897 Acc: 0.9360\n",
      "Epoch 031 | Train Loss: 0.1866 Acc: 0.9280 | Val Loss: 0.1892 Acc: 0.9257\n",
      "Epoch 032 | Train Loss: 0.1744 Acc: 0.9319 | Val Loss: 0.2025 Acc: 0.9239\n",
      "Epoch 033 | Train Loss: 0.1679 Acc: 0.9373 | Val Loss: 0.1913 Acc: 0.9239\n",
      "Epoch 034 | Train Loss: 0.1623 Acc: 0.9387 | Val Loss: 0.2124 Acc: 0.9155\n",
      "Epoch 035 | Train Loss: 0.1580 Acc: 0.9396 | Val Loss: 0.1681 Acc: 0.9426\n",
      "Epoch 036 | Train Loss: 0.1532 Acc: 0.9416 | Val Loss: 0.2012 Acc: 0.9245\n",
      "Epoch 037 | Train Loss: 0.1504 Acc: 0.9426 | Val Loss: 0.1733 Acc: 0.9324\n",
      "Epoch 038 | Train Loss: 0.1667 Acc: 0.9381 | Val Loss: 0.2073 Acc: 0.9239\n",
      "Epoch 039 | Train Loss: 0.1480 Acc: 0.9459 | Val Loss: 0.1686 Acc: 0.9330\n",
      "Epoch 040 | Train Loss: 0.1475 Acc: 0.9481 | Val Loss: 0.1686 Acc: 0.9354\n",
      "Epoch 041 | Train Loss: 0.1294 Acc: 0.9506 | Val Loss: 0.1643 Acc: 0.9348\n",
      "Epoch 042 | Train Loss: 0.1377 Acc: 0.9465 | Val Loss: 0.1719 Acc: 0.9408\n",
      "Epoch 043 | Train Loss: 0.1390 Acc: 0.9449 | Val Loss: 0.1453 Acc: 0.9432\n",
      "Epoch 044 | Train Loss: 0.1407 Acc: 0.9456 | Val Loss: 0.1487 Acc: 0.9402\n",
      "Epoch 045 | Train Loss: 0.1280 Acc: 0.9535 | Val Loss: 0.1495 Acc: 0.9414\n",
      "Epoch 046 | Train Loss: 0.1291 Acc: 0.9523 | Val Loss: 0.1465 Acc: 0.9475\n",
      "Epoch 047 | Train Loss: 0.1252 Acc: 0.9521 | Val Loss: 0.1659 Acc: 0.9372\n",
      "Epoch 048 | Train Loss: 0.1142 Acc: 0.9561 | Val Loss: 0.1644 Acc: 0.9396\n",
      "Epoch 049 | Train Loss: 0.1226 Acc: 0.9527 | Val Loss: 0.1478 Acc: 0.9457\n",
      "Epoch 050 | Train Loss: 0.1207 Acc: 0.9573 | Val Loss: 0.1824 Acc: 0.9312\n",
      "Epoch 051 | Train Loss: 0.1243 Acc: 0.9530 | Val Loss: 0.1763 Acc: 0.9281\n",
      "Epoch 052 | Train Loss: 0.1085 Acc: 0.9568 | Val Loss: 0.1700 Acc: 0.9390\n",
      "Epoch 053 | Train Loss: 0.1106 Acc: 0.9582 | Val Loss: 0.1439 Acc: 0.9469\n",
      "Epoch 054 | Train Loss: 0.1250 Acc: 0.9518 | Val Loss: 0.1522 Acc: 0.9450\n",
      "Epoch 055 | Train Loss: 0.1088 Acc: 0.9571 | Val Loss: 0.1741 Acc: 0.9450\n",
      "Epoch 056 | Train Loss: 0.0957 Acc: 0.9648 | Val Loss: 0.1548 Acc: 0.9438\n",
      "Epoch 057 | Train Loss: 0.1197 Acc: 0.9550 | Val Loss: 0.1465 Acc: 0.9432\n",
      "Epoch 058 | Train Loss: 0.1109 Acc: 0.9601 | Val Loss: 0.1286 Acc: 0.9547\n",
      "Epoch 059 | Train Loss: 0.0939 Acc: 0.9666 | Val Loss: 0.1448 Acc: 0.9493\n",
      "Epoch 060 | Train Loss: 0.0941 Acc: 0.9666 | Val Loss: 0.1616 Acc: 0.9420\n",
      "Epoch 001 | Train Loss: 0.6812 Acc: 0.5774 | Val Loss: 0.6736 Acc: 0.5924\n",
      "Epoch 002 | Train Loss: 0.6787 Acc: 0.5766 | Val Loss: 0.6650 Acc: 0.6008\n",
      "Epoch 003 | Train Loss: 0.6614 Acc: 0.6097 | Val Loss: 0.6440 Acc: 0.6178\n",
      "Epoch 004 | Train Loss: 0.6208 Acc: 0.6665 | Val Loss: 0.6072 Acc: 0.6872\n",
      "Epoch 005 | Train Loss: 0.5784 Acc: 0.7054 | Val Loss: 0.5848 Acc: 0.7083\n",
      "Epoch 006 | Train Loss: 0.5530 Acc: 0.7278 | Val Loss: 0.5324 Acc: 0.7295\n",
      "Epoch 007 | Train Loss: 0.5244 Acc: 0.7457 | Val Loss: 0.5086 Acc: 0.7476\n",
      "Epoch 008 | Train Loss: 0.4906 Acc: 0.7681 | Val Loss: 0.4682 Acc: 0.7814\n",
      "Epoch 009 | Train Loss: 0.4772 Acc: 0.7750 | Val Loss: 0.5071 Acc: 0.7470\n",
      "Epoch 010 | Train Loss: 0.4636 Acc: 0.7836 | Val Loss: 0.4537 Acc: 0.7862\n",
      "Epoch 011 | Train Loss: 0.4341 Acc: 0.7960 | Val Loss: 0.4365 Acc: 0.7886\n",
      "Epoch 012 | Train Loss: 0.4077 Acc: 0.8150 | Val Loss: 0.4272 Acc: 0.8043\n",
      "Epoch 013 | Train Loss: 0.3877 Acc: 0.8262 | Val Loss: 0.3787 Acc: 0.8327\n",
      "Epoch 014 | Train Loss: 0.3631 Acc: 0.8396 | Val Loss: 0.3971 Acc: 0.8213\n",
      "Epoch 015 | Train Loss: 0.3420 Acc: 0.8496 | Val Loss: 0.3545 Acc: 0.8364\n",
      "Epoch 016 | Train Loss: 0.3178 Acc: 0.8652 | Val Loss: 0.3286 Acc: 0.8575\n",
      "Epoch 017 | Train Loss: 0.2935 Acc: 0.8747 | Val Loss: 0.2926 Acc: 0.8714\n",
      "Epoch 018 | Train Loss: 0.2687 Acc: 0.8889 | Val Loss: 0.2517 Acc: 0.9004\n",
      "Epoch 019 | Train Loss: 0.2594 Acc: 0.8910 | Val Loss: 0.2861 Acc: 0.8853\n",
      "Epoch 020 | Train Loss: 0.2350 Acc: 0.9049 | Val Loss: 0.2540 Acc: 0.8859\n",
      "Epoch 021 | Train Loss: 0.2218 Acc: 0.9068 | Val Loss: 0.2640 Acc: 0.8871\n",
      "Epoch 022 | Train Loss: 0.2175 Acc: 0.9154 | Val Loss: 0.2443 Acc: 0.9004\n",
      "Epoch 023 | Train Loss: 0.1927 Acc: 0.9238 | Val Loss: 0.2280 Acc: 0.9082\n",
      "Epoch 024 | Train Loss: 0.2032 Acc: 0.9207 | Val Loss: 0.2245 Acc: 0.9100\n",
      "Epoch 025 | Train Loss: 0.1760 Acc: 0.9284 | Val Loss: 0.2144 Acc: 0.9197\n",
      "Epoch 026 | Train Loss: 0.1725 Acc: 0.9348 | Val Loss: 0.2060 Acc: 0.9149\n",
      "Epoch 027 | Train Loss: 0.1582 Acc: 0.9410 | Val Loss: 0.1931 Acc: 0.9239\n",
      "Epoch 028 | Train Loss: 0.1704 Acc: 0.9348 | Val Loss: 0.1904 Acc: 0.9203\n",
      "Epoch 029 | Train Loss: 0.1519 Acc: 0.9428 | Val Loss: 0.1934 Acc: 0.9185\n",
      "Epoch 030 | Train Loss: 0.1450 Acc: 0.9413 | Val Loss: 0.2029 Acc: 0.9263\n",
      "Epoch 031 | Train Loss: 0.1531 Acc: 0.9434 | Val Loss: 0.1886 Acc: 0.9281\n",
      "Epoch 032 | Train Loss: 0.1378 Acc: 0.9464 | Val Loss: 0.1815 Acc: 0.9287\n",
      "Epoch 033 | Train Loss: 0.1374 Acc: 0.9456 | Val Loss: 0.2066 Acc: 0.9209\n",
      "Epoch 034 | Train Loss: 0.1343 Acc: 0.9470 | Val Loss: 0.1708 Acc: 0.9336\n",
      "Epoch 035 | Train Loss: 0.1161 Acc: 0.9546 | Val Loss: 0.1586 Acc: 0.9366\n",
      "Epoch 036 | Train Loss: 0.1157 Acc: 0.9561 | Val Loss: 0.1862 Acc: 0.9275\n",
      "Epoch 037 | Train Loss: 0.1071 Acc: 0.9591 | Val Loss: 0.1757 Acc: 0.9318\n",
      "Epoch 038 | Train Loss: 0.1120 Acc: 0.9564 | Val Loss: 0.1670 Acc: 0.9348\n",
      "Epoch 039 | Train Loss: 0.1136 Acc: 0.9585 | Val Loss: 0.2039 Acc: 0.9306\n",
      "Epoch 040 | Train Loss: 0.1098 Acc: 0.9585 | Val Loss: 0.2194 Acc: 0.9185\n",
      "Epoch 041 | Train Loss: 0.1086 Acc: 0.9606 | Val Loss: 0.1778 Acc: 0.9336\n",
      "Epoch 042 | Train Loss: 0.0969 Acc: 0.9642 | Val Loss: 0.1429 Acc: 0.9475\n",
      "Epoch 043 | Train Loss: 0.0943 Acc: 0.9636 | Val Loss: 0.1607 Acc: 0.9318\n",
      "Epoch 044 | Train Loss: 0.0965 Acc: 0.9618 | Val Loss: 0.1624 Acc: 0.9348\n",
      "Epoch 045 | Train Loss: 0.0910 Acc: 0.9650 | Val Loss: 0.1523 Acc: 0.9487\n",
      "Epoch 046 | Train Loss: 0.0991 Acc: 0.9623 | Val Loss: 0.2016 Acc: 0.9306\n",
      "Epoch 047 | Train Loss: 0.0901 Acc: 0.9660 | Val Loss: 0.1520 Acc: 0.9420\n",
      "Epoch 048 | Train Loss: 0.0808 Acc: 0.9715 | Val Loss: 0.1626 Acc: 0.9396\n",
      "Epoch 049 | Train Loss: 0.0919 Acc: 0.9659 | Val Loss: 0.1848 Acc: 0.9275\n",
      "Epoch 050 | Train Loss: 0.0793 Acc: 0.9704 | Val Loss: 0.1594 Acc: 0.9450\n",
      "Epoch 051 | Train Loss: 0.0786 Acc: 0.9709 | Val Loss: 0.1525 Acc: 0.9432\n",
      "Epoch 052 | Train Loss: 0.0889 Acc: 0.9687 | Val Loss: 0.1565 Acc: 0.9420\n",
      "Early stopping triggered.\n",
      "Epoch 001 | Train Loss: 0.6804 Acc: 0.5795 | Val Loss: 0.6752 Acc: 0.5851\n",
      "Epoch 002 | Train Loss: 0.6676 Acc: 0.6040 | Val Loss: 0.6425 Acc: 0.6196\n",
      "Epoch 003 | Train Loss: 0.6050 Acc: 0.6810 | Val Loss: 0.5997 Acc: 0.6963\n",
      "Epoch 004 | Train Loss: 0.5678 Acc: 0.7198 | Val Loss: 0.5948 Acc: 0.6860\n",
      "Epoch 005 | Train Loss: 0.5342 Acc: 0.7429 | Val Loss: 0.5391 Acc: 0.7355\n",
      "Epoch 006 | Train Loss: 0.5097 Acc: 0.7572 | Val Loss: 0.5115 Acc: 0.7572\n",
      "Epoch 007 | Train Loss: 0.4734 Acc: 0.7764 | Val Loss: 0.4972 Acc: 0.7470\n",
      "Epoch 008 | Train Loss: 0.4557 Acc: 0.7906 | Val Loss: 0.4323 Acc: 0.7977\n",
      "Epoch 009 | Train Loss: 0.4295 Acc: 0.8002 | Val Loss: 0.4280 Acc: 0.7947\n",
      "Epoch 010 | Train Loss: 0.4111 Acc: 0.8102 | Val Loss: 0.4323 Acc: 0.7977\n",
      "Epoch 011 | Train Loss: 0.3828 Acc: 0.8279 | Val Loss: 0.3836 Acc: 0.8255\n",
      "Epoch 012 | Train Loss: 0.3649 Acc: 0.8436 | Val Loss: 0.3530 Acc: 0.8333\n",
      "Epoch 013 | Train Loss: 0.3382 Acc: 0.8501 | Val Loss: 0.3299 Acc: 0.8466\n",
      "Epoch 014 | Train Loss: 0.3214 Acc: 0.8600 | Val Loss: 0.3207 Acc: 0.8587\n",
      "Epoch 015 | Train Loss: 0.3013 Acc: 0.8723 | Val Loss: 0.3169 Acc: 0.8623\n",
      "Epoch 016 | Train Loss: 0.2724 Acc: 0.8881 | Val Loss: 0.3333 Acc: 0.8696\n",
      "Epoch 017 | Train Loss: 0.2718 Acc: 0.8868 | Val Loss: 0.2567 Acc: 0.8943\n",
      "Epoch 018 | Train Loss: 0.2406 Acc: 0.9046 | Val Loss: 0.2398 Acc: 0.9040\n",
      "Epoch 019 | Train Loss: 0.2151 Acc: 0.9135 | Val Loss: 0.2553 Acc: 0.9010\n",
      "Epoch 020 | Train Loss: 0.2099 Acc: 0.9164 | Val Loss: 0.2451 Acc: 0.8943\n",
      "Epoch 021 | Train Loss: 0.1972 Acc: 0.9212 | Val Loss: 0.2040 Acc: 0.9155\n",
      "Epoch 022 | Train Loss: 0.2076 Acc: 0.9165 | Val Loss: 0.2212 Acc: 0.9118\n",
      "Epoch 023 | Train Loss: 0.1756 Acc: 0.9316 | Val Loss: 0.2187 Acc: 0.9076\n",
      "Epoch 024 | Train Loss: 0.1726 Acc: 0.9316 | Val Loss: 0.2296 Acc: 0.9082\n",
      "Epoch 025 | Train Loss: 0.1652 Acc: 0.9351 | Val Loss: 0.2221 Acc: 0.9130\n",
      "Epoch 026 | Train Loss: 0.1637 Acc: 0.9352 | Val Loss: 0.1813 Acc: 0.9269\n",
      "Epoch 027 | Train Loss: 0.1463 Acc: 0.9428 | Val Loss: 0.2034 Acc: 0.9179\n",
      "Epoch 028 | Train Loss: 0.1415 Acc: 0.9462 | Val Loss: 0.2049 Acc: 0.9257\n",
      "Epoch 029 | Train Loss: 0.1403 Acc: 0.9479 | Val Loss: 0.1707 Acc: 0.9372\n",
      "Epoch 030 | Train Loss: 0.1331 Acc: 0.9475 | Val Loss: 0.1757 Acc: 0.9336\n",
      "Epoch 031 | Train Loss: 0.1223 Acc: 0.9530 | Val Loss: 0.2030 Acc: 0.9203\n",
      "Epoch 032 | Train Loss: 0.1195 Acc: 0.9549 | Val Loss: 0.1734 Acc: 0.9342\n",
      "Epoch 033 | Train Loss: 0.1157 Acc: 0.9561 | Val Loss: 0.1949 Acc: 0.9275\n",
      "Epoch 034 | Train Loss: 0.1093 Acc: 0.9592 | Val Loss: 0.2087 Acc: 0.9173\n",
      "Epoch 035 | Train Loss: 0.1053 Acc: 0.9621 | Val Loss: 0.1880 Acc: 0.9293\n",
      "Epoch 036 | Train Loss: 0.1162 Acc: 0.9558 | Val Loss: 0.2436 Acc: 0.9239\n",
      "Epoch 037 | Train Loss: 0.0970 Acc: 0.9633 | Val Loss: 0.2012 Acc: 0.9269\n",
      "Epoch 038 | Train Loss: 0.1075 Acc: 0.9586 | Val Loss: 0.2053 Acc: 0.9257\n",
      "Epoch 039 | Train Loss: 0.0968 Acc: 0.9647 | Val Loss: 0.1772 Acc: 0.9336\n",
      "Early stopping triggered.\n",
      "Epoch 001 | Train Loss: 0.6824 Acc: 0.5798 | Val Loss: 0.6790 Acc: 0.5942\n",
      "Epoch 002 | Train Loss: 0.6785 Acc: 0.5917 | Val Loss: 0.6771 Acc: 0.5882\n",
      "Epoch 003 | Train Loss: 0.6788 Acc: 0.5881 | Val Loss: 0.6779 Acc: 0.5845\n",
      "Epoch 004 | Train Loss: 0.6756 Acc: 0.5917 | Val Loss: 0.6739 Acc: 0.6033\n",
      "Epoch 005 | Train Loss: 0.6704 Acc: 0.6000 | Val Loss: 0.6634 Acc: 0.6039\n",
      "Epoch 006 | Train Loss: 0.6518 Acc: 0.6249 | Val Loss: 0.6683 Acc: 0.6069\n",
      "Epoch 007 | Train Loss: 0.6174 Acc: 0.6713 | Val Loss: 0.6000 Acc: 0.6739\n",
      "Epoch 008 | Train Loss: 0.5915 Acc: 0.6942 | Val Loss: 0.5687 Acc: 0.7053\n",
      "Epoch 009 | Train Loss: 0.5683 Acc: 0.7119 | Val Loss: 0.5519 Acc: 0.7168\n",
      "Epoch 010 | Train Loss: 0.5512 Acc: 0.7290 | Val Loss: 0.5552 Acc: 0.7210\n",
      "Epoch 011 | Train Loss: 0.5477 Acc: 0.7309 | Val Loss: 0.5459 Acc: 0.7210\n",
      "Epoch 012 | Train Loss: 0.5252 Acc: 0.7463 | Val Loss: 0.5189 Acc: 0.7403\n",
      "Epoch 013 | Train Loss: 0.5110 Acc: 0.7460 | Val Loss: 0.5032 Acc: 0.7397\n",
      "Epoch 014 | Train Loss: 0.4926 Acc: 0.7639 | Val Loss: 0.4734 Acc: 0.7627\n",
      "Epoch 015 | Train Loss: 0.4671 Acc: 0.7758 | Val Loss: 0.5327 Acc: 0.7162\n",
      "Epoch 016 | Train Loss: 0.4530 Acc: 0.7827 | Val Loss: 0.4413 Acc: 0.7856\n",
      "Epoch 017 | Train Loss: 0.4099 Acc: 0.8076 | Val Loss: 0.4176 Acc: 0.7965\n",
      "Epoch 018 | Train Loss: 0.4060 Acc: 0.8058 | Val Loss: 0.3928 Acc: 0.8074\n",
      "Epoch 019 | Train Loss: 0.3616 Acc: 0.8366 | Val Loss: 0.3885 Acc: 0.8110\n",
      "Epoch 020 | Train Loss: 0.3377 Acc: 0.8520 | Val Loss: 0.3721 Acc: 0.8231\n",
      "Epoch 021 | Train Loss: 0.3217 Acc: 0.8594 | Val Loss: 0.3169 Acc: 0.8702\n",
      "Epoch 022 | Train Loss: 0.2864 Acc: 0.8762 | Val Loss: 0.3262 Acc: 0.8629\n",
      "Epoch 023 | Train Loss: 0.2800 Acc: 0.8821 | Val Loss: 0.2952 Acc: 0.8780\n",
      "Epoch 024 | Train Loss: 0.2634 Acc: 0.8922 | Val Loss: 0.2669 Acc: 0.8919\n",
      "Epoch 025 | Train Loss: 0.2355 Acc: 0.9028 | Val Loss: 0.2645 Acc: 0.8943\n",
      "Epoch 026 | Train Loss: 0.2243 Acc: 0.9121 | Val Loss: 0.2517 Acc: 0.8949\n",
      "Epoch 027 | Train Loss: 0.2020 Acc: 0.9221 | Val Loss: 0.2709 Acc: 0.8949\n",
      "Epoch 028 | Train Loss: 0.2112 Acc: 0.9159 | Val Loss: 0.2611 Acc: 0.8943\n",
      "Epoch 029 | Train Loss: 0.2055 Acc: 0.9204 | Val Loss: 0.2196 Acc: 0.9149\n",
      "Epoch 030 | Train Loss: 0.1892 Acc: 0.9271 | Val Loss: 0.2279 Acc: 0.8961\n",
      "Epoch 031 | Train Loss: 0.1802 Acc: 0.9305 | Val Loss: 0.2223 Acc: 0.9136\n",
      "Epoch 032 | Train Loss: 0.1730 Acc: 0.9325 | Val Loss: 0.2043 Acc: 0.9124\n",
      "Epoch 033 | Train Loss: 0.1702 Acc: 0.9324 | Val Loss: 0.2012 Acc: 0.9221\n",
      "Epoch 034 | Train Loss: 0.1628 Acc: 0.9381 | Val Loss: 0.2238 Acc: 0.9070\n",
      "Epoch 035 | Train Loss: 0.1485 Acc: 0.9419 | Val Loss: 0.2037 Acc: 0.9185\n",
      "Epoch 036 | Train Loss: 0.1520 Acc: 0.9416 | Val Loss: 0.2170 Acc: 0.9149\n",
      "Epoch 037 | Train Loss: 0.1341 Acc: 0.9497 | Val Loss: 0.2086 Acc: 0.9227\n",
      "Epoch 038 | Train Loss: 0.1399 Acc: 0.9478 | Val Loss: 0.2008 Acc: 0.9318\n",
      "Epoch 039 | Train Loss: 0.1354 Acc: 0.9469 | Val Loss: 0.1910 Acc: 0.9269\n",
      "Epoch 040 | Train Loss: 0.1202 Acc: 0.9535 | Val Loss: 0.1725 Acc: 0.9324\n",
      "Epoch 041 | Train Loss: 0.1208 Acc: 0.9556 | Val Loss: 0.2001 Acc: 0.9221\n",
      "Epoch 042 | Train Loss: 0.1183 Acc: 0.9552 | Val Loss: 0.1970 Acc: 0.9306\n",
      "Epoch 043 | Train Loss: 0.1197 Acc: 0.9549 | Val Loss: 0.1849 Acc: 0.9330\n",
      "Epoch 044 | Train Loss: 0.1278 Acc: 0.9520 | Val Loss: 0.1939 Acc: 0.9312\n",
      "Epoch 045 | Train Loss: 0.1115 Acc: 0.9574 | Val Loss: 0.1776 Acc: 0.9318\n",
      "Epoch 046 | Train Loss: 0.1003 Acc: 0.9612 | Val Loss: 0.2253 Acc: 0.9233\n",
      "Epoch 047 | Train Loss: 0.1073 Acc: 0.9606 | Val Loss: 0.1875 Acc: 0.9348\n",
      "Epoch 048 | Train Loss: 0.0948 Acc: 0.9651 | Val Loss: 0.1590 Acc: 0.9396\n",
      "Epoch 049 | Train Loss: 0.0981 Acc: 0.9604 | Val Loss: 0.1870 Acc: 0.9275\n",
      "Epoch 050 | Train Loss: 0.0915 Acc: 0.9663 | Val Loss: 0.2443 Acc: 0.9245\n",
      "Epoch 051 | Train Loss: 0.0899 Acc: 0.9645 | Val Loss: 0.1746 Acc: 0.9378\n",
      "Epoch 052 | Train Loss: 0.0958 Acc: 0.9633 | Val Loss: 0.1675 Acc: 0.9390\n",
      "Epoch 053 | Train Loss: 0.0856 Acc: 0.9680 | Val Loss: 0.1479 Acc: 0.9444\n",
      "Epoch 054 | Train Loss: 0.0912 Acc: 0.9642 | Val Loss: 0.1814 Acc: 0.9402\n",
      "Epoch 055 | Train Loss: 0.0947 Acc: 0.9645 | Val Loss: 0.1597 Acc: 0.9408\n",
      "Epoch 056 | Train Loss: 0.0855 Acc: 0.9677 | Val Loss: 0.1607 Acc: 0.9408\n",
      "Epoch 057 | Train Loss: 0.0823 Acc: 0.9728 | Val Loss: 0.1629 Acc: 0.9426\n",
      "Epoch 058 | Train Loss: 0.0755 Acc: 0.9740 | Val Loss: 0.1977 Acc: 0.9342\n",
      "Epoch 059 | Train Loss: 0.0872 Acc: 0.9660 | Val Loss: 0.2024 Acc: 0.9318\n",
      "Epoch 060 | Train Loss: 0.0783 Acc: 0.9718 | Val Loss: 0.2020 Acc: 0.9378\n",
      "Epoch 001 | Train Loss: 0.6819 Acc: 0.5667 | Val Loss: 0.6839 Acc: 0.5749\n",
      "Epoch 002 | Train Loss: 0.6768 Acc: 0.5864 | Val Loss: 0.6762 Acc: 0.5815\n",
      "Epoch 003 | Train Loss: 0.6708 Acc: 0.5952 | Val Loss: 0.6665 Acc: 0.6051\n",
      "Epoch 004 | Train Loss: 0.6633 Acc: 0.6047 | Val Loss: 0.6602 Acc: 0.6008\n",
      "Epoch 005 | Train Loss: 0.6513 Acc: 0.6286 | Val Loss: 0.6392 Acc: 0.6564\n",
      "Epoch 006 | Train Loss: 0.6238 Acc: 0.6680 | Val Loss: 0.6356 Acc: 0.6516\n",
      "Epoch 007 | Train Loss: 0.6058 Acc: 0.6811 | Val Loss: 0.5962 Acc: 0.6914\n",
      "Epoch 008 | Train Loss: 0.5856 Acc: 0.7033 | Val Loss: 0.5926 Acc: 0.6884\n",
      "Epoch 009 | Train Loss: 0.5686 Acc: 0.7180 | Val Loss: 0.5684 Acc: 0.7089\n",
      "Epoch 010 | Train Loss: 0.5560 Acc: 0.7294 | Val Loss: 0.5552 Acc: 0.7186\n",
      "Epoch 011 | Train Loss: 0.5460 Acc: 0.7332 | Val Loss: 0.5634 Acc: 0.7228\n",
      "Epoch 012 | Train Loss: 0.5311 Acc: 0.7448 | Val Loss: 0.5425 Acc: 0.7240\n",
      "Epoch 013 | Train Loss: 0.5240 Acc: 0.7485 | Val Loss: 0.5347 Acc: 0.7343\n",
      "Epoch 014 | Train Loss: 0.5149 Acc: 0.7480 | Val Loss: 0.5225 Acc: 0.7337\n",
      "Epoch 015 | Train Loss: 0.4985 Acc: 0.7658 | Val Loss: 0.5274 Acc: 0.7391\n",
      "Epoch 016 | Train Loss: 0.4917 Acc: 0.7678 | Val Loss: 0.5222 Acc: 0.7367\n",
      "Epoch 017 | Train Loss: 0.4753 Acc: 0.7764 | Val Loss: 0.4890 Acc: 0.7627\n",
      "Epoch 018 | Train Loss: 0.4717 Acc: 0.7783 | Val Loss: 0.4824 Acc: 0.7615\n",
      "Epoch 019 | Train Loss: 0.4506 Acc: 0.7919 | Val Loss: 0.4562 Acc: 0.7784\n",
      "Epoch 020 | Train Loss: 0.4428 Acc: 0.7906 | Val Loss: 0.4656 Acc: 0.7754\n",
      "Epoch 021 | Train Loss: 0.4353 Acc: 0.7984 | Val Loss: 0.4400 Acc: 0.7953\n",
      "Epoch 022 | Train Loss: 0.4206 Acc: 0.8067 | Val Loss: 0.4276 Acc: 0.7983\n",
      "Epoch 023 | Train Loss: 0.4025 Acc: 0.8182 | Val Loss: 0.4058 Acc: 0.8086\n",
      "Epoch 024 | Train Loss: 0.4039 Acc: 0.8165 | Val Loss: 0.4026 Acc: 0.8140\n",
      "Epoch 025 | Train Loss: 0.3781 Acc: 0.8274 | Val Loss: 0.3986 Acc: 0.8158\n",
      "Epoch 026 | Train Loss: 0.3761 Acc: 0.8318 | Val Loss: 0.3974 Acc: 0.8200\n",
      "Epoch 027 | Train Loss: 0.3662 Acc: 0.8378 | Val Loss: 0.3915 Acc: 0.8146\n",
      "Epoch 028 | Train Loss: 0.3485 Acc: 0.8484 | Val Loss: 0.3657 Acc: 0.8309\n",
      "Epoch 029 | Train Loss: 0.3248 Acc: 0.8573 | Val Loss: 0.3511 Acc: 0.8364\n",
      "Epoch 030 | Train Loss: 0.3301 Acc: 0.8492 | Val Loss: 0.3383 Acc: 0.8569\n",
      "Epoch 031 | Train Loss: 0.3108 Acc: 0.8643 | Val Loss: 0.3136 Acc: 0.8617\n",
      "Epoch 032 | Train Loss: 0.2987 Acc: 0.8703 | Val Loss: 0.3105 Acc: 0.8684\n",
      "Epoch 033 | Train Loss: 0.2956 Acc: 0.8697 | Val Loss: 0.2933 Acc: 0.8792\n",
      "Epoch 034 | Train Loss: 0.2800 Acc: 0.8806 | Val Loss: 0.2904 Acc: 0.8762\n",
      "Epoch 035 | Train Loss: 0.2728 Acc: 0.8830 | Val Loss: 0.3379 Acc: 0.8496\n",
      "Epoch 036 | Train Loss: 0.2565 Acc: 0.8916 | Val Loss: 0.2912 Acc: 0.8726\n",
      "Epoch 037 | Train Loss: 0.2539 Acc: 0.8925 | Val Loss: 0.2784 Acc: 0.8786\n",
      "Epoch 038 | Train Loss: 0.2377 Acc: 0.9049 | Val Loss: 0.2596 Acc: 0.8913\n",
      "Epoch 039 | Train Loss: 0.2361 Acc: 0.9023 | Val Loss: 0.3006 Acc: 0.8750\n",
      "Epoch 040 | Train Loss: 0.2278 Acc: 0.9062 | Val Loss: 0.2513 Acc: 0.8937\n",
      "Epoch 041 | Train Loss: 0.2226 Acc: 0.9056 | Val Loss: 0.2518 Acc: 0.8967\n",
      "Epoch 042 | Train Loss: 0.2059 Acc: 0.9145 | Val Loss: 0.2971 Acc: 0.8835\n",
      "Epoch 043 | Train Loss: 0.2080 Acc: 0.9142 | Val Loss: 0.2200 Acc: 0.9112\n",
      "Epoch 044 | Train Loss: 0.1930 Acc: 0.9197 | Val Loss: 0.2212 Acc: 0.9088\n",
      "Epoch 045 | Train Loss: 0.1978 Acc: 0.9206 | Val Loss: 0.2108 Acc: 0.9209\n",
      "Epoch 046 | Train Loss: 0.1842 Acc: 0.9278 | Val Loss: 0.2007 Acc: 0.9191\n",
      "Epoch 047 | Train Loss: 0.1841 Acc: 0.9230 | Val Loss: 0.1963 Acc: 0.9239\n",
      "Epoch 048 | Train Loss: 0.1848 Acc: 0.9283 | Val Loss: 0.1931 Acc: 0.9215\n",
      "Epoch 049 | Train Loss: 0.1785 Acc: 0.9299 | Val Loss: 0.1834 Acc: 0.9287\n",
      "Epoch 050 | Train Loss: 0.1600 Acc: 0.9343 | Val Loss: 0.1953 Acc: 0.9197\n",
      "Epoch 051 | Train Loss: 0.1528 Acc: 0.9363 | Val Loss: 0.1969 Acc: 0.9275\n",
      "Epoch 052 | Train Loss: 0.1448 Acc: 0.9434 | Val Loss: 0.2101 Acc: 0.9227\n",
      "Epoch 053 | Train Loss: 0.1530 Acc: 0.9373 | Val Loss: 0.1805 Acc: 0.9287\n",
      "Epoch 054 | Train Loss: 0.1374 Acc: 0.9431 | Val Loss: 0.1792 Acc: 0.9348\n",
      "Epoch 055 | Train Loss: 0.1330 Acc: 0.9505 | Val Loss: 0.1767 Acc: 0.9281\n",
      "Epoch 056 | Train Loss: 0.1238 Acc: 0.9508 | Val Loss: 0.1925 Acc: 0.9257\n",
      "Epoch 057 | Train Loss: 0.1320 Acc: 0.9488 | Val Loss: 0.1721 Acc: 0.9354\n",
      "Epoch 058 | Train Loss: 0.1187 Acc: 0.9553 | Val Loss: 0.1768 Acc: 0.9324\n",
      "Epoch 059 | Train Loss: 0.1183 Acc: 0.9553 | Val Loss: 0.1689 Acc: 0.9354\n",
      "Epoch 060 | Train Loss: 0.1119 Acc: 0.9543 | Val Loss: 0.1769 Acc: 0.9372\n",
      "Iteration 17/40 | Best Val Loss: 0.1122 | Iter Time: 217.91s | Total Time: 75.30 min\n",
      "Epoch 001 | Train Loss: 0.6834 Acc: 0.5683 | Val Loss: 0.6863 Acc: 0.5586\n",
      "Epoch 002 | Train Loss: 0.6742 Acc: 0.5892 | Val Loss: 0.6687 Acc: 0.5948\n",
      "Epoch 003 | Train Loss: 0.6667 Acc: 0.6082 | Val Loss: 0.6663 Acc: 0.6093\n",
      "Epoch 004 | Train Loss: 0.6589 Acc: 0.6192 | Val Loss: 0.6586 Acc: 0.6111\n",
      "Epoch 005 | Train Loss: 0.6510 Acc: 0.6248 | Val Loss: 0.6485 Acc: 0.6419\n",
      "Epoch 006 | Train Loss: 0.6305 Acc: 0.6586 | Val Loss: 0.5975 Acc: 0.6920\n",
      "Epoch 007 | Train Loss: 0.5930 Acc: 0.6974 | Val Loss: 0.5821 Acc: 0.6938\n",
      "Epoch 008 | Train Loss: 0.5707 Acc: 0.7148 | Val Loss: 0.5644 Acc: 0.7101\n",
      "Epoch 009 | Train Loss: 0.5557 Acc: 0.7270 | Val Loss: 0.5532 Acc: 0.7168\n",
      "Epoch 010 | Train Loss: 0.5450 Acc: 0.7324 | Val Loss: 0.5473 Acc: 0.7222\n",
      "Epoch 011 | Train Loss: 0.5265 Acc: 0.7427 | Val Loss: 0.5281 Acc: 0.7361\n",
      "Epoch 012 | Train Loss: 0.5046 Acc: 0.7548 | Val Loss: 0.5075 Acc: 0.7554\n",
      "Epoch 013 | Train Loss: 0.4960 Acc: 0.7619 | Val Loss: 0.5714 Acc: 0.7059\n",
      "Epoch 014 | Train Loss: 0.4961 Acc: 0.7602 | Val Loss: 0.4887 Acc: 0.7585\n",
      "Epoch 015 | Train Loss: 0.4679 Acc: 0.7812 | Val Loss: 0.4624 Acc: 0.7899\n",
      "Epoch 016 | Train Loss: 0.4474 Acc: 0.7924 | Val Loss: 0.4614 Acc: 0.7699\n",
      "Epoch 017 | Train Loss: 0.4335 Acc: 0.8019 | Val Loss: 0.4370 Acc: 0.7989\n",
      "Epoch 018 | Train Loss: 0.4096 Acc: 0.8170 | Val Loss: 0.4041 Acc: 0.8200\n",
      "Epoch 019 | Train Loss: 0.4095 Acc: 0.8079 | Val Loss: 0.4015 Acc: 0.8170\n",
      "Epoch 020 | Train Loss: 0.3901 Acc: 0.8244 | Val Loss: 0.3863 Acc: 0.8303\n",
      "Epoch 021 | Train Loss: 0.3692 Acc: 0.8348 | Val Loss: 0.3646 Acc: 0.8442\n",
      "Epoch 022 | Train Loss: 0.3515 Acc: 0.8483 | Val Loss: 0.3570 Acc: 0.8521\n",
      "Epoch 023 | Train Loss: 0.3426 Acc: 0.8505 | Val Loss: 0.3140 Acc: 0.8665\n",
      "Epoch 024 | Train Loss: 0.3272 Acc: 0.8628 | Val Loss: 0.3080 Acc: 0.8696\n",
      "Epoch 025 | Train Loss: 0.3085 Acc: 0.8674 | Val Loss: 0.2972 Acc: 0.8720\n",
      "Epoch 026 | Train Loss: 0.2868 Acc: 0.8797 | Val Loss: 0.3061 Acc: 0.8665\n",
      "Epoch 027 | Train Loss: 0.2790 Acc: 0.8852 | Val Loss: 0.3193 Acc: 0.8720\n",
      "Epoch 028 | Train Loss: 0.2785 Acc: 0.8842 | Val Loss: 0.2627 Acc: 0.8919\n",
      "Epoch 029 | Train Loss: 0.2712 Acc: 0.8874 | Val Loss: 0.2516 Acc: 0.9010\n",
      "Epoch 030 | Train Loss: 0.2449 Acc: 0.8979 | Val Loss: 0.2184 Acc: 0.9167\n",
      "Epoch 031 | Train Loss: 0.2338 Acc: 0.9062 | Val Loss: 0.2337 Acc: 0.9058\n",
      "Epoch 032 | Train Loss: 0.2248 Acc: 0.9091 | Val Loss: 0.2262 Acc: 0.9161\n",
      "Epoch 033 | Train Loss: 0.2115 Acc: 0.9133 | Val Loss: 0.2304 Acc: 0.9070\n",
      "Epoch 034 | Train Loss: 0.2175 Acc: 0.9157 | Val Loss: 0.2318 Acc: 0.9040\n",
      "Epoch 035 | Train Loss: 0.2091 Acc: 0.9180 | Val Loss: 0.2320 Acc: 0.9106\n",
      "Epoch 036 | Train Loss: 0.2071 Acc: 0.9171 | Val Loss: 0.2341 Acc: 0.9143\n",
      "Epoch 037 | Train Loss: 0.1889 Acc: 0.9253 | Val Loss: 0.2379 Acc: 0.8986\n",
      "Epoch 038 | Train Loss: 0.1928 Acc: 0.9209 | Val Loss: 0.2088 Acc: 0.9143\n",
      "Epoch 039 | Train Loss: 0.1830 Acc: 0.9254 | Val Loss: 0.1958 Acc: 0.9293\n",
      "Epoch 040 | Train Loss: 0.1921 Acc: 0.9253 | Val Loss: 0.1768 Acc: 0.9360\n",
      "Epoch 041 | Train Loss: 0.1643 Acc: 0.9363 | Val Loss: 0.2082 Acc: 0.9227\n",
      "Epoch 042 | Train Loss: 0.1639 Acc: 0.9399 | Val Loss: 0.2510 Acc: 0.9034\n",
      "Epoch 043 | Train Loss: 0.1719 Acc: 0.9328 | Val Loss: 0.2084 Acc: 0.9215\n",
      "Epoch 044 | Train Loss: 0.1676 Acc: 0.9358 | Val Loss: 0.1908 Acc: 0.9263\n",
      "Epoch 045 | Train Loss: 0.1669 Acc: 0.9363 | Val Loss: 0.2328 Acc: 0.9016\n",
      "Epoch 046 | Train Loss: 0.1607 Acc: 0.9399 | Val Loss: 0.1814 Acc: 0.9306\n",
      "Epoch 047 | Train Loss: 0.1436 Acc: 0.9459 | Val Loss: 0.1854 Acc: 0.9312\n",
      "Epoch 048 | Train Loss: 0.1451 Acc: 0.9411 | Val Loss: 0.1984 Acc: 0.9269\n",
      "Epoch 049 | Train Loss: 0.1478 Acc: 0.9414 | Val Loss: 0.1699 Acc: 0.9408\n",
      "Epoch 050 | Train Loss: 0.1381 Acc: 0.9455 | Val Loss: 0.2173 Acc: 0.9221\n",
      "Epoch 051 | Train Loss: 0.1500 Acc: 0.9449 | Val Loss: 0.1693 Acc: 0.9360\n",
      "Epoch 052 | Train Loss: 0.1402 Acc: 0.9493 | Val Loss: 0.1817 Acc: 0.9312\n",
      "Epoch 053 | Train Loss: 0.1339 Acc: 0.9499 | Val Loss: 0.1684 Acc: 0.9402\n",
      "Epoch 054 | Train Loss: 0.1213 Acc: 0.9561 | Val Loss: 0.2470 Acc: 0.9106\n",
      "Epoch 055 | Train Loss: 0.1253 Acc: 0.9511 | Val Loss: 0.1765 Acc: 0.9432\n",
      "Epoch 056 | Train Loss: 0.1239 Acc: 0.9544 | Val Loss: 0.1748 Acc: 0.9330\n",
      "Epoch 057 | Train Loss: 0.1163 Acc: 0.9544 | Val Loss: 0.2196 Acc: 0.9281\n",
      "Epoch 058 | Train Loss: 0.1171 Acc: 0.9568 | Val Loss: 0.1582 Acc: 0.9432\n",
      "Epoch 059 | Train Loss: 0.1344 Acc: 0.9472 | Val Loss: 0.1782 Acc: 0.9324\n",
      "Epoch 060 | Train Loss: 0.1179 Acc: 0.9582 | Val Loss: 0.2427 Acc: 0.9197\n",
      "Epoch 001 | Train Loss: 0.6700 Acc: 0.5902 | Val Loss: 0.6409 Acc: 0.6383\n",
      "Epoch 002 | Train Loss: 0.6069 Acc: 0.6843 | Val Loss: 0.5910 Acc: 0.6963\n",
      "Epoch 003 | Train Loss: 0.5600 Acc: 0.7204 | Val Loss: 0.5549 Acc: 0.7198\n",
      "Epoch 004 | Train Loss: 0.5332 Acc: 0.7368 | Val Loss: 0.5280 Acc: 0.7385\n",
      "Epoch 005 | Train Loss: 0.5039 Acc: 0.7578 | Val Loss: 0.5519 Acc: 0.7246\n",
      "Epoch 006 | Train Loss: 0.4718 Acc: 0.7787 | Val Loss: 0.4560 Acc: 0.7814\n",
      "Epoch 007 | Train Loss: 0.4234 Acc: 0.8132 | Val Loss: 0.4198 Acc: 0.8080\n",
      "Epoch 008 | Train Loss: 0.3748 Acc: 0.8324 | Val Loss: 0.3842 Acc: 0.8237\n",
      "Epoch 009 | Train Loss: 0.3362 Acc: 0.8505 | Val Loss: 0.3349 Acc: 0.8569\n",
      "Epoch 010 | Train Loss: 0.2939 Acc: 0.8775 | Val Loss: 0.3064 Acc: 0.8768\n",
      "Epoch 011 | Train Loss: 0.2819 Acc: 0.8818 | Val Loss: 0.3456 Acc: 0.8502\n",
      "Epoch 012 | Train Loss: 0.2568 Acc: 0.8975 | Val Loss: 0.2925 Acc: 0.8786\n",
      "Epoch 013 | Train Loss: 0.2284 Acc: 0.9065 | Val Loss: 0.2895 Acc: 0.8744\n",
      "Epoch 014 | Train Loss: 0.2160 Acc: 0.9126 | Val Loss: 0.3260 Acc: 0.8768\n",
      "Epoch 015 | Train Loss: 0.2006 Acc: 0.9189 | Val Loss: 0.2916 Acc: 0.8774\n",
      "Epoch 016 | Train Loss: 0.1818 Acc: 0.9287 | Val Loss: 0.2342 Acc: 0.9058\n",
      "Epoch 017 | Train Loss: 0.1650 Acc: 0.9340 | Val Loss: 0.2491 Acc: 0.9040\n",
      "Epoch 018 | Train Loss: 0.1577 Acc: 0.9369 | Val Loss: 0.2470 Acc: 0.9046\n",
      "Epoch 019 | Train Loss: 0.1398 Acc: 0.9456 | Val Loss: 0.2323 Acc: 0.9106\n",
      "Epoch 020 | Train Loss: 0.1335 Acc: 0.9499 | Val Loss: 0.2278 Acc: 0.9167\n",
      "Epoch 021 | Train Loss: 0.1191 Acc: 0.9533 | Val Loss: 0.2136 Acc: 0.9185\n",
      "Epoch 022 | Train Loss: 0.1093 Acc: 0.9606 | Val Loss: 0.2523 Acc: 0.9118\n",
      "Epoch 023 | Train Loss: 0.1072 Acc: 0.9592 | Val Loss: 0.2072 Acc: 0.9227\n",
      "Epoch 024 | Train Loss: 0.0979 Acc: 0.9635 | Val Loss: 0.2410 Acc: 0.9118\n",
      "Epoch 025 | Train Loss: 0.0893 Acc: 0.9668 | Val Loss: 0.2006 Acc: 0.9354\n",
      "Epoch 026 | Train Loss: 0.0818 Acc: 0.9693 | Val Loss: 0.2354 Acc: 0.9251\n",
      "Epoch 027 | Train Loss: 0.0990 Acc: 0.9635 | Val Loss: 0.2541 Acc: 0.9149\n",
      "Epoch 028 | Train Loss: 0.0888 Acc: 0.9666 | Val Loss: 0.2306 Acc: 0.9239\n",
      "Epoch 029 | Train Loss: 0.0956 Acc: 0.9639 | Val Loss: 0.1993 Acc: 0.9354\n",
      "Epoch 030 | Train Loss: 0.0698 Acc: 0.9767 | Val Loss: 0.2472 Acc: 0.9215\n",
      "Epoch 031 | Train Loss: 0.0715 Acc: 0.9733 | Val Loss: 0.2537 Acc: 0.9203\n",
      "Epoch 032 | Train Loss: 0.0735 Acc: 0.9743 | Val Loss: 0.2256 Acc: 0.9245\n",
      "Epoch 033 | Train Loss: 0.0685 Acc: 0.9731 | Val Loss: 0.2269 Acc: 0.9275\n",
      "Epoch 034 | Train Loss: 0.0677 Acc: 0.9754 | Val Loss: 0.2789 Acc: 0.9143\n",
      "Epoch 035 | Train Loss: 0.0593 Acc: 0.9801 | Val Loss: 0.2290 Acc: 0.9330\n",
      "Epoch 036 | Train Loss: 0.0528 Acc: 0.9813 | Val Loss: 0.2184 Acc: 0.9300\n",
      "Epoch 037 | Train Loss: 0.0594 Acc: 0.9796 | Val Loss: 0.2340 Acc: 0.9287\n",
      "Epoch 038 | Train Loss: 0.0510 Acc: 0.9802 | Val Loss: 0.2243 Acc: 0.9360\n",
      "Epoch 039 | Train Loss: 0.0657 Acc: 0.9760 | Val Loss: 0.1948 Acc: 0.9360\n",
      "Epoch 040 | Train Loss: 0.0451 Acc: 0.9841 | Val Loss: 0.1863 Acc: 0.9378\n",
      "Epoch 041 | Train Loss: 0.0580 Acc: 0.9778 | Val Loss: 0.2170 Acc: 0.9360\n",
      "Epoch 042 | Train Loss: 0.0500 Acc: 0.9820 | Val Loss: 0.2343 Acc: 0.9239\n",
      "Epoch 043 | Train Loss: 0.0468 Acc: 0.9835 | Val Loss: 0.2301 Acc: 0.9354\n",
      "Epoch 044 | Train Loss: 0.0517 Acc: 0.9807 | Val Loss: 0.1790 Acc: 0.9360\n",
      "Epoch 045 | Train Loss: 0.0397 Acc: 0.9858 | Val Loss: 0.2043 Acc: 0.9408\n",
      "Epoch 046 | Train Loss: 0.0472 Acc: 0.9834 | Val Loss: 0.2453 Acc: 0.9293\n",
      "Epoch 047 | Train Loss: 0.0532 Acc: 0.9810 | Val Loss: 0.1985 Acc: 0.9257\n",
      "Epoch 048 | Train Loss: 0.0593 Acc: 0.9792 | Val Loss: 0.2294 Acc: 0.9336\n",
      "Epoch 049 | Train Loss: 0.0408 Acc: 0.9867 | Val Loss: 0.2078 Acc: 0.9414\n",
      "Epoch 050 | Train Loss: 0.0428 Acc: 0.9844 | Val Loss: 0.2178 Acc: 0.9336\n",
      "Epoch 051 | Train Loss: 0.0485 Acc: 0.9841 | Val Loss: 0.1859 Acc: 0.9432\n",
      "Epoch 052 | Train Loss: 0.0425 Acc: 0.9838 | Val Loss: 0.2463 Acc: 0.9324\n",
      "Epoch 053 | Train Loss: 0.0413 Acc: 0.9846 | Val Loss: 0.2023 Acc: 0.9372\n",
      "Epoch 054 | Train Loss: 0.0347 Acc: 0.9870 | Val Loss: 0.1627 Acc: 0.9511\n",
      "Epoch 055 | Train Loss: 0.0494 Acc: 0.9807 | Val Loss: 0.2237 Acc: 0.9239\n",
      "Epoch 056 | Train Loss: 0.0417 Acc: 0.9844 | Val Loss: 0.1652 Acc: 0.9481\n",
      "Epoch 057 | Train Loss: 0.0402 Acc: 0.9864 | Val Loss: 0.1779 Acc: 0.9457\n",
      "Epoch 058 | Train Loss: 0.0334 Acc: 0.9873 | Val Loss: 0.2221 Acc: 0.9348\n",
      "Epoch 059 | Train Loss: 0.0442 Acc: 0.9835 | Val Loss: 0.2009 Acc: 0.9384\n",
      "Epoch 060 | Train Loss: 0.0409 Acc: 0.9846 | Val Loss: 0.2025 Acc: 0.9414\n",
      "Epoch 001 | Train Loss: 0.6796 Acc: 0.5818 | Val Loss: 0.6773 Acc: 0.5888\n",
      "Epoch 002 | Train Loss: 0.6707 Acc: 0.6052 | Val Loss: 0.6830 Acc: 0.5658\n",
      "Epoch 003 | Train Loss: 0.6614 Acc: 0.6083 | Val Loss: 0.6322 Acc: 0.6516\n",
      "Epoch 004 | Train Loss: 0.6295 Acc: 0.6624 | Val Loss: 0.6004 Acc: 0.6932\n",
      "Epoch 005 | Train Loss: 0.5854 Acc: 0.7084 | Val Loss: 0.5917 Acc: 0.6884\n",
      "Epoch 006 | Train Loss: 0.5577 Acc: 0.7291 | Val Loss: 0.5515 Acc: 0.7234\n",
      "Epoch 007 | Train Loss: 0.5471 Acc: 0.7385 | Val Loss: 0.5467 Acc: 0.7240\n",
      "Epoch 008 | Train Loss: 0.5239 Acc: 0.7498 | Val Loss: 0.5150 Acc: 0.7415\n",
      "Epoch 009 | Train Loss: 0.5211 Acc: 0.7509 | Val Loss: 0.5466 Acc: 0.7228\n",
      "Epoch 010 | Train Loss: 0.4983 Acc: 0.7649 | Val Loss: 0.5251 Acc: 0.7385\n",
      "Epoch 011 | Train Loss: 0.4864 Acc: 0.7719 | Val Loss: 0.4860 Acc: 0.7615\n",
      "Epoch 012 | Train Loss: 0.4679 Acc: 0.7811 | Val Loss: 0.4981 Acc: 0.7603\n",
      "Epoch 013 | Train Loss: 0.4580 Acc: 0.7910 | Val Loss: 0.4596 Acc: 0.7850\n",
      "Epoch 014 | Train Loss: 0.4539 Acc: 0.7928 | Val Loss: 0.4400 Acc: 0.7953\n",
      "Epoch 015 | Train Loss: 0.4278 Acc: 0.8040 | Val Loss: 0.4389 Acc: 0.7850\n",
      "Epoch 016 | Train Loss: 0.4177 Acc: 0.8101 | Val Loss: 0.4164 Acc: 0.7977\n",
      "Epoch 017 | Train Loss: 0.4071 Acc: 0.8167 | Val Loss: 0.3847 Acc: 0.8261\n",
      "Epoch 018 | Train Loss: 0.3925 Acc: 0.8333 | Val Loss: 0.3761 Acc: 0.8388\n",
      "Epoch 019 | Train Loss: 0.3704 Acc: 0.8386 | Val Loss: 0.3674 Acc: 0.8376\n",
      "Epoch 020 | Train Loss: 0.3650 Acc: 0.8422 | Val Loss: 0.3485 Acc: 0.8472\n",
      "Epoch 021 | Train Loss: 0.3461 Acc: 0.8484 | Val Loss: 0.3281 Acc: 0.8617\n",
      "Epoch 022 | Train Loss: 0.3298 Acc: 0.8609 | Val Loss: 0.3420 Acc: 0.8563\n",
      "Epoch 023 | Train Loss: 0.3119 Acc: 0.8631 | Val Loss: 0.3093 Acc: 0.8720\n",
      "Epoch 024 | Train Loss: 0.3015 Acc: 0.8736 | Val Loss: 0.3170 Acc: 0.8587\n",
      "Epoch 025 | Train Loss: 0.2873 Acc: 0.8771 | Val Loss: 0.3379 Acc: 0.8521\n",
      "Epoch 026 | Train Loss: 0.2797 Acc: 0.8842 | Val Loss: 0.3017 Acc: 0.8744\n",
      "Epoch 027 | Train Loss: 0.2644 Acc: 0.8901 | Val Loss: 0.3167 Acc: 0.8641\n",
      "Epoch 028 | Train Loss: 0.2571 Acc: 0.9000 | Val Loss: 0.2954 Acc: 0.8798\n",
      "Epoch 029 | Train Loss: 0.2419 Acc: 0.9011 | Val Loss: 0.2488 Acc: 0.8967\n",
      "Epoch 030 | Train Loss: 0.2333 Acc: 0.9073 | Val Loss: 0.2522 Acc: 0.9010\n",
      "Epoch 031 | Train Loss: 0.2199 Acc: 0.9105 | Val Loss: 0.2514 Acc: 0.8943\n",
      "Epoch 032 | Train Loss: 0.2172 Acc: 0.9121 | Val Loss: 0.2971 Acc: 0.8750\n",
      "Epoch 033 | Train Loss: 0.2213 Acc: 0.9126 | Val Loss: 0.2357 Acc: 0.9082\n",
      "Epoch 034 | Train Loss: 0.2057 Acc: 0.9191 | Val Loss: 0.2127 Acc: 0.9191\n",
      "Epoch 035 | Train Loss: 0.1889 Acc: 0.9262 | Val Loss: 0.2193 Acc: 0.9167\n",
      "Epoch 036 | Train Loss: 0.1837 Acc: 0.9225 | Val Loss: 0.2479 Acc: 0.9022\n",
      "Epoch 037 | Train Loss: 0.1895 Acc: 0.9257 | Val Loss: 0.2360 Acc: 0.9052\n",
      "Epoch 038 | Train Loss: 0.1737 Acc: 0.9295 | Val Loss: 0.1939 Acc: 0.9227\n",
      "Epoch 039 | Train Loss: 0.1693 Acc: 0.9328 | Val Loss: 0.2344 Acc: 0.8986\n",
      "Epoch 040 | Train Loss: 0.1589 Acc: 0.9379 | Val Loss: 0.2098 Acc: 0.9112\n",
      "Epoch 041 | Train Loss: 0.1686 Acc: 0.9342 | Val Loss: 0.1879 Acc: 0.9233\n",
      "Epoch 042 | Train Loss: 0.1601 Acc: 0.9416 | Val Loss: 0.1787 Acc: 0.9257\n",
      "Epoch 043 | Train Loss: 0.1548 Acc: 0.9379 | Val Loss: 0.2008 Acc: 0.9221\n",
      "Epoch 044 | Train Loss: 0.1587 Acc: 0.9405 | Val Loss: 0.1968 Acc: 0.9221\n",
      "Epoch 045 | Train Loss: 0.1481 Acc: 0.9446 | Val Loss: 0.1736 Acc: 0.9306\n",
      "Epoch 046 | Train Loss: 0.1338 Acc: 0.9494 | Val Loss: 0.1905 Acc: 0.9306\n",
      "Epoch 047 | Train Loss: 0.1417 Acc: 0.9441 | Val Loss: 0.1873 Acc: 0.9293\n",
      "Epoch 048 | Train Loss: 0.1299 Acc: 0.9473 | Val Loss: 0.2017 Acc: 0.9185\n",
      "Epoch 049 | Train Loss: 0.1374 Acc: 0.9470 | Val Loss: 0.1888 Acc: 0.9263\n",
      "Epoch 050 | Train Loss: 0.1294 Acc: 0.9500 | Val Loss: 0.1643 Acc: 0.9450\n",
      "Epoch 051 | Train Loss: 0.1278 Acc: 0.9503 | Val Loss: 0.1709 Acc: 0.9336\n",
      "Epoch 052 | Train Loss: 0.1238 Acc: 0.9541 | Val Loss: 0.1952 Acc: 0.9318\n",
      "Epoch 053 | Train Loss: 0.1269 Acc: 0.9512 | Val Loss: 0.2327 Acc: 0.9155\n",
      "Epoch 054 | Train Loss: 0.1110 Acc: 0.9571 | Val Loss: 0.1777 Acc: 0.9360\n",
      "Epoch 055 | Train Loss: 0.1163 Acc: 0.9559 | Val Loss: 0.1933 Acc: 0.9269\n",
      "Epoch 056 | Train Loss: 0.1169 Acc: 0.9533 | Val Loss: 0.1859 Acc: 0.9306\n",
      "Epoch 057 | Train Loss: 0.1122 Acc: 0.9576 | Val Loss: 0.2127 Acc: 0.9281\n",
      "Epoch 058 | Train Loss: 0.1090 Acc: 0.9564 | Val Loss: 0.1837 Acc: 0.9342\n",
      "Epoch 059 | Train Loss: 0.1144 Acc: 0.9565 | Val Loss: 0.1638 Acc: 0.9354\n",
      "Epoch 060 | Train Loss: 0.1049 Acc: 0.9616 | Val Loss: 0.1702 Acc: 0.9354\n",
      "Epoch 001 | Train Loss: 0.6791 Acc: 0.5834 | Val Loss: 0.6733 Acc: 0.5936\n",
      "Epoch 002 | Train Loss: 0.6536 Acc: 0.6136 | Val Loss: 0.6369 Acc: 0.6564\n",
      "Epoch 003 | Train Loss: 0.6077 Acc: 0.6819 | Val Loss: 0.5806 Acc: 0.7017\n",
      "Epoch 004 | Train Loss: 0.5708 Acc: 0.7119 | Val Loss: 0.5699 Acc: 0.7107\n",
      "Epoch 005 | Train Loss: 0.5407 Acc: 0.7278 | Val Loss: 0.5469 Acc: 0.7204\n",
      "Epoch 006 | Train Loss: 0.5149 Acc: 0.7498 | Val Loss: 0.5086 Acc: 0.7518\n",
      "Epoch 007 | Train Loss: 0.4889 Acc: 0.7642 | Val Loss: 0.5043 Acc: 0.7446\n",
      "Epoch 008 | Train Loss: 0.4649 Acc: 0.7738 | Val Loss: 0.4566 Acc: 0.7886\n",
      "Epoch 009 | Train Loss: 0.4300 Acc: 0.7971 | Val Loss: 0.4367 Acc: 0.7844\n",
      "Epoch 010 | Train Loss: 0.4109 Acc: 0.8069 | Val Loss: 0.4486 Acc: 0.7778\n",
      "Epoch 011 | Train Loss: 0.3857 Acc: 0.8256 | Val Loss: 0.3798 Acc: 0.8303\n",
      "Epoch 012 | Train Loss: 0.3599 Acc: 0.8335 | Val Loss: 0.3500 Acc: 0.8454\n",
      "Epoch 013 | Train Loss: 0.3340 Acc: 0.8535 | Val Loss: 0.3182 Acc: 0.8629\n",
      "Epoch 014 | Train Loss: 0.3124 Acc: 0.8676 | Val Loss: 0.2939 Acc: 0.8798\n",
      "Epoch 015 | Train Loss: 0.2777 Acc: 0.8818 | Val Loss: 0.2555 Acc: 0.8895\n",
      "Epoch 016 | Train Loss: 0.2754 Acc: 0.8857 | Val Loss: 0.2874 Acc: 0.8678\n",
      "Epoch 017 | Train Loss: 0.2653 Acc: 0.8895 | Val Loss: 0.2549 Acc: 0.9040\n",
      "Epoch 018 | Train Loss: 0.2428 Acc: 0.8990 | Val Loss: 0.2458 Acc: 0.9052\n",
      "Epoch 019 | Train Loss: 0.2198 Acc: 0.9102 | Val Loss: 0.2257 Acc: 0.9124\n",
      "Epoch 020 | Train Loss: 0.2213 Acc: 0.9102 | Val Loss: 0.2285 Acc: 0.9076\n",
      "Epoch 021 | Train Loss: 0.2033 Acc: 0.9195 | Val Loss: 0.2033 Acc: 0.9167\n",
      "Epoch 022 | Train Loss: 0.1886 Acc: 0.9265 | Val Loss: 0.1982 Acc: 0.9233\n",
      "Epoch 023 | Train Loss: 0.1918 Acc: 0.9197 | Val Loss: 0.1962 Acc: 0.9233\n",
      "Epoch 024 | Train Loss: 0.1661 Acc: 0.9325 | Val Loss: 0.1885 Acc: 0.9227\n",
      "Epoch 025 | Train Loss: 0.1656 Acc: 0.9324 | Val Loss: 0.2036 Acc: 0.9239\n",
      "Epoch 026 | Train Loss: 0.1541 Acc: 0.9390 | Val Loss: 0.1752 Acc: 0.9336\n",
      "Epoch 027 | Train Loss: 0.1402 Acc: 0.9441 | Val Loss: 0.2276 Acc: 0.9124\n",
      "Epoch 028 | Train Loss: 0.1480 Acc: 0.9446 | Val Loss: 0.2045 Acc: 0.9257\n",
      "Epoch 029 | Train Loss: 0.1393 Acc: 0.9493 | Val Loss: 0.2143 Acc: 0.9167\n",
      "Epoch 030 | Train Loss: 0.1404 Acc: 0.9472 | Val Loss: 0.1612 Acc: 0.9390\n",
      "Epoch 031 | Train Loss: 0.1313 Acc: 0.9499 | Val Loss: 0.1623 Acc: 0.9414\n",
      "Epoch 032 | Train Loss: 0.1084 Acc: 0.9579 | Val Loss: 0.2094 Acc: 0.9263\n",
      "Epoch 033 | Train Loss: 0.1142 Acc: 0.9559 | Val Loss: 0.1643 Acc: 0.9408\n",
      "Epoch 034 | Train Loss: 0.1080 Acc: 0.9610 | Val Loss: 0.1548 Acc: 0.9426\n",
      "Epoch 035 | Train Loss: 0.1038 Acc: 0.9592 | Val Loss: 0.2149 Acc: 0.9263\n",
      "Epoch 036 | Train Loss: 0.0899 Acc: 0.9656 | Val Loss: 0.1736 Acc: 0.9378\n",
      "Epoch 037 | Train Loss: 0.0914 Acc: 0.9629 | Val Loss: 0.1736 Acc: 0.9384\n",
      "Epoch 038 | Train Loss: 0.0914 Acc: 0.9639 | Val Loss: 0.1597 Acc: 0.9426\n",
      "Epoch 039 | Train Loss: 0.1006 Acc: 0.9589 | Val Loss: 0.1479 Acc: 0.9444\n",
      "Epoch 040 | Train Loss: 0.0874 Acc: 0.9695 | Val Loss: 0.1455 Acc: 0.9511\n",
      "Epoch 041 | Train Loss: 0.0783 Acc: 0.9695 | Val Loss: 0.1496 Acc: 0.9432\n",
      "Epoch 042 | Train Loss: 0.0791 Acc: 0.9698 | Val Loss: 0.1626 Acc: 0.9481\n",
      "Epoch 043 | Train Loss: 0.0879 Acc: 0.9659 | Val Loss: 0.1472 Acc: 0.9493\n",
      "Epoch 044 | Train Loss: 0.0737 Acc: 0.9716 | Val Loss: 0.1523 Acc: 0.9450\n",
      "Epoch 045 | Train Loss: 0.0749 Acc: 0.9730 | Val Loss: 0.1495 Acc: 0.9511\n",
      "Epoch 046 | Train Loss: 0.0760 Acc: 0.9721 | Val Loss: 0.1514 Acc: 0.9499\n",
      "Epoch 047 | Train Loss: 0.0723 Acc: 0.9740 | Val Loss: 0.1468 Acc: 0.9517\n",
      "Epoch 048 | Train Loss: 0.0770 Acc: 0.9724 | Val Loss: 0.1547 Acc: 0.9499\n",
      "Epoch 049 | Train Loss: 0.0676 Acc: 0.9757 | Val Loss: 0.1337 Acc: 0.9553\n",
      "Epoch 050 | Train Loss: 0.0641 Acc: 0.9780 | Val Loss: 0.1848 Acc: 0.9438\n",
      "Epoch 051 | Train Loss: 0.0661 Acc: 0.9739 | Val Loss: 0.1609 Acc: 0.9493\n",
      "Epoch 052 | Train Loss: 0.0586 Acc: 0.9783 | Val Loss: 0.1515 Acc: 0.9481\n",
      "Epoch 053 | Train Loss: 0.0622 Acc: 0.9757 | Val Loss: 0.1389 Acc: 0.9577\n",
      "Epoch 054 | Train Loss: 0.0636 Acc: 0.9748 | Val Loss: 0.1483 Acc: 0.9499\n",
      "Epoch 055 | Train Loss: 0.0620 Acc: 0.9758 | Val Loss: 0.1378 Acc: 0.9559\n",
      "Epoch 056 | Train Loss: 0.0579 Acc: 0.9769 | Val Loss: 0.1679 Acc: 0.9426\n",
      "Epoch 057 | Train Loss: 0.0572 Acc: 0.9789 | Val Loss: 0.1592 Acc: 0.9475\n",
      "Epoch 058 | Train Loss: 0.0500 Acc: 0.9816 | Val Loss: 0.1343 Acc: 0.9523\n",
      "Epoch 059 | Train Loss: 0.0643 Acc: 0.9757 | Val Loss: 0.1311 Acc: 0.9511\n",
      "Epoch 060 | Train Loss: 0.0539 Acc: 0.9811 | Val Loss: 0.1701 Acc: 0.9475\n",
      "Epoch 001 | Train Loss: 0.6770 Acc: 0.5809 | Val Loss: 0.6669 Acc: 0.6014\n",
      "Epoch 002 | Train Loss: 0.6468 Acc: 0.6277 | Val Loss: 0.6265 Acc: 0.6655\n",
      "Epoch 003 | Train Loss: 0.5869 Acc: 0.7059 | Val Loss: 0.5931 Acc: 0.6842\n",
      "Epoch 004 | Train Loss: 0.5500 Acc: 0.7334 | Val Loss: 0.5499 Acc: 0.7234\n",
      "Epoch 005 | Train Loss: 0.5228 Acc: 0.7421 | Val Loss: 0.5394 Acc: 0.7313\n",
      "Epoch 006 | Train Loss: 0.4882 Acc: 0.7684 | Val Loss: 0.4725 Acc: 0.7820\n",
      "Epoch 007 | Train Loss: 0.4583 Acc: 0.7889 | Val Loss: 0.4861 Acc: 0.7566\n",
      "Epoch 008 | Train Loss: 0.4368 Acc: 0.7990 | Val Loss: 0.4505 Acc: 0.7874\n",
      "Epoch 009 | Train Loss: 0.4090 Acc: 0.8170 | Val Loss: 0.3872 Acc: 0.8273\n",
      "Epoch 010 | Train Loss: 0.3697 Acc: 0.8409 | Val Loss: 0.3543 Acc: 0.8418\n",
      "Epoch 011 | Train Loss: 0.3438 Acc: 0.8498 | Val Loss: 0.3624 Acc: 0.8333\n",
      "Epoch 012 | Train Loss: 0.3175 Acc: 0.8634 | Val Loss: 0.3051 Acc: 0.8671\n",
      "Epoch 013 | Train Loss: 0.2972 Acc: 0.8726 | Val Loss: 0.2802 Acc: 0.8792\n",
      "Epoch 014 | Train Loss: 0.2711 Acc: 0.8851 | Val Loss: 0.2933 Acc: 0.8696\n",
      "Epoch 015 | Train Loss: 0.2631 Acc: 0.8937 | Val Loss: 0.2633 Acc: 0.8816\n",
      "Epoch 016 | Train Loss: 0.2350 Acc: 0.9028 | Val Loss: 0.2544 Acc: 0.8913\n",
      "Epoch 017 | Train Loss: 0.2250 Acc: 0.9085 | Val Loss: 0.2474 Acc: 0.9010\n",
      "Epoch 018 | Train Loss: 0.2120 Acc: 0.9153 | Val Loss: 0.2501 Acc: 0.8998\n",
      "Epoch 019 | Train Loss: 0.1906 Acc: 0.9225 | Val Loss: 0.2381 Acc: 0.9094\n",
      "Epoch 020 | Train Loss: 0.1899 Acc: 0.9260 | Val Loss: 0.2744 Acc: 0.8883\n",
      "Epoch 021 | Train Loss: 0.1774 Acc: 0.9271 | Val Loss: 0.2605 Acc: 0.9004\n",
      "Epoch 022 | Train Loss: 0.1596 Acc: 0.9405 | Val Loss: 0.2545 Acc: 0.9016\n",
      "Epoch 023 | Train Loss: 0.1526 Acc: 0.9411 | Val Loss: 0.2095 Acc: 0.9136\n",
      "Epoch 024 | Train Loss: 0.1481 Acc: 0.9408 | Val Loss: 0.1937 Acc: 0.9221\n",
      "Epoch 025 | Train Loss: 0.1364 Acc: 0.9470 | Val Loss: 0.2194 Acc: 0.9143\n",
      "Epoch 026 | Train Loss: 0.1337 Acc: 0.9518 | Val Loss: 0.1994 Acc: 0.9263\n",
      "Epoch 027 | Train Loss: 0.1293 Acc: 0.9491 | Val Loss: 0.1962 Acc: 0.9227\n",
      "Epoch 028 | Train Loss: 0.1184 Acc: 0.9529 | Val Loss: 0.2026 Acc: 0.9209\n",
      "Epoch 029 | Train Loss: 0.1166 Acc: 0.9544 | Val Loss: 0.2044 Acc: 0.9324\n",
      "Epoch 030 | Train Loss: 0.1130 Acc: 0.9567 | Val Loss: 0.1858 Acc: 0.9378\n",
      "Epoch 031 | Train Loss: 0.1092 Acc: 0.9570 | Val Loss: 0.2012 Acc: 0.9312\n",
      "Epoch 032 | Train Loss: 0.0932 Acc: 0.9624 | Val Loss: 0.2115 Acc: 0.9251\n",
      "Epoch 033 | Train Loss: 0.0838 Acc: 0.9678 | Val Loss: 0.2080 Acc: 0.9269\n",
      "Epoch 034 | Train Loss: 0.0964 Acc: 0.9654 | Val Loss: 0.1972 Acc: 0.9215\n",
      "Epoch 035 | Train Loss: 0.0890 Acc: 0.9671 | Val Loss: 0.2104 Acc: 0.9312\n",
      "Epoch 036 | Train Loss: 0.0875 Acc: 0.9677 | Val Loss: 0.1832 Acc: 0.9342\n",
      "Epoch 037 | Train Loss: 0.0899 Acc: 0.9656 | Val Loss: 0.1973 Acc: 0.9336\n",
      "Epoch 038 | Train Loss: 0.0868 Acc: 0.9690 | Val Loss: 0.2114 Acc: 0.9348\n",
      "Epoch 039 | Train Loss: 0.0903 Acc: 0.9662 | Val Loss: 0.1809 Acc: 0.9336\n",
      "Epoch 040 | Train Loss: 0.0759 Acc: 0.9719 | Val Loss: 0.1926 Acc: 0.9330\n",
      "Epoch 041 | Train Loss: 0.0675 Acc: 0.9760 | Val Loss: 0.1963 Acc: 0.9324\n",
      "Epoch 042 | Train Loss: 0.0767 Acc: 0.9721 | Val Loss: 0.1742 Acc: 0.9348\n",
      "Epoch 043 | Train Loss: 0.0585 Acc: 0.9789 | Val Loss: 0.1978 Acc: 0.9348\n",
      "Epoch 044 | Train Loss: 0.0714 Acc: 0.9731 | Val Loss: 0.1671 Acc: 0.9402\n",
      "Epoch 045 | Train Loss: 0.0730 Acc: 0.9733 | Val Loss: 0.1971 Acc: 0.9281\n",
      "Epoch 046 | Train Loss: 0.0700 Acc: 0.9760 | Val Loss: 0.1493 Acc: 0.9426\n",
      "Epoch 047 | Train Loss: 0.0585 Acc: 0.9770 | Val Loss: 0.2257 Acc: 0.9287\n",
      "Epoch 048 | Train Loss: 0.0738 Acc: 0.9710 | Val Loss: 0.1926 Acc: 0.9366\n",
      "Epoch 049 | Train Loss: 0.0651 Acc: 0.9746 | Val Loss: 0.1513 Acc: 0.9444\n",
      "Epoch 050 | Train Loss: 0.0573 Acc: 0.9793 | Val Loss: 0.1767 Acc: 0.9469\n",
      "Epoch 051 | Train Loss: 0.0518 Acc: 0.9804 | Val Loss: 0.1635 Acc: 0.9487\n",
      "Epoch 052 | Train Loss: 0.0584 Acc: 0.9811 | Val Loss: 0.1621 Acc: 0.9408\n",
      "Epoch 053 | Train Loss: 0.0555 Acc: 0.9793 | Val Loss: 0.1853 Acc: 0.9432\n",
      "Epoch 054 | Train Loss: 0.0560 Acc: 0.9813 | Val Loss: 0.1554 Acc: 0.9523\n",
      "Epoch 055 | Train Loss: 0.0441 Acc: 0.9848 | Val Loss: 0.1823 Acc: 0.9342\n",
      "Epoch 056 | Train Loss: 0.0535 Acc: 0.9805 | Val Loss: 0.2643 Acc: 0.9233\n",
      "Early stopping triggered.\n",
      "Epoch 001 | Train Loss: 0.6805 Acc: 0.5775 | Val Loss: 0.6751 Acc: 0.5912\n",
      "Epoch 002 | Train Loss: 0.6730 Acc: 0.5940 | Val Loss: 0.6725 Acc: 0.5900\n",
      "Epoch 003 | Train Loss: 0.6551 Acc: 0.6201 | Val Loss: 0.6273 Acc: 0.6697\n",
      "Epoch 004 | Train Loss: 0.6001 Acc: 0.6894 | Val Loss: 0.5880 Acc: 0.6993\n",
      "Epoch 005 | Train Loss: 0.5590 Acc: 0.7219 | Val Loss: 0.5431 Acc: 0.7367\n",
      "Epoch 006 | Train Loss: 0.5294 Acc: 0.7441 | Val Loss: 0.5236 Acc: 0.7476\n",
      "Epoch 007 | Train Loss: 0.5092 Acc: 0.7530 | Val Loss: 0.5491 Acc: 0.7222\n",
      "Epoch 008 | Train Loss: 0.4863 Acc: 0.7755 | Val Loss: 0.4951 Acc: 0.7639\n",
      "Epoch 009 | Train Loss: 0.4646 Acc: 0.7838 | Val Loss: 0.4662 Acc: 0.7699\n",
      "Epoch 010 | Train Loss: 0.4441 Acc: 0.7966 | Val Loss: 0.4646 Acc: 0.7935\n",
      "Epoch 011 | Train Loss: 0.4237 Acc: 0.8028 | Val Loss: 0.4348 Acc: 0.7971\n",
      "Epoch 012 | Train Loss: 0.3974 Acc: 0.8179 | Val Loss: 0.3765 Acc: 0.8225\n",
      "Epoch 013 | Train Loss: 0.3659 Acc: 0.8386 | Val Loss: 0.3548 Acc: 0.8454\n",
      "Epoch 014 | Train Loss: 0.3506 Acc: 0.8483 | Val Loss: 0.3260 Acc: 0.8587\n",
      "Epoch 015 | Train Loss: 0.3309 Acc: 0.8572 | Val Loss: 0.3094 Acc: 0.8605\n",
      "Epoch 016 | Train Loss: 0.3012 Acc: 0.8717 | Val Loss: 0.3103 Acc: 0.8659\n",
      "Epoch 017 | Train Loss: 0.2759 Acc: 0.8807 | Val Loss: 0.2522 Acc: 0.8943\n",
      "Epoch 018 | Train Loss: 0.2685 Acc: 0.8830 | Val Loss: 0.2440 Acc: 0.9022\n",
      "Epoch 019 | Train Loss: 0.2445 Acc: 0.8990 | Val Loss: 0.2707 Acc: 0.8835\n",
      "Epoch 020 | Train Loss: 0.2312 Acc: 0.9040 | Val Loss: 0.2292 Acc: 0.9004\n",
      "Epoch 021 | Train Loss: 0.2194 Acc: 0.9127 | Val Loss: 0.2373 Acc: 0.8986\n",
      "Epoch 022 | Train Loss: 0.2017 Acc: 0.9156 | Val Loss: 0.2252 Acc: 0.9143\n",
      "Epoch 023 | Train Loss: 0.2084 Acc: 0.9167 | Val Loss: 0.2253 Acc: 0.9028\n",
      "Epoch 024 | Train Loss: 0.1886 Acc: 0.9245 | Val Loss: 0.2174 Acc: 0.9082\n",
      "Epoch 025 | Train Loss: 0.1784 Acc: 0.9289 | Val Loss: 0.1965 Acc: 0.9203\n",
      "Epoch 026 | Train Loss: 0.1671 Acc: 0.9316 | Val Loss: 0.1874 Acc: 0.9263\n",
      "Epoch 027 | Train Loss: 0.1523 Acc: 0.9416 | Val Loss: 0.2099 Acc: 0.9227\n",
      "Epoch 028 | Train Loss: 0.1536 Acc: 0.9390 | Val Loss: 0.1757 Acc: 0.9312\n",
      "Epoch 029 | Train Loss: 0.1407 Acc: 0.9450 | Val Loss: 0.1813 Acc: 0.9269\n",
      "Epoch 030 | Train Loss: 0.1298 Acc: 0.9470 | Val Loss: 0.1977 Acc: 0.9221\n",
      "Epoch 031 | Train Loss: 0.1329 Acc: 0.9503 | Val Loss: 0.1804 Acc: 0.9318\n",
      "Epoch 032 | Train Loss: 0.1182 Acc: 0.9546 | Val Loss: 0.1834 Acc: 0.9348\n",
      "Epoch 033 | Train Loss: 0.1148 Acc: 0.9550 | Val Loss: 0.1793 Acc: 0.9384\n",
      "Epoch 034 | Train Loss: 0.1053 Acc: 0.9568 | Val Loss: 0.1639 Acc: 0.9366\n",
      "Epoch 035 | Train Loss: 0.1064 Acc: 0.9609 | Val Loss: 0.1621 Acc: 0.9378\n",
      "Epoch 036 | Train Loss: 0.1003 Acc: 0.9636 | Val Loss: 0.1696 Acc: 0.9360\n",
      "Epoch 037 | Train Loss: 0.0957 Acc: 0.9635 | Val Loss: 0.1629 Acc: 0.9384\n",
      "Epoch 038 | Train Loss: 0.0878 Acc: 0.9669 | Val Loss: 0.1775 Acc: 0.9342\n",
      "Epoch 039 | Train Loss: 0.0998 Acc: 0.9623 | Val Loss: 0.1405 Acc: 0.9493\n",
      "Epoch 040 | Train Loss: 0.0815 Acc: 0.9697 | Val Loss: 0.1673 Acc: 0.9384\n",
      "Epoch 041 | Train Loss: 0.0903 Acc: 0.9645 | Val Loss: 0.1503 Acc: 0.9444\n",
      "Epoch 042 | Train Loss: 0.0767 Acc: 0.9743 | Val Loss: 0.1567 Acc: 0.9481\n",
      "Epoch 043 | Train Loss: 0.0726 Acc: 0.9736 | Val Loss: 0.1509 Acc: 0.9499\n",
      "Epoch 044 | Train Loss: 0.0763 Acc: 0.9698 | Val Loss: 0.1479 Acc: 0.9469\n",
      "Epoch 045 | Train Loss: 0.0676 Acc: 0.9751 | Val Loss: 0.1459 Acc: 0.9469\n",
      "Epoch 046 | Train Loss: 0.0774 Acc: 0.9709 | Val Loss: 0.1444 Acc: 0.9487\n",
      "Epoch 047 | Train Loss: 0.0723 Acc: 0.9740 | Val Loss: 0.1943 Acc: 0.9251\n",
      "Epoch 048 | Train Loss: 0.0672 Acc: 0.9734 | Val Loss: 0.1300 Acc: 0.9529\n",
      "Epoch 049 | Train Loss: 0.0570 Acc: 0.9805 | Val Loss: 0.1230 Acc: 0.9583\n",
      "Epoch 050 | Train Loss: 0.0597 Acc: 0.9778 | Val Loss: 0.1333 Acc: 0.9547\n",
      "Epoch 051 | Train Loss: 0.0646 Acc: 0.9766 | Val Loss: 0.1606 Acc: 0.9469\n",
      "Epoch 052 | Train Loss: 0.0548 Acc: 0.9811 | Val Loss: 0.1592 Acc: 0.9469\n",
      "Epoch 053 | Train Loss: 0.0601 Acc: 0.9766 | Val Loss: 0.1384 Acc: 0.9553\n",
      "Epoch 054 | Train Loss: 0.0453 Acc: 0.9829 | Val Loss: 0.1534 Acc: 0.9481\n",
      "Epoch 055 | Train Loss: 0.0507 Acc: 0.9808 | Val Loss: 0.1300 Acc: 0.9559\n",
      "Epoch 056 | Train Loss: 0.0443 Acc: 0.9844 | Val Loss: 0.1523 Acc: 0.9481\n",
      "Epoch 057 | Train Loss: 0.0546 Acc: 0.9787 | Val Loss: 0.1398 Acc: 0.9547\n",
      "Epoch 058 | Train Loss: 0.0598 Acc: 0.9790 | Val Loss: 0.1341 Acc: 0.9529\n",
      "Epoch 059 | Train Loss: 0.0469 Acc: 0.9829 | Val Loss: 0.1274 Acc: 0.9517\n",
      "Early stopping triggered.\n",
      "Epoch 001 | Train Loss: 0.6783 Acc: 0.5825 | Val Loss: 0.6757 Acc: 0.5894\n",
      "Epoch 002 | Train Loss: 0.6727 Acc: 0.5914 | Val Loss: 0.7189 Acc: 0.5405\n",
      "Epoch 003 | Train Loss: 0.6618 Acc: 0.6062 | Val Loss: 0.6608 Acc: 0.6033\n",
      "Epoch 004 | Train Loss: 0.6478 Acc: 0.6254 | Val Loss: 0.6212 Acc: 0.6721\n",
      "Epoch 005 | Train Loss: 0.6030 Acc: 0.6867 | Val Loss: 0.5933 Acc: 0.7017\n",
      "Epoch 006 | Train Loss: 0.5708 Acc: 0.7187 | Val Loss: 0.6114 Acc: 0.6703\n",
      "Epoch 007 | Train Loss: 0.5446 Acc: 0.7367 | Val Loss: 0.5395 Acc: 0.7331\n",
      "Epoch 008 | Train Loss: 0.5187 Acc: 0.7542 | Val Loss: 0.5014 Acc: 0.7548\n",
      "Epoch 009 | Train Loss: 0.4867 Acc: 0.7734 | Val Loss: 0.4777 Acc: 0.7693\n",
      "Epoch 010 | Train Loss: 0.4594 Acc: 0.7879 | Val Loss: 0.4788 Acc: 0.7512\n",
      "Epoch 011 | Train Loss: 0.4494 Acc: 0.7978 | Val Loss: 0.4617 Acc: 0.7832\n",
      "Epoch 012 | Train Loss: 0.4121 Acc: 0.8185 | Val Loss: 0.4208 Acc: 0.8001\n",
      "Epoch 013 | Train Loss: 0.3988 Acc: 0.8178 | Val Loss: 0.4399 Acc: 0.8062\n",
      "Epoch 014 | Train Loss: 0.3717 Acc: 0.8341 | Val Loss: 0.3818 Acc: 0.8134\n",
      "Epoch 015 | Train Loss: 0.3613 Acc: 0.8378 | Val Loss: 0.3617 Acc: 0.8430\n",
      "Epoch 016 | Train Loss: 0.3307 Acc: 0.8538 | Val Loss: 0.3389 Acc: 0.8484\n",
      "Epoch 017 | Train Loss: 0.3036 Acc: 0.8735 | Val Loss: 0.3358 Acc: 0.8514\n",
      "Epoch 018 | Train Loss: 0.2901 Acc: 0.8763 | Val Loss: 0.3073 Acc: 0.8720\n",
      "Epoch 019 | Train Loss: 0.2745 Acc: 0.8843 | Val Loss: 0.2912 Acc: 0.8762\n",
      "Epoch 020 | Train Loss: 0.2560 Acc: 0.8945 | Val Loss: 0.2797 Acc: 0.8798\n",
      "Epoch 021 | Train Loss: 0.2548 Acc: 0.8920 | Val Loss: 0.2712 Acc: 0.8943\n",
      "Epoch 022 | Train Loss: 0.2359 Acc: 0.9031 | Val Loss: 0.2586 Acc: 0.8961\n",
      "Epoch 023 | Train Loss: 0.2126 Acc: 0.9115 | Val Loss: 0.2547 Acc: 0.9010\n",
      "Epoch 024 | Train Loss: 0.2149 Acc: 0.9135 | Val Loss: 0.2809 Acc: 0.8967\n",
      "Epoch 025 | Train Loss: 0.1959 Acc: 0.9244 | Val Loss: 0.2221 Acc: 0.9094\n",
      "Epoch 026 | Train Loss: 0.1786 Acc: 0.9280 | Val Loss: 0.2505 Acc: 0.8973\n",
      "Epoch 027 | Train Loss: 0.1847 Acc: 0.9262 | Val Loss: 0.2320 Acc: 0.9094\n",
      "Epoch 028 | Train Loss: 0.1604 Acc: 0.9367 | Val Loss: 0.2124 Acc: 0.9167\n",
      "Epoch 029 | Train Loss: 0.1686 Acc: 0.9346 | Val Loss: 0.2456 Acc: 0.9118\n",
      "Epoch 030 | Train Loss: 0.1684 Acc: 0.9336 | Val Loss: 0.2058 Acc: 0.9233\n",
      "Epoch 031 | Train Loss: 0.1457 Acc: 0.9437 | Val Loss: 0.2052 Acc: 0.9155\n",
      "Epoch 032 | Train Loss: 0.1423 Acc: 0.9458 | Val Loss: 0.2070 Acc: 0.9167\n",
      "Epoch 033 | Train Loss: 0.1382 Acc: 0.9461 | Val Loss: 0.1965 Acc: 0.9269\n",
      "Epoch 034 | Train Loss: 0.1356 Acc: 0.9464 | Val Loss: 0.2055 Acc: 0.9215\n",
      "Epoch 035 | Train Loss: 0.1318 Acc: 0.9464 | Val Loss: 0.2300 Acc: 0.9100\n",
      "Epoch 036 | Train Loss: 0.1171 Acc: 0.9562 | Val Loss: 0.2012 Acc: 0.9251\n",
      "Epoch 037 | Train Loss: 0.1194 Acc: 0.9550 | Val Loss: 0.1974 Acc: 0.9293\n",
      "Epoch 038 | Train Loss: 0.1184 Acc: 0.9577 | Val Loss: 0.1919 Acc: 0.9257\n",
      "Epoch 039 | Train Loss: 0.1081 Acc: 0.9616 | Val Loss: 0.2095 Acc: 0.9112\n",
      "Epoch 040 | Train Loss: 0.1036 Acc: 0.9607 | Val Loss: 0.1615 Acc: 0.9372\n",
      "Epoch 041 | Train Loss: 0.0953 Acc: 0.9651 | Val Loss: 0.2000 Acc: 0.9227\n",
      "Epoch 042 | Train Loss: 0.0976 Acc: 0.9624 | Val Loss: 0.2023 Acc: 0.9233\n",
      "Epoch 043 | Train Loss: 0.1077 Acc: 0.9600 | Val Loss: 0.1978 Acc: 0.9330\n",
      "Epoch 044 | Train Loss: 0.0854 Acc: 0.9700 | Val Loss: 0.1865 Acc: 0.9300\n",
      "Epoch 045 | Train Loss: 0.0909 Acc: 0.9645 | Val Loss: 0.1763 Acc: 0.9402\n",
      "Epoch 046 | Train Loss: 0.0840 Acc: 0.9669 | Val Loss: 0.1963 Acc: 0.9306\n",
      "Epoch 047 | Train Loss: 0.0803 Acc: 0.9695 | Val Loss: 0.2077 Acc: 0.9209\n",
      "Epoch 048 | Train Loss: 0.0754 Acc: 0.9722 | Val Loss: 0.1906 Acc: 0.9348\n",
      "Epoch 049 | Train Loss: 0.0736 Acc: 0.9733 | Val Loss: 0.1855 Acc: 0.9378\n",
      "Epoch 050 | Train Loss: 0.0813 Acc: 0.9701 | Val Loss: 0.1932 Acc: 0.9293\n",
      "Early stopping triggered.\n",
      "Epoch 001 | Train Loss: 0.6795 Acc: 0.5816 | Val Loss: 0.6814 Acc: 0.5688\n",
      "Epoch 002 | Train Loss: 0.6783 Acc: 0.5818 | Val Loss: 0.6795 Acc: 0.5773\n",
      "Epoch 003 | Train Loss: 0.6716 Acc: 0.5961 | Val Loss: 0.6721 Acc: 0.6002\n",
      "Epoch 004 | Train Loss: 0.6660 Acc: 0.6032 | Val Loss: 0.6574 Acc: 0.5960\n",
      "Epoch 005 | Train Loss: 0.6587 Acc: 0.6070 | Val Loss: 0.6361 Acc: 0.6594\n",
      "Epoch 006 | Train Loss: 0.6152 Acc: 0.6900 | Val Loss: 0.6027 Acc: 0.6860\n",
      "Epoch 007 | Train Loss: 0.5850 Acc: 0.7010 | Val Loss: 0.6186 Acc: 0.6437\n",
      "Epoch 008 | Train Loss: 0.5601 Acc: 0.7157 | Val Loss: 0.5518 Acc: 0.7150\n",
      "Epoch 009 | Train Loss: 0.5421 Acc: 0.7335 | Val Loss: 0.5503 Acc: 0.7240\n",
      "Epoch 010 | Train Loss: 0.5219 Acc: 0.7469 | Val Loss: 0.5169 Acc: 0.7301\n",
      "Epoch 011 | Train Loss: 0.5117 Acc: 0.7482 | Val Loss: 0.5291 Acc: 0.7313\n",
      "Epoch 012 | Train Loss: 0.4906 Acc: 0.7622 | Val Loss: 0.5339 Acc: 0.7428\n",
      "Epoch 013 | Train Loss: 0.4636 Acc: 0.7750 | Val Loss: 0.4645 Acc: 0.7681\n",
      "Epoch 014 | Train Loss: 0.4585 Acc: 0.7844 | Val Loss: 0.4647 Acc: 0.7736\n",
      "Epoch 015 | Train Loss: 0.4311 Acc: 0.7986 | Val Loss: 0.4318 Acc: 0.7941\n",
      "Epoch 016 | Train Loss: 0.4075 Acc: 0.8184 | Val Loss: 0.5232 Acc: 0.7603\n",
      "Epoch 017 | Train Loss: 0.3964 Acc: 0.8256 | Val Loss: 0.4182 Acc: 0.7971\n",
      "Epoch 018 | Train Loss: 0.3733 Acc: 0.8315 | Val Loss: 0.3739 Acc: 0.8327\n",
      "Epoch 019 | Train Loss: 0.3508 Acc: 0.8449 | Val Loss: 0.3651 Acc: 0.8315\n",
      "Epoch 020 | Train Loss: 0.3369 Acc: 0.8547 | Val Loss: 0.3333 Acc: 0.8496\n",
      "Epoch 021 | Train Loss: 0.3210 Acc: 0.8626 | Val Loss: 0.3015 Acc: 0.8708\n",
      "Epoch 022 | Train Loss: 0.2936 Acc: 0.8732 | Val Loss: 0.3228 Acc: 0.8629\n",
      "Epoch 023 | Train Loss: 0.2864 Acc: 0.8821 | Val Loss: 0.2634 Acc: 0.8943\n",
      "Epoch 024 | Train Loss: 0.2614 Acc: 0.8911 | Val Loss: 0.2831 Acc: 0.8786\n",
      "Epoch 025 | Train Loss: 0.2635 Acc: 0.8890 | Val Loss: 0.2777 Acc: 0.8859\n",
      "Epoch 026 | Train Loss: 0.2593 Acc: 0.8908 | Val Loss: 0.2796 Acc: 0.8822\n",
      "Epoch 027 | Train Loss: 0.2401 Acc: 0.9047 | Val Loss: 0.2342 Acc: 0.9130\n",
      "Epoch 028 | Train Loss: 0.2206 Acc: 0.9126 | Val Loss: 0.3081 Acc: 0.8786\n",
      "Epoch 029 | Train Loss: 0.2168 Acc: 0.9118 | Val Loss: 0.2434 Acc: 0.9100\n",
      "Epoch 030 | Train Loss: 0.2081 Acc: 0.9127 | Val Loss: 0.2323 Acc: 0.9118\n",
      "Epoch 031 | Train Loss: 0.1997 Acc: 0.9204 | Val Loss: 0.2613 Acc: 0.8961\n",
      "Epoch 032 | Train Loss: 0.1953 Acc: 0.9227 | Val Loss: 0.2214 Acc: 0.9082\n",
      "Epoch 033 | Train Loss: 0.1808 Acc: 0.9283 | Val Loss: 0.2389 Acc: 0.9058\n",
      "Epoch 034 | Train Loss: 0.1891 Acc: 0.9260 | Val Loss: 0.2059 Acc: 0.9197\n",
      "Epoch 035 | Train Loss: 0.1671 Acc: 0.9372 | Val Loss: 0.2166 Acc: 0.9130\n",
      "Epoch 036 | Train Loss: 0.1664 Acc: 0.9363 | Val Loss: 0.2318 Acc: 0.9088\n",
      "Epoch 037 | Train Loss: 0.1620 Acc: 0.9384 | Val Loss: 0.1895 Acc: 0.9233\n",
      "Epoch 038 | Train Loss: 0.1578 Acc: 0.9396 | Val Loss: 0.2039 Acc: 0.9251\n",
      "Epoch 039 | Train Loss: 0.1533 Acc: 0.9373 | Val Loss: 0.1902 Acc: 0.9281\n",
      "Epoch 040 | Train Loss: 0.1407 Acc: 0.9449 | Val Loss: 0.2009 Acc: 0.9197\n",
      "Epoch 041 | Train Loss: 0.1470 Acc: 0.9465 | Val Loss: 0.1972 Acc: 0.9275\n",
      "Epoch 042 | Train Loss: 0.1410 Acc: 0.9459 | Val Loss: 0.1898 Acc: 0.9251\n",
      "Epoch 043 | Train Loss: 0.1412 Acc: 0.9491 | Val Loss: 0.2113 Acc: 0.9269\n",
      "Epoch 044 | Train Loss: 0.1339 Acc: 0.9490 | Val Loss: 0.1925 Acc: 0.9366\n",
      "Epoch 045 | Train Loss: 0.1219 Acc: 0.9527 | Val Loss: 0.1797 Acc: 0.9312\n",
      "Epoch 046 | Train Loss: 0.1341 Acc: 0.9500 | Val Loss: 0.1884 Acc: 0.9293\n",
      "Epoch 047 | Train Loss: 0.1205 Acc: 0.9543 | Val Loss: 0.1959 Acc: 0.9330\n",
      "Epoch 048 | Train Loss: 0.1258 Acc: 0.9532 | Val Loss: 0.1950 Acc: 0.9324\n",
      "Epoch 049 | Train Loss: 0.1226 Acc: 0.9535 | Val Loss: 0.1793 Acc: 0.9330\n",
      "Epoch 050 | Train Loss: 0.1063 Acc: 0.9600 | Val Loss: 0.1908 Acc: 0.9354\n",
      "Epoch 051 | Train Loss: 0.1023 Acc: 0.9612 | Val Loss: 0.1979 Acc: 0.9318\n",
      "Epoch 052 | Train Loss: 0.0996 Acc: 0.9633 | Val Loss: 0.2389 Acc: 0.9245\n",
      "Epoch 053 | Train Loss: 0.1162 Acc: 0.9579 | Val Loss: 0.2114 Acc: 0.9227\n",
      "Epoch 054 | Train Loss: 0.1160 Acc: 0.9580 | Val Loss: 0.1960 Acc: 0.9312\n",
      "Epoch 055 | Train Loss: 0.1076 Acc: 0.9627 | Val Loss: 0.1726 Acc: 0.9414\n",
      "Epoch 056 | Train Loss: 0.0994 Acc: 0.9641 | Val Loss: 0.2005 Acc: 0.9318\n",
      "Epoch 057 | Train Loss: 0.1027 Acc: 0.9613 | Val Loss: 0.1964 Acc: 0.9281\n",
      "Epoch 058 | Train Loss: 0.1034 Acc: 0.9618 | Val Loss: 0.1807 Acc: 0.9390\n",
      "Epoch 059 | Train Loss: 0.1107 Acc: 0.9592 | Val Loss: 0.1830 Acc: 0.9372\n",
      "Epoch 060 | Train Loss: 0.0970 Acc: 0.9627 | Val Loss: 0.1818 Acc: 0.9378\n",
      "Epoch 001 | Train Loss: 0.6809 Acc: 0.5756 | Val Loss: 0.6765 Acc: 0.5857\n",
      "Epoch 002 | Train Loss: 0.6760 Acc: 0.5880 | Val Loss: 0.6749 Acc: 0.5839\n",
      "Epoch 003 | Train Loss: 0.6704 Acc: 0.5994 | Val Loss: 0.6672 Acc: 0.5906\n",
      "Epoch 004 | Train Loss: 0.6426 Acc: 0.6387 | Val Loss: 0.6241 Acc: 0.6800\n",
      "Epoch 005 | Train Loss: 0.6020 Acc: 0.6834 | Val Loss: 0.5895 Acc: 0.6944\n",
      "Epoch 006 | Train Loss: 0.5764 Acc: 0.7098 | Val Loss: 0.6186 Acc: 0.6866\n",
      "Epoch 007 | Train Loss: 0.5644 Acc: 0.7169 | Val Loss: 0.5710 Acc: 0.7023\n",
      "Epoch 008 | Train Loss: 0.5374 Acc: 0.7398 | Val Loss: 0.5543 Acc: 0.7204\n",
      "Epoch 009 | Train Loss: 0.5304 Acc: 0.7408 | Val Loss: 0.5488 Acc: 0.7283\n",
      "Epoch 010 | Train Loss: 0.5200 Acc: 0.7506 | Val Loss: 0.5299 Acc: 0.7361\n",
      "Epoch 011 | Train Loss: 0.5077 Acc: 0.7572 | Val Loss: 0.5152 Acc: 0.7421\n",
      "Epoch 012 | Train Loss: 0.4897 Acc: 0.7693 | Val Loss: 0.5036 Acc: 0.7566\n",
      "Epoch 013 | Train Loss: 0.4706 Acc: 0.7820 | Val Loss: 0.4603 Acc: 0.7766\n",
      "Epoch 014 | Train Loss: 0.4427 Acc: 0.7936 | Val Loss: 0.4419 Acc: 0.7899\n",
      "Epoch 015 | Train Loss: 0.4270 Acc: 0.8060 | Val Loss: 0.4700 Acc: 0.7832\n",
      "Epoch 016 | Train Loss: 0.4160 Acc: 0.8075 | Val Loss: 0.3927 Acc: 0.8249\n",
      "Epoch 017 | Train Loss: 0.3965 Acc: 0.8181 | Val Loss: 0.4138 Acc: 0.7989\n",
      "Epoch 018 | Train Loss: 0.3715 Acc: 0.8357 | Val Loss: 0.3738 Acc: 0.8297\n",
      "Epoch 019 | Train Loss: 0.3547 Acc: 0.8428 | Val Loss: 0.3456 Acc: 0.8460\n",
      "Epoch 020 | Train Loss: 0.3461 Acc: 0.8498 | Val Loss: 0.3280 Acc: 0.8629\n",
      "Epoch 021 | Train Loss: 0.3197 Acc: 0.8620 | Val Loss: 0.3274 Acc: 0.8587\n",
      "Epoch 022 | Train Loss: 0.3212 Acc: 0.8579 | Val Loss: 0.3122 Acc: 0.8641\n",
      "Epoch 023 | Train Loss: 0.3036 Acc: 0.8735 | Val Loss: 0.3529 Acc: 0.8424\n",
      "Epoch 024 | Train Loss: 0.2815 Acc: 0.8812 | Val Loss: 0.2921 Acc: 0.8738\n",
      "Epoch 025 | Train Loss: 0.2787 Acc: 0.8839 | Val Loss: 0.2879 Acc: 0.8877\n",
      "Epoch 026 | Train Loss: 0.2552 Acc: 0.8954 | Val Loss: 0.2555 Acc: 0.8961\n",
      "Epoch 027 | Train Loss: 0.2564 Acc: 0.8913 | Val Loss: 0.2803 Acc: 0.8835\n",
      "Epoch 028 | Train Loss: 0.2405 Acc: 0.9005 | Val Loss: 0.2483 Acc: 0.8986\n",
      "Epoch 029 | Train Loss: 0.2220 Acc: 0.9077 | Val Loss: 0.2584 Acc: 0.8937\n",
      "Epoch 030 | Train Loss: 0.2191 Acc: 0.9099 | Val Loss: 0.2268 Acc: 0.9161\n",
      "Epoch 031 | Train Loss: 0.2274 Acc: 0.9099 | Val Loss: 0.2178 Acc: 0.9167\n",
      "Epoch 032 | Train Loss: 0.2041 Acc: 0.9200 | Val Loss: 0.2521 Acc: 0.9028\n",
      "Epoch 033 | Train Loss: 0.2054 Acc: 0.9213 | Val Loss: 0.2111 Acc: 0.9155\n",
      "Epoch 034 | Train Loss: 0.1974 Acc: 0.9233 | Val Loss: 0.2222 Acc: 0.9094\n",
      "Epoch 035 | Train Loss: 0.1864 Acc: 0.9266 | Val Loss: 0.2256 Acc: 0.9155\n",
      "Epoch 036 | Train Loss: 0.1921 Acc: 0.9222 | Val Loss: 0.2071 Acc: 0.9185\n",
      "Epoch 037 | Train Loss: 0.1779 Acc: 0.9298 | Val Loss: 0.2011 Acc: 0.9257\n",
      "Epoch 038 | Train Loss: 0.1636 Acc: 0.9354 | Val Loss: 0.1913 Acc: 0.9269\n",
      "Epoch 039 | Train Loss: 0.1663 Acc: 0.9357 | Val Loss: 0.2141 Acc: 0.9215\n",
      "Epoch 040 | Train Loss: 0.1640 Acc: 0.9337 | Val Loss: 0.1814 Acc: 0.9384\n",
      "Epoch 041 | Train Loss: 0.1545 Acc: 0.9390 | Val Loss: 0.1825 Acc: 0.9318\n",
      "Epoch 042 | Train Loss: 0.1439 Acc: 0.9440 | Val Loss: 0.1759 Acc: 0.9300\n",
      "Epoch 043 | Train Loss: 0.1488 Acc: 0.9426 | Val Loss: 0.1809 Acc: 0.9312\n",
      "Epoch 044 | Train Loss: 0.1428 Acc: 0.9405 | Val Loss: 0.2286 Acc: 0.9052\n",
      "Epoch 045 | Train Loss: 0.1392 Acc: 0.9459 | Val Loss: 0.1798 Acc: 0.9318\n",
      "Epoch 046 | Train Loss: 0.1347 Acc: 0.9482 | Val Loss: 0.1907 Acc: 0.9300\n",
      "Epoch 047 | Train Loss: 0.1334 Acc: 0.9511 | Val Loss: 0.1632 Acc: 0.9366\n",
      "Epoch 048 | Train Loss: 0.1297 Acc: 0.9515 | Val Loss: 0.1665 Acc: 0.9420\n",
      "Epoch 049 | Train Loss: 0.1249 Acc: 0.9543 | Val Loss: 0.1767 Acc: 0.9390\n",
      "Epoch 050 | Train Loss: 0.1269 Acc: 0.9543 | Val Loss: 0.1744 Acc: 0.9293\n",
      "Epoch 051 | Train Loss: 0.1147 Acc: 0.9558 | Val Loss: 0.1519 Acc: 0.9469\n",
      "Epoch 052 | Train Loss: 0.1125 Acc: 0.9564 | Val Loss: 0.1596 Acc: 0.9390\n",
      "Epoch 053 | Train Loss: 0.1214 Acc: 0.9538 | Val Loss: 0.1861 Acc: 0.9287\n",
      "Epoch 054 | Train Loss: 0.1097 Acc: 0.9615 | Val Loss: 0.1526 Acc: 0.9444\n",
      "Epoch 055 | Train Loss: 0.1093 Acc: 0.9583 | Val Loss: 0.1717 Acc: 0.9336\n",
      "Epoch 056 | Train Loss: 0.1066 Acc: 0.9604 | Val Loss: 0.1718 Acc: 0.9414\n",
      "Epoch 057 | Train Loss: 0.1076 Acc: 0.9586 | Val Loss: 0.1722 Acc: 0.9354\n",
      "Epoch 058 | Train Loss: 0.1033 Acc: 0.9626 | Val Loss: 0.1559 Acc: 0.9487\n",
      "Epoch 059 | Train Loss: 0.0952 Acc: 0.9624 | Val Loss: 0.1579 Acc: 0.9475\n",
      "Epoch 060 | Train Loss: 0.1063 Acc: 0.9603 | Val Loss: 0.1758 Acc: 0.9336\n",
      "Epoch 001 | Train Loss: 0.6800 Acc: 0.5792 | Val Loss: 0.6851 Acc: 0.5864\n",
      "Epoch 002 | Train Loss: 0.6723 Acc: 0.5950 | Val Loss: 0.6711 Acc: 0.5996\n",
      "Epoch 003 | Train Loss: 0.6590 Acc: 0.6121 | Val Loss: 0.6629 Acc: 0.5894\n",
      "Epoch 004 | Train Loss: 0.6395 Acc: 0.6387 | Val Loss: 0.6459 Acc: 0.6123\n",
      "Epoch 005 | Train Loss: 0.5873 Acc: 0.7015 | Val Loss: 0.5784 Acc: 0.7023\n",
      "Epoch 006 | Train Loss: 0.5624 Acc: 0.7240 | Val Loss: 0.5635 Acc: 0.7107\n",
      "Epoch 007 | Train Loss: 0.5424 Acc: 0.7323 | Val Loss: 0.5365 Acc: 0.7271\n",
      "Epoch 008 | Train Loss: 0.5205 Acc: 0.7435 | Val Loss: 0.5212 Acc: 0.7373\n",
      "Epoch 009 | Train Loss: 0.5096 Acc: 0.7524 | Val Loss: 0.5086 Acc: 0.7542\n",
      "Epoch 010 | Train Loss: 0.4920 Acc: 0.7693 | Val Loss: 0.4965 Acc: 0.7530\n",
      "Epoch 011 | Train Loss: 0.4661 Acc: 0.7767 | Val Loss: 0.4674 Acc: 0.7736\n",
      "Epoch 012 | Train Loss: 0.4431 Acc: 0.7948 | Val Loss: 0.4527 Acc: 0.7742\n",
      "Epoch 013 | Train Loss: 0.4180 Acc: 0.8067 | Val Loss: 0.4278 Acc: 0.7989\n",
      "Epoch 014 | Train Loss: 0.4005 Acc: 0.8170 | Val Loss: 0.3807 Acc: 0.8194\n",
      "Epoch 015 | Train Loss: 0.3915 Acc: 0.8203 | Val Loss: 0.3853 Acc: 0.8176\n",
      "Epoch 016 | Train Loss: 0.3666 Acc: 0.8338 | Val Loss: 0.3651 Acc: 0.8279\n",
      "Epoch 017 | Train Loss: 0.3467 Acc: 0.8492 | Val Loss: 0.3447 Acc: 0.8370\n",
      "Epoch 018 | Train Loss: 0.3355 Acc: 0.8522 | Val Loss: 0.3624 Acc: 0.8285\n",
      "Epoch 019 | Train Loss: 0.3100 Acc: 0.8664 | Val Loss: 0.3603 Acc: 0.8321\n",
      "Epoch 020 | Train Loss: 0.2983 Acc: 0.8709 | Val Loss: 0.3114 Acc: 0.8684\n",
      "Epoch 021 | Train Loss: 0.2899 Acc: 0.8729 | Val Loss: 0.3281 Acc: 0.8647\n",
      "Epoch 022 | Train Loss: 0.2795 Acc: 0.8828 | Val Loss: 0.2861 Acc: 0.8822\n",
      "Epoch 023 | Train Loss: 0.2569 Acc: 0.8949 | Val Loss: 0.3066 Acc: 0.8786\n",
      "Epoch 024 | Train Loss: 0.2450 Acc: 0.8964 | Val Loss: 0.2656 Acc: 0.8919\n",
      "Epoch 025 | Train Loss: 0.2297 Acc: 0.9071 | Val Loss: 0.2552 Acc: 0.8979\n",
      "Epoch 026 | Train Loss: 0.2352 Acc: 0.9017 | Val Loss: 0.2624 Acc: 0.8883\n",
      "Epoch 027 | Train Loss: 0.2040 Acc: 0.9183 | Val Loss: 0.2643 Acc: 0.8937\n",
      "Epoch 028 | Train Loss: 0.1990 Acc: 0.9215 | Val Loss: 0.2372 Acc: 0.9118\n",
      "Epoch 029 | Train Loss: 0.1855 Acc: 0.9262 | Val Loss: 0.2351 Acc: 0.9016\n",
      "Epoch 030 | Train Loss: 0.1781 Acc: 0.9310 | Val Loss: 0.2306 Acc: 0.9106\n",
      "Epoch 031 | Train Loss: 0.1705 Acc: 0.9327 | Val Loss: 0.2052 Acc: 0.9197\n",
      "Epoch 032 | Train Loss: 0.1656 Acc: 0.9366 | Val Loss: 0.1951 Acc: 0.9239\n",
      "Epoch 033 | Train Loss: 0.1517 Acc: 0.9402 | Val Loss: 0.2393 Acc: 0.9052\n",
      "Epoch 034 | Train Loss: 0.1542 Acc: 0.9398 | Val Loss: 0.2030 Acc: 0.9209\n",
      "Epoch 035 | Train Loss: 0.1377 Acc: 0.9462 | Val Loss: 0.2205 Acc: 0.9167\n",
      "Epoch 036 | Train Loss: 0.1378 Acc: 0.9482 | Val Loss: 0.2240 Acc: 0.9124\n",
      "Epoch 037 | Train Loss: 0.1355 Acc: 0.9481 | Val Loss: 0.2021 Acc: 0.9257\n",
      "Epoch 038 | Train Loss: 0.1320 Acc: 0.9487 | Val Loss: 0.2006 Acc: 0.9263\n",
      "Epoch 039 | Train Loss: 0.1280 Acc: 0.9502 | Val Loss: 0.1982 Acc: 0.9287\n",
      "Epoch 040 | Train Loss: 0.1109 Acc: 0.9585 | Val Loss: 0.1895 Acc: 0.9293\n",
      "Epoch 041 | Train Loss: 0.1136 Acc: 0.9583 | Val Loss: 0.1893 Acc: 0.9281\n",
      "Epoch 042 | Train Loss: 0.1091 Acc: 0.9553 | Val Loss: 0.2323 Acc: 0.9130\n",
      "Epoch 043 | Train Loss: 0.1171 Acc: 0.9555 | Val Loss: 0.1896 Acc: 0.9306\n",
      "Epoch 044 | Train Loss: 0.1179 Acc: 0.9544 | Val Loss: 0.2015 Acc: 0.9275\n",
      "Epoch 045 | Train Loss: 0.1026 Acc: 0.9618 | Val Loss: 0.1810 Acc: 0.9324\n",
      "Epoch 046 | Train Loss: 0.1018 Acc: 0.9610 | Val Loss: 0.1987 Acc: 0.9275\n",
      "Epoch 047 | Train Loss: 0.1009 Acc: 0.9613 | Val Loss: 0.2098 Acc: 0.9179\n",
      "Epoch 048 | Train Loss: 0.0999 Acc: 0.9635 | Val Loss: 0.1719 Acc: 0.9438\n",
      "Epoch 049 | Train Loss: 0.0807 Acc: 0.9712 | Val Loss: 0.2238 Acc: 0.9221\n",
      "Epoch 050 | Train Loss: 0.1003 Acc: 0.9629 | Val Loss: 0.2073 Acc: 0.9281\n",
      "Epoch 051 | Train Loss: 0.0827 Acc: 0.9700 | Val Loss: 0.1806 Acc: 0.9420\n",
      "Epoch 052 | Train Loss: 0.0943 Acc: 0.9657 | Val Loss: 0.2202 Acc: 0.9300\n",
      "Epoch 053 | Train Loss: 0.0825 Acc: 0.9695 | Val Loss: 0.1927 Acc: 0.9426\n",
      "Epoch 054 | Train Loss: 0.0852 Acc: 0.9700 | Val Loss: 0.2152 Acc: 0.9221\n",
      "Epoch 055 | Train Loss: 0.0852 Acc: 0.9689 | Val Loss: 0.1619 Acc: 0.9420\n",
      "Epoch 056 | Train Loss: 0.0732 Acc: 0.9719 | Val Loss: 0.2029 Acc: 0.9330\n",
      "Epoch 057 | Train Loss: 0.0797 Acc: 0.9700 | Val Loss: 0.1905 Acc: 0.9372\n",
      "Epoch 058 | Train Loss: 0.0797 Acc: 0.9706 | Val Loss: 0.1692 Acc: 0.9396\n",
      "Epoch 059 | Train Loss: 0.0804 Acc: 0.9707 | Val Loss: 0.1684 Acc: 0.9396\n",
      "Epoch 060 | Train Loss: 0.0789 Acc: 0.9712 | Val Loss: 0.2095 Acc: 0.9354\n",
      "Iteration 18/40 | Best Val Loss: 0.1122 | Iter Time: 222.91s | Total Time: 79.02 min\n",
      "Epoch 001 | Train Loss: 0.6808 Acc: 0.5756 | Val Loss: 0.6796 Acc: 0.5707\n",
      "Epoch 002 | Train Loss: 0.6642 Acc: 0.5984 | Val Loss: 0.6643 Acc: 0.5990\n",
      "Epoch 003 | Train Loss: 0.6266 Acc: 0.6618 | Val Loss: 0.6193 Acc: 0.6655\n",
      "Epoch 004 | Train Loss: 0.5671 Acc: 0.7175 | Val Loss: 0.5845 Acc: 0.7047\n",
      "Epoch 005 | Train Loss: 0.5484 Acc: 0.7275 | Val Loss: 0.5511 Acc: 0.7234\n",
      "Epoch 006 | Train Loss: 0.5219 Acc: 0.7462 | Val Loss: 0.5303 Acc: 0.7319\n",
      "Epoch 007 | Train Loss: 0.4970 Acc: 0.7566 | Val Loss: 0.4859 Acc: 0.7566\n",
      "Epoch 008 | Train Loss: 0.4625 Acc: 0.7839 | Val Loss: 0.4940 Acc: 0.7518\n",
      "Epoch 009 | Train Loss: 0.4408 Acc: 0.7972 | Val Loss: 0.4483 Acc: 0.7820\n",
      "Epoch 010 | Train Loss: 0.4046 Acc: 0.8194 | Val Loss: 0.4259 Acc: 0.7959\n",
      "Epoch 011 | Train Loss: 0.3815 Acc: 0.8253 | Val Loss: 0.3853 Acc: 0.8243\n",
      "Epoch 012 | Train Loss: 0.3569 Acc: 0.8428 | Val Loss: 0.3473 Acc: 0.8436\n",
      "Epoch 013 | Train Loss: 0.3280 Acc: 0.8557 | Val Loss: 0.3322 Acc: 0.8514\n",
      "Epoch 014 | Train Loss: 0.3070 Acc: 0.8715 | Val Loss: 0.3040 Acc: 0.8696\n",
      "Epoch 015 | Train Loss: 0.2779 Acc: 0.8849 | Val Loss: 0.2956 Acc: 0.8671\n",
      "Epoch 016 | Train Loss: 0.2633 Acc: 0.8934 | Val Loss: 0.2700 Acc: 0.8937\n",
      "Epoch 017 | Train Loss: 0.2382 Acc: 0.9020 | Val Loss: 0.2393 Acc: 0.8949\n",
      "Epoch 018 | Train Loss: 0.2125 Acc: 0.9170 | Val Loss: 0.2588 Acc: 0.8973\n",
      "Epoch 019 | Train Loss: 0.2081 Acc: 0.9139 | Val Loss: 0.2133 Acc: 0.9143\n",
      "Epoch 020 | Train Loss: 0.1977 Acc: 0.9186 | Val Loss: 0.2204 Acc: 0.9076\n",
      "Epoch 021 | Train Loss: 0.1692 Acc: 0.9319 | Val Loss: 0.2122 Acc: 0.9149\n",
      "Epoch 022 | Train Loss: 0.1699 Acc: 0.9333 | Val Loss: 0.2126 Acc: 0.9130\n",
      "Epoch 023 | Train Loss: 0.1535 Acc: 0.9404 | Val Loss: 0.2112 Acc: 0.9161\n",
      "Epoch 024 | Train Loss: 0.1441 Acc: 0.9447 | Val Loss: 0.1859 Acc: 0.9318\n",
      "Epoch 025 | Train Loss: 0.1276 Acc: 0.9469 | Val Loss: 0.1814 Acc: 0.9300\n",
      "Epoch 026 | Train Loss: 0.1305 Acc: 0.9481 | Val Loss: 0.2709 Acc: 0.9004\n",
      "Epoch 027 | Train Loss: 0.1270 Acc: 0.9508 | Val Loss: 0.1858 Acc: 0.9281\n",
      "Epoch 028 | Train Loss: 0.1117 Acc: 0.9571 | Val Loss: 0.2131 Acc: 0.9263\n",
      "Epoch 029 | Train Loss: 0.1060 Acc: 0.9592 | Val Loss: 0.2077 Acc: 0.9275\n",
      "Epoch 030 | Train Loss: 0.1016 Acc: 0.9612 | Val Loss: 0.1789 Acc: 0.9330\n",
      "Epoch 031 | Train Loss: 0.0981 Acc: 0.9653 | Val Loss: 0.1613 Acc: 0.9420\n",
      "Epoch 032 | Train Loss: 0.0845 Acc: 0.9681 | Val Loss: 0.1840 Acc: 0.9354\n",
      "Epoch 033 | Train Loss: 0.0833 Acc: 0.9686 | Val Loss: 0.1984 Acc: 0.9306\n",
      "Epoch 034 | Train Loss: 0.0864 Acc: 0.9669 | Val Loss: 0.1723 Acc: 0.9390\n",
      "Epoch 035 | Train Loss: 0.0749 Acc: 0.9731 | Val Loss: 0.1789 Acc: 0.9336\n",
      "Epoch 036 | Train Loss: 0.0741 Acc: 0.9731 | Val Loss: 0.1555 Acc: 0.9463\n",
      "Epoch 037 | Train Loss: 0.0669 Acc: 0.9754 | Val Loss: 0.1526 Acc: 0.9493\n",
      "Epoch 038 | Train Loss: 0.0741 Acc: 0.9740 | Val Loss: 0.1681 Acc: 0.9408\n",
      "Epoch 039 | Train Loss: 0.0569 Acc: 0.9799 | Val Loss: 0.1843 Acc: 0.9348\n",
      "Epoch 040 | Train Loss: 0.0639 Acc: 0.9758 | Val Loss: 0.1779 Acc: 0.9336\n",
      "Epoch 041 | Train Loss: 0.0722 Acc: 0.9728 | Val Loss: 0.1962 Acc: 0.9342\n",
      "Epoch 042 | Train Loss: 0.0557 Acc: 0.9801 | Val Loss: 0.1712 Acc: 0.9457\n",
      "Epoch 043 | Train Loss: 0.0541 Acc: 0.9813 | Val Loss: 0.1727 Acc: 0.9420\n",
      "Epoch 044 | Train Loss: 0.0587 Acc: 0.9796 | Val Loss: 0.1815 Acc: 0.9396\n",
      "Epoch 045 | Train Loss: 0.0595 Acc: 0.9793 | Val Loss: 0.1791 Acc: 0.9354\n",
      "Epoch 046 | Train Loss: 0.0518 Acc: 0.9807 | Val Loss: 0.2010 Acc: 0.9390\n",
      "Epoch 047 | Train Loss: 0.0520 Acc: 0.9814 | Val Loss: 0.1512 Acc: 0.9505\n",
      "Epoch 048 | Train Loss: 0.0413 Acc: 0.9851 | Val Loss: 0.2040 Acc: 0.9384\n",
      "Epoch 049 | Train Loss: 0.0447 Acc: 0.9835 | Val Loss: 0.1848 Acc: 0.9438\n",
      "Epoch 050 | Train Loss: 0.0491 Acc: 0.9808 | Val Loss: 0.1592 Acc: 0.9493\n",
      "Epoch 051 | Train Loss: 0.0432 Acc: 0.9828 | Val Loss: 0.1590 Acc: 0.9517\n",
      "Epoch 052 | Train Loss: 0.0419 Acc: 0.9849 | Val Loss: 0.1430 Acc: 0.9571\n",
      "Epoch 053 | Train Loss: 0.0417 Acc: 0.9864 | Val Loss: 0.1710 Acc: 0.9438\n",
      "Epoch 054 | Train Loss: 0.0434 Acc: 0.9834 | Val Loss: 0.1512 Acc: 0.9469\n",
      "Epoch 055 | Train Loss: 0.0357 Acc: 0.9866 | Val Loss: 0.1545 Acc: 0.9523\n",
      "Epoch 056 | Train Loss: 0.0442 Acc: 0.9844 | Val Loss: 0.1496 Acc: 0.9505\n",
      "Epoch 057 | Train Loss: 0.0383 Acc: 0.9861 | Val Loss: 0.1749 Acc: 0.9505\n",
      "Epoch 058 | Train Loss: 0.0439 Acc: 0.9844 | Val Loss: 0.1726 Acc: 0.9444\n",
      "Epoch 059 | Train Loss: 0.0365 Acc: 0.9875 | Val Loss: 0.1716 Acc: 0.9541\n",
      "Epoch 060 | Train Loss: 0.0449 Acc: 0.9838 | Val Loss: 0.1509 Acc: 0.9565\n",
      "Epoch 001 | Train Loss: 0.6777 Acc: 0.5842 | Val Loss: 0.6712 Acc: 0.5900\n",
      "Epoch 002 | Train Loss: 0.6627 Acc: 0.6076 | Val Loss: 0.6762 Acc: 0.5918\n",
      "Epoch 003 | Train Loss: 0.5838 Acc: 0.7083 | Val Loss: 0.5673 Acc: 0.7071\n",
      "Epoch 004 | Train Loss: 0.5067 Acc: 0.7608 | Val Loss: 0.4705 Acc: 0.7850\n",
      "Epoch 005 | Train Loss: 0.4352 Acc: 0.8054 | Val Loss: 0.4485 Acc: 0.7862\n",
      "Epoch 006 | Train Loss: 0.3955 Acc: 0.8324 | Val Loss: 0.3805 Acc: 0.8261\n",
      "Epoch 007 | Train Loss: 0.3314 Acc: 0.8618 | Val Loss: 0.3333 Acc: 0.8539\n",
      "Epoch 008 | Train Loss: 0.3059 Acc: 0.8724 | Val Loss: 0.3245 Acc: 0.8605\n",
      "Epoch 009 | Train Loss: 0.2652 Acc: 0.8942 | Val Loss: 0.2856 Acc: 0.8768\n",
      "Epoch 010 | Train Loss: 0.2277 Acc: 0.9073 | Val Loss: 0.3137 Acc: 0.8696\n",
      "Epoch 011 | Train Loss: 0.2153 Acc: 0.9157 | Val Loss: 0.3068 Acc: 0.8659\n",
      "Epoch 012 | Train Loss: 0.1882 Acc: 0.9250 | Val Loss: 0.2640 Acc: 0.8961\n",
      "Epoch 013 | Train Loss: 0.1870 Acc: 0.9280 | Val Loss: 0.2862 Acc: 0.8883\n",
      "Epoch 014 | Train Loss: 0.1678 Acc: 0.9330 | Val Loss: 0.2472 Acc: 0.8937\n",
      "Epoch 015 | Train Loss: 0.1415 Acc: 0.9458 | Val Loss: 0.2529 Acc: 0.8992\n",
      "Epoch 016 | Train Loss: 0.1400 Acc: 0.9481 | Val Loss: 0.2321 Acc: 0.9034\n",
      "Epoch 017 | Train Loss: 0.1181 Acc: 0.9527 | Val Loss: 0.2139 Acc: 0.9233\n",
      "Epoch 018 | Train Loss: 0.1154 Acc: 0.9559 | Val Loss: 0.2064 Acc: 0.9191\n",
      "Epoch 019 | Train Loss: 0.1093 Acc: 0.9601 | Val Loss: 0.2582 Acc: 0.8925\n",
      "Epoch 020 | Train Loss: 0.0938 Acc: 0.9650 | Val Loss: 0.2059 Acc: 0.9209\n",
      "Epoch 021 | Train Loss: 0.0851 Acc: 0.9683 | Val Loss: 0.2302 Acc: 0.9161\n",
      "Epoch 022 | Train Loss: 0.0892 Acc: 0.9654 | Val Loss: 0.2207 Acc: 0.9197\n",
      "Epoch 023 | Train Loss: 0.0830 Acc: 0.9677 | Val Loss: 0.2027 Acc: 0.9263\n",
      "Epoch 024 | Train Loss: 0.0796 Acc: 0.9698 | Val Loss: 0.1840 Acc: 0.9300\n",
      "Epoch 025 | Train Loss: 0.0685 Acc: 0.9751 | Val Loss: 0.2019 Acc: 0.9281\n",
      "Epoch 026 | Train Loss: 0.0651 Acc: 0.9758 | Val Loss: 0.1667 Acc: 0.9432\n",
      "Epoch 027 | Train Loss: 0.0731 Acc: 0.9712 | Val Loss: 0.1708 Acc: 0.9312\n",
      "Epoch 028 | Train Loss: 0.0562 Acc: 0.9816 | Val Loss: 0.1899 Acc: 0.9348\n",
      "Epoch 029 | Train Loss: 0.0706 Acc: 0.9743 | Val Loss: 0.1995 Acc: 0.9203\n",
      "Epoch 030 | Train Loss: 0.0521 Acc: 0.9816 | Val Loss: 0.1740 Acc: 0.9384\n",
      "Epoch 031 | Train Loss: 0.0477 Acc: 0.9843 | Val Loss: 0.2193 Acc: 0.9312\n",
      "Epoch 032 | Train Loss: 0.0577 Acc: 0.9793 | Val Loss: 0.1853 Acc: 0.9348\n",
      "Epoch 033 | Train Loss: 0.0543 Acc: 0.9792 | Val Loss: 0.2039 Acc: 0.9324\n",
      "Epoch 034 | Train Loss: 0.0498 Acc: 0.9820 | Val Loss: 0.2413 Acc: 0.9312\n",
      "Epoch 035 | Train Loss: 0.0474 Acc: 0.9811 | Val Loss: 0.1922 Acc: 0.9408\n",
      "Epoch 036 | Train Loss: 0.0425 Acc: 0.9848 | Val Loss: 0.2487 Acc: 0.9257\n",
      "Early stopping triggered.\n",
      "Epoch 001 | Train Loss: 0.6810 Acc: 0.5729 | Val Loss: 0.6764 Acc: 0.5930\n",
      "Epoch 002 | Train Loss: 0.6628 Acc: 0.6079 | Val Loss: 0.6363 Acc: 0.6540\n",
      "Epoch 003 | Train Loss: 0.6221 Acc: 0.6690 | Val Loss: 0.6009 Acc: 0.6824\n",
      "Epoch 004 | Train Loss: 0.5727 Acc: 0.7170 | Val Loss: 0.5856 Acc: 0.7029\n",
      "Epoch 005 | Train Loss: 0.5490 Acc: 0.7308 | Val Loss: 0.5449 Acc: 0.7264\n",
      "Epoch 006 | Train Loss: 0.5306 Acc: 0.7404 | Val Loss: 0.5332 Acc: 0.7271\n",
      "Epoch 007 | Train Loss: 0.5076 Acc: 0.7554 | Val Loss: 0.5191 Acc: 0.7349\n",
      "Epoch 008 | Train Loss: 0.4819 Acc: 0.7685 | Val Loss: 0.4942 Acc: 0.7669\n",
      "Epoch 009 | Train Loss: 0.4577 Acc: 0.7820 | Val Loss: 0.4461 Acc: 0.7784\n",
      "Epoch 010 | Train Loss: 0.4304 Acc: 0.8016 | Val Loss: 0.4583 Acc: 0.7886\n",
      "Epoch 011 | Train Loss: 0.4042 Acc: 0.8191 | Val Loss: 0.3979 Acc: 0.8092\n",
      "Epoch 012 | Train Loss: 0.3645 Acc: 0.8422 | Val Loss: 0.3749 Acc: 0.8219\n",
      "Epoch 013 | Train Loss: 0.3490 Acc: 0.8475 | Val Loss: 0.3493 Acc: 0.8430\n",
      "Epoch 014 | Train Loss: 0.3313 Acc: 0.8576 | Val Loss: 0.3094 Acc: 0.8671\n",
      "Epoch 015 | Train Loss: 0.2953 Acc: 0.8800 | Val Loss: 0.2974 Acc: 0.8702\n",
      "Epoch 016 | Train Loss: 0.2753 Acc: 0.8860 | Val Loss: 0.2567 Acc: 0.8853\n",
      "Epoch 017 | Train Loss: 0.2547 Acc: 0.8901 | Val Loss: 0.2401 Acc: 0.9028\n",
      "Epoch 018 | Train Loss: 0.2406 Acc: 0.9047 | Val Loss: 0.3224 Acc: 0.8635\n",
      "Epoch 019 | Train Loss: 0.2207 Acc: 0.9106 | Val Loss: 0.2305 Acc: 0.9070\n",
      "Epoch 020 | Train Loss: 0.2214 Acc: 0.9088 | Val Loss: 0.2322 Acc: 0.9082\n",
      "Epoch 021 | Train Loss: 0.1887 Acc: 0.9239 | Val Loss: 0.2131 Acc: 0.9118\n",
      "Epoch 022 | Train Loss: 0.1928 Acc: 0.9257 | Val Loss: 0.2451 Acc: 0.8967\n",
      "Epoch 023 | Train Loss: 0.1797 Acc: 0.9319 | Val Loss: 0.2021 Acc: 0.9173\n",
      "Epoch 024 | Train Loss: 0.1601 Acc: 0.9381 | Val Loss: 0.2111 Acc: 0.9179\n",
      "Epoch 025 | Train Loss: 0.1623 Acc: 0.9367 | Val Loss: 0.2267 Acc: 0.9058\n",
      "Epoch 026 | Train Loss: 0.1498 Acc: 0.9378 | Val Loss: 0.1749 Acc: 0.9293\n",
      "Epoch 027 | Train Loss: 0.1353 Acc: 0.9470 | Val Loss: 0.1773 Acc: 0.9245\n",
      "Epoch 028 | Train Loss: 0.1343 Acc: 0.9503 | Val Loss: 0.1940 Acc: 0.9324\n",
      "Epoch 029 | Train Loss: 0.1424 Acc: 0.9434 | Val Loss: 0.1822 Acc: 0.9269\n",
      "Epoch 030 | Train Loss: 0.1213 Acc: 0.9558 | Val Loss: 0.2041 Acc: 0.9239\n",
      "Epoch 031 | Train Loss: 0.1217 Acc: 0.9565 | Val Loss: 0.1756 Acc: 0.9330\n",
      "Epoch 032 | Train Loss: 0.1117 Acc: 0.9564 | Val Loss: 0.1984 Acc: 0.9161\n",
      "Epoch 033 | Train Loss: 0.1157 Acc: 0.9571 | Val Loss: 0.2413 Acc: 0.9058\n",
      "Epoch 034 | Train Loss: 0.0979 Acc: 0.9618 | Val Loss: 0.1854 Acc: 0.9293\n",
      "Epoch 035 | Train Loss: 0.1207 Acc: 0.9541 | Val Loss: 0.1857 Acc: 0.9318\n",
      "Epoch 036 | Train Loss: 0.1008 Acc: 0.9656 | Val Loss: 0.2001 Acc: 0.9306\n",
      "Early stopping triggered.\n",
      "Epoch 001 | Train Loss: 0.6865 Acc: 0.5641 | Val Loss: 0.6793 Acc: 0.5833\n",
      "Epoch 002 | Train Loss: 0.6758 Acc: 0.5883 | Val Loss: 0.6796 Acc: 0.5773\n",
      "Epoch 003 | Train Loss: 0.6746 Acc: 0.5914 | Val Loss: 0.6742 Acc: 0.5930\n",
      "Epoch 004 | Train Loss: 0.6713 Acc: 0.5958 | Val Loss: 0.6721 Acc: 0.5857\n",
      "Epoch 005 | Train Loss: 0.6643 Acc: 0.6058 | Val Loss: 0.6669 Acc: 0.5960\n",
      "Epoch 006 | Train Loss: 0.6618 Acc: 0.6091 | Val Loss: 0.6590 Acc: 0.6063\n",
      "Epoch 007 | Train Loss: 0.6517 Acc: 0.6222 | Val Loss: 0.6486 Acc: 0.6147\n",
      "Epoch 008 | Train Loss: 0.6357 Acc: 0.6429 | Val Loss: 0.6397 Acc: 0.6232\n",
      "Epoch 009 | Train Loss: 0.6254 Acc: 0.6621 | Val Loss: 0.6090 Acc: 0.6944\n",
      "Epoch 010 | Train Loss: 0.6007 Acc: 0.6840 | Val Loss: 0.6291 Acc: 0.6431\n",
      "Epoch 011 | Train Loss: 0.6055 Acc: 0.6819 | Val Loss: 0.5915 Acc: 0.6999\n",
      "Epoch 012 | Train Loss: 0.5812 Acc: 0.7063 | Val Loss: 0.5838 Acc: 0.7041\n",
      "Epoch 013 | Train Loss: 0.5796 Acc: 0.7080 | Val Loss: 0.5902 Acc: 0.6981\n",
      "Epoch 014 | Train Loss: 0.5707 Acc: 0.7146 | Val Loss: 0.5725 Acc: 0.7059\n",
      "Epoch 015 | Train Loss: 0.5673 Acc: 0.7151 | Val Loss: 0.5660 Acc: 0.7114\n",
      "Epoch 016 | Train Loss: 0.5597 Acc: 0.7189 | Val Loss: 0.5671 Acc: 0.7120\n",
      "Epoch 017 | Train Loss: 0.5564 Acc: 0.7258 | Val Loss: 0.5657 Acc: 0.7162\n",
      "Epoch 018 | Train Loss: 0.5490 Acc: 0.7278 | Val Loss: 0.5632 Acc: 0.7210\n",
      "Epoch 019 | Train Loss: 0.5456 Acc: 0.7288 | Val Loss: 0.5505 Acc: 0.7222\n",
      "Epoch 020 | Train Loss: 0.5401 Acc: 0.7321 | Val Loss: 0.5456 Acc: 0.7240\n",
      "Epoch 021 | Train Loss: 0.5428 Acc: 0.7323 | Val Loss: 0.5441 Acc: 0.7240\n",
      "Epoch 022 | Train Loss: 0.5311 Acc: 0.7424 | Val Loss: 0.5384 Acc: 0.7301\n",
      "Epoch 023 | Train Loss: 0.5298 Acc: 0.7404 | Val Loss: 0.5417 Acc: 0.7168\n",
      "Epoch 024 | Train Loss: 0.5275 Acc: 0.7408 | Val Loss: 0.5326 Acc: 0.7283\n",
      "Epoch 025 | Train Loss: 0.5211 Acc: 0.7456 | Val Loss: 0.5342 Acc: 0.7355\n",
      "Epoch 026 | Train Loss: 0.5163 Acc: 0.7465 | Val Loss: 0.5290 Acc: 0.7385\n",
      "Epoch 027 | Train Loss: 0.5128 Acc: 0.7486 | Val Loss: 0.5209 Acc: 0.7295\n",
      "Epoch 028 | Train Loss: 0.5119 Acc: 0.7501 | Val Loss: 0.5227 Acc: 0.7421\n",
      "Epoch 029 | Train Loss: 0.5047 Acc: 0.7543 | Val Loss: 0.5154 Acc: 0.7482\n",
      "Epoch 030 | Train Loss: 0.5042 Acc: 0.7587 | Val Loss: 0.5143 Acc: 0.7409\n",
      "Epoch 031 | Train Loss: 0.4986 Acc: 0.7593 | Val Loss: 0.5045 Acc: 0.7434\n",
      "Epoch 032 | Train Loss: 0.4905 Acc: 0.7646 | Val Loss: 0.5007 Acc: 0.7579\n",
      "Epoch 033 | Train Loss: 0.4879 Acc: 0.7651 | Val Loss: 0.4998 Acc: 0.7621\n",
      "Epoch 034 | Train Loss: 0.4865 Acc: 0.7654 | Val Loss: 0.4901 Acc: 0.7645\n",
      "Epoch 035 | Train Loss: 0.4778 Acc: 0.7762 | Val Loss: 0.4865 Acc: 0.7736\n",
      "Epoch 036 | Train Loss: 0.4693 Acc: 0.7799 | Val Loss: 0.4836 Acc: 0.7675\n",
      "Epoch 037 | Train Loss: 0.4627 Acc: 0.7839 | Val Loss: 0.4785 Acc: 0.7784\n",
      "Epoch 038 | Train Loss: 0.4687 Acc: 0.7800 | Val Loss: 0.4755 Acc: 0.7814\n",
      "Epoch 039 | Train Loss: 0.4644 Acc: 0.7848 | Val Loss: 0.4758 Acc: 0.7760\n",
      "Epoch 040 | Train Loss: 0.4517 Acc: 0.7906 | Val Loss: 0.4632 Acc: 0.7893\n",
      "Epoch 041 | Train Loss: 0.4547 Acc: 0.7874 | Val Loss: 0.4623 Acc: 0.7844\n",
      "Epoch 042 | Train Loss: 0.4483 Acc: 0.7868 | Val Loss: 0.4518 Acc: 0.7977\n",
      "Epoch 043 | Train Loss: 0.4353 Acc: 0.8018 | Val Loss: 0.4507 Acc: 0.7899\n",
      "Epoch 044 | Train Loss: 0.4371 Acc: 0.8008 | Val Loss: 0.4561 Acc: 0.7874\n",
      "Epoch 045 | Train Loss: 0.4428 Acc: 0.7873 | Val Loss: 0.4403 Acc: 0.7947\n",
      "Epoch 046 | Train Loss: 0.4307 Acc: 0.8048 | Val Loss: 0.4396 Acc: 0.7935\n",
      "Epoch 047 | Train Loss: 0.4251 Acc: 0.8081 | Val Loss: 0.4774 Acc: 0.7736\n",
      "Epoch 048 | Train Loss: 0.4310 Acc: 0.8008 | Val Loss: 0.4332 Acc: 0.8074\n",
      "Epoch 049 | Train Loss: 0.4133 Acc: 0.8149 | Val Loss: 0.4263 Acc: 0.8068\n",
      "Epoch 050 | Train Loss: 0.4166 Acc: 0.8129 | Val Loss: 0.4167 Acc: 0.8062\n",
      "Epoch 051 | Train Loss: 0.4126 Acc: 0.8132 | Val Loss: 0.4200 Acc: 0.8146\n",
      "Epoch 052 | Train Loss: 0.4080 Acc: 0.8143 | Val Loss: 0.4118 Acc: 0.8098\n",
      "Epoch 053 | Train Loss: 0.4046 Acc: 0.8194 | Val Loss: 0.4124 Acc: 0.8122\n",
      "Epoch 054 | Train Loss: 0.4000 Acc: 0.8197 | Val Loss: 0.4028 Acc: 0.8188\n",
      "Epoch 055 | Train Loss: 0.3971 Acc: 0.8155 | Val Loss: 0.4026 Acc: 0.8200\n",
      "Epoch 056 | Train Loss: 0.3907 Acc: 0.8205 | Val Loss: 0.3913 Acc: 0.8219\n",
      "Epoch 057 | Train Loss: 0.3881 Acc: 0.8261 | Val Loss: 0.3975 Acc: 0.8237\n",
      "Epoch 058 | Train Loss: 0.3860 Acc: 0.8239 | Val Loss: 0.4083 Acc: 0.8140\n",
      "Epoch 059 | Train Loss: 0.3822 Acc: 0.8267 | Val Loss: 0.3863 Acc: 0.8237\n",
      "Epoch 060 | Train Loss: 0.3678 Acc: 0.8378 | Val Loss: 0.3772 Acc: 0.8267\n",
      "Epoch 001 | Train Loss: 0.6801 Acc: 0.5750 | Val Loss: 0.6754 Acc: 0.5894\n",
      "Epoch 002 | Train Loss: 0.6668 Acc: 0.5996 | Val Loss: 0.6432 Acc: 0.6202\n",
      "Epoch 003 | Train Loss: 0.6094 Acc: 0.6796 | Val Loss: 0.5722 Acc: 0.7071\n",
      "Epoch 004 | Train Loss: 0.5628 Acc: 0.7211 | Val Loss: 0.5943 Acc: 0.6914\n",
      "Epoch 005 | Train Loss: 0.5356 Acc: 0.7389 | Val Loss: 0.5274 Acc: 0.7367\n",
      "Epoch 006 | Train Loss: 0.5100 Acc: 0.7524 | Val Loss: 0.5242 Acc: 0.7325\n",
      "Epoch 007 | Train Loss: 0.4793 Acc: 0.7728 | Val Loss: 0.4985 Acc: 0.7554\n",
      "Epoch 008 | Train Loss: 0.4697 Acc: 0.7809 | Val Loss: 0.5181 Acc: 0.7428\n",
      "Epoch 009 | Train Loss: 0.4458 Acc: 0.7990 | Val Loss: 0.4297 Acc: 0.7989\n",
      "Epoch 010 | Train Loss: 0.4156 Acc: 0.8134 | Val Loss: 0.4418 Acc: 0.7917\n",
      "Epoch 011 | Train Loss: 0.3920 Acc: 0.8252 | Val Loss: 0.3778 Acc: 0.8140\n",
      "Epoch 012 | Train Loss: 0.3588 Acc: 0.8449 | Val Loss: 0.3539 Acc: 0.8418\n",
      "Epoch 013 | Train Loss: 0.3406 Acc: 0.8554 | Val Loss: 0.3158 Acc: 0.8641\n",
      "Epoch 014 | Train Loss: 0.3223 Acc: 0.8671 | Val Loss: 0.3686 Acc: 0.8442\n",
      "Epoch 015 | Train Loss: 0.3043 Acc: 0.8705 | Val Loss: 0.3014 Acc: 0.8708\n",
      "Epoch 016 | Train Loss: 0.2886 Acc: 0.8794 | Val Loss: 0.2574 Acc: 0.8931\n",
      "Epoch 017 | Train Loss: 0.2696 Acc: 0.8886 | Val Loss: 0.2622 Acc: 0.8925\n",
      "Epoch 018 | Train Loss: 0.2579 Acc: 0.8928 | Val Loss: 0.2381 Acc: 0.9040\n",
      "Epoch 019 | Train Loss: 0.2328 Acc: 0.9076 | Val Loss: 0.2743 Acc: 0.8804\n",
      "Epoch 020 | Train Loss: 0.2375 Acc: 0.9056 | Val Loss: 0.2423 Acc: 0.8998\n",
      "Epoch 021 | Train Loss: 0.2165 Acc: 0.9123 | Val Loss: 0.2178 Acc: 0.9070\n",
      "Epoch 022 | Train Loss: 0.2012 Acc: 0.9171 | Val Loss: 0.2199 Acc: 0.9112\n",
      "Epoch 023 | Train Loss: 0.1891 Acc: 0.9259 | Val Loss: 0.2183 Acc: 0.9070\n",
      "Epoch 024 | Train Loss: 0.1888 Acc: 0.9257 | Val Loss: 0.2160 Acc: 0.9118\n",
      "Epoch 025 | Train Loss: 0.1788 Acc: 0.9298 | Val Loss: 0.1926 Acc: 0.9245\n",
      "Epoch 026 | Train Loss: 0.1640 Acc: 0.9354 | Val Loss: 0.1992 Acc: 0.9197\n",
      "Epoch 027 | Train Loss: 0.1542 Acc: 0.9416 | Val Loss: 0.2105 Acc: 0.9179\n",
      "Epoch 028 | Train Loss: 0.1490 Acc: 0.9417 | Val Loss: 0.2011 Acc: 0.9239\n",
      "Epoch 029 | Train Loss: 0.1386 Acc: 0.9491 | Val Loss: 0.1738 Acc: 0.9318\n",
      "Epoch 030 | Train Loss: 0.1451 Acc: 0.9453 | Val Loss: 0.1885 Acc: 0.9251\n",
      "Epoch 031 | Train Loss: 0.1311 Acc: 0.9508 | Val Loss: 0.1762 Acc: 0.9330\n",
      "Epoch 032 | Train Loss: 0.1201 Acc: 0.9520 | Val Loss: 0.2984 Acc: 0.9034\n",
      "Epoch 033 | Train Loss: 0.1310 Acc: 0.9503 | Val Loss: 0.1673 Acc: 0.9324\n",
      "Epoch 034 | Train Loss: 0.1173 Acc: 0.9538 | Val Loss: 0.1752 Acc: 0.9318\n",
      "Epoch 035 | Train Loss: 0.1243 Acc: 0.9521 | Val Loss: 0.1690 Acc: 0.9366\n",
      "Epoch 036 | Train Loss: 0.1034 Acc: 0.9615 | Val Loss: 0.1645 Acc: 0.9384\n",
      "Epoch 037 | Train Loss: 0.1048 Acc: 0.9610 | Val Loss: 0.1700 Acc: 0.9360\n",
      "Epoch 038 | Train Loss: 0.1003 Acc: 0.9600 | Val Loss: 0.1532 Acc: 0.9432\n",
      "Epoch 039 | Train Loss: 0.1010 Acc: 0.9606 | Val Loss: 0.1642 Acc: 0.9408\n",
      "Epoch 040 | Train Loss: 0.0968 Acc: 0.9629 | Val Loss: 0.1849 Acc: 0.9378\n",
      "Epoch 041 | Train Loss: 0.0965 Acc: 0.9630 | Val Loss: 0.1651 Acc: 0.9402\n",
      "Epoch 042 | Train Loss: 0.0882 Acc: 0.9668 | Val Loss: 0.1829 Acc: 0.9396\n",
      "Epoch 043 | Train Loss: 0.0881 Acc: 0.9678 | Val Loss: 0.1603 Acc: 0.9402\n",
      "Epoch 044 | Train Loss: 0.0823 Acc: 0.9687 | Val Loss: 0.1646 Acc: 0.9444\n",
      "Epoch 045 | Train Loss: 0.0862 Acc: 0.9690 | Val Loss: 0.2029 Acc: 0.9384\n",
      "Epoch 046 | Train Loss: 0.0827 Acc: 0.9689 | Val Loss: 0.1461 Acc: 0.9517\n",
      "Epoch 047 | Train Loss: 0.0937 Acc: 0.9654 | Val Loss: 0.1627 Acc: 0.9420\n",
      "Epoch 048 | Train Loss: 0.0842 Acc: 0.9690 | Val Loss: 0.1568 Acc: 0.9450\n",
      "Epoch 049 | Train Loss: 0.0735 Acc: 0.9743 | Val Loss: 0.1605 Acc: 0.9402\n",
      "Epoch 050 | Train Loss: 0.0758 Acc: 0.9730 | Val Loss: 0.1600 Acc: 0.9475\n",
      "Epoch 051 | Train Loss: 0.0749 Acc: 0.9742 | Val Loss: 0.1639 Acc: 0.9354\n",
      "Epoch 052 | Train Loss: 0.0789 Acc: 0.9721 | Val Loss: 0.1727 Acc: 0.9481\n",
      "Epoch 053 | Train Loss: 0.0841 Acc: 0.9681 | Val Loss: 0.1233 Acc: 0.9535\n",
      "Epoch 054 | Train Loss: 0.0646 Acc: 0.9763 | Val Loss: 0.1694 Acc: 0.9475\n",
      "Epoch 055 | Train Loss: 0.0670 Acc: 0.9749 | Val Loss: 0.1428 Acc: 0.9481\n",
      "Epoch 056 | Train Loss: 0.0653 Acc: 0.9781 | Val Loss: 0.1286 Acc: 0.9523\n",
      "Epoch 057 | Train Loss: 0.0659 Acc: 0.9772 | Val Loss: 0.1637 Acc: 0.9457\n",
      "Epoch 058 | Train Loss: 0.0706 Acc: 0.9728 | Val Loss: 0.1757 Acc: 0.9414\n",
      "Epoch 059 | Train Loss: 0.0602 Acc: 0.9770 | Val Loss: 0.1644 Acc: 0.9487\n",
      "Epoch 060 | Train Loss: 0.0618 Acc: 0.9796 | Val Loss: 0.2071 Acc: 0.9378\n",
      "Epoch 001 | Train Loss: 0.6895 Acc: 0.5340 | Val Loss: 0.6830 Acc: 0.5707\n",
      "Epoch 002 | Train Loss: 0.6802 Acc: 0.5854 | Val Loss: 0.6793 Acc: 0.5803\n",
      "Epoch 003 | Train Loss: 0.6772 Acc: 0.5872 | Val Loss: 0.6755 Acc: 0.5912\n",
      "Epoch 004 | Train Loss: 0.6723 Acc: 0.5979 | Val Loss: 0.6762 Acc: 0.5857\n",
      "Epoch 005 | Train Loss: 0.6687 Acc: 0.6018 | Val Loss: 0.6686 Acc: 0.5906\n",
      "Epoch 006 | Train Loss: 0.6627 Acc: 0.6085 | Val Loss: 0.6659 Acc: 0.5936\n",
      "Epoch 007 | Train Loss: 0.6581 Acc: 0.6091 | Val Loss: 0.6629 Acc: 0.5936\n",
      "Epoch 008 | Train Loss: 0.6507 Acc: 0.6186 | Val Loss: 0.6571 Acc: 0.6021\n",
      "Epoch 009 | Train Loss: 0.6311 Acc: 0.6553 | Val Loss: 0.6089 Acc: 0.6763\n",
      "Epoch 010 | Train Loss: 0.6133 Acc: 0.6770 | Val Loss: 0.6103 Acc: 0.6751\n",
      "Epoch 011 | Train Loss: 0.6111 Acc: 0.6778 | Val Loss: 0.6100 Acc: 0.6757\n",
      "Epoch 012 | Train Loss: 0.6012 Acc: 0.6924 | Val Loss: 0.5927 Acc: 0.7011\n",
      "Epoch 013 | Train Loss: 0.5974 Acc: 0.6955 | Val Loss: 0.5956 Acc: 0.6842\n",
      "Epoch 014 | Train Loss: 0.6007 Acc: 0.6924 | Val Loss: 0.5872 Acc: 0.6987\n",
      "Epoch 015 | Train Loss: 0.5888 Acc: 0.7047 | Val Loss: 0.5849 Acc: 0.7053\n",
      "Epoch 016 | Train Loss: 0.5846 Acc: 0.7089 | Val Loss: 0.5809 Acc: 0.7101\n",
      "Epoch 017 | Train Loss: 0.5777 Acc: 0.7121 | Val Loss: 0.5777 Acc: 0.7047\n",
      "Epoch 018 | Train Loss: 0.5807 Acc: 0.7086 | Val Loss: 0.5979 Acc: 0.6878\n",
      "Epoch 019 | Train Loss: 0.5761 Acc: 0.7098 | Val Loss: 0.5821 Acc: 0.7071\n",
      "Epoch 020 | Train Loss: 0.5694 Acc: 0.7207 | Val Loss: 0.5728 Acc: 0.7120\n",
      "Epoch 021 | Train Loss: 0.5648 Acc: 0.7219 | Val Loss: 0.5718 Acc: 0.7156\n",
      "Epoch 022 | Train Loss: 0.5682 Acc: 0.7178 | Val Loss: 0.5689 Acc: 0.7144\n",
      "Epoch 023 | Train Loss: 0.5566 Acc: 0.7240 | Val Loss: 0.5649 Acc: 0.7162\n",
      "Epoch 024 | Train Loss: 0.5626 Acc: 0.7228 | Val Loss: 0.5645 Acc: 0.7144\n",
      "Epoch 025 | Train Loss: 0.5513 Acc: 0.7290 | Val Loss: 0.5607 Acc: 0.7180\n",
      "Epoch 026 | Train Loss: 0.5473 Acc: 0.7358 | Val Loss: 0.5568 Acc: 0.7174\n",
      "Epoch 027 | Train Loss: 0.5402 Acc: 0.7380 | Val Loss: 0.5526 Acc: 0.7192\n",
      "Epoch 028 | Train Loss: 0.5473 Acc: 0.7335 | Val Loss: 0.5526 Acc: 0.7210\n",
      "Epoch 029 | Train Loss: 0.5387 Acc: 0.7424 | Val Loss: 0.5522 Acc: 0.7222\n",
      "Epoch 030 | Train Loss: 0.5329 Acc: 0.7421 | Val Loss: 0.5506 Acc: 0.7174\n",
      "Epoch 031 | Train Loss: 0.5390 Acc: 0.7338 | Val Loss: 0.5428 Acc: 0.7240\n",
      "Epoch 032 | Train Loss: 0.5315 Acc: 0.7423 | Val Loss: 0.5451 Acc: 0.7252\n",
      "Epoch 033 | Train Loss: 0.5324 Acc: 0.7423 | Val Loss: 0.5584 Acc: 0.7156\n",
      "Epoch 034 | Train Loss: 0.5237 Acc: 0.7504 | Val Loss: 0.5414 Acc: 0.7283\n",
      "Epoch 035 | Train Loss: 0.5219 Acc: 0.7451 | Val Loss: 0.5361 Acc: 0.7264\n",
      "Epoch 036 | Train Loss: 0.5182 Acc: 0.7492 | Val Loss: 0.5368 Acc: 0.7240\n",
      "Epoch 037 | Train Loss: 0.5187 Acc: 0.7503 | Val Loss: 0.5310 Acc: 0.7337\n",
      "Epoch 038 | Train Loss: 0.5100 Acc: 0.7546 | Val Loss: 0.5255 Acc: 0.7331\n",
      "Epoch 039 | Train Loss: 0.5066 Acc: 0.7589 | Val Loss: 0.5459 Acc: 0.7301\n",
      "Epoch 040 | Train Loss: 0.5090 Acc: 0.7568 | Val Loss: 0.5246 Acc: 0.7367\n",
      "Epoch 041 | Train Loss: 0.5015 Acc: 0.7583 | Val Loss: 0.5436 Acc: 0.7240\n",
      "Epoch 042 | Train Loss: 0.5097 Acc: 0.7551 | Val Loss: 0.5197 Acc: 0.7379\n",
      "Epoch 043 | Train Loss: 0.4975 Acc: 0.7617 | Val Loss: 0.5176 Acc: 0.7373\n",
      "Epoch 044 | Train Loss: 0.4923 Acc: 0.7631 | Val Loss: 0.5104 Acc: 0.7464\n",
      "Epoch 045 | Train Loss: 0.4920 Acc: 0.7640 | Val Loss: 0.5073 Acc: 0.7452\n",
      "Epoch 046 | Train Loss: 0.4876 Acc: 0.7705 | Val Loss: 0.5073 Acc: 0.7494\n",
      "Epoch 047 | Train Loss: 0.4834 Acc: 0.7681 | Val Loss: 0.5055 Acc: 0.7476\n",
      "Epoch 048 | Train Loss: 0.4806 Acc: 0.7716 | Val Loss: 0.5065 Acc: 0.7476\n",
      "Epoch 049 | Train Loss: 0.4805 Acc: 0.7749 | Val Loss: 0.4952 Acc: 0.7512\n",
      "Epoch 050 | Train Loss: 0.4768 Acc: 0.7743 | Val Loss: 0.4932 Acc: 0.7542\n",
      "Epoch 051 | Train Loss: 0.4676 Acc: 0.7817 | Val Loss: 0.4920 Acc: 0.7554\n",
      "Epoch 052 | Train Loss: 0.4673 Acc: 0.7752 | Val Loss: 0.4971 Acc: 0.7548\n",
      "Epoch 053 | Train Loss: 0.4651 Acc: 0.7812 | Val Loss: 0.4935 Acc: 0.7494\n",
      "Epoch 054 | Train Loss: 0.4589 Acc: 0.7844 | Val Loss: 0.4755 Acc: 0.7711\n",
      "Epoch 055 | Train Loss: 0.4552 Acc: 0.7859 | Val Loss: 0.4738 Acc: 0.7651\n",
      "Epoch 056 | Train Loss: 0.4539 Acc: 0.7874 | Val Loss: 0.4745 Acc: 0.7651\n",
      "Epoch 057 | Train Loss: 0.4549 Acc: 0.7868 | Val Loss: 0.4990 Acc: 0.7524\n",
      "Epoch 058 | Train Loss: 0.4496 Acc: 0.7892 | Val Loss: 0.4785 Acc: 0.7609\n",
      "Epoch 059 | Train Loss: 0.4434 Acc: 0.7948 | Val Loss: 0.4581 Acc: 0.7808\n",
      "Epoch 060 | Train Loss: 0.4461 Acc: 0.7885 | Val Loss: 0.4799 Acc: 0.7621\n",
      "Epoch 001 | Train Loss: 0.6820 Acc: 0.5710 | Val Loss: 0.6735 Acc: 0.5797\n",
      "Epoch 002 | Train Loss: 0.6675 Acc: 0.5923 | Val Loss: 0.6566 Acc: 0.6178\n",
      "Epoch 003 | Train Loss: 0.6298 Acc: 0.6585 | Val Loss: 0.5913 Acc: 0.6957\n",
      "Epoch 004 | Train Loss: 0.5721 Acc: 0.7142 | Val Loss: 0.5645 Acc: 0.7083\n",
      "Epoch 005 | Train Loss: 0.5480 Acc: 0.7272 | Val Loss: 0.5698 Acc: 0.6999\n",
      "Epoch 006 | Train Loss: 0.5215 Acc: 0.7433 | Val Loss: 0.5181 Acc: 0.7252\n",
      "Epoch 007 | Train Loss: 0.5064 Acc: 0.7545 | Val Loss: 0.5039 Acc: 0.7452\n",
      "Epoch 008 | Train Loss: 0.4681 Acc: 0.7788 | Val Loss: 0.4646 Acc: 0.7669\n",
      "Epoch 009 | Train Loss: 0.4426 Acc: 0.7975 | Val Loss: 0.4446 Acc: 0.7868\n",
      "Epoch 010 | Train Loss: 0.4225 Acc: 0.8040 | Val Loss: 0.4282 Acc: 0.8001\n",
      "Epoch 011 | Train Loss: 0.4085 Acc: 0.8146 | Val Loss: 0.4216 Acc: 0.7989\n",
      "Epoch 012 | Train Loss: 0.3834 Acc: 0.8276 | Val Loss: 0.3967 Acc: 0.8164\n",
      "Epoch 013 | Train Loss: 0.3586 Acc: 0.8436 | Val Loss: 0.3519 Acc: 0.8430\n",
      "Epoch 014 | Train Loss: 0.3479 Acc: 0.8470 | Val Loss: 0.3404 Acc: 0.8472\n",
      "Epoch 015 | Train Loss: 0.3195 Acc: 0.8661 | Val Loss: 0.3192 Acc: 0.8617\n",
      "Epoch 016 | Train Loss: 0.2961 Acc: 0.8785 | Val Loss: 0.3252 Acc: 0.8575\n",
      "Epoch 017 | Train Loss: 0.2882 Acc: 0.8771 | Val Loss: 0.2940 Acc: 0.8792\n",
      "Epoch 018 | Train Loss: 0.2742 Acc: 0.8857 | Val Loss: 0.3069 Acc: 0.8653\n",
      "Epoch 019 | Train Loss: 0.2664 Acc: 0.8866 | Val Loss: 0.2984 Acc: 0.8750\n",
      "Epoch 020 | Train Loss: 0.2508 Acc: 0.8966 | Val Loss: 0.2541 Acc: 0.8877\n",
      "Epoch 021 | Train Loss: 0.2201 Acc: 0.9115 | Val Loss: 0.2884 Acc: 0.8804\n",
      "Epoch 022 | Train Loss: 0.2045 Acc: 0.9167 | Val Loss: 0.2578 Acc: 0.8913\n",
      "Epoch 023 | Train Loss: 0.2079 Acc: 0.9153 | Val Loss: 0.2439 Acc: 0.8919\n",
      "Epoch 024 | Train Loss: 0.1890 Acc: 0.9218 | Val Loss: 0.2231 Acc: 0.9088\n",
      "Epoch 025 | Train Loss: 0.1711 Acc: 0.9333 | Val Loss: 0.2034 Acc: 0.9209\n",
      "Epoch 026 | Train Loss: 0.1720 Acc: 0.9304 | Val Loss: 0.2159 Acc: 0.9136\n",
      "Epoch 027 | Train Loss: 0.1537 Acc: 0.9405 | Val Loss: 0.2254 Acc: 0.9082\n",
      "Epoch 028 | Train Loss: 0.1431 Acc: 0.9455 | Val Loss: 0.2294 Acc: 0.9124\n",
      "Epoch 029 | Train Loss: 0.1367 Acc: 0.9476 | Val Loss: 0.1987 Acc: 0.9161\n",
      "Epoch 030 | Train Loss: 0.1343 Acc: 0.9496 | Val Loss: 0.2156 Acc: 0.9179\n",
      "Epoch 031 | Train Loss: 0.1280 Acc: 0.9511 | Val Loss: 0.2086 Acc: 0.9215\n",
      "Epoch 032 | Train Loss: 0.1165 Acc: 0.9555 | Val Loss: 0.2119 Acc: 0.9173\n",
      "Epoch 033 | Train Loss: 0.1171 Acc: 0.9559 | Val Loss: 0.1874 Acc: 0.9336\n",
      "Epoch 034 | Train Loss: 0.1073 Acc: 0.9597 | Val Loss: 0.1854 Acc: 0.9312\n",
      "Epoch 035 | Train Loss: 0.1076 Acc: 0.9595 | Val Loss: 0.1936 Acc: 0.9251\n",
      "Epoch 036 | Train Loss: 0.0972 Acc: 0.9650 | Val Loss: 0.2140 Acc: 0.9191\n",
      "Epoch 037 | Train Loss: 0.0850 Acc: 0.9665 | Val Loss: 0.1982 Acc: 0.9257\n",
      "Epoch 038 | Train Loss: 0.0935 Acc: 0.9683 | Val Loss: 0.1859 Acc: 0.9275\n",
      "Epoch 039 | Train Loss: 0.0794 Acc: 0.9712 | Val Loss: 0.2173 Acc: 0.9300\n",
      "Epoch 040 | Train Loss: 0.0876 Acc: 0.9662 | Val Loss: 0.1603 Acc: 0.9432\n",
      "Epoch 041 | Train Loss: 0.0867 Acc: 0.9675 | Val Loss: 0.1689 Acc: 0.9396\n",
      "Epoch 042 | Train Loss: 0.0789 Acc: 0.9713 | Val Loss: 0.1808 Acc: 0.9300\n",
      "Epoch 043 | Train Loss: 0.0768 Acc: 0.9722 | Val Loss: 0.2080 Acc: 0.9312\n",
      "Epoch 044 | Train Loss: 0.0703 Acc: 0.9746 | Val Loss: 0.1799 Acc: 0.9438\n",
      "Epoch 045 | Train Loss: 0.0701 Acc: 0.9743 | Val Loss: 0.1724 Acc: 0.9420\n",
      "Epoch 046 | Train Loss: 0.0754 Acc: 0.9731 | Val Loss: 0.1736 Acc: 0.9384\n",
      "Epoch 047 | Train Loss: 0.0637 Acc: 0.9763 | Val Loss: 0.1560 Acc: 0.9450\n",
      "Epoch 048 | Train Loss: 0.0639 Acc: 0.9786 | Val Loss: 0.1760 Acc: 0.9444\n",
      "Epoch 049 | Train Loss: 0.0586 Acc: 0.9778 | Val Loss: 0.1994 Acc: 0.9360\n",
      "Epoch 050 | Train Loss: 0.0681 Acc: 0.9761 | Val Loss: 0.1732 Acc: 0.9408\n",
      "Epoch 051 | Train Loss: 0.0608 Acc: 0.9778 | Val Loss: 0.1748 Acc: 0.9426\n",
      "Epoch 052 | Train Loss: 0.0588 Acc: 0.9787 | Val Loss: 0.1674 Acc: 0.9420\n",
      "Epoch 053 | Train Loss: 0.0554 Acc: 0.9823 | Val Loss: 0.1847 Acc: 0.9390\n",
      "Epoch 054 | Train Loss: 0.0542 Acc: 0.9814 | Val Loss: 0.1734 Acc: 0.9438\n",
      "Epoch 055 | Train Loss: 0.0543 Acc: 0.9795 | Val Loss: 0.1519 Acc: 0.9450\n",
      "Epoch 056 | Train Loss: 0.0521 Acc: 0.9808 | Val Loss: 0.1588 Acc: 0.9481\n",
      "Epoch 057 | Train Loss: 0.0493 Acc: 0.9834 | Val Loss: 0.2941 Acc: 0.9094\n",
      "Epoch 058 | Train Loss: 0.0556 Acc: 0.9772 | Val Loss: 0.1837 Acc: 0.9408\n",
      "Epoch 059 | Train Loss: 0.0547 Acc: 0.9798 | Val Loss: 0.1636 Acc: 0.9469\n",
      "Epoch 060 | Train Loss: 0.0430 Acc: 0.9834 | Val Loss: 0.1753 Acc: 0.9426\n",
      "Epoch 001 | Train Loss: 0.6788 Acc: 0.5816 | Val Loss: 0.6762 Acc: 0.5924\n",
      "Epoch 002 | Train Loss: 0.6639 Acc: 0.6027 | Val Loss: 0.6549 Acc: 0.6129\n",
      "Epoch 003 | Train Loss: 0.6114 Acc: 0.6843 | Val Loss: 0.5808 Acc: 0.7071\n",
      "Epoch 004 | Train Loss: 0.5697 Acc: 0.7187 | Val Loss: 0.5566 Acc: 0.7120\n",
      "Epoch 005 | Train Loss: 0.5436 Acc: 0.7318 | Val Loss: 0.5421 Acc: 0.7216\n",
      "Epoch 006 | Train Loss: 0.5276 Acc: 0.7388 | Val Loss: 0.5138 Acc: 0.7494\n",
      "Epoch 007 | Train Loss: 0.4973 Acc: 0.7625 | Val Loss: 0.4837 Acc: 0.7675\n",
      "Epoch 008 | Train Loss: 0.4730 Acc: 0.7793 | Val Loss: 0.4751 Acc: 0.7760\n",
      "Epoch 009 | Train Loss: 0.4522 Acc: 0.7871 | Val Loss: 0.4711 Acc: 0.7778\n",
      "Epoch 010 | Train Loss: 0.4338 Acc: 0.7998 | Val Loss: 0.4153 Acc: 0.7965\n",
      "Epoch 011 | Train Loss: 0.4173 Acc: 0.8114 | Val Loss: 0.3875 Acc: 0.8164\n",
      "Epoch 012 | Train Loss: 0.3926 Acc: 0.8220 | Val Loss: 0.3954 Acc: 0.8037\n",
      "Epoch 013 | Train Loss: 0.3893 Acc: 0.8244 | Val Loss: 0.3604 Acc: 0.8357\n",
      "Epoch 014 | Train Loss: 0.3630 Acc: 0.8356 | Val Loss: 0.3477 Acc: 0.8412\n",
      "Epoch 015 | Train Loss: 0.3455 Acc: 0.8523 | Val Loss: 0.3228 Acc: 0.8545\n",
      "Epoch 016 | Train Loss: 0.3353 Acc: 0.8567 | Val Loss: 0.3201 Acc: 0.8599\n",
      "Epoch 017 | Train Loss: 0.3167 Acc: 0.8643 | Val Loss: 0.2892 Acc: 0.8810\n",
      "Epoch 018 | Train Loss: 0.2913 Acc: 0.8774 | Val Loss: 0.2759 Acc: 0.8829\n",
      "Epoch 019 | Train Loss: 0.2753 Acc: 0.8887 | Val Loss: 0.2736 Acc: 0.8907\n",
      "Epoch 020 | Train Loss: 0.2676 Acc: 0.8917 | Val Loss: 0.2577 Acc: 0.8895\n",
      "Epoch 021 | Train Loss: 0.2694 Acc: 0.8878 | Val Loss: 0.2438 Acc: 0.8998\n",
      "Epoch 022 | Train Loss: 0.2356 Acc: 0.9068 | Val Loss: 0.2463 Acc: 0.9058\n",
      "Epoch 023 | Train Loss: 0.2218 Acc: 0.9120 | Val Loss: 0.2304 Acc: 0.9064\n",
      "Epoch 024 | Train Loss: 0.2208 Acc: 0.9124 | Val Loss: 0.2364 Acc: 0.9094\n",
      "Epoch 025 | Train Loss: 0.2120 Acc: 0.9156 | Val Loss: 0.2350 Acc: 0.9052\n",
      "Epoch 026 | Train Loss: 0.2083 Acc: 0.9164 | Val Loss: 0.2010 Acc: 0.9143\n",
      "Epoch 027 | Train Loss: 0.1929 Acc: 0.9204 | Val Loss: 0.2195 Acc: 0.9124\n",
      "Epoch 028 | Train Loss: 0.1768 Acc: 0.9302 | Val Loss: 0.2217 Acc: 0.9112\n",
      "Epoch 029 | Train Loss: 0.1794 Acc: 0.9278 | Val Loss: 0.2023 Acc: 0.9197\n",
      "Epoch 030 | Train Loss: 0.1794 Acc: 0.9299 | Val Loss: 0.1888 Acc: 0.9215\n",
      "Epoch 031 | Train Loss: 0.1731 Acc: 0.9311 | Val Loss: 0.1926 Acc: 0.9269\n",
      "Epoch 032 | Train Loss: 0.1679 Acc: 0.9363 | Val Loss: 0.1926 Acc: 0.9306\n",
      "Epoch 033 | Train Loss: 0.1521 Acc: 0.9432 | Val Loss: 0.1845 Acc: 0.9300\n",
      "Epoch 034 | Train Loss: 0.1503 Acc: 0.9435 | Val Loss: 0.1799 Acc: 0.9342\n",
      "Epoch 035 | Train Loss: 0.1524 Acc: 0.9405 | Val Loss: 0.1559 Acc: 0.9414\n",
      "Epoch 036 | Train Loss: 0.1449 Acc: 0.9452 | Val Loss: 0.1966 Acc: 0.9233\n",
      "Epoch 037 | Train Loss: 0.1500 Acc: 0.9456 | Val Loss: 0.1686 Acc: 0.9396\n",
      "Epoch 038 | Train Loss: 0.1381 Acc: 0.9493 | Val Loss: 0.1655 Acc: 0.9390\n",
      "Epoch 039 | Train Loss: 0.1374 Acc: 0.9459 | Val Loss: 0.1717 Acc: 0.9287\n",
      "Epoch 040 | Train Loss: 0.1324 Acc: 0.9526 | Val Loss: 0.2034 Acc: 0.9239\n",
      "Epoch 041 | Train Loss: 0.1296 Acc: 0.9520 | Val Loss: 0.1822 Acc: 0.9360\n",
      "Epoch 042 | Train Loss: 0.1236 Acc: 0.9532 | Val Loss: 0.1654 Acc: 0.9390\n",
      "Epoch 043 | Train Loss: 0.1209 Acc: 0.9564 | Val Loss: 0.1762 Acc: 0.9354\n",
      "Epoch 044 | Train Loss: 0.1254 Acc: 0.9512 | Val Loss: 0.1672 Acc: 0.9438\n",
      "Epoch 045 | Train Loss: 0.1181 Acc: 0.9565 | Val Loss: 0.1791 Acc: 0.9330\n",
      "Early stopping triggered.\n",
      "Epoch 001 | Train Loss: 0.6800 Acc: 0.5760 | Val Loss: 0.6759 Acc: 0.5857\n",
      "Epoch 002 | Train Loss: 0.6593 Acc: 0.6175 | Val Loss: 0.6473 Acc: 0.6244\n",
      "Epoch 003 | Train Loss: 0.6130 Acc: 0.6764 | Val Loss: 0.6031 Acc: 0.6854\n",
      "Epoch 004 | Train Loss: 0.5665 Acc: 0.7158 | Val Loss: 0.5556 Acc: 0.7240\n",
      "Epoch 005 | Train Loss: 0.5300 Acc: 0.7411 | Val Loss: 0.5289 Acc: 0.7421\n",
      "Epoch 006 | Train Loss: 0.5014 Acc: 0.7619 | Val Loss: 0.5053 Acc: 0.7627\n",
      "Epoch 007 | Train Loss: 0.4719 Acc: 0.7791 | Val Loss: 0.4918 Acc: 0.7657\n",
      "Epoch 008 | Train Loss: 0.4345 Acc: 0.7963 | Val Loss: 0.4132 Acc: 0.8092\n",
      "Epoch 009 | Train Loss: 0.4135 Acc: 0.8169 | Val Loss: 0.3971 Acc: 0.8170\n",
      "Epoch 010 | Train Loss: 0.3794 Acc: 0.8357 | Val Loss: 0.3750 Acc: 0.8267\n",
      "Epoch 011 | Train Loss: 0.3527 Acc: 0.8481 | Val Loss: 0.3386 Acc: 0.8484\n",
      "Epoch 012 | Train Loss: 0.3210 Acc: 0.8656 | Val Loss: 0.3115 Acc: 0.8726\n",
      "Epoch 013 | Train Loss: 0.2956 Acc: 0.8804 | Val Loss: 0.3113 Acc: 0.8653\n",
      "Epoch 014 | Train Loss: 0.2919 Acc: 0.8800 | Val Loss: 0.3219 Acc: 0.8665\n",
      "Epoch 015 | Train Loss: 0.2694 Acc: 0.8910 | Val Loss: 0.3380 Acc: 0.8533\n",
      "Epoch 016 | Train Loss: 0.2506 Acc: 0.8991 | Val Loss: 0.2540 Acc: 0.8853\n",
      "Epoch 017 | Train Loss: 0.2365 Acc: 0.9043 | Val Loss: 0.2626 Acc: 0.8865\n",
      "Epoch 018 | Train Loss: 0.2217 Acc: 0.9115 | Val Loss: 0.2565 Acc: 0.8901\n",
      "Epoch 019 | Train Loss: 0.2008 Acc: 0.9241 | Val Loss: 0.2272 Acc: 0.9016\n",
      "Epoch 020 | Train Loss: 0.2055 Acc: 0.9219 | Val Loss: 0.2200 Acc: 0.9155\n",
      "Epoch 021 | Train Loss: 0.1973 Acc: 0.9259 | Val Loss: 0.2182 Acc: 0.9112\n",
      "Epoch 022 | Train Loss: 0.1742 Acc: 0.9343 | Val Loss: 0.2141 Acc: 0.9082\n",
      "Epoch 023 | Train Loss: 0.1684 Acc: 0.9339 | Val Loss: 0.2026 Acc: 0.9191\n",
      "Epoch 024 | Train Loss: 0.1597 Acc: 0.9382 | Val Loss: 0.2111 Acc: 0.9143\n",
      "Epoch 025 | Train Loss: 0.1414 Acc: 0.9453 | Val Loss: 0.2296 Acc: 0.9022\n",
      "Epoch 026 | Train Loss: 0.1370 Acc: 0.9493 | Val Loss: 0.2021 Acc: 0.9245\n",
      "Epoch 027 | Train Loss: 0.1297 Acc: 0.9511 | Val Loss: 0.2247 Acc: 0.9221\n",
      "Epoch 028 | Train Loss: 0.1336 Acc: 0.9491 | Val Loss: 0.1809 Acc: 0.9348\n",
      "Epoch 029 | Train Loss: 0.1254 Acc: 0.9544 | Val Loss: 0.2610 Acc: 0.9016\n",
      "Epoch 030 | Train Loss: 0.1148 Acc: 0.9576 | Val Loss: 0.2080 Acc: 0.9233\n",
      "Epoch 031 | Train Loss: 0.1137 Acc: 0.9571 | Val Loss: 0.1781 Acc: 0.9312\n",
      "Epoch 032 | Train Loss: 0.1144 Acc: 0.9564 | Val Loss: 0.1906 Acc: 0.9257\n",
      "Epoch 033 | Train Loss: 0.1077 Acc: 0.9610 | Val Loss: 0.1863 Acc: 0.9287\n",
      "Epoch 034 | Train Loss: 0.1078 Acc: 0.9574 | Val Loss: 0.1726 Acc: 0.9324\n",
      "Epoch 035 | Train Loss: 0.1096 Acc: 0.9604 | Val Loss: 0.1707 Acc: 0.9366\n",
      "Epoch 036 | Train Loss: 0.0916 Acc: 0.9638 | Val Loss: 0.1845 Acc: 0.9336\n",
      "Epoch 037 | Train Loss: 0.0841 Acc: 0.9677 | Val Loss: 0.2119 Acc: 0.9300\n",
      "Epoch 038 | Train Loss: 0.0980 Acc: 0.9626 | Val Loss: 0.1940 Acc: 0.9300\n",
      "Epoch 039 | Train Loss: 0.0855 Acc: 0.9681 | Val Loss: 0.1912 Acc: 0.9360\n",
      "Epoch 040 | Train Loss: 0.0852 Acc: 0.9692 | Val Loss: 0.1560 Acc: 0.9414\n",
      "Epoch 041 | Train Loss: 0.0794 Acc: 0.9684 | Val Loss: 0.1760 Acc: 0.9342\n",
      "Epoch 042 | Train Loss: 0.0785 Acc: 0.9707 | Val Loss: 0.2150 Acc: 0.9281\n",
      "Epoch 043 | Train Loss: 0.0905 Acc: 0.9680 | Val Loss: 0.1626 Acc: 0.9354\n",
      "Epoch 044 | Train Loss: 0.0755 Acc: 0.9736 | Val Loss: 0.1909 Acc: 0.9269\n",
      "Epoch 045 | Train Loss: 0.0804 Acc: 0.9684 | Val Loss: 0.1924 Acc: 0.9342\n",
      "Epoch 046 | Train Loss: 0.0750 Acc: 0.9721 | Val Loss: 0.1788 Acc: 0.9354\n",
      "Epoch 047 | Train Loss: 0.0706 Acc: 0.9736 | Val Loss: 0.1703 Acc: 0.9432\n",
      "Epoch 048 | Train Loss: 0.0664 Acc: 0.9743 | Val Loss: 0.2071 Acc: 0.9318\n",
      "Epoch 049 | Train Loss: 0.0784 Acc: 0.9712 | Val Loss: 0.1852 Acc: 0.9366\n",
      "Epoch 050 | Train Loss: 0.0601 Acc: 0.9805 | Val Loss: 0.1914 Acc: 0.9438\n",
      "Early stopping triggered.\n",
      "Epoch 001 | Train Loss: 0.6815 Acc: 0.5738 | Val Loss: 0.6780 Acc: 0.5839\n",
      "Epoch 002 | Train Loss: 0.6755 Acc: 0.5866 | Val Loss: 0.6752 Acc: 0.5797\n",
      "Epoch 003 | Train Loss: 0.6614 Acc: 0.6073 | Val Loss: 0.6674 Acc: 0.5876\n",
      "Epoch 004 | Train Loss: 0.6484 Acc: 0.6349 | Val Loss: 0.6250 Acc: 0.6498\n",
      "Epoch 005 | Train Loss: 0.6117 Acc: 0.6727 | Val Loss: 0.6220 Acc: 0.6600\n",
      "Epoch 006 | Train Loss: 0.5928 Acc: 0.6927 | Val Loss: 0.5756 Acc: 0.6993\n",
      "Epoch 007 | Train Loss: 0.5759 Acc: 0.7032 | Val Loss: 0.5767 Acc: 0.7041\n",
      "Epoch 008 | Train Loss: 0.5630 Acc: 0.7093 | Val Loss: 0.5622 Acc: 0.7126\n",
      "Epoch 009 | Train Loss: 0.5500 Acc: 0.7275 | Val Loss: 0.5456 Acc: 0.7228\n",
      "Epoch 010 | Train Loss: 0.5364 Acc: 0.7347 | Val Loss: 0.5603 Acc: 0.7168\n",
      "Epoch 011 | Train Loss: 0.5327 Acc: 0.7400 | Val Loss: 0.5263 Acc: 0.7258\n",
      "Epoch 012 | Train Loss: 0.5177 Acc: 0.7495 | Val Loss: 0.5136 Acc: 0.7482\n",
      "Epoch 013 | Train Loss: 0.5009 Acc: 0.7572 | Val Loss: 0.5091 Acc: 0.7403\n",
      "Epoch 014 | Train Loss: 0.4832 Acc: 0.7682 | Val Loss: 0.4910 Acc: 0.7603\n",
      "Epoch 015 | Train Loss: 0.4786 Acc: 0.7713 | Val Loss: 0.4657 Acc: 0.7723\n",
      "Epoch 016 | Train Loss: 0.4665 Acc: 0.7711 | Val Loss: 0.4956 Acc: 0.7657\n",
      "Epoch 017 | Train Loss: 0.4745 Acc: 0.7749 | Val Loss: 0.4681 Acc: 0.7663\n",
      "Epoch 018 | Train Loss: 0.4458 Acc: 0.7907 | Val Loss: 0.4575 Acc: 0.7711\n",
      "Epoch 019 | Train Loss: 0.4365 Acc: 0.7918 | Val Loss: 0.4417 Acc: 0.7790\n",
      "Epoch 020 | Train Loss: 0.4231 Acc: 0.8018 | Val Loss: 0.4241 Acc: 0.7935\n",
      "Epoch 021 | Train Loss: 0.4117 Acc: 0.8101 | Val Loss: 0.3977 Acc: 0.8092\n",
      "Epoch 022 | Train Loss: 0.4016 Acc: 0.8131 | Val Loss: 0.4127 Acc: 0.8122\n",
      "Epoch 023 | Train Loss: 0.3847 Acc: 0.8280 | Val Loss: 0.4159 Acc: 0.8104\n",
      "Epoch 024 | Train Loss: 0.3767 Acc: 0.8295 | Val Loss: 0.3782 Acc: 0.8261\n",
      "Epoch 025 | Train Loss: 0.3668 Acc: 0.8374 | Val Loss: 0.3552 Acc: 0.8527\n",
      "Epoch 026 | Train Loss: 0.3478 Acc: 0.8486 | Val Loss: 0.3403 Acc: 0.8533\n",
      "Epoch 027 | Train Loss: 0.3422 Acc: 0.8534 | Val Loss: 0.3557 Acc: 0.8351\n",
      "Epoch 028 | Train Loss: 0.3275 Acc: 0.8570 | Val Loss: 0.3595 Acc: 0.8357\n",
      "Epoch 029 | Train Loss: 0.3185 Acc: 0.8566 | Val Loss: 0.2914 Acc: 0.8726\n",
      "Epoch 030 | Train Loss: 0.3059 Acc: 0.8721 | Val Loss: 0.3159 Acc: 0.8678\n",
      "Epoch 031 | Train Loss: 0.3117 Acc: 0.8709 | Val Loss: 0.2910 Acc: 0.8829\n",
      "Epoch 032 | Train Loss: 0.2874 Acc: 0.8809 | Val Loss: 0.2985 Acc: 0.8714\n",
      "Epoch 033 | Train Loss: 0.2822 Acc: 0.8800 | Val Loss: 0.2979 Acc: 0.8696\n",
      "Epoch 034 | Train Loss: 0.2848 Acc: 0.8765 | Val Loss: 0.2987 Acc: 0.8702\n",
      "Epoch 035 | Train Loss: 0.2780 Acc: 0.8848 | Val Loss: 0.2524 Acc: 0.8925\n",
      "Epoch 036 | Train Loss: 0.2616 Acc: 0.8925 | Val Loss: 0.2671 Acc: 0.8847\n",
      "Epoch 037 | Train Loss: 0.2549 Acc: 0.8928 | Val Loss: 0.2644 Acc: 0.8835\n",
      "Epoch 038 | Train Loss: 0.2616 Acc: 0.8905 | Val Loss: 0.2562 Acc: 0.8967\n",
      "Epoch 039 | Train Loss: 0.2500 Acc: 0.8984 | Val Loss: 0.2844 Acc: 0.8853\n",
      "Epoch 040 | Train Loss: 0.2403 Acc: 0.8996 | Val Loss: 0.2870 Acc: 0.8949\n",
      "Epoch 041 | Train Loss: 0.2376 Acc: 0.9013 | Val Loss: 0.2486 Acc: 0.8931\n",
      "Epoch 042 | Train Loss: 0.2450 Acc: 0.8990 | Val Loss: 0.2477 Acc: 0.8955\n",
      "Epoch 043 | Train Loss: 0.2319 Acc: 0.9056 | Val Loss: 0.2294 Acc: 0.9143\n",
      "Epoch 044 | Train Loss: 0.2254 Acc: 0.9112 | Val Loss: 0.2241 Acc: 0.9149\n",
      "Epoch 045 | Train Loss: 0.2230 Acc: 0.9100 | Val Loss: 0.2328 Acc: 0.9143\n",
      "Epoch 046 | Train Loss: 0.2105 Acc: 0.9127 | Val Loss: 0.2244 Acc: 0.9112\n",
      "Epoch 047 | Train Loss: 0.2041 Acc: 0.9183 | Val Loss: 0.2078 Acc: 0.9179\n",
      "Epoch 048 | Train Loss: 0.2045 Acc: 0.9219 | Val Loss: 0.2368 Acc: 0.9094\n",
      "Epoch 049 | Train Loss: 0.1953 Acc: 0.9218 | Val Loss: 0.2137 Acc: 0.9124\n",
      "Epoch 050 | Train Loss: 0.1987 Acc: 0.9221 | Val Loss: 0.2313 Acc: 0.9070\n",
      "Epoch 051 | Train Loss: 0.1960 Acc: 0.9216 | Val Loss: 0.2132 Acc: 0.9100\n",
      "Epoch 052 | Train Loss: 0.1914 Acc: 0.9219 | Val Loss: 0.2353 Acc: 0.9052\n",
      "Epoch 053 | Train Loss: 0.1966 Acc: 0.9225 | Val Loss: 0.2049 Acc: 0.9197\n",
      "Epoch 054 | Train Loss: 0.1781 Acc: 0.9281 | Val Loss: 0.2161 Acc: 0.9130\n",
      "Epoch 055 | Train Loss: 0.1921 Acc: 0.9298 | Val Loss: 0.2427 Acc: 0.9058\n",
      "Epoch 056 | Train Loss: 0.1960 Acc: 0.9242 | Val Loss: 0.1723 Acc: 0.9330\n",
      "Epoch 057 | Train Loss: 0.1664 Acc: 0.9324 | Val Loss: 0.2125 Acc: 0.9179\n",
      "Epoch 058 | Train Loss: 0.1788 Acc: 0.9302 | Val Loss: 0.1682 Acc: 0.9366\n",
      "Epoch 059 | Train Loss: 0.1689 Acc: 0.9348 | Val Loss: 0.1680 Acc: 0.9342\n",
      "Epoch 060 | Train Loss: 0.1621 Acc: 0.9367 | Val Loss: 0.1898 Acc: 0.9287\n",
      "Iteration 19/40 | Best Val Loss: 0.1122 | Iter Time: 200.66s | Total Time: 82.36 min\n",
      "Epoch 001 | Train Loss: 0.6781 Acc: 0.5842 | Val Loss: 0.6717 Acc: 0.5906\n",
      "Epoch 002 | Train Loss: 0.6664 Acc: 0.6032 | Val Loss: 0.6633 Acc: 0.6081\n",
      "Epoch 003 | Train Loss: 0.6355 Acc: 0.6511 | Val Loss: 0.6314 Acc: 0.6787\n",
      "Epoch 004 | Train Loss: 0.6035 Acc: 0.6872 | Val Loss: 0.5778 Acc: 0.7047\n",
      "Epoch 005 | Train Loss: 0.5625 Acc: 0.7184 | Val Loss: 0.5458 Acc: 0.7319\n",
      "Epoch 006 | Train Loss: 0.5263 Acc: 0.7465 | Val Loss: 0.5147 Acc: 0.7482\n",
      "Epoch 007 | Train Loss: 0.5044 Acc: 0.7602 | Val Loss: 0.5060 Acc: 0.7488\n",
      "Epoch 008 | Train Loss: 0.4810 Acc: 0.7774 | Val Loss: 0.4950 Acc: 0.7621\n",
      "Epoch 009 | Train Loss: 0.4562 Acc: 0.7862 | Val Loss: 0.4542 Acc: 0.7874\n",
      "Epoch 010 | Train Loss: 0.4381 Acc: 0.7977 | Val Loss: 0.4280 Acc: 0.7886\n",
      "Epoch 011 | Train Loss: 0.4018 Acc: 0.8144 | Val Loss: 0.3822 Acc: 0.8219\n",
      "Epoch 012 | Train Loss: 0.3846 Acc: 0.8250 | Val Loss: 0.4038 Acc: 0.8110\n",
      "Epoch 013 | Train Loss: 0.3629 Acc: 0.8386 | Val Loss: 0.3703 Acc: 0.8291\n",
      "Epoch 014 | Train Loss: 0.3533 Acc: 0.8461 | Val Loss: 0.3477 Acc: 0.8388\n",
      "Epoch 015 | Train Loss: 0.3221 Acc: 0.8615 | Val Loss: 0.3128 Acc: 0.8641\n",
      "Epoch 016 | Train Loss: 0.2994 Acc: 0.8736 | Val Loss: 0.3237 Acc: 0.8575\n",
      "Epoch 017 | Train Loss: 0.2786 Acc: 0.8842 | Val Loss: 0.2686 Acc: 0.8883\n",
      "Epoch 018 | Train Loss: 0.2502 Acc: 0.8948 | Val Loss: 0.2529 Acc: 0.8949\n",
      "Epoch 019 | Train Loss: 0.2391 Acc: 0.8997 | Val Loss: 0.2282 Acc: 0.9046\n",
      "Epoch 020 | Train Loss: 0.2263 Acc: 0.9094 | Val Loss: 0.2250 Acc: 0.9112\n",
      "Epoch 021 | Train Loss: 0.2083 Acc: 0.9126 | Val Loss: 0.2412 Acc: 0.9046\n",
      "Epoch 022 | Train Loss: 0.1864 Acc: 0.9254 | Val Loss: 0.2185 Acc: 0.9173\n",
      "Epoch 023 | Train Loss: 0.1829 Acc: 0.9298 | Val Loss: 0.2698 Acc: 0.9016\n",
      "Epoch 024 | Train Loss: 0.1727 Acc: 0.9318 | Val Loss: 0.2197 Acc: 0.9118\n",
      "Epoch 025 | Train Loss: 0.1733 Acc: 0.9316 | Val Loss: 0.1864 Acc: 0.9263\n",
      "Epoch 026 | Train Loss: 0.1535 Acc: 0.9407 | Val Loss: 0.1943 Acc: 0.9287\n",
      "Epoch 027 | Train Loss: 0.1440 Acc: 0.9422 | Val Loss: 0.2014 Acc: 0.9173\n",
      "Epoch 028 | Train Loss: 0.1400 Acc: 0.9487 | Val Loss: 0.1905 Acc: 0.9215\n",
      "Epoch 029 | Train Loss: 0.1445 Acc: 0.9447 | Val Loss: 0.1868 Acc: 0.9263\n",
      "Epoch 030 | Train Loss: 0.1312 Acc: 0.9505 | Val Loss: 0.1782 Acc: 0.9306\n",
      "Epoch 031 | Train Loss: 0.1121 Acc: 0.9561 | Val Loss: 0.1872 Acc: 0.9275\n",
      "Epoch 032 | Train Loss: 0.1158 Acc: 0.9582 | Val Loss: 0.1622 Acc: 0.9312\n",
      "Epoch 033 | Train Loss: 0.1078 Acc: 0.9600 | Val Loss: 0.1606 Acc: 0.9324\n",
      "Epoch 034 | Train Loss: 0.0986 Acc: 0.9612 | Val Loss: 0.1632 Acc: 0.9360\n",
      "Epoch 035 | Train Loss: 0.0938 Acc: 0.9666 | Val Loss: 0.1651 Acc: 0.9390\n",
      "Epoch 036 | Train Loss: 0.1025 Acc: 0.9630 | Val Loss: 0.1766 Acc: 0.9330\n",
      "Epoch 037 | Train Loss: 0.1028 Acc: 0.9618 | Val Loss: 0.2350 Acc: 0.9197\n",
      "Epoch 038 | Train Loss: 0.0909 Acc: 0.9669 | Val Loss: 0.1517 Acc: 0.9378\n",
      "Epoch 039 | Train Loss: 0.0931 Acc: 0.9653 | Val Loss: 0.1747 Acc: 0.9318\n",
      "Epoch 040 | Train Loss: 0.0820 Acc: 0.9703 | Val Loss: 0.1650 Acc: 0.9300\n",
      "Epoch 041 | Train Loss: 0.0672 Acc: 0.9767 | Val Loss: 0.1800 Acc: 0.9330\n",
      "Epoch 042 | Train Loss: 0.0856 Acc: 0.9684 | Val Loss: 0.1673 Acc: 0.9378\n",
      "Epoch 043 | Train Loss: 0.0787 Acc: 0.9710 | Val Loss: 0.1943 Acc: 0.9227\n",
      "Epoch 044 | Train Loss: 0.0957 Acc: 0.9641 | Val Loss: 0.1798 Acc: 0.9257\n",
      "Epoch 045 | Train Loss: 0.0698 Acc: 0.9716 | Val Loss: 0.1813 Acc: 0.9306\n",
      "Epoch 046 | Train Loss: 0.0674 Acc: 0.9752 | Val Loss: 0.1685 Acc: 0.9390\n",
      "Epoch 047 | Train Loss: 0.0711 Acc: 0.9742 | Val Loss: 0.1764 Acc: 0.9336\n",
      "Epoch 048 | Train Loss: 0.0559 Acc: 0.9799 | Val Loss: 0.1591 Acc: 0.9432\n",
      "Early stopping triggered.\n",
      "Epoch 001 | Train Loss: 0.6785 Acc: 0.5796 | Val Loss: 0.6732 Acc: 0.5882\n",
      "Epoch 002 | Train Loss: 0.6632 Acc: 0.6053 | Val Loss: 0.6421 Acc: 0.6347\n",
      "Epoch 003 | Train Loss: 0.6278 Acc: 0.6659 | Val Loss: 0.6232 Acc: 0.6691\n",
      "Epoch 004 | Train Loss: 0.5865 Acc: 0.7081 | Val Loss: 0.5758 Acc: 0.7053\n",
      "Epoch 005 | Train Loss: 0.5581 Acc: 0.7258 | Val Loss: 0.5717 Acc: 0.7077\n",
      "Epoch 006 | Train Loss: 0.5381 Acc: 0.7429 | Val Loss: 0.6106 Acc: 0.6769\n",
      "Epoch 007 | Train Loss: 0.5283 Acc: 0.7463 | Val Loss: 0.5354 Acc: 0.7391\n",
      "Epoch 008 | Train Loss: 0.5055 Acc: 0.7598 | Val Loss: 0.5350 Acc: 0.7409\n",
      "Epoch 009 | Train Loss: 0.4920 Acc: 0.7700 | Val Loss: 0.4986 Acc: 0.7536\n",
      "Epoch 010 | Train Loss: 0.4804 Acc: 0.7767 | Val Loss: 0.4723 Acc: 0.7748\n",
      "Epoch 011 | Train Loss: 0.4490 Acc: 0.7904 | Val Loss: 0.4674 Acc: 0.7784\n",
      "Epoch 012 | Train Loss: 0.4251 Acc: 0.8021 | Val Loss: 0.4216 Acc: 0.7983\n",
      "Epoch 013 | Train Loss: 0.3930 Acc: 0.8268 | Val Loss: 0.4087 Acc: 0.8068\n",
      "Epoch 014 | Train Loss: 0.3682 Acc: 0.8433 | Val Loss: 0.4287 Acc: 0.7899\n",
      "Epoch 015 | Train Loss: 0.3609 Acc: 0.8389 | Val Loss: 0.3736 Acc: 0.8291\n",
      "Epoch 016 | Train Loss: 0.3287 Acc: 0.8617 | Val Loss: 0.4031 Acc: 0.8194\n",
      "Epoch 017 | Train Loss: 0.3178 Acc: 0.8606 | Val Loss: 0.3349 Acc: 0.8460\n",
      "Epoch 018 | Train Loss: 0.2965 Acc: 0.8738 | Val Loss: 0.3345 Acc: 0.8575\n",
      "Epoch 019 | Train Loss: 0.2609 Acc: 0.8925 | Val Loss: 0.3217 Acc: 0.8671\n",
      "Epoch 020 | Train Loss: 0.2518 Acc: 0.8957 | Val Loss: 0.3295 Acc: 0.8557\n",
      "Epoch 021 | Train Loss: 0.2340 Acc: 0.9032 | Val Loss: 0.2807 Acc: 0.8750\n",
      "Epoch 022 | Train Loss: 0.2318 Acc: 0.9046 | Val Loss: 0.2902 Acc: 0.8750\n",
      "Epoch 023 | Train Loss: 0.2087 Acc: 0.9147 | Val Loss: 0.2920 Acc: 0.8835\n",
      "Epoch 024 | Train Loss: 0.1937 Acc: 0.9259 | Val Loss: 0.2574 Acc: 0.9010\n",
      "Epoch 025 | Train Loss: 0.1865 Acc: 0.9269 | Val Loss: 0.2534 Acc: 0.8949\n",
      "Epoch 026 | Train Loss: 0.1886 Acc: 0.9254 | Val Loss: 0.2595 Acc: 0.8998\n",
      "Epoch 027 | Train Loss: 0.1555 Acc: 0.9381 | Val Loss: 0.2622 Acc: 0.8937\n",
      "Epoch 028 | Train Loss: 0.1561 Acc: 0.9343 | Val Loss: 0.2772 Acc: 0.8871\n",
      "Epoch 029 | Train Loss: 0.1421 Acc: 0.9422 | Val Loss: 0.2471 Acc: 0.8986\n",
      "Epoch 030 | Train Loss: 0.1491 Acc: 0.9423 | Val Loss: 0.2315 Acc: 0.8998\n",
      "Epoch 031 | Train Loss: 0.1328 Acc: 0.9467 | Val Loss: 0.2717 Acc: 0.8992\n",
      "Epoch 032 | Train Loss: 0.1216 Acc: 0.9532 | Val Loss: 0.2615 Acc: 0.9010\n",
      "Epoch 033 | Train Loss: 0.1140 Acc: 0.9586 | Val Loss: 0.2270 Acc: 0.9173\n",
      "Epoch 034 | Train Loss: 0.1174 Acc: 0.9524 | Val Loss: 0.2355 Acc: 0.9130\n",
      "Epoch 035 | Train Loss: 0.1195 Acc: 0.9559 | Val Loss: 0.2422 Acc: 0.9028\n",
      "Epoch 036 | Train Loss: 0.1025 Acc: 0.9623 | Val Loss: 0.2673 Acc: 0.9052\n",
      "Epoch 037 | Train Loss: 0.1057 Acc: 0.9623 | Val Loss: 0.2139 Acc: 0.9155\n",
      "Epoch 038 | Train Loss: 0.0907 Acc: 0.9641 | Val Loss: 0.2267 Acc: 0.9245\n",
      "Epoch 039 | Train Loss: 0.0975 Acc: 0.9666 | Val Loss: 0.2455 Acc: 0.9203\n",
      "Epoch 040 | Train Loss: 0.0846 Acc: 0.9703 | Val Loss: 0.2257 Acc: 0.9185\n",
      "Epoch 041 | Train Loss: 0.0794 Acc: 0.9713 | Val Loss: 0.2059 Acc: 0.9293\n",
      "Epoch 042 | Train Loss: 0.0870 Acc: 0.9690 | Val Loss: 0.2108 Acc: 0.9197\n",
      "Epoch 043 | Train Loss: 0.0868 Acc: 0.9701 | Val Loss: 0.2012 Acc: 0.9227\n",
      "Epoch 044 | Train Loss: 0.0698 Acc: 0.9733 | Val Loss: 0.2301 Acc: 0.9372\n",
      "Epoch 045 | Train Loss: 0.0758 Acc: 0.9739 | Val Loss: 0.1847 Acc: 0.9306\n",
      "Epoch 046 | Train Loss: 0.0696 Acc: 0.9757 | Val Loss: 0.2029 Acc: 0.9287\n",
      "Epoch 047 | Train Loss: 0.0678 Acc: 0.9740 | Val Loss: 0.2045 Acc: 0.9306\n",
      "Epoch 048 | Train Loss: 0.0698 Acc: 0.9737 | Val Loss: 0.2132 Acc: 0.9287\n",
      "Epoch 049 | Train Loss: 0.0737 Acc: 0.9733 | Val Loss: 0.2232 Acc: 0.9239\n",
      "Epoch 050 | Train Loss: 0.0696 Acc: 0.9733 | Val Loss: 0.1985 Acc: 0.9275\n",
      "Epoch 051 | Train Loss: 0.0691 Acc: 0.9760 | Val Loss: 0.1936 Acc: 0.9312\n",
      "Epoch 052 | Train Loss: 0.0624 Acc: 0.9783 | Val Loss: 0.2295 Acc: 0.9251\n",
      "Epoch 053 | Train Loss: 0.0676 Acc: 0.9778 | Val Loss: 0.1950 Acc: 0.9287\n",
      "Epoch 054 | Train Loss: 0.0721 Acc: 0.9743 | Val Loss: 0.1995 Acc: 0.9336\n",
      "Epoch 055 | Train Loss: 0.0556 Acc: 0.9793 | Val Loss: 0.1960 Acc: 0.9384\n",
      "Early stopping triggered.\n",
      "Epoch 001 | Train Loss: 0.6802 Acc: 0.5777 | Val Loss: 0.6784 Acc: 0.5864\n",
      "Epoch 002 | Train Loss: 0.6721 Acc: 0.5966 | Val Loss: 0.6705 Acc: 0.6027\n",
      "Epoch 003 | Train Loss: 0.6611 Acc: 0.6100 | Val Loss: 0.6666 Acc: 0.6069\n",
      "Epoch 004 | Train Loss: 0.6548 Acc: 0.6197 | Val Loss: 0.6330 Acc: 0.6739\n",
      "Epoch 005 | Train Loss: 0.6047 Acc: 0.6893 | Val Loss: 0.5871 Acc: 0.7023\n",
      "Epoch 006 | Train Loss: 0.5669 Acc: 0.7223 | Val Loss: 0.5720 Acc: 0.7138\n",
      "Epoch 007 | Train Loss: 0.5577 Acc: 0.7297 | Val Loss: 0.5417 Acc: 0.7271\n",
      "Epoch 008 | Train Loss: 0.5250 Acc: 0.7472 | Val Loss: 0.5325 Acc: 0.7156\n",
      "Epoch 009 | Train Loss: 0.5109 Acc: 0.7503 | Val Loss: 0.4884 Acc: 0.7536\n",
      "Epoch 010 | Train Loss: 0.4859 Acc: 0.7681 | Val Loss: 0.4780 Acc: 0.7512\n",
      "Epoch 011 | Train Loss: 0.4545 Acc: 0.7854 | Val Loss: 0.4945 Acc: 0.7808\n",
      "Epoch 012 | Train Loss: 0.4302 Acc: 0.8014 | Val Loss: 0.4172 Acc: 0.8062\n",
      "Epoch 013 | Train Loss: 0.4128 Acc: 0.8144 | Val Loss: 0.4072 Acc: 0.8031\n",
      "Epoch 014 | Train Loss: 0.3784 Acc: 0.8330 | Val Loss: 0.3848 Acc: 0.8243\n",
      "Epoch 015 | Train Loss: 0.3686 Acc: 0.8383 | Val Loss: 0.4006 Acc: 0.8122\n",
      "Epoch 016 | Train Loss: 0.3395 Acc: 0.8504 | Val Loss: 0.3527 Acc: 0.8412\n",
      "Epoch 017 | Train Loss: 0.3061 Acc: 0.8698 | Val Loss: 0.3045 Acc: 0.8726\n",
      "Epoch 018 | Train Loss: 0.2869 Acc: 0.8797 | Val Loss: 0.2989 Acc: 0.8629\n",
      "Epoch 019 | Train Loss: 0.2680 Acc: 0.8880 | Val Loss: 0.2697 Acc: 0.8901\n",
      "Epoch 020 | Train Loss: 0.2577 Acc: 0.8936 | Val Loss: 0.2592 Acc: 0.8841\n",
      "Epoch 021 | Train Loss: 0.2384 Acc: 0.9022 | Val Loss: 0.2602 Acc: 0.8816\n",
      "Epoch 022 | Train Loss: 0.2193 Acc: 0.9070 | Val Loss: 0.2482 Acc: 0.9010\n",
      "Epoch 023 | Train Loss: 0.2264 Acc: 0.9082 | Val Loss: 0.2692 Acc: 0.8949\n",
      "Epoch 024 | Train Loss: 0.2084 Acc: 0.9145 | Val Loss: 0.2359 Acc: 0.9052\n",
      "Epoch 025 | Train Loss: 0.1931 Acc: 0.9206 | Val Loss: 0.2181 Acc: 0.9112\n",
      "Epoch 026 | Train Loss: 0.1910 Acc: 0.9259 | Val Loss: 0.2072 Acc: 0.9167\n",
      "Epoch 027 | Train Loss: 0.1699 Acc: 0.9289 | Val Loss: 0.2065 Acc: 0.9179\n",
      "Epoch 028 | Train Loss: 0.1521 Acc: 0.9390 | Val Loss: 0.2135 Acc: 0.9215\n",
      "Epoch 029 | Train Loss: 0.1590 Acc: 0.9363 | Val Loss: 0.2332 Acc: 0.9124\n",
      "Epoch 030 | Train Loss: 0.1639 Acc: 0.9339 | Val Loss: 0.1850 Acc: 0.9257\n",
      "Epoch 031 | Train Loss: 0.1393 Acc: 0.9441 | Val Loss: 0.2013 Acc: 0.9221\n",
      "Epoch 032 | Train Loss: 0.1455 Acc: 0.9422 | Val Loss: 0.1959 Acc: 0.9227\n",
      "Epoch 033 | Train Loss: 0.1343 Acc: 0.9476 | Val Loss: 0.1940 Acc: 0.9300\n",
      "Epoch 034 | Train Loss: 0.1301 Acc: 0.9509 | Val Loss: 0.2001 Acc: 0.9215\n",
      "Epoch 035 | Train Loss: 0.1293 Acc: 0.9494 | Val Loss: 0.1916 Acc: 0.9257\n",
      "Epoch 036 | Train Loss: 0.1170 Acc: 0.9562 | Val Loss: 0.1813 Acc: 0.9281\n",
      "Epoch 037 | Train Loss: 0.1209 Acc: 0.9555 | Val Loss: 0.1897 Acc: 0.9263\n",
      "Epoch 038 | Train Loss: 0.1138 Acc: 0.9564 | Val Loss: 0.1890 Acc: 0.9281\n",
      "Epoch 039 | Train Loss: 0.1141 Acc: 0.9567 | Val Loss: 0.2039 Acc: 0.9281\n",
      "Epoch 040 | Train Loss: 0.1101 Acc: 0.9577 | Val Loss: 0.1718 Acc: 0.9384\n",
      "Epoch 041 | Train Loss: 0.0952 Acc: 0.9641 | Val Loss: 0.1825 Acc: 0.9324\n",
      "Epoch 042 | Train Loss: 0.0967 Acc: 0.9650 | Val Loss: 0.1907 Acc: 0.9275\n",
      "Epoch 043 | Train Loss: 0.0840 Acc: 0.9678 | Val Loss: 0.1718 Acc: 0.9432\n",
      "Epoch 044 | Train Loss: 0.0876 Acc: 0.9684 | Val Loss: 0.1879 Acc: 0.9269\n",
      "Epoch 045 | Train Loss: 0.0990 Acc: 0.9626 | Val Loss: 0.1759 Acc: 0.9324\n",
      "Epoch 046 | Train Loss: 0.0850 Acc: 0.9669 | Val Loss: 0.2004 Acc: 0.9330\n",
      "Epoch 047 | Train Loss: 0.0936 Acc: 0.9668 | Val Loss: 0.1826 Acc: 0.9275\n",
      "Epoch 048 | Train Loss: 0.0914 Acc: 0.9651 | Val Loss: 0.1422 Acc: 0.9463\n",
      "Epoch 049 | Train Loss: 0.0744 Acc: 0.9718 | Val Loss: 0.1811 Acc: 0.9336\n",
      "Epoch 050 | Train Loss: 0.0778 Acc: 0.9719 | Val Loss: 0.1723 Acc: 0.9384\n",
      "Epoch 051 | Train Loss: 0.0702 Acc: 0.9739 | Val Loss: 0.1763 Acc: 0.9390\n",
      "Epoch 052 | Train Loss: 0.0779 Acc: 0.9713 | Val Loss: 0.1434 Acc: 0.9475\n",
      "Epoch 053 | Train Loss: 0.0714 Acc: 0.9739 | Val Loss: 0.2463 Acc: 0.9269\n",
      "Epoch 054 | Train Loss: 0.0758 Acc: 0.9707 | Val Loss: 0.1677 Acc: 0.9366\n",
      "Epoch 055 | Train Loss: 0.0741 Acc: 0.9706 | Val Loss: 0.1650 Acc: 0.9372\n",
      "Epoch 056 | Train Loss: 0.0726 Acc: 0.9731 | Val Loss: 0.1789 Acc: 0.9469\n",
      "Epoch 057 | Train Loss: 0.0670 Acc: 0.9751 | Val Loss: 0.1929 Acc: 0.9408\n",
      "Epoch 058 | Train Loss: 0.0655 Acc: 0.9789 | Val Loss: 0.1412 Acc: 0.9571\n",
      "Epoch 059 | Train Loss: 0.0673 Acc: 0.9748 | Val Loss: 0.1661 Acc: 0.9384\n",
      "Epoch 060 | Train Loss: 0.0676 Acc: 0.9760 | Val Loss: 0.1816 Acc: 0.9318\n",
      "Epoch 001 | Train Loss: 0.6888 Acc: 0.5543 | Val Loss: 0.6867 Acc: 0.5586\n",
      "Epoch 002 | Train Loss: 0.6845 Acc: 0.5627 | Val Loss: 0.6814 Acc: 0.5791\n",
      "Epoch 003 | Train Loss: 0.6765 Acc: 0.5920 | Val Loss: 0.6797 Acc: 0.5767\n",
      "Epoch 004 | Train Loss: 0.6726 Acc: 0.5944 | Val Loss: 0.6715 Acc: 0.5912\n",
      "Epoch 005 | Train Loss: 0.6661 Acc: 0.6035 | Val Loss: 0.6653 Acc: 0.6033\n",
      "Epoch 006 | Train Loss: 0.6611 Acc: 0.6062 | Val Loss: 0.6609 Acc: 0.6002\n",
      "Epoch 007 | Train Loss: 0.6541 Acc: 0.6114 | Val Loss: 0.6509 Acc: 0.6063\n",
      "Epoch 008 | Train Loss: 0.6397 Acc: 0.6397 | Val Loss: 0.6382 Acc: 0.6443\n",
      "Epoch 009 | Train Loss: 0.6267 Acc: 0.6627 | Val Loss: 0.6136 Acc: 0.6781\n",
      "Epoch 010 | Train Loss: 0.6195 Acc: 0.6725 | Val Loss: 0.6116 Acc: 0.6655\n",
      "Epoch 011 | Train Loss: 0.6115 Acc: 0.6769 | Val Loss: 0.6083 Acc: 0.6830\n",
      "Epoch 012 | Train Loss: 0.6057 Acc: 0.6859 | Val Loss: 0.5996 Acc: 0.6896\n",
      "Epoch 013 | Train Loss: 0.6024 Acc: 0.6893 | Val Loss: 0.5951 Acc: 0.6957\n",
      "Epoch 014 | Train Loss: 0.5963 Acc: 0.6936 | Val Loss: 0.5919 Acc: 0.6975\n",
      "Epoch 015 | Train Loss: 0.5944 Acc: 0.6936 | Val Loss: 0.5904 Acc: 0.6975\n",
      "Epoch 016 | Train Loss: 0.5896 Acc: 0.6982 | Val Loss: 0.5834 Acc: 0.7041\n",
      "Epoch 017 | Train Loss: 0.5926 Acc: 0.6908 | Val Loss: 0.5906 Acc: 0.6944\n",
      "Epoch 018 | Train Loss: 0.5803 Acc: 0.7063 | Val Loss: 0.5815 Acc: 0.6999\n",
      "Epoch 019 | Train Loss: 0.5766 Acc: 0.7121 | Val Loss: 0.5740 Acc: 0.7114\n",
      "Epoch 020 | Train Loss: 0.5710 Acc: 0.7149 | Val Loss: 0.5681 Acc: 0.7132\n",
      "Epoch 021 | Train Loss: 0.5667 Acc: 0.7172 | Val Loss: 0.5723 Acc: 0.7126\n",
      "Epoch 022 | Train Loss: 0.5652 Acc: 0.7189 | Val Loss: 0.5732 Acc: 0.7156\n",
      "Epoch 023 | Train Loss: 0.5571 Acc: 0.7257 | Val Loss: 0.5689 Acc: 0.7065\n",
      "Epoch 024 | Train Loss: 0.5587 Acc: 0.7226 | Val Loss: 0.5582 Acc: 0.7204\n",
      "Epoch 025 | Train Loss: 0.5526 Acc: 0.7327 | Val Loss: 0.5564 Acc: 0.7234\n",
      "Epoch 026 | Train Loss: 0.5447 Acc: 0.7312 | Val Loss: 0.5522 Acc: 0.7246\n",
      "Epoch 027 | Train Loss: 0.5479 Acc: 0.7329 | Val Loss: 0.5594 Acc: 0.7228\n",
      "Epoch 028 | Train Loss: 0.5461 Acc: 0.7329 | Val Loss: 0.5504 Acc: 0.7283\n",
      "Epoch 029 | Train Loss: 0.5400 Acc: 0.7379 | Val Loss: 0.5450 Acc: 0.7264\n",
      "Epoch 030 | Train Loss: 0.5342 Acc: 0.7412 | Val Loss: 0.5539 Acc: 0.7210\n",
      "Epoch 031 | Train Loss: 0.5336 Acc: 0.7433 | Val Loss: 0.5460 Acc: 0.7283\n",
      "Epoch 032 | Train Loss: 0.5328 Acc: 0.7450 | Val Loss: 0.5589 Acc: 0.7138\n",
      "Epoch 033 | Train Loss: 0.5265 Acc: 0.7491 | Val Loss: 0.5420 Acc: 0.7325\n",
      "Epoch 034 | Train Loss: 0.5290 Acc: 0.7468 | Val Loss: 0.5342 Acc: 0.7349\n",
      "Epoch 035 | Train Loss: 0.5212 Acc: 0.7457 | Val Loss: 0.5975 Acc: 0.6860\n",
      "Epoch 036 | Train Loss: 0.5269 Acc: 0.7486 | Val Loss: 0.5580 Acc: 0.7144\n",
      "Epoch 037 | Train Loss: 0.5192 Acc: 0.7513 | Val Loss: 0.5337 Acc: 0.7343\n",
      "Epoch 038 | Train Loss: 0.5167 Acc: 0.7515 | Val Loss: 0.5273 Acc: 0.7482\n",
      "Epoch 039 | Train Loss: 0.5090 Acc: 0.7595 | Val Loss: 0.5293 Acc: 0.7440\n",
      "Epoch 040 | Train Loss: 0.5166 Acc: 0.7559 | Val Loss: 0.5264 Acc: 0.7446\n",
      "Epoch 041 | Train Loss: 0.5018 Acc: 0.7663 | Val Loss: 0.5229 Acc: 0.7488\n",
      "Epoch 042 | Train Loss: 0.5024 Acc: 0.7617 | Val Loss: 0.5199 Acc: 0.7512\n",
      "Epoch 043 | Train Loss: 0.5063 Acc: 0.7625 | Val Loss: 0.5293 Acc: 0.7440\n",
      "Epoch 044 | Train Loss: 0.5046 Acc: 0.7673 | Val Loss: 0.5392 Acc: 0.7271\n",
      "Epoch 045 | Train Loss: 0.4952 Acc: 0.7685 | Val Loss: 0.5167 Acc: 0.7524\n",
      "Epoch 046 | Train Loss: 0.4960 Acc: 0.7685 | Val Loss: 0.5138 Acc: 0.7506\n",
      "Epoch 047 | Train Loss: 0.4909 Acc: 0.7738 | Val Loss: 0.5126 Acc: 0.7560\n",
      "Epoch 048 | Train Loss: 0.4910 Acc: 0.7743 | Val Loss: 0.5175 Acc: 0.7500\n",
      "Epoch 049 | Train Loss: 0.4880 Acc: 0.7747 | Val Loss: 0.5175 Acc: 0.7458\n",
      "Epoch 050 | Train Loss: 0.4858 Acc: 0.7770 | Val Loss: 0.5099 Acc: 0.7554\n",
      "Epoch 051 | Train Loss: 0.4801 Acc: 0.7777 | Val Loss: 0.5055 Acc: 0.7603\n",
      "Epoch 052 | Train Loss: 0.4813 Acc: 0.7788 | Val Loss: 0.5094 Acc: 0.7554\n",
      "Epoch 053 | Train Loss: 0.4804 Acc: 0.7780 | Val Loss: 0.5033 Acc: 0.7585\n",
      "Epoch 054 | Train Loss: 0.4803 Acc: 0.7818 | Val Loss: 0.5136 Acc: 0.7566\n",
      "Epoch 055 | Train Loss: 0.4756 Acc: 0.7835 | Val Loss: 0.5034 Acc: 0.7579\n",
      "Epoch 056 | Train Loss: 0.4681 Acc: 0.7895 | Val Loss: 0.5011 Acc: 0.7572\n",
      "Epoch 057 | Train Loss: 0.4641 Acc: 0.7879 | Val Loss: 0.5001 Acc: 0.7572\n",
      "Epoch 058 | Train Loss: 0.4714 Acc: 0.7877 | Val Loss: 0.4918 Acc: 0.7633\n",
      "Epoch 059 | Train Loss: 0.4630 Acc: 0.7894 | Val Loss: 0.4975 Acc: 0.7699\n",
      "Epoch 060 | Train Loss: 0.4639 Acc: 0.7865 | Val Loss: 0.4922 Acc: 0.7657\n",
      "Epoch 001 | Train Loss: 0.6811 Acc: 0.5760 | Val Loss: 0.6839 Acc: 0.5628\n",
      "Epoch 002 | Train Loss: 0.6745 Acc: 0.5886 | Val Loss: 0.6583 Acc: 0.6033\n",
      "Epoch 003 | Train Loss: 0.6439 Acc: 0.6332 | Val Loss: 0.6250 Acc: 0.6576\n",
      "Epoch 004 | Train Loss: 0.5831 Acc: 0.7026 | Val Loss: 0.5737 Acc: 0.6981\n",
      "Epoch 005 | Train Loss: 0.5489 Acc: 0.7352 | Val Loss: 0.5293 Acc: 0.7403\n",
      "Epoch 006 | Train Loss: 0.5166 Acc: 0.7497 | Val Loss: 0.4966 Acc: 0.7609\n",
      "Epoch 007 | Train Loss: 0.4886 Acc: 0.7700 | Val Loss: 0.4701 Acc: 0.7566\n",
      "Epoch 008 | Train Loss: 0.4673 Acc: 0.7794 | Val Loss: 0.4490 Acc: 0.7929\n",
      "Epoch 009 | Train Loss: 0.4268 Acc: 0.7987 | Val Loss: 0.4320 Acc: 0.7923\n",
      "Epoch 010 | Train Loss: 0.4157 Acc: 0.8110 | Val Loss: 0.4093 Acc: 0.8019\n",
      "Epoch 011 | Train Loss: 0.3764 Acc: 0.8323 | Val Loss: 0.4001 Acc: 0.8025\n",
      "Epoch 012 | Train Loss: 0.3574 Acc: 0.8430 | Val Loss: 0.3384 Acc: 0.8442\n",
      "Epoch 013 | Train Loss: 0.3354 Acc: 0.8501 | Val Loss: 0.3280 Acc: 0.8593\n",
      "Epoch 014 | Train Loss: 0.3103 Acc: 0.8670 | Val Loss: 0.3148 Acc: 0.8557\n",
      "Epoch 015 | Train Loss: 0.2893 Acc: 0.8727 | Val Loss: 0.3439 Acc: 0.8502\n",
      "Epoch 016 | Train Loss: 0.2881 Acc: 0.8782 | Val Loss: 0.2961 Acc: 0.8702\n",
      "Epoch 017 | Train Loss: 0.2613 Acc: 0.8948 | Val Loss: 0.2663 Acc: 0.8780\n",
      "Epoch 018 | Train Loss: 0.2452 Acc: 0.9019 | Val Loss: 0.2436 Acc: 0.9040\n",
      "Epoch 019 | Train Loss: 0.2246 Acc: 0.9068 | Val Loss: 0.2638 Acc: 0.8853\n",
      "Epoch 020 | Train Loss: 0.2198 Acc: 0.9129 | Val Loss: 0.2291 Acc: 0.9064\n",
      "Epoch 021 | Train Loss: 0.2094 Acc: 0.9156 | Val Loss: 0.2212 Acc: 0.9076\n",
      "Epoch 022 | Train Loss: 0.1884 Acc: 0.9271 | Val Loss: 0.2303 Acc: 0.9106\n",
      "Epoch 023 | Train Loss: 0.1896 Acc: 0.9215 | Val Loss: 0.2168 Acc: 0.9076\n",
      "Epoch 024 | Train Loss: 0.1713 Acc: 0.9318 | Val Loss: 0.1950 Acc: 0.9179\n",
      "Epoch 025 | Train Loss: 0.1539 Acc: 0.9361 | Val Loss: 0.1946 Acc: 0.9239\n",
      "Epoch 026 | Train Loss: 0.1459 Acc: 0.9408 | Val Loss: 0.2204 Acc: 0.9130\n",
      "Epoch 027 | Train Loss: 0.1561 Acc: 0.9384 | Val Loss: 0.1815 Acc: 0.9227\n",
      "Epoch 028 | Train Loss: 0.1395 Acc: 0.9444 | Val Loss: 0.1916 Acc: 0.9215\n",
      "Epoch 029 | Train Loss: 0.1342 Acc: 0.9476 | Val Loss: 0.1755 Acc: 0.9330\n",
      "Epoch 030 | Train Loss: 0.1315 Acc: 0.9517 | Val Loss: 0.1811 Acc: 0.9281\n",
      "Epoch 031 | Train Loss: 0.1176 Acc: 0.9549 | Val Loss: 0.1682 Acc: 0.9306\n",
      "Epoch 032 | Train Loss: 0.1131 Acc: 0.9562 | Val Loss: 0.2038 Acc: 0.9275\n",
      "Epoch 033 | Train Loss: 0.1138 Acc: 0.9552 | Val Loss: 0.1717 Acc: 0.9306\n",
      "Epoch 034 | Train Loss: 0.1105 Acc: 0.9574 | Val Loss: 0.1826 Acc: 0.9275\n",
      "Epoch 035 | Train Loss: 0.1178 Acc: 0.9562 | Val Loss: 0.1750 Acc: 0.9306\n",
      "Epoch 036 | Train Loss: 0.0998 Acc: 0.9607 | Val Loss: 0.1622 Acc: 0.9318\n",
      "Epoch 037 | Train Loss: 0.0946 Acc: 0.9678 | Val Loss: 0.2333 Acc: 0.9173\n",
      "Epoch 038 | Train Loss: 0.1013 Acc: 0.9623 | Val Loss: 0.1438 Acc: 0.9396\n",
      "Epoch 039 | Train Loss: 0.0874 Acc: 0.9659 | Val Loss: 0.2046 Acc: 0.9161\n",
      "Epoch 040 | Train Loss: 0.0996 Acc: 0.9630 | Val Loss: 0.1613 Acc: 0.9378\n",
      "Epoch 041 | Train Loss: 0.0886 Acc: 0.9677 | Val Loss: 0.1446 Acc: 0.9408\n",
      "Epoch 042 | Train Loss: 0.0781 Acc: 0.9718 | Val Loss: 0.1523 Acc: 0.9408\n",
      "Epoch 043 | Train Loss: 0.0810 Acc: 0.9706 | Val Loss: 0.1691 Acc: 0.9330\n",
      "Epoch 044 | Train Loss: 0.0812 Acc: 0.9689 | Val Loss: 0.1709 Acc: 0.9330\n",
      "Epoch 045 | Train Loss: 0.0829 Acc: 0.9681 | Val Loss: 0.1618 Acc: 0.9378\n",
      "Epoch 046 | Train Loss: 0.0706 Acc: 0.9734 | Val Loss: 0.1673 Acc: 0.9390\n",
      "Epoch 047 | Train Loss: 0.0734 Acc: 0.9730 | Val Loss: 0.1480 Acc: 0.9396\n",
      "Epoch 048 | Train Loss: 0.0651 Acc: 0.9767 | Val Loss: 0.1948 Acc: 0.9269\n",
      "Early stopping triggered.\n",
      "Epoch 001 | Train Loss: 0.6768 Acc: 0.5860 | Val Loss: 0.6772 Acc: 0.5882\n",
      "Epoch 002 | Train Loss: 0.6677 Acc: 0.6011 | Val Loss: 0.6513 Acc: 0.6335\n",
      "Epoch 003 | Train Loss: 0.6200 Acc: 0.6713 | Val Loss: 0.5951 Acc: 0.6842\n",
      "Epoch 004 | Train Loss: 0.5747 Acc: 0.7196 | Val Loss: 0.5677 Acc: 0.7132\n",
      "Epoch 005 | Train Loss: 0.5458 Acc: 0.7367 | Val Loss: 0.5469 Acc: 0.7234\n",
      "Epoch 006 | Train Loss: 0.5224 Acc: 0.7510 | Val Loss: 0.5163 Acc: 0.7488\n",
      "Epoch 007 | Train Loss: 0.4915 Acc: 0.7703 | Val Loss: 0.4941 Acc: 0.7579\n",
      "Epoch 008 | Train Loss: 0.4810 Acc: 0.7691 | Val Loss: 0.5014 Acc: 0.7560\n",
      "Epoch 009 | Train Loss: 0.4517 Acc: 0.7897 | Val Loss: 0.4545 Acc: 0.7808\n",
      "Epoch 010 | Train Loss: 0.4298 Acc: 0.8007 | Val Loss: 0.4750 Acc: 0.7748\n",
      "Epoch 011 | Train Loss: 0.3968 Acc: 0.8182 | Val Loss: 0.4030 Acc: 0.8074\n",
      "Epoch 012 | Train Loss: 0.3807 Acc: 0.8297 | Val Loss: 0.3826 Acc: 0.8207\n",
      "Epoch 013 | Train Loss: 0.3579 Acc: 0.8430 | Val Loss: 0.3755 Acc: 0.8170\n",
      "Epoch 014 | Train Loss: 0.3376 Acc: 0.8569 | Val Loss: 0.3429 Acc: 0.8472\n",
      "Epoch 015 | Train Loss: 0.3093 Acc: 0.8676 | Val Loss: 0.3089 Acc: 0.8671\n",
      "Epoch 016 | Train Loss: 0.3033 Acc: 0.8670 | Val Loss: 0.2892 Acc: 0.8780\n",
      "Epoch 017 | Train Loss: 0.2650 Acc: 0.8874 | Val Loss: 0.2795 Acc: 0.8810\n",
      "Epoch 018 | Train Loss: 0.2598 Acc: 0.8945 | Val Loss: 0.3156 Acc: 0.8774\n",
      "Epoch 019 | Train Loss: 0.2481 Acc: 0.9034 | Val Loss: 0.2899 Acc: 0.8659\n",
      "Epoch 020 | Train Loss: 0.2298 Acc: 0.9076 | Val Loss: 0.2461 Acc: 0.8998\n",
      "Epoch 021 | Train Loss: 0.2206 Acc: 0.9085 | Val Loss: 0.2256 Acc: 0.9106\n",
      "Epoch 022 | Train Loss: 0.2020 Acc: 0.9222 | Val Loss: 0.2146 Acc: 0.9070\n",
      "Epoch 023 | Train Loss: 0.1884 Acc: 0.9265 | Val Loss: 0.2090 Acc: 0.9064\n",
      "Epoch 024 | Train Loss: 0.1803 Acc: 0.9257 | Val Loss: 0.2171 Acc: 0.9112\n",
      "Epoch 025 | Train Loss: 0.1716 Acc: 0.9357 | Val Loss: 0.2111 Acc: 0.9167\n",
      "Epoch 026 | Train Loss: 0.1630 Acc: 0.9367 | Val Loss: 0.2715 Acc: 0.8877\n",
      "Epoch 027 | Train Loss: 0.1667 Acc: 0.9330 | Val Loss: 0.1994 Acc: 0.9161\n",
      "Epoch 028 | Train Loss: 0.1488 Acc: 0.9444 | Val Loss: 0.2017 Acc: 0.9197\n",
      "Epoch 029 | Train Loss: 0.1522 Acc: 0.9414 | Val Loss: 0.1889 Acc: 0.9257\n",
      "Epoch 030 | Train Loss: 0.1396 Acc: 0.9446 | Val Loss: 0.1973 Acc: 0.9257\n",
      "Epoch 031 | Train Loss: 0.1426 Acc: 0.9444 | Val Loss: 0.2002 Acc: 0.9239\n",
      "Epoch 032 | Train Loss: 0.1325 Acc: 0.9529 | Val Loss: 0.2010 Acc: 0.9233\n",
      "Epoch 033 | Train Loss: 0.1267 Acc: 0.9535 | Val Loss: 0.2004 Acc: 0.9149\n",
      "Epoch 034 | Train Loss: 0.1354 Acc: 0.9485 | Val Loss: 0.1895 Acc: 0.9281\n",
      "Epoch 035 | Train Loss: 0.1193 Acc: 0.9520 | Val Loss: 0.2273 Acc: 0.9112\n",
      "Epoch 036 | Train Loss: 0.1247 Acc: 0.9570 | Val Loss: 0.1675 Acc: 0.9318\n",
      "Epoch 037 | Train Loss: 0.1140 Acc: 0.9559 | Val Loss: 0.1785 Acc: 0.9281\n",
      "Epoch 038 | Train Loss: 0.1048 Acc: 0.9600 | Val Loss: 0.2172 Acc: 0.9245\n",
      "Epoch 039 | Train Loss: 0.1084 Acc: 0.9598 | Val Loss: 0.1899 Acc: 0.9239\n",
      "Epoch 040 | Train Loss: 0.1005 Acc: 0.9632 | Val Loss: 0.1642 Acc: 0.9342\n",
      "Epoch 041 | Train Loss: 0.0968 Acc: 0.9641 | Val Loss: 0.1719 Acc: 0.9233\n",
      "Epoch 042 | Train Loss: 0.0888 Acc: 0.9692 | Val Loss: 0.1591 Acc: 0.9402\n",
      "Epoch 043 | Train Loss: 0.1010 Acc: 0.9621 | Val Loss: 0.1660 Acc: 0.9372\n",
      "Epoch 044 | Train Loss: 0.0958 Acc: 0.9662 | Val Loss: 0.1539 Acc: 0.9438\n",
      "Epoch 045 | Train Loss: 0.0940 Acc: 0.9638 | Val Loss: 0.1658 Acc: 0.9438\n",
      "Epoch 046 | Train Loss: 0.0819 Acc: 0.9712 | Val Loss: 0.1637 Acc: 0.9402\n",
      "Epoch 047 | Train Loss: 0.0943 Acc: 0.9635 | Val Loss: 0.1953 Acc: 0.9287\n",
      "Epoch 048 | Train Loss: 0.0929 Acc: 0.9660 | Val Loss: 0.1716 Acc: 0.9402\n",
      "Epoch 049 | Train Loss: 0.0829 Acc: 0.9706 | Val Loss: 0.1886 Acc: 0.9342\n",
      "Epoch 050 | Train Loss: 0.0810 Acc: 0.9689 | Val Loss: 0.1808 Acc: 0.9420\n",
      "Epoch 051 | Train Loss: 0.0741 Acc: 0.9740 | Val Loss: 0.2554 Acc: 0.9336\n",
      "Epoch 052 | Train Loss: 0.0944 Acc: 0.9657 | Val Loss: 0.1909 Acc: 0.9300\n",
      "Epoch 053 | Train Loss: 0.0813 Acc: 0.9700 | Val Loss: 0.1615 Acc: 0.9426\n",
      "Epoch 054 | Train Loss: 0.0840 Acc: 0.9689 | Val Loss: 0.1999 Acc: 0.9378\n",
      "Early stopping triggered.\n",
      "Epoch 001 | Train Loss: 0.6842 Acc: 0.5692 | Val Loss: 0.6805 Acc: 0.5815\n",
      "Epoch 002 | Train Loss: 0.6755 Acc: 0.5910 | Val Loss: 0.6699 Acc: 0.5888\n",
      "Epoch 003 | Train Loss: 0.6624 Acc: 0.6000 | Val Loss: 0.6552 Acc: 0.6093\n",
      "Epoch 004 | Train Loss: 0.6327 Acc: 0.6520 | Val Loss: 0.6586 Acc: 0.6196\n",
      "Epoch 005 | Train Loss: 0.5887 Acc: 0.7047 | Val Loss: 0.5812 Acc: 0.7053\n",
      "Epoch 006 | Train Loss: 0.5491 Acc: 0.7349 | Val Loss: 0.5630 Acc: 0.7126\n",
      "Epoch 007 | Train Loss: 0.5360 Acc: 0.7400 | Val Loss: 0.5757 Acc: 0.7198\n",
      "Epoch 008 | Train Loss: 0.5049 Acc: 0.7664 | Val Loss: 0.5187 Acc: 0.7434\n",
      "Epoch 009 | Train Loss: 0.4975 Acc: 0.7590 | Val Loss: 0.5007 Acc: 0.7440\n",
      "Epoch 010 | Train Loss: 0.4652 Acc: 0.7800 | Val Loss: 0.4557 Acc: 0.7820\n",
      "Epoch 011 | Train Loss: 0.4335 Acc: 0.7947 | Val Loss: 0.4345 Acc: 0.7886\n",
      "Epoch 012 | Train Loss: 0.4270 Acc: 0.7990 | Val Loss: 0.4365 Acc: 0.7778\n",
      "Epoch 013 | Train Loss: 0.4036 Acc: 0.8126 | Val Loss: 0.4031 Acc: 0.8086\n",
      "Epoch 014 | Train Loss: 0.3850 Acc: 0.8235 | Val Loss: 0.4305 Acc: 0.8013\n",
      "Epoch 015 | Train Loss: 0.3654 Acc: 0.8326 | Val Loss: 0.3763 Acc: 0.8237\n",
      "Epoch 016 | Train Loss: 0.3541 Acc: 0.8404 | Val Loss: 0.4040 Acc: 0.8050\n",
      "Epoch 017 | Train Loss: 0.3360 Acc: 0.8501 | Val Loss: 0.3496 Acc: 0.8514\n",
      "Epoch 018 | Train Loss: 0.3159 Acc: 0.8652 | Val Loss: 0.3392 Acc: 0.8484\n",
      "Epoch 019 | Train Loss: 0.3065 Acc: 0.8697 | Val Loss: 0.3465 Acc: 0.8490\n",
      "Epoch 020 | Train Loss: 0.2938 Acc: 0.8717 | Val Loss: 0.2977 Acc: 0.8810\n",
      "Epoch 021 | Train Loss: 0.2711 Acc: 0.8878 | Val Loss: 0.3016 Acc: 0.8750\n",
      "Epoch 022 | Train Loss: 0.2639 Acc: 0.8848 | Val Loss: 0.2849 Acc: 0.8756\n",
      "Epoch 023 | Train Loss: 0.2424 Acc: 0.9016 | Val Loss: 0.2674 Acc: 0.8919\n",
      "Epoch 024 | Train Loss: 0.2142 Acc: 0.9100 | Val Loss: 0.2578 Acc: 0.8937\n",
      "Epoch 025 | Train Loss: 0.2119 Acc: 0.9130 | Val Loss: 0.2515 Acc: 0.9004\n",
      "Epoch 026 | Train Loss: 0.1988 Acc: 0.9197 | Val Loss: 0.2379 Acc: 0.9100\n",
      "Epoch 027 | Train Loss: 0.1887 Acc: 0.9234 | Val Loss: 0.2543 Acc: 0.8979\n",
      "Epoch 028 | Train Loss: 0.1821 Acc: 0.9298 | Val Loss: 0.2179 Acc: 0.9143\n",
      "Epoch 029 | Train Loss: 0.1702 Acc: 0.9327 | Val Loss: 0.2152 Acc: 0.9203\n",
      "Epoch 030 | Train Loss: 0.1591 Acc: 0.9367 | Val Loss: 0.2000 Acc: 0.9257\n",
      "Epoch 031 | Train Loss: 0.1528 Acc: 0.9411 | Val Loss: 0.2181 Acc: 0.9215\n",
      "Epoch 032 | Train Loss: 0.1401 Acc: 0.9452 | Val Loss: 0.2286 Acc: 0.9112\n",
      "Epoch 033 | Train Loss: 0.1300 Acc: 0.9506 | Val Loss: 0.2896 Acc: 0.8943\n",
      "Epoch 034 | Train Loss: 0.1379 Acc: 0.9459 | Val Loss: 0.1915 Acc: 0.9336\n",
      "Epoch 035 | Train Loss: 0.1228 Acc: 0.9538 | Val Loss: 0.2012 Acc: 0.9324\n",
      "Epoch 036 | Train Loss: 0.1135 Acc: 0.9549 | Val Loss: 0.1877 Acc: 0.9306\n",
      "Epoch 037 | Train Loss: 0.1179 Acc: 0.9533 | Val Loss: 0.1928 Acc: 0.9269\n",
      "Epoch 038 | Train Loss: 0.1081 Acc: 0.9600 | Val Loss: 0.2133 Acc: 0.9330\n",
      "Epoch 039 | Train Loss: 0.1106 Acc: 0.9568 | Val Loss: 0.1682 Acc: 0.9426\n",
      "Epoch 040 | Train Loss: 0.1130 Acc: 0.9579 | Val Loss: 0.1694 Acc: 0.9390\n",
      "Epoch 041 | Train Loss: 0.0947 Acc: 0.9648 | Val Loss: 0.2135 Acc: 0.9215\n",
      "Epoch 042 | Train Loss: 0.0893 Acc: 0.9697 | Val Loss: 0.1951 Acc: 0.9330\n",
      "Epoch 043 | Train Loss: 0.1012 Acc: 0.9604 | Val Loss: 0.1836 Acc: 0.9366\n",
      "Epoch 044 | Train Loss: 0.0855 Acc: 0.9695 | Val Loss: 0.1799 Acc: 0.9396\n",
      "Epoch 045 | Train Loss: 0.0743 Acc: 0.9743 | Val Loss: 0.1769 Acc: 0.9396\n",
      "Epoch 046 | Train Loss: 0.0848 Acc: 0.9674 | Val Loss: 0.1832 Acc: 0.9420\n",
      "Epoch 047 | Train Loss: 0.0807 Acc: 0.9701 | Val Loss: 0.1996 Acc: 0.9390\n",
      "Epoch 048 | Train Loss: 0.0673 Acc: 0.9764 | Val Loss: 0.2022 Acc: 0.9330\n",
      "Epoch 049 | Train Loss: 0.0747 Acc: 0.9715 | Val Loss: 0.1892 Acc: 0.9372\n",
      "Early stopping triggered.\n",
      "Epoch 001 | Train Loss: 0.6784 Acc: 0.5813 | Val Loss: 0.6812 Acc: 0.5809\n",
      "Epoch 002 | Train Loss: 0.6715 Acc: 0.5919 | Val Loss: 0.6578 Acc: 0.5966\n",
      "Epoch 003 | Train Loss: 0.6458 Acc: 0.6366 | Val Loss: 0.6436 Acc: 0.6322\n",
      "Epoch 004 | Train Loss: 0.5924 Acc: 0.6941 | Val Loss: 0.5779 Acc: 0.7059\n",
      "Epoch 005 | Train Loss: 0.5527 Acc: 0.7293 | Val Loss: 0.5526 Acc: 0.7246\n",
      "Epoch 006 | Train Loss: 0.5353 Acc: 0.7368 | Val Loss: 0.5231 Acc: 0.7343\n",
      "Epoch 007 | Train Loss: 0.5110 Acc: 0.7571 | Val Loss: 0.4975 Acc: 0.7566\n",
      "Epoch 008 | Train Loss: 0.4887 Acc: 0.7649 | Val Loss: 0.4797 Acc: 0.7609\n",
      "Epoch 009 | Train Loss: 0.4675 Acc: 0.7788 | Val Loss: 0.4423 Acc: 0.7959\n",
      "Epoch 010 | Train Loss: 0.4426 Acc: 0.7953 | Val Loss: 0.4106 Acc: 0.8056\n",
      "Epoch 011 | Train Loss: 0.4207 Acc: 0.8093 | Val Loss: 0.3937 Acc: 0.8062\n",
      "Epoch 012 | Train Loss: 0.3929 Acc: 0.8191 | Val Loss: 0.3866 Acc: 0.8152\n",
      "Epoch 013 | Train Loss: 0.3755 Acc: 0.8381 | Val Loss: 0.3663 Acc: 0.8357\n",
      "Epoch 014 | Train Loss: 0.3680 Acc: 0.8386 | Val Loss: 0.3344 Acc: 0.8551\n",
      "Epoch 015 | Train Loss: 0.3287 Acc: 0.8552 | Val Loss: 0.3157 Acc: 0.8581\n",
      "Epoch 016 | Train Loss: 0.3127 Acc: 0.8664 | Val Loss: 0.3127 Acc: 0.8629\n",
      "Epoch 017 | Train Loss: 0.2867 Acc: 0.8786 | Val Loss: 0.2653 Acc: 0.8943\n",
      "Epoch 018 | Train Loss: 0.2783 Acc: 0.8843 | Val Loss: 0.2606 Acc: 0.8871\n",
      "Epoch 019 | Train Loss: 0.2727 Acc: 0.8854 | Val Loss: 0.2381 Acc: 0.9046\n",
      "Epoch 020 | Train Loss: 0.2524 Acc: 0.8939 | Val Loss: 0.2460 Acc: 0.8961\n",
      "Epoch 021 | Train Loss: 0.2564 Acc: 0.8919 | Val Loss: 0.2743 Acc: 0.8798\n",
      "Epoch 022 | Train Loss: 0.2289 Acc: 0.9088 | Val Loss: 0.2296 Acc: 0.9070\n",
      "Epoch 023 | Train Loss: 0.2120 Acc: 0.9180 | Val Loss: 0.2202 Acc: 0.9130\n",
      "Epoch 024 | Train Loss: 0.2020 Acc: 0.9170 | Val Loss: 0.2437 Acc: 0.9028\n",
      "Epoch 025 | Train Loss: 0.1987 Acc: 0.9204 | Val Loss: 0.2187 Acc: 0.9143\n",
      "Epoch 026 | Train Loss: 0.1815 Acc: 0.9262 | Val Loss: 0.2024 Acc: 0.9179\n",
      "Epoch 027 | Train Loss: 0.1836 Acc: 0.9277 | Val Loss: 0.1913 Acc: 0.9263\n",
      "Epoch 028 | Train Loss: 0.1831 Acc: 0.9234 | Val Loss: 0.1909 Acc: 0.9269\n",
      "Epoch 029 | Train Loss: 0.1638 Acc: 0.9324 | Val Loss: 0.1714 Acc: 0.9300\n",
      "Epoch 030 | Train Loss: 0.1601 Acc: 0.9364 | Val Loss: 0.2006 Acc: 0.9167\n",
      "Epoch 031 | Train Loss: 0.1538 Acc: 0.9395 | Val Loss: 0.1591 Acc: 0.9366\n",
      "Epoch 032 | Train Loss: 0.1516 Acc: 0.9417 | Val Loss: 0.2142 Acc: 0.9143\n",
      "Epoch 033 | Train Loss: 0.1511 Acc: 0.9425 | Val Loss: 0.1543 Acc: 0.9396\n",
      "Epoch 034 | Train Loss: 0.1381 Acc: 0.9484 | Val Loss: 0.1696 Acc: 0.9330\n",
      "Epoch 035 | Train Loss: 0.1279 Acc: 0.9515 | Val Loss: 0.1824 Acc: 0.9306\n",
      "Epoch 036 | Train Loss: 0.1298 Acc: 0.9503 | Val Loss: 0.1664 Acc: 0.9432\n",
      "Epoch 037 | Train Loss: 0.1211 Acc: 0.9533 | Val Loss: 0.1574 Acc: 0.9348\n",
      "Epoch 038 | Train Loss: 0.1292 Acc: 0.9529 | Val Loss: 0.1620 Acc: 0.9384\n",
      "Epoch 039 | Train Loss: 0.1215 Acc: 0.9562 | Val Loss: 0.1642 Acc: 0.9354\n",
      "Epoch 040 | Train Loss: 0.1247 Acc: 0.9558 | Val Loss: 0.1532 Acc: 0.9463\n",
      "Epoch 041 | Train Loss: 0.1180 Acc: 0.9571 | Val Loss: 0.1664 Acc: 0.9330\n",
      "Epoch 042 | Train Loss: 0.1178 Acc: 0.9552 | Val Loss: 0.1525 Acc: 0.9511\n",
      "Epoch 043 | Train Loss: 0.1096 Acc: 0.9613 | Val Loss: 0.1609 Acc: 0.9450\n",
      "Epoch 044 | Train Loss: 0.0960 Acc: 0.9644 | Val Loss: 0.1693 Acc: 0.9426\n",
      "Epoch 045 | Train Loss: 0.1029 Acc: 0.9606 | Val Loss: 0.1477 Acc: 0.9444\n",
      "Epoch 046 | Train Loss: 0.0977 Acc: 0.9623 | Val Loss: 0.1671 Acc: 0.9444\n",
      "Epoch 047 | Train Loss: 0.0982 Acc: 0.9636 | Val Loss: 0.1763 Acc: 0.9414\n",
      "Epoch 048 | Train Loss: 0.0943 Acc: 0.9616 | Val Loss: 0.1467 Acc: 0.9517\n",
      "Epoch 049 | Train Loss: 0.1010 Acc: 0.9641 | Val Loss: 0.1456 Acc: 0.9487\n",
      "Epoch 050 | Train Loss: 0.0967 Acc: 0.9662 | Val Loss: 0.1276 Acc: 0.9547\n",
      "Epoch 051 | Train Loss: 0.0936 Acc: 0.9669 | Val Loss: 0.1363 Acc: 0.9529\n",
      "Epoch 052 | Train Loss: 0.0880 Acc: 0.9697 | Val Loss: 0.1319 Acc: 0.9523\n",
      "Epoch 053 | Train Loss: 0.0906 Acc: 0.9656 | Val Loss: 0.1412 Acc: 0.9553\n",
      "Epoch 054 | Train Loss: 0.0795 Acc: 0.9719 | Val Loss: 0.1586 Acc: 0.9481\n",
      "Epoch 055 | Train Loss: 0.0930 Acc: 0.9650 | Val Loss: 0.1401 Acc: 0.9438\n",
      "Epoch 056 | Train Loss: 0.0822 Acc: 0.9706 | Val Loss: 0.1337 Acc: 0.9577\n",
      "Epoch 057 | Train Loss: 0.0840 Acc: 0.9683 | Val Loss: 0.1322 Acc: 0.9523\n",
      "Epoch 058 | Train Loss: 0.0850 Acc: 0.9681 | Val Loss: 0.1298 Acc: 0.9481\n",
      "Epoch 059 | Train Loss: 0.0818 Acc: 0.9689 | Val Loss: 0.1434 Acc: 0.9517\n",
      "Epoch 060 | Train Loss: 0.0816 Acc: 0.9674 | Val Loss: 0.1452 Acc: 0.9529\n",
      "Early stopping triggered.\n",
      "Epoch 001 | Train Loss: 0.6783 Acc: 0.5860 | Val Loss: 0.6696 Acc: 0.5978\n",
      "Epoch 002 | Train Loss: 0.6670 Acc: 0.6121 | Val Loss: 0.6625 Acc: 0.6123\n",
      "Epoch 003 | Train Loss: 0.6633 Acc: 0.6138 | Val Loss: 0.6614 Acc: 0.6141\n",
      "Epoch 004 | Train Loss: 0.6455 Acc: 0.6289 | Val Loss: 0.6186 Acc: 0.6546\n",
      "Epoch 005 | Train Loss: 0.5851 Acc: 0.7086 | Val Loss: 0.5806 Acc: 0.6987\n",
      "Epoch 006 | Train Loss: 0.5403 Acc: 0.7364 | Val Loss: 0.6043 Acc: 0.7059\n",
      "Epoch 007 | Train Loss: 0.5146 Acc: 0.7510 | Val Loss: 0.5433 Acc: 0.7337\n",
      "Epoch 008 | Train Loss: 0.4899 Acc: 0.7719 | Val Loss: 0.4803 Acc: 0.7748\n",
      "Epoch 009 | Train Loss: 0.4554 Acc: 0.7886 | Val Loss: 0.4759 Acc: 0.7742\n",
      "Epoch 010 | Train Loss: 0.4239 Acc: 0.8057 | Val Loss: 0.4234 Acc: 0.8037\n",
      "Epoch 011 | Train Loss: 0.4179 Acc: 0.8158 | Val Loss: 0.4307 Acc: 0.8013\n",
      "Epoch 012 | Train Loss: 0.3781 Acc: 0.8354 | Val Loss: 0.3985 Acc: 0.8176\n",
      "Epoch 013 | Train Loss: 0.3511 Acc: 0.8477 | Val Loss: 0.3814 Acc: 0.8255\n",
      "Epoch 014 | Train Loss: 0.3183 Acc: 0.8649 | Val Loss: 0.3509 Acc: 0.8345\n",
      "Epoch 015 | Train Loss: 0.3105 Acc: 0.8692 | Val Loss: 0.3429 Acc: 0.8472\n",
      "Epoch 016 | Train Loss: 0.2997 Acc: 0.8739 | Val Loss: 0.3109 Acc: 0.8587\n",
      "Epoch 017 | Train Loss: 0.2748 Acc: 0.8846 | Val Loss: 0.2708 Acc: 0.8907\n",
      "Epoch 018 | Train Loss: 0.2630 Acc: 0.8904 | Val Loss: 0.2680 Acc: 0.8913\n",
      "Epoch 019 | Train Loss: 0.2530 Acc: 0.8984 | Val Loss: 0.2837 Acc: 0.8816\n",
      "Epoch 020 | Train Loss: 0.2297 Acc: 0.9083 | Val Loss: 0.2642 Acc: 0.8835\n",
      "Epoch 021 | Train Loss: 0.2121 Acc: 0.9133 | Val Loss: 0.2467 Acc: 0.9058\n",
      "Epoch 022 | Train Loss: 0.1952 Acc: 0.9219 | Val Loss: 0.2594 Acc: 0.8986\n",
      "Epoch 023 | Train Loss: 0.1974 Acc: 0.9228 | Val Loss: 0.2483 Acc: 0.8979\n",
      "Epoch 024 | Train Loss: 0.1964 Acc: 0.9215 | Val Loss: 0.2348 Acc: 0.9143\n",
      "Epoch 025 | Train Loss: 0.1719 Acc: 0.9307 | Val Loss: 0.2447 Acc: 0.9010\n",
      "Epoch 026 | Train Loss: 0.1790 Acc: 0.9296 | Val Loss: 0.2193 Acc: 0.9149\n",
      "Epoch 027 | Train Loss: 0.1573 Acc: 0.9407 | Val Loss: 0.2191 Acc: 0.9136\n",
      "Epoch 028 | Train Loss: 0.1543 Acc: 0.9393 | Val Loss: 0.2425 Acc: 0.9100\n",
      "Epoch 029 | Train Loss: 0.1605 Acc: 0.9385 | Val Loss: 0.2489 Acc: 0.9070\n",
      "Epoch 030 | Train Loss: 0.1597 Acc: 0.9363 | Val Loss: 0.2162 Acc: 0.9173\n",
      "Epoch 031 | Train Loss: 0.1420 Acc: 0.9485 | Val Loss: 0.1864 Acc: 0.9324\n",
      "Epoch 032 | Train Loss: 0.1336 Acc: 0.9493 | Val Loss: 0.2122 Acc: 0.9191\n",
      "Epoch 033 | Train Loss: 0.1310 Acc: 0.9505 | Val Loss: 0.1972 Acc: 0.9306\n",
      "Epoch 034 | Train Loss: 0.1352 Acc: 0.9499 | Val Loss: 0.1825 Acc: 0.9336\n",
      "Epoch 035 | Train Loss: 0.1241 Acc: 0.9514 | Val Loss: 0.2623 Acc: 0.9064\n",
      "Epoch 036 | Train Loss: 0.1171 Acc: 0.9579 | Val Loss: 0.2179 Acc: 0.9227\n",
      "Epoch 037 | Train Loss: 0.1128 Acc: 0.9546 | Val Loss: 0.1834 Acc: 0.9281\n",
      "Epoch 038 | Train Loss: 0.1148 Acc: 0.9556 | Val Loss: 0.2051 Acc: 0.9275\n",
      "Epoch 039 | Train Loss: 0.1196 Acc: 0.9539 | Val Loss: 0.1992 Acc: 0.9275\n",
      "Epoch 040 | Train Loss: 0.0986 Acc: 0.9675 | Val Loss: 0.2422 Acc: 0.9203\n",
      "Epoch 041 | Train Loss: 0.1087 Acc: 0.9620 | Val Loss: 0.2028 Acc: 0.9324\n",
      "Epoch 042 | Train Loss: 0.1177 Acc: 0.9582 | Val Loss: 0.1776 Acc: 0.9306\n",
      "Epoch 043 | Train Loss: 0.0995 Acc: 0.9624 | Val Loss: 0.2206 Acc: 0.9239\n",
      "Epoch 044 | Train Loss: 0.0936 Acc: 0.9656 | Val Loss: 0.2058 Acc: 0.9275\n",
      "Epoch 045 | Train Loss: 0.0956 Acc: 0.9644 | Val Loss: 0.1929 Acc: 0.9312\n",
      "Epoch 046 | Train Loss: 0.0951 Acc: 0.9657 | Val Loss: 0.1839 Acc: 0.9306\n",
      "Epoch 047 | Train Loss: 0.1006 Acc: 0.9607 | Val Loss: 0.1971 Acc: 0.9312\n",
      "Epoch 048 | Train Loss: 0.0970 Acc: 0.9618 | Val Loss: 0.2127 Acc: 0.9306\n",
      "Epoch 049 | Train Loss: 0.0984 Acc: 0.9657 | Val Loss: 0.1735 Acc: 0.9330\n",
      "Epoch 050 | Train Loss: 0.0917 Acc: 0.9677 | Val Loss: 0.2124 Acc: 0.9239\n",
      "Epoch 051 | Train Loss: 0.1010 Acc: 0.9659 | Val Loss: 0.1986 Acc: 0.9312\n",
      "Epoch 052 | Train Loss: 0.0969 Acc: 0.9650 | Val Loss: 0.2102 Acc: 0.9269\n",
      "Epoch 053 | Train Loss: 0.0908 Acc: 0.9668 | Val Loss: 0.1769 Acc: 0.9390\n",
      "Epoch 054 | Train Loss: 0.0852 Acc: 0.9701 | Val Loss: 0.1822 Acc: 0.9414\n",
      "Epoch 055 | Train Loss: 0.0844 Acc: 0.9698 | Val Loss: 0.2014 Acc: 0.9312\n",
      "Epoch 056 | Train Loss: 0.0763 Acc: 0.9725 | Val Loss: 0.1811 Acc: 0.9287\n",
      "Epoch 057 | Train Loss: 0.0876 Acc: 0.9662 | Val Loss: 0.1771 Acc: 0.9360\n",
      "Epoch 058 | Train Loss: 0.0869 Acc: 0.9672 | Val Loss: 0.1833 Acc: 0.9348\n",
      "Epoch 059 | Train Loss: 0.0736 Acc: 0.9740 | Val Loss: 0.2310 Acc: 0.9306\n",
      "Early stopping triggered.\n",
      "Epoch 001 | Train Loss: 0.6785 Acc: 0.5821 | Val Loss: 0.6745 Acc: 0.5906\n",
      "Epoch 002 | Train Loss: 0.6768 Acc: 0.5887 | Val Loss: 0.6724 Acc: 0.5906\n",
      "Epoch 003 | Train Loss: 0.6394 Acc: 0.6435 | Val Loss: 0.6291 Acc: 0.6486\n",
      "Epoch 004 | Train Loss: 0.5851 Acc: 0.6994 | Val Loss: 0.5731 Acc: 0.7041\n",
      "Epoch 005 | Train Loss: 0.5573 Acc: 0.7193 | Val Loss: 0.5504 Acc: 0.7168\n",
      "Epoch 006 | Train Loss: 0.5328 Acc: 0.7423 | Val Loss: 0.5315 Acc: 0.7397\n",
      "Epoch 007 | Train Loss: 0.5073 Acc: 0.7559 | Val Loss: 0.5078 Acc: 0.7554\n",
      "Epoch 008 | Train Loss: 0.4808 Acc: 0.7691 | Val Loss: 0.4578 Acc: 0.7754\n",
      "Epoch 009 | Train Loss: 0.4623 Acc: 0.7838 | Val Loss: 0.4547 Acc: 0.7784\n",
      "Epoch 010 | Train Loss: 0.4367 Acc: 0.7981 | Val Loss: 0.4217 Acc: 0.8056\n",
      "Epoch 011 | Train Loss: 0.4086 Acc: 0.8134 | Val Loss: 0.4403 Acc: 0.7868\n",
      "Epoch 012 | Train Loss: 0.3896 Acc: 0.8215 | Val Loss: 0.3823 Acc: 0.8207\n",
      "Epoch 013 | Train Loss: 0.3671 Acc: 0.8360 | Val Loss: 0.3902 Acc: 0.8110\n",
      "Epoch 014 | Train Loss: 0.3533 Acc: 0.8467 | Val Loss: 0.3781 Acc: 0.8376\n",
      "Epoch 015 | Train Loss: 0.3347 Acc: 0.8535 | Val Loss: 0.3507 Acc: 0.8394\n",
      "Epoch 016 | Train Loss: 0.3136 Acc: 0.8646 | Val Loss: 0.3120 Acc: 0.8647\n",
      "Epoch 017 | Train Loss: 0.3053 Acc: 0.8714 | Val Loss: 0.2829 Acc: 0.8732\n",
      "Epoch 018 | Train Loss: 0.2788 Acc: 0.8852 | Val Loss: 0.2982 Acc: 0.8690\n",
      "Epoch 019 | Train Loss: 0.2594 Acc: 0.8945 | Val Loss: 0.2536 Acc: 0.8907\n",
      "Epoch 020 | Train Loss: 0.2654 Acc: 0.8881 | Val Loss: 0.2721 Acc: 0.8883\n",
      "Epoch 021 | Train Loss: 0.2516 Acc: 0.9011 | Val Loss: 0.2705 Acc: 0.8919\n",
      "Epoch 022 | Train Loss: 0.2310 Acc: 0.9083 | Val Loss: 0.2537 Acc: 0.8949\n",
      "Epoch 023 | Train Loss: 0.2155 Acc: 0.9121 | Val Loss: 0.2254 Acc: 0.9088\n",
      "Epoch 024 | Train Loss: 0.2105 Acc: 0.9130 | Val Loss: 0.2257 Acc: 0.9136\n",
      "Epoch 025 | Train Loss: 0.1949 Acc: 0.9234 | Val Loss: 0.2226 Acc: 0.9016\n",
      "Epoch 026 | Train Loss: 0.1993 Acc: 0.9207 | Val Loss: 0.2135 Acc: 0.9179\n",
      "Epoch 027 | Train Loss: 0.1846 Acc: 0.9256 | Val Loss: 0.2373 Acc: 0.9136\n",
      "Epoch 028 | Train Loss: 0.1686 Acc: 0.9330 | Val Loss: 0.2161 Acc: 0.9185\n",
      "Epoch 029 | Train Loss: 0.2204 Acc: 0.9123 | Val Loss: 0.2120 Acc: 0.9143\n",
      "Epoch 030 | Train Loss: 0.1735 Acc: 0.9357 | Val Loss: 0.2087 Acc: 0.9161\n",
      "Epoch 031 | Train Loss: 0.1584 Acc: 0.9387 | Val Loss: 0.2081 Acc: 0.9227\n",
      "Epoch 032 | Train Loss: 0.1587 Acc: 0.9378 | Val Loss: 0.1988 Acc: 0.9221\n",
      "Epoch 033 | Train Loss: 0.1448 Acc: 0.9459 | Val Loss: 0.1844 Acc: 0.9318\n",
      "Epoch 034 | Train Loss: 0.1381 Acc: 0.9459 | Val Loss: 0.1965 Acc: 0.9233\n",
      "Epoch 035 | Train Loss: 0.1332 Acc: 0.9485 | Val Loss: 0.1861 Acc: 0.9281\n",
      "Epoch 036 | Train Loss: 0.1358 Acc: 0.9476 | Val Loss: 0.1972 Acc: 0.9300\n",
      "Epoch 037 | Train Loss: 0.1423 Acc: 0.9432 | Val Loss: 0.1550 Acc: 0.9384\n",
      "Epoch 038 | Train Loss: 0.1202 Acc: 0.9568 | Val Loss: 0.1637 Acc: 0.9378\n",
      "Epoch 039 | Train Loss: 0.1287 Acc: 0.9508 | Val Loss: 0.1970 Acc: 0.9269\n",
      "Epoch 040 | Train Loss: 0.1160 Acc: 0.9586 | Val Loss: 0.1524 Acc: 0.9432\n",
      "Epoch 041 | Train Loss: 0.1119 Acc: 0.9588 | Val Loss: 0.1503 Acc: 0.9414\n",
      "Epoch 042 | Train Loss: 0.1042 Acc: 0.9623 | Val Loss: 0.1414 Acc: 0.9457\n",
      "Epoch 043 | Train Loss: 0.1061 Acc: 0.9591 | Val Loss: 0.1821 Acc: 0.9324\n",
      "Epoch 044 | Train Loss: 0.1051 Acc: 0.9607 | Val Loss: 0.1456 Acc: 0.9505\n",
      "Epoch 045 | Train Loss: 0.0917 Acc: 0.9666 | Val Loss: 0.1625 Acc: 0.9481\n",
      "Epoch 046 | Train Loss: 0.1084 Acc: 0.9597 | Val Loss: 0.1589 Acc: 0.9457\n",
      "Epoch 047 | Train Loss: 0.0949 Acc: 0.9650 | Val Loss: 0.1484 Acc: 0.9493\n",
      "Epoch 048 | Train Loss: 0.1061 Acc: 0.9620 | Val Loss: 0.1535 Acc: 0.9408\n",
      "Epoch 049 | Train Loss: 0.1022 Acc: 0.9627 | Val Loss: 0.1477 Acc: 0.9463\n",
      "Epoch 050 | Train Loss: 0.0899 Acc: 0.9651 | Val Loss: 0.1626 Acc: 0.9390\n",
      "Epoch 051 | Train Loss: 0.0891 Acc: 0.9663 | Val Loss: 0.1467 Acc: 0.9475\n",
      "Epoch 052 | Train Loss: 0.0969 Acc: 0.9638 | Val Loss: 0.1524 Acc: 0.9450\n",
      "Early stopping triggered.\n",
      "Iteration 20/40 | Best Val Loss: 0.1122 | Iter Time: 211.60s | Total Time: 85.89 min\n",
      "Epoch 001 | Train Loss: 0.6810 Acc: 0.5736 | Val Loss: 0.6758 Acc: 0.5882\n",
      "Epoch 002 | Train Loss: 0.6723 Acc: 0.5994 | Val Loss: 0.6727 Acc: 0.5966\n",
      "Epoch 003 | Train Loss: 0.6653 Acc: 0.6020 | Val Loss: 0.6607 Acc: 0.6099\n",
      "Epoch 004 | Train Loss: 0.6583 Acc: 0.6139 | Val Loss: 0.6226 Acc: 0.6775\n",
      "Epoch 005 | Train Loss: 0.6082 Acc: 0.6807 | Val Loss: 0.5895 Acc: 0.7029\n",
      "Epoch 006 | Train Loss: 0.5645 Acc: 0.7184 | Val Loss: 0.5596 Acc: 0.7168\n",
      "Epoch 007 | Train Loss: 0.5362 Acc: 0.7392 | Val Loss: 0.5320 Acc: 0.7343\n",
      "Epoch 008 | Train Loss: 0.5206 Acc: 0.7475 | Val Loss: 0.5082 Acc: 0.7488\n",
      "Epoch 009 | Train Loss: 0.4951 Acc: 0.7681 | Val Loss: 0.4855 Acc: 0.7621\n",
      "Epoch 010 | Train Loss: 0.4814 Acc: 0.7687 | Val Loss: 0.4832 Acc: 0.7657\n",
      "Epoch 011 | Train Loss: 0.4584 Acc: 0.7853 | Val Loss: 0.4196 Acc: 0.8037\n",
      "Epoch 012 | Train Loss: 0.4266 Acc: 0.7987 | Val Loss: 0.4759 Acc: 0.7844\n",
      "Epoch 013 | Train Loss: 0.4141 Acc: 0.8150 | Val Loss: 0.3925 Acc: 0.8297\n",
      "Epoch 014 | Train Loss: 0.3887 Acc: 0.8300 | Val Loss: 0.3741 Acc: 0.8345\n",
      "Epoch 015 | Train Loss: 0.3623 Acc: 0.8455 | Val Loss: 0.3717 Acc: 0.8400\n",
      "Epoch 016 | Train Loss: 0.3457 Acc: 0.8525 | Val Loss: 0.3444 Acc: 0.8478\n",
      "Epoch 017 | Train Loss: 0.3275 Acc: 0.8626 | Val Loss: 0.3308 Acc: 0.8575\n",
      "Epoch 018 | Train Loss: 0.3042 Acc: 0.8730 | Val Loss: 0.3339 Acc: 0.8545\n",
      "Epoch 019 | Train Loss: 0.2855 Acc: 0.8840 | Val Loss: 0.2930 Acc: 0.8792\n",
      "Epoch 020 | Train Loss: 0.2807 Acc: 0.8837 | Val Loss: 0.2950 Acc: 0.8835\n",
      "Epoch 021 | Train Loss: 0.2680 Acc: 0.8878 | Val Loss: 0.2605 Acc: 0.8992\n",
      "Epoch 022 | Train Loss: 0.2613 Acc: 0.8945 | Val Loss: 0.2597 Acc: 0.8949\n",
      "Epoch 023 | Train Loss: 0.2488 Acc: 0.9047 | Val Loss: 0.2366 Acc: 0.9118\n",
      "Epoch 024 | Train Loss: 0.2465 Acc: 0.9011 | Val Loss: 0.2669 Acc: 0.8889\n",
      "Epoch 025 | Train Loss: 0.2296 Acc: 0.9065 | Val Loss: 0.2471 Acc: 0.8979\n",
      "Epoch 026 | Train Loss: 0.2165 Acc: 0.9159 | Val Loss: 0.2281 Acc: 0.9094\n",
      "Epoch 027 | Train Loss: 0.2116 Acc: 0.9182 | Val Loss: 0.2438 Acc: 0.9058\n",
      "Epoch 028 | Train Loss: 0.2017 Acc: 0.9200 | Val Loss: 0.2191 Acc: 0.9143\n",
      "Epoch 029 | Train Loss: 0.1931 Acc: 0.9238 | Val Loss: 0.2090 Acc: 0.9245\n",
      "Epoch 030 | Train Loss: 0.2006 Acc: 0.9239 | Val Loss: 0.2044 Acc: 0.9215\n",
      "Epoch 031 | Train Loss: 0.1865 Acc: 0.9263 | Val Loss: 0.1989 Acc: 0.9227\n",
      "Epoch 032 | Train Loss: 0.1684 Acc: 0.9364 | Val Loss: 0.1923 Acc: 0.9269\n",
      "Epoch 033 | Train Loss: 0.1792 Acc: 0.9266 | Val Loss: 0.1900 Acc: 0.9354\n",
      "Epoch 034 | Train Loss: 0.1628 Acc: 0.9381 | Val Loss: 0.2045 Acc: 0.9263\n",
      "Epoch 035 | Train Loss: 0.1791 Acc: 0.9318 | Val Loss: 0.1989 Acc: 0.9233\n",
      "Epoch 036 | Train Loss: 0.1493 Acc: 0.9417 | Val Loss: 0.2148 Acc: 0.9136\n",
      "Epoch 037 | Train Loss: 0.1534 Acc: 0.9422 | Val Loss: 0.1779 Acc: 0.9300\n",
      "Epoch 038 | Train Loss: 0.1522 Acc: 0.9434 | Val Loss: 0.2208 Acc: 0.9124\n",
      "Epoch 039 | Train Loss: 0.1307 Acc: 0.9494 | Val Loss: 0.2091 Acc: 0.9263\n",
      "Epoch 040 | Train Loss: 0.1674 Acc: 0.9355 | Val Loss: 0.1680 Acc: 0.9366\n",
      "Epoch 041 | Train Loss: 0.1400 Acc: 0.9493 | Val Loss: 0.1846 Acc: 0.9384\n",
      "Epoch 042 | Train Loss: 0.1253 Acc: 0.9511 | Val Loss: 0.1721 Acc: 0.9366\n",
      "Epoch 043 | Train Loss: 0.1361 Acc: 0.9470 | Val Loss: 0.1749 Acc: 0.9384\n",
      "Epoch 044 | Train Loss: 0.1343 Acc: 0.9479 | Val Loss: 0.1658 Acc: 0.9408\n",
      "Epoch 045 | Train Loss: 0.1287 Acc: 0.9514 | Val Loss: 0.1849 Acc: 0.9251\n",
      "Epoch 046 | Train Loss: 0.1315 Acc: 0.9493 | Val Loss: 0.1937 Acc: 0.9366\n",
      "Epoch 047 | Train Loss: 0.1231 Acc: 0.9555 | Val Loss: 0.1649 Acc: 0.9378\n",
      "Epoch 048 | Train Loss: 0.1087 Acc: 0.9630 | Val Loss: 0.1724 Acc: 0.9354\n",
      "Epoch 049 | Train Loss: 0.1178 Acc: 0.9568 | Val Loss: 0.1926 Acc: 0.9287\n",
      "Epoch 050 | Train Loss: 0.1082 Acc: 0.9604 | Val Loss: 0.1534 Acc: 0.9414\n",
      "Epoch 051 | Train Loss: 0.1106 Acc: 0.9586 | Val Loss: 0.1692 Acc: 0.9330\n",
      "Epoch 052 | Train Loss: 0.1141 Acc: 0.9574 | Val Loss: 0.1615 Acc: 0.9432\n",
      "Epoch 053 | Train Loss: 0.1140 Acc: 0.9571 | Val Loss: 0.1852 Acc: 0.9354\n",
      "Epoch 054 | Train Loss: 0.1052 Acc: 0.9616 | Val Loss: 0.1665 Acc: 0.9414\n",
      "Epoch 055 | Train Loss: 0.1097 Acc: 0.9565 | Val Loss: 0.1385 Acc: 0.9547\n",
      "Epoch 056 | Train Loss: 0.1092 Acc: 0.9589 | Val Loss: 0.1911 Acc: 0.9275\n",
      "Epoch 057 | Train Loss: 0.1081 Acc: 0.9591 | Val Loss: 0.1588 Acc: 0.9378\n",
      "Epoch 058 | Train Loss: 0.1085 Acc: 0.9598 | Val Loss: 0.2420 Acc: 0.9034\n",
      "Epoch 059 | Train Loss: 0.1135 Acc: 0.9589 | Val Loss: 0.1671 Acc: 0.9426\n",
      "Epoch 060 | Train Loss: 0.1015 Acc: 0.9621 | Val Loss: 0.1456 Acc: 0.9475\n",
      "Epoch 001 | Train Loss: 0.6802 Acc: 0.5812 | Val Loss: 0.6726 Acc: 0.5930\n",
      "Epoch 002 | Train Loss: 0.6715 Acc: 0.5958 | Val Loss: 0.6704 Acc: 0.5966\n",
      "Epoch 003 | Train Loss: 0.6622 Acc: 0.6139 | Val Loss: 0.6408 Acc: 0.6643\n",
      "Epoch 004 | Train Loss: 0.6302 Acc: 0.6612 | Val Loss: 0.5975 Acc: 0.6987\n",
      "Epoch 005 | Train Loss: 0.5936 Acc: 0.7050 | Val Loss: 0.5711 Acc: 0.7059\n",
      "Epoch 006 | Train Loss: 0.5735 Acc: 0.7158 | Val Loss: 0.5639 Acc: 0.7156\n",
      "Epoch 007 | Train Loss: 0.5635 Acc: 0.7217 | Val Loss: 0.5717 Acc: 0.7107\n",
      "Epoch 008 | Train Loss: 0.5485 Acc: 0.7327 | Val Loss: 0.5528 Acc: 0.7138\n",
      "Epoch 009 | Train Loss: 0.5427 Acc: 0.7370 | Val Loss: 0.5376 Acc: 0.7361\n",
      "Epoch 010 | Train Loss: 0.5324 Acc: 0.7466 | Val Loss: 0.5405 Acc: 0.7325\n",
      "Epoch 011 | Train Loss: 0.5194 Acc: 0.7545 | Val Loss: 0.5210 Acc: 0.7440\n",
      "Epoch 012 | Train Loss: 0.5100 Acc: 0.7571 | Val Loss: 0.5080 Acc: 0.7572\n",
      "Epoch 013 | Train Loss: 0.5014 Acc: 0.7592 | Val Loss: 0.5099 Acc: 0.7494\n",
      "Epoch 014 | Train Loss: 0.4951 Acc: 0.7611 | Val Loss: 0.4749 Acc: 0.7627\n",
      "Epoch 015 | Train Loss: 0.4696 Acc: 0.7805 | Val Loss: 0.4855 Acc: 0.7603\n",
      "Epoch 016 | Train Loss: 0.4533 Acc: 0.7835 | Val Loss: 0.4569 Acc: 0.7802\n",
      "Epoch 017 | Train Loss: 0.4488 Acc: 0.7922 | Val Loss: 0.4645 Acc: 0.7814\n",
      "Epoch 018 | Train Loss: 0.4302 Acc: 0.8008 | Val Loss: 0.4422 Acc: 0.7868\n",
      "Epoch 019 | Train Loss: 0.4090 Acc: 0.8096 | Val Loss: 0.4516 Acc: 0.7723\n",
      "Epoch 020 | Train Loss: 0.4154 Acc: 0.8104 | Val Loss: 0.4220 Acc: 0.7947\n",
      "Epoch 021 | Train Loss: 0.3905 Acc: 0.8165 | Val Loss: 0.4142 Acc: 0.8013\n",
      "Epoch 022 | Train Loss: 0.3879 Acc: 0.8232 | Val Loss: 0.4256 Acc: 0.7941\n",
      "Epoch 023 | Train Loss: 0.3566 Acc: 0.8436 | Val Loss: 0.3883 Acc: 0.8237\n",
      "Epoch 024 | Train Loss: 0.3498 Acc: 0.8457 | Val Loss: 0.3848 Acc: 0.8219\n",
      "Epoch 025 | Train Loss: 0.3449 Acc: 0.8534 | Val Loss: 0.3744 Acc: 0.8297\n",
      "Epoch 026 | Train Loss: 0.3340 Acc: 0.8621 | Val Loss: 0.3424 Acc: 0.8430\n",
      "Epoch 027 | Train Loss: 0.3299 Acc: 0.8591 | Val Loss: 0.3131 Acc: 0.8696\n",
      "Epoch 028 | Train Loss: 0.3002 Acc: 0.8742 | Val Loss: 0.2997 Acc: 0.8678\n",
      "Epoch 029 | Train Loss: 0.2936 Acc: 0.8765 | Val Loss: 0.2915 Acc: 0.8750\n",
      "Epoch 030 | Train Loss: 0.2829 Acc: 0.8821 | Val Loss: 0.2913 Acc: 0.8762\n",
      "Epoch 031 | Train Loss: 0.2640 Acc: 0.8902 | Val Loss: 0.2883 Acc: 0.8774\n",
      "Epoch 032 | Train Loss: 0.2544 Acc: 0.8954 | Val Loss: 0.2772 Acc: 0.8810\n",
      "Epoch 033 | Train Loss: 0.2593 Acc: 0.8955 | Val Loss: 0.2663 Acc: 0.8877\n",
      "Epoch 034 | Train Loss: 0.2416 Acc: 0.9019 | Val Loss: 0.2482 Acc: 0.8992\n",
      "Epoch 035 | Train Loss: 0.2330 Acc: 0.9074 | Val Loss: 0.2406 Acc: 0.8979\n",
      "Epoch 036 | Train Loss: 0.2415 Acc: 0.9050 | Val Loss: 0.2449 Acc: 0.9070\n",
      "Epoch 037 | Train Loss: 0.2226 Acc: 0.9082 | Val Loss: 0.2233 Acc: 0.9100\n",
      "Epoch 038 | Train Loss: 0.2271 Acc: 0.9099 | Val Loss: 0.2344 Acc: 0.9070\n",
      "Epoch 039 | Train Loss: 0.2239 Acc: 0.9091 | Val Loss: 0.2278 Acc: 0.9028\n",
      "Epoch 040 | Train Loss: 0.2058 Acc: 0.9183 | Val Loss: 0.2267 Acc: 0.9100\n",
      "Epoch 041 | Train Loss: 0.1923 Acc: 0.9244 | Val Loss: 0.2346 Acc: 0.9070\n",
      "Epoch 042 | Train Loss: 0.1934 Acc: 0.9231 | Val Loss: 0.2325 Acc: 0.9082\n",
      "Epoch 043 | Train Loss: 0.1928 Acc: 0.9198 | Val Loss: 0.2104 Acc: 0.9203\n",
      "Epoch 044 | Train Loss: 0.1795 Acc: 0.9315 | Val Loss: 0.2625 Acc: 0.9082\n",
      "Epoch 045 | Train Loss: 0.1755 Acc: 0.9311 | Val Loss: 0.2051 Acc: 0.9179\n",
      "Epoch 046 | Train Loss: 0.1787 Acc: 0.9322 | Val Loss: 0.2178 Acc: 0.9173\n",
      "Epoch 047 | Train Loss: 0.1830 Acc: 0.9305 | Val Loss: 0.2201 Acc: 0.9173\n",
      "Epoch 048 | Train Loss: 0.1571 Acc: 0.9417 | Val Loss: 0.1820 Acc: 0.9233\n",
      "Epoch 049 | Train Loss: 0.1700 Acc: 0.9328 | Val Loss: 0.2219 Acc: 0.9124\n",
      "Epoch 050 | Train Loss: 0.1489 Acc: 0.9452 | Val Loss: 0.1915 Acc: 0.9293\n",
      "Epoch 051 | Train Loss: 0.1568 Acc: 0.9432 | Val Loss: 0.1875 Acc: 0.9318\n",
      "Epoch 052 | Train Loss: 0.1502 Acc: 0.9431 | Val Loss: 0.1956 Acc: 0.9245\n",
      "Epoch 053 | Train Loss: 0.1587 Acc: 0.9358 | Val Loss: 0.2092 Acc: 0.9173\n",
      "Epoch 054 | Train Loss: 0.1463 Acc: 0.9450 | Val Loss: 0.1948 Acc: 0.9233\n",
      "Epoch 055 | Train Loss: 0.1400 Acc: 0.9472 | Val Loss: 0.2014 Acc: 0.9269\n",
      "Epoch 056 | Train Loss: 0.1517 Acc: 0.9419 | Val Loss: 0.2111 Acc: 0.9058\n",
      "Epoch 057 | Train Loss: 0.1456 Acc: 0.9459 | Val Loss: 0.2214 Acc: 0.9239\n",
      "Epoch 058 | Train Loss: 0.1364 Acc: 0.9469 | Val Loss: 0.1801 Acc: 0.9275\n",
      "Epoch 059 | Train Loss: 0.1327 Acc: 0.9499 | Val Loss: 0.1938 Acc: 0.9281\n",
      "Epoch 060 | Train Loss: 0.1416 Acc: 0.9455 | Val Loss: 0.1927 Acc: 0.9306\n",
      "Epoch 001 | Train Loss: 0.6776 Acc: 0.5845 | Val Loss: 0.6688 Acc: 0.5972\n",
      "Epoch 002 | Train Loss: 0.6794 Acc: 0.5798 | Val Loss: 0.6738 Acc: 0.5900\n",
      "Epoch 003 | Train Loss: 0.6555 Acc: 0.6189 | Val Loss: 0.6290 Acc: 0.6552\n",
      "Epoch 004 | Train Loss: 0.6138 Acc: 0.6795 | Val Loss: 0.6090 Acc: 0.6781\n",
      "Epoch 005 | Train Loss: 0.5781 Acc: 0.7119 | Val Loss: 0.5673 Acc: 0.7083\n",
      "Epoch 006 | Train Loss: 0.5620 Acc: 0.7193 | Val Loss: 0.5578 Acc: 0.7144\n",
      "Epoch 007 | Train Loss: 0.5378 Acc: 0.7308 | Val Loss: 0.5363 Acc: 0.7252\n",
      "Epoch 008 | Train Loss: 0.5169 Acc: 0.7485 | Val Loss: 0.5296 Acc: 0.7295\n",
      "Epoch 009 | Train Loss: 0.5007 Acc: 0.7524 | Val Loss: 0.4985 Acc: 0.7476\n",
      "Epoch 010 | Train Loss: 0.4834 Acc: 0.7636 | Val Loss: 0.4757 Acc: 0.7784\n",
      "Epoch 011 | Train Loss: 0.4654 Acc: 0.7824 | Val Loss: 0.5022 Acc: 0.7615\n",
      "Epoch 012 | Train Loss: 0.4510 Acc: 0.7888 | Val Loss: 0.4408 Acc: 0.8031\n",
      "Epoch 013 | Train Loss: 0.4343 Acc: 0.7993 | Val Loss: 0.4220 Acc: 0.8037\n",
      "Epoch 014 | Train Loss: 0.3997 Acc: 0.8164 | Val Loss: 0.4033 Acc: 0.8188\n",
      "Epoch 015 | Train Loss: 0.3888 Acc: 0.8223 | Val Loss: 0.3743 Acc: 0.8424\n",
      "Epoch 016 | Train Loss: 0.3744 Acc: 0.8300 | Val Loss: 0.3670 Acc: 0.8418\n",
      "Epoch 017 | Train Loss: 0.3613 Acc: 0.8418 | Val Loss: 0.3420 Acc: 0.8448\n",
      "Epoch 018 | Train Loss: 0.3397 Acc: 0.8532 | Val Loss: 0.3327 Acc: 0.8569\n",
      "Epoch 019 | Train Loss: 0.3213 Acc: 0.8567 | Val Loss: 0.3797 Acc: 0.8333\n",
      "Epoch 020 | Train Loss: 0.3014 Acc: 0.8703 | Val Loss: 0.3318 Acc: 0.8539\n",
      "Epoch 021 | Train Loss: 0.3054 Acc: 0.8727 | Val Loss: 0.3225 Acc: 0.8575\n",
      "Epoch 022 | Train Loss: 0.2911 Acc: 0.8771 | Val Loss: 0.2716 Acc: 0.8871\n",
      "Epoch 023 | Train Loss: 0.2755 Acc: 0.8842 | Val Loss: 0.2694 Acc: 0.8907\n",
      "Epoch 024 | Train Loss: 0.2748 Acc: 0.8877 | Val Loss: 0.2625 Acc: 0.8883\n",
      "Epoch 025 | Train Loss: 0.2471 Acc: 0.9008 | Val Loss: 0.2523 Acc: 0.8955\n",
      "Epoch 026 | Train Loss: 0.2557 Acc: 0.8952 | Val Loss: 0.2439 Acc: 0.9004\n",
      "Epoch 027 | Train Loss: 0.2349 Acc: 0.9019 | Val Loss: 0.2648 Acc: 0.9016\n",
      "Epoch 028 | Train Loss: 0.2420 Acc: 0.9017 | Val Loss: 0.2410 Acc: 0.8998\n",
      "Epoch 029 | Train Loss: 0.2224 Acc: 0.9097 | Val Loss: 0.2332 Acc: 0.9034\n",
      "Epoch 030 | Train Loss: 0.2166 Acc: 0.9121 | Val Loss: 0.2226 Acc: 0.9191\n",
      "Epoch 031 | Train Loss: 0.2057 Acc: 0.9173 | Val Loss: 0.2230 Acc: 0.9094\n",
      "Epoch 032 | Train Loss: 0.1876 Acc: 0.9277 | Val Loss: 0.2161 Acc: 0.9173\n",
      "Epoch 033 | Train Loss: 0.1923 Acc: 0.9204 | Val Loss: 0.2021 Acc: 0.9197\n",
      "Epoch 034 | Train Loss: 0.1926 Acc: 0.9250 | Val Loss: 0.2008 Acc: 0.9191\n",
      "Epoch 035 | Train Loss: 0.1878 Acc: 0.9275 | Val Loss: 0.1831 Acc: 0.9263\n",
      "Epoch 036 | Train Loss: 0.1843 Acc: 0.9284 | Val Loss: 0.1869 Acc: 0.9257\n",
      "Epoch 037 | Train Loss: 0.1633 Acc: 0.9372 | Val Loss: 0.1957 Acc: 0.9263\n",
      "Epoch 038 | Train Loss: 0.1709 Acc: 0.9327 | Val Loss: 0.1803 Acc: 0.9293\n",
      "Epoch 039 | Train Loss: 0.1560 Acc: 0.9367 | Val Loss: 0.2107 Acc: 0.9173\n",
      "Epoch 040 | Train Loss: 0.1570 Acc: 0.9392 | Val Loss: 0.1686 Acc: 0.9342\n",
      "Epoch 041 | Train Loss: 0.1434 Acc: 0.9408 | Val Loss: 0.1918 Acc: 0.9269\n",
      "Epoch 042 | Train Loss: 0.1440 Acc: 0.9414 | Val Loss: 0.1822 Acc: 0.9300\n",
      "Epoch 043 | Train Loss: 0.1335 Acc: 0.9503 | Val Loss: 0.1730 Acc: 0.9312\n",
      "Epoch 044 | Train Loss: 0.1393 Acc: 0.9479 | Val Loss: 0.1752 Acc: 0.9312\n",
      "Epoch 045 | Train Loss: 0.1378 Acc: 0.9470 | Val Loss: 0.1677 Acc: 0.9330\n",
      "Epoch 046 | Train Loss: 0.1332 Acc: 0.9479 | Val Loss: 0.2097 Acc: 0.9197\n",
      "Epoch 047 | Train Loss: 0.1334 Acc: 0.9509 | Val Loss: 0.1616 Acc: 0.9372\n",
      "Epoch 048 | Train Loss: 0.1352 Acc: 0.9484 | Val Loss: 0.1531 Acc: 0.9396\n",
      "Epoch 049 | Train Loss: 0.1288 Acc: 0.9512 | Val Loss: 0.1841 Acc: 0.9342\n",
      "Epoch 050 | Train Loss: 0.1127 Acc: 0.9580 | Val Loss: 0.2122 Acc: 0.9330\n",
      "Epoch 051 | Train Loss: 0.1287 Acc: 0.9520 | Val Loss: 0.1464 Acc: 0.9426\n",
      "Epoch 052 | Train Loss: 0.1176 Acc: 0.9574 | Val Loss: 0.1687 Acc: 0.9342\n",
      "Epoch 053 | Train Loss: 0.1113 Acc: 0.9558 | Val Loss: 0.1599 Acc: 0.9384\n",
      "Epoch 054 | Train Loss: 0.1140 Acc: 0.9544 | Val Loss: 0.1293 Acc: 0.9511\n",
      "Epoch 055 | Train Loss: 0.0995 Acc: 0.9627 | Val Loss: 0.1537 Acc: 0.9438\n",
      "Epoch 056 | Train Loss: 0.1010 Acc: 0.9636 | Val Loss: 0.1504 Acc: 0.9444\n",
      "Epoch 057 | Train Loss: 0.1004 Acc: 0.9598 | Val Loss: 0.1803 Acc: 0.9432\n",
      "Epoch 058 | Train Loss: 0.1018 Acc: 0.9604 | Val Loss: 0.1481 Acc: 0.9481\n",
      "Epoch 059 | Train Loss: 0.0993 Acc: 0.9626 | Val Loss: 0.1440 Acc: 0.9475\n",
      "Epoch 060 | Train Loss: 0.0985 Acc: 0.9627 | Val Loss: 0.2105 Acc: 0.9257\n",
      "Epoch 001 | Train Loss: 0.6831 Acc: 0.5742 | Val Loss: 0.6823 Acc: 0.5664\n",
      "Epoch 002 | Train Loss: 0.6796 Acc: 0.5870 | Val Loss: 0.6749 Acc: 0.5912\n",
      "Epoch 003 | Train Loss: 0.6700 Acc: 0.6043 | Val Loss: 0.6676 Acc: 0.5960\n",
      "Epoch 004 | Train Loss: 0.6600 Acc: 0.6138 | Val Loss: 0.6700 Acc: 0.5894\n",
      "Epoch 005 | Train Loss: 0.6409 Acc: 0.6523 | Val Loss: 0.6266 Acc: 0.6733\n",
      "Epoch 006 | Train Loss: 0.6046 Acc: 0.6938 | Val Loss: 0.6125 Acc: 0.6896\n",
      "Epoch 007 | Train Loss: 0.5855 Acc: 0.7078 | Val Loss: 0.5782 Acc: 0.7156\n",
      "Epoch 008 | Train Loss: 0.5673 Acc: 0.7217 | Val Loss: 0.5678 Acc: 0.7162\n",
      "Epoch 009 | Train Loss: 0.5592 Acc: 0.7275 | Val Loss: 0.5528 Acc: 0.7252\n",
      "Epoch 010 | Train Loss: 0.5554 Acc: 0.7312 | Val Loss: 0.5485 Acc: 0.7343\n",
      "Epoch 011 | Train Loss: 0.5506 Acc: 0.7332 | Val Loss: 0.5459 Acc: 0.7246\n",
      "Epoch 012 | Train Loss: 0.5318 Acc: 0.7418 | Val Loss: 0.5344 Acc: 0.7343\n",
      "Epoch 013 | Train Loss: 0.5338 Acc: 0.7456 | Val Loss: 0.5429 Acc: 0.7289\n",
      "Epoch 014 | Train Loss: 0.5265 Acc: 0.7426 | Val Loss: 0.5254 Acc: 0.7385\n",
      "Epoch 015 | Train Loss: 0.5230 Acc: 0.7475 | Val Loss: 0.5141 Acc: 0.7403\n",
      "Epoch 016 | Train Loss: 0.5239 Acc: 0.7513 | Val Loss: 0.5187 Acc: 0.7428\n",
      "Epoch 017 | Train Loss: 0.4989 Acc: 0.7646 | Val Loss: 0.5340 Acc: 0.7349\n",
      "Epoch 018 | Train Loss: 0.4951 Acc: 0.7632 | Val Loss: 0.5163 Acc: 0.7434\n",
      "Epoch 019 | Train Loss: 0.4843 Acc: 0.7673 | Val Loss: 0.5005 Acc: 0.7579\n",
      "Epoch 020 | Train Loss: 0.4743 Acc: 0.7782 | Val Loss: 0.4733 Acc: 0.7693\n",
      "Epoch 021 | Train Loss: 0.4678 Acc: 0.7803 | Val Loss: 0.4835 Acc: 0.7748\n",
      "Epoch 022 | Train Loss: 0.4696 Acc: 0.7799 | Val Loss: 0.4621 Acc: 0.7693\n",
      "Epoch 023 | Train Loss: 0.4505 Acc: 0.7944 | Val Loss: 0.4488 Acc: 0.7850\n",
      "Epoch 024 | Train Loss: 0.4565 Acc: 0.7918 | Val Loss: 0.4760 Acc: 0.7790\n",
      "Epoch 025 | Train Loss: 0.4419 Acc: 0.7978 | Val Loss: 0.4556 Acc: 0.7844\n",
      "Epoch 026 | Train Loss: 0.4320 Acc: 0.8064 | Val Loss: 0.4155 Acc: 0.8056\n",
      "Epoch 027 | Train Loss: 0.4128 Acc: 0.8185 | Val Loss: 0.3957 Acc: 0.8297\n",
      "Epoch 028 | Train Loss: 0.4145 Acc: 0.8111 | Val Loss: 0.4467 Acc: 0.7977\n",
      "Epoch 029 | Train Loss: 0.3934 Acc: 0.8232 | Val Loss: 0.4240 Acc: 0.7971\n",
      "Epoch 030 | Train Loss: 0.4004 Acc: 0.8218 | Val Loss: 0.3739 Acc: 0.8339\n",
      "Epoch 031 | Train Loss: 0.3764 Acc: 0.8365 | Val Loss: 0.3575 Acc: 0.8430\n",
      "Epoch 032 | Train Loss: 0.3521 Acc: 0.8511 | Val Loss: 0.3556 Acc: 0.8418\n",
      "Epoch 033 | Train Loss: 0.3605 Acc: 0.8451 | Val Loss: 0.3559 Acc: 0.8394\n",
      "Epoch 034 | Train Loss: 0.3527 Acc: 0.8486 | Val Loss: 0.3431 Acc: 0.8454\n",
      "Epoch 035 | Train Loss: 0.3538 Acc: 0.8455 | Val Loss: 0.3357 Acc: 0.8587\n",
      "Epoch 036 | Train Loss: 0.3348 Acc: 0.8596 | Val Loss: 0.3333 Acc: 0.8623\n",
      "Epoch 037 | Train Loss: 0.3292 Acc: 0.8560 | Val Loss: 0.3261 Acc: 0.8605\n",
      "Epoch 038 | Train Loss: 0.3242 Acc: 0.8641 | Val Loss: 0.3206 Acc: 0.8623\n",
      "Epoch 039 | Train Loss: 0.3238 Acc: 0.8621 | Val Loss: 0.2785 Acc: 0.8804\n",
      "Epoch 040 | Train Loss: 0.3108 Acc: 0.8720 | Val Loss: 0.3181 Acc: 0.8623\n",
      "Epoch 041 | Train Loss: 0.3015 Acc: 0.8739 | Val Loss: 0.2768 Acc: 0.8810\n",
      "Epoch 042 | Train Loss: 0.3031 Acc: 0.8730 | Val Loss: 0.2800 Acc: 0.8841\n",
      "Epoch 043 | Train Loss: 0.3111 Acc: 0.8697 | Val Loss: 0.3255 Acc: 0.8539\n",
      "Epoch 044 | Train Loss: 0.2842 Acc: 0.8842 | Val Loss: 0.2771 Acc: 0.8865\n",
      "Epoch 045 | Train Loss: 0.2892 Acc: 0.8821 | Val Loss: 0.2994 Acc: 0.8665\n",
      "Epoch 046 | Train Loss: 0.2772 Acc: 0.8904 | Val Loss: 0.2953 Acc: 0.8720\n",
      "Epoch 047 | Train Loss: 0.2824 Acc: 0.8812 | Val Loss: 0.3133 Acc: 0.8750\n",
      "Epoch 048 | Train Loss: 0.2629 Acc: 0.8948 | Val Loss: 0.2729 Acc: 0.8762\n",
      "Epoch 049 | Train Loss: 0.2620 Acc: 0.8942 | Val Loss: 0.2597 Acc: 0.8907\n",
      "Epoch 050 | Train Loss: 0.2587 Acc: 0.8933 | Val Loss: 0.2390 Acc: 0.8998\n",
      "Epoch 051 | Train Loss: 0.2507 Acc: 0.8999 | Val Loss: 0.2429 Acc: 0.9040\n",
      "Epoch 052 | Train Loss: 0.2614 Acc: 0.8939 | Val Loss: 0.2478 Acc: 0.9052\n",
      "Epoch 053 | Train Loss: 0.2368 Acc: 0.9026 | Val Loss: 0.2360 Acc: 0.9112\n",
      "Epoch 054 | Train Loss: 0.2384 Acc: 0.9056 | Val Loss: 0.2815 Acc: 0.8871\n",
      "Epoch 055 | Train Loss: 0.2412 Acc: 0.9059 | Val Loss: 0.2430 Acc: 0.9076\n",
      "Epoch 056 | Train Loss: 0.2442 Acc: 0.9046 | Val Loss: 0.2416 Acc: 0.8955\n",
      "Epoch 057 | Train Loss: 0.2419 Acc: 0.9093 | Val Loss: 0.2305 Acc: 0.9136\n",
      "Epoch 058 | Train Loss: 0.2462 Acc: 0.9010 | Val Loss: 0.2425 Acc: 0.9034\n",
      "Epoch 059 | Train Loss: 0.2342 Acc: 0.9091 | Val Loss: 0.2216 Acc: 0.9136\n",
      "Epoch 060 | Train Loss: 0.2313 Acc: 0.9133 | Val Loss: 0.2327 Acc: 0.9082\n",
      "Epoch 001 | Train Loss: 0.6825 Acc: 0.5748 | Val Loss: 0.6846 Acc: 0.5586\n",
      "Epoch 002 | Train Loss: 0.6781 Acc: 0.5822 | Val Loss: 0.6741 Acc: 0.5954\n",
      "Epoch 003 | Train Loss: 0.6599 Acc: 0.6098 | Val Loss: 0.6271 Acc: 0.6757\n",
      "Epoch 004 | Train Loss: 0.6065 Acc: 0.6879 | Val Loss: 0.5994 Acc: 0.6957\n",
      "Epoch 005 | Train Loss: 0.5680 Acc: 0.7192 | Val Loss: 0.5993 Acc: 0.6787\n",
      "Epoch 006 | Train Loss: 0.5490 Acc: 0.7302 | Val Loss: 0.5465 Acc: 0.7343\n",
      "Epoch 007 | Train Loss: 0.5349 Acc: 0.7394 | Val Loss: 0.5457 Acc: 0.7204\n",
      "Epoch 008 | Train Loss: 0.5139 Acc: 0.7575 | Val Loss: 0.4989 Acc: 0.7554\n",
      "Epoch 009 | Train Loss: 0.5012 Acc: 0.7617 | Val Loss: 0.4988 Acc: 0.7548\n",
      "Epoch 010 | Train Loss: 0.4880 Acc: 0.7688 | Val Loss: 0.4948 Acc: 0.7548\n",
      "Epoch 011 | Train Loss: 0.4668 Acc: 0.7830 | Val Loss: 0.4479 Acc: 0.7826\n",
      "Epoch 012 | Train Loss: 0.4572 Acc: 0.7864 | Val Loss: 0.4376 Acc: 0.7941\n",
      "Epoch 013 | Train Loss: 0.4353 Acc: 0.7971 | Val Loss: 0.4379 Acc: 0.7832\n",
      "Epoch 014 | Train Loss: 0.4126 Acc: 0.8122 | Val Loss: 0.4440 Acc: 0.7923\n",
      "Epoch 015 | Train Loss: 0.4050 Acc: 0.8173 | Val Loss: 0.3929 Acc: 0.8043\n",
      "Epoch 016 | Train Loss: 0.3753 Acc: 0.8318 | Val Loss: 0.3667 Acc: 0.8243\n",
      "Epoch 017 | Train Loss: 0.3809 Acc: 0.8277 | Val Loss: 0.3753 Acc: 0.8158\n",
      "Epoch 018 | Train Loss: 0.3406 Acc: 0.8496 | Val Loss: 0.3426 Acc: 0.8466\n",
      "Epoch 019 | Train Loss: 0.3313 Acc: 0.8547 | Val Loss: 0.3543 Acc: 0.8291\n",
      "Epoch 020 | Train Loss: 0.3124 Acc: 0.8623 | Val Loss: 0.2981 Acc: 0.8702\n",
      "Epoch 021 | Train Loss: 0.3089 Acc: 0.8667 | Val Loss: 0.3133 Acc: 0.8569\n",
      "Epoch 022 | Train Loss: 0.2852 Acc: 0.8831 | Val Loss: 0.3071 Acc: 0.8502\n",
      "Epoch 023 | Train Loss: 0.2805 Acc: 0.8791 | Val Loss: 0.3228 Acc: 0.8533\n",
      "Epoch 024 | Train Loss: 0.2609 Acc: 0.8880 | Val Loss: 0.2493 Acc: 0.8919\n",
      "Epoch 025 | Train Loss: 0.2430 Acc: 0.9005 | Val Loss: 0.2674 Acc: 0.8895\n",
      "Epoch 026 | Train Loss: 0.2385 Acc: 0.9037 | Val Loss: 0.2461 Acc: 0.8992\n",
      "Epoch 027 | Train Loss: 0.2269 Acc: 0.9105 | Val Loss: 0.2166 Acc: 0.9143\n",
      "Epoch 028 | Train Loss: 0.2234 Acc: 0.9082 | Val Loss: 0.2693 Acc: 0.8853\n",
      "Epoch 029 | Train Loss: 0.2112 Acc: 0.9174 | Val Loss: 0.2357 Acc: 0.9004\n",
      "Epoch 030 | Train Loss: 0.2032 Acc: 0.9206 | Val Loss: 0.2140 Acc: 0.9143\n",
      "Epoch 031 | Train Loss: 0.1962 Acc: 0.9209 | Val Loss: 0.2076 Acc: 0.9143\n",
      "Epoch 032 | Train Loss: 0.1918 Acc: 0.9251 | Val Loss: 0.2387 Acc: 0.9046\n",
      "Epoch 033 | Train Loss: 0.1876 Acc: 0.9234 | Val Loss: 0.2001 Acc: 0.9209\n",
      "Epoch 034 | Train Loss: 0.1673 Acc: 0.9372 | Val Loss: 0.2054 Acc: 0.9209\n",
      "Epoch 035 | Train Loss: 0.1679 Acc: 0.9367 | Val Loss: 0.2152 Acc: 0.9149\n",
      "Epoch 036 | Train Loss: 0.1690 Acc: 0.9334 | Val Loss: 0.1885 Acc: 0.9257\n",
      "Epoch 037 | Train Loss: 0.1683 Acc: 0.9348 | Val Loss: 0.1974 Acc: 0.9161\n",
      "Epoch 038 | Train Loss: 0.1498 Acc: 0.9425 | Val Loss: 0.1890 Acc: 0.9215\n",
      "Epoch 039 | Train Loss: 0.1672 Acc: 0.9331 | Val Loss: 0.2045 Acc: 0.9179\n",
      "Epoch 040 | Train Loss: 0.1425 Acc: 0.9440 | Val Loss: 0.1824 Acc: 0.9281\n",
      "Epoch 041 | Train Loss: 0.1364 Acc: 0.9470 | Val Loss: 0.2029 Acc: 0.9149\n",
      "Epoch 042 | Train Loss: 0.1431 Acc: 0.9458 | Val Loss: 0.1955 Acc: 0.9221\n",
      "Epoch 043 | Train Loss: 0.1400 Acc: 0.9484 | Val Loss: 0.1634 Acc: 0.9348\n",
      "Epoch 044 | Train Loss: 0.1324 Acc: 0.9497 | Val Loss: 0.2309 Acc: 0.9124\n",
      "Epoch 045 | Train Loss: 0.1327 Acc: 0.9478 | Val Loss: 0.1965 Acc: 0.9167\n",
      "Epoch 046 | Train Loss: 0.1383 Acc: 0.9467 | Val Loss: 0.1988 Acc: 0.9257\n",
      "Epoch 047 | Train Loss: 0.1331 Acc: 0.9499 | Val Loss: 0.1853 Acc: 0.9275\n",
      "Epoch 048 | Train Loss: 0.1117 Acc: 0.9588 | Val Loss: 0.1671 Acc: 0.9354\n",
      "Epoch 049 | Train Loss: 0.1201 Acc: 0.9530 | Val Loss: 0.1740 Acc: 0.9366\n",
      "Epoch 050 | Train Loss: 0.1135 Acc: 0.9571 | Val Loss: 0.1592 Acc: 0.9384\n",
      "Epoch 051 | Train Loss: 0.1199 Acc: 0.9553 | Val Loss: 0.1811 Acc: 0.9287\n",
      "Epoch 052 | Train Loss: 0.1026 Acc: 0.9618 | Val Loss: 0.1664 Acc: 0.9324\n",
      "Epoch 053 | Train Loss: 0.1066 Acc: 0.9574 | Val Loss: 0.1752 Acc: 0.9366\n",
      "Epoch 054 | Train Loss: 0.1020 Acc: 0.9595 | Val Loss: 0.1538 Acc: 0.9378\n",
      "Epoch 055 | Train Loss: 0.1041 Acc: 0.9606 | Val Loss: 0.1847 Acc: 0.9324\n",
      "Epoch 056 | Train Loss: 0.1043 Acc: 0.9606 | Val Loss: 0.1936 Acc: 0.9287\n",
      "Epoch 057 | Train Loss: 0.1065 Acc: 0.9607 | Val Loss: 0.1652 Acc: 0.9372\n",
      "Epoch 058 | Train Loss: 0.0952 Acc: 0.9629 | Val Loss: 0.1608 Acc: 0.9372\n",
      "Epoch 059 | Train Loss: 0.0927 Acc: 0.9663 | Val Loss: 0.1955 Acc: 0.9300\n",
      "Epoch 060 | Train Loss: 0.0972 Acc: 0.9648 | Val Loss: 0.1717 Acc: 0.9396\n",
      "Epoch 001 | Train Loss: 0.6781 Acc: 0.5825 | Val Loss: 0.6738 Acc: 0.5882\n",
      "Epoch 002 | Train Loss: 0.6698 Acc: 0.6012 | Val Loss: 0.6703 Acc: 0.5996\n",
      "Epoch 003 | Train Loss: 0.6654 Acc: 0.6006 | Val Loss: 0.6639 Acc: 0.5912\n",
      "Epoch 004 | Train Loss: 0.6454 Acc: 0.6266 | Val Loss: 0.6128 Acc: 0.6727\n",
      "Epoch 005 | Train Loss: 0.5926 Acc: 0.6973 | Val Loss: 0.5691 Acc: 0.7017\n",
      "Epoch 006 | Train Loss: 0.5607 Acc: 0.7241 | Val Loss: 0.5605 Acc: 0.7065\n",
      "Epoch 007 | Train Loss: 0.5407 Acc: 0.7312 | Val Loss: 0.5440 Acc: 0.7144\n",
      "Epoch 008 | Train Loss: 0.5284 Acc: 0.7429 | Val Loss: 0.5673 Acc: 0.7283\n",
      "Epoch 009 | Train Loss: 0.5221 Acc: 0.7478 | Val Loss: 0.5369 Acc: 0.7307\n",
      "Epoch 010 | Train Loss: 0.5082 Acc: 0.7537 | Val Loss: 0.5245 Acc: 0.7458\n",
      "Epoch 011 | Train Loss: 0.4897 Acc: 0.7646 | Val Loss: 0.5053 Acc: 0.7506\n",
      "Epoch 012 | Train Loss: 0.4859 Acc: 0.7681 | Val Loss: 0.4865 Acc: 0.7699\n",
      "Epoch 013 | Train Loss: 0.4689 Acc: 0.7802 | Val Loss: 0.4814 Acc: 0.7645\n",
      "Epoch 014 | Train Loss: 0.4567 Acc: 0.7823 | Val Loss: 0.5150 Acc: 0.7796\n",
      "Epoch 015 | Train Loss: 0.4507 Acc: 0.7971 | Val Loss: 0.4592 Acc: 0.7808\n",
      "Epoch 016 | Train Loss: 0.4245 Acc: 0.8027 | Val Loss: 0.4426 Acc: 0.7886\n",
      "Epoch 017 | Train Loss: 0.4034 Acc: 0.8194 | Val Loss: 0.4387 Acc: 0.7874\n",
      "Epoch 018 | Train Loss: 0.3930 Acc: 0.8264 | Val Loss: 0.3907 Acc: 0.8237\n",
      "Epoch 019 | Train Loss: 0.3805 Acc: 0.8304 | Val Loss: 0.3819 Acc: 0.8291\n",
      "Epoch 020 | Train Loss: 0.3612 Acc: 0.8422 | Val Loss: 0.3540 Acc: 0.8400\n",
      "Epoch 021 | Train Loss: 0.3487 Acc: 0.8558 | Val Loss: 0.3433 Acc: 0.8376\n",
      "Epoch 022 | Train Loss: 0.3328 Acc: 0.8599 | Val Loss: 0.3486 Acc: 0.8448\n",
      "Epoch 023 | Train Loss: 0.3184 Acc: 0.8682 | Val Loss: 0.3139 Acc: 0.8696\n",
      "Epoch 024 | Train Loss: 0.3122 Acc: 0.8668 | Val Loss: 0.3063 Acc: 0.8738\n",
      "Epoch 025 | Train Loss: 0.2906 Acc: 0.8757 | Val Loss: 0.2902 Acc: 0.8822\n",
      "Epoch 026 | Train Loss: 0.2875 Acc: 0.8846 | Val Loss: 0.2858 Acc: 0.8822\n",
      "Epoch 027 | Train Loss: 0.2828 Acc: 0.8837 | Val Loss: 0.2730 Acc: 0.8883\n",
      "Epoch 028 | Train Loss: 0.2653 Acc: 0.8883 | Val Loss: 0.3109 Acc: 0.8738\n",
      "Epoch 029 | Train Loss: 0.2584 Acc: 0.8949 | Val Loss: 0.2545 Acc: 0.8961\n",
      "Epoch 030 | Train Loss: 0.2382 Acc: 0.9049 | Val Loss: 0.2823 Acc: 0.8792\n",
      "Epoch 031 | Train Loss: 0.2377 Acc: 0.9025 | Val Loss: 0.2469 Acc: 0.8925\n",
      "Epoch 032 | Train Loss: 0.2130 Acc: 0.9154 | Val Loss: 0.2158 Acc: 0.9106\n",
      "Epoch 033 | Train Loss: 0.2088 Acc: 0.9195 | Val Loss: 0.2535 Acc: 0.8967\n",
      "Epoch 034 | Train Loss: 0.2124 Acc: 0.9167 | Val Loss: 0.2829 Acc: 0.9004\n",
      "Epoch 035 | Train Loss: 0.2082 Acc: 0.9170 | Val Loss: 0.2518 Acc: 0.8998\n",
      "Epoch 036 | Train Loss: 0.1918 Acc: 0.9236 | Val Loss: 0.2440 Acc: 0.9082\n",
      "Epoch 037 | Train Loss: 0.1843 Acc: 0.9299 | Val Loss: 0.2456 Acc: 0.9088\n",
      "Epoch 038 | Train Loss: 0.1851 Acc: 0.9299 | Val Loss: 0.2476 Acc: 0.9058\n",
      "Epoch 039 | Train Loss: 0.1836 Acc: 0.9305 | Val Loss: 0.2267 Acc: 0.9106\n",
      "Epoch 040 | Train Loss: 0.1778 Acc: 0.9310 | Val Loss: 0.2281 Acc: 0.9155\n",
      "Epoch 041 | Train Loss: 0.1706 Acc: 0.9321 | Val Loss: 0.2438 Acc: 0.9034\n",
      "Epoch 042 | Train Loss: 0.1635 Acc: 0.9352 | Val Loss: 0.2051 Acc: 0.9191\n",
      "Epoch 043 | Train Loss: 0.1587 Acc: 0.9416 | Val Loss: 0.2213 Acc: 0.9179\n",
      "Epoch 044 | Train Loss: 0.1538 Acc: 0.9408 | Val Loss: 0.2079 Acc: 0.9251\n",
      "Epoch 045 | Train Loss: 0.1511 Acc: 0.9408 | Val Loss: 0.1929 Acc: 0.9281\n",
      "Epoch 046 | Train Loss: 0.1495 Acc: 0.9404 | Val Loss: 0.1892 Acc: 0.9312\n",
      "Epoch 047 | Train Loss: 0.1511 Acc: 0.9449 | Val Loss: 0.1923 Acc: 0.9257\n",
      "Epoch 048 | Train Loss: 0.1327 Acc: 0.9500 | Val Loss: 0.1909 Acc: 0.9318\n",
      "Epoch 049 | Train Loss: 0.1289 Acc: 0.9509 | Val Loss: 0.2106 Acc: 0.9263\n",
      "Epoch 050 | Train Loss: 0.1395 Acc: 0.9465 | Val Loss: 0.1634 Acc: 0.9402\n",
      "Epoch 051 | Train Loss: 0.1332 Acc: 0.9465 | Val Loss: 0.1737 Acc: 0.9306\n",
      "Epoch 052 | Train Loss: 0.1272 Acc: 0.9562 | Val Loss: 0.1970 Acc: 0.9324\n",
      "Epoch 053 | Train Loss: 0.1347 Acc: 0.9481 | Val Loss: 0.1606 Acc: 0.9402\n",
      "Epoch 054 | Train Loss: 0.1249 Acc: 0.9574 | Val Loss: 0.1891 Acc: 0.9306\n",
      "Epoch 055 | Train Loss: 0.1202 Acc: 0.9564 | Val Loss: 0.1705 Acc: 0.9336\n",
      "Epoch 056 | Train Loss: 0.1201 Acc: 0.9552 | Val Loss: 0.2029 Acc: 0.9221\n",
      "Epoch 057 | Train Loss: 0.1168 Acc: 0.9577 | Val Loss: 0.1945 Acc: 0.9263\n",
      "Epoch 058 | Train Loss: 0.1084 Acc: 0.9609 | Val Loss: 0.1719 Acc: 0.9444\n",
      "Epoch 059 | Train Loss: 0.1028 Acc: 0.9598 | Val Loss: 0.1633 Acc: 0.9457\n",
      "Epoch 060 | Train Loss: 0.1104 Acc: 0.9567 | Val Loss: 0.1674 Acc: 0.9408\n",
      "Epoch 001 | Train Loss: 0.6782 Acc: 0.5796 | Val Loss: 0.6791 Acc: 0.5761\n",
      "Epoch 002 | Train Loss: 0.6689 Acc: 0.5991 | Val Loss: 0.6830 Acc: 0.5809\n",
      "Epoch 003 | Train Loss: 0.6560 Acc: 0.6191 | Val Loss: 0.6350 Acc: 0.6582\n",
      "Epoch 004 | Train Loss: 0.6171 Acc: 0.6714 | Val Loss: 0.6114 Acc: 0.6806\n",
      "Epoch 005 | Train Loss: 0.5752 Acc: 0.7125 | Val Loss: 0.5882 Acc: 0.6987\n",
      "Epoch 006 | Train Loss: 0.5501 Acc: 0.7300 | Val Loss: 0.5572 Acc: 0.7174\n",
      "Epoch 007 | Train Loss: 0.5355 Acc: 0.7397 | Val Loss: 0.5417 Acc: 0.7307\n",
      "Epoch 008 | Train Loss: 0.5140 Acc: 0.7531 | Val Loss: 0.5283 Acc: 0.7403\n",
      "Epoch 009 | Train Loss: 0.4969 Acc: 0.7617 | Val Loss: 0.5020 Acc: 0.7542\n",
      "Epoch 010 | Train Loss: 0.4750 Acc: 0.7743 | Val Loss: 0.4847 Acc: 0.7530\n",
      "Epoch 011 | Train Loss: 0.4635 Acc: 0.7774 | Val Loss: 0.4541 Acc: 0.7784\n",
      "Epoch 012 | Train Loss: 0.4382 Acc: 0.7996 | Val Loss: 0.4478 Acc: 0.7832\n",
      "Epoch 013 | Train Loss: 0.4206 Acc: 0.8073 | Val Loss: 0.4200 Acc: 0.8074\n",
      "Epoch 014 | Train Loss: 0.4106 Acc: 0.8126 | Val Loss: 0.4126 Acc: 0.8007\n",
      "Epoch 015 | Train Loss: 0.3783 Acc: 0.8295 | Val Loss: 0.4146 Acc: 0.8025\n",
      "Epoch 016 | Train Loss: 0.3780 Acc: 0.8323 | Val Loss: 0.4181 Acc: 0.7880\n",
      "Epoch 017 | Train Loss: 0.3415 Acc: 0.8445 | Val Loss: 0.3732 Acc: 0.8297\n",
      "Epoch 018 | Train Loss: 0.3278 Acc: 0.8585 | Val Loss: 0.3241 Acc: 0.8593\n",
      "Epoch 019 | Train Loss: 0.3022 Acc: 0.8691 | Val Loss: 0.3172 Acc: 0.8641\n",
      "Epoch 020 | Train Loss: 0.3026 Acc: 0.8720 | Val Loss: 0.3094 Acc: 0.8696\n",
      "Epoch 021 | Train Loss: 0.2782 Acc: 0.8806 | Val Loss: 0.3205 Acc: 0.8539\n",
      "Epoch 022 | Train Loss: 0.2649 Acc: 0.8926 | Val Loss: 0.3025 Acc: 0.8720\n",
      "Epoch 023 | Train Loss: 0.2483 Acc: 0.9010 | Val Loss: 0.2749 Acc: 0.8829\n",
      "Epoch 024 | Train Loss: 0.2429 Acc: 0.9017 | Val Loss: 0.2899 Acc: 0.8804\n",
      "Epoch 025 | Train Loss: 0.2193 Acc: 0.9100 | Val Loss: 0.3135 Acc: 0.8629\n",
      "Epoch 026 | Train Loss: 0.2220 Acc: 0.9080 | Val Loss: 0.2565 Acc: 0.8955\n",
      "Epoch 027 | Train Loss: 0.2133 Acc: 0.9144 | Val Loss: 0.2342 Acc: 0.9088\n",
      "Epoch 028 | Train Loss: 0.1911 Acc: 0.9234 | Val Loss: 0.2230 Acc: 0.9064\n",
      "Epoch 029 | Train Loss: 0.1843 Acc: 0.9259 | Val Loss: 0.2441 Acc: 0.9040\n",
      "Epoch 030 | Train Loss: 0.1832 Acc: 0.9268 | Val Loss: 0.2416 Acc: 0.9016\n",
      "Epoch 031 | Train Loss: 0.1760 Acc: 0.9311 | Val Loss: 0.2377 Acc: 0.9028\n",
      "Epoch 032 | Train Loss: 0.1715 Acc: 0.9336 | Val Loss: 0.2271 Acc: 0.9064\n",
      "Epoch 033 | Train Loss: 0.1518 Acc: 0.9435 | Val Loss: 0.2123 Acc: 0.9136\n",
      "Epoch 034 | Train Loss: 0.1585 Acc: 0.9395 | Val Loss: 0.2476 Acc: 0.9016\n",
      "Epoch 035 | Train Loss: 0.1317 Acc: 0.9491 | Val Loss: 0.1891 Acc: 0.9293\n",
      "Epoch 036 | Train Loss: 0.1286 Acc: 0.9527 | Val Loss: 0.1689 Acc: 0.9384\n",
      "Epoch 037 | Train Loss: 0.1372 Acc: 0.9494 | Val Loss: 0.1733 Acc: 0.9342\n",
      "Epoch 038 | Train Loss: 0.1195 Acc: 0.9532 | Val Loss: 0.2019 Acc: 0.9251\n",
      "Epoch 039 | Train Loss: 0.1206 Acc: 0.9556 | Val Loss: 0.1750 Acc: 0.9384\n",
      "Epoch 040 | Train Loss: 0.1141 Acc: 0.9564 | Val Loss: 0.1787 Acc: 0.9378\n",
      "Epoch 041 | Train Loss: 0.1123 Acc: 0.9546 | Val Loss: 0.1756 Acc: 0.9378\n",
      "Epoch 042 | Train Loss: 0.1145 Acc: 0.9559 | Val Loss: 0.2148 Acc: 0.9239\n",
      "Epoch 043 | Train Loss: 0.1038 Acc: 0.9589 | Val Loss: 0.1643 Acc: 0.9342\n",
      "Epoch 044 | Train Loss: 0.1087 Acc: 0.9562 | Val Loss: 0.1513 Acc: 0.9402\n",
      "Epoch 045 | Train Loss: 0.0909 Acc: 0.9671 | Val Loss: 0.1840 Acc: 0.9330\n",
      "Epoch 046 | Train Loss: 0.1005 Acc: 0.9609 | Val Loss: 0.1682 Acc: 0.9372\n",
      "Epoch 047 | Train Loss: 0.0868 Acc: 0.9678 | Val Loss: 0.1714 Acc: 0.9354\n",
      "Epoch 048 | Train Loss: 0.0809 Acc: 0.9698 | Val Loss: 0.1761 Acc: 0.9360\n",
      "Epoch 049 | Train Loss: 0.0900 Acc: 0.9687 | Val Loss: 0.1636 Acc: 0.9402\n",
      "Epoch 050 | Train Loss: 0.0847 Acc: 0.9672 | Val Loss: 0.1522 Acc: 0.9444\n",
      "Epoch 051 | Train Loss: 0.0906 Acc: 0.9675 | Val Loss: 0.1551 Acc: 0.9396\n",
      "Epoch 052 | Train Loss: 0.0801 Acc: 0.9703 | Val Loss: 0.1622 Acc: 0.9402\n",
      "Epoch 053 | Train Loss: 0.0798 Acc: 0.9707 | Val Loss: 0.1649 Acc: 0.9457\n",
      "Epoch 054 | Train Loss: 0.0774 Acc: 0.9716 | Val Loss: 0.1729 Acc: 0.9438\n",
      "Early stopping triggered.\n",
      "Epoch 001 | Train Loss: 0.6787 Acc: 0.5778 | Val Loss: 0.6745 Acc: 0.5900\n",
      "Epoch 002 | Train Loss: 0.6590 Acc: 0.6097 | Val Loss: 0.6715 Acc: 0.5851\n",
      "Epoch 003 | Train Loss: 0.6067 Acc: 0.6737 | Val Loss: 0.6012 Acc: 0.6818\n",
      "Epoch 004 | Train Loss: 0.5652 Acc: 0.7217 | Val Loss: 0.5635 Acc: 0.7065\n",
      "Epoch 005 | Train Loss: 0.5388 Acc: 0.7350 | Val Loss: 0.5240 Acc: 0.7325\n",
      "Epoch 006 | Train Loss: 0.5156 Acc: 0.7498 | Val Loss: 0.5122 Acc: 0.7470\n",
      "Epoch 007 | Train Loss: 0.4971 Acc: 0.7651 | Val Loss: 0.5019 Acc: 0.7548\n",
      "Epoch 008 | Train Loss: 0.4615 Acc: 0.7897 | Val Loss: 0.4714 Acc: 0.7784\n",
      "Epoch 009 | Train Loss: 0.4524 Acc: 0.7977 | Val Loss: 0.4454 Acc: 0.7844\n",
      "Epoch 010 | Train Loss: 0.4246 Acc: 0.8057 | Val Loss: 0.4080 Acc: 0.8056\n",
      "Epoch 011 | Train Loss: 0.3999 Acc: 0.8179 | Val Loss: 0.4289 Acc: 0.8001\n",
      "Epoch 012 | Train Loss: 0.3793 Acc: 0.8333 | Val Loss: 0.4051 Acc: 0.8104\n",
      "Epoch 013 | Train Loss: 0.3519 Acc: 0.8460 | Val Loss: 0.3670 Acc: 0.8321\n",
      "Epoch 014 | Train Loss: 0.3311 Acc: 0.8570 | Val Loss: 0.3495 Acc: 0.8376\n",
      "Epoch 015 | Train Loss: 0.3078 Acc: 0.8700 | Val Loss: 0.2913 Acc: 0.8774\n",
      "Epoch 016 | Train Loss: 0.2899 Acc: 0.8795 | Val Loss: 0.2966 Acc: 0.8671\n",
      "Epoch 017 | Train Loss: 0.2549 Acc: 0.8955 | Val Loss: 0.3791 Acc: 0.8406\n",
      "Epoch 018 | Train Loss: 0.2517 Acc: 0.8936 | Val Loss: 0.2523 Acc: 0.8901\n",
      "Epoch 019 | Train Loss: 0.2241 Acc: 0.9132 | Val Loss: 0.2570 Acc: 0.8961\n",
      "Epoch 020 | Train Loss: 0.2086 Acc: 0.9182 | Val Loss: 0.2338 Acc: 0.8967\n",
      "Epoch 021 | Train Loss: 0.2015 Acc: 0.9200 | Val Loss: 0.2450 Acc: 0.8998\n",
      "Epoch 022 | Train Loss: 0.1957 Acc: 0.9225 | Val Loss: 0.2360 Acc: 0.8986\n",
      "Epoch 023 | Train Loss: 0.1853 Acc: 0.9302 | Val Loss: 0.2292 Acc: 0.9034\n",
      "Epoch 024 | Train Loss: 0.1794 Acc: 0.9319 | Val Loss: 0.2388 Acc: 0.9016\n",
      "Epoch 025 | Train Loss: 0.1593 Acc: 0.9366 | Val Loss: 0.2307 Acc: 0.9088\n",
      "Epoch 026 | Train Loss: 0.1725 Acc: 0.9337 | Val Loss: 0.1944 Acc: 0.9221\n",
      "Epoch 027 | Train Loss: 0.1354 Acc: 0.9472 | Val Loss: 0.2143 Acc: 0.9155\n",
      "Epoch 028 | Train Loss: 0.1413 Acc: 0.9440 | Val Loss: 0.1962 Acc: 0.9263\n",
      "Epoch 029 | Train Loss: 0.1369 Acc: 0.9462 | Val Loss: 0.2423 Acc: 0.9203\n",
      "Epoch 030 | Train Loss: 0.1320 Acc: 0.9496 | Val Loss: 0.2166 Acc: 0.9155\n",
      "Epoch 031 | Train Loss: 0.1271 Acc: 0.9517 | Val Loss: 0.2140 Acc: 0.9227\n",
      "Epoch 032 | Train Loss: 0.1263 Acc: 0.9500 | Val Loss: 0.1737 Acc: 0.9330\n",
      "Epoch 033 | Train Loss: 0.1131 Acc: 0.9597 | Val Loss: 0.1919 Acc: 0.9281\n",
      "Epoch 034 | Train Loss: 0.1079 Acc: 0.9588 | Val Loss: 0.2002 Acc: 0.9263\n",
      "Epoch 035 | Train Loss: 0.1103 Acc: 0.9616 | Val Loss: 0.1756 Acc: 0.9324\n",
      "Epoch 036 | Train Loss: 0.1015 Acc: 0.9621 | Val Loss: 0.2061 Acc: 0.9251\n",
      "Epoch 037 | Train Loss: 0.1044 Acc: 0.9632 | Val Loss: 0.1978 Acc: 0.9300\n",
      "Epoch 038 | Train Loss: 0.0959 Acc: 0.9656 | Val Loss: 0.1761 Acc: 0.9366\n",
      "Epoch 039 | Train Loss: 0.0917 Acc: 0.9678 | Val Loss: 0.1892 Acc: 0.9360\n",
      "Epoch 040 | Train Loss: 0.0948 Acc: 0.9639 | Val Loss: 0.1886 Acc: 0.9348\n",
      "Epoch 041 | Train Loss: 0.0848 Acc: 0.9672 | Val Loss: 0.1694 Acc: 0.9366\n",
      "Epoch 042 | Train Loss: 0.0974 Acc: 0.9638 | Val Loss: 0.1818 Acc: 0.9318\n",
      "Epoch 043 | Train Loss: 0.0758 Acc: 0.9709 | Val Loss: 0.1842 Acc: 0.9306\n",
      "Epoch 044 | Train Loss: 0.0748 Acc: 0.9743 | Val Loss: 0.2085 Acc: 0.9293\n",
      "Epoch 045 | Train Loss: 0.0915 Acc: 0.9663 | Val Loss: 0.1849 Acc: 0.9300\n",
      "Epoch 046 | Train Loss: 0.0723 Acc: 0.9736 | Val Loss: 0.1598 Acc: 0.9396\n",
      "Epoch 047 | Train Loss: 0.0830 Acc: 0.9680 | Val Loss: 0.2290 Acc: 0.9209\n",
      "Epoch 048 | Train Loss: 0.0870 Acc: 0.9681 | Val Loss: 0.1551 Acc: 0.9438\n",
      "Epoch 049 | Train Loss: 0.0760 Acc: 0.9728 | Val Loss: 0.1497 Acc: 0.9493\n",
      "Epoch 050 | Train Loss: 0.0683 Acc: 0.9746 | Val Loss: 0.1464 Acc: 0.9450\n",
      "Epoch 051 | Train Loss: 0.0637 Acc: 0.9786 | Val Loss: 0.1561 Acc: 0.9457\n",
      "Epoch 052 | Train Loss: 0.0727 Acc: 0.9733 | Val Loss: 0.1645 Acc: 0.9324\n",
      "Epoch 053 | Train Loss: 0.0647 Acc: 0.9764 | Val Loss: 0.1767 Acc: 0.9402\n",
      "Epoch 054 | Train Loss: 0.0634 Acc: 0.9760 | Val Loss: 0.1663 Acc: 0.9390\n",
      "Epoch 055 | Train Loss: 0.0772 Acc: 0.9715 | Val Loss: 0.1893 Acc: 0.9390\n",
      "Epoch 056 | Train Loss: 0.0788 Acc: 0.9718 | Val Loss: 0.1459 Acc: 0.9523\n",
      "Epoch 057 | Train Loss: 0.0673 Acc: 0.9755 | Val Loss: 0.1806 Acc: 0.9402\n",
      "Epoch 058 | Train Loss: 0.0584 Acc: 0.9790 | Val Loss: 0.1944 Acc: 0.9420\n",
      "Epoch 059 | Train Loss: 0.0601 Acc: 0.9764 | Val Loss: 0.1696 Acc: 0.9396\n",
      "Epoch 060 | Train Loss: 0.0562 Acc: 0.9787 | Val Loss: 0.1545 Acc: 0.9475\n",
      "Epoch 001 | Train Loss: 0.6835 Acc: 0.5747 | Val Loss: 0.6763 Acc: 0.5900\n",
      "Epoch 002 | Train Loss: 0.6760 Acc: 0.5851 | Val Loss: 0.6773 Acc: 0.5767\n",
      "Epoch 003 | Train Loss: 0.6702 Acc: 0.5979 | Val Loss: 0.6704 Acc: 0.5978\n",
      "Epoch 004 | Train Loss: 0.6441 Acc: 0.6354 | Val Loss: 0.6170 Acc: 0.6697\n",
      "Epoch 005 | Train Loss: 0.5939 Acc: 0.7003 | Val Loss: 0.5636 Acc: 0.7168\n",
      "Epoch 006 | Train Loss: 0.5546 Acc: 0.7331 | Val Loss: 0.5457 Acc: 0.7295\n",
      "Epoch 007 | Train Loss: 0.5271 Acc: 0.7512 | Val Loss: 0.5221 Acc: 0.7415\n",
      "Epoch 008 | Train Loss: 0.4861 Acc: 0.7758 | Val Loss: 0.4673 Acc: 0.7784\n",
      "Epoch 009 | Train Loss: 0.4565 Acc: 0.7960 | Val Loss: 0.4034 Acc: 0.8164\n",
      "Epoch 010 | Train Loss: 0.4227 Acc: 0.8096 | Val Loss: 0.3903 Acc: 0.8207\n",
      "Epoch 011 | Train Loss: 0.4070 Acc: 0.8211 | Val Loss: 0.4281 Acc: 0.7989\n",
      "Epoch 012 | Train Loss: 0.3836 Acc: 0.8347 | Val Loss: 0.3704 Acc: 0.8376\n",
      "Epoch 013 | Train Loss: 0.3531 Acc: 0.8513 | Val Loss: 0.3425 Acc: 0.8484\n",
      "Epoch 014 | Train Loss: 0.3387 Acc: 0.8579 | Val Loss: 0.3011 Acc: 0.8714\n",
      "Epoch 015 | Train Loss: 0.3272 Acc: 0.8590 | Val Loss: 0.3011 Acc: 0.8708\n",
      "Epoch 016 | Train Loss: 0.3121 Acc: 0.8703 | Val Loss: 0.3027 Acc: 0.8684\n",
      "Epoch 017 | Train Loss: 0.2949 Acc: 0.8791 | Val Loss: 0.2784 Acc: 0.8877\n",
      "Epoch 018 | Train Loss: 0.2721 Acc: 0.8890 | Val Loss: 0.2902 Acc: 0.8732\n",
      "Epoch 019 | Train Loss: 0.2679 Acc: 0.8874 | Val Loss: 0.2499 Acc: 0.9076\n",
      "Epoch 020 | Train Loss: 0.2621 Acc: 0.8917 | Val Loss: 0.2552 Acc: 0.8986\n",
      "Epoch 021 | Train Loss: 0.2583 Acc: 0.8979 | Val Loss: 0.2404 Acc: 0.8986\n",
      "Epoch 022 | Train Loss: 0.2410 Acc: 0.8991 | Val Loss: 0.2382 Acc: 0.9100\n",
      "Epoch 023 | Train Loss: 0.2343 Acc: 0.9108 | Val Loss: 0.2283 Acc: 0.9064\n",
      "Epoch 024 | Train Loss: 0.2235 Acc: 0.9106 | Val Loss: 0.2200 Acc: 0.9155\n",
      "Epoch 025 | Train Loss: 0.2114 Acc: 0.9182 | Val Loss: 0.2289 Acc: 0.9136\n",
      "Epoch 026 | Train Loss: 0.2114 Acc: 0.9177 | Val Loss: 0.2420 Acc: 0.9004\n",
      "Epoch 027 | Train Loss: 0.2090 Acc: 0.9148 | Val Loss: 0.2081 Acc: 0.9215\n",
      "Epoch 028 | Train Loss: 0.2080 Acc: 0.9183 | Val Loss: 0.2214 Acc: 0.9130\n",
      "Epoch 029 | Train Loss: 0.2007 Acc: 0.9201 | Val Loss: 0.2525 Acc: 0.8979\n",
      "Epoch 030 | Train Loss: 0.2088 Acc: 0.9182 | Val Loss: 0.1977 Acc: 0.9203\n",
      "Epoch 031 | Train Loss: 0.1857 Acc: 0.9278 | Val Loss: 0.2157 Acc: 0.9215\n",
      "Epoch 032 | Train Loss: 0.1910 Acc: 0.9245 | Val Loss: 0.2114 Acc: 0.9179\n",
      "Epoch 033 | Train Loss: 0.1787 Acc: 0.9352 | Val Loss: 0.2207 Acc: 0.9136\n",
      "Epoch 034 | Train Loss: 0.1670 Acc: 0.9322 | Val Loss: 0.2009 Acc: 0.9191\n",
      "Epoch 035 | Train Loss: 0.1775 Acc: 0.9319 | Val Loss: 0.2183 Acc: 0.9070\n",
      "Epoch 036 | Train Loss: 0.1710 Acc: 0.9337 | Val Loss: 0.2123 Acc: 0.9179\n",
      "Epoch 037 | Train Loss: 0.1628 Acc: 0.9345 | Val Loss: 0.1814 Acc: 0.9312\n",
      "Epoch 038 | Train Loss: 0.1601 Acc: 0.9402 | Val Loss: 0.1932 Acc: 0.9227\n",
      "Epoch 039 | Train Loss: 0.1584 Acc: 0.9381 | Val Loss: 0.1648 Acc: 0.9384\n",
      "Epoch 040 | Train Loss: 0.1636 Acc: 0.9358 | Val Loss: 0.1904 Acc: 0.9269\n",
      "Epoch 041 | Train Loss: 0.1545 Acc: 0.9410 | Val Loss: 0.1812 Acc: 0.9336\n",
      "Epoch 042 | Train Loss: 0.1528 Acc: 0.9401 | Val Loss: 0.1670 Acc: 0.9348\n",
      "Epoch 043 | Train Loss: 0.1429 Acc: 0.9458 | Val Loss: 0.1834 Acc: 0.9209\n",
      "Epoch 044 | Train Loss: 0.1440 Acc: 0.9475 | Val Loss: 0.1779 Acc: 0.9366\n",
      "Epoch 045 | Train Loss: 0.1373 Acc: 0.9493 | Val Loss: 0.1712 Acc: 0.9414\n",
      "Epoch 046 | Train Loss: 0.1471 Acc: 0.9446 | Val Loss: 0.1847 Acc: 0.9287\n",
      "Epoch 047 | Train Loss: 0.1449 Acc: 0.9413 | Val Loss: 0.1696 Acc: 0.9366\n",
      "Epoch 048 | Train Loss: 0.1366 Acc: 0.9490 | Val Loss: 0.1848 Acc: 0.9342\n",
      "Epoch 049 | Train Loss: 0.1272 Acc: 0.9550 | Val Loss: 0.1614 Acc: 0.9378\n",
      "Epoch 050 | Train Loss: 0.1313 Acc: 0.9485 | Val Loss: 0.1623 Acc: 0.9378\n",
      "Epoch 051 | Train Loss: 0.1341 Acc: 0.9490 | Val Loss: 0.1589 Acc: 0.9420\n",
      "Epoch 052 | Train Loss: 0.1312 Acc: 0.9488 | Val Loss: 0.2040 Acc: 0.9227\n",
      "Epoch 053 | Train Loss: 0.1270 Acc: 0.9506 | Val Loss: 0.1670 Acc: 0.9487\n",
      "Epoch 054 | Train Loss: 0.1270 Acc: 0.9484 | Val Loss: 0.1507 Acc: 0.9444\n",
      "Epoch 055 | Train Loss: 0.1186 Acc: 0.9567 | Val Loss: 0.1640 Acc: 0.9438\n",
      "Epoch 056 | Train Loss: 0.1292 Acc: 0.9532 | Val Loss: 0.1815 Acc: 0.9306\n",
      "Epoch 057 | Train Loss: 0.1148 Acc: 0.9592 | Val Loss: 0.1838 Acc: 0.9324\n",
      "Epoch 058 | Train Loss: 0.1304 Acc: 0.9497 | Val Loss: 0.1725 Acc: 0.9372\n",
      "Epoch 059 | Train Loss: 0.1169 Acc: 0.9524 | Val Loss: 0.1440 Acc: 0.9511\n",
      "Epoch 060 | Train Loss: 0.1126 Acc: 0.9597 | Val Loss: 0.1406 Acc: 0.9517\n",
      "Epoch 001 | Train Loss: 0.6796 Acc: 0.5786 | Val Loss: 0.6767 Acc: 0.5851\n",
      "Epoch 002 | Train Loss: 0.6704 Acc: 0.5931 | Val Loss: 0.6623 Acc: 0.6045\n",
      "Epoch 003 | Train Loss: 0.6555 Acc: 0.6127 | Val Loss: 0.6363 Acc: 0.6473\n",
      "Epoch 004 | Train Loss: 0.6277 Acc: 0.6597 | Val Loss: 0.6088 Acc: 0.6721\n",
      "Epoch 005 | Train Loss: 0.6040 Acc: 0.6840 | Val Loss: 0.5944 Acc: 0.6908\n",
      "Epoch 006 | Train Loss: 0.5743 Acc: 0.7119 | Val Loss: 0.5612 Acc: 0.7114\n",
      "Epoch 007 | Train Loss: 0.5522 Acc: 0.7257 | Val Loss: 0.5825 Acc: 0.7071\n",
      "Epoch 008 | Train Loss: 0.5425 Acc: 0.7303 | Val Loss: 0.5406 Acc: 0.7343\n",
      "Epoch 009 | Train Loss: 0.5217 Acc: 0.7436 | Val Loss: 0.5289 Acc: 0.7385\n",
      "Epoch 010 | Train Loss: 0.5104 Acc: 0.7533 | Val Loss: 0.4975 Acc: 0.7627\n",
      "Epoch 011 | Train Loss: 0.4871 Acc: 0.7660 | Val Loss: 0.4918 Acc: 0.7566\n",
      "Epoch 012 | Train Loss: 0.4652 Acc: 0.7758 | Val Loss: 0.4644 Acc: 0.7832\n",
      "Epoch 013 | Train Loss: 0.4481 Acc: 0.7889 | Val Loss: 0.4426 Acc: 0.7844\n",
      "Epoch 014 | Train Loss: 0.4286 Acc: 0.7998 | Val Loss: 0.4366 Acc: 0.7953\n",
      "Epoch 015 | Train Loss: 0.4082 Acc: 0.8102 | Val Loss: 0.4070 Acc: 0.8074\n",
      "Epoch 016 | Train Loss: 0.3862 Acc: 0.8181 | Val Loss: 0.3819 Acc: 0.8207\n",
      "Epoch 017 | Train Loss: 0.3785 Acc: 0.8286 | Val Loss: 0.3600 Acc: 0.8412\n",
      "Epoch 018 | Train Loss: 0.3601 Acc: 0.8384 | Val Loss: 0.3424 Acc: 0.8569\n",
      "Epoch 019 | Train Loss: 0.3340 Acc: 0.8540 | Val Loss: 0.3250 Acc: 0.8527\n",
      "Epoch 020 | Train Loss: 0.3333 Acc: 0.8544 | Val Loss: 0.3314 Acc: 0.8551\n",
      "Epoch 021 | Train Loss: 0.3083 Acc: 0.8608 | Val Loss: 0.3091 Acc: 0.8563\n",
      "Epoch 022 | Train Loss: 0.2902 Acc: 0.8727 | Val Loss: 0.2780 Acc: 0.8798\n",
      "Epoch 023 | Train Loss: 0.2748 Acc: 0.8851 | Val Loss: 0.2714 Acc: 0.8865\n",
      "Epoch 024 | Train Loss: 0.2657 Acc: 0.8883 | Val Loss: 0.2769 Acc: 0.8859\n",
      "Epoch 025 | Train Loss: 0.2545 Acc: 0.8923 | Val Loss: 0.2707 Acc: 0.8835\n",
      "Epoch 026 | Train Loss: 0.2527 Acc: 0.8934 | Val Loss: 0.2521 Acc: 0.8986\n",
      "Epoch 027 | Train Loss: 0.2313 Acc: 0.9014 | Val Loss: 0.2577 Acc: 0.8907\n",
      "Epoch 028 | Train Loss: 0.2219 Acc: 0.9074 | Val Loss: 0.2326 Acc: 0.9004\n",
      "Epoch 029 | Train Loss: 0.2090 Acc: 0.9145 | Val Loss: 0.2217 Acc: 0.9082\n",
      "Epoch 030 | Train Loss: 0.2058 Acc: 0.9188 | Val Loss: 0.2187 Acc: 0.9106\n",
      "Epoch 031 | Train Loss: 0.1849 Acc: 0.9242 | Val Loss: 0.2023 Acc: 0.9269\n",
      "Epoch 032 | Train Loss: 0.1895 Acc: 0.9230 | Val Loss: 0.2078 Acc: 0.9155\n",
      "Epoch 033 | Train Loss: 0.1901 Acc: 0.9218 | Val Loss: 0.2044 Acc: 0.9173\n",
      "Epoch 034 | Train Loss: 0.1720 Acc: 0.9304 | Val Loss: 0.2366 Acc: 0.9088\n",
      "Epoch 035 | Train Loss: 0.1668 Acc: 0.9328 | Val Loss: 0.2016 Acc: 0.9227\n",
      "Epoch 036 | Train Loss: 0.1712 Acc: 0.9298 | Val Loss: 0.2403 Acc: 0.9028\n",
      "Epoch 037 | Train Loss: 0.1529 Acc: 0.9405 | Val Loss: 0.1858 Acc: 0.9263\n",
      "Epoch 038 | Train Loss: 0.1567 Acc: 0.9385 | Val Loss: 0.1941 Acc: 0.9257\n",
      "Epoch 039 | Train Loss: 0.1392 Acc: 0.9438 | Val Loss: 0.1684 Acc: 0.9360\n",
      "Epoch 040 | Train Loss: 0.1349 Acc: 0.9488 | Val Loss: 0.1827 Acc: 0.9336\n",
      "Epoch 041 | Train Loss: 0.1317 Acc: 0.9490 | Val Loss: 0.1961 Acc: 0.9300\n",
      "Epoch 042 | Train Loss: 0.1268 Acc: 0.9494 | Val Loss: 0.2045 Acc: 0.9287\n",
      "Epoch 043 | Train Loss: 0.1187 Acc: 0.9544 | Val Loss: 0.1827 Acc: 0.9300\n",
      "Epoch 044 | Train Loss: 0.1231 Acc: 0.9544 | Val Loss: 0.1597 Acc: 0.9402\n",
      "Epoch 045 | Train Loss: 0.1191 Acc: 0.9562 | Val Loss: 0.2175 Acc: 0.9257\n",
      "Epoch 046 | Train Loss: 0.1152 Acc: 0.9582 | Val Loss: 0.1909 Acc: 0.9293\n",
      "Epoch 047 | Train Loss: 0.1165 Acc: 0.9555 | Val Loss: 0.1819 Acc: 0.9293\n",
      "Epoch 048 | Train Loss: 0.1047 Acc: 0.9600 | Val Loss: 0.1770 Acc: 0.9348\n",
      "Epoch 049 | Train Loss: 0.1152 Acc: 0.9549 | Val Loss: 0.1717 Acc: 0.9360\n",
      "Epoch 050 | Train Loss: 0.0970 Acc: 0.9642 | Val Loss: 0.1614 Acc: 0.9384\n",
      "Epoch 051 | Train Loss: 0.0949 Acc: 0.9607 | Val Loss: 0.1731 Acc: 0.9360\n",
      "Epoch 052 | Train Loss: 0.0972 Acc: 0.9626 | Val Loss: 0.1945 Acc: 0.9312\n",
      "Epoch 053 | Train Loss: 0.0930 Acc: 0.9657 | Val Loss: 0.1718 Acc: 0.9444\n",
      "Epoch 054 | Train Loss: 0.0908 Acc: 0.9660 | Val Loss: 0.1632 Acc: 0.9390\n",
      "Early stopping triggered.\n",
      "Iteration 21/40 | Best Val Loss: 0.1122 | Iter Time: 237.37s | Total Time: 89.84 min\n",
      "Epoch 001 | Train Loss: 0.6803 Acc: 0.5822 | Val Loss: 0.6748 Acc: 0.5924\n",
      "Epoch 002 | Train Loss: 0.6761 Acc: 0.5901 | Val Loss: 0.6739 Acc: 0.5936\n",
      "Epoch 003 | Train Loss: 0.6647 Acc: 0.6043 | Val Loss: 0.6609 Acc: 0.6051\n",
      "Epoch 004 | Train Loss: 0.6411 Acc: 0.6393 | Val Loss: 0.6180 Acc: 0.6709\n",
      "Epoch 005 | Train Loss: 0.5869 Acc: 0.6998 | Val Loss: 0.5733 Acc: 0.7107\n",
      "Epoch 006 | Train Loss: 0.5484 Acc: 0.7340 | Val Loss: 0.5397 Acc: 0.7307\n",
      "Epoch 007 | Train Loss: 0.5173 Acc: 0.7494 | Val Loss: 0.5145 Acc: 0.7512\n",
      "Epoch 008 | Train Loss: 0.4938 Acc: 0.7693 | Val Loss: 0.4804 Acc: 0.7657\n",
      "Epoch 009 | Train Loss: 0.4781 Acc: 0.7700 | Val Loss: 0.4661 Acc: 0.7893\n",
      "Epoch 010 | Train Loss: 0.4527 Acc: 0.7957 | Val Loss: 0.4474 Acc: 0.7832\n",
      "Epoch 011 | Train Loss: 0.4349 Acc: 0.8007 | Val Loss: 0.4476 Acc: 0.7929\n",
      "Epoch 012 | Train Loss: 0.4082 Acc: 0.8200 | Val Loss: 0.4009 Acc: 0.8104\n",
      "Epoch 013 | Train Loss: 0.3916 Acc: 0.8283 | Val Loss: 0.3880 Acc: 0.8194\n",
      "Epoch 014 | Train Loss: 0.3797 Acc: 0.8357 | Val Loss: 0.3476 Acc: 0.8442\n",
      "Epoch 015 | Train Loss: 0.3439 Acc: 0.8495 | Val Loss: 0.3424 Acc: 0.8533\n",
      "Epoch 016 | Train Loss: 0.3309 Acc: 0.8563 | Val Loss: 0.3091 Acc: 0.8551\n",
      "Epoch 017 | Train Loss: 0.2989 Acc: 0.8697 | Val Loss: 0.3090 Acc: 0.8708\n",
      "Epoch 018 | Train Loss: 0.2851 Acc: 0.8792 | Val Loss: 0.2880 Acc: 0.8653\n",
      "Epoch 019 | Train Loss: 0.2590 Acc: 0.8939 | Val Loss: 0.2736 Acc: 0.8774\n",
      "Epoch 020 | Train Loss: 0.2539 Acc: 0.8943 | Val Loss: 0.2560 Acc: 0.8913\n",
      "Epoch 021 | Train Loss: 0.2314 Acc: 0.9065 | Val Loss: 0.2471 Acc: 0.8943\n",
      "Epoch 022 | Train Loss: 0.2303 Acc: 0.9053 | Val Loss: 0.2522 Acc: 0.8907\n",
      "Epoch 023 | Train Loss: 0.2121 Acc: 0.9144 | Val Loss: 0.2415 Acc: 0.8973\n",
      "Epoch 024 | Train Loss: 0.2038 Acc: 0.9195 | Val Loss: 0.2227 Acc: 0.9100\n",
      "Epoch 025 | Train Loss: 0.1855 Acc: 0.9266 | Val Loss: 0.2514 Acc: 0.8973\n",
      "Epoch 026 | Train Loss: 0.1799 Acc: 0.9333 | Val Loss: 0.3035 Acc: 0.8696\n",
      "Epoch 027 | Train Loss: 0.1720 Acc: 0.9328 | Val Loss: 0.2267 Acc: 0.9106\n",
      "Epoch 028 | Train Loss: 0.1627 Acc: 0.9390 | Val Loss: 0.2020 Acc: 0.9221\n",
      "Epoch 029 | Train Loss: 0.1587 Acc: 0.9370 | Val Loss: 0.2003 Acc: 0.9149\n",
      "Epoch 030 | Train Loss: 0.1471 Acc: 0.9432 | Val Loss: 0.2397 Acc: 0.9034\n",
      "Epoch 031 | Train Loss: 0.1376 Acc: 0.9434 | Val Loss: 0.2202 Acc: 0.9094\n",
      "Epoch 032 | Train Loss: 0.1501 Acc: 0.9405 | Val Loss: 0.2157 Acc: 0.9124\n",
      "Epoch 033 | Train Loss: 0.1309 Acc: 0.9497 | Val Loss: 0.1989 Acc: 0.9191\n",
      "Epoch 034 | Train Loss: 0.1221 Acc: 0.9530 | Val Loss: 0.2019 Acc: 0.9155\n",
      "Epoch 035 | Train Loss: 0.1204 Acc: 0.9541 | Val Loss: 0.1903 Acc: 0.9293\n",
      "Epoch 036 | Train Loss: 0.1136 Acc: 0.9579 | Val Loss: 0.2081 Acc: 0.9269\n",
      "Epoch 037 | Train Loss: 0.1064 Acc: 0.9623 | Val Loss: 0.2056 Acc: 0.9161\n",
      "Epoch 038 | Train Loss: 0.1030 Acc: 0.9592 | Val Loss: 0.1866 Acc: 0.9318\n",
      "Epoch 039 | Train Loss: 0.1032 Acc: 0.9589 | Val Loss: 0.1867 Acc: 0.9263\n",
      "Epoch 040 | Train Loss: 0.1002 Acc: 0.9616 | Val Loss: 0.1717 Acc: 0.9281\n",
      "Epoch 041 | Train Loss: 0.0940 Acc: 0.9647 | Val Loss: 0.1843 Acc: 0.9324\n",
      "Epoch 042 | Train Loss: 0.0993 Acc: 0.9623 | Val Loss: 0.1795 Acc: 0.9366\n",
      "Epoch 043 | Train Loss: 0.0882 Acc: 0.9663 | Val Loss: 0.1913 Acc: 0.9269\n",
      "Epoch 044 | Train Loss: 0.0871 Acc: 0.9666 | Val Loss: 0.2082 Acc: 0.9354\n",
      "Epoch 045 | Train Loss: 0.0798 Acc: 0.9703 | Val Loss: 0.1953 Acc: 0.9239\n",
      "Epoch 046 | Train Loss: 0.0812 Acc: 0.9706 | Val Loss: 0.1805 Acc: 0.9336\n",
      "Epoch 047 | Train Loss: 0.0755 Acc: 0.9728 | Val Loss: 0.2041 Acc: 0.9275\n",
      "Epoch 048 | Train Loss: 0.0784 Acc: 0.9712 | Val Loss: 0.1710 Acc: 0.9348\n",
      "Epoch 049 | Train Loss: 0.0668 Acc: 0.9739 | Val Loss: 0.1717 Acc: 0.9372\n",
      "Epoch 050 | Train Loss: 0.0726 Acc: 0.9722 | Val Loss: 0.1766 Acc: 0.9281\n",
      "Epoch 051 | Train Loss: 0.0747 Acc: 0.9722 | Val Loss: 0.1860 Acc: 0.9384\n",
      "Epoch 052 | Train Loss: 0.0777 Acc: 0.9719 | Val Loss: 0.1668 Acc: 0.9366\n",
      "Epoch 053 | Train Loss: 0.0657 Acc: 0.9752 | Val Loss: 0.1780 Acc: 0.9312\n",
      "Epoch 054 | Train Loss: 0.0660 Acc: 0.9755 | Val Loss: 0.1728 Acc: 0.9384\n",
      "Epoch 055 | Train Loss: 0.0603 Acc: 0.9775 | Val Loss: 0.1604 Acc: 0.9396\n",
      "Epoch 056 | Train Loss: 0.0599 Acc: 0.9774 | Val Loss: 0.1542 Acc: 0.9457\n",
      "Epoch 057 | Train Loss: 0.0595 Acc: 0.9780 | Val Loss: 0.1802 Acc: 0.9348\n",
      "Epoch 058 | Train Loss: 0.0571 Acc: 0.9777 | Val Loss: 0.1757 Acc: 0.9438\n",
      "Epoch 059 | Train Loss: 0.0674 Acc: 0.9737 | Val Loss: 0.1619 Acc: 0.9432\n",
      "Epoch 060 | Train Loss: 0.0593 Acc: 0.9769 | Val Loss: 0.1403 Acc: 0.9487\n",
      "Epoch 001 | Train Loss: 0.6806 Acc: 0.5825 | Val Loss: 0.6740 Acc: 0.5930\n",
      "Epoch 002 | Train Loss: 0.6668 Acc: 0.6008 | Val Loss: 0.6598 Acc: 0.6063\n",
      "Epoch 003 | Train Loss: 0.6453 Acc: 0.6329 | Val Loss: 0.6058 Acc: 0.6926\n",
      "Epoch 004 | Train Loss: 0.6125 Acc: 0.6770 | Val Loss: 0.5910 Acc: 0.6999\n",
      "Epoch 005 | Train Loss: 0.5772 Acc: 0.7112 | Val Loss: 0.5714 Acc: 0.7144\n",
      "Epoch 006 | Train Loss: 0.5567 Acc: 0.7288 | Val Loss: 0.5604 Acc: 0.7138\n",
      "Epoch 007 | Train Loss: 0.5436 Acc: 0.7386 | Val Loss: 0.5560 Acc: 0.7234\n",
      "Epoch 008 | Train Loss: 0.5286 Acc: 0.7442 | Val Loss: 0.5320 Acc: 0.7313\n",
      "Epoch 009 | Train Loss: 0.5190 Acc: 0.7465 | Val Loss: 0.5348 Acc: 0.7349\n",
      "Epoch 010 | Train Loss: 0.4902 Acc: 0.7675 | Val Loss: 0.5002 Acc: 0.7536\n",
      "Epoch 011 | Train Loss: 0.4753 Acc: 0.7808 | Val Loss: 0.4895 Acc: 0.7693\n",
      "Epoch 012 | Train Loss: 0.4540 Acc: 0.7931 | Val Loss: 0.4899 Acc: 0.7748\n",
      "Epoch 013 | Train Loss: 0.4405 Acc: 0.7936 | Val Loss: 0.5430 Acc: 0.7506\n",
      "Epoch 014 | Train Loss: 0.4327 Acc: 0.8045 | Val Loss: 0.4448 Acc: 0.7820\n",
      "Epoch 015 | Train Loss: 0.4050 Acc: 0.8149 | Val Loss: 0.4289 Acc: 0.7911\n",
      "Epoch 016 | Train Loss: 0.3982 Acc: 0.8184 | Val Loss: 0.4231 Acc: 0.7874\n",
      "Epoch 017 | Train Loss: 0.3682 Acc: 0.8330 | Val Loss: 0.3928 Acc: 0.8031\n",
      "Epoch 018 | Train Loss: 0.3667 Acc: 0.8360 | Val Loss: 0.3946 Acc: 0.8098\n",
      "Epoch 019 | Train Loss: 0.3529 Acc: 0.8464 | Val Loss: 0.3669 Acc: 0.8333\n",
      "Epoch 020 | Train Loss: 0.3339 Acc: 0.8578 | Val Loss: 0.3519 Acc: 0.8321\n",
      "Epoch 021 | Train Loss: 0.3144 Acc: 0.8617 | Val Loss: 0.2911 Acc: 0.8696\n",
      "Epoch 022 | Train Loss: 0.2912 Acc: 0.8745 | Val Loss: 0.2939 Acc: 0.8671\n",
      "Epoch 023 | Train Loss: 0.2813 Acc: 0.8780 | Val Loss: 0.2686 Acc: 0.8744\n",
      "Epoch 024 | Train Loss: 0.2719 Acc: 0.8860 | Val Loss: 0.2983 Acc: 0.8635\n",
      "Epoch 025 | Train Loss: 0.2599 Acc: 0.8970 | Val Loss: 0.3005 Acc: 0.8629\n",
      "Epoch 026 | Train Loss: 0.2448 Acc: 0.8970 | Val Loss: 0.2663 Acc: 0.8829\n",
      "Epoch 027 | Train Loss: 0.2491 Acc: 0.8991 | Val Loss: 0.2659 Acc: 0.8949\n",
      "Epoch 028 | Train Loss: 0.2305 Acc: 0.9077 | Val Loss: 0.2263 Acc: 0.9064\n",
      "Epoch 029 | Train Loss: 0.2254 Acc: 0.9083 | Val Loss: 0.2318 Acc: 0.8979\n",
      "Epoch 030 | Train Loss: 0.2208 Acc: 0.9136 | Val Loss: 0.2378 Acc: 0.9034\n",
      "Epoch 031 | Train Loss: 0.2024 Acc: 0.9179 | Val Loss: 0.2260 Acc: 0.9082\n",
      "Epoch 032 | Train Loss: 0.2019 Acc: 0.9233 | Val Loss: 0.2378 Acc: 0.9070\n",
      "Epoch 033 | Train Loss: 0.2039 Acc: 0.9177 | Val Loss: 0.2583 Acc: 0.8816\n",
      "Epoch 034 | Train Loss: 0.1993 Acc: 0.9171 | Val Loss: 0.2202 Acc: 0.9022\n",
      "Epoch 035 | Train Loss: 0.1871 Acc: 0.9272 | Val Loss: 0.2129 Acc: 0.9118\n",
      "Epoch 036 | Train Loss: 0.1793 Acc: 0.9311 | Val Loss: 0.2223 Acc: 0.9167\n",
      "Epoch 037 | Train Loss: 0.1688 Acc: 0.9355 | Val Loss: 0.2095 Acc: 0.9149\n",
      "Epoch 038 | Train Loss: 0.1657 Acc: 0.9349 | Val Loss: 0.2140 Acc: 0.9185\n",
      "Epoch 039 | Train Loss: 0.1597 Acc: 0.9382 | Val Loss: 0.1985 Acc: 0.9173\n",
      "Epoch 040 | Train Loss: 0.1604 Acc: 0.9402 | Val Loss: 0.2598 Acc: 0.8992\n",
      "Epoch 041 | Train Loss: 0.1647 Acc: 0.9348 | Val Loss: 0.1957 Acc: 0.9215\n",
      "Epoch 042 | Train Loss: 0.1382 Acc: 0.9482 | Val Loss: 0.1989 Acc: 0.9245\n",
      "Epoch 043 | Train Loss: 0.1501 Acc: 0.9401 | Val Loss: 0.1965 Acc: 0.9197\n",
      "Epoch 044 | Train Loss: 0.1382 Acc: 0.9450 | Val Loss: 0.1847 Acc: 0.9306\n",
      "Epoch 045 | Train Loss: 0.1457 Acc: 0.9443 | Val Loss: 0.1717 Acc: 0.9300\n",
      "Epoch 046 | Train Loss: 0.1310 Acc: 0.9493 | Val Loss: 0.1890 Acc: 0.9269\n",
      "Epoch 047 | Train Loss: 0.1397 Acc: 0.9455 | Val Loss: 0.1940 Acc: 0.9233\n",
      "Epoch 048 | Train Loss: 0.1316 Acc: 0.9491 | Val Loss: 0.1628 Acc: 0.9324\n",
      "Epoch 049 | Train Loss: 0.1188 Acc: 0.9527 | Val Loss: 0.1659 Acc: 0.9408\n",
      "Epoch 050 | Train Loss: 0.1187 Acc: 0.9559 | Val Loss: 0.1757 Acc: 0.9324\n",
      "Epoch 051 | Train Loss: 0.1199 Acc: 0.9544 | Val Loss: 0.1649 Acc: 0.9354\n",
      "Epoch 052 | Train Loss: 0.1238 Acc: 0.9541 | Val Loss: 0.1774 Acc: 0.9336\n",
      "Epoch 053 | Train Loss: 0.1099 Acc: 0.9576 | Val Loss: 0.1726 Acc: 0.9384\n",
      "Epoch 054 | Train Loss: 0.1091 Acc: 0.9589 | Val Loss: 0.1922 Acc: 0.9251\n",
      "Epoch 055 | Train Loss: 0.1126 Acc: 0.9568 | Val Loss: 0.1757 Acc: 0.9378\n",
      "Epoch 056 | Train Loss: 0.1032 Acc: 0.9626 | Val Loss: 0.1842 Acc: 0.9354\n",
      "Epoch 057 | Train Loss: 0.1106 Acc: 0.9579 | Val Loss: 0.1872 Acc: 0.9251\n",
      "Epoch 058 | Train Loss: 0.1003 Acc: 0.9632 | Val Loss: 0.2027 Acc: 0.9306\n",
      "Early stopping triggered.\n",
      "Epoch 001 | Train Loss: 0.6813 Acc: 0.5786 | Val Loss: 0.6780 Acc: 0.5882\n",
      "Epoch 002 | Train Loss: 0.6735 Acc: 0.5901 | Val Loss: 0.6749 Acc: 0.5906\n",
      "Epoch 003 | Train Loss: 0.6564 Acc: 0.6109 | Val Loss: 0.6388 Acc: 0.6467\n",
      "Epoch 004 | Train Loss: 0.6185 Acc: 0.6749 | Val Loss: 0.5896 Acc: 0.6969\n",
      "Epoch 005 | Train Loss: 0.5808 Acc: 0.7075 | Val Loss: 0.5713 Acc: 0.7144\n",
      "Epoch 006 | Train Loss: 0.5615 Acc: 0.7213 | Val Loss: 0.5486 Acc: 0.7264\n",
      "Epoch 007 | Train Loss: 0.5411 Acc: 0.7299 | Val Loss: 0.5407 Acc: 0.7162\n",
      "Epoch 008 | Train Loss: 0.5208 Acc: 0.7498 | Val Loss: 0.5135 Acc: 0.7482\n",
      "Epoch 009 | Train Loss: 0.5039 Acc: 0.7589 | Val Loss: 0.4990 Acc: 0.7506\n",
      "Epoch 010 | Train Loss: 0.4778 Acc: 0.7740 | Val Loss: 0.4632 Acc: 0.7862\n",
      "Epoch 011 | Train Loss: 0.4538 Acc: 0.7854 | Val Loss: 0.4795 Acc: 0.7766\n",
      "Epoch 012 | Train Loss: 0.4554 Acc: 0.7850 | Val Loss: 0.4490 Acc: 0.7808\n",
      "Epoch 013 | Train Loss: 0.4141 Acc: 0.8104 | Val Loss: 0.4123 Acc: 0.8056\n",
      "Epoch 014 | Train Loss: 0.3952 Acc: 0.8212 | Val Loss: 0.3620 Acc: 0.8400\n",
      "Epoch 015 | Train Loss: 0.3734 Acc: 0.8401 | Val Loss: 0.4289 Acc: 0.7911\n",
      "Epoch 016 | Train Loss: 0.3440 Acc: 0.8466 | Val Loss: 0.3237 Acc: 0.8593\n",
      "Epoch 017 | Train Loss: 0.3266 Acc: 0.8591 | Val Loss: 0.3241 Acc: 0.8587\n",
      "Epoch 018 | Train Loss: 0.3046 Acc: 0.8682 | Val Loss: 0.2839 Acc: 0.8774\n",
      "Epoch 019 | Train Loss: 0.2786 Acc: 0.8837 | Val Loss: 0.2821 Acc: 0.8829\n",
      "Epoch 020 | Train Loss: 0.2622 Acc: 0.8892 | Val Loss: 0.2663 Acc: 0.8925\n",
      "Epoch 021 | Train Loss: 0.2472 Acc: 0.8984 | Val Loss: 0.2477 Acc: 0.8998\n",
      "Epoch 022 | Train Loss: 0.2367 Acc: 0.9011 | Val Loss: 0.2378 Acc: 0.9022\n",
      "Epoch 023 | Train Loss: 0.2175 Acc: 0.9127 | Val Loss: 0.2265 Acc: 0.9124\n",
      "Epoch 024 | Train Loss: 0.2056 Acc: 0.9153 | Val Loss: 0.2779 Acc: 0.8865\n",
      "Epoch 025 | Train Loss: 0.2062 Acc: 0.9145 | Val Loss: 0.2480 Acc: 0.8949\n",
      "Epoch 026 | Train Loss: 0.1914 Acc: 0.9259 | Val Loss: 0.2180 Acc: 0.9185\n",
      "Epoch 027 | Train Loss: 0.1902 Acc: 0.9257 | Val Loss: 0.2053 Acc: 0.9173\n",
      "Epoch 028 | Train Loss: 0.1873 Acc: 0.9247 | Val Loss: 0.2010 Acc: 0.9221\n",
      "Epoch 029 | Train Loss: 0.1665 Acc: 0.9315 | Val Loss: 0.2125 Acc: 0.9221\n",
      "Epoch 030 | Train Loss: 0.1640 Acc: 0.9381 | Val Loss: 0.1915 Acc: 0.9179\n",
      "Epoch 031 | Train Loss: 0.1535 Acc: 0.9385 | Val Loss: 0.1721 Acc: 0.9318\n",
      "Epoch 032 | Train Loss: 0.1495 Acc: 0.9431 | Val Loss: 0.2096 Acc: 0.9209\n",
      "Epoch 033 | Train Loss: 0.1358 Acc: 0.9503 | Val Loss: 0.1759 Acc: 0.9269\n",
      "Epoch 034 | Train Loss: 0.1397 Acc: 0.9455 | Val Loss: 0.2339 Acc: 0.9203\n",
      "Epoch 035 | Train Loss: 0.1401 Acc: 0.9456 | Val Loss: 0.1740 Acc: 0.9324\n",
      "Epoch 036 | Train Loss: 0.1258 Acc: 0.9511 | Val Loss: 0.1773 Acc: 0.9300\n",
      "Epoch 037 | Train Loss: 0.1290 Acc: 0.9503 | Val Loss: 0.1680 Acc: 0.9330\n",
      "Epoch 038 | Train Loss: 0.1160 Acc: 0.9555 | Val Loss: 0.1421 Acc: 0.9493\n",
      "Epoch 039 | Train Loss: 0.1045 Acc: 0.9615 | Val Loss: 0.1575 Acc: 0.9324\n",
      "Epoch 040 | Train Loss: 0.1084 Acc: 0.9595 | Val Loss: 0.1614 Acc: 0.9402\n",
      "Epoch 041 | Train Loss: 0.1017 Acc: 0.9623 | Val Loss: 0.1515 Acc: 0.9457\n",
      "Epoch 042 | Train Loss: 0.1080 Acc: 0.9583 | Val Loss: 0.1850 Acc: 0.9408\n",
      "Epoch 043 | Train Loss: 0.1018 Acc: 0.9636 | Val Loss: 0.1522 Acc: 0.9426\n",
      "Epoch 044 | Train Loss: 0.0936 Acc: 0.9650 | Val Loss: 0.1624 Acc: 0.9535\n",
      "Epoch 045 | Train Loss: 0.0903 Acc: 0.9630 | Val Loss: 0.1783 Acc: 0.9408\n",
      "Epoch 046 | Train Loss: 0.0884 Acc: 0.9663 | Val Loss: 0.1617 Acc: 0.9414\n",
      "Epoch 047 | Train Loss: 0.0857 Acc: 0.9663 | Val Loss: 0.1338 Acc: 0.9595\n",
      "Epoch 048 | Train Loss: 0.0915 Acc: 0.9662 | Val Loss: 0.1399 Acc: 0.9523\n",
      "Epoch 049 | Train Loss: 0.0905 Acc: 0.9677 | Val Loss: 0.1727 Acc: 0.9372\n",
      "Epoch 050 | Train Loss: 0.0774 Acc: 0.9715 | Val Loss: 0.1538 Acc: 0.9438\n",
      "Epoch 051 | Train Loss: 0.0876 Acc: 0.9651 | Val Loss: 0.1265 Acc: 0.9553\n",
      "Epoch 052 | Train Loss: 0.0643 Acc: 0.9746 | Val Loss: 0.1329 Acc: 0.9529\n",
      "Epoch 053 | Train Loss: 0.0878 Acc: 0.9660 | Val Loss: 0.1301 Acc: 0.9475\n",
      "Epoch 054 | Train Loss: 0.0836 Acc: 0.9684 | Val Loss: 0.1393 Acc: 0.9523\n",
      "Epoch 055 | Train Loss: 0.0682 Acc: 0.9749 | Val Loss: 0.1508 Acc: 0.9481\n",
      "Epoch 056 | Train Loss: 0.0806 Acc: 0.9710 | Val Loss: 0.1321 Acc: 0.9547\n",
      "Epoch 057 | Train Loss: 0.0673 Acc: 0.9739 | Val Loss: 0.1216 Acc: 0.9559\n",
      "Epoch 058 | Train Loss: 0.0715 Acc: 0.9757 | Val Loss: 0.1555 Acc: 0.9469\n",
      "Epoch 059 | Train Loss: 0.0730 Acc: 0.9754 | Val Loss: 0.1380 Acc: 0.9547\n",
      "Epoch 060 | Train Loss: 0.0640 Acc: 0.9764 | Val Loss: 0.1560 Acc: 0.9438\n",
      "Epoch 001 | Train Loss: 0.6823 Acc: 0.5701 | Val Loss: 0.6804 Acc: 0.5652\n",
      "Epoch 002 | Train Loss: 0.6683 Acc: 0.5975 | Val Loss: 0.6469 Acc: 0.6498\n",
      "Epoch 003 | Train Loss: 0.6267 Acc: 0.6651 | Val Loss: 0.6110 Acc: 0.6600\n",
      "Epoch 004 | Train Loss: 0.5850 Acc: 0.7080 | Val Loss: 0.5621 Acc: 0.7132\n",
      "Epoch 005 | Train Loss: 0.5598 Acc: 0.7264 | Val Loss: 0.5467 Acc: 0.7198\n",
      "Epoch 006 | Train Loss: 0.5370 Acc: 0.7465 | Val Loss: 0.5300 Acc: 0.7373\n",
      "Epoch 007 | Train Loss: 0.5102 Acc: 0.7637 | Val Loss: 0.4942 Acc: 0.7560\n",
      "Epoch 008 | Train Loss: 0.4989 Acc: 0.7681 | Val Loss: 0.4979 Acc: 0.7585\n",
      "Epoch 009 | Train Loss: 0.4764 Acc: 0.7777 | Val Loss: 0.5102 Acc: 0.7560\n",
      "Epoch 010 | Train Loss: 0.4585 Acc: 0.7853 | Val Loss: 0.4303 Acc: 0.7911\n",
      "Epoch 011 | Train Loss: 0.4307 Acc: 0.8042 | Val Loss: 0.4179 Acc: 0.7995\n",
      "Epoch 012 | Train Loss: 0.4199 Acc: 0.8095 | Val Loss: 0.4116 Acc: 0.8025\n",
      "Epoch 013 | Train Loss: 0.3988 Acc: 0.8212 | Val Loss: 0.3557 Acc: 0.8376\n",
      "Epoch 014 | Train Loss: 0.3725 Acc: 0.8339 | Val Loss: 0.3569 Acc: 0.8339\n",
      "Epoch 015 | Train Loss: 0.3668 Acc: 0.8389 | Val Loss: 0.3456 Acc: 0.8466\n",
      "Epoch 016 | Train Loss: 0.3513 Acc: 0.8549 | Val Loss: 0.3145 Acc: 0.8623\n",
      "Epoch 017 | Train Loss: 0.3186 Acc: 0.8638 | Val Loss: 0.3029 Acc: 0.8647\n",
      "Epoch 018 | Train Loss: 0.3084 Acc: 0.8715 | Val Loss: 0.3124 Acc: 0.8732\n",
      "Epoch 019 | Train Loss: 0.2938 Acc: 0.8807 | Val Loss: 0.3210 Acc: 0.8581\n",
      "Epoch 020 | Train Loss: 0.2846 Acc: 0.8818 | Val Loss: 0.2691 Acc: 0.8841\n",
      "Epoch 021 | Train Loss: 0.2811 Acc: 0.8846 | Val Loss: 0.2578 Acc: 0.8877\n",
      "Epoch 022 | Train Loss: 0.2604 Acc: 0.8966 | Val Loss: 0.2388 Acc: 0.9010\n",
      "Epoch 023 | Train Loss: 0.2497 Acc: 0.8957 | Val Loss: 0.2340 Acc: 0.9022\n",
      "Epoch 024 | Train Loss: 0.2377 Acc: 0.9091 | Val Loss: 0.2336 Acc: 0.9004\n",
      "Epoch 025 | Train Loss: 0.2288 Acc: 0.9087 | Val Loss: 0.2455 Acc: 0.9058\n",
      "Epoch 026 | Train Loss: 0.2405 Acc: 0.9034 | Val Loss: 0.2618 Acc: 0.8883\n",
      "Epoch 027 | Train Loss: 0.2142 Acc: 0.9173 | Val Loss: 0.2235 Acc: 0.9058\n",
      "Epoch 028 | Train Loss: 0.2090 Acc: 0.9174 | Val Loss: 0.2327 Acc: 0.8973\n",
      "Epoch 029 | Train Loss: 0.2049 Acc: 0.9188 | Val Loss: 0.2614 Acc: 0.8937\n",
      "Epoch 030 | Train Loss: 0.2043 Acc: 0.9210 | Val Loss: 0.1942 Acc: 0.9185\n",
      "Epoch 031 | Train Loss: 0.1944 Acc: 0.9250 | Val Loss: 0.2140 Acc: 0.9124\n",
      "Epoch 032 | Train Loss: 0.1910 Acc: 0.9253 | Val Loss: 0.1939 Acc: 0.9227\n",
      "Epoch 033 | Train Loss: 0.1859 Acc: 0.9268 | Val Loss: 0.1763 Acc: 0.9263\n",
      "Epoch 034 | Train Loss: 0.1725 Acc: 0.9324 | Val Loss: 0.2110 Acc: 0.9245\n",
      "Epoch 035 | Train Loss: 0.1843 Acc: 0.9290 | Val Loss: 0.1954 Acc: 0.9215\n",
      "Epoch 036 | Train Loss: 0.1677 Acc: 0.9345 | Val Loss: 0.1910 Acc: 0.9251\n",
      "Epoch 037 | Train Loss: 0.1687 Acc: 0.9316 | Val Loss: 0.1671 Acc: 0.9402\n",
      "Epoch 038 | Train Loss: 0.1611 Acc: 0.9355 | Val Loss: 0.1572 Acc: 0.9450\n",
      "Epoch 039 | Train Loss: 0.1454 Acc: 0.9429 | Val Loss: 0.1836 Acc: 0.9306\n",
      "Epoch 040 | Train Loss: 0.1523 Acc: 0.9381 | Val Loss: 0.1641 Acc: 0.9384\n",
      "Epoch 041 | Train Loss: 0.1454 Acc: 0.9464 | Val Loss: 0.1682 Acc: 0.9378\n",
      "Epoch 042 | Train Loss: 0.1444 Acc: 0.9470 | Val Loss: 0.1894 Acc: 0.9330\n",
      "Epoch 043 | Train Loss: 0.1537 Acc: 0.9420 | Val Loss: 0.1505 Acc: 0.9420\n",
      "Epoch 044 | Train Loss: 0.1351 Acc: 0.9526 | Val Loss: 0.1862 Acc: 0.9342\n",
      "Epoch 045 | Train Loss: 0.1368 Acc: 0.9472 | Val Loss: 0.1833 Acc: 0.9348\n",
      "Epoch 046 | Train Loss: 0.1385 Acc: 0.9478 | Val Loss: 0.1641 Acc: 0.9366\n",
      "Epoch 047 | Train Loss: 0.1311 Acc: 0.9509 | Val Loss: 0.1840 Acc: 0.9275\n",
      "Epoch 048 | Train Loss: 0.1308 Acc: 0.9500 | Val Loss: 0.1752 Acc: 0.9312\n",
      "Epoch 049 | Train Loss: 0.1210 Acc: 0.9546 | Val Loss: 0.1547 Acc: 0.9505\n",
      "Epoch 050 | Train Loss: 0.1285 Acc: 0.9514 | Val Loss: 0.1680 Acc: 0.9336\n",
      "Epoch 051 | Train Loss: 0.1393 Acc: 0.9487 | Val Loss: 0.1858 Acc: 0.9281\n",
      "Epoch 052 | Train Loss: 0.1274 Acc: 0.9491 | Val Loss: 0.1599 Acc: 0.9384\n",
      "Epoch 053 | Train Loss: 0.1203 Acc: 0.9564 | Val Loss: 0.1577 Acc: 0.9420\n",
      "Early stopping triggered.\n",
      "Epoch 001 | Train Loss: 0.6805 Acc: 0.5827 | Val Loss: 0.6747 Acc: 0.5924\n",
      "Epoch 002 | Train Loss: 0.6732 Acc: 0.5931 | Val Loss: 0.6698 Acc: 0.6008\n",
      "Epoch 003 | Train Loss: 0.6664 Acc: 0.6029 | Val Loss: 0.6621 Acc: 0.6039\n",
      "Epoch 004 | Train Loss: 0.6482 Acc: 0.6252 | Val Loss: 0.6224 Acc: 0.6636\n",
      "Epoch 005 | Train Loss: 0.6113 Acc: 0.6784 | Val Loss: 0.5838 Acc: 0.7029\n",
      "Epoch 006 | Train Loss: 0.5707 Acc: 0.7115 | Val Loss: 0.5622 Acc: 0.7065\n",
      "Epoch 007 | Train Loss: 0.5502 Acc: 0.7258 | Val Loss: 0.5471 Acc: 0.7156\n",
      "Epoch 008 | Train Loss: 0.5283 Acc: 0.7352 | Val Loss: 0.5345 Acc: 0.7289\n",
      "Epoch 009 | Train Loss: 0.5178 Acc: 0.7429 | Val Loss: 0.5120 Acc: 0.7355\n",
      "Epoch 010 | Train Loss: 0.4888 Acc: 0.7642 | Val Loss: 0.4878 Acc: 0.7639\n",
      "Epoch 011 | Train Loss: 0.4621 Acc: 0.7774 | Val Loss: 0.4926 Acc: 0.7579\n",
      "Epoch 012 | Train Loss: 0.4469 Acc: 0.7909 | Val Loss: 0.4460 Acc: 0.7742\n",
      "Epoch 013 | Train Loss: 0.4256 Acc: 0.8010 | Val Loss: 0.4150 Acc: 0.8043\n",
      "Epoch 014 | Train Loss: 0.4029 Acc: 0.8140 | Val Loss: 0.4189 Acc: 0.8122\n",
      "Epoch 015 | Train Loss: 0.3846 Acc: 0.8313 | Val Loss: 0.4213 Acc: 0.7941\n",
      "Epoch 016 | Train Loss: 0.3537 Acc: 0.8436 | Val Loss: 0.3288 Acc: 0.8490\n",
      "Epoch 017 | Train Loss: 0.3359 Acc: 0.8457 | Val Loss: 0.3100 Acc: 0.8599\n",
      "Epoch 018 | Train Loss: 0.3151 Acc: 0.8609 | Val Loss: 0.2913 Acc: 0.8756\n",
      "Epoch 019 | Train Loss: 0.2808 Acc: 0.8831 | Val Loss: 0.2824 Acc: 0.8702\n",
      "Epoch 020 | Train Loss: 0.2802 Acc: 0.8818 | Val Loss: 0.2762 Acc: 0.8816\n",
      "Epoch 021 | Train Loss: 0.2630 Acc: 0.8955 | Val Loss: 0.2743 Acc: 0.8774\n",
      "Epoch 022 | Train Loss: 0.2490 Acc: 0.8972 | Val Loss: 0.2579 Acc: 0.8907\n",
      "Epoch 023 | Train Loss: 0.2429 Acc: 0.9017 | Val Loss: 0.2759 Acc: 0.8913\n",
      "Epoch 024 | Train Loss: 0.2347 Acc: 0.9028 | Val Loss: 0.2478 Acc: 0.9004\n",
      "Epoch 025 | Train Loss: 0.2174 Acc: 0.9132 | Val Loss: 0.2623 Acc: 0.8804\n",
      "Epoch 026 | Train Loss: 0.1978 Acc: 0.9219 | Val Loss: 0.2254 Acc: 0.9185\n",
      "Epoch 027 | Train Loss: 0.1955 Acc: 0.9216 | Val Loss: 0.2143 Acc: 0.9118\n",
      "Epoch 028 | Train Loss: 0.1910 Acc: 0.9280 | Val Loss: 0.2272 Acc: 0.9052\n",
      "Epoch 029 | Train Loss: 0.1944 Acc: 0.9256 | Val Loss: 0.2045 Acc: 0.9130\n",
      "Epoch 030 | Train Loss: 0.1607 Acc: 0.9360 | Val Loss: 0.2358 Acc: 0.9106\n",
      "Epoch 031 | Train Loss: 0.1619 Acc: 0.9346 | Val Loss: 0.2001 Acc: 0.9143\n",
      "Epoch 032 | Train Loss: 0.1637 Acc: 0.9349 | Val Loss: 0.2018 Acc: 0.9155\n",
      "Epoch 033 | Train Loss: 0.1614 Acc: 0.9398 | Val Loss: 0.1869 Acc: 0.9263\n",
      "Epoch 034 | Train Loss: 0.1444 Acc: 0.9452 | Val Loss: 0.1736 Acc: 0.9269\n",
      "Epoch 035 | Train Loss: 0.1403 Acc: 0.9470 | Val Loss: 0.1935 Acc: 0.9300\n",
      "Epoch 036 | Train Loss: 0.1411 Acc: 0.9446 | Val Loss: 0.2029 Acc: 0.9215\n",
      "Epoch 037 | Train Loss: 0.1407 Acc: 0.9467 | Val Loss: 0.1853 Acc: 0.9239\n",
      "Epoch 038 | Train Loss: 0.1248 Acc: 0.9539 | Val Loss: 0.1848 Acc: 0.9390\n",
      "Epoch 039 | Train Loss: 0.1238 Acc: 0.9524 | Val Loss: 0.1726 Acc: 0.9281\n",
      "Epoch 040 | Train Loss: 0.1167 Acc: 0.9561 | Val Loss: 0.1868 Acc: 0.9251\n",
      "Epoch 041 | Train Loss: 0.1309 Acc: 0.9506 | Val Loss: 0.1871 Acc: 0.9239\n",
      "Epoch 042 | Train Loss: 0.1115 Acc: 0.9580 | Val Loss: 0.1673 Acc: 0.9354\n",
      "Epoch 043 | Train Loss: 0.1178 Acc: 0.9568 | Val Loss: 0.1810 Acc: 0.9348\n",
      "Epoch 044 | Train Loss: 0.1052 Acc: 0.9601 | Val Loss: 0.1585 Acc: 0.9402\n",
      "Epoch 045 | Train Loss: 0.1042 Acc: 0.9615 | Val Loss: 0.1684 Acc: 0.9318\n",
      "Epoch 046 | Train Loss: 0.1079 Acc: 0.9585 | Val Loss: 0.1722 Acc: 0.9354\n",
      "Epoch 047 | Train Loss: 0.0953 Acc: 0.9641 | Val Loss: 0.1628 Acc: 0.9378\n",
      "Epoch 048 | Train Loss: 0.0991 Acc: 0.9616 | Val Loss: 0.1870 Acc: 0.9263\n",
      "Epoch 049 | Train Loss: 0.0964 Acc: 0.9662 | Val Loss: 0.1848 Acc: 0.9251\n",
      "Epoch 050 | Train Loss: 0.0971 Acc: 0.9650 | Val Loss: 0.1675 Acc: 0.9384\n",
      "Epoch 051 | Train Loss: 0.0964 Acc: 0.9659 | Val Loss: 0.1527 Acc: 0.9432\n",
      "Epoch 052 | Train Loss: 0.0880 Acc: 0.9697 | Val Loss: 0.1727 Acc: 0.9360\n",
      "Epoch 053 | Train Loss: 0.0942 Acc: 0.9654 | Val Loss: 0.1625 Acc: 0.9408\n",
      "Epoch 054 | Train Loss: 0.0875 Acc: 0.9671 | Val Loss: 0.1632 Acc: 0.9426\n",
      "Epoch 055 | Train Loss: 0.0918 Acc: 0.9648 | Val Loss: 0.1810 Acc: 0.9384\n",
      "Epoch 056 | Train Loss: 0.0777 Acc: 0.9733 | Val Loss: 0.1807 Acc: 0.9438\n",
      "Epoch 057 | Train Loss: 0.0778 Acc: 0.9677 | Val Loss: 0.1735 Acc: 0.9444\n",
      "Epoch 058 | Train Loss: 0.0855 Acc: 0.9698 | Val Loss: 0.1461 Acc: 0.9481\n",
      "Epoch 059 | Train Loss: 0.0745 Acc: 0.9713 | Val Loss: 0.1768 Acc: 0.9372\n",
      "Epoch 060 | Train Loss: 0.0775 Acc: 0.9716 | Val Loss: 0.1611 Acc: 0.9396\n",
      "Epoch 001 | Train Loss: 0.6860 Acc: 0.5591 | Val Loss: 0.6789 Acc: 0.5882\n",
      "Epoch 002 | Train Loss: 0.6762 Acc: 0.5923 | Val Loss: 0.6780 Acc: 0.5779\n",
      "Epoch 003 | Train Loss: 0.6748 Acc: 0.5898 | Val Loss: 0.6765 Acc: 0.5882\n",
      "Epoch 004 | Train Loss: 0.6692 Acc: 0.5988 | Val Loss: 0.6657 Acc: 0.6014\n",
      "Epoch 005 | Train Loss: 0.6605 Acc: 0.6101 | Val Loss: 0.6568 Acc: 0.6033\n",
      "Epoch 006 | Train Loss: 0.6523 Acc: 0.6159 | Val Loss: 0.6524 Acc: 0.6171\n",
      "Epoch 007 | Train Loss: 0.6342 Acc: 0.6499 | Val Loss: 0.6126 Acc: 0.6842\n",
      "Epoch 008 | Train Loss: 0.6116 Acc: 0.6785 | Val Loss: 0.6066 Acc: 0.6806\n",
      "Epoch 009 | Train Loss: 0.6034 Acc: 0.6861 | Val Loss: 0.5960 Acc: 0.6872\n",
      "Epoch 010 | Train Loss: 0.5968 Acc: 0.6947 | Val Loss: 0.5934 Acc: 0.6987\n",
      "Epoch 011 | Train Loss: 0.5809 Acc: 0.7103 | Val Loss: 0.6046 Acc: 0.6872\n",
      "Epoch 012 | Train Loss: 0.5774 Acc: 0.7146 | Val Loss: 0.6151 Acc: 0.6685\n",
      "Epoch 013 | Train Loss: 0.5735 Acc: 0.7133 | Val Loss: 0.5682 Acc: 0.7192\n",
      "Epoch 014 | Train Loss: 0.5606 Acc: 0.7249 | Val Loss: 0.5577 Acc: 0.7222\n",
      "Epoch 015 | Train Loss: 0.5473 Acc: 0.7359 | Val Loss: 0.5524 Acc: 0.7258\n",
      "Epoch 016 | Train Loss: 0.5414 Acc: 0.7364 | Val Loss: 0.5454 Acc: 0.7295\n",
      "Epoch 017 | Train Loss: 0.5302 Acc: 0.7460 | Val Loss: 0.5416 Acc: 0.7307\n",
      "Epoch 018 | Train Loss: 0.5247 Acc: 0.7504 | Val Loss: 0.5488 Acc: 0.7277\n",
      "Epoch 019 | Train Loss: 0.5213 Acc: 0.7542 | Val Loss: 0.5615 Acc: 0.7120\n",
      "Epoch 020 | Train Loss: 0.5135 Acc: 0.7557 | Val Loss: 0.5249 Acc: 0.7391\n",
      "Epoch 021 | Train Loss: 0.5022 Acc: 0.7649 | Val Loss: 0.5197 Acc: 0.7403\n",
      "Epoch 022 | Train Loss: 0.5049 Acc: 0.7620 | Val Loss: 0.5208 Acc: 0.7379\n",
      "Epoch 023 | Train Loss: 0.5038 Acc: 0.7643 | Val Loss: 0.5185 Acc: 0.7434\n",
      "Epoch 024 | Train Loss: 0.4861 Acc: 0.7696 | Val Loss: 0.5101 Acc: 0.7470\n",
      "Epoch 025 | Train Loss: 0.4851 Acc: 0.7755 | Val Loss: 0.5141 Acc: 0.7476\n",
      "Epoch 026 | Train Loss: 0.4828 Acc: 0.7758 | Val Loss: 0.5173 Acc: 0.7385\n",
      "Epoch 027 | Train Loss: 0.4755 Acc: 0.7805 | Val Loss: 0.5356 Acc: 0.7373\n",
      "Epoch 028 | Train Loss: 0.4649 Acc: 0.7808 | Val Loss: 0.4873 Acc: 0.7633\n",
      "Epoch 029 | Train Loss: 0.4611 Acc: 0.7879 | Val Loss: 0.4858 Acc: 0.7639\n",
      "Epoch 030 | Train Loss: 0.4521 Acc: 0.7912 | Val Loss: 0.4734 Acc: 0.7681\n",
      "Epoch 031 | Train Loss: 0.4478 Acc: 0.7910 | Val Loss: 0.4723 Acc: 0.7717\n",
      "Epoch 032 | Train Loss: 0.4411 Acc: 0.7965 | Val Loss: 0.4674 Acc: 0.7729\n",
      "Epoch 033 | Train Loss: 0.4447 Acc: 0.7947 | Val Loss: 0.4573 Acc: 0.7766\n",
      "Epoch 034 | Train Loss: 0.4341 Acc: 0.7977 | Val Loss: 0.4514 Acc: 0.7802\n",
      "Epoch 035 | Train Loss: 0.4282 Acc: 0.8043 | Val Loss: 0.4559 Acc: 0.7868\n",
      "Epoch 036 | Train Loss: 0.4211 Acc: 0.8087 | Val Loss: 0.4447 Acc: 0.7862\n",
      "Epoch 037 | Train Loss: 0.4086 Acc: 0.8147 | Val Loss: 0.4236 Acc: 0.8007\n",
      "Epoch 038 | Train Loss: 0.4035 Acc: 0.8200 | Val Loss: 0.4221 Acc: 0.7953\n",
      "Epoch 039 | Train Loss: 0.4026 Acc: 0.8128 | Val Loss: 0.4131 Acc: 0.8037\n",
      "Epoch 040 | Train Loss: 0.3930 Acc: 0.8200 | Val Loss: 0.4046 Acc: 0.8086\n",
      "Epoch 041 | Train Loss: 0.3861 Acc: 0.8277 | Val Loss: 0.4222 Acc: 0.7983\n",
      "Epoch 042 | Train Loss: 0.3720 Acc: 0.8333 | Val Loss: 0.3963 Acc: 0.8194\n",
      "Epoch 043 | Train Loss: 0.3798 Acc: 0.8253 | Val Loss: 0.3827 Acc: 0.8237\n",
      "Epoch 044 | Train Loss: 0.3577 Acc: 0.8390 | Val Loss: 0.3953 Acc: 0.8116\n",
      "Epoch 045 | Train Loss: 0.3521 Acc: 0.8387 | Val Loss: 0.3643 Acc: 0.8333\n",
      "Epoch 046 | Train Loss: 0.3444 Acc: 0.8472 | Val Loss: 0.3728 Acc: 0.8261\n",
      "Epoch 047 | Train Loss: 0.3396 Acc: 0.8451 | Val Loss: 0.3581 Acc: 0.8400\n",
      "Epoch 048 | Train Loss: 0.3400 Acc: 0.8455 | Val Loss: 0.3422 Acc: 0.8484\n",
      "Epoch 049 | Train Loss: 0.3328 Acc: 0.8528 | Val Loss: 0.3506 Acc: 0.8442\n",
      "Epoch 050 | Train Loss: 0.3188 Acc: 0.8569 | Val Loss: 0.3507 Acc: 0.8376\n",
      "Epoch 051 | Train Loss: 0.3210 Acc: 0.8566 | Val Loss: 0.3410 Acc: 0.8400\n",
      "Epoch 052 | Train Loss: 0.3132 Acc: 0.8572 | Val Loss: 0.3318 Acc: 0.8563\n",
      "Epoch 053 | Train Loss: 0.3005 Acc: 0.8697 | Val Loss: 0.3163 Acc: 0.8629\n",
      "Epoch 054 | Train Loss: 0.2887 Acc: 0.8723 | Val Loss: 0.3285 Acc: 0.8575\n",
      "Epoch 055 | Train Loss: 0.2916 Acc: 0.8723 | Val Loss: 0.3062 Acc: 0.8690\n",
      "Epoch 056 | Train Loss: 0.2847 Acc: 0.8771 | Val Loss: 0.3268 Acc: 0.8593\n",
      "Epoch 057 | Train Loss: 0.2836 Acc: 0.8824 | Val Loss: 0.3689 Acc: 0.8364\n",
      "Epoch 058 | Train Loss: 0.2741 Acc: 0.8842 | Val Loss: 0.2986 Acc: 0.8792\n",
      "Epoch 059 | Train Loss: 0.2707 Acc: 0.8809 | Val Loss: 0.3462 Acc: 0.8406\n",
      "Epoch 060 | Train Loss: 0.2712 Acc: 0.8813 | Val Loss: 0.2877 Acc: 0.8804\n",
      "Epoch 001 | Train Loss: 0.6820 Acc: 0.5674 | Val Loss: 0.6815 Acc: 0.5688\n",
      "Epoch 002 | Train Loss: 0.6665 Acc: 0.5964 | Val Loss: 0.6375 Acc: 0.6504\n",
      "Epoch 003 | Train Loss: 0.6258 Acc: 0.6598 | Val Loss: 0.6042 Acc: 0.6854\n",
      "Epoch 004 | Train Loss: 0.5728 Acc: 0.7155 | Val Loss: 0.5752 Acc: 0.7089\n",
      "Epoch 005 | Train Loss: 0.5521 Acc: 0.7249 | Val Loss: 0.5716 Acc: 0.7107\n",
      "Epoch 006 | Train Loss: 0.5306 Acc: 0.7392 | Val Loss: 0.5197 Acc: 0.7464\n",
      "Epoch 007 | Train Loss: 0.5036 Acc: 0.7581 | Val Loss: 0.4916 Acc: 0.7609\n",
      "Epoch 008 | Train Loss: 0.4774 Acc: 0.7720 | Val Loss: 0.4793 Acc: 0.7742\n",
      "Epoch 009 | Train Loss: 0.4555 Acc: 0.7874 | Val Loss: 0.4503 Acc: 0.7808\n",
      "Epoch 010 | Train Loss: 0.4348 Acc: 0.8008 | Val Loss: 0.4138 Acc: 0.8068\n",
      "Epoch 011 | Train Loss: 0.4228 Acc: 0.8095 | Val Loss: 0.4036 Acc: 0.8062\n",
      "Epoch 012 | Train Loss: 0.3929 Acc: 0.8249 | Val Loss: 0.4113 Acc: 0.8074\n",
      "Epoch 013 | Train Loss: 0.3769 Acc: 0.8304 | Val Loss: 0.3551 Acc: 0.8261\n",
      "Epoch 014 | Train Loss: 0.3566 Acc: 0.8412 | Val Loss: 0.3545 Acc: 0.8339\n",
      "Epoch 015 | Train Loss: 0.3338 Acc: 0.8532 | Val Loss: 0.3233 Acc: 0.8502\n",
      "Epoch 016 | Train Loss: 0.3142 Acc: 0.8686 | Val Loss: 0.3061 Acc: 0.8665\n",
      "Epoch 017 | Train Loss: 0.2966 Acc: 0.8742 | Val Loss: 0.4074 Acc: 0.8225\n",
      "Epoch 018 | Train Loss: 0.2952 Acc: 0.8742 | Val Loss: 0.2870 Acc: 0.8786\n",
      "Epoch 019 | Train Loss: 0.2658 Acc: 0.8857 | Val Loss: 0.2835 Acc: 0.8780\n",
      "Epoch 020 | Train Loss: 0.2536 Acc: 0.8954 | Val Loss: 0.2765 Acc: 0.8780\n",
      "Epoch 021 | Train Loss: 0.2473 Acc: 0.8972 | Val Loss: 0.3031 Acc: 0.8647\n",
      "Epoch 022 | Train Loss: 0.2374 Acc: 0.9010 | Val Loss: 0.2480 Acc: 0.8925\n",
      "Epoch 023 | Train Loss: 0.2139 Acc: 0.9154 | Val Loss: 0.2432 Acc: 0.9004\n",
      "Epoch 024 | Train Loss: 0.2150 Acc: 0.9121 | Val Loss: 0.2267 Acc: 0.9058\n",
      "Epoch 025 | Train Loss: 0.1962 Acc: 0.9221 | Val Loss: 0.2322 Acc: 0.9022\n",
      "Epoch 026 | Train Loss: 0.1864 Acc: 0.9284 | Val Loss: 0.2151 Acc: 0.9106\n",
      "Epoch 027 | Train Loss: 0.1812 Acc: 0.9251 | Val Loss: 0.2095 Acc: 0.9136\n",
      "Epoch 028 | Train Loss: 0.1711 Acc: 0.9330 | Val Loss: 0.2359 Acc: 0.8992\n",
      "Epoch 029 | Train Loss: 0.1671 Acc: 0.9324 | Val Loss: 0.1837 Acc: 0.9281\n",
      "Epoch 030 | Train Loss: 0.1549 Acc: 0.9370 | Val Loss: 0.2097 Acc: 0.9136\n",
      "Epoch 031 | Train Loss: 0.1687 Acc: 0.9295 | Val Loss: 0.1811 Acc: 0.9221\n",
      "Epoch 032 | Train Loss: 0.1457 Acc: 0.9443 | Val Loss: 0.1866 Acc: 0.9287\n",
      "Epoch 033 | Train Loss: 0.1391 Acc: 0.9479 | Val Loss: 0.1778 Acc: 0.9263\n",
      "Epoch 034 | Train Loss: 0.1363 Acc: 0.9499 | Val Loss: 0.1680 Acc: 0.9366\n",
      "Epoch 035 | Train Loss: 0.1129 Acc: 0.9571 | Val Loss: 0.1837 Acc: 0.9287\n",
      "Epoch 036 | Train Loss: 0.1262 Acc: 0.9530 | Val Loss: 0.2622 Acc: 0.9004\n",
      "Epoch 037 | Train Loss: 0.1197 Acc: 0.9526 | Val Loss: 0.1668 Acc: 0.9348\n",
      "Epoch 038 | Train Loss: 0.1218 Acc: 0.9535 | Val Loss: 0.2049 Acc: 0.9233\n",
      "Epoch 039 | Train Loss: 0.1103 Acc: 0.9582 | Val Loss: 0.1665 Acc: 0.9330\n",
      "Epoch 040 | Train Loss: 0.1075 Acc: 0.9627 | Val Loss: 0.1761 Acc: 0.9336\n",
      "Epoch 041 | Train Loss: 0.0921 Acc: 0.9666 | Val Loss: 0.1907 Acc: 0.9318\n",
      "Epoch 042 | Train Loss: 0.0963 Acc: 0.9648 | Val Loss: 0.1736 Acc: 0.9306\n",
      "Epoch 043 | Train Loss: 0.0968 Acc: 0.9629 | Val Loss: 0.1810 Acc: 0.9281\n",
      "Epoch 044 | Train Loss: 0.0962 Acc: 0.9662 | Val Loss: 0.1642 Acc: 0.9408\n",
      "Epoch 045 | Train Loss: 0.0971 Acc: 0.9632 | Val Loss: 0.1952 Acc: 0.9275\n",
      "Epoch 046 | Train Loss: 0.0937 Acc: 0.9642 | Val Loss: 0.1994 Acc: 0.9275\n",
      "Epoch 047 | Train Loss: 0.0748 Acc: 0.9721 | Val Loss: 0.1765 Acc: 0.9324\n",
      "Epoch 048 | Train Loss: 0.0886 Acc: 0.9648 | Val Loss: 0.1660 Acc: 0.9354\n",
      "Epoch 049 | Train Loss: 0.0868 Acc: 0.9686 | Val Loss: 0.1570 Acc: 0.9432\n",
      "Epoch 050 | Train Loss: 0.0761 Acc: 0.9709 | Val Loss: 0.1992 Acc: 0.9263\n",
      "Epoch 051 | Train Loss: 0.0854 Acc: 0.9687 | Val Loss: 0.1697 Acc: 0.9378\n",
      "Epoch 052 | Train Loss: 0.0655 Acc: 0.9755 | Val Loss: 0.1672 Acc: 0.9444\n",
      "Epoch 053 | Train Loss: 0.0800 Acc: 0.9701 | Val Loss: 0.1563 Acc: 0.9390\n",
      "Epoch 054 | Train Loss: 0.0754 Acc: 0.9713 | Val Loss: 0.1548 Acc: 0.9463\n",
      "Epoch 055 | Train Loss: 0.0600 Acc: 0.9784 | Val Loss: 0.1527 Acc: 0.9444\n",
      "Epoch 056 | Train Loss: 0.0623 Acc: 0.9761 | Val Loss: 0.1712 Acc: 0.9432\n",
      "Epoch 057 | Train Loss: 0.0715 Acc: 0.9730 | Val Loss: 0.1357 Acc: 0.9505\n",
      "Epoch 058 | Train Loss: 0.0562 Acc: 0.9783 | Val Loss: 0.1415 Acc: 0.9541\n",
      "Epoch 059 | Train Loss: 0.0628 Acc: 0.9754 | Val Loss: 0.1546 Acc: 0.9463\n",
      "Epoch 060 | Train Loss: 0.0667 Acc: 0.9761 | Val Loss: 0.1627 Acc: 0.9463\n",
      "Epoch 001 | Train Loss: 0.6800 Acc: 0.5796 | Val Loss: 0.6801 Acc: 0.5743\n",
      "Epoch 002 | Train Loss: 0.6747 Acc: 0.5908 | Val Loss: 0.6657 Acc: 0.5936\n",
      "Epoch 003 | Train Loss: 0.6214 Acc: 0.6627 | Val Loss: 0.5767 Acc: 0.7071\n",
      "Epoch 004 | Train Loss: 0.5630 Acc: 0.7231 | Val Loss: 0.5585 Acc: 0.7228\n",
      "Epoch 005 | Train Loss: 0.5362 Acc: 0.7364 | Val Loss: 0.5356 Acc: 0.7337\n",
      "Epoch 006 | Train Loss: 0.5113 Acc: 0.7504 | Val Loss: 0.5229 Acc: 0.7361\n",
      "Epoch 007 | Train Loss: 0.4890 Acc: 0.7714 | Val Loss: 0.4890 Acc: 0.7603\n",
      "Epoch 008 | Train Loss: 0.4658 Acc: 0.7824 | Val Loss: 0.4752 Acc: 0.7729\n",
      "Epoch 009 | Train Loss: 0.4258 Acc: 0.8005 | Val Loss: 0.4205 Acc: 0.7965\n",
      "Epoch 010 | Train Loss: 0.3915 Acc: 0.8224 | Val Loss: 0.3836 Acc: 0.8134\n",
      "Epoch 011 | Train Loss: 0.3549 Acc: 0.8457 | Val Loss: 0.3654 Acc: 0.8357\n",
      "Epoch 012 | Train Loss: 0.3343 Acc: 0.8544 | Val Loss: 0.3059 Acc: 0.8732\n",
      "Epoch 013 | Train Loss: 0.3124 Acc: 0.8671 | Val Loss: 0.2990 Acc: 0.8768\n",
      "Epoch 014 | Train Loss: 0.2867 Acc: 0.8825 | Val Loss: 0.2705 Acc: 0.8859\n",
      "Epoch 015 | Train Loss: 0.2600 Acc: 0.8981 | Val Loss: 0.2536 Acc: 0.9010\n",
      "Epoch 016 | Train Loss: 0.2418 Acc: 0.9011 | Val Loss: 0.2585 Acc: 0.8865\n",
      "Epoch 017 | Train Loss: 0.2190 Acc: 0.9141 | Val Loss: 0.2385 Acc: 0.9058\n",
      "Epoch 018 | Train Loss: 0.2044 Acc: 0.9215 | Val Loss: 0.2214 Acc: 0.9076\n",
      "Epoch 019 | Train Loss: 0.1996 Acc: 0.9231 | Val Loss: 0.2546 Acc: 0.8937\n",
      "Epoch 020 | Train Loss: 0.1860 Acc: 0.9262 | Val Loss: 0.2380 Acc: 0.9094\n",
      "Epoch 021 | Train Loss: 0.1579 Acc: 0.9360 | Val Loss: 0.2277 Acc: 0.9112\n",
      "Epoch 022 | Train Loss: 0.1619 Acc: 0.9381 | Val Loss: 0.2311 Acc: 0.9118\n",
      "Epoch 023 | Train Loss: 0.1432 Acc: 0.9437 | Val Loss: 0.2157 Acc: 0.9191\n",
      "Epoch 024 | Train Loss: 0.1349 Acc: 0.9465 | Val Loss: 0.2189 Acc: 0.9239\n",
      "Epoch 025 | Train Loss: 0.1247 Acc: 0.9520 | Val Loss: 0.2013 Acc: 0.9239\n",
      "Epoch 026 | Train Loss: 0.1273 Acc: 0.9502 | Val Loss: 0.1901 Acc: 0.9269\n",
      "Epoch 027 | Train Loss: 0.1217 Acc: 0.9547 | Val Loss: 0.2129 Acc: 0.9245\n",
      "Epoch 028 | Train Loss: 0.1071 Acc: 0.9623 | Val Loss: 0.2189 Acc: 0.9269\n",
      "Epoch 029 | Train Loss: 0.1079 Acc: 0.9588 | Val Loss: 0.1758 Acc: 0.9330\n",
      "Epoch 030 | Train Loss: 0.0982 Acc: 0.9636 | Val Loss: 0.2085 Acc: 0.9293\n",
      "Epoch 031 | Train Loss: 0.1060 Acc: 0.9598 | Val Loss: 0.1876 Acc: 0.9263\n",
      "Epoch 032 | Train Loss: 0.0913 Acc: 0.9644 | Val Loss: 0.1942 Acc: 0.9293\n",
      "Epoch 033 | Train Loss: 0.0940 Acc: 0.9653 | Val Loss: 0.1787 Acc: 0.9293\n",
      "Epoch 034 | Train Loss: 0.0957 Acc: 0.9638 | Val Loss: 0.1731 Acc: 0.9366\n",
      "Epoch 035 | Train Loss: 0.0866 Acc: 0.9704 | Val Loss: 0.1603 Acc: 0.9378\n",
      "Epoch 036 | Train Loss: 0.0863 Acc: 0.9700 | Val Loss: 0.1805 Acc: 0.9233\n",
      "Epoch 037 | Train Loss: 0.0791 Acc: 0.9712 | Val Loss: 0.1796 Acc: 0.9342\n",
      "Epoch 038 | Train Loss: 0.0814 Acc: 0.9715 | Val Loss: 0.1995 Acc: 0.9227\n",
      "Epoch 039 | Train Loss: 0.0761 Acc: 0.9727 | Val Loss: 0.1767 Acc: 0.9420\n",
      "Epoch 040 | Train Loss: 0.0689 Acc: 0.9758 | Val Loss: 0.2131 Acc: 0.9185\n",
      "Epoch 041 | Train Loss: 0.0708 Acc: 0.9746 | Val Loss: 0.2068 Acc: 0.9293\n",
      "Epoch 042 | Train Loss: 0.0778 Acc: 0.9707 | Val Loss: 0.1716 Acc: 0.9342\n",
      "Epoch 043 | Train Loss: 0.0726 Acc: 0.9737 | Val Loss: 0.1506 Acc: 0.9457\n",
      "Epoch 044 | Train Loss: 0.0663 Acc: 0.9789 | Val Loss: 0.3163 Acc: 0.9149\n",
      "Epoch 045 | Train Loss: 0.0637 Acc: 0.9777 | Val Loss: 0.1752 Acc: 0.9324\n",
      "Epoch 046 | Train Loss: 0.0631 Acc: 0.9761 | Val Loss: 0.1962 Acc: 0.9167\n",
      "Epoch 047 | Train Loss: 0.0643 Acc: 0.9767 | Val Loss: 0.1894 Acc: 0.9354\n",
      "Epoch 048 | Train Loss: 0.0653 Acc: 0.9749 | Val Loss: 0.1789 Acc: 0.9402\n",
      "Epoch 049 | Train Loss: 0.0609 Acc: 0.9739 | Val Loss: 0.1913 Acc: 0.9366\n",
      "Epoch 050 | Train Loss: 0.0554 Acc: 0.9786 | Val Loss: 0.1557 Acc: 0.9469\n",
      "Epoch 051 | Train Loss: 0.0671 Acc: 0.9760 | Val Loss: 0.1499 Acc: 0.9517\n",
      "Epoch 052 | Train Loss: 0.0627 Acc: 0.9761 | Val Loss: 0.1704 Acc: 0.9511\n",
      "Epoch 053 | Train Loss: 0.0559 Acc: 0.9813 | Val Loss: 0.2511 Acc: 0.9275\n",
      "Epoch 054 | Train Loss: 0.0567 Acc: 0.9816 | Val Loss: 0.1918 Acc: 0.9378\n",
      "Epoch 055 | Train Loss: 0.0643 Acc: 0.9770 | Val Loss: 0.1656 Acc: 0.9408\n",
      "Epoch 056 | Train Loss: 0.0510 Acc: 0.9811 | Val Loss: 0.2028 Acc: 0.9348\n",
      "Epoch 057 | Train Loss: 0.0561 Acc: 0.9789 | Val Loss: 0.1657 Acc: 0.9481\n",
      "Epoch 058 | Train Loss: 0.0569 Acc: 0.9807 | Val Loss: 0.1824 Acc: 0.9360\n",
      "Epoch 059 | Train Loss: 0.0483 Acc: 0.9823 | Val Loss: 0.2011 Acc: 0.9378\n",
      "Epoch 060 | Train Loss: 0.0553 Acc: 0.9789 | Val Loss: 0.1904 Acc: 0.9378\n",
      "Epoch 001 | Train Loss: 0.6789 Acc: 0.5778 | Val Loss: 0.6737 Acc: 0.5912\n",
      "Epoch 002 | Train Loss: 0.6690 Acc: 0.6017 | Val Loss: 0.6664 Acc: 0.6027\n",
      "Epoch 003 | Train Loss: 0.6577 Acc: 0.6138 | Val Loss: 0.6565 Acc: 0.6039\n",
      "Epoch 004 | Train Loss: 0.6147 Acc: 0.6745 | Val Loss: 0.5968 Acc: 0.6884\n",
      "Epoch 005 | Train Loss: 0.5831 Acc: 0.7042 | Val Loss: 0.5915 Acc: 0.6963\n",
      "Epoch 006 | Train Loss: 0.5518 Acc: 0.7241 | Val Loss: 0.5775 Acc: 0.7126\n",
      "Epoch 007 | Train Loss: 0.5464 Acc: 0.7331 | Val Loss: 0.5373 Acc: 0.7307\n",
      "Epoch 008 | Train Loss: 0.5282 Acc: 0.7424 | Val Loss: 0.5208 Acc: 0.7379\n",
      "Epoch 009 | Train Loss: 0.5067 Acc: 0.7577 | Val Loss: 0.5024 Acc: 0.7554\n",
      "Epoch 010 | Train Loss: 0.4824 Acc: 0.7693 | Val Loss: 0.5224 Acc: 0.7409\n",
      "Epoch 011 | Train Loss: 0.4747 Acc: 0.7752 | Val Loss: 0.4847 Acc: 0.7591\n",
      "Epoch 012 | Train Loss: 0.4657 Acc: 0.7759 | Val Loss: 0.4753 Acc: 0.7669\n",
      "Epoch 013 | Train Loss: 0.4409 Acc: 0.7933 | Val Loss: 0.4378 Acc: 0.7886\n",
      "Epoch 014 | Train Loss: 0.4201 Acc: 0.8042 | Val Loss: 0.4138 Acc: 0.8043\n",
      "Epoch 015 | Train Loss: 0.4049 Acc: 0.8164 | Val Loss: 0.4067 Acc: 0.8086\n",
      "Epoch 016 | Train Loss: 0.3891 Acc: 0.8182 | Val Loss: 0.3875 Acc: 0.8231\n",
      "Epoch 017 | Train Loss: 0.3703 Acc: 0.8289 | Val Loss: 0.3746 Acc: 0.8279\n",
      "Epoch 018 | Train Loss: 0.3498 Acc: 0.8415 | Val Loss: 0.3447 Acc: 0.8394\n",
      "Epoch 019 | Train Loss: 0.3375 Acc: 0.8504 | Val Loss: 0.3508 Acc: 0.8460\n",
      "Epoch 020 | Train Loss: 0.3312 Acc: 0.8529 | Val Loss: 0.3285 Acc: 0.8490\n",
      "Epoch 021 | Train Loss: 0.3021 Acc: 0.8708 | Val Loss: 0.3074 Acc: 0.8635\n",
      "Epoch 022 | Train Loss: 0.2908 Acc: 0.8777 | Val Loss: 0.2902 Acc: 0.8714\n",
      "Epoch 023 | Train Loss: 0.2841 Acc: 0.8785 | Val Loss: 0.2806 Acc: 0.8780\n",
      "Epoch 024 | Train Loss: 0.2622 Acc: 0.8892 | Val Loss: 0.2416 Acc: 0.8986\n",
      "Epoch 025 | Train Loss: 0.2442 Acc: 0.8987 | Val Loss: 0.2571 Acc: 0.8949\n",
      "Epoch 026 | Train Loss: 0.2335 Acc: 0.9055 | Val Loss: 0.2296 Acc: 0.9022\n",
      "Epoch 027 | Train Loss: 0.2327 Acc: 0.9044 | Val Loss: 0.2521 Acc: 0.8937\n",
      "Epoch 028 | Train Loss: 0.2351 Acc: 0.9029 | Val Loss: 0.2447 Acc: 0.9028\n",
      "Epoch 029 | Train Loss: 0.2021 Acc: 0.9183 | Val Loss: 0.2338 Acc: 0.9058\n",
      "Epoch 030 | Train Loss: 0.2086 Acc: 0.9176 | Val Loss: 0.2251 Acc: 0.9088\n",
      "Epoch 031 | Train Loss: 0.1900 Acc: 0.9236 | Val Loss: 0.2064 Acc: 0.9185\n",
      "Epoch 032 | Train Loss: 0.1748 Acc: 0.9299 | Val Loss: 0.2037 Acc: 0.9221\n",
      "Epoch 033 | Train Loss: 0.1820 Acc: 0.9250 | Val Loss: 0.1906 Acc: 0.9263\n",
      "Epoch 034 | Train Loss: 0.1647 Acc: 0.9372 | Val Loss: 0.2521 Acc: 0.9124\n",
      "Epoch 035 | Train Loss: 0.1615 Acc: 0.9360 | Val Loss: 0.1797 Acc: 0.9348\n",
      "Epoch 036 | Train Loss: 0.1546 Acc: 0.9390 | Val Loss: 0.1788 Acc: 0.9269\n",
      "Epoch 037 | Train Loss: 0.1441 Acc: 0.9447 | Val Loss: 0.2110 Acc: 0.9269\n",
      "Epoch 038 | Train Loss: 0.1484 Acc: 0.9440 | Val Loss: 0.1883 Acc: 0.9239\n",
      "Epoch 039 | Train Loss: 0.1452 Acc: 0.9414 | Val Loss: 0.2050 Acc: 0.9185\n",
      "Epoch 040 | Train Loss: 0.1288 Acc: 0.9499 | Val Loss: 0.1886 Acc: 0.9306\n",
      "Epoch 041 | Train Loss: 0.1159 Acc: 0.9541 | Val Loss: 0.2119 Acc: 0.9251\n",
      "Epoch 042 | Train Loss: 0.1323 Acc: 0.9497 | Val Loss: 0.1801 Acc: 0.9306\n",
      "Epoch 043 | Train Loss: 0.1227 Acc: 0.9497 | Val Loss: 0.1662 Acc: 0.9324\n",
      "Epoch 044 | Train Loss: 0.1199 Acc: 0.9541 | Val Loss: 0.1754 Acc: 0.9354\n",
      "Epoch 045 | Train Loss: 0.1285 Acc: 0.9521 | Val Loss: 0.1564 Acc: 0.9487\n",
      "Epoch 046 | Train Loss: 0.1167 Acc: 0.9552 | Val Loss: 0.1621 Acc: 0.9342\n",
      "Epoch 047 | Train Loss: 0.1108 Acc: 0.9571 | Val Loss: 0.1801 Acc: 0.9360\n",
      "Epoch 048 | Train Loss: 0.1137 Acc: 0.9573 | Val Loss: 0.1591 Acc: 0.9420\n",
      "Epoch 049 | Train Loss: 0.0977 Acc: 0.9650 | Val Loss: 0.1781 Acc: 0.9408\n",
      "Epoch 050 | Train Loss: 0.0978 Acc: 0.9620 | Val Loss: 0.1801 Acc: 0.9372\n",
      "Epoch 051 | Train Loss: 0.0911 Acc: 0.9654 | Val Loss: 0.1781 Acc: 0.9384\n",
      "Epoch 052 | Train Loss: 0.0957 Acc: 0.9648 | Val Loss: 0.1580 Acc: 0.9450\n",
      "Epoch 053 | Train Loss: 0.0890 Acc: 0.9653 | Val Loss: 0.1541 Acc: 0.9432\n",
      "Epoch 054 | Train Loss: 0.0801 Acc: 0.9707 | Val Loss: 0.1510 Acc: 0.9420\n",
      "Epoch 055 | Train Loss: 0.0912 Acc: 0.9642 | Val Loss: 0.2096 Acc: 0.9293\n",
      "Epoch 056 | Train Loss: 0.0915 Acc: 0.9653 | Val Loss: 0.1810 Acc: 0.9336\n",
      "Epoch 057 | Train Loss: 0.0860 Acc: 0.9689 | Val Loss: 0.1786 Acc: 0.9324\n",
      "Epoch 058 | Train Loss: 0.0801 Acc: 0.9698 | Val Loss: 0.1925 Acc: 0.9372\n",
      "Epoch 059 | Train Loss: 0.0809 Acc: 0.9692 | Val Loss: 0.1425 Acc: 0.9505\n",
      "Epoch 060 | Train Loss: 0.0826 Acc: 0.9690 | Val Loss: 0.1685 Acc: 0.9408\n",
      "Epoch 001 | Train Loss: 0.6825 Acc: 0.5722 | Val Loss: 0.6762 Acc: 0.5857\n",
      "Epoch 002 | Train Loss: 0.6726 Acc: 0.5941 | Val Loss: 0.6667 Acc: 0.6033\n",
      "Epoch 003 | Train Loss: 0.6642 Acc: 0.6046 | Val Loss: 0.6650 Acc: 0.6033\n",
      "Epoch 004 | Train Loss: 0.6568 Acc: 0.6129 | Val Loss: 0.6476 Acc: 0.6153\n",
      "Epoch 005 | Train Loss: 0.6280 Acc: 0.6609 | Val Loss: 0.6099 Acc: 0.6848\n",
      "Epoch 006 | Train Loss: 0.5880 Acc: 0.7056 | Val Loss: 0.5651 Acc: 0.7095\n",
      "Epoch 007 | Train Loss: 0.5622 Acc: 0.7222 | Val Loss: 0.5544 Acc: 0.7271\n",
      "Epoch 008 | Train Loss: 0.5429 Acc: 0.7365 | Val Loss: 0.5554 Acc: 0.7210\n",
      "Epoch 009 | Train Loss: 0.5266 Acc: 0.7472 | Val Loss: 0.5235 Acc: 0.7415\n",
      "Epoch 010 | Train Loss: 0.5148 Acc: 0.7501 | Val Loss: 0.5094 Acc: 0.7530\n",
      "Epoch 011 | Train Loss: 0.4932 Acc: 0.7642 | Val Loss: 0.4735 Acc: 0.7687\n",
      "Epoch 012 | Train Loss: 0.4743 Acc: 0.7732 | Val Loss: 0.4593 Acc: 0.7772\n",
      "Epoch 013 | Train Loss: 0.4573 Acc: 0.7847 | Val Loss: 0.4462 Acc: 0.7814\n",
      "Epoch 014 | Train Loss: 0.4329 Acc: 0.8030 | Val Loss: 0.4072 Acc: 0.8086\n",
      "Epoch 015 | Train Loss: 0.4261 Acc: 0.8043 | Val Loss: 0.4017 Acc: 0.8068\n",
      "Epoch 016 | Train Loss: 0.3975 Acc: 0.8181 | Val Loss: 0.3938 Acc: 0.8146\n",
      "Epoch 017 | Train Loss: 0.3792 Acc: 0.8326 | Val Loss: 0.4402 Acc: 0.8019\n",
      "Epoch 018 | Train Loss: 0.3885 Acc: 0.8232 | Val Loss: 0.3955 Acc: 0.8182\n",
      "Epoch 019 | Train Loss: 0.3519 Acc: 0.8449 | Val Loss: 0.3275 Acc: 0.8557\n",
      "Epoch 020 | Train Loss: 0.3430 Acc: 0.8486 | Val Loss: 0.3219 Acc: 0.8569\n",
      "Epoch 021 | Train Loss: 0.3229 Acc: 0.8582 | Val Loss: 0.3103 Acc: 0.8623\n",
      "Epoch 022 | Train Loss: 0.3162 Acc: 0.8605 | Val Loss: 0.3155 Acc: 0.8617\n",
      "Epoch 023 | Train Loss: 0.3080 Acc: 0.8677 | Val Loss: 0.2808 Acc: 0.8816\n",
      "Epoch 024 | Train Loss: 0.2814 Acc: 0.8801 | Val Loss: 0.2659 Acc: 0.8889\n",
      "Epoch 025 | Train Loss: 0.2783 Acc: 0.8822 | Val Loss: 0.2651 Acc: 0.8889\n",
      "Epoch 026 | Train Loss: 0.2646 Acc: 0.8889 | Val Loss: 0.2570 Acc: 0.8889\n",
      "Epoch 027 | Train Loss: 0.2489 Acc: 0.8948 | Val Loss: 0.2304 Acc: 0.9046\n",
      "Epoch 028 | Train Loss: 0.2425 Acc: 0.8997 | Val Loss: 0.2463 Acc: 0.9064\n",
      "Epoch 029 | Train Loss: 0.2313 Acc: 0.9050 | Val Loss: 0.2173 Acc: 0.9179\n",
      "Epoch 030 | Train Loss: 0.2339 Acc: 0.9055 | Val Loss: 0.2324 Acc: 0.9070\n",
      "Epoch 031 | Train Loss: 0.2265 Acc: 0.9077 | Val Loss: 0.2362 Acc: 0.9010\n",
      "Epoch 032 | Train Loss: 0.2024 Acc: 0.9194 | Val Loss: 0.2716 Acc: 0.8901\n",
      "Epoch 033 | Train Loss: 0.2107 Acc: 0.9161 | Val Loss: 0.2075 Acc: 0.9191\n",
      "Epoch 034 | Train Loss: 0.2012 Acc: 0.9183 | Val Loss: 0.1995 Acc: 0.9173\n",
      "Epoch 035 | Train Loss: 0.1959 Acc: 0.9219 | Val Loss: 0.2046 Acc: 0.9203\n",
      "Epoch 036 | Train Loss: 0.1881 Acc: 0.9268 | Val Loss: 0.1844 Acc: 0.9318\n",
      "Epoch 037 | Train Loss: 0.1875 Acc: 0.9253 | Val Loss: 0.2447 Acc: 0.8998\n",
      "Epoch 038 | Train Loss: 0.1776 Acc: 0.9274 | Val Loss: 0.1918 Acc: 0.9300\n",
      "Epoch 039 | Train Loss: 0.1688 Acc: 0.9321 | Val Loss: 0.1750 Acc: 0.9366\n",
      "Epoch 040 | Train Loss: 0.1643 Acc: 0.9370 | Val Loss: 0.1709 Acc: 0.9269\n",
      "Epoch 041 | Train Loss: 0.1650 Acc: 0.9351 | Val Loss: 0.1785 Acc: 0.9342\n",
      "Epoch 042 | Train Loss: 0.1640 Acc: 0.9355 | Val Loss: 0.2039 Acc: 0.9275\n",
      "Epoch 043 | Train Loss: 0.1551 Acc: 0.9405 | Val Loss: 0.1588 Acc: 0.9414\n",
      "Epoch 044 | Train Loss: 0.1574 Acc: 0.9360 | Val Loss: 0.1577 Acc: 0.9330\n",
      "Epoch 045 | Train Loss: 0.1542 Acc: 0.9398 | Val Loss: 0.1584 Acc: 0.9414\n",
      "Epoch 046 | Train Loss: 0.1543 Acc: 0.9407 | Val Loss: 0.1722 Acc: 0.9312\n",
      "Epoch 047 | Train Loss: 0.1477 Acc: 0.9435 | Val Loss: 0.1955 Acc: 0.9257\n",
      "Epoch 048 | Train Loss: 0.1350 Acc: 0.9506 | Val Loss: 0.1600 Acc: 0.9438\n",
      "Epoch 049 | Train Loss: 0.1345 Acc: 0.9470 | Val Loss: 0.1621 Acc: 0.9372\n",
      "Epoch 050 | Train Loss: 0.1201 Acc: 0.9517 | Val Loss: 0.1543 Acc: 0.9426\n",
      "Epoch 051 | Train Loss: 0.1271 Acc: 0.9506 | Val Loss: 0.1487 Acc: 0.9469\n",
      "Epoch 052 | Train Loss: 0.1280 Acc: 0.9514 | Val Loss: 0.1649 Acc: 0.9384\n",
      "Epoch 053 | Train Loss: 0.1195 Acc: 0.9564 | Val Loss: 0.1606 Acc: 0.9360\n",
      "Epoch 054 | Train Loss: 0.1082 Acc: 0.9583 | Val Loss: 0.1745 Acc: 0.9390\n",
      "Epoch 055 | Train Loss: 0.1140 Acc: 0.9549 | Val Loss: 0.1552 Acc: 0.9372\n",
      "Epoch 056 | Train Loss: 0.1134 Acc: 0.9544 | Val Loss: 0.1393 Acc: 0.9487\n",
      "Epoch 057 | Train Loss: 0.1210 Acc: 0.9546 | Val Loss: 0.1377 Acc: 0.9475\n",
      "Epoch 058 | Train Loss: 0.1070 Acc: 0.9573 | Val Loss: 0.1618 Acc: 0.9420\n",
      "Epoch 059 | Train Loss: 0.1126 Acc: 0.9585 | Val Loss: 0.1598 Acc: 0.9408\n",
      "Epoch 060 | Train Loss: 0.1138 Acc: 0.9579 | Val Loss: 0.1882 Acc: 0.9354\n",
      "Iteration 22/40 | Best Val Loss: 0.1122 | Iter Time: 238.11s | Total Time: 93.81 min\n",
      "Epoch 001 | Train Loss: 0.6825 Acc: 0.5732 | Val Loss: 0.6757 Acc: 0.5936\n",
      "Epoch 002 | Train Loss: 0.6718 Acc: 0.5955 | Val Loss: 0.6689 Acc: 0.5990\n",
      "Epoch 003 | Train Loss: 0.6636 Acc: 0.6080 | Val Loss: 0.6546 Acc: 0.6479\n",
      "Epoch 004 | Train Loss: 0.6483 Acc: 0.6269 | Val Loss: 0.6282 Acc: 0.6558\n",
      "Epoch 005 | Train Loss: 0.6183 Acc: 0.6730 | Val Loss: 0.6005 Acc: 0.6860\n",
      "Epoch 006 | Train Loss: 0.5871 Acc: 0.7019 | Val Loss: 0.5805 Acc: 0.7035\n",
      "Epoch 007 | Train Loss: 0.5616 Acc: 0.7250 | Val Loss: 0.5656 Acc: 0.7107\n",
      "Epoch 008 | Train Loss: 0.5386 Acc: 0.7376 | Val Loss: 0.5497 Acc: 0.7204\n",
      "Epoch 009 | Train Loss: 0.5187 Acc: 0.7482 | Val Loss: 0.5386 Acc: 0.7240\n",
      "Epoch 010 | Train Loss: 0.5119 Acc: 0.7518 | Val Loss: 0.5553 Acc: 0.7095\n",
      "Epoch 011 | Train Loss: 0.4945 Acc: 0.7623 | Val Loss: 0.5087 Acc: 0.7434\n",
      "Epoch 012 | Train Loss: 0.4837 Acc: 0.7691 | Val Loss: 0.5031 Acc: 0.7506\n",
      "Epoch 013 | Train Loss: 0.4668 Acc: 0.7802 | Val Loss: 0.4913 Acc: 0.7645\n",
      "Epoch 014 | Train Loss: 0.4505 Acc: 0.7886 | Val Loss: 0.4844 Acc: 0.7615\n",
      "Epoch 015 | Train Loss: 0.4367 Acc: 0.7921 | Val Loss: 0.4828 Acc: 0.7512\n",
      "Epoch 016 | Train Loss: 0.4236 Acc: 0.8063 | Val Loss: 0.4428 Acc: 0.7905\n",
      "Epoch 017 | Train Loss: 0.3858 Acc: 0.8274 | Val Loss: 0.4762 Acc: 0.7742\n",
      "Epoch 018 | Train Loss: 0.3885 Acc: 0.8212 | Val Loss: 0.4557 Acc: 0.7669\n",
      "Epoch 019 | Train Loss: 0.3768 Acc: 0.8270 | Val Loss: 0.3862 Acc: 0.8213\n",
      "Epoch 020 | Train Loss: 0.3402 Acc: 0.8478 | Val Loss: 0.3525 Acc: 0.8448\n",
      "Epoch 021 | Train Loss: 0.3090 Acc: 0.8602 | Val Loss: 0.3604 Acc: 0.8291\n",
      "Epoch 022 | Train Loss: 0.3150 Acc: 0.8620 | Val Loss: 0.3440 Acc: 0.8406\n",
      "Epoch 023 | Train Loss: 0.2815 Acc: 0.8791 | Val Loss: 0.3029 Acc: 0.8665\n",
      "Epoch 024 | Train Loss: 0.2717 Acc: 0.8860 | Val Loss: 0.3018 Acc: 0.8750\n",
      "Epoch 025 | Train Loss: 0.2616 Acc: 0.8836 | Val Loss: 0.2898 Acc: 0.8756\n",
      "Epoch 026 | Train Loss: 0.2374 Acc: 0.8991 | Val Loss: 0.2651 Acc: 0.8949\n",
      "Epoch 027 | Train Loss: 0.2168 Acc: 0.9102 | Val Loss: 0.2565 Acc: 0.8901\n",
      "Epoch 028 | Train Loss: 0.2056 Acc: 0.9167 | Val Loss: 0.2471 Acc: 0.8967\n",
      "Epoch 029 | Train Loss: 0.1966 Acc: 0.9194 | Val Loss: 0.2400 Acc: 0.9058\n",
      "Epoch 030 | Train Loss: 0.1920 Acc: 0.9192 | Val Loss: 0.2439 Acc: 0.8931\n",
      "Epoch 031 | Train Loss: 0.1721 Acc: 0.9278 | Val Loss: 0.2350 Acc: 0.9040\n",
      "Epoch 032 | Train Loss: 0.1571 Acc: 0.9363 | Val Loss: 0.2199 Acc: 0.9076\n",
      "Epoch 033 | Train Loss: 0.1631 Acc: 0.9357 | Val Loss: 0.2363 Acc: 0.9028\n",
      "Epoch 034 | Train Loss: 0.1469 Acc: 0.9414 | Val Loss: 0.2001 Acc: 0.9161\n",
      "Epoch 035 | Train Loss: 0.1430 Acc: 0.9425 | Val Loss: 0.2129 Acc: 0.9215\n",
      "Epoch 036 | Train Loss: 0.1391 Acc: 0.9452 | Val Loss: 0.1960 Acc: 0.9239\n",
      "Epoch 037 | Train Loss: 0.1306 Acc: 0.9496 | Val Loss: 0.2135 Acc: 0.9136\n",
      "Epoch 038 | Train Loss: 0.1139 Acc: 0.9547 | Val Loss: 0.1964 Acc: 0.9251\n",
      "Epoch 039 | Train Loss: 0.1169 Acc: 0.9524 | Val Loss: 0.1932 Acc: 0.9300\n",
      "Epoch 040 | Train Loss: 0.1165 Acc: 0.9555 | Val Loss: 0.2094 Acc: 0.9209\n",
      "Epoch 041 | Train Loss: 0.1048 Acc: 0.9586 | Val Loss: 0.1952 Acc: 0.9215\n",
      "Epoch 042 | Train Loss: 0.1001 Acc: 0.9604 | Val Loss: 0.1862 Acc: 0.9293\n",
      "Epoch 043 | Train Loss: 0.0946 Acc: 0.9648 | Val Loss: 0.2045 Acc: 0.9251\n",
      "Epoch 044 | Train Loss: 0.0801 Acc: 0.9689 | Val Loss: 0.1808 Acc: 0.9330\n",
      "Epoch 045 | Train Loss: 0.0901 Acc: 0.9651 | Val Loss: 0.1865 Acc: 0.9281\n",
      "Epoch 046 | Train Loss: 0.0793 Acc: 0.9687 | Val Loss: 0.1909 Acc: 0.9330\n",
      "Epoch 047 | Train Loss: 0.0742 Acc: 0.9737 | Val Loss: 0.1762 Acc: 0.9372\n",
      "Epoch 048 | Train Loss: 0.0742 Acc: 0.9718 | Val Loss: 0.2475 Acc: 0.9161\n",
      "Epoch 049 | Train Loss: 0.0768 Acc: 0.9710 | Val Loss: 0.2359 Acc: 0.9203\n",
      "Epoch 050 | Train Loss: 0.0763 Acc: 0.9710 | Val Loss: 0.1995 Acc: 0.9348\n",
      "Epoch 051 | Train Loss: 0.0654 Acc: 0.9748 | Val Loss: 0.1955 Acc: 0.9384\n",
      "Epoch 052 | Train Loss: 0.0697 Acc: 0.9734 | Val Loss: 0.2041 Acc: 0.9354\n",
      "Epoch 053 | Train Loss: 0.0518 Acc: 0.9814 | Val Loss: 0.2019 Acc: 0.9318\n",
      "Epoch 054 | Train Loss: 0.0693 Acc: 0.9727 | Val Loss: 0.1854 Acc: 0.9396\n",
      "Epoch 055 | Train Loss: 0.0610 Acc: 0.9764 | Val Loss: 0.2161 Acc: 0.9300\n",
      "Epoch 056 | Train Loss: 0.0517 Acc: 0.9795 | Val Loss: 0.2109 Acc: 0.9330\n",
      "Epoch 057 | Train Loss: 0.0673 Acc: 0.9749 | Val Loss: 0.2002 Acc: 0.9306\n",
      "Early stopping triggered.\n",
      "Epoch 001 | Train Loss: 0.6802 Acc: 0.5840 | Val Loss: 0.6741 Acc: 0.5888\n",
      "Epoch 002 | Train Loss: 0.6489 Acc: 0.6301 | Val Loss: 0.6615 Acc: 0.6153\n",
      "Epoch 003 | Train Loss: 0.5863 Acc: 0.7003 | Val Loss: 0.5736 Acc: 0.6987\n",
      "Epoch 004 | Train Loss: 0.5491 Acc: 0.7220 | Val Loss: 0.5390 Acc: 0.7283\n",
      "Epoch 005 | Train Loss: 0.5120 Acc: 0.7566 | Val Loss: 0.5338 Acc: 0.7379\n",
      "Epoch 006 | Train Loss: 0.4743 Acc: 0.7731 | Val Loss: 0.5287 Acc: 0.7421\n",
      "Epoch 007 | Train Loss: 0.4365 Acc: 0.7948 | Val Loss: 0.4621 Acc: 0.7772\n",
      "Epoch 008 | Train Loss: 0.4063 Acc: 0.8096 | Val Loss: 0.4593 Acc: 0.7736\n",
      "Epoch 009 | Train Loss: 0.3727 Acc: 0.8344 | Val Loss: 0.3645 Acc: 0.8261\n",
      "Epoch 010 | Train Loss: 0.3323 Acc: 0.8557 | Val Loss: 0.3436 Acc: 0.8436\n",
      "Epoch 011 | Train Loss: 0.2980 Acc: 0.8736 | Val Loss: 0.3060 Acc: 0.8647\n",
      "Epoch 012 | Train Loss: 0.2827 Acc: 0.8815 | Val Loss: 0.3051 Acc: 0.8611\n",
      "Epoch 013 | Train Loss: 0.2392 Acc: 0.9013 | Val Loss: 0.2846 Acc: 0.8732\n",
      "Epoch 014 | Train Loss: 0.2095 Acc: 0.9148 | Val Loss: 0.2444 Acc: 0.8949\n",
      "Epoch 015 | Train Loss: 0.1919 Acc: 0.9241 | Val Loss: 0.2386 Acc: 0.8967\n",
      "Epoch 016 | Train Loss: 0.1693 Acc: 0.9319 | Val Loss: 0.2225 Acc: 0.9112\n",
      "Epoch 017 | Train Loss: 0.1605 Acc: 0.9355 | Val Loss: 0.2224 Acc: 0.9155\n",
      "Epoch 018 | Train Loss: 0.1543 Acc: 0.9376 | Val Loss: 0.1907 Acc: 0.9233\n",
      "Epoch 019 | Train Loss: 0.1347 Acc: 0.9500 | Val Loss: 0.2333 Acc: 0.9106\n",
      "Epoch 020 | Train Loss: 0.1395 Acc: 0.9449 | Val Loss: 0.1832 Acc: 0.9239\n",
      "Epoch 021 | Train Loss: 0.1124 Acc: 0.9568 | Val Loss: 0.1940 Acc: 0.9300\n",
      "Epoch 022 | Train Loss: 0.1074 Acc: 0.9592 | Val Loss: 0.1720 Acc: 0.9426\n",
      "Epoch 023 | Train Loss: 0.0959 Acc: 0.9624 | Val Loss: 0.1917 Acc: 0.9300\n",
      "Epoch 024 | Train Loss: 0.0939 Acc: 0.9644 | Val Loss: 0.1964 Acc: 0.9209\n",
      "Epoch 025 | Train Loss: 0.1007 Acc: 0.9620 | Val Loss: 0.1632 Acc: 0.9420\n",
      "Epoch 026 | Train Loss: 0.0817 Acc: 0.9713 | Val Loss: 0.1795 Acc: 0.9342\n",
      "Epoch 027 | Train Loss: 0.0842 Acc: 0.9692 | Val Loss: 0.1933 Acc: 0.9281\n",
      "Epoch 028 | Train Loss: 0.0777 Acc: 0.9690 | Val Loss: 0.1854 Acc: 0.9360\n",
      "Epoch 029 | Train Loss: 0.0718 Acc: 0.9742 | Val Loss: 0.1722 Acc: 0.9366\n",
      "Epoch 030 | Train Loss: 0.0722 Acc: 0.9724 | Val Loss: 0.1539 Acc: 0.9475\n",
      "Epoch 031 | Train Loss: 0.0609 Acc: 0.9767 | Val Loss: 0.1763 Acc: 0.9457\n",
      "Epoch 032 | Train Loss: 0.0594 Acc: 0.9778 | Val Loss: 0.1883 Acc: 0.9444\n",
      "Epoch 033 | Train Loss: 0.0639 Acc: 0.9752 | Val Loss: 0.1684 Acc: 0.9330\n",
      "Epoch 034 | Train Loss: 0.0534 Acc: 0.9807 | Val Loss: 0.2172 Acc: 0.9233\n",
      "Epoch 035 | Train Loss: 0.0560 Acc: 0.9786 | Val Loss: 0.2303 Acc: 0.9312\n",
      "Epoch 036 | Train Loss: 0.0615 Acc: 0.9774 | Val Loss: 0.1575 Acc: 0.9463\n",
      "Epoch 037 | Train Loss: 0.0567 Acc: 0.9801 | Val Loss: 0.1753 Acc: 0.9414\n",
      "Epoch 038 | Train Loss: 0.0577 Acc: 0.9761 | Val Loss: 0.2364 Acc: 0.9215\n",
      "Epoch 039 | Train Loss: 0.0474 Acc: 0.9848 | Val Loss: 0.1992 Acc: 0.9414\n",
      "Epoch 040 | Train Loss: 0.0534 Acc: 0.9814 | Val Loss: 0.1829 Acc: 0.9384\n",
      "Early stopping triggered.\n",
      "Epoch 001 | Train Loss: 0.6837 Acc: 0.5683 | Val Loss: 0.6767 Acc: 0.5864\n",
      "Epoch 002 | Train Loss: 0.6739 Acc: 0.5911 | Val Loss: 0.6709 Acc: 0.5924\n",
      "Epoch 003 | Train Loss: 0.6670 Acc: 0.6062 | Val Loss: 0.6661 Acc: 0.6033\n",
      "Epoch 004 | Train Loss: 0.6622 Acc: 0.6079 | Val Loss: 0.6624 Acc: 0.6014\n",
      "Epoch 005 | Train Loss: 0.6455 Acc: 0.6382 | Val Loss: 0.6128 Acc: 0.6854\n",
      "Epoch 006 | Train Loss: 0.6020 Acc: 0.6914 | Val Loss: 0.5849 Acc: 0.6975\n",
      "Epoch 007 | Train Loss: 0.5632 Acc: 0.7193 | Val Loss: 0.5539 Acc: 0.7264\n",
      "Epoch 008 | Train Loss: 0.5445 Acc: 0.7329 | Val Loss: 0.5419 Acc: 0.7355\n",
      "Epoch 009 | Train Loss: 0.5271 Acc: 0.7441 | Val Loss: 0.5148 Acc: 0.7464\n",
      "Epoch 010 | Train Loss: 0.5087 Acc: 0.7551 | Val Loss: 0.5127 Acc: 0.7621\n",
      "Epoch 011 | Train Loss: 0.4927 Acc: 0.7682 | Val Loss: 0.4887 Acc: 0.7633\n",
      "Epoch 012 | Train Loss: 0.4754 Acc: 0.7716 | Val Loss: 0.4685 Acc: 0.7729\n",
      "Epoch 013 | Train Loss: 0.4392 Acc: 0.7913 | Val Loss: 0.4388 Acc: 0.7941\n",
      "Epoch 014 | Train Loss: 0.4323 Acc: 0.7998 | Val Loss: 0.4273 Acc: 0.7947\n",
      "Epoch 015 | Train Loss: 0.4101 Acc: 0.8114 | Val Loss: 0.3932 Acc: 0.8080\n",
      "Epoch 016 | Train Loss: 0.3773 Acc: 0.8304 | Val Loss: 0.3940 Acc: 0.8207\n",
      "Epoch 017 | Train Loss: 0.3736 Acc: 0.8288 | Val Loss: 0.3740 Acc: 0.8158\n",
      "Epoch 018 | Train Loss: 0.3508 Acc: 0.8412 | Val Loss: 0.3516 Acc: 0.8357\n",
      "Epoch 019 | Train Loss: 0.3316 Acc: 0.8510 | Val Loss: 0.3569 Acc: 0.8333\n",
      "Epoch 020 | Train Loss: 0.3176 Acc: 0.8646 | Val Loss: 0.3810 Acc: 0.8273\n",
      "Epoch 021 | Train Loss: 0.2994 Acc: 0.8686 | Val Loss: 0.3039 Acc: 0.8641\n",
      "Epoch 022 | Train Loss: 0.2800 Acc: 0.8848 | Val Loss: 0.3001 Acc: 0.8641\n",
      "Epoch 023 | Train Loss: 0.2690 Acc: 0.8871 | Val Loss: 0.2899 Acc: 0.8762\n",
      "Epoch 024 | Train Loss: 0.2534 Acc: 0.8942 | Val Loss: 0.2630 Acc: 0.8865\n",
      "Epoch 025 | Train Loss: 0.2404 Acc: 0.8979 | Val Loss: 0.2640 Acc: 0.8841\n",
      "Epoch 026 | Train Loss: 0.2331 Acc: 0.9052 | Val Loss: 0.2627 Acc: 0.8889\n",
      "Epoch 027 | Train Loss: 0.2149 Acc: 0.9127 | Val Loss: 0.2347 Acc: 0.9064\n",
      "Epoch 028 | Train Loss: 0.2094 Acc: 0.9173 | Val Loss: 0.2567 Acc: 0.8955\n",
      "Epoch 029 | Train Loss: 0.1937 Acc: 0.9204 | Val Loss: 0.2483 Acc: 0.8998\n",
      "Epoch 030 | Train Loss: 0.1854 Acc: 0.9254 | Val Loss: 0.2361 Acc: 0.8992\n",
      "Epoch 031 | Train Loss: 0.1773 Acc: 0.9287 | Val Loss: 0.2386 Acc: 0.9046\n",
      "Epoch 032 | Train Loss: 0.1829 Acc: 0.9263 | Val Loss: 0.2300 Acc: 0.9100\n",
      "Epoch 033 | Train Loss: 0.1715 Acc: 0.9299 | Val Loss: 0.2378 Acc: 0.9112\n",
      "Epoch 034 | Train Loss: 0.1611 Acc: 0.9370 | Val Loss: 0.2638 Acc: 0.9100\n",
      "Epoch 035 | Train Loss: 0.1633 Acc: 0.9378 | Val Loss: 0.2046 Acc: 0.9173\n",
      "Epoch 036 | Train Loss: 0.1471 Acc: 0.9411 | Val Loss: 0.2344 Acc: 0.9076\n",
      "Epoch 037 | Train Loss: 0.1506 Acc: 0.9392 | Val Loss: 0.2465 Acc: 0.9112\n",
      "Epoch 038 | Train Loss: 0.1353 Acc: 0.9487 | Val Loss: 0.2248 Acc: 0.9118\n",
      "Epoch 039 | Train Loss: 0.1388 Acc: 0.9499 | Val Loss: 0.2162 Acc: 0.9179\n",
      "Epoch 040 | Train Loss: 0.1265 Acc: 0.9524 | Val Loss: 0.2194 Acc: 0.9251\n",
      "Epoch 041 | Train Loss: 0.1237 Acc: 0.9532 | Val Loss: 0.1998 Acc: 0.9293\n",
      "Epoch 042 | Train Loss: 0.1232 Acc: 0.9529 | Val Loss: 0.2076 Acc: 0.9221\n",
      "Epoch 043 | Train Loss: 0.1171 Acc: 0.9520 | Val Loss: 0.2052 Acc: 0.9191\n",
      "Epoch 044 | Train Loss: 0.1146 Acc: 0.9546 | Val Loss: 0.1882 Acc: 0.9306\n",
      "Epoch 045 | Train Loss: 0.1058 Acc: 0.9591 | Val Loss: 0.1940 Acc: 0.9336\n",
      "Epoch 046 | Train Loss: 0.1051 Acc: 0.9582 | Val Loss: 0.2011 Acc: 0.9263\n",
      "Epoch 047 | Train Loss: 0.1185 Acc: 0.9549 | Val Loss: 0.1751 Acc: 0.9342\n",
      "Epoch 048 | Train Loss: 0.1068 Acc: 0.9603 | Val Loss: 0.1999 Acc: 0.9263\n",
      "Epoch 049 | Train Loss: 0.1087 Acc: 0.9588 | Val Loss: 0.1896 Acc: 0.9306\n",
      "Epoch 050 | Train Loss: 0.0945 Acc: 0.9641 | Val Loss: 0.2204 Acc: 0.9209\n",
      "Epoch 051 | Train Loss: 0.0915 Acc: 0.9668 | Val Loss: 0.2158 Acc: 0.9191\n",
      "Epoch 052 | Train Loss: 0.1003 Acc: 0.9642 | Val Loss: 0.2073 Acc: 0.9251\n",
      "Epoch 053 | Train Loss: 0.0949 Acc: 0.9659 | Val Loss: 0.1922 Acc: 0.9330\n",
      "Epoch 054 | Train Loss: 0.0938 Acc: 0.9648 | Val Loss: 0.1915 Acc: 0.9312\n",
      "Epoch 055 | Train Loss: 0.0834 Acc: 0.9697 | Val Loss: 0.2433 Acc: 0.9251\n",
      "Epoch 056 | Train Loss: 0.0901 Acc: 0.9684 | Val Loss: 0.2050 Acc: 0.9306\n",
      "Epoch 057 | Train Loss: 0.0841 Acc: 0.9692 | Val Loss: 0.2463 Acc: 0.9167\n",
      "Early stopping triggered.\n",
      "Epoch 001 | Train Loss: 0.6850 Acc: 0.5550 | Val Loss: 0.6786 Acc: 0.5851\n",
      "Epoch 002 | Train Loss: 0.6776 Acc: 0.5819 | Val Loss: 0.6766 Acc: 0.5882\n",
      "Epoch 003 | Train Loss: 0.6760 Acc: 0.5899 | Val Loss: 0.6731 Acc: 0.5906\n",
      "Epoch 004 | Train Loss: 0.6697 Acc: 0.5984 | Val Loss: 0.6725 Acc: 0.5797\n",
      "Epoch 005 | Train Loss: 0.6640 Acc: 0.6049 | Val Loss: 0.6635 Acc: 0.5990\n",
      "Epoch 006 | Train Loss: 0.6563 Acc: 0.6132 | Val Loss: 0.6533 Acc: 0.6069\n",
      "Epoch 007 | Train Loss: 0.6482 Acc: 0.6325 | Val Loss: 0.6450 Acc: 0.6419\n",
      "Epoch 008 | Train Loss: 0.6372 Acc: 0.6503 | Val Loss: 0.6263 Acc: 0.6667\n",
      "Epoch 009 | Train Loss: 0.6192 Acc: 0.6665 | Val Loss: 0.6104 Acc: 0.6793\n",
      "Epoch 010 | Train Loss: 0.6035 Acc: 0.6849 | Val Loss: 0.6018 Acc: 0.6884\n",
      "Epoch 011 | Train Loss: 0.5912 Acc: 0.6920 | Val Loss: 0.5832 Acc: 0.6999\n",
      "Epoch 012 | Train Loss: 0.5827 Acc: 0.6986 | Val Loss: 0.5763 Acc: 0.7089\n",
      "Epoch 013 | Train Loss: 0.5691 Acc: 0.7143 | Val Loss: 0.5692 Acc: 0.7144\n",
      "Epoch 014 | Train Loss: 0.5648 Acc: 0.7146 | Val Loss: 0.5636 Acc: 0.7210\n",
      "Epoch 015 | Train Loss: 0.5597 Acc: 0.7231 | Val Loss: 0.5619 Acc: 0.7264\n",
      "Epoch 016 | Train Loss: 0.5536 Acc: 0.7254 | Val Loss: 0.5688 Acc: 0.7107\n",
      "Epoch 017 | Train Loss: 0.5437 Acc: 0.7308 | Val Loss: 0.5620 Acc: 0.7150\n",
      "Epoch 018 | Train Loss: 0.5347 Acc: 0.7430 | Val Loss: 0.5400 Acc: 0.7343\n",
      "Epoch 019 | Train Loss: 0.5252 Acc: 0.7454 | Val Loss: 0.5329 Acc: 0.7264\n",
      "Epoch 020 | Train Loss: 0.5206 Acc: 0.7456 | Val Loss: 0.5333 Acc: 0.7313\n",
      "Epoch 021 | Train Loss: 0.5099 Acc: 0.7545 | Val Loss: 0.5273 Acc: 0.7355\n",
      "Epoch 022 | Train Loss: 0.5027 Acc: 0.7581 | Val Loss: 0.5181 Acc: 0.7409\n",
      "Epoch 023 | Train Loss: 0.5051 Acc: 0.7522 | Val Loss: 0.5244 Acc: 0.7397\n",
      "Epoch 024 | Train Loss: 0.4917 Acc: 0.7651 | Val Loss: 0.5093 Acc: 0.7434\n",
      "Epoch 025 | Train Loss: 0.4844 Acc: 0.7666 | Val Loss: 0.5030 Acc: 0.7572\n",
      "Epoch 026 | Train Loss: 0.4834 Acc: 0.7722 | Val Loss: 0.5022 Acc: 0.7530\n",
      "Epoch 027 | Train Loss: 0.4797 Acc: 0.7699 | Val Loss: 0.5036 Acc: 0.7506\n",
      "Epoch 028 | Train Loss: 0.4704 Acc: 0.7732 | Val Loss: 0.4761 Acc: 0.7742\n",
      "Epoch 029 | Train Loss: 0.4639 Acc: 0.7854 | Val Loss: 0.4793 Acc: 0.7693\n",
      "Epoch 030 | Train Loss: 0.4518 Acc: 0.7900 | Val Loss: 0.4845 Acc: 0.7645\n",
      "Epoch 031 | Train Loss: 0.4568 Acc: 0.7888 | Val Loss: 0.4610 Acc: 0.7802\n",
      "Epoch 032 | Train Loss: 0.4418 Acc: 0.7941 | Val Loss: 0.4721 Acc: 0.7657\n",
      "Epoch 033 | Train Loss: 0.4428 Acc: 0.7927 | Val Loss: 0.4522 Acc: 0.7880\n",
      "Epoch 034 | Train Loss: 0.4383 Acc: 0.7962 | Val Loss: 0.4449 Acc: 0.7953\n",
      "Epoch 035 | Train Loss: 0.4286 Acc: 0.8040 | Val Loss: 0.4408 Acc: 0.7899\n",
      "Epoch 036 | Train Loss: 0.4270 Acc: 0.8052 | Val Loss: 0.4466 Acc: 0.7886\n",
      "Epoch 037 | Train Loss: 0.4192 Acc: 0.8085 | Val Loss: 0.4364 Acc: 0.7911\n",
      "Epoch 038 | Train Loss: 0.4190 Acc: 0.8072 | Val Loss: 0.4711 Acc: 0.7705\n",
      "Epoch 039 | Train Loss: 0.4114 Acc: 0.8051 | Val Loss: 0.4262 Acc: 0.8043\n",
      "Epoch 040 | Train Loss: 0.4067 Acc: 0.8208 | Val Loss: 0.4161 Acc: 0.8025\n",
      "Epoch 041 | Train Loss: 0.3991 Acc: 0.8172 | Val Loss: 0.4084 Acc: 0.8031\n",
      "Epoch 042 | Train Loss: 0.3966 Acc: 0.8197 | Val Loss: 0.4243 Acc: 0.7977\n",
      "Epoch 043 | Train Loss: 0.3903 Acc: 0.8232 | Val Loss: 0.4116 Acc: 0.8110\n",
      "Epoch 044 | Train Loss: 0.3773 Acc: 0.8313 | Val Loss: 0.4012 Acc: 0.8086\n",
      "Epoch 045 | Train Loss: 0.3705 Acc: 0.8301 | Val Loss: 0.3906 Acc: 0.8243\n",
      "Epoch 046 | Train Loss: 0.3677 Acc: 0.8330 | Val Loss: 0.3903 Acc: 0.8140\n",
      "Epoch 047 | Train Loss: 0.3698 Acc: 0.8309 | Val Loss: 0.4198 Acc: 0.7929\n",
      "Epoch 048 | Train Loss: 0.3632 Acc: 0.8298 | Val Loss: 0.3744 Acc: 0.8285\n",
      "Epoch 049 | Train Loss: 0.3502 Acc: 0.8433 | Val Loss: 0.3766 Acc: 0.8255\n",
      "Epoch 050 | Train Loss: 0.3423 Acc: 0.8477 | Val Loss: 0.3704 Acc: 0.8357\n",
      "Epoch 051 | Train Loss: 0.3422 Acc: 0.8492 | Val Loss: 0.3629 Acc: 0.8376\n",
      "Epoch 052 | Train Loss: 0.3360 Acc: 0.8513 | Val Loss: 0.3613 Acc: 0.8418\n",
      "Epoch 053 | Train Loss: 0.3234 Acc: 0.8563 | Val Loss: 0.3794 Acc: 0.8291\n",
      "Epoch 054 | Train Loss: 0.3298 Acc: 0.8508 | Val Loss: 0.3451 Acc: 0.8539\n",
      "Epoch 055 | Train Loss: 0.3216 Acc: 0.8576 | Val Loss: 0.3675 Acc: 0.8388\n",
      "Epoch 056 | Train Loss: 0.3197 Acc: 0.8596 | Val Loss: 0.3480 Acc: 0.8424\n",
      "Epoch 057 | Train Loss: 0.3143 Acc: 0.8584 | Val Loss: 0.3628 Acc: 0.8406\n",
      "Epoch 058 | Train Loss: 0.3086 Acc: 0.8646 | Val Loss: 0.3323 Acc: 0.8575\n",
      "Epoch 059 | Train Loss: 0.3076 Acc: 0.8635 | Val Loss: 0.3345 Acc: 0.8508\n",
      "Epoch 060 | Train Loss: 0.2937 Acc: 0.8694 | Val Loss: 0.3254 Acc: 0.8665\n",
      "Epoch 001 | Train Loss: 0.6822 Acc: 0.5682 | Val Loss: 0.6768 Acc: 0.5851\n",
      "Epoch 002 | Train Loss: 0.6704 Acc: 0.5913 | Val Loss: 0.6643 Acc: 0.5948\n",
      "Epoch 003 | Train Loss: 0.6221 Acc: 0.6665 | Val Loss: 0.5902 Acc: 0.6981\n",
      "Epoch 004 | Train Loss: 0.5646 Acc: 0.7175 | Val Loss: 0.5726 Acc: 0.7150\n",
      "Epoch 005 | Train Loss: 0.5385 Acc: 0.7414 | Val Loss: 0.5515 Acc: 0.7138\n",
      "Epoch 006 | Train Loss: 0.5266 Acc: 0.7459 | Val Loss: 0.5434 Acc: 0.7258\n",
      "Epoch 007 | Train Loss: 0.4997 Acc: 0.7581 | Val Loss: 0.5153 Acc: 0.7415\n",
      "Epoch 008 | Train Loss: 0.4768 Acc: 0.7796 | Val Loss: 0.4699 Acc: 0.7766\n",
      "Epoch 009 | Train Loss: 0.4531 Acc: 0.7868 | Val Loss: 0.4484 Acc: 0.7820\n",
      "Epoch 010 | Train Loss: 0.4355 Acc: 0.7944 | Val Loss: 0.4307 Acc: 0.8013\n",
      "Epoch 011 | Train Loss: 0.4111 Acc: 0.8144 | Val Loss: 0.4007 Acc: 0.8140\n",
      "Epoch 012 | Train Loss: 0.3790 Acc: 0.8268 | Val Loss: 0.3888 Acc: 0.8092\n",
      "Epoch 013 | Train Loss: 0.3574 Acc: 0.8431 | Val Loss: 0.3958 Acc: 0.8207\n",
      "Epoch 014 | Train Loss: 0.3289 Acc: 0.8558 | Val Loss: 0.3316 Acc: 0.8502\n",
      "Epoch 015 | Train Loss: 0.3100 Acc: 0.8652 | Val Loss: 0.3237 Acc: 0.8484\n",
      "Epoch 016 | Train Loss: 0.2784 Acc: 0.8842 | Val Loss: 0.2941 Acc: 0.8678\n",
      "Epoch 017 | Train Loss: 0.2671 Acc: 0.8914 | Val Loss: 0.3147 Acc: 0.8720\n",
      "Epoch 018 | Train Loss: 0.2459 Acc: 0.8996 | Val Loss: 0.2771 Acc: 0.8871\n",
      "Epoch 019 | Train Loss: 0.2332 Acc: 0.9088 | Val Loss: 0.3041 Acc: 0.8816\n",
      "Epoch 020 | Train Loss: 0.2173 Acc: 0.9127 | Val Loss: 0.2529 Acc: 0.8992\n",
      "Epoch 021 | Train Loss: 0.2132 Acc: 0.9164 | Val Loss: 0.2285 Acc: 0.9004\n",
      "Epoch 022 | Train Loss: 0.1879 Acc: 0.9266 | Val Loss: 0.2392 Acc: 0.9058\n",
      "Epoch 023 | Train Loss: 0.1906 Acc: 0.9244 | Val Loss: 0.2170 Acc: 0.9203\n",
      "Epoch 024 | Train Loss: 0.1688 Acc: 0.9334 | Val Loss: 0.2410 Acc: 0.9070\n",
      "Epoch 025 | Train Loss: 0.1777 Acc: 0.9301 | Val Loss: 0.2569 Acc: 0.9010\n",
      "Epoch 026 | Train Loss: 0.1566 Acc: 0.9373 | Val Loss: 0.1981 Acc: 0.9245\n",
      "Epoch 027 | Train Loss: 0.1412 Acc: 0.9453 | Val Loss: 0.2269 Acc: 0.9130\n",
      "Epoch 028 | Train Loss: 0.1327 Acc: 0.9465 | Val Loss: 0.1960 Acc: 0.9203\n",
      "Epoch 029 | Train Loss: 0.1325 Acc: 0.9462 | Val Loss: 0.2022 Acc: 0.9088\n",
      "Epoch 030 | Train Loss: 0.1347 Acc: 0.9493 | Val Loss: 0.2177 Acc: 0.9118\n",
      "Epoch 031 | Train Loss: 0.1175 Acc: 0.9562 | Val Loss: 0.1880 Acc: 0.9263\n",
      "Epoch 032 | Train Loss: 0.1187 Acc: 0.9533 | Val Loss: 0.2110 Acc: 0.9239\n",
      "Epoch 033 | Train Loss: 0.1213 Acc: 0.9547 | Val Loss: 0.1741 Acc: 0.9360\n",
      "Epoch 034 | Train Loss: 0.1106 Acc: 0.9530 | Val Loss: 0.1937 Acc: 0.9324\n",
      "Epoch 035 | Train Loss: 0.1048 Acc: 0.9598 | Val Loss: 0.1843 Acc: 0.9263\n",
      "Epoch 036 | Train Loss: 0.1065 Acc: 0.9610 | Val Loss: 0.1620 Acc: 0.9426\n",
      "Epoch 037 | Train Loss: 0.0916 Acc: 0.9684 | Val Loss: 0.1579 Acc: 0.9414\n",
      "Epoch 038 | Train Loss: 0.0997 Acc: 0.9636 | Val Loss: 0.1725 Acc: 0.9378\n",
      "Epoch 039 | Train Loss: 0.0915 Acc: 0.9644 | Val Loss: 0.1635 Acc: 0.9420\n",
      "Epoch 040 | Train Loss: 0.0936 Acc: 0.9662 | Val Loss: 0.1734 Acc: 0.9426\n",
      "Epoch 041 | Train Loss: 0.0812 Acc: 0.9700 | Val Loss: 0.1837 Acc: 0.9366\n",
      "Epoch 042 | Train Loss: 0.0845 Acc: 0.9687 | Val Loss: 0.1512 Acc: 0.9414\n",
      "Epoch 043 | Train Loss: 0.0854 Acc: 0.9678 | Val Loss: 0.1845 Acc: 0.9396\n",
      "Epoch 044 | Train Loss: 0.0821 Acc: 0.9706 | Val Loss: 0.1645 Acc: 0.9342\n",
      "Epoch 045 | Train Loss: 0.0715 Acc: 0.9751 | Val Loss: 0.1700 Acc: 0.9324\n",
      "Epoch 046 | Train Loss: 0.0827 Acc: 0.9680 | Val Loss: 0.1686 Acc: 0.9396\n",
      "Epoch 047 | Train Loss: 0.0863 Acc: 0.9690 | Val Loss: 0.1798 Acc: 0.9372\n",
      "Epoch 048 | Train Loss: 0.0674 Acc: 0.9778 | Val Loss: 0.1441 Acc: 0.9487\n",
      "Epoch 049 | Train Loss: 0.0772 Acc: 0.9737 | Val Loss: 0.1498 Acc: 0.9469\n",
      "Epoch 050 | Train Loss: 0.0812 Acc: 0.9704 | Val Loss: 0.1944 Acc: 0.9300\n",
      "Epoch 051 | Train Loss: 0.0619 Acc: 0.9778 | Val Loss: 0.1793 Acc: 0.9390\n",
      "Epoch 052 | Train Loss: 0.0940 Acc: 0.9639 | Val Loss: 0.1400 Acc: 0.9469\n",
      "Epoch 053 | Train Loss: 0.0615 Acc: 0.9760 | Val Loss: 0.1549 Acc: 0.9432\n",
      "Epoch 054 | Train Loss: 0.0670 Acc: 0.9760 | Val Loss: 0.1431 Acc: 0.9511\n",
      "Epoch 055 | Train Loss: 0.0605 Acc: 0.9770 | Val Loss: 0.1607 Acc: 0.9457\n",
      "Epoch 056 | Train Loss: 0.0627 Acc: 0.9760 | Val Loss: 0.1897 Acc: 0.9378\n",
      "Epoch 057 | Train Loss: 0.0617 Acc: 0.9784 | Val Loss: 0.1660 Acc: 0.9450\n",
      "Epoch 058 | Train Loss: 0.0580 Acc: 0.9767 | Val Loss: 0.1529 Acc: 0.9505\n",
      "Epoch 059 | Train Loss: 0.0654 Acc: 0.9775 | Val Loss: 0.1796 Acc: 0.9360\n",
      "Epoch 060 | Train Loss: 0.0621 Acc: 0.9766 | Val Loss: 0.1856 Acc: 0.9360\n",
      "Epoch 001 | Train Loss: 0.6882 Acc: 0.5514 | Val Loss: 0.6835 Acc: 0.5713\n",
      "Epoch 002 | Train Loss: 0.6795 Acc: 0.5872 | Val Loss: 0.6777 Acc: 0.5912\n",
      "Epoch 003 | Train Loss: 0.6760 Acc: 0.5883 | Val Loss: 0.6757 Acc: 0.5918\n",
      "Epoch 004 | Train Loss: 0.6748 Acc: 0.5910 | Val Loss: 0.6741 Acc: 0.5936\n",
      "Epoch 005 | Train Loss: 0.6714 Acc: 0.6005 | Val Loss: 0.6713 Acc: 0.5900\n",
      "Epoch 006 | Train Loss: 0.6651 Acc: 0.6056 | Val Loss: 0.6652 Acc: 0.5954\n",
      "Epoch 007 | Train Loss: 0.6525 Acc: 0.6210 | Val Loss: 0.6407 Acc: 0.6304\n",
      "Epoch 008 | Train Loss: 0.6294 Acc: 0.6577 | Val Loss: 0.6110 Acc: 0.6751\n",
      "Epoch 009 | Train Loss: 0.6164 Acc: 0.6701 | Val Loss: 0.6077 Acc: 0.6781\n",
      "Epoch 010 | Train Loss: 0.6081 Acc: 0.6814 | Val Loss: 0.6012 Acc: 0.6878\n",
      "Epoch 011 | Train Loss: 0.6054 Acc: 0.6841 | Val Loss: 0.5992 Acc: 0.6938\n",
      "Epoch 012 | Train Loss: 0.6027 Acc: 0.6864 | Val Loss: 0.5944 Acc: 0.6950\n",
      "Epoch 013 | Train Loss: 0.5971 Acc: 0.6926 | Val Loss: 0.5944 Acc: 0.6987\n",
      "Epoch 014 | Train Loss: 0.5954 Acc: 0.6899 | Val Loss: 0.5873 Acc: 0.6999\n",
      "Epoch 015 | Train Loss: 0.5888 Acc: 0.7015 | Val Loss: 0.5875 Acc: 0.6969\n",
      "Epoch 016 | Train Loss: 0.5827 Acc: 0.7066 | Val Loss: 0.5798 Acc: 0.7077\n",
      "Epoch 017 | Train Loss: 0.5753 Acc: 0.7106 | Val Loss: 0.5839 Acc: 0.7041\n",
      "Epoch 018 | Train Loss: 0.5773 Acc: 0.7133 | Val Loss: 0.5881 Acc: 0.6932\n",
      "Epoch 019 | Train Loss: 0.5724 Acc: 0.7142 | Val Loss: 0.5695 Acc: 0.7186\n",
      "Epoch 020 | Train Loss: 0.5707 Acc: 0.7201 | Val Loss: 0.5908 Acc: 0.6914\n",
      "Epoch 021 | Train Loss: 0.5683 Acc: 0.7175 | Val Loss: 0.5719 Acc: 0.7126\n",
      "Epoch 022 | Train Loss: 0.5621 Acc: 0.7152 | Val Loss: 0.5637 Acc: 0.7180\n",
      "Epoch 023 | Train Loss: 0.5563 Acc: 0.7258 | Val Loss: 0.5752 Acc: 0.7029\n",
      "Epoch 024 | Train Loss: 0.5551 Acc: 0.7312 | Val Loss: 0.5591 Acc: 0.7162\n",
      "Epoch 025 | Train Loss: 0.5514 Acc: 0.7288 | Val Loss: 0.5572 Acc: 0.7186\n",
      "Epoch 026 | Train Loss: 0.5467 Acc: 0.7311 | Val Loss: 0.5633 Acc: 0.7174\n",
      "Epoch 027 | Train Loss: 0.5524 Acc: 0.7276 | Val Loss: 0.5544 Acc: 0.7216\n",
      "Epoch 028 | Train Loss: 0.5451 Acc: 0.7362 | Val Loss: 0.5597 Acc: 0.7198\n",
      "Epoch 029 | Train Loss: 0.5444 Acc: 0.7329 | Val Loss: 0.5553 Acc: 0.7120\n",
      "Epoch 030 | Train Loss: 0.5379 Acc: 0.7389 | Val Loss: 0.5536 Acc: 0.7277\n",
      "Epoch 031 | Train Loss: 0.5382 Acc: 0.7343 | Val Loss: 0.5474 Acc: 0.7222\n",
      "Epoch 032 | Train Loss: 0.5272 Acc: 0.7454 | Val Loss: 0.5444 Acc: 0.7277\n",
      "Epoch 033 | Train Loss: 0.5316 Acc: 0.7412 | Val Loss: 0.5411 Acc: 0.7283\n",
      "Epoch 034 | Train Loss: 0.5258 Acc: 0.7482 | Val Loss: 0.5431 Acc: 0.7198\n",
      "Epoch 035 | Train Loss: 0.5185 Acc: 0.7501 | Val Loss: 0.5402 Acc: 0.7295\n",
      "Epoch 036 | Train Loss: 0.5152 Acc: 0.7506 | Val Loss: 0.5406 Acc: 0.7301\n",
      "Epoch 037 | Train Loss: 0.5213 Acc: 0.7462 | Val Loss: 0.5382 Acc: 0.7301\n",
      "Epoch 038 | Train Loss: 0.5166 Acc: 0.7472 | Val Loss: 0.5261 Acc: 0.7295\n",
      "Epoch 039 | Train Loss: 0.5031 Acc: 0.7584 | Val Loss: 0.5226 Acc: 0.7373\n",
      "Epoch 040 | Train Loss: 0.5094 Acc: 0.7527 | Val Loss: 0.5266 Acc: 0.7355\n",
      "Epoch 041 | Train Loss: 0.4989 Acc: 0.7604 | Val Loss: 0.5196 Acc: 0.7319\n",
      "Epoch 042 | Train Loss: 0.4944 Acc: 0.7625 | Val Loss: 0.5242 Acc: 0.7409\n",
      "Epoch 043 | Train Loss: 0.4995 Acc: 0.7626 | Val Loss: 0.5271 Acc: 0.7307\n",
      "Epoch 044 | Train Loss: 0.4947 Acc: 0.7652 | Val Loss: 0.5075 Acc: 0.7440\n",
      "Epoch 045 | Train Loss: 0.4868 Acc: 0.7690 | Val Loss: 0.5055 Acc: 0.7415\n",
      "Epoch 046 | Train Loss: 0.4808 Acc: 0.7734 | Val Loss: 0.5138 Acc: 0.7343\n",
      "Epoch 047 | Train Loss: 0.4827 Acc: 0.7735 | Val Loss: 0.4934 Acc: 0.7524\n",
      "Epoch 048 | Train Loss: 0.4772 Acc: 0.7759 | Val Loss: 0.4943 Acc: 0.7518\n",
      "Epoch 049 | Train Loss: 0.4731 Acc: 0.7720 | Val Loss: 0.4857 Acc: 0.7512\n",
      "Epoch 050 | Train Loss: 0.4630 Acc: 0.7823 | Val Loss: 0.4995 Acc: 0.7458\n",
      "Epoch 051 | Train Loss: 0.4741 Acc: 0.7738 | Val Loss: 0.4773 Acc: 0.7675\n",
      "Epoch 052 | Train Loss: 0.4615 Acc: 0.7856 | Val Loss: 0.4755 Acc: 0.7681\n",
      "Epoch 053 | Train Loss: 0.4580 Acc: 0.7845 | Val Loss: 0.4704 Acc: 0.7609\n",
      "Epoch 054 | Train Loss: 0.4587 Acc: 0.7833 | Val Loss: 0.4717 Acc: 0.7633\n",
      "Epoch 055 | Train Loss: 0.4588 Acc: 0.7830 | Val Loss: 0.4731 Acc: 0.7651\n",
      "Epoch 056 | Train Loss: 0.4448 Acc: 0.7898 | Val Loss: 0.4701 Acc: 0.7621\n",
      "Epoch 057 | Train Loss: 0.4457 Acc: 0.7965 | Val Loss: 0.4556 Acc: 0.7742\n",
      "Epoch 058 | Train Loss: 0.4395 Acc: 0.7983 | Val Loss: 0.4736 Acc: 0.7669\n",
      "Epoch 059 | Train Loss: 0.4403 Acc: 0.7962 | Val Loss: 0.4520 Acc: 0.7832\n",
      "Epoch 060 | Train Loss: 0.4383 Acc: 0.7953 | Val Loss: 0.4561 Acc: 0.7742\n",
      "Epoch 001 | Train Loss: 0.6812 Acc: 0.5766 | Val Loss: 0.6862 Acc: 0.5586\n",
      "Epoch 002 | Train Loss: 0.6806 Acc: 0.5780 | Val Loss: 0.6754 Acc: 0.5924\n",
      "Epoch 003 | Train Loss: 0.6692 Acc: 0.5961 | Val Loss: 0.6657 Acc: 0.5942\n",
      "Epoch 004 | Train Loss: 0.6519 Acc: 0.6228 | Val Loss: 0.6228 Acc: 0.6679\n",
      "Epoch 005 | Train Loss: 0.6035 Acc: 0.6927 | Val Loss: 0.6467 Acc: 0.6504\n",
      "Epoch 006 | Train Loss: 0.5705 Acc: 0.7116 | Val Loss: 0.5827 Acc: 0.6884\n",
      "Epoch 007 | Train Loss: 0.5494 Acc: 0.7300 | Val Loss: 0.5680 Acc: 0.7180\n",
      "Epoch 008 | Train Loss: 0.5342 Acc: 0.7355 | Val Loss: 0.5416 Acc: 0.7246\n",
      "Epoch 009 | Train Loss: 0.5170 Acc: 0.7515 | Val Loss: 0.5201 Acc: 0.7391\n",
      "Epoch 010 | Train Loss: 0.4931 Acc: 0.7569 | Val Loss: 0.5100 Acc: 0.7421\n",
      "Epoch 011 | Train Loss: 0.4788 Acc: 0.7684 | Val Loss: 0.5096 Acc: 0.7566\n",
      "Epoch 012 | Train Loss: 0.4544 Acc: 0.7854 | Val Loss: 0.4674 Acc: 0.7705\n",
      "Epoch 013 | Train Loss: 0.4355 Acc: 0.7954 | Val Loss: 0.4679 Acc: 0.7790\n",
      "Epoch 014 | Train Loss: 0.4196 Acc: 0.8069 | Val Loss: 0.4009 Acc: 0.8104\n",
      "Epoch 015 | Train Loss: 0.3946 Acc: 0.8188 | Val Loss: 0.3841 Acc: 0.8273\n",
      "Epoch 016 | Train Loss: 0.3846 Acc: 0.8271 | Val Loss: 0.3893 Acc: 0.8158\n",
      "Epoch 017 | Train Loss: 0.3635 Acc: 0.8380 | Val Loss: 0.3634 Acc: 0.8339\n",
      "Epoch 018 | Train Loss: 0.3440 Acc: 0.8458 | Val Loss: 0.3754 Acc: 0.8303\n",
      "Epoch 019 | Train Loss: 0.3267 Acc: 0.8579 | Val Loss: 0.3445 Acc: 0.8508\n",
      "Epoch 020 | Train Loss: 0.3162 Acc: 0.8626 | Val Loss: 0.3227 Acc: 0.8599\n",
      "Epoch 021 | Train Loss: 0.3028 Acc: 0.8726 | Val Loss: 0.3659 Acc: 0.8394\n",
      "Epoch 022 | Train Loss: 0.2924 Acc: 0.8762 | Val Loss: 0.3369 Acc: 0.8611\n",
      "Epoch 023 | Train Loss: 0.2680 Acc: 0.8869 | Val Loss: 0.2923 Acc: 0.8780\n",
      "Epoch 024 | Train Loss: 0.2638 Acc: 0.8955 | Val Loss: 0.2869 Acc: 0.8702\n",
      "Epoch 025 | Train Loss: 0.2548 Acc: 0.8936 | Val Loss: 0.2700 Acc: 0.8895\n",
      "Epoch 026 | Train Loss: 0.2346 Acc: 0.9056 | Val Loss: 0.2645 Acc: 0.8931\n",
      "Epoch 027 | Train Loss: 0.2308 Acc: 0.9105 | Val Loss: 0.2395 Acc: 0.9034\n",
      "Epoch 028 | Train Loss: 0.2224 Acc: 0.9130 | Val Loss: 0.2444 Acc: 0.8973\n",
      "Epoch 029 | Train Loss: 0.2054 Acc: 0.9189 | Val Loss: 0.2177 Acc: 0.9106\n",
      "Epoch 030 | Train Loss: 0.1973 Acc: 0.9216 | Val Loss: 0.2601 Acc: 0.8967\n",
      "Epoch 031 | Train Loss: 0.1892 Acc: 0.9275 | Val Loss: 0.2374 Acc: 0.9004\n",
      "Epoch 032 | Train Loss: 0.1721 Acc: 0.9305 | Val Loss: 0.2310 Acc: 0.9034\n",
      "Epoch 033 | Train Loss: 0.1864 Acc: 0.9260 | Val Loss: 0.2027 Acc: 0.9167\n",
      "Epoch 034 | Train Loss: 0.1619 Acc: 0.9351 | Val Loss: 0.2558 Acc: 0.8973\n",
      "Epoch 035 | Train Loss: 0.1625 Acc: 0.9384 | Val Loss: 0.2009 Acc: 0.9221\n",
      "Epoch 036 | Train Loss: 0.1553 Acc: 0.9387 | Val Loss: 0.2107 Acc: 0.9197\n",
      "Epoch 037 | Train Loss: 0.1432 Acc: 0.9441 | Val Loss: 0.2728 Acc: 0.9118\n",
      "Epoch 038 | Train Loss: 0.1454 Acc: 0.9452 | Val Loss: 0.1839 Acc: 0.9269\n",
      "Epoch 039 | Train Loss: 0.1491 Acc: 0.9455 | Val Loss: 0.1781 Acc: 0.9300\n",
      "Epoch 040 | Train Loss: 0.1318 Acc: 0.9500 | Val Loss: 0.2059 Acc: 0.9221\n",
      "Epoch 041 | Train Loss: 0.1284 Acc: 0.9502 | Val Loss: 0.1833 Acc: 0.9281\n",
      "Epoch 042 | Train Loss: 0.1287 Acc: 0.9497 | Val Loss: 0.1839 Acc: 0.9312\n",
      "Epoch 043 | Train Loss: 0.1242 Acc: 0.9532 | Val Loss: 0.1714 Acc: 0.9287\n",
      "Epoch 044 | Train Loss: 0.1190 Acc: 0.9547 | Val Loss: 0.1973 Acc: 0.9257\n",
      "Epoch 045 | Train Loss: 0.1181 Acc: 0.9549 | Val Loss: 0.1611 Acc: 0.9414\n",
      "Epoch 046 | Train Loss: 0.1125 Acc: 0.9585 | Val Loss: 0.1860 Acc: 0.9257\n",
      "Epoch 047 | Train Loss: 0.1199 Acc: 0.9538 | Val Loss: 0.1616 Acc: 0.9366\n",
      "Epoch 048 | Train Loss: 0.1135 Acc: 0.9579 | Val Loss: 0.1644 Acc: 0.9330\n",
      "Epoch 049 | Train Loss: 0.0971 Acc: 0.9624 | Val Loss: 0.1775 Acc: 0.9366\n",
      "Epoch 050 | Train Loss: 0.1029 Acc: 0.9624 | Val Loss: 0.1566 Acc: 0.9426\n",
      "Epoch 051 | Train Loss: 0.0949 Acc: 0.9648 | Val Loss: 0.1695 Acc: 0.9348\n",
      "Epoch 052 | Train Loss: 0.1130 Acc: 0.9565 | Val Loss: 0.1712 Acc: 0.9293\n",
      "Epoch 053 | Train Loss: 0.0983 Acc: 0.9623 | Val Loss: 0.1650 Acc: 0.9390\n",
      "Epoch 054 | Train Loss: 0.0961 Acc: 0.9609 | Val Loss: 0.1626 Acc: 0.9342\n",
      "Epoch 055 | Train Loss: 0.0943 Acc: 0.9672 | Val Loss: 0.1890 Acc: 0.9330\n",
      "Epoch 056 | Train Loss: 0.1041 Acc: 0.9629 | Val Loss: 0.1746 Acc: 0.9336\n",
      "Epoch 057 | Train Loss: 0.0953 Acc: 0.9636 | Val Loss: 0.1863 Acc: 0.9263\n",
      "Epoch 058 | Train Loss: 0.0843 Acc: 0.9707 | Val Loss: 0.1718 Acc: 0.9438\n",
      "Epoch 059 | Train Loss: 0.0801 Acc: 0.9709 | Val Loss: 0.1634 Acc: 0.9402\n",
      "Epoch 060 | Train Loss: 0.0849 Acc: 0.9703 | Val Loss: 0.1613 Acc: 0.9426\n",
      "Early stopping triggered.\n",
      "Epoch 001 | Train Loss: 0.6778 Acc: 0.5822 | Val Loss: 0.6707 Acc: 0.5936\n",
      "Epoch 002 | Train Loss: 0.6617 Acc: 0.6144 | Val Loss: 0.6231 Acc: 0.6679\n",
      "Epoch 003 | Train Loss: 0.6109 Acc: 0.6784 | Val Loss: 0.6115 Acc: 0.6944\n",
      "Epoch 004 | Train Loss: 0.5823 Acc: 0.7077 | Val Loss: 0.5720 Acc: 0.7077\n",
      "Epoch 005 | Train Loss: 0.5611 Acc: 0.7231 | Val Loss: 0.5569 Acc: 0.7204\n",
      "Epoch 006 | Train Loss: 0.5470 Acc: 0.7291 | Val Loss: 0.5735 Acc: 0.7029\n",
      "Epoch 007 | Train Loss: 0.5309 Acc: 0.7421 | Val Loss: 0.5356 Acc: 0.7295\n",
      "Epoch 008 | Train Loss: 0.5189 Acc: 0.7530 | Val Loss: 0.5385 Acc: 0.7349\n",
      "Epoch 009 | Train Loss: 0.5076 Acc: 0.7581 | Val Loss: 0.5355 Acc: 0.7258\n",
      "Epoch 010 | Train Loss: 0.4860 Acc: 0.7681 | Val Loss: 0.5082 Acc: 0.7428\n",
      "Epoch 011 | Train Loss: 0.4687 Acc: 0.7838 | Val Loss: 0.4782 Acc: 0.7711\n",
      "Epoch 012 | Train Loss: 0.4496 Acc: 0.7906 | Val Loss: 0.4503 Acc: 0.7850\n",
      "Epoch 013 | Train Loss: 0.4290 Acc: 0.8048 | Val Loss: 0.4357 Acc: 0.7971\n",
      "Epoch 014 | Train Loss: 0.4093 Acc: 0.8138 | Val Loss: 0.4272 Acc: 0.8001\n",
      "Epoch 015 | Train Loss: 0.3991 Acc: 0.8170 | Val Loss: 0.3710 Acc: 0.8394\n",
      "Epoch 016 | Train Loss: 0.3590 Acc: 0.8409 | Val Loss: 0.3494 Acc: 0.8490\n",
      "Epoch 017 | Train Loss: 0.3352 Acc: 0.8523 | Val Loss: 0.3441 Acc: 0.8539\n",
      "Epoch 018 | Train Loss: 0.3399 Acc: 0.8546 | Val Loss: 0.3746 Acc: 0.8237\n",
      "Epoch 019 | Train Loss: 0.3131 Acc: 0.8659 | Val Loss: 0.3178 Acc: 0.8593\n",
      "Epoch 020 | Train Loss: 0.2954 Acc: 0.8730 | Val Loss: 0.2848 Acc: 0.8774\n",
      "Epoch 021 | Train Loss: 0.2868 Acc: 0.8797 | Val Loss: 0.2818 Acc: 0.8738\n",
      "Epoch 022 | Train Loss: 0.2703 Acc: 0.8862 | Val Loss: 0.2560 Acc: 0.8973\n",
      "Epoch 023 | Train Loss: 0.2511 Acc: 0.8942 | Val Loss: 0.3103 Acc: 0.8671\n",
      "Epoch 024 | Train Loss: 0.2551 Acc: 0.8973 | Val Loss: 0.2982 Acc: 0.8690\n",
      "Epoch 025 | Train Loss: 0.2276 Acc: 0.9047 | Val Loss: 0.3147 Acc: 0.8732\n",
      "Epoch 026 | Train Loss: 0.2283 Acc: 0.9085 | Val Loss: 0.2594 Acc: 0.8895\n",
      "Epoch 027 | Train Loss: 0.2182 Acc: 0.9144 | Val Loss: 0.2374 Acc: 0.9070\n",
      "Epoch 028 | Train Loss: 0.2093 Acc: 0.9136 | Val Loss: 0.2383 Acc: 0.9070\n",
      "Epoch 029 | Train Loss: 0.1939 Acc: 0.9234 | Val Loss: 0.2586 Acc: 0.9010\n",
      "Epoch 030 | Train Loss: 0.2001 Acc: 0.9218 | Val Loss: 0.2265 Acc: 0.9136\n",
      "Epoch 031 | Train Loss: 0.1883 Acc: 0.9230 | Val Loss: 0.2561 Acc: 0.9010\n",
      "Epoch 032 | Train Loss: 0.1766 Acc: 0.9253 | Val Loss: 0.2483 Acc: 0.9034\n",
      "Epoch 033 | Train Loss: 0.1719 Acc: 0.9299 | Val Loss: 0.2045 Acc: 0.9269\n",
      "Epoch 034 | Train Loss: 0.1692 Acc: 0.9333 | Val Loss: 0.2309 Acc: 0.8913\n",
      "Epoch 035 | Train Loss: 0.1577 Acc: 0.9369 | Val Loss: 0.2260 Acc: 0.9034\n",
      "Epoch 036 | Train Loss: 0.1601 Acc: 0.9393 | Val Loss: 0.2309 Acc: 0.9136\n",
      "Epoch 037 | Train Loss: 0.1535 Acc: 0.9385 | Val Loss: 0.2084 Acc: 0.9167\n",
      "Epoch 038 | Train Loss: 0.1580 Acc: 0.9398 | Val Loss: 0.1906 Acc: 0.9275\n",
      "Epoch 039 | Train Loss: 0.1546 Acc: 0.9381 | Val Loss: 0.2093 Acc: 0.9203\n",
      "Epoch 040 | Train Loss: 0.1421 Acc: 0.9473 | Val Loss: 0.1910 Acc: 0.9251\n",
      "Epoch 041 | Train Loss: 0.1439 Acc: 0.9455 | Val Loss: 0.1903 Acc: 0.9312\n",
      "Epoch 042 | Train Loss: 0.1335 Acc: 0.9506 | Val Loss: 0.2050 Acc: 0.9130\n",
      "Epoch 043 | Train Loss: 0.1293 Acc: 0.9472 | Val Loss: 0.1861 Acc: 0.9293\n",
      "Epoch 044 | Train Loss: 0.1286 Acc: 0.9493 | Val Loss: 0.2154 Acc: 0.9185\n",
      "Epoch 045 | Train Loss: 0.1217 Acc: 0.9518 | Val Loss: 0.1939 Acc: 0.9269\n",
      "Epoch 046 | Train Loss: 0.1218 Acc: 0.9546 | Val Loss: 0.1706 Acc: 0.9342\n",
      "Epoch 047 | Train Loss: 0.1167 Acc: 0.9553 | Val Loss: 0.1765 Acc: 0.9324\n",
      "Epoch 048 | Train Loss: 0.1160 Acc: 0.9567 | Val Loss: 0.1915 Acc: 0.9287\n",
      "Epoch 049 | Train Loss: 0.1111 Acc: 0.9579 | Val Loss: 0.1793 Acc: 0.9354\n",
      "Epoch 050 | Train Loss: 0.1072 Acc: 0.9582 | Val Loss: 0.1864 Acc: 0.9269\n",
      "Epoch 051 | Train Loss: 0.1066 Acc: 0.9595 | Val Loss: 0.1943 Acc: 0.9275\n",
      "Epoch 052 | Train Loss: 0.1150 Acc: 0.9550 | Val Loss: 0.1971 Acc: 0.9173\n",
      "Epoch 053 | Train Loss: 0.1147 Acc: 0.9568 | Val Loss: 0.1655 Acc: 0.9306\n",
      "Epoch 054 | Train Loss: 0.1052 Acc: 0.9600 | Val Loss: 0.1799 Acc: 0.9360\n",
      "Epoch 055 | Train Loss: 0.1041 Acc: 0.9588 | Val Loss: 0.1688 Acc: 0.9348\n",
      "Epoch 056 | Train Loss: 0.0995 Acc: 0.9615 | Val Loss: 0.1883 Acc: 0.9263\n",
      "Epoch 057 | Train Loss: 0.1010 Acc: 0.9606 | Val Loss: 0.1612 Acc: 0.9372\n",
      "Epoch 058 | Train Loss: 0.0933 Acc: 0.9632 | Val Loss: 0.2259 Acc: 0.9155\n",
      "Epoch 059 | Train Loss: 0.0959 Acc: 0.9620 | Val Loss: 0.1921 Acc: 0.9275\n",
      "Epoch 060 | Train Loss: 0.0973 Acc: 0.9635 | Val Loss: 0.1808 Acc: 0.9263\n",
      "Epoch 001 | Train Loss: 0.6830 Acc: 0.5727 | Val Loss: 0.6765 Acc: 0.5894\n",
      "Epoch 002 | Train Loss: 0.6754 Acc: 0.5904 | Val Loss: 0.6765 Acc: 0.5803\n",
      "Epoch 003 | Train Loss: 0.6398 Acc: 0.6428 | Val Loss: 0.6039 Acc: 0.6812\n",
      "Epoch 004 | Train Loss: 0.5721 Acc: 0.7160 | Val Loss: 0.5561 Acc: 0.7186\n",
      "Epoch 005 | Train Loss: 0.5265 Acc: 0.7498 | Val Loss: 0.5254 Acc: 0.7367\n",
      "Epoch 006 | Train Loss: 0.4999 Acc: 0.7637 | Val Loss: 0.4816 Acc: 0.7627\n",
      "Epoch 007 | Train Loss: 0.4580 Acc: 0.7888 | Val Loss: 0.4530 Acc: 0.7953\n",
      "Epoch 008 | Train Loss: 0.4280 Acc: 0.8101 | Val Loss: 0.4599 Acc: 0.7808\n",
      "Epoch 009 | Train Loss: 0.4084 Acc: 0.8155 | Val Loss: 0.4217 Acc: 0.8056\n",
      "Epoch 010 | Train Loss: 0.3702 Acc: 0.8398 | Val Loss: 0.3501 Acc: 0.8454\n",
      "Epoch 011 | Train Loss: 0.3355 Acc: 0.8566 | Val Loss: 0.3689 Acc: 0.8418\n",
      "Epoch 012 | Train Loss: 0.3183 Acc: 0.8650 | Val Loss: 0.3026 Acc: 0.8611\n",
      "Epoch 013 | Train Loss: 0.2866 Acc: 0.8792 | Val Loss: 0.3149 Acc: 0.8581\n",
      "Epoch 014 | Train Loss: 0.2567 Acc: 0.8951 | Val Loss: 0.3016 Acc: 0.8671\n",
      "Epoch 015 | Train Loss: 0.2454 Acc: 0.8973 | Val Loss: 0.2485 Acc: 0.8961\n",
      "Epoch 016 | Train Loss: 0.2223 Acc: 0.9109 | Val Loss: 0.2396 Acc: 0.8979\n",
      "Epoch 017 | Train Loss: 0.2021 Acc: 0.9224 | Val Loss: 0.2211 Acc: 0.9112\n",
      "Epoch 018 | Train Loss: 0.1910 Acc: 0.9241 | Val Loss: 0.2108 Acc: 0.9143\n",
      "Epoch 019 | Train Loss: 0.1744 Acc: 0.9307 | Val Loss: 0.2092 Acc: 0.9173\n",
      "Epoch 020 | Train Loss: 0.1653 Acc: 0.9340 | Val Loss: 0.2035 Acc: 0.9161\n",
      "Epoch 021 | Train Loss: 0.1532 Acc: 0.9405 | Val Loss: 0.2019 Acc: 0.9191\n",
      "Epoch 022 | Train Loss: 0.1524 Acc: 0.9396 | Val Loss: 0.1813 Acc: 0.9312\n",
      "Epoch 023 | Train Loss: 0.1324 Acc: 0.9488 | Val Loss: 0.2269 Acc: 0.9130\n",
      "Epoch 024 | Train Loss: 0.1299 Acc: 0.9469 | Val Loss: 0.2014 Acc: 0.9300\n",
      "Epoch 025 | Train Loss: 0.1318 Acc: 0.9481 | Val Loss: 0.1864 Acc: 0.9257\n",
      "Epoch 026 | Train Loss: 0.1198 Acc: 0.9550 | Val Loss: 0.1859 Acc: 0.9306\n",
      "Epoch 027 | Train Loss: 0.1158 Acc: 0.9580 | Val Loss: 0.1764 Acc: 0.9342\n",
      "Epoch 028 | Train Loss: 0.1111 Acc: 0.9576 | Val Loss: 0.1856 Acc: 0.9408\n",
      "Epoch 029 | Train Loss: 0.0983 Acc: 0.9644 | Val Loss: 0.1635 Acc: 0.9402\n",
      "Epoch 030 | Train Loss: 0.0937 Acc: 0.9668 | Val Loss: 0.1681 Acc: 0.9444\n",
      "Epoch 031 | Train Loss: 0.0853 Acc: 0.9689 | Val Loss: 0.1873 Acc: 0.9366\n",
      "Epoch 032 | Train Loss: 0.0765 Acc: 0.9722 | Val Loss: 0.1943 Acc: 0.9318\n",
      "Epoch 033 | Train Loss: 0.0827 Acc: 0.9692 | Val Loss: 0.1616 Acc: 0.9390\n",
      "Epoch 034 | Train Loss: 0.0834 Acc: 0.9709 | Val Loss: 0.1855 Acc: 0.9330\n",
      "Epoch 035 | Train Loss: 0.0863 Acc: 0.9659 | Val Loss: 0.1697 Acc: 0.9384\n",
      "Epoch 036 | Train Loss: 0.0720 Acc: 0.9715 | Val Loss: 0.1856 Acc: 0.9378\n",
      "Epoch 037 | Train Loss: 0.0741 Acc: 0.9736 | Val Loss: 0.1763 Acc: 0.9372\n",
      "Epoch 038 | Train Loss: 0.0656 Acc: 0.9725 | Val Loss: 0.1735 Acc: 0.9414\n",
      "Epoch 039 | Train Loss: 0.0715 Acc: 0.9748 | Val Loss: 0.1717 Acc: 0.9336\n",
      "Epoch 040 | Train Loss: 0.0671 Acc: 0.9752 | Val Loss: 0.1553 Acc: 0.9469\n",
      "Epoch 041 | Train Loss: 0.0691 Acc: 0.9743 | Val Loss: 0.1925 Acc: 0.9330\n",
      "Epoch 042 | Train Loss: 0.0647 Acc: 0.9748 | Val Loss: 0.1753 Acc: 0.9336\n",
      "Epoch 043 | Train Loss: 0.0669 Acc: 0.9748 | Val Loss: 0.1642 Acc: 0.9481\n",
      "Epoch 044 | Train Loss: 0.0627 Acc: 0.9780 | Val Loss: 0.1721 Acc: 0.9372\n",
      "Epoch 045 | Train Loss: 0.0652 Acc: 0.9749 | Val Loss: 0.1549 Acc: 0.9444\n",
      "Epoch 046 | Train Loss: 0.0563 Acc: 0.9801 | Val Loss: 0.1589 Acc: 0.9493\n",
      "Epoch 047 | Train Loss: 0.0559 Acc: 0.9780 | Val Loss: 0.1838 Acc: 0.9408\n",
      "Epoch 048 | Train Loss: 0.0556 Acc: 0.9798 | Val Loss: 0.1469 Acc: 0.9517\n",
      "Epoch 049 | Train Loss: 0.0496 Acc: 0.9825 | Val Loss: 0.1987 Acc: 0.9293\n",
      "Epoch 050 | Train Loss: 0.0512 Acc: 0.9793 | Val Loss: 0.1667 Acc: 0.9469\n",
      "Epoch 051 | Train Loss: 0.0555 Acc: 0.9817 | Val Loss: 0.1969 Acc: 0.9372\n",
      "Epoch 052 | Train Loss: 0.0577 Acc: 0.9790 | Val Loss: 0.1836 Acc: 0.9457\n",
      "Epoch 053 | Train Loss: 0.0558 Acc: 0.9793 | Val Loss: 0.1552 Acc: 0.9499\n",
      "Epoch 054 | Train Loss: 0.0683 Acc: 0.9742 | Val Loss: 0.1885 Acc: 0.9342\n",
      "Epoch 055 | Train Loss: 0.0516 Acc: 0.9819 | Val Loss: 0.1680 Acc: 0.9475\n",
      "Epoch 056 | Train Loss: 0.0516 Acc: 0.9810 | Val Loss: 0.1540 Acc: 0.9450\n",
      "Epoch 057 | Train Loss: 0.0538 Acc: 0.9793 | Val Loss: 0.2016 Acc: 0.9366\n",
      "Epoch 058 | Train Loss: 0.0585 Acc: 0.9787 | Val Loss: 0.1332 Acc: 0.9499\n",
      "Epoch 059 | Train Loss: 0.0477 Acc: 0.9819 | Val Loss: 0.1827 Acc: 0.9481\n",
      "Epoch 060 | Train Loss: 0.0481 Acc: 0.9834 | Val Loss: 0.1879 Acc: 0.9348\n",
      "Epoch 001 | Train Loss: 0.6800 Acc: 0.5840 | Val Loss: 0.6710 Acc: 0.5996\n",
      "Epoch 002 | Train Loss: 0.6657 Acc: 0.6027 | Val Loss: 0.6632 Acc: 0.6014\n",
      "Epoch 003 | Train Loss: 0.6607 Acc: 0.6056 | Val Loss: 0.6731 Acc: 0.5737\n",
      "Epoch 004 | Train Loss: 0.6362 Acc: 0.6467 | Val Loss: 0.6134 Acc: 0.6606\n",
      "Epoch 005 | Train Loss: 0.5933 Acc: 0.6961 | Val Loss: 0.5872 Acc: 0.6818\n",
      "Epoch 006 | Train Loss: 0.5662 Acc: 0.7220 | Val Loss: 0.5658 Acc: 0.7228\n",
      "Epoch 007 | Train Loss: 0.5437 Acc: 0.7350 | Val Loss: 0.5421 Acc: 0.7373\n",
      "Epoch 008 | Train Loss: 0.5172 Acc: 0.7516 | Val Loss: 0.5256 Acc: 0.7307\n",
      "Epoch 009 | Train Loss: 0.5083 Acc: 0.7587 | Val Loss: 0.5070 Acc: 0.7585\n",
      "Epoch 010 | Train Loss: 0.4768 Acc: 0.7761 | Val Loss: 0.4691 Acc: 0.7705\n",
      "Epoch 011 | Train Loss: 0.4534 Acc: 0.7854 | Val Loss: 0.4607 Acc: 0.7754\n",
      "Epoch 012 | Train Loss: 0.4432 Acc: 0.7984 | Val Loss: 0.4344 Acc: 0.8092\n",
      "Epoch 013 | Train Loss: 0.4208 Acc: 0.8028 | Val Loss: 0.4403 Acc: 0.8086\n",
      "Epoch 014 | Train Loss: 0.4161 Acc: 0.8079 | Val Loss: 0.4080 Acc: 0.8122\n",
      "Epoch 015 | Train Loss: 0.3847 Acc: 0.8209 | Val Loss: 0.4405 Acc: 0.7784\n",
      "Epoch 016 | Train Loss: 0.3819 Acc: 0.8285 | Val Loss: 0.3930 Acc: 0.8164\n",
      "Epoch 017 | Train Loss: 0.3516 Acc: 0.8421 | Val Loss: 0.3476 Acc: 0.8376\n",
      "Epoch 018 | Train Loss: 0.3430 Acc: 0.8513 | Val Loss: 0.3514 Acc: 0.8442\n",
      "Epoch 019 | Train Loss: 0.3232 Acc: 0.8587 | Val Loss: 0.3313 Acc: 0.8617\n",
      "Epoch 020 | Train Loss: 0.3057 Acc: 0.8701 | Val Loss: 0.3082 Acc: 0.8708\n",
      "Epoch 021 | Train Loss: 0.2957 Acc: 0.8730 | Val Loss: 0.4067 Acc: 0.8249\n",
      "Epoch 022 | Train Loss: 0.2886 Acc: 0.8803 | Val Loss: 0.2932 Acc: 0.8816\n",
      "Epoch 023 | Train Loss: 0.2692 Acc: 0.8857 | Val Loss: 0.2649 Acc: 0.8895\n",
      "Epoch 024 | Train Loss: 0.2578 Acc: 0.8916 | Val Loss: 0.3165 Acc: 0.8696\n",
      "Epoch 025 | Train Loss: 0.2404 Acc: 0.9023 | Val Loss: 0.2720 Acc: 0.8937\n",
      "Epoch 026 | Train Loss: 0.2365 Acc: 0.9058 | Val Loss: 0.2646 Acc: 0.9010\n",
      "Epoch 027 | Train Loss: 0.2195 Acc: 0.9135 | Val Loss: 0.2576 Acc: 0.8937\n",
      "Epoch 028 | Train Loss: 0.2206 Acc: 0.9091 | Val Loss: 0.2732 Acc: 0.8955\n",
      "Epoch 029 | Train Loss: 0.2068 Acc: 0.9153 | Val Loss: 0.2323 Acc: 0.9136\n",
      "Epoch 030 | Train Loss: 0.2027 Acc: 0.9182 | Val Loss: 0.2451 Acc: 0.9052\n",
      "Epoch 031 | Train Loss: 0.1984 Acc: 0.9203 | Val Loss: 0.2543 Acc: 0.8979\n",
      "Epoch 032 | Train Loss: 0.1809 Acc: 0.9287 | Val Loss: 0.2305 Acc: 0.9106\n",
      "Epoch 033 | Train Loss: 0.1738 Acc: 0.9339 | Val Loss: 0.2165 Acc: 0.9185\n",
      "Epoch 034 | Train Loss: 0.1824 Acc: 0.9299 | Val Loss: 0.2013 Acc: 0.9149\n",
      "Epoch 035 | Train Loss: 0.1746 Acc: 0.9330 | Val Loss: 0.2101 Acc: 0.9239\n",
      "Epoch 036 | Train Loss: 0.1636 Acc: 0.9363 | Val Loss: 0.1891 Acc: 0.9300\n",
      "Epoch 037 | Train Loss: 0.1516 Acc: 0.9425 | Val Loss: 0.1917 Acc: 0.9306\n",
      "Epoch 038 | Train Loss: 0.1546 Acc: 0.9429 | Val Loss: 0.2402 Acc: 0.9082\n",
      "Epoch 039 | Train Loss: 0.1571 Acc: 0.9401 | Val Loss: 0.1752 Acc: 0.9318\n",
      "Epoch 040 | Train Loss: 0.1460 Acc: 0.9453 | Val Loss: 0.1836 Acc: 0.9372\n",
      "Epoch 041 | Train Loss: 0.1400 Acc: 0.9499 | Val Loss: 0.2082 Acc: 0.9269\n",
      "Epoch 042 | Train Loss: 0.1356 Acc: 0.9520 | Val Loss: 0.1939 Acc: 0.9293\n",
      "Epoch 043 | Train Loss: 0.1295 Acc: 0.9515 | Val Loss: 0.1976 Acc: 0.9287\n",
      "Epoch 044 | Train Loss: 0.1297 Acc: 0.9509 | Val Loss: 0.2112 Acc: 0.9191\n",
      "Epoch 045 | Train Loss: 0.1229 Acc: 0.9524 | Val Loss: 0.1800 Acc: 0.9324\n",
      "Epoch 046 | Train Loss: 0.1186 Acc: 0.9559 | Val Loss: 0.1959 Acc: 0.9306\n",
      "Epoch 047 | Train Loss: 0.1188 Acc: 0.9565 | Val Loss: 0.1917 Acc: 0.9318\n",
      "Epoch 048 | Train Loss: 0.1176 Acc: 0.9574 | Val Loss: 0.1982 Acc: 0.9239\n",
      "Epoch 049 | Train Loss: 0.1222 Acc: 0.9512 | Val Loss: 0.1903 Acc: 0.9306\n",
      "Early stopping triggered.\n",
      "Iteration 23/40 | Best Val Loss: 0.1122 | Iter Time: 217.16s | Total Time: 97.43 min\n",
      "Epoch 001 | Train Loss: 0.6810 Acc: 0.5777 | Val Loss: 0.6768 Acc: 0.5839\n",
      "Epoch 002 | Train Loss: 0.6745 Acc: 0.5934 | Val Loss: 0.6727 Acc: 0.5876\n",
      "Epoch 003 | Train Loss: 0.6699 Acc: 0.6014 | Val Loss: 0.6704 Acc: 0.5960\n",
      "Epoch 004 | Train Loss: 0.6570 Acc: 0.6168 | Val Loss: 0.6362 Acc: 0.6298\n",
      "Epoch 005 | Train Loss: 0.5793 Acc: 0.7036 | Val Loss: 0.5590 Acc: 0.7216\n",
      "Epoch 006 | Train Loss: 0.5393 Acc: 0.7334 | Val Loss: 0.5341 Acc: 0.7301\n",
      "Epoch 007 | Train Loss: 0.5042 Acc: 0.7589 | Val Loss: 0.5017 Acc: 0.7669\n",
      "Epoch 008 | Train Loss: 0.4801 Acc: 0.7720 | Val Loss: 0.4848 Acc: 0.7657\n",
      "Epoch 009 | Train Loss: 0.4461 Acc: 0.8034 | Val Loss: 0.4295 Acc: 0.8068\n",
      "Epoch 010 | Train Loss: 0.3998 Acc: 0.8232 | Val Loss: 0.3991 Acc: 0.8237\n",
      "Epoch 011 | Train Loss: 0.3768 Acc: 0.8374 | Val Loss: 0.3878 Acc: 0.8158\n",
      "Epoch 012 | Train Loss: 0.3231 Acc: 0.8626 | Val Loss: 0.3876 Acc: 0.8231\n",
      "Epoch 013 | Train Loss: 0.2958 Acc: 0.8792 | Val Loss: 0.2839 Acc: 0.8847\n",
      "Epoch 014 | Train Loss: 0.2621 Acc: 0.8905 | Val Loss: 0.2853 Acc: 0.8895\n",
      "Epoch 015 | Train Loss: 0.2611 Acc: 0.8898 | Val Loss: 0.2842 Acc: 0.8804\n",
      "Epoch 016 | Train Loss: 0.2351 Acc: 0.9025 | Val Loss: 0.2900 Acc: 0.8792\n",
      "Epoch 017 | Train Loss: 0.2069 Acc: 0.9174 | Val Loss: 0.2230 Acc: 0.9052\n",
      "Epoch 018 | Train Loss: 0.1994 Acc: 0.9201 | Val Loss: 0.2324 Acc: 0.9040\n",
      "Epoch 019 | Train Loss: 0.1680 Acc: 0.9360 | Val Loss: 0.2038 Acc: 0.9136\n",
      "Epoch 020 | Train Loss: 0.1604 Acc: 0.9369 | Val Loss: 0.2812 Acc: 0.8853\n",
      "Epoch 021 | Train Loss: 0.1629 Acc: 0.9319 | Val Loss: 0.2262 Acc: 0.9149\n",
      "Epoch 022 | Train Loss: 0.1407 Acc: 0.9467 | Val Loss: 0.2431 Acc: 0.9070\n",
      "Epoch 023 | Train Loss: 0.1471 Acc: 0.9434 | Val Loss: 0.1884 Acc: 0.9215\n",
      "Epoch 024 | Train Loss: 0.1333 Acc: 0.9500 | Val Loss: 0.2064 Acc: 0.9197\n",
      "Epoch 025 | Train Loss: 0.1171 Acc: 0.9556 | Val Loss: 0.2123 Acc: 0.9209\n",
      "Epoch 026 | Train Loss: 0.1189 Acc: 0.9550 | Val Loss: 0.2083 Acc: 0.9215\n",
      "Epoch 027 | Train Loss: 0.1177 Acc: 0.9541 | Val Loss: 0.2385 Acc: 0.9106\n",
      "Epoch 028 | Train Loss: 0.1036 Acc: 0.9639 | Val Loss: 0.1649 Acc: 0.9330\n",
      "Epoch 029 | Train Loss: 0.0986 Acc: 0.9633 | Val Loss: 0.2272 Acc: 0.9203\n",
      "Epoch 030 | Train Loss: 0.1075 Acc: 0.9604 | Val Loss: 0.1992 Acc: 0.9239\n",
      "Epoch 031 | Train Loss: 0.0992 Acc: 0.9620 | Val Loss: 0.1692 Acc: 0.9360\n",
      "Epoch 032 | Train Loss: 0.1035 Acc: 0.9633 | Val Loss: 0.1926 Acc: 0.9324\n",
      "Epoch 033 | Train Loss: 0.0961 Acc: 0.9635 | Val Loss: 0.1701 Acc: 0.9408\n",
      "Epoch 034 | Train Loss: 0.0965 Acc: 0.9654 | Val Loss: 0.2165 Acc: 0.9215\n",
      "Epoch 035 | Train Loss: 0.0844 Acc: 0.9687 | Val Loss: 0.1927 Acc: 0.9257\n",
      "Epoch 036 | Train Loss: 0.0748 Acc: 0.9727 | Val Loss: 0.2122 Acc: 0.9227\n",
      "Epoch 037 | Train Loss: 0.0867 Acc: 0.9684 | Val Loss: 0.1784 Acc: 0.9414\n",
      "Epoch 038 | Train Loss: 0.0815 Acc: 0.9678 | Val Loss: 0.1906 Acc: 0.9342\n",
      "Early stopping triggered.\n",
      "Epoch 001 | Train Loss: 0.6719 Acc: 0.5926 | Val Loss: 0.6526 Acc: 0.5996\n",
      "Epoch 002 | Train Loss: 0.6087 Acc: 0.6743 | Val Loss: 0.5749 Acc: 0.7126\n",
      "Epoch 003 | Train Loss: 0.5433 Acc: 0.7337 | Val Loss: 0.5488 Acc: 0.7162\n",
      "Epoch 004 | Train Loss: 0.5024 Acc: 0.7575 | Val Loss: 0.5023 Acc: 0.7566\n",
      "Epoch 005 | Train Loss: 0.4616 Acc: 0.7770 | Val Loss: 0.4440 Acc: 0.7893\n",
      "Epoch 006 | Train Loss: 0.3992 Acc: 0.8175 | Val Loss: 0.3944 Acc: 0.8188\n",
      "Epoch 007 | Train Loss: 0.3557 Acc: 0.8403 | Val Loss: 0.3366 Acc: 0.8521\n",
      "Epoch 008 | Train Loss: 0.2926 Acc: 0.8771 | Val Loss: 0.2893 Acc: 0.8744\n",
      "Epoch 009 | Train Loss: 0.2613 Acc: 0.8923 | Val Loss: 0.2586 Acc: 0.8955\n",
      "Epoch 010 | Train Loss: 0.2246 Acc: 0.9080 | Val Loss: 0.2521 Acc: 0.8967\n",
      "Epoch 011 | Train Loss: 0.1952 Acc: 0.9248 | Val Loss: 0.2385 Acc: 0.9064\n",
      "Epoch 012 | Train Loss: 0.1887 Acc: 0.9251 | Val Loss: 0.2425 Acc: 0.9082\n",
      "Epoch 013 | Train Loss: 0.1601 Acc: 0.9379 | Val Loss: 0.2344 Acc: 0.9034\n",
      "Epoch 014 | Train Loss: 0.1422 Acc: 0.9432 | Val Loss: 0.2132 Acc: 0.9155\n",
      "Epoch 015 | Train Loss: 0.1339 Acc: 0.9491 | Val Loss: 0.1884 Acc: 0.9203\n",
      "Epoch 016 | Train Loss: 0.1130 Acc: 0.9543 | Val Loss: 0.2451 Acc: 0.9064\n",
      "Epoch 017 | Train Loss: 0.0987 Acc: 0.9633 | Val Loss: 0.2078 Acc: 0.9251\n",
      "Epoch 018 | Train Loss: 0.0973 Acc: 0.9656 | Val Loss: 0.2144 Acc: 0.9312\n",
      "Epoch 019 | Train Loss: 0.0996 Acc: 0.9635 | Val Loss: 0.1961 Acc: 0.9378\n",
      "Epoch 020 | Train Loss: 0.0820 Acc: 0.9712 | Val Loss: 0.1724 Acc: 0.9378\n",
      "Epoch 021 | Train Loss: 0.0749 Acc: 0.9724 | Val Loss: 0.1976 Acc: 0.9408\n",
      "Epoch 022 | Train Loss: 0.0714 Acc: 0.9721 | Val Loss: 0.1922 Acc: 0.9354\n",
      "Epoch 023 | Train Loss: 0.0619 Acc: 0.9766 | Val Loss: 0.1645 Acc: 0.9414\n",
      "Epoch 024 | Train Loss: 0.0648 Acc: 0.9764 | Val Loss: 0.2034 Acc: 0.9263\n",
      "Epoch 025 | Train Loss: 0.0564 Acc: 0.9778 | Val Loss: 0.1977 Acc: 0.9336\n",
      "Epoch 026 | Train Loss: 0.0546 Acc: 0.9808 | Val Loss: 0.1940 Acc: 0.9348\n",
      "Epoch 027 | Train Loss: 0.0474 Acc: 0.9838 | Val Loss: 0.2419 Acc: 0.9221\n",
      "Epoch 028 | Train Loss: 0.0633 Acc: 0.9772 | Val Loss: 0.1672 Acc: 0.9450\n",
      "Epoch 029 | Train Loss: 0.0469 Acc: 0.9844 | Val Loss: 0.1940 Acc: 0.9342\n",
      "Epoch 030 | Train Loss: 0.0395 Acc: 0.9863 | Val Loss: 0.2535 Acc: 0.9251\n",
      "Epoch 031 | Train Loss: 0.0452 Acc: 0.9851 | Val Loss: 0.1804 Acc: 0.9463\n",
      "Epoch 032 | Train Loss: 0.0420 Acc: 0.9846 | Val Loss: 0.1835 Acc: 0.9432\n",
      "Epoch 033 | Train Loss: 0.0536 Acc: 0.9805 | Val Loss: 0.1837 Acc: 0.9384\n",
      "Early stopping triggered.\n",
      "Epoch 001 | Train Loss: 0.6793 Acc: 0.5783 | Val Loss: 0.6713 Acc: 0.5912\n",
      "Epoch 002 | Train Loss: 0.6711 Acc: 0.5994 | Val Loss: 0.6675 Acc: 0.6008\n",
      "Epoch 003 | Train Loss: 0.6530 Acc: 0.6263 | Val Loss: 0.6326 Acc: 0.6697\n",
      "Epoch 004 | Train Loss: 0.6313 Acc: 0.6612 | Val Loss: 0.6497 Acc: 0.6383\n",
      "Epoch 005 | Train Loss: 0.6006 Acc: 0.6859 | Val Loss: 0.5957 Acc: 0.6920\n",
      "Epoch 006 | Train Loss: 0.5661 Acc: 0.7090 | Val Loss: 0.5554 Acc: 0.7234\n",
      "Epoch 007 | Train Loss: 0.5471 Acc: 0.7291 | Val Loss: 0.5300 Acc: 0.7349\n",
      "Epoch 008 | Train Loss: 0.5166 Acc: 0.7457 | Val Loss: 0.5495 Acc: 0.7120\n",
      "Epoch 009 | Train Loss: 0.5057 Acc: 0.7537 | Val Loss: 0.4999 Acc: 0.7482\n",
      "Epoch 010 | Train Loss: 0.4757 Acc: 0.7764 | Val Loss: 0.4997 Acc: 0.7560\n",
      "Epoch 011 | Train Loss: 0.4666 Acc: 0.7737 | Val Loss: 0.4697 Acc: 0.7591\n",
      "Epoch 012 | Train Loss: 0.4440 Acc: 0.7918 | Val Loss: 0.4381 Acc: 0.7754\n",
      "Epoch 013 | Train Loss: 0.4250 Acc: 0.8011 | Val Loss: 0.4135 Acc: 0.8098\n",
      "Epoch 014 | Train Loss: 0.3913 Acc: 0.8244 | Val Loss: 0.4220 Acc: 0.7983\n",
      "Epoch 015 | Train Loss: 0.3819 Acc: 0.8279 | Val Loss: 0.3864 Acc: 0.8176\n",
      "Epoch 016 | Train Loss: 0.3418 Acc: 0.8498 | Val Loss: 0.3477 Acc: 0.8412\n",
      "Epoch 017 | Train Loss: 0.3367 Acc: 0.8501 | Val Loss: 0.3671 Acc: 0.8351\n",
      "Epoch 018 | Train Loss: 0.3141 Acc: 0.8637 | Val Loss: 0.3298 Acc: 0.8442\n",
      "Epoch 019 | Train Loss: 0.3108 Acc: 0.8691 | Val Loss: 0.3025 Acc: 0.8659\n",
      "Epoch 020 | Train Loss: 0.2959 Acc: 0.8717 | Val Loss: 0.2739 Acc: 0.8804\n",
      "Epoch 021 | Train Loss: 0.2620 Acc: 0.8913 | Val Loss: 0.2666 Acc: 0.8835\n",
      "Epoch 022 | Train Loss: 0.2475 Acc: 0.8972 | Val Loss: 0.2882 Acc: 0.8738\n",
      "Epoch 023 | Train Loss: 0.2427 Acc: 0.9000 | Val Loss: 0.2514 Acc: 0.8943\n",
      "Epoch 024 | Train Loss: 0.2222 Acc: 0.9090 | Val Loss: 0.2754 Acc: 0.8859\n",
      "Epoch 025 | Train Loss: 0.2102 Acc: 0.9139 | Val Loss: 0.2563 Acc: 0.8931\n",
      "Epoch 026 | Train Loss: 0.2168 Acc: 0.9115 | Val Loss: 0.2512 Acc: 0.8955\n",
      "Epoch 027 | Train Loss: 0.1942 Acc: 0.9245 | Val Loss: 0.2237 Acc: 0.9155\n",
      "Epoch 028 | Train Loss: 0.1820 Acc: 0.9278 | Val Loss: 0.2383 Acc: 0.9016\n",
      "Epoch 029 | Train Loss: 0.1877 Acc: 0.9244 | Val Loss: 0.2437 Acc: 0.9034\n",
      "Epoch 030 | Train Loss: 0.1694 Acc: 0.9345 | Val Loss: 0.2372 Acc: 0.9004\n",
      "Epoch 031 | Train Loss: 0.1749 Acc: 0.9304 | Val Loss: 0.1927 Acc: 0.9215\n",
      "Epoch 032 | Train Loss: 0.1679 Acc: 0.9337 | Val Loss: 0.1795 Acc: 0.9221\n",
      "Epoch 033 | Train Loss: 0.1515 Acc: 0.9393 | Val Loss: 0.2241 Acc: 0.9112\n",
      "Epoch 034 | Train Loss: 0.1601 Acc: 0.9381 | Val Loss: 0.1923 Acc: 0.9300\n",
      "Epoch 035 | Train Loss: 0.1479 Acc: 0.9431 | Val Loss: 0.1931 Acc: 0.9293\n",
      "Epoch 036 | Train Loss: 0.1452 Acc: 0.9423 | Val Loss: 0.2539 Acc: 0.8998\n",
      "Epoch 037 | Train Loss: 0.1375 Acc: 0.9475 | Val Loss: 0.2398 Acc: 0.9082\n",
      "Epoch 038 | Train Loss: 0.1325 Acc: 0.9482 | Val Loss: 0.2174 Acc: 0.9136\n",
      "Epoch 039 | Train Loss: 0.1282 Acc: 0.9490 | Val Loss: 0.1704 Acc: 0.9348\n",
      "Epoch 040 | Train Loss: 0.1186 Acc: 0.9536 | Val Loss: 0.2063 Acc: 0.9149\n",
      "Epoch 041 | Train Loss: 0.1177 Acc: 0.9558 | Val Loss: 0.1696 Acc: 0.9354\n",
      "Epoch 042 | Train Loss: 0.1105 Acc: 0.9613 | Val Loss: 0.2302 Acc: 0.9118\n",
      "Epoch 043 | Train Loss: 0.1015 Acc: 0.9621 | Val Loss: 0.1587 Acc: 0.9414\n",
      "Epoch 044 | Train Loss: 0.1095 Acc: 0.9565 | Val Loss: 0.1731 Acc: 0.9342\n",
      "Epoch 045 | Train Loss: 0.0994 Acc: 0.9615 | Val Loss: 0.1758 Acc: 0.9342\n",
      "Epoch 046 | Train Loss: 0.0940 Acc: 0.9642 | Val Loss: 0.1655 Acc: 0.9330\n",
      "Epoch 047 | Train Loss: 0.0878 Acc: 0.9684 | Val Loss: 0.1606 Acc: 0.9366\n",
      "Epoch 048 | Train Loss: 0.0985 Acc: 0.9629 | Val Loss: 0.1520 Acc: 0.9402\n",
      "Epoch 049 | Train Loss: 0.0942 Acc: 0.9626 | Val Loss: 0.1566 Acc: 0.9426\n",
      "Epoch 050 | Train Loss: 0.1004 Acc: 0.9636 | Val Loss: 0.1625 Acc: 0.9426\n",
      "Epoch 051 | Train Loss: 0.0839 Acc: 0.9686 | Val Loss: 0.1464 Acc: 0.9420\n",
      "Epoch 052 | Train Loss: 0.0916 Acc: 0.9663 | Val Loss: 0.1874 Acc: 0.9324\n",
      "Epoch 053 | Train Loss: 0.0864 Acc: 0.9674 | Val Loss: 0.1568 Acc: 0.9432\n",
      "Epoch 054 | Train Loss: 0.0781 Acc: 0.9725 | Val Loss: 0.1454 Acc: 0.9481\n",
      "Epoch 055 | Train Loss: 0.0890 Acc: 0.9678 | Val Loss: 0.1447 Acc: 0.9499\n",
      "Epoch 056 | Train Loss: 0.0811 Acc: 0.9712 | Val Loss: 0.1746 Acc: 0.9402\n",
      "Epoch 057 | Train Loss: 0.0861 Acc: 0.9668 | Val Loss: 0.1733 Acc: 0.9348\n",
      "Epoch 058 | Train Loss: 0.0756 Acc: 0.9751 | Val Loss: 0.1906 Acc: 0.9414\n",
      "Epoch 059 | Train Loss: 0.0775 Acc: 0.9740 | Val Loss: 0.1567 Acc: 0.9408\n",
      "Epoch 060 | Train Loss: 0.0805 Acc: 0.9715 | Val Loss: 0.1676 Acc: 0.9360\n",
      "Epoch 001 | Train Loss: 0.6801 Acc: 0.5799 | Val Loss: 0.6756 Acc: 0.5870\n",
      "Epoch 002 | Train Loss: 0.6754 Acc: 0.5917 | Val Loss: 0.6736 Acc: 0.5936\n",
      "Epoch 003 | Train Loss: 0.6708 Acc: 0.5923 | Val Loss: 0.6664 Acc: 0.5924\n",
      "Epoch 004 | Train Loss: 0.6438 Acc: 0.6331 | Val Loss: 0.6207 Acc: 0.6679\n",
      "Epoch 005 | Train Loss: 0.5982 Acc: 0.6906 | Val Loss: 0.5782 Acc: 0.7101\n",
      "Epoch 006 | Train Loss: 0.5622 Acc: 0.7148 | Val Loss: 0.5458 Acc: 0.7198\n",
      "Epoch 007 | Train Loss: 0.5355 Acc: 0.7353 | Val Loss: 0.5296 Acc: 0.7295\n",
      "Epoch 008 | Train Loss: 0.5150 Acc: 0.7512 | Val Loss: 0.4969 Acc: 0.7470\n",
      "Epoch 009 | Train Loss: 0.4899 Acc: 0.7590 | Val Loss: 0.4970 Acc: 0.7518\n",
      "Epoch 010 | Train Loss: 0.4701 Acc: 0.7782 | Val Loss: 0.4571 Acc: 0.7784\n",
      "Epoch 011 | Train Loss: 0.4546 Acc: 0.7892 | Val Loss: 0.4443 Acc: 0.7874\n",
      "Epoch 012 | Train Loss: 0.4412 Acc: 0.7939 | Val Loss: 0.4357 Acc: 0.7893\n",
      "Epoch 013 | Train Loss: 0.4176 Acc: 0.8090 | Val Loss: 0.4058 Acc: 0.8074\n",
      "Epoch 014 | Train Loss: 0.3936 Acc: 0.8199 | Val Loss: 0.3825 Acc: 0.8128\n",
      "Epoch 015 | Train Loss: 0.3762 Acc: 0.8297 | Val Loss: 0.3809 Acc: 0.8231\n",
      "Epoch 016 | Train Loss: 0.3653 Acc: 0.8395 | Val Loss: 0.3585 Acc: 0.8364\n",
      "Epoch 017 | Train Loss: 0.3391 Acc: 0.8508 | Val Loss: 0.3267 Acc: 0.8460\n",
      "Epoch 018 | Train Loss: 0.3124 Acc: 0.8667 | Val Loss: 0.3137 Acc: 0.8641\n",
      "Epoch 019 | Train Loss: 0.2951 Acc: 0.8769 | Val Loss: 0.2855 Acc: 0.8690\n",
      "Epoch 020 | Train Loss: 0.2712 Acc: 0.8898 | Val Loss: 0.2872 Acc: 0.8762\n",
      "Epoch 021 | Train Loss: 0.2616 Acc: 0.8939 | Val Loss: 0.3108 Acc: 0.8587\n",
      "Epoch 022 | Train Loss: 0.2452 Acc: 0.9017 | Val Loss: 0.2634 Acc: 0.8798\n",
      "Epoch 023 | Train Loss: 0.2419 Acc: 0.9025 | Val Loss: 0.2449 Acc: 0.9004\n",
      "Epoch 024 | Train Loss: 0.2279 Acc: 0.9138 | Val Loss: 0.2304 Acc: 0.9028\n",
      "Epoch 025 | Train Loss: 0.2102 Acc: 0.9177 | Val Loss: 0.2169 Acc: 0.9106\n",
      "Epoch 026 | Train Loss: 0.2075 Acc: 0.9180 | Val Loss: 0.2516 Acc: 0.9004\n",
      "Epoch 027 | Train Loss: 0.1911 Acc: 0.9274 | Val Loss: 0.2022 Acc: 0.9179\n",
      "Epoch 028 | Train Loss: 0.1606 Acc: 0.9358 | Val Loss: 0.1962 Acc: 0.9221\n",
      "Epoch 029 | Train Loss: 0.1665 Acc: 0.9342 | Val Loss: 0.2113 Acc: 0.9088\n",
      "Epoch 030 | Train Loss: 0.1552 Acc: 0.9401 | Val Loss: 0.1912 Acc: 0.9203\n",
      "Epoch 031 | Train Loss: 0.1471 Acc: 0.9422 | Val Loss: 0.1936 Acc: 0.9257\n",
      "Epoch 032 | Train Loss: 0.1560 Acc: 0.9385 | Val Loss: 0.1881 Acc: 0.9245\n",
      "Epoch 033 | Train Loss: 0.1486 Acc: 0.9447 | Val Loss: 0.1831 Acc: 0.9281\n",
      "Epoch 034 | Train Loss: 0.1294 Acc: 0.9496 | Val Loss: 0.1662 Acc: 0.9414\n",
      "Epoch 035 | Train Loss: 0.1280 Acc: 0.9521 | Val Loss: 0.1770 Acc: 0.9324\n",
      "Epoch 036 | Train Loss: 0.1221 Acc: 0.9550 | Val Loss: 0.1846 Acc: 0.9293\n",
      "Epoch 037 | Train Loss: 0.1182 Acc: 0.9524 | Val Loss: 0.1851 Acc: 0.9342\n",
      "Epoch 038 | Train Loss: 0.1176 Acc: 0.9555 | Val Loss: 0.2131 Acc: 0.9306\n",
      "Epoch 039 | Train Loss: 0.1127 Acc: 0.9573 | Val Loss: 0.1716 Acc: 0.9372\n",
      "Epoch 040 | Train Loss: 0.1026 Acc: 0.9609 | Val Loss: 0.1911 Acc: 0.9354\n",
      "Epoch 041 | Train Loss: 0.1025 Acc: 0.9626 | Val Loss: 0.1713 Acc: 0.9366\n",
      "Epoch 042 | Train Loss: 0.1070 Acc: 0.9607 | Val Loss: 0.1781 Acc: 0.9287\n",
      "Epoch 043 | Train Loss: 0.0859 Acc: 0.9698 | Val Loss: 0.1759 Acc: 0.9414\n",
      "Epoch 044 | Train Loss: 0.1008 Acc: 0.9638 | Val Loss: 0.1561 Acc: 0.9414\n",
      "Epoch 045 | Train Loss: 0.0752 Acc: 0.9731 | Val Loss: 0.1724 Acc: 0.9414\n",
      "Epoch 046 | Train Loss: 0.0950 Acc: 0.9636 | Val Loss: 0.1609 Acc: 0.9481\n",
      "Epoch 047 | Train Loss: 0.0837 Acc: 0.9690 | Val Loss: 0.1704 Acc: 0.9414\n",
      "Epoch 048 | Train Loss: 0.0812 Acc: 0.9703 | Val Loss: 0.1683 Acc: 0.9366\n",
      "Epoch 049 | Train Loss: 0.0836 Acc: 0.9690 | Val Loss: 0.1687 Acc: 0.9384\n",
      "Epoch 050 | Train Loss: 0.0727 Acc: 0.9736 | Val Loss: 0.1398 Acc: 0.9529\n",
      "Epoch 051 | Train Loss: 0.0735 Acc: 0.9734 | Val Loss: 0.1775 Acc: 0.9444\n",
      "Epoch 052 | Train Loss: 0.0896 Acc: 0.9668 | Val Loss: 0.1359 Acc: 0.9523\n",
      "Epoch 053 | Train Loss: 0.0598 Acc: 0.9784 | Val Loss: 0.1864 Acc: 0.9378\n",
      "Epoch 054 | Train Loss: 0.0666 Acc: 0.9742 | Val Loss: 0.1754 Acc: 0.9444\n",
      "Epoch 055 | Train Loss: 0.0632 Acc: 0.9766 | Val Loss: 0.1816 Acc: 0.9402\n",
      "Epoch 056 | Train Loss: 0.0700 Acc: 0.9749 | Val Loss: 0.1278 Acc: 0.9565\n",
      "Epoch 057 | Train Loss: 0.0611 Acc: 0.9790 | Val Loss: 0.1461 Acc: 0.9487\n",
      "Epoch 058 | Train Loss: 0.0599 Acc: 0.9792 | Val Loss: 0.1488 Acc: 0.9487\n",
      "Epoch 059 | Train Loss: 0.0618 Acc: 0.9781 | Val Loss: 0.1826 Acc: 0.9324\n",
      "Epoch 060 | Train Loss: 0.0648 Acc: 0.9764 | Val Loss: 0.1390 Acc: 0.9487\n",
      "Epoch 001 | Train Loss: 0.6785 Acc: 0.5809 | Val Loss: 0.6757 Acc: 0.5857\n",
      "Epoch 002 | Train Loss: 0.6707 Acc: 0.5973 | Val Loss: 0.6671 Acc: 0.6014\n",
      "Epoch 003 | Train Loss: 0.6642 Acc: 0.6082 | Val Loss: 0.6687 Acc: 0.6039\n",
      "Epoch 004 | Train Loss: 0.6591 Acc: 0.6103 | Val Loss: 0.6417 Acc: 0.6105\n",
      "Epoch 005 | Train Loss: 0.6015 Acc: 0.6900 | Val Loss: 0.5714 Acc: 0.7156\n",
      "Epoch 006 | Train Loss: 0.5439 Acc: 0.7308 | Val Loss: 0.5411 Acc: 0.7325\n",
      "Epoch 007 | Train Loss: 0.5117 Acc: 0.7536 | Val Loss: 0.4969 Acc: 0.7560\n",
      "Epoch 008 | Train Loss: 0.4794 Acc: 0.7716 | Val Loss: 0.4527 Acc: 0.7935\n",
      "Epoch 009 | Train Loss: 0.4577 Acc: 0.7931 | Val Loss: 0.4162 Acc: 0.8182\n",
      "Epoch 010 | Train Loss: 0.4167 Acc: 0.8172 | Val Loss: 0.3928 Acc: 0.8231\n",
      "Epoch 011 | Train Loss: 0.3942 Acc: 0.8229 | Val Loss: 0.3678 Acc: 0.8357\n",
      "Epoch 012 | Train Loss: 0.3551 Acc: 0.8430 | Val Loss: 0.3311 Acc: 0.8557\n",
      "Epoch 013 | Train Loss: 0.3247 Acc: 0.8609 | Val Loss: 0.3173 Acc: 0.8702\n",
      "Epoch 014 | Train Loss: 0.3028 Acc: 0.8679 | Val Loss: 0.2999 Acc: 0.8768\n",
      "Epoch 015 | Train Loss: 0.2677 Acc: 0.8884 | Val Loss: 0.2924 Acc: 0.8822\n",
      "Epoch 016 | Train Loss: 0.2554 Acc: 0.8945 | Val Loss: 0.2708 Acc: 0.8883\n",
      "Epoch 017 | Train Loss: 0.2491 Acc: 0.8960 | Val Loss: 0.2663 Acc: 0.8871\n",
      "Epoch 018 | Train Loss: 0.2304 Acc: 0.9020 | Val Loss: 0.2371 Acc: 0.9028\n",
      "Epoch 019 | Train Loss: 0.2143 Acc: 0.9115 | Val Loss: 0.2147 Acc: 0.9124\n",
      "Epoch 020 | Train Loss: 0.1918 Acc: 0.9215 | Val Loss: 0.2197 Acc: 0.9112\n",
      "Epoch 021 | Train Loss: 0.1879 Acc: 0.9231 | Val Loss: 0.2349 Acc: 0.9088\n",
      "Epoch 022 | Train Loss: 0.1815 Acc: 0.9299 | Val Loss: 0.2002 Acc: 0.9233\n",
      "Epoch 023 | Train Loss: 0.1678 Acc: 0.9334 | Val Loss: 0.2109 Acc: 0.9306\n",
      "Epoch 024 | Train Loss: 0.1528 Acc: 0.9393 | Val Loss: 0.1998 Acc: 0.9191\n",
      "Epoch 025 | Train Loss: 0.1603 Acc: 0.9390 | Val Loss: 0.2014 Acc: 0.9161\n",
      "Epoch 026 | Train Loss: 0.1494 Acc: 0.9376 | Val Loss: 0.1979 Acc: 0.9257\n",
      "Epoch 027 | Train Loss: 0.1442 Acc: 0.9428 | Val Loss: 0.2166 Acc: 0.9203\n",
      "Epoch 028 | Train Loss: 0.1418 Acc: 0.9437 | Val Loss: 0.1830 Acc: 0.9263\n",
      "Epoch 029 | Train Loss: 0.1385 Acc: 0.9469 | Val Loss: 0.1878 Acc: 0.9275\n",
      "Epoch 030 | Train Loss: 0.1281 Acc: 0.9520 | Val Loss: 0.1788 Acc: 0.9324\n",
      "Epoch 031 | Train Loss: 0.1234 Acc: 0.9500 | Val Loss: 0.1623 Acc: 0.9426\n",
      "Epoch 032 | Train Loss: 0.1044 Acc: 0.9607 | Val Loss: 0.1840 Acc: 0.9306\n",
      "Epoch 033 | Train Loss: 0.1095 Acc: 0.9556 | Val Loss: 0.1889 Acc: 0.9293\n",
      "Epoch 034 | Train Loss: 0.1107 Acc: 0.9583 | Val Loss: 0.2051 Acc: 0.9293\n",
      "Epoch 035 | Train Loss: 0.1122 Acc: 0.9571 | Val Loss: 0.1562 Acc: 0.9444\n",
      "Epoch 036 | Train Loss: 0.1000 Acc: 0.9626 | Val Loss: 0.1754 Acc: 0.9390\n",
      "Epoch 037 | Train Loss: 0.0985 Acc: 0.9642 | Val Loss: 0.1848 Acc: 0.9251\n",
      "Epoch 038 | Train Loss: 0.0976 Acc: 0.9657 | Val Loss: 0.1725 Acc: 0.9342\n",
      "Epoch 039 | Train Loss: 0.0997 Acc: 0.9647 | Val Loss: 0.1708 Acc: 0.9366\n",
      "Epoch 040 | Train Loss: 0.0952 Acc: 0.9648 | Val Loss: 0.1637 Acc: 0.9378\n",
      "Epoch 041 | Train Loss: 0.0879 Acc: 0.9660 | Val Loss: 0.1601 Acc: 0.9444\n",
      "Epoch 042 | Train Loss: 0.0926 Acc: 0.9657 | Val Loss: 0.1346 Acc: 0.9487\n",
      "Epoch 043 | Train Loss: 0.0841 Acc: 0.9693 | Val Loss: 0.2009 Acc: 0.9306\n",
      "Epoch 044 | Train Loss: 0.0791 Acc: 0.9704 | Val Loss: 0.1673 Acc: 0.9366\n",
      "Epoch 045 | Train Loss: 0.0737 Acc: 0.9709 | Val Loss: 0.1928 Acc: 0.9342\n",
      "Epoch 046 | Train Loss: 0.0848 Acc: 0.9686 | Val Loss: 0.1801 Acc: 0.9324\n",
      "Epoch 047 | Train Loss: 0.0911 Acc: 0.9678 | Val Loss: 0.1366 Acc: 0.9523\n",
      "Epoch 048 | Train Loss: 0.0886 Acc: 0.9665 | Val Loss: 0.1323 Acc: 0.9493\n",
      "Epoch 049 | Train Loss: 0.0799 Acc: 0.9712 | Val Loss: 0.1557 Acc: 0.9390\n",
      "Epoch 050 | Train Loss: 0.0751 Acc: 0.9745 | Val Loss: 0.1589 Acc: 0.9457\n",
      "Epoch 051 | Train Loss: 0.0639 Acc: 0.9751 | Val Loss: 0.1772 Acc: 0.9457\n",
      "Epoch 052 | Train Loss: 0.0852 Acc: 0.9675 | Val Loss: 0.1680 Acc: 0.9342\n",
      "Epoch 053 | Train Loss: 0.0675 Acc: 0.9739 | Val Loss: 0.1706 Acc: 0.9414\n",
      "Epoch 054 | Train Loss: 0.0790 Acc: 0.9710 | Val Loss: 0.2046 Acc: 0.9330\n",
      "Epoch 055 | Train Loss: 0.0714 Acc: 0.9727 | Val Loss: 0.1461 Acc: 0.9444\n",
      "Epoch 056 | Train Loss: 0.0663 Acc: 0.9742 | Val Loss: 0.1398 Acc: 0.9529\n",
      "Epoch 057 | Train Loss: 0.0680 Acc: 0.9736 | Val Loss: 0.1460 Acc: 0.9499\n",
      "Epoch 058 | Train Loss: 0.0687 Acc: 0.9713 | Val Loss: 0.1598 Acc: 0.9475\n",
      "Early stopping triggered.\n",
      "Epoch 001 | Train Loss: 0.6816 Acc: 0.5804 | Val Loss: 0.6824 Acc: 0.5743\n",
      "Epoch 002 | Train Loss: 0.6700 Acc: 0.5988 | Val Loss: 0.6753 Acc: 0.5839\n",
      "Epoch 003 | Train Loss: 0.6546 Acc: 0.6144 | Val Loss: 0.6385 Acc: 0.6498\n",
      "Epoch 004 | Train Loss: 0.6304 Acc: 0.6610 | Val Loss: 0.6100 Acc: 0.6679\n",
      "Epoch 005 | Train Loss: 0.5948 Acc: 0.6942 | Val Loss: 0.5966 Acc: 0.6806\n",
      "Epoch 006 | Train Loss: 0.5647 Acc: 0.7187 | Val Loss: 0.5758 Acc: 0.6938\n",
      "Epoch 007 | Train Loss: 0.5443 Acc: 0.7364 | Val Loss: 0.5646 Acc: 0.7083\n",
      "Epoch 008 | Train Loss: 0.5244 Acc: 0.7433 | Val Loss: 0.5208 Acc: 0.7458\n",
      "Epoch 009 | Train Loss: 0.5011 Acc: 0.7629 | Val Loss: 0.4967 Acc: 0.7579\n",
      "Epoch 010 | Train Loss: 0.4792 Acc: 0.7753 | Val Loss: 0.5421 Acc: 0.7319\n",
      "Epoch 011 | Train Loss: 0.4661 Acc: 0.7773 | Val Loss: 0.4564 Acc: 0.7802\n",
      "Epoch 012 | Train Loss: 0.4281 Acc: 0.8054 | Val Loss: 0.4314 Acc: 0.7953\n",
      "Epoch 013 | Train Loss: 0.4094 Acc: 0.8052 | Val Loss: 0.4321 Acc: 0.7808\n",
      "Epoch 014 | Train Loss: 0.3839 Acc: 0.8226 | Val Loss: 0.3797 Acc: 0.8207\n",
      "Epoch 015 | Train Loss: 0.3805 Acc: 0.8288 | Val Loss: 0.3665 Acc: 0.8297\n",
      "Epoch 016 | Train Loss: 0.3432 Acc: 0.8502 | Val Loss: 0.3217 Acc: 0.8653\n",
      "Epoch 017 | Train Loss: 0.3228 Acc: 0.8593 | Val Loss: 0.3061 Acc: 0.8684\n",
      "Epoch 018 | Train Loss: 0.3051 Acc: 0.8665 | Val Loss: 0.3026 Acc: 0.8623\n",
      "Epoch 019 | Train Loss: 0.2830 Acc: 0.8821 | Val Loss: 0.2732 Acc: 0.8919\n",
      "Epoch 020 | Train Loss: 0.2654 Acc: 0.8911 | Val Loss: 0.3115 Acc: 0.8678\n",
      "Epoch 021 | Train Loss: 0.2558 Acc: 0.8940 | Val Loss: 0.2642 Acc: 0.8901\n",
      "Epoch 022 | Train Loss: 0.2343 Acc: 0.9040 | Val Loss: 0.2550 Acc: 0.8949\n",
      "Epoch 023 | Train Loss: 0.2319 Acc: 0.9074 | Val Loss: 0.2219 Acc: 0.9143\n",
      "Epoch 024 | Train Loss: 0.2166 Acc: 0.9127 | Val Loss: 0.2515 Acc: 0.8913\n",
      "Epoch 025 | Train Loss: 0.1981 Acc: 0.9191 | Val Loss: 0.2281 Acc: 0.9052\n",
      "Epoch 026 | Train Loss: 0.1836 Acc: 0.9292 | Val Loss: 0.2080 Acc: 0.9112\n",
      "Epoch 027 | Train Loss: 0.1774 Acc: 0.9308 | Val Loss: 0.2231 Acc: 0.9094\n",
      "Epoch 028 | Train Loss: 0.1551 Acc: 0.9395 | Val Loss: 0.2177 Acc: 0.9106\n",
      "Epoch 029 | Train Loss: 0.1564 Acc: 0.9385 | Val Loss: 0.1995 Acc: 0.9245\n",
      "Epoch 030 | Train Loss: 0.1613 Acc: 0.9357 | Val Loss: 0.2101 Acc: 0.9197\n",
      "Epoch 031 | Train Loss: 0.1424 Acc: 0.9479 | Val Loss: 0.1977 Acc: 0.9221\n",
      "Epoch 032 | Train Loss: 0.1409 Acc: 0.9432 | Val Loss: 0.1848 Acc: 0.9269\n",
      "Epoch 033 | Train Loss: 0.1287 Acc: 0.9481 | Val Loss: 0.1885 Acc: 0.9306\n",
      "Epoch 034 | Train Loss: 0.1272 Acc: 0.9500 | Val Loss: 0.1814 Acc: 0.9342\n",
      "Epoch 035 | Train Loss: 0.1129 Acc: 0.9573 | Val Loss: 0.2005 Acc: 0.9263\n",
      "Epoch 036 | Train Loss: 0.1131 Acc: 0.9564 | Val Loss: 0.1624 Acc: 0.9414\n",
      "Epoch 037 | Train Loss: 0.1099 Acc: 0.9574 | Val Loss: 0.1707 Acc: 0.9360\n",
      "Epoch 038 | Train Loss: 0.1028 Acc: 0.9618 | Val Loss: 0.2295 Acc: 0.9155\n",
      "Epoch 039 | Train Loss: 0.1025 Acc: 0.9604 | Val Loss: 0.1629 Acc: 0.9402\n",
      "Epoch 040 | Train Loss: 0.1037 Acc: 0.9626 | Val Loss: 0.1712 Acc: 0.9354\n",
      "Epoch 041 | Train Loss: 0.0882 Acc: 0.9657 | Val Loss: 0.1829 Acc: 0.9414\n",
      "Epoch 042 | Train Loss: 0.0844 Acc: 0.9666 | Val Loss: 0.1776 Acc: 0.9312\n",
      "Epoch 043 | Train Loss: 0.0883 Acc: 0.9675 | Val Loss: 0.1517 Acc: 0.9450\n",
      "Epoch 044 | Train Loss: 0.0898 Acc: 0.9677 | Val Loss: 0.1654 Acc: 0.9378\n",
      "Epoch 045 | Train Loss: 0.0791 Acc: 0.9695 | Val Loss: 0.1666 Acc: 0.9354\n",
      "Epoch 046 | Train Loss: 0.0876 Acc: 0.9654 | Val Loss: 0.1390 Acc: 0.9511\n",
      "Epoch 047 | Train Loss: 0.0821 Acc: 0.9686 | Val Loss: 0.1538 Acc: 0.9426\n",
      "Epoch 048 | Train Loss: 0.0714 Acc: 0.9734 | Val Loss: 0.1400 Acc: 0.9511\n",
      "Epoch 049 | Train Loss: 0.0662 Acc: 0.9757 | Val Loss: 0.1673 Acc: 0.9414\n",
      "Epoch 050 | Train Loss: 0.0662 Acc: 0.9749 | Val Loss: 0.1625 Acc: 0.9414\n",
      "Epoch 051 | Train Loss: 0.0753 Acc: 0.9734 | Val Loss: 0.1828 Acc: 0.9366\n",
      "Epoch 052 | Train Loss: 0.0750 Acc: 0.9724 | Val Loss: 0.1428 Acc: 0.9505\n",
      "Epoch 053 | Train Loss: 0.0662 Acc: 0.9775 | Val Loss: 0.1386 Acc: 0.9565\n",
      "Epoch 054 | Train Loss: 0.0612 Acc: 0.9784 | Val Loss: 0.1693 Acc: 0.9469\n",
      "Epoch 055 | Train Loss: 0.0626 Acc: 0.9795 | Val Loss: 0.1476 Acc: 0.9523\n",
      "Epoch 056 | Train Loss: 0.0643 Acc: 0.9775 | Val Loss: 0.1768 Acc: 0.9463\n",
      "Epoch 057 | Train Loss: 0.0705 Acc: 0.9737 | Val Loss: 0.1509 Acc: 0.9475\n",
      "Epoch 058 | Train Loss: 0.0548 Acc: 0.9805 | Val Loss: 0.1440 Acc: 0.9547\n",
      "Epoch 059 | Train Loss: 0.0655 Acc: 0.9758 | Val Loss: 0.1350 Acc: 0.9535\n",
      "Epoch 060 | Train Loss: 0.0571 Acc: 0.9798 | Val Loss: 0.1367 Acc: 0.9505\n",
      "Epoch 001 | Train Loss: 0.6803 Acc: 0.5763 | Val Loss: 0.6853 Acc: 0.5870\n",
      "Epoch 002 | Train Loss: 0.6745 Acc: 0.5957 | Val Loss: 0.6728 Acc: 0.5912\n",
      "Epoch 003 | Train Loss: 0.6670 Acc: 0.6008 | Val Loss: 0.6680 Acc: 0.6039\n",
      "Epoch 004 | Train Loss: 0.6652 Acc: 0.6106 | Val Loss: 0.6645 Acc: 0.5972\n",
      "Epoch 005 | Train Loss: 0.6594 Acc: 0.6095 | Val Loss: 0.6628 Acc: 0.6045\n",
      "Epoch 006 | Train Loss: 0.6440 Acc: 0.6388 | Val Loss: 0.6100 Acc: 0.6751\n",
      "Epoch 007 | Train Loss: 0.5979 Acc: 0.6938 | Val Loss: 0.5936 Acc: 0.6944\n",
      "Epoch 008 | Train Loss: 0.5621 Acc: 0.7225 | Val Loss: 0.5492 Acc: 0.7246\n",
      "Epoch 009 | Train Loss: 0.5197 Acc: 0.7516 | Val Loss: 0.5284 Acc: 0.7337\n",
      "Epoch 010 | Train Loss: 0.5193 Acc: 0.7474 | Val Loss: 0.5094 Acc: 0.7506\n",
      "Epoch 011 | Train Loss: 0.4772 Acc: 0.7774 | Val Loss: 0.4876 Acc: 0.7717\n",
      "Epoch 012 | Train Loss: 0.4543 Acc: 0.7889 | Val Loss: 0.4323 Acc: 0.8037\n",
      "Epoch 013 | Train Loss: 0.4194 Acc: 0.8018 | Val Loss: 0.4501 Acc: 0.7917\n",
      "Epoch 014 | Train Loss: 0.3984 Acc: 0.8202 | Val Loss: 0.4330 Acc: 0.7832\n",
      "Epoch 015 | Train Loss: 0.3816 Acc: 0.8312 | Val Loss: 0.3492 Acc: 0.8436\n",
      "Epoch 016 | Train Loss: 0.3450 Acc: 0.8484 | Val Loss: 0.3622 Acc: 0.8357\n",
      "Epoch 017 | Train Loss: 0.3373 Acc: 0.8573 | Val Loss: 0.3505 Acc: 0.8406\n",
      "Epoch 018 | Train Loss: 0.3114 Acc: 0.8646 | Val Loss: 0.3260 Acc: 0.8521\n",
      "Epoch 019 | Train Loss: 0.3051 Acc: 0.8653 | Val Loss: 0.2990 Acc: 0.8847\n",
      "Epoch 020 | Train Loss: 0.2737 Acc: 0.8857 | Val Loss: 0.2702 Acc: 0.8913\n",
      "Epoch 021 | Train Loss: 0.2530 Acc: 0.8929 | Val Loss: 0.2804 Acc: 0.8768\n",
      "Epoch 022 | Train Loss: 0.2455 Acc: 0.9000 | Val Loss: 0.3046 Acc: 0.8671\n",
      "Epoch 023 | Train Loss: 0.2398 Acc: 0.9062 | Val Loss: 0.2517 Acc: 0.8943\n",
      "Epoch 024 | Train Loss: 0.2376 Acc: 0.9046 | Val Loss: 0.2319 Acc: 0.9143\n",
      "Epoch 025 | Train Loss: 0.1940 Acc: 0.9215 | Val Loss: 0.2548 Acc: 0.9010\n",
      "Epoch 026 | Train Loss: 0.2045 Acc: 0.9183 | Val Loss: 0.2296 Acc: 0.9034\n",
      "Epoch 027 | Train Loss: 0.1745 Acc: 0.9342 | Val Loss: 0.2249 Acc: 0.9161\n",
      "Epoch 028 | Train Loss: 0.1919 Acc: 0.9233 | Val Loss: 0.2206 Acc: 0.9070\n",
      "Epoch 029 | Train Loss: 0.1780 Acc: 0.9325 | Val Loss: 0.2239 Acc: 0.9112\n",
      "Epoch 030 | Train Loss: 0.1785 Acc: 0.9293 | Val Loss: 0.2056 Acc: 0.9149\n",
      "Epoch 031 | Train Loss: 0.1617 Acc: 0.9363 | Val Loss: 0.2332 Acc: 0.9076\n",
      "Epoch 032 | Train Loss: 0.1694 Acc: 0.9331 | Val Loss: 0.1996 Acc: 0.9215\n",
      "Epoch 033 | Train Loss: 0.1531 Acc: 0.9404 | Val Loss: 0.2000 Acc: 0.9185\n",
      "Epoch 034 | Train Loss: 0.1466 Acc: 0.9444 | Val Loss: 0.2278 Acc: 0.9046\n",
      "Epoch 035 | Train Loss: 0.1403 Acc: 0.9449 | Val Loss: 0.2225 Acc: 0.9130\n",
      "Epoch 036 | Train Loss: 0.1372 Acc: 0.9485 | Val Loss: 0.2003 Acc: 0.9269\n",
      "Epoch 037 | Train Loss: 0.1460 Acc: 0.9422 | Val Loss: 0.1841 Acc: 0.9239\n",
      "Epoch 038 | Train Loss: 0.1252 Acc: 0.9527 | Val Loss: 0.1762 Acc: 0.9257\n",
      "Epoch 039 | Train Loss: 0.1324 Acc: 0.9509 | Val Loss: 0.1937 Acc: 0.9251\n",
      "Epoch 040 | Train Loss: 0.1315 Acc: 0.9511 | Val Loss: 0.1777 Acc: 0.9251\n",
      "Epoch 041 | Train Loss: 0.1197 Acc: 0.9544 | Val Loss: 0.1634 Acc: 0.9408\n",
      "Epoch 042 | Train Loss: 0.1198 Acc: 0.9541 | Val Loss: 0.1683 Acc: 0.9402\n",
      "Epoch 043 | Train Loss: 0.1113 Acc: 0.9607 | Val Loss: 0.2067 Acc: 0.9245\n",
      "Epoch 044 | Train Loss: 0.1154 Acc: 0.9565 | Val Loss: 0.1873 Acc: 0.9251\n",
      "Epoch 045 | Train Loss: 0.1095 Acc: 0.9598 | Val Loss: 0.1745 Acc: 0.9342\n",
      "Epoch 046 | Train Loss: 0.0992 Acc: 0.9660 | Val Loss: 0.1929 Acc: 0.9330\n",
      "Epoch 047 | Train Loss: 0.0992 Acc: 0.9635 | Val Loss: 0.2073 Acc: 0.9257\n",
      "Epoch 048 | Train Loss: 0.0949 Acc: 0.9635 | Val Loss: 0.1719 Acc: 0.9444\n",
      "Epoch 049 | Train Loss: 0.1048 Acc: 0.9600 | Val Loss: 0.2017 Acc: 0.9348\n",
      "Epoch 050 | Train Loss: 0.0995 Acc: 0.9627 | Val Loss: 0.1798 Acc: 0.9324\n",
      "Epoch 051 | Train Loss: 0.1057 Acc: 0.9594 | Val Loss: 0.1832 Acc: 0.9275\n",
      "Early stopping triggered.\n",
      "Epoch 001 | Train Loss: 0.6782 Acc: 0.5799 | Val Loss: 0.6794 Acc: 0.5731\n",
      "Epoch 002 | Train Loss: 0.6655 Acc: 0.6020 | Val Loss: 0.6620 Acc: 0.5996\n",
      "Epoch 003 | Train Loss: 0.6380 Acc: 0.6496 | Val Loss: 0.5858 Acc: 0.6987\n",
      "Epoch 004 | Train Loss: 0.5793 Acc: 0.7112 | Val Loss: 0.5643 Acc: 0.7180\n",
      "Epoch 005 | Train Loss: 0.5599 Acc: 0.7263 | Val Loss: 0.5499 Acc: 0.7210\n",
      "Epoch 006 | Train Loss: 0.5443 Acc: 0.7359 | Val Loss: 0.5346 Acc: 0.7240\n",
      "Epoch 007 | Train Loss: 0.5239 Acc: 0.7491 | Val Loss: 0.5235 Acc: 0.7391\n",
      "Epoch 008 | Train Loss: 0.5110 Acc: 0.7560 | Val Loss: 0.5199 Acc: 0.7446\n",
      "Epoch 009 | Train Loss: 0.5013 Acc: 0.7631 | Val Loss: 0.4729 Acc: 0.7681\n",
      "Epoch 010 | Train Loss: 0.4740 Acc: 0.7761 | Val Loss: 0.5233 Acc: 0.7560\n",
      "Epoch 011 | Train Loss: 0.4620 Acc: 0.7838 | Val Loss: 0.4382 Acc: 0.7880\n",
      "Epoch 012 | Train Loss: 0.4370 Acc: 0.7933 | Val Loss: 0.4509 Acc: 0.7995\n",
      "Epoch 013 | Train Loss: 0.4339 Acc: 0.8002 | Val Loss: 0.4358 Acc: 0.7899\n",
      "Epoch 014 | Train Loss: 0.4143 Acc: 0.8129 | Val Loss: 0.4204 Acc: 0.7965\n",
      "Epoch 015 | Train Loss: 0.4065 Acc: 0.8081 | Val Loss: 0.3894 Acc: 0.8176\n",
      "Epoch 016 | Train Loss: 0.3823 Acc: 0.8312 | Val Loss: 0.3809 Acc: 0.8273\n",
      "Epoch 017 | Train Loss: 0.3784 Acc: 0.8267 | Val Loss: 0.3638 Acc: 0.8315\n",
      "Epoch 018 | Train Loss: 0.3657 Acc: 0.8377 | Val Loss: 0.3503 Acc: 0.8321\n",
      "Epoch 019 | Train Loss: 0.3464 Acc: 0.8490 | Val Loss: 0.3310 Acc: 0.8454\n",
      "Epoch 020 | Train Loss: 0.3354 Acc: 0.8552 | Val Loss: 0.3389 Acc: 0.8490\n",
      "Epoch 021 | Train Loss: 0.3200 Acc: 0.8643 | Val Loss: 0.3432 Acc: 0.8466\n",
      "Epoch 022 | Train Loss: 0.3143 Acc: 0.8618 | Val Loss: 0.3113 Acc: 0.8611\n",
      "Epoch 023 | Train Loss: 0.2990 Acc: 0.8721 | Val Loss: 0.2941 Acc: 0.8744\n",
      "Epoch 024 | Train Loss: 0.2867 Acc: 0.8745 | Val Loss: 0.3187 Acc: 0.8738\n",
      "Epoch 025 | Train Loss: 0.2756 Acc: 0.8846 | Val Loss: 0.2602 Acc: 0.8919\n",
      "Epoch 026 | Train Loss: 0.2662 Acc: 0.8917 | Val Loss: 0.2677 Acc: 0.8913\n",
      "Epoch 027 | Train Loss: 0.2643 Acc: 0.8865 | Val Loss: 0.2607 Acc: 0.8895\n",
      "Epoch 028 | Train Loss: 0.2608 Acc: 0.8955 | Val Loss: 0.2539 Acc: 0.8986\n",
      "Epoch 029 | Train Loss: 0.2389 Acc: 0.9006 | Val Loss: 0.2631 Acc: 0.8937\n",
      "Epoch 030 | Train Loss: 0.2398 Acc: 0.9049 | Val Loss: 0.2389 Acc: 0.9034\n",
      "Epoch 031 | Train Loss: 0.2352 Acc: 0.9043 | Val Loss: 0.2551 Acc: 0.8955\n",
      "Epoch 032 | Train Loss: 0.2285 Acc: 0.9064 | Val Loss: 0.2372 Acc: 0.9058\n",
      "Epoch 033 | Train Loss: 0.2200 Acc: 0.9094 | Val Loss: 0.2453 Acc: 0.8937\n",
      "Epoch 034 | Train Loss: 0.2095 Acc: 0.9170 | Val Loss: 0.2257 Acc: 0.9070\n",
      "Epoch 035 | Train Loss: 0.1942 Acc: 0.9277 | Val Loss: 0.2289 Acc: 0.9136\n",
      "Epoch 036 | Train Loss: 0.2012 Acc: 0.9207 | Val Loss: 0.2444 Acc: 0.9028\n",
      "Epoch 037 | Train Loss: 0.1966 Acc: 0.9221 | Val Loss: 0.2079 Acc: 0.9143\n",
      "Epoch 038 | Train Loss: 0.1888 Acc: 0.9262 | Val Loss: 0.2171 Acc: 0.9100\n",
      "Epoch 039 | Train Loss: 0.1796 Acc: 0.9296 | Val Loss: 0.2323 Acc: 0.9022\n",
      "Epoch 040 | Train Loss: 0.1848 Acc: 0.9254 | Val Loss: 0.2134 Acc: 0.9173\n",
      "Epoch 041 | Train Loss: 0.1833 Acc: 0.9271 | Val Loss: 0.2270 Acc: 0.9179\n",
      "Epoch 042 | Train Loss: 0.1688 Acc: 0.9367 | Val Loss: 0.1823 Acc: 0.9330\n",
      "Epoch 043 | Train Loss: 0.1619 Acc: 0.9369 | Val Loss: 0.1952 Acc: 0.9191\n",
      "Epoch 044 | Train Loss: 0.1630 Acc: 0.9363 | Val Loss: 0.2018 Acc: 0.9185\n",
      "Epoch 045 | Train Loss: 0.1614 Acc: 0.9376 | Val Loss: 0.1983 Acc: 0.9203\n",
      "Epoch 046 | Train Loss: 0.1569 Acc: 0.9373 | Val Loss: 0.1889 Acc: 0.9324\n",
      "Epoch 047 | Train Loss: 0.1440 Acc: 0.9473 | Val Loss: 0.2059 Acc: 0.9263\n",
      "Epoch 048 | Train Loss: 0.1537 Acc: 0.9385 | Val Loss: 0.1992 Acc: 0.9179\n",
      "Epoch 049 | Train Loss: 0.1462 Acc: 0.9434 | Val Loss: 0.2247 Acc: 0.9197\n",
      "Epoch 050 | Train Loss: 0.1403 Acc: 0.9481 | Val Loss: 0.1816 Acc: 0.9306\n",
      "Epoch 051 | Train Loss: 0.1496 Acc: 0.9407 | Val Loss: 0.1821 Acc: 0.9275\n",
      "Epoch 052 | Train Loss: 0.1351 Acc: 0.9493 | Val Loss: 0.1876 Acc: 0.9275\n",
      "Epoch 053 | Train Loss: 0.1432 Acc: 0.9469 | Val Loss: 0.1795 Acc: 0.9312\n",
      "Epoch 054 | Train Loss: 0.1253 Acc: 0.9508 | Val Loss: 0.1900 Acc: 0.9402\n",
      "Epoch 055 | Train Loss: 0.1263 Acc: 0.9514 | Val Loss: 0.1869 Acc: 0.9312\n",
      "Epoch 056 | Train Loss: 0.1279 Acc: 0.9532 | Val Loss: 0.1781 Acc: 0.9348\n",
      "Epoch 057 | Train Loss: 0.1242 Acc: 0.9532 | Val Loss: 0.1720 Acc: 0.9354\n",
      "Epoch 058 | Train Loss: 0.1284 Acc: 0.9524 | Val Loss: 0.1706 Acc: 0.9306\n",
      "Epoch 059 | Train Loss: 0.1075 Acc: 0.9586 | Val Loss: 0.1603 Acc: 0.9432\n",
      "Epoch 060 | Train Loss: 0.1190 Acc: 0.9570 | Val Loss: 0.2105 Acc: 0.9233\n",
      "Epoch 001 | Train Loss: 0.6793 Acc: 0.5812 | Val Loss: 0.6747 Acc: 0.5936\n",
      "Epoch 002 | Train Loss: 0.6625 Acc: 0.6109 | Val Loss: 0.6372 Acc: 0.6467\n",
      "Epoch 003 | Train Loss: 0.6133 Acc: 0.6767 | Val Loss: 0.5704 Acc: 0.7005\n",
      "Epoch 004 | Train Loss: 0.5610 Acc: 0.7249 | Val Loss: 0.5950 Acc: 0.6914\n",
      "Epoch 005 | Train Loss: 0.5251 Acc: 0.7408 | Val Loss: 0.5209 Acc: 0.7367\n",
      "Epoch 006 | Train Loss: 0.4987 Acc: 0.7580 | Val Loss: 0.4963 Acc: 0.7572\n",
      "Epoch 007 | Train Loss: 0.4722 Acc: 0.7787 | Val Loss: 0.4777 Acc: 0.7609\n",
      "Epoch 008 | Train Loss: 0.4398 Acc: 0.7919 | Val Loss: 0.4332 Acc: 0.7941\n",
      "Epoch 009 | Train Loss: 0.4140 Acc: 0.8128 | Val Loss: 0.3888 Acc: 0.8152\n",
      "Epoch 010 | Train Loss: 0.3920 Acc: 0.8235 | Val Loss: 0.3959 Acc: 0.8152\n",
      "Epoch 011 | Train Loss: 0.3616 Acc: 0.8433 | Val Loss: 0.3464 Acc: 0.8569\n",
      "Epoch 012 | Train Loss: 0.3379 Acc: 0.8585 | Val Loss: 0.3094 Acc: 0.8533\n",
      "Epoch 013 | Train Loss: 0.3005 Acc: 0.8739 | Val Loss: 0.3121 Acc: 0.8629\n",
      "Epoch 014 | Train Loss: 0.2919 Acc: 0.8789 | Val Loss: 0.3135 Acc: 0.8684\n",
      "Epoch 015 | Train Loss: 0.2609 Acc: 0.8936 | Val Loss: 0.3000 Acc: 0.8798\n",
      "Epoch 016 | Train Loss: 0.2605 Acc: 0.8942 | Val Loss: 0.2940 Acc: 0.8762\n",
      "Epoch 017 | Train Loss: 0.2397 Acc: 0.9049 | Val Loss: 0.2602 Acc: 0.8943\n",
      "Epoch 018 | Train Loss: 0.2150 Acc: 0.9157 | Val Loss: 0.2976 Acc: 0.8829\n",
      "Epoch 019 | Train Loss: 0.2089 Acc: 0.9188 | Val Loss: 0.2620 Acc: 0.8973\n",
      "Epoch 020 | Train Loss: 0.2074 Acc: 0.9174 | Val Loss: 0.2160 Acc: 0.9179\n",
      "Epoch 021 | Train Loss: 0.1765 Acc: 0.9340 | Val Loss: 0.2448 Acc: 0.9028\n",
      "Epoch 022 | Train Loss: 0.1694 Acc: 0.9364 | Val Loss: 0.2196 Acc: 0.9173\n",
      "Epoch 023 | Train Loss: 0.1706 Acc: 0.9327 | Val Loss: 0.2202 Acc: 0.9173\n",
      "Epoch 024 | Train Loss: 0.1577 Acc: 0.9404 | Val Loss: 0.2038 Acc: 0.9233\n",
      "Epoch 025 | Train Loss: 0.1487 Acc: 0.9401 | Val Loss: 0.2074 Acc: 0.9233\n",
      "Epoch 026 | Train Loss: 0.1468 Acc: 0.9416 | Val Loss: 0.2092 Acc: 0.9227\n",
      "Epoch 027 | Train Loss: 0.1333 Acc: 0.9497 | Val Loss: 0.1895 Acc: 0.9281\n",
      "Epoch 028 | Train Loss: 0.1360 Acc: 0.9476 | Val Loss: 0.1966 Acc: 0.9312\n",
      "Epoch 029 | Train Loss: 0.1301 Acc: 0.9500 | Val Loss: 0.2003 Acc: 0.9281\n",
      "Epoch 030 | Train Loss: 0.1104 Acc: 0.9586 | Val Loss: 0.2027 Acc: 0.9287\n",
      "Epoch 031 | Train Loss: 0.1205 Acc: 0.9547 | Val Loss: 0.1986 Acc: 0.9239\n",
      "Epoch 032 | Train Loss: 0.1090 Acc: 0.9600 | Val Loss: 0.1802 Acc: 0.9348\n",
      "Epoch 033 | Train Loss: 0.1159 Acc: 0.9582 | Val Loss: 0.1796 Acc: 0.9287\n",
      "Epoch 034 | Train Loss: 0.1029 Acc: 0.9597 | Val Loss: 0.1845 Acc: 0.9360\n",
      "Epoch 035 | Train Loss: 0.1017 Acc: 0.9613 | Val Loss: 0.2253 Acc: 0.9287\n",
      "Epoch 036 | Train Loss: 0.0896 Acc: 0.9681 | Val Loss: 0.1927 Acc: 0.9275\n",
      "Epoch 037 | Train Loss: 0.1035 Acc: 0.9601 | Val Loss: 0.2544 Acc: 0.9076\n",
      "Epoch 038 | Train Loss: 0.0911 Acc: 0.9657 | Val Loss: 0.1759 Acc: 0.9378\n",
      "Epoch 039 | Train Loss: 0.0833 Acc: 0.9700 | Val Loss: 0.1960 Acc: 0.9330\n",
      "Epoch 040 | Train Loss: 0.0883 Acc: 0.9662 | Val Loss: 0.1604 Acc: 0.9444\n",
      "Epoch 041 | Train Loss: 0.0704 Acc: 0.9740 | Val Loss: 0.1981 Acc: 0.9251\n",
      "Epoch 042 | Train Loss: 0.0987 Acc: 0.9636 | Val Loss: 0.1810 Acc: 0.9336\n",
      "Epoch 043 | Train Loss: 0.0699 Acc: 0.9745 | Val Loss: 0.1977 Acc: 0.9318\n",
      "Epoch 044 | Train Loss: 0.0747 Acc: 0.9703 | Val Loss: 0.1796 Acc: 0.9354\n",
      "Epoch 045 | Train Loss: 0.0766 Acc: 0.9728 | Val Loss: 0.1484 Acc: 0.9444\n",
      "Epoch 046 | Train Loss: 0.0720 Acc: 0.9736 | Val Loss: 0.1836 Acc: 0.9432\n",
      "Epoch 047 | Train Loss: 0.0715 Acc: 0.9713 | Val Loss: 0.1619 Acc: 0.9432\n",
      "Epoch 048 | Train Loss: 0.0809 Acc: 0.9721 | Val Loss: 0.1564 Acc: 0.9457\n",
      "Epoch 049 | Train Loss: 0.0645 Acc: 0.9775 | Val Loss: 0.1756 Acc: 0.9432\n",
      "Epoch 050 | Train Loss: 0.0702 Acc: 0.9736 | Val Loss: 0.1722 Acc: 0.9408\n",
      "Epoch 051 | Train Loss: 0.0606 Acc: 0.9780 | Val Loss: 0.1941 Acc: 0.9390\n",
      "Epoch 052 | Train Loss: 0.0633 Acc: 0.9787 | Val Loss: 0.1676 Acc: 0.9384\n",
      "Epoch 053 | Train Loss: 0.0751 Acc: 0.9757 | Val Loss: 0.1654 Acc: 0.9396\n",
      "Epoch 054 | Train Loss: 0.0490 Acc: 0.9828 | Val Loss: 0.2305 Acc: 0.9312\n",
      "Epoch 055 | Train Loss: 0.0710 Acc: 0.9719 | Val Loss: 0.1560 Acc: 0.9408\n",
      "Early stopping triggered.\n",
      "Epoch 001 | Train Loss: 0.6825 Acc: 0.5716 | Val Loss: 0.6790 Acc: 0.5773\n",
      "Epoch 002 | Train Loss: 0.6743 Acc: 0.5938 | Val Loss: 0.6710 Acc: 0.5954\n",
      "Epoch 003 | Train Loss: 0.6447 Acc: 0.6317 | Val Loss: 0.6082 Acc: 0.6715\n",
      "Epoch 004 | Train Loss: 0.5803 Acc: 0.7081 | Val Loss: 0.5602 Acc: 0.7144\n",
      "Epoch 005 | Train Loss: 0.5527 Acc: 0.7252 | Val Loss: 0.5513 Acc: 0.7283\n",
      "Epoch 006 | Train Loss: 0.5315 Acc: 0.7386 | Val Loss: 0.5290 Acc: 0.7379\n",
      "Epoch 007 | Train Loss: 0.5136 Acc: 0.7531 | Val Loss: 0.5031 Acc: 0.7512\n",
      "Epoch 008 | Train Loss: 0.4855 Acc: 0.7709 | Val Loss: 0.4745 Acc: 0.7717\n",
      "Epoch 009 | Train Loss: 0.4603 Acc: 0.7829 | Val Loss: 0.4516 Acc: 0.7880\n",
      "Epoch 010 | Train Loss: 0.4522 Acc: 0.7883 | Val Loss: 0.4584 Acc: 0.7874\n",
      "Epoch 011 | Train Loss: 0.4243 Acc: 0.8036 | Val Loss: 0.4234 Acc: 0.8013\n",
      "Epoch 012 | Train Loss: 0.4099 Acc: 0.8102 | Val Loss: 0.4212 Acc: 0.8037\n",
      "Epoch 013 | Train Loss: 0.3923 Acc: 0.8232 | Val Loss: 0.4301 Acc: 0.7856\n",
      "Epoch 014 | Train Loss: 0.3752 Acc: 0.8357 | Val Loss: 0.3641 Acc: 0.8357\n",
      "Epoch 015 | Train Loss: 0.3545 Acc: 0.8415 | Val Loss: 0.3644 Acc: 0.8273\n",
      "Epoch 016 | Train Loss: 0.3279 Acc: 0.8606 | Val Loss: 0.3313 Acc: 0.8442\n",
      "Epoch 017 | Train Loss: 0.3202 Acc: 0.8585 | Val Loss: 0.3136 Acc: 0.8575\n",
      "Epoch 018 | Train Loss: 0.3097 Acc: 0.8665 | Val Loss: 0.3016 Acc: 0.8708\n",
      "Epoch 019 | Train Loss: 0.2854 Acc: 0.8801 | Val Loss: 0.2902 Acc: 0.8780\n",
      "Epoch 020 | Train Loss: 0.2574 Acc: 0.8904 | Val Loss: 0.2745 Acc: 0.8786\n",
      "Epoch 021 | Train Loss: 0.2477 Acc: 0.8979 | Val Loss: 0.3020 Acc: 0.8629\n",
      "Epoch 022 | Train Loss: 0.2415 Acc: 0.9023 | Val Loss: 0.3098 Acc: 0.8690\n",
      "Epoch 023 | Train Loss: 0.2349 Acc: 0.9023 | Val Loss: 0.2515 Acc: 0.8847\n",
      "Epoch 024 | Train Loss: 0.2261 Acc: 0.9079 | Val Loss: 0.2325 Acc: 0.9010\n",
      "Epoch 025 | Train Loss: 0.2106 Acc: 0.9145 | Val Loss: 0.2468 Acc: 0.8979\n",
      "Epoch 026 | Train Loss: 0.1915 Acc: 0.9248 | Val Loss: 0.2328 Acc: 0.9046\n",
      "Epoch 027 | Train Loss: 0.1941 Acc: 0.9225 | Val Loss: 0.2773 Acc: 0.8877\n",
      "Epoch 028 | Train Loss: 0.1834 Acc: 0.9277 | Val Loss: 0.2100 Acc: 0.9058\n",
      "Epoch 029 | Train Loss: 0.1628 Acc: 0.9355 | Val Loss: 0.2093 Acc: 0.9161\n",
      "Epoch 030 | Train Loss: 0.1486 Acc: 0.9387 | Val Loss: 0.2401 Acc: 0.9088\n",
      "Epoch 031 | Train Loss: 0.1593 Acc: 0.9378 | Val Loss: 0.2693 Acc: 0.8919\n",
      "Epoch 032 | Train Loss: 0.1534 Acc: 0.9401 | Val Loss: 0.2067 Acc: 0.9155\n",
      "Epoch 033 | Train Loss: 0.1492 Acc: 0.9426 | Val Loss: 0.2292 Acc: 0.9052\n",
      "Epoch 034 | Train Loss: 0.1289 Acc: 0.9493 | Val Loss: 0.1999 Acc: 0.9167\n",
      "Epoch 035 | Train Loss: 0.1437 Acc: 0.9425 | Val Loss: 0.1753 Acc: 0.9293\n",
      "Epoch 036 | Train Loss: 0.1313 Acc: 0.9508 | Val Loss: 0.2031 Acc: 0.9191\n",
      "Epoch 037 | Train Loss: 0.1222 Acc: 0.9539 | Val Loss: 0.1854 Acc: 0.9300\n",
      "Epoch 038 | Train Loss: 0.1259 Acc: 0.9520 | Val Loss: 0.1800 Acc: 0.9306\n",
      "Epoch 039 | Train Loss: 0.1218 Acc: 0.9511 | Val Loss: 0.1895 Acc: 0.9287\n",
      "Epoch 040 | Train Loss: 0.1142 Acc: 0.9586 | Val Loss: 0.1886 Acc: 0.9245\n",
      "Epoch 041 | Train Loss: 0.1117 Acc: 0.9574 | Val Loss: 0.1915 Acc: 0.9257\n",
      "Epoch 042 | Train Loss: 0.1161 Acc: 0.9559 | Val Loss: 0.1754 Acc: 0.9330\n",
      "Epoch 043 | Train Loss: 0.1033 Acc: 0.9645 | Val Loss: 0.1997 Acc: 0.9227\n",
      "Epoch 044 | Train Loss: 0.1019 Acc: 0.9610 | Val Loss: 0.1766 Acc: 0.9378\n",
      "Epoch 045 | Train Loss: 0.1033 Acc: 0.9589 | Val Loss: 0.1529 Acc: 0.9390\n",
      "Epoch 046 | Train Loss: 0.0880 Acc: 0.9660 | Val Loss: 0.1714 Acc: 0.9342\n",
      "Epoch 047 | Train Loss: 0.0890 Acc: 0.9671 | Val Loss: 0.1654 Acc: 0.9390\n",
      "Epoch 048 | Train Loss: 0.0936 Acc: 0.9616 | Val Loss: 0.1656 Acc: 0.9372\n",
      "Epoch 049 | Train Loss: 0.0858 Acc: 0.9683 | Val Loss: 0.1867 Acc: 0.9318\n",
      "Epoch 050 | Train Loss: 0.0856 Acc: 0.9674 | Val Loss: 0.2109 Acc: 0.9342\n",
      "Epoch 051 | Train Loss: 0.0963 Acc: 0.9648 | Val Loss: 0.1936 Acc: 0.9287\n",
      "Epoch 052 | Train Loss: 0.0822 Acc: 0.9700 | Val Loss: 0.1811 Acc: 0.9330\n",
      "Epoch 053 | Train Loss: 0.0815 Acc: 0.9686 | Val Loss: 0.1944 Acc: 0.9245\n",
      "Epoch 054 | Train Loss: 0.0819 Acc: 0.9669 | Val Loss: 0.1539 Acc: 0.9438\n",
      "Epoch 055 | Train Loss: 0.0827 Acc: 0.9713 | Val Loss: 0.1605 Acc: 0.9342\n",
      "Early stopping triggered.\n",
      "Iteration 24/40 | Best Val Loss: 0.1122 | Iter Time: 211.11s | Total Time: 100.95 min\n",
      "Epoch 001 | Train Loss: 0.6689 Acc: 0.5929 | Val Loss: 0.6877 Acc: 0.5978\n",
      "Epoch 002 | Train Loss: 0.6206 Acc: 0.6793 | Val Loss: 0.5872 Acc: 0.6890\n",
      "Epoch 003 | Train Loss: 0.5648 Acc: 0.7172 | Val Loss: 0.5370 Acc: 0.7361\n",
      "Epoch 004 | Train Loss: 0.5404 Acc: 0.7376 | Val Loss: 0.5319 Acc: 0.7258\n",
      "Epoch 005 | Train Loss: 0.5090 Acc: 0.7619 | Val Loss: 0.4997 Acc: 0.7566\n",
      "Epoch 006 | Train Loss: 0.4890 Acc: 0.7700 | Val Loss: 0.4820 Acc: 0.7669\n",
      "Epoch 007 | Train Loss: 0.4897 Acc: 0.7675 | Val Loss: 0.4634 Acc: 0.7826\n",
      "Epoch 008 | Train Loss: 0.4562 Acc: 0.7945 | Val Loss: 0.4283 Acc: 0.7941\n",
      "Epoch 009 | Train Loss: 0.4418 Acc: 0.7915 | Val Loss: 0.4148 Acc: 0.7989\n",
      "Epoch 010 | Train Loss: 0.4328 Acc: 0.8010 | Val Loss: 0.4649 Acc: 0.7699\n",
      "Epoch 011 | Train Loss: 0.4044 Acc: 0.8128 | Val Loss: 0.3777 Acc: 0.8122\n",
      "Epoch 012 | Train Loss: 0.3886 Acc: 0.8255 | Val Loss: 0.3655 Acc: 0.8273\n",
      "Epoch 013 | Train Loss: 0.3630 Acc: 0.8363 | Val Loss: 0.3586 Acc: 0.8243\n",
      "Epoch 014 | Train Loss: 0.3538 Acc: 0.8454 | Val Loss: 0.2995 Acc: 0.8653\n",
      "Epoch 015 | Train Loss: 0.3191 Acc: 0.8618 | Val Loss: 0.3043 Acc: 0.8671\n",
      "Epoch 016 | Train Loss: 0.3139 Acc: 0.8671 | Val Loss: 0.3748 Acc: 0.8333\n",
      "Epoch 017 | Train Loss: 0.2916 Acc: 0.8717 | Val Loss: 0.2719 Acc: 0.8804\n",
      "Epoch 018 | Train Loss: 0.2908 Acc: 0.8768 | Val Loss: 0.2508 Acc: 0.8955\n",
      "Epoch 019 | Train Loss: 0.2796 Acc: 0.8827 | Val Loss: 0.2400 Acc: 0.8986\n",
      "Epoch 020 | Train Loss: 0.2522 Acc: 0.8948 | Val Loss: 0.3162 Acc: 0.8605\n",
      "Epoch 021 | Train Loss: 0.2514 Acc: 0.8970 | Val Loss: 0.2762 Acc: 0.8804\n",
      "Epoch 022 | Train Loss: 0.2273 Acc: 0.9087 | Val Loss: 0.2100 Acc: 0.9149\n",
      "Epoch 023 | Train Loss: 0.2216 Acc: 0.9100 | Val Loss: 0.2159 Acc: 0.9106\n",
      "Epoch 024 | Train Loss: 0.2132 Acc: 0.9141 | Val Loss: 0.2302 Acc: 0.9022\n",
      "Epoch 025 | Train Loss: 0.1979 Acc: 0.9213 | Val Loss: 0.2762 Acc: 0.8931\n",
      "Epoch 026 | Train Loss: 0.2139 Acc: 0.9145 | Val Loss: 0.1942 Acc: 0.9239\n",
      "Epoch 027 | Train Loss: 0.1987 Acc: 0.9233 | Val Loss: 0.2587 Acc: 0.8919\n",
      "Epoch 028 | Train Loss: 0.1903 Acc: 0.9251 | Val Loss: 0.2154 Acc: 0.9227\n",
      "Epoch 029 | Train Loss: 0.1732 Acc: 0.9321 | Val Loss: 0.1778 Acc: 0.9312\n",
      "Epoch 030 | Train Loss: 0.1718 Acc: 0.9337 | Val Loss: 0.2298 Acc: 0.9143\n",
      "Epoch 031 | Train Loss: 0.1761 Acc: 0.9295 | Val Loss: 0.1690 Acc: 0.9336\n",
      "Epoch 032 | Train Loss: 0.1639 Acc: 0.9404 | Val Loss: 0.1791 Acc: 0.9336\n",
      "Epoch 033 | Train Loss: 0.1541 Acc: 0.9413 | Val Loss: 0.1681 Acc: 0.9360\n",
      "Epoch 034 | Train Loss: 0.1645 Acc: 0.9379 | Val Loss: 0.1835 Acc: 0.9287\n",
      "Epoch 035 | Train Loss: 0.1489 Acc: 0.9425 | Val Loss: 0.2108 Acc: 0.9203\n",
      "Epoch 036 | Train Loss: 0.1498 Acc: 0.9446 | Val Loss: 0.1669 Acc: 0.9366\n",
      "Epoch 037 | Train Loss: 0.1541 Acc: 0.9381 | Val Loss: 0.1934 Acc: 0.9275\n",
      "Epoch 038 | Train Loss: 0.1397 Acc: 0.9487 | Val Loss: 0.1661 Acc: 0.9360\n",
      "Epoch 039 | Train Loss: 0.1469 Acc: 0.9438 | Val Loss: 0.1646 Acc: 0.9390\n",
      "Epoch 040 | Train Loss: 0.1380 Acc: 0.9464 | Val Loss: 0.1867 Acc: 0.9293\n",
      "Epoch 041 | Train Loss: 0.1327 Acc: 0.9505 | Val Loss: 0.1574 Acc: 0.9444\n",
      "Epoch 042 | Train Loss: 0.1299 Acc: 0.9520 | Val Loss: 0.2033 Acc: 0.9318\n",
      "Epoch 043 | Train Loss: 0.1205 Acc: 0.9570 | Val Loss: 0.1709 Acc: 0.9384\n",
      "Epoch 044 | Train Loss: 0.1189 Acc: 0.9576 | Val Loss: 0.1568 Acc: 0.9420\n",
      "Epoch 045 | Train Loss: 0.1064 Acc: 0.9615 | Val Loss: 0.1449 Acc: 0.9481\n",
      "Epoch 046 | Train Loss: 0.1149 Acc: 0.9597 | Val Loss: 0.1664 Acc: 0.9396\n",
      "Epoch 047 | Train Loss: 0.1180 Acc: 0.9550 | Val Loss: 0.1500 Acc: 0.9463\n",
      "Epoch 048 | Train Loss: 0.1090 Acc: 0.9591 | Val Loss: 0.1537 Acc: 0.9408\n",
      "Epoch 049 | Train Loss: 0.1176 Acc: 0.9547 | Val Loss: 0.1815 Acc: 0.9384\n",
      "Epoch 050 | Train Loss: 0.1130 Acc: 0.9604 | Val Loss: 0.1273 Acc: 0.9505\n",
      "Epoch 051 | Train Loss: 0.1109 Acc: 0.9591 | Val Loss: 0.1528 Acc: 0.9336\n",
      "Epoch 052 | Train Loss: 0.1134 Acc: 0.9562 | Val Loss: 0.1842 Acc: 0.9396\n",
      "Epoch 053 | Train Loss: 0.0998 Acc: 0.9635 | Val Loss: 0.1398 Acc: 0.9457\n",
      "Epoch 054 | Train Loss: 0.1146 Acc: 0.9600 | Val Loss: 0.1352 Acc: 0.9493\n",
      "Epoch 055 | Train Loss: 0.1036 Acc: 0.9610 | Val Loss: 0.1604 Acc: 0.9408\n",
      "Epoch 056 | Train Loss: 0.1128 Acc: 0.9583 | Val Loss: 0.1707 Acc: 0.9348\n",
      "Epoch 057 | Train Loss: 0.0979 Acc: 0.9638 | Val Loss: 0.1536 Acc: 0.9450\n",
      "Epoch 058 | Train Loss: 0.0908 Acc: 0.9683 | Val Loss: 0.1696 Acc: 0.9414\n",
      "Epoch 059 | Train Loss: 0.0919 Acc: 0.9638 | Val Loss: 0.1352 Acc: 0.9517\n",
      "Epoch 060 | Train Loss: 0.0985 Acc: 0.9635 | Val Loss: 0.1368 Acc: 0.9541\n",
      "Early stopping triggered.\n",
      "Epoch 001 | Train Loss: 0.6819 Acc: 0.5765 | Val Loss: 0.6769 Acc: 0.5845\n",
      "Epoch 002 | Train Loss: 0.6765 Acc: 0.5905 | Val Loss: 0.6859 Acc: 0.5628\n",
      "Epoch 003 | Train Loss: 0.6771 Acc: 0.5860 | Val Loss: 0.6817 Acc: 0.5586\n",
      "Epoch 004 | Train Loss: 0.6611 Acc: 0.6133 | Val Loss: 0.6654 Acc: 0.6093\n",
      "Epoch 005 | Train Loss: 0.6542 Acc: 0.6237 | Val Loss: 0.6348 Acc: 0.6510\n",
      "Epoch 006 | Train Loss: 0.6130 Acc: 0.6819 | Val Loss: 0.5721 Acc: 0.7089\n",
      "Epoch 007 | Train Loss: 0.5592 Acc: 0.7279 | Val Loss: 0.5466 Acc: 0.7313\n",
      "Epoch 008 | Train Loss: 0.5415 Acc: 0.7435 | Val Loss: 0.5359 Acc: 0.7379\n",
      "Epoch 009 | Train Loss: 0.5086 Acc: 0.7623 | Val Loss: 0.5074 Acc: 0.7591\n",
      "Epoch 010 | Train Loss: 0.4902 Acc: 0.7709 | Val Loss: 0.5233 Acc: 0.7609\n",
      "Epoch 011 | Train Loss: 0.4581 Acc: 0.7877 | Val Loss: 0.4780 Acc: 0.7814\n",
      "Epoch 012 | Train Loss: 0.4393 Acc: 0.8005 | Val Loss: 0.4244 Acc: 0.8056\n",
      "Epoch 013 | Train Loss: 0.4216 Acc: 0.8101 | Val Loss: 0.4362 Acc: 0.7911\n",
      "Epoch 014 | Train Loss: 0.3921 Acc: 0.8309 | Val Loss: 0.3973 Acc: 0.8207\n",
      "Epoch 015 | Train Loss: 0.3551 Acc: 0.8469 | Val Loss: 0.3851 Acc: 0.8231\n",
      "Epoch 016 | Train Loss: 0.3449 Acc: 0.8538 | Val Loss: 0.3674 Acc: 0.8496\n",
      "Epoch 017 | Train Loss: 0.3159 Acc: 0.8652 | Val Loss: 0.3562 Acc: 0.8490\n",
      "Epoch 018 | Train Loss: 0.2984 Acc: 0.8751 | Val Loss: 0.3195 Acc: 0.8653\n",
      "Epoch 019 | Train Loss: 0.2839 Acc: 0.8801 | Val Loss: 0.3276 Acc: 0.8671\n",
      "Epoch 020 | Train Loss: 0.2702 Acc: 0.8869 | Val Loss: 0.3030 Acc: 0.8744\n",
      "Epoch 021 | Train Loss: 0.2491 Acc: 0.8970 | Val Loss: 0.3176 Acc: 0.8702\n",
      "Epoch 022 | Train Loss: 0.2397 Acc: 0.9034 | Val Loss: 0.2782 Acc: 0.8889\n",
      "Epoch 023 | Train Loss: 0.2121 Acc: 0.9168 | Val Loss: 0.2760 Acc: 0.8895\n",
      "Epoch 024 | Train Loss: 0.2056 Acc: 0.9186 | Val Loss: 0.2660 Acc: 0.9028\n",
      "Epoch 025 | Train Loss: 0.1890 Acc: 0.9287 | Val Loss: 0.2733 Acc: 0.8913\n",
      "Epoch 026 | Train Loss: 0.1800 Acc: 0.9278 | Val Loss: 0.2713 Acc: 0.9004\n",
      "Epoch 027 | Train Loss: 0.1674 Acc: 0.9379 | Val Loss: 0.2653 Acc: 0.9016\n",
      "Epoch 028 | Train Loss: 0.1738 Acc: 0.9336 | Val Loss: 0.2814 Acc: 0.9022\n",
      "Epoch 029 | Train Loss: 0.1609 Acc: 0.9411 | Val Loss: 0.2520 Acc: 0.8998\n",
      "Epoch 030 | Train Loss: 0.1588 Acc: 0.9382 | Val Loss: 0.3240 Acc: 0.8877\n",
      "Epoch 031 | Train Loss: 0.1501 Acc: 0.9411 | Val Loss: 0.2205 Acc: 0.9155\n",
      "Epoch 032 | Train Loss: 0.1370 Acc: 0.9467 | Val Loss: 0.2500 Acc: 0.9112\n",
      "Epoch 033 | Train Loss: 0.1330 Acc: 0.9503 | Val Loss: 0.2538 Acc: 0.9118\n",
      "Epoch 034 | Train Loss: 0.1260 Acc: 0.9533 | Val Loss: 0.2207 Acc: 0.9185\n",
      "Epoch 035 | Train Loss: 0.1209 Acc: 0.9532 | Val Loss: 0.2470 Acc: 0.9239\n",
      "Epoch 036 | Train Loss: 0.1234 Acc: 0.9511 | Val Loss: 0.2179 Acc: 0.9179\n",
      "Epoch 037 | Train Loss: 0.1119 Acc: 0.9553 | Val Loss: 0.2245 Acc: 0.9185\n",
      "Epoch 038 | Train Loss: 0.1110 Acc: 0.9553 | Val Loss: 0.2118 Acc: 0.9179\n",
      "Epoch 039 | Train Loss: 0.0959 Acc: 0.9633 | Val Loss: 0.2358 Acc: 0.9203\n",
      "Epoch 040 | Train Loss: 0.0920 Acc: 0.9645 | Val Loss: 0.2453 Acc: 0.9167\n",
      "Epoch 041 | Train Loss: 0.1002 Acc: 0.9632 | Val Loss: 0.2168 Acc: 0.9239\n",
      "Epoch 042 | Train Loss: 0.0943 Acc: 0.9654 | Val Loss: 0.2033 Acc: 0.9209\n",
      "Epoch 043 | Train Loss: 0.0907 Acc: 0.9703 | Val Loss: 0.2398 Acc: 0.9221\n",
      "Epoch 044 | Train Loss: 0.0869 Acc: 0.9657 | Val Loss: 0.2457 Acc: 0.9179\n",
      "Epoch 045 | Train Loss: 0.0810 Acc: 0.9712 | Val Loss: 0.1867 Acc: 0.9366\n",
      "Epoch 046 | Train Loss: 0.0897 Acc: 0.9689 | Val Loss: 0.2225 Acc: 0.9215\n",
      "Epoch 047 | Train Loss: 0.0793 Acc: 0.9706 | Val Loss: 0.2395 Acc: 0.9300\n",
      "Epoch 048 | Train Loss: 0.0860 Acc: 0.9681 | Val Loss: 0.2496 Acc: 0.9203\n",
      "Epoch 049 | Train Loss: 0.0741 Acc: 0.9728 | Val Loss: 0.1971 Acc: 0.9342\n",
      "Epoch 050 | Train Loss: 0.0753 Acc: 0.9712 | Val Loss: 0.2142 Acc: 0.9179\n",
      "Epoch 051 | Train Loss: 0.0765 Acc: 0.9719 | Val Loss: 0.2040 Acc: 0.9233\n",
      "Epoch 052 | Train Loss: 0.0788 Acc: 0.9718 | Val Loss: 0.2048 Acc: 0.9281\n",
      "Epoch 053 | Train Loss: 0.0734 Acc: 0.9733 | Val Loss: 0.1827 Acc: 0.9378\n",
      "Epoch 054 | Train Loss: 0.0720 Acc: 0.9731 | Val Loss: 0.1935 Acc: 0.9354\n",
      "Epoch 055 | Train Loss: 0.0657 Acc: 0.9758 | Val Loss: 0.2190 Acc: 0.9372\n",
      "Epoch 056 | Train Loss: 0.0706 Acc: 0.9743 | Val Loss: 0.2163 Acc: 0.9324\n",
      "Epoch 057 | Train Loss: 0.0646 Acc: 0.9775 | Val Loss: 0.2281 Acc: 0.9300\n",
      "Epoch 058 | Train Loss: 0.0726 Acc: 0.9722 | Val Loss: 0.2349 Acc: 0.9287\n",
      "Epoch 059 | Train Loss: 0.0610 Acc: 0.9774 | Val Loss: 0.2614 Acc: 0.9179\n",
      "Epoch 060 | Train Loss: 0.0768 Acc: 0.9713 | Val Loss: 0.2218 Acc: 0.9245\n",
      "Epoch 001 | Train Loss: 0.6828 Acc: 0.5742 | Val Loss: 0.6747 Acc: 0.5839\n",
      "Epoch 002 | Train Loss: 0.6785 Acc: 0.5816 | Val Loss: 0.6802 Acc: 0.5749\n",
      "Epoch 003 | Train Loss: 0.6693 Acc: 0.5946 | Val Loss: 0.6586 Acc: 0.6111\n",
      "Epoch 004 | Train Loss: 0.6291 Acc: 0.6524 | Val Loss: 0.5808 Acc: 0.7114\n",
      "Epoch 005 | Train Loss: 0.5636 Acc: 0.7238 | Val Loss: 0.5406 Acc: 0.7222\n",
      "Epoch 006 | Train Loss: 0.5390 Acc: 0.7368 | Val Loss: 0.5250 Acc: 0.7415\n",
      "Epoch 007 | Train Loss: 0.5181 Acc: 0.7525 | Val Loss: 0.5053 Acc: 0.7500\n",
      "Epoch 008 | Train Loss: 0.4971 Acc: 0.7681 | Val Loss: 0.4837 Acc: 0.7669\n",
      "Epoch 009 | Train Loss: 0.4828 Acc: 0.7759 | Val Loss: 0.4948 Acc: 0.7633\n",
      "Epoch 010 | Train Loss: 0.4493 Acc: 0.7928 | Val Loss: 0.4448 Acc: 0.7868\n",
      "Epoch 011 | Train Loss: 0.4314 Acc: 0.8021 | Val Loss: 0.4183 Acc: 0.8001\n",
      "Epoch 012 | Train Loss: 0.4063 Acc: 0.8144 | Val Loss: 0.3981 Acc: 0.8140\n",
      "Epoch 013 | Train Loss: 0.3915 Acc: 0.8289 | Val Loss: 0.3718 Acc: 0.8285\n",
      "Epoch 014 | Train Loss: 0.3506 Acc: 0.8483 | Val Loss: 0.3783 Acc: 0.8333\n",
      "Epoch 015 | Train Loss: 0.3392 Acc: 0.8520 | Val Loss: 0.3192 Acc: 0.8527\n",
      "Epoch 016 | Train Loss: 0.3121 Acc: 0.8683 | Val Loss: 0.3012 Acc: 0.8641\n",
      "Epoch 017 | Train Loss: 0.3055 Acc: 0.8688 | Val Loss: 0.3004 Acc: 0.8690\n",
      "Epoch 018 | Train Loss: 0.2911 Acc: 0.8830 | Val Loss: 0.2595 Acc: 0.8913\n",
      "Epoch 019 | Train Loss: 0.2786 Acc: 0.8857 | Val Loss: 0.2552 Acc: 0.8925\n",
      "Epoch 020 | Train Loss: 0.2625 Acc: 0.8954 | Val Loss: 0.2756 Acc: 0.8853\n",
      "Epoch 021 | Train Loss: 0.2480 Acc: 0.8990 | Val Loss: 0.2356 Acc: 0.9010\n",
      "Epoch 022 | Train Loss: 0.2367 Acc: 0.9011 | Val Loss: 0.2416 Acc: 0.8967\n",
      "Epoch 023 | Train Loss: 0.2307 Acc: 0.9070 | Val Loss: 0.2233 Acc: 0.9076\n",
      "Epoch 024 | Train Loss: 0.2211 Acc: 0.9090 | Val Loss: 0.2131 Acc: 0.9118\n",
      "Epoch 025 | Train Loss: 0.2165 Acc: 0.9126 | Val Loss: 0.2082 Acc: 0.9185\n",
      "Epoch 026 | Train Loss: 0.1985 Acc: 0.9204 | Val Loss: 0.2213 Acc: 0.9058\n",
      "Epoch 027 | Train Loss: 0.2036 Acc: 0.9200 | Val Loss: 0.1924 Acc: 0.9215\n",
      "Epoch 028 | Train Loss: 0.1906 Acc: 0.9239 | Val Loss: 0.2324 Acc: 0.9028\n",
      "Epoch 029 | Train Loss: 0.1892 Acc: 0.9260 | Val Loss: 0.2193 Acc: 0.9167\n",
      "Epoch 030 | Train Loss: 0.1797 Acc: 0.9311 | Val Loss: 0.2053 Acc: 0.9179\n",
      "Epoch 031 | Train Loss: 0.1634 Acc: 0.9364 | Val Loss: 0.1806 Acc: 0.9312\n",
      "Epoch 032 | Train Loss: 0.1676 Acc: 0.9367 | Val Loss: 0.1850 Acc: 0.9179\n",
      "Epoch 033 | Train Loss: 0.1523 Acc: 0.9408 | Val Loss: 0.1788 Acc: 0.9312\n",
      "Epoch 034 | Train Loss: 0.1560 Acc: 0.9399 | Val Loss: 0.1847 Acc: 0.9263\n",
      "Epoch 035 | Train Loss: 0.1518 Acc: 0.9405 | Val Loss: 0.1873 Acc: 0.9209\n",
      "Epoch 036 | Train Loss: 0.1416 Acc: 0.9414 | Val Loss: 0.1849 Acc: 0.9281\n",
      "Epoch 037 | Train Loss: 0.1423 Acc: 0.9431 | Val Loss: 0.1977 Acc: 0.9215\n",
      "Epoch 038 | Train Loss: 0.1378 Acc: 0.9475 | Val Loss: 0.1886 Acc: 0.9300\n",
      "Epoch 039 | Train Loss: 0.1310 Acc: 0.9490 | Val Loss: 0.1764 Acc: 0.9372\n",
      "Epoch 040 | Train Loss: 0.1304 Acc: 0.9499 | Val Loss: 0.2019 Acc: 0.9203\n",
      "Epoch 041 | Train Loss: 0.1282 Acc: 0.9502 | Val Loss: 0.1772 Acc: 0.9342\n",
      "Epoch 042 | Train Loss: 0.1267 Acc: 0.9514 | Val Loss: 0.1729 Acc: 0.9360\n",
      "Epoch 043 | Train Loss: 0.1134 Acc: 0.9565 | Val Loss: 0.1605 Acc: 0.9396\n",
      "Epoch 044 | Train Loss: 0.1094 Acc: 0.9561 | Val Loss: 0.1537 Acc: 0.9396\n",
      "Epoch 045 | Train Loss: 0.1134 Acc: 0.9549 | Val Loss: 0.1650 Acc: 0.9342\n",
      "Epoch 046 | Train Loss: 0.1123 Acc: 0.9571 | Val Loss: 0.1909 Acc: 0.9293\n",
      "Epoch 047 | Train Loss: 0.1128 Acc: 0.9541 | Val Loss: 0.1641 Acc: 0.9324\n",
      "Epoch 048 | Train Loss: 0.1021 Acc: 0.9610 | Val Loss: 0.1514 Acc: 0.9414\n",
      "Epoch 049 | Train Loss: 0.1129 Acc: 0.9562 | Val Loss: 0.1608 Acc: 0.9378\n",
      "Epoch 050 | Train Loss: 0.1034 Acc: 0.9574 | Val Loss: 0.1513 Acc: 0.9463\n",
      "Epoch 051 | Train Loss: 0.1117 Acc: 0.9552 | Val Loss: 0.1761 Acc: 0.9360\n",
      "Epoch 052 | Train Loss: 0.1035 Acc: 0.9623 | Val Loss: 0.1397 Acc: 0.9420\n",
      "Epoch 053 | Train Loss: 0.1012 Acc: 0.9613 | Val Loss: 0.1303 Acc: 0.9481\n",
      "Epoch 054 | Train Loss: 0.0964 Acc: 0.9636 | Val Loss: 0.1715 Acc: 0.9360\n",
      "Epoch 055 | Train Loss: 0.1014 Acc: 0.9623 | Val Loss: 0.1352 Acc: 0.9487\n",
      "Epoch 056 | Train Loss: 0.0908 Acc: 0.9650 | Val Loss: 0.1278 Acc: 0.9559\n",
      "Epoch 057 | Train Loss: 0.0960 Acc: 0.9651 | Val Loss: 0.1358 Acc: 0.9432\n",
      "Epoch 058 | Train Loss: 0.0978 Acc: 0.9642 | Val Loss: 0.1346 Acc: 0.9517\n",
      "Epoch 059 | Train Loss: 0.0952 Acc: 0.9644 | Val Loss: 0.1576 Acc: 0.9463\n",
      "Epoch 060 | Train Loss: 0.0952 Acc: 0.9647 | Val Loss: 0.1344 Acc: 0.9420\n",
      "Epoch 001 | Train Loss: 0.6831 Acc: 0.5686 | Val Loss: 0.6800 Acc: 0.5845\n",
      "Epoch 002 | Train Loss: 0.6729 Acc: 0.5938 | Val Loss: 0.6573 Acc: 0.6051\n",
      "Epoch 003 | Train Loss: 0.6447 Acc: 0.6435 | Val Loss: 0.6387 Acc: 0.6534\n",
      "Epoch 004 | Train Loss: 0.6160 Acc: 0.6779 | Val Loss: 0.6044 Acc: 0.6800\n",
      "Epoch 005 | Train Loss: 0.5882 Acc: 0.7045 | Val Loss: 0.5751 Acc: 0.6993\n",
      "Epoch 006 | Train Loss: 0.5727 Acc: 0.7136 | Val Loss: 0.5706 Acc: 0.7132\n",
      "Epoch 007 | Train Loss: 0.5529 Acc: 0.7261 | Val Loss: 0.5610 Acc: 0.7168\n",
      "Epoch 008 | Train Loss: 0.5421 Acc: 0.7321 | Val Loss: 0.5489 Acc: 0.7144\n",
      "Epoch 009 | Train Loss: 0.5299 Acc: 0.7391 | Val Loss: 0.5467 Acc: 0.7204\n",
      "Epoch 010 | Train Loss: 0.5240 Acc: 0.7438 | Val Loss: 0.5117 Acc: 0.7440\n",
      "Epoch 011 | Train Loss: 0.5011 Acc: 0.7525 | Val Loss: 0.5089 Acc: 0.7585\n",
      "Epoch 012 | Train Loss: 0.4909 Acc: 0.7651 | Val Loss: 0.4702 Acc: 0.7736\n",
      "Epoch 013 | Train Loss: 0.4594 Acc: 0.7853 | Val Loss: 0.4406 Acc: 0.7929\n",
      "Epoch 014 | Train Loss: 0.4370 Acc: 0.7906 | Val Loss: 0.4256 Acc: 0.7893\n",
      "Epoch 015 | Train Loss: 0.4081 Acc: 0.8117 | Val Loss: 0.4010 Acc: 0.8086\n",
      "Epoch 016 | Train Loss: 0.3960 Acc: 0.8224 | Val Loss: 0.3821 Acc: 0.8309\n",
      "Epoch 017 | Train Loss: 0.3658 Acc: 0.8381 | Val Loss: 0.3592 Acc: 0.8364\n",
      "Epoch 018 | Train Loss: 0.3394 Acc: 0.8576 | Val Loss: 0.3069 Acc: 0.8647\n",
      "Epoch 019 | Train Loss: 0.3195 Acc: 0.8638 | Val Loss: 0.3292 Acc: 0.8563\n",
      "Epoch 020 | Train Loss: 0.3037 Acc: 0.8688 | Val Loss: 0.3170 Acc: 0.8629\n",
      "Epoch 021 | Train Loss: 0.2910 Acc: 0.8794 | Val Loss: 0.2959 Acc: 0.8853\n",
      "Epoch 022 | Train Loss: 0.2677 Acc: 0.8929 | Val Loss: 0.2782 Acc: 0.8835\n",
      "Epoch 023 | Train Loss: 0.2678 Acc: 0.8875 | Val Loss: 0.2888 Acc: 0.8786\n",
      "Epoch 024 | Train Loss: 0.2476 Acc: 0.9008 | Val Loss: 0.2513 Acc: 0.9010\n",
      "Epoch 025 | Train Loss: 0.2375 Acc: 0.9035 | Val Loss: 0.2833 Acc: 0.8804\n",
      "Epoch 026 | Train Loss: 0.2226 Acc: 0.9124 | Val Loss: 0.2415 Acc: 0.9028\n",
      "Epoch 027 | Train Loss: 0.2112 Acc: 0.9198 | Val Loss: 0.2273 Acc: 0.9100\n",
      "Epoch 028 | Train Loss: 0.1928 Acc: 0.9222 | Val Loss: 0.2050 Acc: 0.9257\n",
      "Epoch 029 | Train Loss: 0.1872 Acc: 0.9260 | Val Loss: 0.2340 Acc: 0.9149\n",
      "Epoch 030 | Train Loss: 0.1850 Acc: 0.9293 | Val Loss: 0.2307 Acc: 0.9088\n",
      "Epoch 031 | Train Loss: 0.1736 Acc: 0.9352 | Val Loss: 0.2303 Acc: 0.9155\n",
      "Epoch 032 | Train Loss: 0.1743 Acc: 0.9346 | Val Loss: 0.2406 Acc: 0.9112\n",
      "Epoch 033 | Train Loss: 0.1762 Acc: 0.9287 | Val Loss: 0.2020 Acc: 0.9197\n",
      "Epoch 034 | Train Loss: 0.1652 Acc: 0.9369 | Val Loss: 0.1794 Acc: 0.9336\n",
      "Epoch 035 | Train Loss: 0.1456 Acc: 0.9488 | Val Loss: 0.1801 Acc: 0.9348\n",
      "Epoch 036 | Train Loss: 0.1331 Acc: 0.9511 | Val Loss: 0.1838 Acc: 0.9330\n",
      "Epoch 037 | Train Loss: 0.1422 Acc: 0.9453 | Val Loss: 0.1606 Acc: 0.9354\n",
      "Epoch 038 | Train Loss: 0.1484 Acc: 0.9428 | Val Loss: 0.1590 Acc: 0.9402\n",
      "Epoch 039 | Train Loss: 0.1345 Acc: 0.9476 | Val Loss: 0.1795 Acc: 0.9324\n",
      "Epoch 040 | Train Loss: 0.1307 Acc: 0.9517 | Val Loss: 0.1755 Acc: 0.9384\n",
      "Epoch 041 | Train Loss: 0.1298 Acc: 0.9508 | Val Loss: 0.1548 Acc: 0.9432\n",
      "Epoch 042 | Train Loss: 0.1127 Acc: 0.9588 | Val Loss: 0.1662 Acc: 0.9408\n",
      "Epoch 043 | Train Loss: 0.1227 Acc: 0.9546 | Val Loss: 0.1804 Acc: 0.9312\n",
      "Epoch 044 | Train Loss: 0.1199 Acc: 0.9567 | Val Loss: 0.1969 Acc: 0.9312\n",
      "Epoch 045 | Train Loss: 0.1132 Acc: 0.9597 | Val Loss: 0.1852 Acc: 0.9318\n",
      "Epoch 046 | Train Loss: 0.1205 Acc: 0.9538 | Val Loss: 0.1377 Acc: 0.9450\n",
      "Epoch 047 | Train Loss: 0.0931 Acc: 0.9657 | Val Loss: 0.1426 Acc: 0.9487\n",
      "Epoch 048 | Train Loss: 0.0996 Acc: 0.9630 | Val Loss: 0.1372 Acc: 0.9517\n",
      "Epoch 049 | Train Loss: 0.0916 Acc: 0.9663 | Val Loss: 0.1877 Acc: 0.9408\n",
      "Epoch 050 | Train Loss: 0.0880 Acc: 0.9669 | Val Loss: 0.1593 Acc: 0.9457\n",
      "Epoch 051 | Train Loss: 0.0982 Acc: 0.9644 | Val Loss: 0.1453 Acc: 0.9499\n",
      "Epoch 052 | Train Loss: 0.0961 Acc: 0.9656 | Val Loss: 0.1437 Acc: 0.9481\n",
      "Epoch 053 | Train Loss: 0.0985 Acc: 0.9650 | Val Loss: 0.1415 Acc: 0.9457\n",
      "Epoch 054 | Train Loss: 0.0821 Acc: 0.9692 | Val Loss: 0.1742 Acc: 0.9408\n",
      "Epoch 055 | Train Loss: 0.1032 Acc: 0.9641 | Val Loss: 0.1657 Acc: 0.9348\n",
      "Epoch 056 | Train Loss: 0.1000 Acc: 0.9618 | Val Loss: 0.1433 Acc: 0.9444\n",
      "Epoch 057 | Train Loss: 0.0821 Acc: 0.9693 | Val Loss: 0.1631 Acc: 0.9523\n",
      "Epoch 058 | Train Loss: 0.0889 Acc: 0.9660 | Val Loss: 0.1471 Acc: 0.9487\n",
      "Early stopping triggered.\n",
      "Epoch 001 | Train Loss: 0.6797 Acc: 0.5778 | Val Loss: 0.6762 Acc: 0.5821\n",
      "Epoch 002 | Train Loss: 0.6702 Acc: 0.5984 | Val Loss: 0.6602 Acc: 0.6045\n",
      "Epoch 003 | Train Loss: 0.6452 Acc: 0.6352 | Val Loss: 0.6313 Acc: 0.6630\n",
      "Epoch 004 | Train Loss: 0.6076 Acc: 0.6875 | Val Loss: 0.5760 Acc: 0.7041\n",
      "Epoch 005 | Train Loss: 0.5660 Acc: 0.7110 | Val Loss: 0.5854 Acc: 0.7089\n",
      "Epoch 006 | Train Loss: 0.5354 Acc: 0.7346 | Val Loss: 0.5330 Acc: 0.7373\n",
      "Epoch 007 | Train Loss: 0.5132 Acc: 0.7522 | Val Loss: 0.5077 Acc: 0.7585\n",
      "Epoch 008 | Train Loss: 0.4952 Acc: 0.7649 | Val Loss: 0.4847 Acc: 0.7742\n",
      "Epoch 009 | Train Loss: 0.4796 Acc: 0.7773 | Val Loss: 0.5116 Acc: 0.7633\n",
      "Epoch 010 | Train Loss: 0.4608 Acc: 0.7864 | Val Loss: 0.4613 Acc: 0.7826\n",
      "Epoch 011 | Train Loss: 0.4340 Acc: 0.7975 | Val Loss: 0.5125 Acc: 0.7488\n",
      "Epoch 012 | Train Loss: 0.4061 Acc: 0.8178 | Val Loss: 0.4010 Acc: 0.8098\n",
      "Epoch 013 | Train Loss: 0.3843 Acc: 0.8268 | Val Loss: 0.3809 Acc: 0.8200\n",
      "Epoch 014 | Train Loss: 0.3696 Acc: 0.8389 | Val Loss: 0.3627 Acc: 0.8388\n",
      "Epoch 015 | Train Loss: 0.3433 Acc: 0.8532 | Val Loss: 0.3769 Acc: 0.8279\n",
      "Epoch 016 | Train Loss: 0.3424 Acc: 0.8502 | Val Loss: 0.3169 Acc: 0.8593\n",
      "Epoch 017 | Train Loss: 0.3065 Acc: 0.8635 | Val Loss: 0.3345 Acc: 0.8436\n",
      "Epoch 018 | Train Loss: 0.2920 Acc: 0.8786 | Val Loss: 0.3032 Acc: 0.8617\n",
      "Epoch 019 | Train Loss: 0.2764 Acc: 0.8813 | Val Loss: 0.2700 Acc: 0.8853\n",
      "Epoch 020 | Train Loss: 0.2619 Acc: 0.8871 | Val Loss: 0.2905 Acc: 0.8726\n",
      "Epoch 021 | Train Loss: 0.2538 Acc: 0.8976 | Val Loss: 0.2800 Acc: 0.8816\n",
      "Epoch 022 | Train Loss: 0.2370 Acc: 0.9071 | Val Loss: 0.2953 Acc: 0.8859\n",
      "Epoch 023 | Train Loss: 0.2317 Acc: 0.9052 | Val Loss: 0.2988 Acc: 0.8696\n",
      "Epoch 024 | Train Loss: 0.2299 Acc: 0.9065 | Val Loss: 0.2457 Acc: 0.8961\n",
      "Epoch 025 | Train Loss: 0.2052 Acc: 0.9203 | Val Loss: 0.2445 Acc: 0.9052\n",
      "Epoch 026 | Train Loss: 0.1971 Acc: 0.9212 | Val Loss: 0.2507 Acc: 0.9028\n",
      "Epoch 027 | Train Loss: 0.1858 Acc: 0.9256 | Val Loss: 0.2211 Acc: 0.9124\n",
      "Epoch 028 | Train Loss: 0.1874 Acc: 0.9268 | Val Loss: 0.2199 Acc: 0.9130\n",
      "Epoch 029 | Train Loss: 0.1764 Acc: 0.9281 | Val Loss: 0.2127 Acc: 0.9155\n",
      "Epoch 030 | Train Loss: 0.1661 Acc: 0.9324 | Val Loss: 0.2279 Acc: 0.9161\n",
      "Epoch 031 | Train Loss: 0.1618 Acc: 0.9396 | Val Loss: 0.2652 Acc: 0.8961\n",
      "Epoch 032 | Train Loss: 0.1552 Acc: 0.9381 | Val Loss: 0.2192 Acc: 0.9191\n",
      "Epoch 033 | Train Loss: 0.1495 Acc: 0.9423 | Val Loss: 0.2015 Acc: 0.9209\n",
      "Epoch 034 | Train Loss: 0.1404 Acc: 0.9422 | Val Loss: 0.2248 Acc: 0.9046\n",
      "Epoch 035 | Train Loss: 0.1438 Acc: 0.9459 | Val Loss: 0.1995 Acc: 0.9209\n",
      "Epoch 036 | Train Loss: 0.1402 Acc: 0.9458 | Val Loss: 0.1780 Acc: 0.9336\n",
      "Epoch 037 | Train Loss: 0.1345 Acc: 0.9473 | Val Loss: 0.2421 Acc: 0.9082\n",
      "Epoch 038 | Train Loss: 0.1274 Acc: 0.9484 | Val Loss: 0.2134 Acc: 0.9185\n",
      "Epoch 039 | Train Loss: 0.1265 Acc: 0.9503 | Val Loss: 0.2354 Acc: 0.9022\n",
      "Epoch 040 | Train Loss: 0.1195 Acc: 0.9520 | Val Loss: 0.1719 Acc: 0.9354\n",
      "Epoch 041 | Train Loss: 0.1191 Acc: 0.9573 | Val Loss: 0.1789 Acc: 0.9245\n",
      "Epoch 042 | Train Loss: 0.1090 Acc: 0.9591 | Val Loss: 0.1967 Acc: 0.9257\n",
      "Epoch 043 | Train Loss: 0.1064 Acc: 0.9604 | Val Loss: 0.1669 Acc: 0.9390\n",
      "Epoch 044 | Train Loss: 0.1118 Acc: 0.9565 | Val Loss: 0.1665 Acc: 0.9372\n",
      "Epoch 045 | Train Loss: 0.0985 Acc: 0.9623 | Val Loss: 0.1869 Acc: 0.9330\n",
      "Epoch 046 | Train Loss: 0.0996 Acc: 0.9636 | Val Loss: 0.1701 Acc: 0.9390\n",
      "Epoch 047 | Train Loss: 0.0941 Acc: 0.9642 | Val Loss: 0.1843 Acc: 0.9336\n",
      "Epoch 048 | Train Loss: 0.1001 Acc: 0.9618 | Val Loss: 0.1558 Acc: 0.9469\n",
      "Epoch 049 | Train Loss: 0.1031 Acc: 0.9594 | Val Loss: 0.1819 Acc: 0.9414\n",
      "Epoch 050 | Train Loss: 0.0962 Acc: 0.9627 | Val Loss: 0.1856 Acc: 0.9330\n",
      "Epoch 051 | Train Loss: 0.0937 Acc: 0.9641 | Val Loss: 0.1670 Acc: 0.9414\n",
      "Epoch 052 | Train Loss: 0.0846 Acc: 0.9672 | Val Loss: 0.2119 Acc: 0.9263\n",
      "Epoch 053 | Train Loss: 0.0917 Acc: 0.9657 | Val Loss: 0.1694 Acc: 0.9384\n",
      "Epoch 054 | Train Loss: 0.0940 Acc: 0.9644 | Val Loss: 0.1539 Acc: 0.9384\n",
      "Epoch 055 | Train Loss: 0.0858 Acc: 0.9686 | Val Loss: 0.1788 Acc: 0.9390\n",
      "Epoch 056 | Train Loss: 0.0865 Acc: 0.9697 | Val Loss: 0.1909 Acc: 0.9384\n",
      "Epoch 057 | Train Loss: 0.0785 Acc: 0.9709 | Val Loss: 0.1990 Acc: 0.9342\n",
      "Epoch 058 | Train Loss: 0.0822 Acc: 0.9695 | Val Loss: 0.1936 Acc: 0.9360\n",
      "Epoch 059 | Train Loss: 0.0829 Acc: 0.9689 | Val Loss: 0.1846 Acc: 0.9348\n",
      "Epoch 060 | Train Loss: 0.0755 Acc: 0.9722 | Val Loss: 0.1590 Acc: 0.9438\n",
      "Epoch 001 | Train Loss: 0.6815 Acc: 0.5750 | Val Loss: 0.6746 Acc: 0.5918\n",
      "Epoch 002 | Train Loss: 0.6730 Acc: 0.5925 | Val Loss: 0.6704 Acc: 0.5996\n",
      "Epoch 003 | Train Loss: 0.6551 Acc: 0.6180 | Val Loss: 0.6269 Acc: 0.6661\n",
      "Epoch 004 | Train Loss: 0.6211 Acc: 0.6698 | Val Loss: 0.6091 Acc: 0.6890\n",
      "Epoch 005 | Train Loss: 0.5825 Acc: 0.7050 | Val Loss: 0.5752 Acc: 0.7035\n",
      "Epoch 006 | Train Loss: 0.5729 Acc: 0.7107 | Val Loss: 0.5596 Acc: 0.7234\n",
      "Epoch 007 | Train Loss: 0.5464 Acc: 0.7308 | Val Loss: 0.5562 Acc: 0.7180\n",
      "Epoch 008 | Train Loss: 0.5319 Acc: 0.7412 | Val Loss: 0.5353 Acc: 0.7222\n",
      "Epoch 009 | Train Loss: 0.5140 Acc: 0.7515 | Val Loss: 0.5197 Acc: 0.7343\n",
      "Epoch 010 | Train Loss: 0.5107 Acc: 0.7534 | Val Loss: 0.5110 Acc: 0.7403\n",
      "Epoch 011 | Train Loss: 0.4847 Acc: 0.7759 | Val Loss: 0.4916 Acc: 0.7554\n",
      "Epoch 012 | Train Loss: 0.4694 Acc: 0.7811 | Val Loss: 0.4817 Acc: 0.7669\n",
      "Epoch 013 | Train Loss: 0.4500 Acc: 0.7860 | Val Loss: 0.4464 Acc: 0.7838\n",
      "Epoch 014 | Train Loss: 0.4386 Acc: 0.7963 | Val Loss: 0.4245 Acc: 0.7965\n",
      "Epoch 015 | Train Loss: 0.4178 Acc: 0.8113 | Val Loss: 0.4180 Acc: 0.8001\n",
      "Epoch 016 | Train Loss: 0.4020 Acc: 0.8176 | Val Loss: 0.4084 Acc: 0.8110\n",
      "Epoch 017 | Train Loss: 0.3836 Acc: 0.8303 | Val Loss: 0.3732 Acc: 0.8315\n",
      "Epoch 018 | Train Loss: 0.3613 Acc: 0.8440 | Val Loss: 0.3630 Acc: 0.8345\n",
      "Epoch 019 | Train Loss: 0.3500 Acc: 0.8489 | Val Loss: 0.3405 Acc: 0.8478\n",
      "Epoch 020 | Train Loss: 0.3391 Acc: 0.8535 | Val Loss: 0.3196 Acc: 0.8623\n",
      "Epoch 021 | Train Loss: 0.3212 Acc: 0.8609 | Val Loss: 0.3081 Acc: 0.8665\n",
      "Epoch 022 | Train Loss: 0.3110 Acc: 0.8700 | Val Loss: 0.3522 Acc: 0.8424\n",
      "Epoch 023 | Train Loss: 0.2913 Acc: 0.8771 | Val Loss: 0.3687 Acc: 0.8394\n",
      "Epoch 024 | Train Loss: 0.2880 Acc: 0.8845 | Val Loss: 0.2976 Acc: 0.8708\n",
      "Epoch 025 | Train Loss: 0.2640 Acc: 0.8890 | Val Loss: 0.2736 Acc: 0.8816\n",
      "Epoch 026 | Train Loss: 0.2583 Acc: 0.9000 | Val Loss: 0.2579 Acc: 0.8937\n",
      "Epoch 027 | Train Loss: 0.2475 Acc: 0.8997 | Val Loss: 0.2434 Acc: 0.8979\n",
      "Epoch 028 | Train Loss: 0.2249 Acc: 0.9108 | Val Loss: 0.2493 Acc: 0.9034\n",
      "Epoch 029 | Train Loss: 0.2275 Acc: 0.9096 | Val Loss: 0.2618 Acc: 0.8907\n",
      "Epoch 030 | Train Loss: 0.2178 Acc: 0.9130 | Val Loss: 0.2433 Acc: 0.9028\n",
      "Epoch 031 | Train Loss: 0.2208 Acc: 0.9106 | Val Loss: 0.2371 Acc: 0.9070\n",
      "Epoch 032 | Train Loss: 0.2033 Acc: 0.9207 | Val Loss: 0.2317 Acc: 0.9052\n",
      "Epoch 033 | Train Loss: 0.1950 Acc: 0.9248 | Val Loss: 0.2285 Acc: 0.9124\n",
      "Epoch 034 | Train Loss: 0.1801 Acc: 0.9315 | Val Loss: 0.2078 Acc: 0.9245\n",
      "Epoch 035 | Train Loss: 0.1779 Acc: 0.9324 | Val Loss: 0.2034 Acc: 0.9179\n",
      "Epoch 036 | Train Loss: 0.1747 Acc: 0.9328 | Val Loss: 0.2212 Acc: 0.9130\n",
      "Epoch 037 | Train Loss: 0.1708 Acc: 0.9293 | Val Loss: 0.2050 Acc: 0.9179\n",
      "Epoch 038 | Train Loss: 0.1732 Acc: 0.9349 | Val Loss: 0.2156 Acc: 0.9130\n",
      "Epoch 039 | Train Loss: 0.1592 Acc: 0.9364 | Val Loss: 0.2180 Acc: 0.9185\n",
      "Epoch 040 | Train Loss: 0.1581 Acc: 0.9390 | Val Loss: 0.1860 Acc: 0.9257\n",
      "Epoch 041 | Train Loss: 0.1509 Acc: 0.9369 | Val Loss: 0.1886 Acc: 0.9293\n",
      "Epoch 042 | Train Loss: 0.1460 Acc: 0.9410 | Val Loss: 0.2164 Acc: 0.9173\n",
      "Epoch 043 | Train Loss: 0.1378 Acc: 0.9481 | Val Loss: 0.1748 Acc: 0.9306\n",
      "Epoch 044 | Train Loss: 0.1475 Acc: 0.9434 | Val Loss: 0.2148 Acc: 0.9179\n",
      "Epoch 045 | Train Loss: 0.1471 Acc: 0.9414 | Val Loss: 0.1857 Acc: 0.9372\n",
      "Epoch 046 | Train Loss: 0.1366 Acc: 0.9479 | Val Loss: 0.2018 Acc: 0.9324\n",
      "Epoch 047 | Train Loss: 0.1339 Acc: 0.9514 | Val Loss: 0.1786 Acc: 0.9330\n",
      "Epoch 048 | Train Loss: 0.1188 Acc: 0.9529 | Val Loss: 0.1509 Acc: 0.9450\n",
      "Epoch 049 | Train Loss: 0.1253 Acc: 0.9555 | Val Loss: 0.1612 Acc: 0.9396\n",
      "Epoch 050 | Train Loss: 0.1170 Acc: 0.9549 | Val Loss: 0.1616 Acc: 0.9378\n",
      "Epoch 051 | Train Loss: 0.1261 Acc: 0.9539 | Val Loss: 0.1369 Acc: 0.9432\n",
      "Epoch 052 | Train Loss: 0.1131 Acc: 0.9553 | Val Loss: 0.1418 Acc: 0.9487\n",
      "Epoch 053 | Train Loss: 0.1156 Acc: 0.9567 | Val Loss: 0.1919 Acc: 0.9318\n",
      "Epoch 054 | Train Loss: 0.1140 Acc: 0.9562 | Val Loss: 0.1465 Acc: 0.9432\n",
      "Epoch 055 | Train Loss: 0.1183 Acc: 0.9547 | Val Loss: 0.1726 Acc: 0.9372\n",
      "Epoch 056 | Train Loss: 0.1071 Acc: 0.9595 | Val Loss: 0.1494 Acc: 0.9390\n",
      "Epoch 057 | Train Loss: 0.1146 Acc: 0.9564 | Val Loss: 0.1536 Acc: 0.9426\n",
      "Epoch 058 | Train Loss: 0.1019 Acc: 0.9588 | Val Loss: 0.1587 Acc: 0.9402\n",
      "Epoch 059 | Train Loss: 0.1060 Acc: 0.9583 | Val Loss: 0.1452 Acc: 0.9378\n",
      "Epoch 060 | Train Loss: 0.0964 Acc: 0.9650 | Val Loss: 0.1848 Acc: 0.9306\n",
      "Epoch 001 | Train Loss: 0.6812 Acc: 0.5759 | Val Loss: 0.6754 Acc: 0.5882\n",
      "Epoch 002 | Train Loss: 0.6688 Acc: 0.5976 | Val Loss: 0.6472 Acc: 0.6479\n",
      "Epoch 003 | Train Loss: 0.6316 Acc: 0.6542 | Val Loss: 0.6119 Acc: 0.6727\n",
      "Epoch 004 | Train Loss: 0.6074 Acc: 0.6846 | Val Loss: 0.5796 Acc: 0.6987\n",
      "Epoch 005 | Train Loss: 0.5643 Acc: 0.7187 | Val Loss: 0.5494 Acc: 0.7168\n",
      "Epoch 006 | Train Loss: 0.5458 Acc: 0.7358 | Val Loss: 0.5618 Acc: 0.7144\n",
      "Epoch 007 | Train Loss: 0.5190 Acc: 0.7552 | Val Loss: 0.5065 Acc: 0.7488\n",
      "Epoch 008 | Train Loss: 0.4975 Acc: 0.7589 | Val Loss: 0.4875 Acc: 0.7572\n",
      "Epoch 009 | Train Loss: 0.4779 Acc: 0.7762 | Val Loss: 0.4617 Acc: 0.7742\n",
      "Epoch 010 | Train Loss: 0.4564 Acc: 0.7817 | Val Loss: 0.4654 Acc: 0.7796\n",
      "Epoch 011 | Train Loss: 0.4355 Acc: 0.8011 | Val Loss: 0.4391 Acc: 0.7935\n",
      "Epoch 012 | Train Loss: 0.4148 Acc: 0.8132 | Val Loss: 0.3933 Acc: 0.8225\n",
      "Epoch 013 | Train Loss: 0.4009 Acc: 0.8224 | Val Loss: 0.4174 Acc: 0.8074\n",
      "Epoch 014 | Train Loss: 0.3670 Acc: 0.8359 | Val Loss: 0.3928 Acc: 0.8225\n",
      "Epoch 015 | Train Loss: 0.3430 Acc: 0.8496 | Val Loss: 0.3285 Acc: 0.8623\n",
      "Epoch 016 | Train Loss: 0.3222 Acc: 0.8617 | Val Loss: 0.3404 Acc: 0.8370\n",
      "Epoch 017 | Train Loss: 0.3158 Acc: 0.8653 | Val Loss: 0.3008 Acc: 0.8822\n",
      "Epoch 018 | Train Loss: 0.2866 Acc: 0.8765 | Val Loss: 0.2781 Acc: 0.8859\n",
      "Epoch 019 | Train Loss: 0.2654 Acc: 0.8883 | Val Loss: 0.2726 Acc: 0.8847\n",
      "Epoch 020 | Train Loss: 0.2459 Acc: 0.9010 | Val Loss: 0.2609 Acc: 0.8943\n",
      "Epoch 021 | Train Loss: 0.2384 Acc: 0.9005 | Val Loss: 0.2399 Acc: 0.9022\n",
      "Epoch 022 | Train Loss: 0.2244 Acc: 0.9085 | Val Loss: 0.2432 Acc: 0.9016\n",
      "Epoch 023 | Train Loss: 0.2161 Acc: 0.9126 | Val Loss: 0.3024 Acc: 0.8792\n",
      "Epoch 024 | Train Loss: 0.2027 Acc: 0.9167 | Val Loss: 0.2544 Acc: 0.9004\n",
      "Epoch 025 | Train Loss: 0.1902 Acc: 0.9233 | Val Loss: 0.2215 Acc: 0.9130\n",
      "Epoch 026 | Train Loss: 0.1784 Acc: 0.9263 | Val Loss: 0.2155 Acc: 0.9173\n",
      "Epoch 027 | Train Loss: 0.1728 Acc: 0.9287 | Val Loss: 0.2069 Acc: 0.9179\n",
      "Epoch 028 | Train Loss: 0.1635 Acc: 0.9349 | Val Loss: 0.2118 Acc: 0.9155\n",
      "Epoch 029 | Train Loss: 0.1636 Acc: 0.9369 | Val Loss: 0.2045 Acc: 0.9239\n",
      "Epoch 030 | Train Loss: 0.1561 Acc: 0.9361 | Val Loss: 0.2303 Acc: 0.9088\n",
      "Epoch 031 | Train Loss: 0.1508 Acc: 0.9373 | Val Loss: 0.2001 Acc: 0.9257\n",
      "Epoch 032 | Train Loss: 0.1454 Acc: 0.9413 | Val Loss: 0.2276 Acc: 0.9082\n",
      "Epoch 033 | Train Loss: 0.1385 Acc: 0.9446 | Val Loss: 0.2004 Acc: 0.9203\n",
      "Epoch 034 | Train Loss: 0.1330 Acc: 0.9475 | Val Loss: 0.1811 Acc: 0.9378\n",
      "Epoch 035 | Train Loss: 0.1243 Acc: 0.9506 | Val Loss: 0.1846 Acc: 0.9275\n",
      "Epoch 036 | Train Loss: 0.1231 Acc: 0.9523 | Val Loss: 0.2152 Acc: 0.9197\n",
      "Epoch 037 | Train Loss: 0.1159 Acc: 0.9574 | Val Loss: 0.1600 Acc: 0.9463\n",
      "Epoch 038 | Train Loss: 0.1075 Acc: 0.9588 | Val Loss: 0.1752 Acc: 0.9324\n",
      "Epoch 039 | Train Loss: 0.1158 Acc: 0.9567 | Val Loss: 0.2006 Acc: 0.9306\n",
      "Epoch 040 | Train Loss: 0.1044 Acc: 0.9603 | Val Loss: 0.1576 Acc: 0.9372\n",
      "Epoch 041 | Train Loss: 0.1056 Acc: 0.9609 | Val Loss: 0.1558 Acc: 0.9469\n",
      "Epoch 042 | Train Loss: 0.0907 Acc: 0.9663 | Val Loss: 0.2156 Acc: 0.9348\n",
      "Epoch 043 | Train Loss: 0.0932 Acc: 0.9644 | Val Loss: 0.1630 Acc: 0.9408\n",
      "Epoch 044 | Train Loss: 0.0966 Acc: 0.9659 | Val Loss: 0.1896 Acc: 0.9390\n",
      "Epoch 045 | Train Loss: 0.0900 Acc: 0.9684 | Val Loss: 0.1884 Acc: 0.9336\n",
      "Epoch 046 | Train Loss: 0.0912 Acc: 0.9648 | Val Loss: 0.1716 Acc: 0.9414\n",
      "Epoch 047 | Train Loss: 0.0814 Acc: 0.9704 | Val Loss: 0.1689 Acc: 0.9420\n",
      "Epoch 048 | Train Loss: 0.0912 Acc: 0.9648 | Val Loss: 0.1589 Acc: 0.9450\n",
      "Epoch 049 | Train Loss: 0.0841 Acc: 0.9677 | Val Loss: 0.1883 Acc: 0.9324\n",
      "Epoch 050 | Train Loss: 0.0790 Acc: 0.9721 | Val Loss: 0.1791 Acc: 0.9432\n",
      "Epoch 051 | Train Loss: 0.0939 Acc: 0.9656 | Val Loss: 0.1717 Acc: 0.9342\n",
      "Early stopping triggered.\n",
      "Epoch 001 | Train Loss: 0.6805 Acc: 0.5793 | Val Loss: 0.6747 Acc: 0.5894\n",
      "Epoch 002 | Train Loss: 0.6691 Acc: 0.5985 | Val Loss: 0.6440 Acc: 0.6292\n",
      "Epoch 003 | Train Loss: 0.6177 Acc: 0.6701 | Val Loss: 0.5912 Acc: 0.6848\n",
      "Epoch 004 | Train Loss: 0.5882 Acc: 0.7021 | Val Loss: 0.5698 Acc: 0.7041\n",
      "Epoch 005 | Train Loss: 0.5570 Acc: 0.7241 | Val Loss: 0.5445 Acc: 0.7295\n",
      "Epoch 006 | Train Loss: 0.5452 Acc: 0.7323 | Val Loss: 0.5353 Acc: 0.7301\n",
      "Epoch 007 | Train Loss: 0.5180 Acc: 0.7465 | Val Loss: 0.5281 Acc: 0.7470\n",
      "Epoch 008 | Train Loss: 0.5053 Acc: 0.7534 | Val Loss: 0.5166 Acc: 0.7373\n",
      "Epoch 009 | Train Loss: 0.4919 Acc: 0.7691 | Val Loss: 0.4879 Acc: 0.7651\n",
      "Epoch 010 | Train Loss: 0.4791 Acc: 0.7788 | Val Loss: 0.4765 Acc: 0.7717\n",
      "Epoch 011 | Train Loss: 0.4642 Acc: 0.7788 | Val Loss: 0.4327 Acc: 0.7886\n",
      "Epoch 012 | Train Loss: 0.4551 Acc: 0.7876 | Val Loss: 0.4232 Acc: 0.7893\n",
      "Epoch 013 | Train Loss: 0.4221 Acc: 0.8093 | Val Loss: 0.4111 Acc: 0.8146\n",
      "Epoch 014 | Train Loss: 0.4251 Acc: 0.8102 | Val Loss: 0.4284 Acc: 0.8013\n",
      "Epoch 015 | Train Loss: 0.4176 Acc: 0.8102 | Val Loss: 0.3986 Acc: 0.8086\n",
      "Epoch 016 | Train Loss: 0.3962 Acc: 0.8203 | Val Loss: 0.4002 Acc: 0.8001\n",
      "Epoch 017 | Train Loss: 0.3824 Acc: 0.8223 | Val Loss: 0.3527 Acc: 0.8382\n",
      "Epoch 018 | Train Loss: 0.3610 Acc: 0.8424 | Val Loss: 0.3217 Acc: 0.8533\n",
      "Epoch 019 | Train Loss: 0.3581 Acc: 0.8455 | Val Loss: 0.3416 Acc: 0.8460\n",
      "Epoch 020 | Train Loss: 0.3507 Acc: 0.8460 | Val Loss: 0.3225 Acc: 0.8617\n",
      "Epoch 021 | Train Loss: 0.3324 Acc: 0.8547 | Val Loss: 0.3435 Acc: 0.8533\n",
      "Epoch 022 | Train Loss: 0.3227 Acc: 0.8638 | Val Loss: 0.3011 Acc: 0.8684\n",
      "Epoch 023 | Train Loss: 0.3215 Acc: 0.8631 | Val Loss: 0.2944 Acc: 0.8696\n",
      "Epoch 024 | Train Loss: 0.3152 Acc: 0.8662 | Val Loss: 0.3679 Acc: 0.8551\n",
      "Epoch 025 | Train Loss: 0.3072 Acc: 0.8689 | Val Loss: 0.2804 Acc: 0.8786\n",
      "Epoch 026 | Train Loss: 0.2998 Acc: 0.8775 | Val Loss: 0.2672 Acc: 0.8798\n",
      "Epoch 027 | Train Loss: 0.2929 Acc: 0.8778 | Val Loss: 0.2716 Acc: 0.8841\n",
      "Epoch 028 | Train Loss: 0.2823 Acc: 0.8845 | Val Loss: 0.2852 Acc: 0.8853\n",
      "Epoch 029 | Train Loss: 0.2712 Acc: 0.8899 | Val Loss: 0.2462 Acc: 0.9040\n",
      "Epoch 030 | Train Loss: 0.2743 Acc: 0.8902 | Val Loss: 0.2919 Acc: 0.8708\n",
      "Epoch 031 | Train Loss: 0.2628 Acc: 0.8958 | Val Loss: 0.2480 Acc: 0.8961\n",
      "Epoch 032 | Train Loss: 0.2604 Acc: 0.8948 | Val Loss: 0.2307 Acc: 0.9016\n",
      "Epoch 033 | Train Loss: 0.2442 Acc: 0.9002 | Val Loss: 0.2723 Acc: 0.8865\n",
      "Epoch 034 | Train Loss: 0.2443 Acc: 0.9026 | Val Loss: 0.2837 Acc: 0.8774\n",
      "Epoch 035 | Train Loss: 0.2465 Acc: 0.8967 | Val Loss: 0.2214 Acc: 0.9149\n",
      "Epoch 036 | Train Loss: 0.2315 Acc: 0.9053 | Val Loss: 0.2220 Acc: 0.9094\n",
      "Epoch 037 | Train Loss: 0.2243 Acc: 0.9120 | Val Loss: 0.2120 Acc: 0.9070\n",
      "Epoch 038 | Train Loss: 0.2239 Acc: 0.9070 | Val Loss: 0.2093 Acc: 0.9149\n",
      "Epoch 039 | Train Loss: 0.2150 Acc: 0.9144 | Val Loss: 0.1988 Acc: 0.9179\n",
      "Epoch 040 | Train Loss: 0.2115 Acc: 0.9147 | Val Loss: 0.1998 Acc: 0.9215\n",
      "Epoch 041 | Train Loss: 0.1986 Acc: 0.9242 | Val Loss: 0.2243 Acc: 0.9088\n",
      "Epoch 042 | Train Loss: 0.1983 Acc: 0.9245 | Val Loss: 0.1929 Acc: 0.9239\n",
      "Epoch 043 | Train Loss: 0.2009 Acc: 0.9225 | Val Loss: 0.2088 Acc: 0.9215\n",
      "Epoch 044 | Train Loss: 0.2002 Acc: 0.9201 | Val Loss: 0.1727 Acc: 0.9336\n",
      "Epoch 045 | Train Loss: 0.1915 Acc: 0.9268 | Val Loss: 0.1960 Acc: 0.9221\n",
      "Epoch 046 | Train Loss: 0.1896 Acc: 0.9266 | Val Loss: 0.2063 Acc: 0.9185\n",
      "Epoch 047 | Train Loss: 0.1916 Acc: 0.9234 | Val Loss: 0.1904 Acc: 0.9215\n",
      "Epoch 048 | Train Loss: 0.1808 Acc: 0.9284 | Val Loss: 0.1973 Acc: 0.9203\n",
      "Epoch 049 | Train Loss: 0.1780 Acc: 0.9301 | Val Loss: 0.2042 Acc: 0.9161\n",
      "Epoch 050 | Train Loss: 0.1882 Acc: 0.9277 | Val Loss: 0.1684 Acc: 0.9336\n",
      "Epoch 051 | Train Loss: 0.1725 Acc: 0.9310 | Val Loss: 0.1634 Acc: 0.9342\n",
      "Epoch 052 | Train Loss: 0.1614 Acc: 0.9379 | Val Loss: 0.1894 Acc: 0.9263\n",
      "Epoch 053 | Train Loss: 0.1620 Acc: 0.9384 | Val Loss: 0.1853 Acc: 0.9300\n",
      "Epoch 054 | Train Loss: 0.1744 Acc: 0.9322 | Val Loss: 0.1884 Acc: 0.9149\n",
      "Epoch 055 | Train Loss: 0.1644 Acc: 0.9390 | Val Loss: 0.1558 Acc: 0.9384\n",
      "Epoch 056 | Train Loss: 0.1536 Acc: 0.9420 | Val Loss: 0.1723 Acc: 0.9372\n",
      "Epoch 057 | Train Loss: 0.1594 Acc: 0.9407 | Val Loss: 0.1665 Acc: 0.9378\n",
      "Epoch 058 | Train Loss: 0.1625 Acc: 0.9361 | Val Loss: 0.1896 Acc: 0.9251\n",
      "Epoch 059 | Train Loss: 0.1604 Acc: 0.9345 | Val Loss: 0.1655 Acc: 0.9306\n",
      "Epoch 060 | Train Loss: 0.1594 Acc: 0.9375 | Val Loss: 0.1743 Acc: 0.9275\n",
      "Epoch 001 | Train Loss: 0.6789 Acc: 0.5842 | Val Loss: 0.6850 Acc: 0.5664\n",
      "Epoch 002 | Train Loss: 0.6851 Acc: 0.5680 | Val Loss: 0.6760 Acc: 0.5924\n",
      "Epoch 003 | Train Loss: 0.6750 Acc: 0.5886 | Val Loss: 0.6687 Acc: 0.5996\n",
      "Epoch 004 | Train Loss: 0.6797 Acc: 0.5762 | Val Loss: 0.6744 Acc: 0.5876\n",
      "Epoch 005 | Train Loss: 0.6642 Acc: 0.6040 | Val Loss: 0.6537 Acc: 0.6099\n",
      "Epoch 006 | Train Loss: 0.6216 Acc: 0.6684 | Val Loss: 0.5862 Acc: 0.6975\n",
      "Epoch 007 | Train Loss: 0.5880 Acc: 0.6944 | Val Loss: 0.5874 Acc: 0.7059\n",
      "Epoch 008 | Train Loss: 0.5598 Acc: 0.7190 | Val Loss: 0.5655 Acc: 0.7162\n",
      "Epoch 009 | Train Loss: 0.5400 Acc: 0.7355 | Val Loss: 0.5555 Acc: 0.7156\n",
      "Epoch 010 | Train Loss: 0.5287 Acc: 0.7478 | Val Loss: 0.5369 Acc: 0.7403\n",
      "Epoch 011 | Train Loss: 0.5107 Acc: 0.7539 | Val Loss: 0.5179 Acc: 0.7343\n",
      "Epoch 012 | Train Loss: 0.4875 Acc: 0.7711 | Val Loss: 0.5060 Acc: 0.7542\n",
      "Epoch 013 | Train Loss: 0.4645 Acc: 0.7845 | Val Loss: 0.4764 Acc: 0.7681\n",
      "Epoch 014 | Train Loss: 0.4573 Acc: 0.7873 | Val Loss: 0.4400 Acc: 0.7989\n",
      "Epoch 015 | Train Loss: 0.4394 Acc: 0.7996 | Val Loss: 0.4365 Acc: 0.8031\n",
      "Epoch 016 | Train Loss: 0.4220 Acc: 0.8090 | Val Loss: 0.4256 Acc: 0.7923\n",
      "Epoch 017 | Train Loss: 0.4058 Acc: 0.8149 | Val Loss: 0.3963 Acc: 0.8188\n",
      "Epoch 018 | Train Loss: 0.3861 Acc: 0.8241 | Val Loss: 0.3948 Acc: 0.8182\n",
      "Epoch 019 | Train Loss: 0.3759 Acc: 0.8316 | Val Loss: 0.3801 Acc: 0.8249\n",
      "Epoch 020 | Train Loss: 0.3561 Acc: 0.8460 | Val Loss: 0.3741 Acc: 0.8406\n",
      "Epoch 021 | Train Loss: 0.3416 Acc: 0.8511 | Val Loss: 0.3365 Acc: 0.8490\n",
      "Epoch 022 | Train Loss: 0.3298 Acc: 0.8519 | Val Loss: 0.3253 Acc: 0.8611\n",
      "Epoch 023 | Train Loss: 0.3128 Acc: 0.8659 | Val Loss: 0.3024 Acc: 0.8714\n",
      "Epoch 024 | Train Loss: 0.2983 Acc: 0.8711 | Val Loss: 0.3045 Acc: 0.8629\n",
      "Epoch 025 | Train Loss: 0.2874 Acc: 0.8804 | Val Loss: 0.2828 Acc: 0.8816\n",
      "Epoch 026 | Train Loss: 0.2654 Acc: 0.8908 | Val Loss: 0.2637 Acc: 0.8865\n",
      "Epoch 027 | Train Loss: 0.2531 Acc: 0.8933 | Val Loss: 0.2675 Acc: 0.8883\n",
      "Epoch 028 | Train Loss: 0.2379 Acc: 0.9047 | Val Loss: 0.2552 Acc: 0.8895\n",
      "Epoch 029 | Train Loss: 0.2508 Acc: 0.9006 | Val Loss: 0.3159 Acc: 0.8708\n",
      "Epoch 030 | Train Loss: 0.2305 Acc: 0.9070 | Val Loss: 0.2431 Acc: 0.8955\n",
      "Epoch 031 | Train Loss: 0.2149 Acc: 0.9123 | Val Loss: 0.2419 Acc: 0.9004\n",
      "Epoch 032 | Train Loss: 0.2012 Acc: 0.9170 | Val Loss: 0.2028 Acc: 0.9130\n",
      "Epoch 033 | Train Loss: 0.2056 Acc: 0.9182 | Val Loss: 0.2184 Acc: 0.9046\n",
      "Epoch 034 | Train Loss: 0.1989 Acc: 0.9225 | Val Loss: 0.2258 Acc: 0.9100\n",
      "Epoch 035 | Train Loss: 0.1977 Acc: 0.9179 | Val Loss: 0.2231 Acc: 0.9112\n",
      "Epoch 036 | Train Loss: 0.1760 Acc: 0.9318 | Val Loss: 0.2061 Acc: 0.9130\n",
      "Epoch 037 | Train Loss: 0.1784 Acc: 0.9343 | Val Loss: 0.1929 Acc: 0.9209\n",
      "Epoch 038 | Train Loss: 0.1728 Acc: 0.9301 | Val Loss: 0.2045 Acc: 0.9130\n",
      "Epoch 039 | Train Loss: 0.1606 Acc: 0.9337 | Val Loss: 0.2084 Acc: 0.9191\n",
      "Epoch 040 | Train Loss: 0.1571 Acc: 0.9387 | Val Loss: 0.1906 Acc: 0.9215\n",
      "Epoch 041 | Train Loss: 0.1609 Acc: 0.9355 | Val Loss: 0.2019 Acc: 0.9179\n",
      "Epoch 042 | Train Loss: 0.1415 Acc: 0.9465 | Val Loss: 0.1832 Acc: 0.9257\n",
      "Epoch 043 | Train Loss: 0.1375 Acc: 0.9452 | Val Loss: 0.2094 Acc: 0.9191\n",
      "Epoch 044 | Train Loss: 0.1341 Acc: 0.9470 | Val Loss: 0.2088 Acc: 0.9167\n",
      "Epoch 045 | Train Loss: 0.1364 Acc: 0.9473 | Val Loss: 0.2188 Acc: 0.9269\n",
      "Epoch 046 | Train Loss: 0.1397 Acc: 0.9464 | Val Loss: 0.1793 Acc: 0.9342\n",
      "Epoch 047 | Train Loss: 0.1222 Acc: 0.9535 | Val Loss: 0.1934 Acc: 0.9300\n",
      "Epoch 048 | Train Loss: 0.1380 Acc: 0.9449 | Val Loss: 0.1924 Acc: 0.9275\n",
      "Epoch 049 | Train Loss: 0.1206 Acc: 0.9527 | Val Loss: 0.2229 Acc: 0.9088\n",
      "Epoch 050 | Train Loss: 0.1195 Acc: 0.9530 | Val Loss: 0.2101 Acc: 0.9245\n",
      "Epoch 051 | Train Loss: 0.1152 Acc: 0.9546 | Val Loss: 0.1569 Acc: 0.9384\n",
      "Epoch 052 | Train Loss: 0.1093 Acc: 0.9574 | Val Loss: 0.1747 Acc: 0.9354\n",
      "Epoch 053 | Train Loss: 0.1134 Acc: 0.9565 | Val Loss: 0.1574 Acc: 0.9396\n",
      "Epoch 054 | Train Loss: 0.1061 Acc: 0.9606 | Val Loss: 0.1946 Acc: 0.9275\n",
      "Epoch 055 | Train Loss: 0.1032 Acc: 0.9604 | Val Loss: 0.1730 Acc: 0.9396\n",
      "Epoch 056 | Train Loss: 0.0995 Acc: 0.9627 | Val Loss: 0.1691 Acc: 0.9372\n",
      "Epoch 057 | Train Loss: 0.1011 Acc: 0.9647 | Val Loss: 0.1847 Acc: 0.9354\n",
      "Epoch 058 | Train Loss: 0.1103 Acc: 0.9571 | Val Loss: 0.1640 Acc: 0.9396\n",
      "Epoch 059 | Train Loss: 0.0927 Acc: 0.9659 | Val Loss: 0.1754 Acc: 0.9396\n",
      "Epoch 060 | Train Loss: 0.0957 Acc: 0.9659 | Val Loss: 0.1568 Acc: 0.9384\n",
      "Epoch 001 | Train Loss: 0.6816 Acc: 0.5715 | Val Loss: 0.6840 Acc: 0.5616\n",
      "Epoch 002 | Train Loss: 0.6739 Acc: 0.5932 | Val Loss: 0.6820 Acc: 0.5737\n",
      "Epoch 003 | Train Loss: 0.6645 Acc: 0.6029 | Val Loss: 0.6582 Acc: 0.6099\n",
      "Epoch 004 | Train Loss: 0.6394 Acc: 0.6467 | Val Loss: 0.6245 Acc: 0.6715\n",
      "Epoch 005 | Train Loss: 0.6002 Acc: 0.6890 | Val Loss: 0.5917 Acc: 0.6981\n",
      "Epoch 006 | Train Loss: 0.5714 Acc: 0.7130 | Val Loss: 0.5521 Acc: 0.7252\n",
      "Epoch 007 | Train Loss: 0.5484 Acc: 0.7285 | Val Loss: 0.5576 Acc: 0.7198\n",
      "Epoch 008 | Train Loss: 0.5270 Acc: 0.7430 | Val Loss: 0.5183 Acc: 0.7361\n",
      "Epoch 009 | Train Loss: 0.5181 Acc: 0.7478 | Val Loss: 0.5131 Acc: 0.7494\n",
      "Epoch 010 | Train Loss: 0.4853 Acc: 0.7728 | Val Loss: 0.4822 Acc: 0.7609\n",
      "Epoch 011 | Train Loss: 0.4641 Acc: 0.7805 | Val Loss: 0.4889 Acc: 0.7615\n",
      "Epoch 012 | Train Loss: 0.4397 Acc: 0.7975 | Val Loss: 0.4399 Acc: 0.7886\n",
      "Epoch 013 | Train Loss: 0.4271 Acc: 0.8030 | Val Loss: 0.4346 Acc: 0.7874\n",
      "Epoch 014 | Train Loss: 0.4110 Acc: 0.8082 | Val Loss: 0.4832 Acc: 0.7699\n",
      "Epoch 015 | Train Loss: 0.3841 Acc: 0.8303 | Val Loss: 0.4079 Acc: 0.7989\n",
      "Epoch 016 | Train Loss: 0.3653 Acc: 0.8383 | Val Loss: 0.3666 Acc: 0.8345\n",
      "Epoch 017 | Train Loss: 0.3574 Acc: 0.8377 | Val Loss: 0.3643 Acc: 0.8327\n",
      "Epoch 018 | Train Loss: 0.3436 Acc: 0.8496 | Val Loss: 0.3398 Acc: 0.8454\n",
      "Epoch 019 | Train Loss: 0.3147 Acc: 0.8635 | Val Loss: 0.3280 Acc: 0.8569\n",
      "Epoch 020 | Train Loss: 0.2995 Acc: 0.8735 | Val Loss: 0.2913 Acc: 0.8738\n",
      "Epoch 021 | Train Loss: 0.2823 Acc: 0.8813 | Val Loss: 0.3147 Acc: 0.8690\n",
      "Epoch 022 | Train Loss: 0.2772 Acc: 0.8824 | Val Loss: 0.3329 Acc: 0.8551\n",
      "Epoch 023 | Train Loss: 0.2520 Acc: 0.8982 | Val Loss: 0.2692 Acc: 0.8913\n",
      "Epoch 024 | Train Loss: 0.2477 Acc: 0.9006 | Val Loss: 0.2621 Acc: 0.8967\n",
      "Epoch 025 | Train Loss: 0.2408 Acc: 0.8991 | Val Loss: 0.2881 Acc: 0.8816\n",
      "Epoch 026 | Train Loss: 0.2326 Acc: 0.9062 | Val Loss: 0.2819 Acc: 0.8841\n",
      "Epoch 027 | Train Loss: 0.2141 Acc: 0.9157 | Val Loss: 0.2514 Acc: 0.8949\n",
      "Epoch 028 | Train Loss: 0.2105 Acc: 0.9126 | Val Loss: 0.2453 Acc: 0.9010\n",
      "Epoch 029 | Train Loss: 0.1957 Acc: 0.9207 | Val Loss: 0.2605 Acc: 0.8931\n",
      "Epoch 030 | Train Loss: 0.1985 Acc: 0.9216 | Val Loss: 0.2339 Acc: 0.9028\n",
      "Epoch 031 | Train Loss: 0.1828 Acc: 0.9262 | Val Loss: 0.2244 Acc: 0.9106\n",
      "Epoch 032 | Train Loss: 0.1846 Acc: 0.9290 | Val Loss: 0.2362 Acc: 0.8986\n",
      "Epoch 033 | Train Loss: 0.1650 Acc: 0.9361 | Val Loss: 0.1871 Acc: 0.9209\n",
      "Epoch 034 | Train Loss: 0.1675 Acc: 0.9328 | Val Loss: 0.2282 Acc: 0.9058\n",
      "Epoch 035 | Train Loss: 0.1670 Acc: 0.9355 | Val Loss: 0.2217 Acc: 0.9136\n",
      "Epoch 036 | Train Loss: 0.1539 Acc: 0.9413 | Val Loss: 0.2216 Acc: 0.9106\n",
      "Epoch 037 | Train Loss: 0.1496 Acc: 0.9399 | Val Loss: 0.2059 Acc: 0.9221\n",
      "Epoch 038 | Train Loss: 0.1470 Acc: 0.9414 | Val Loss: 0.1929 Acc: 0.9209\n",
      "Epoch 039 | Train Loss: 0.1410 Acc: 0.9456 | Val Loss: 0.2179 Acc: 0.9149\n",
      "Epoch 040 | Train Loss: 0.1404 Acc: 0.9414 | Val Loss: 0.1839 Acc: 0.9221\n",
      "Epoch 041 | Train Loss: 0.1333 Acc: 0.9487 | Val Loss: 0.1901 Acc: 0.9215\n",
      "Epoch 042 | Train Loss: 0.1358 Acc: 0.9491 | Val Loss: 0.1842 Acc: 0.9275\n",
      "Epoch 043 | Train Loss: 0.1333 Acc: 0.9487 | Val Loss: 0.1822 Acc: 0.9318\n",
      "Epoch 044 | Train Loss: 0.1254 Acc: 0.9521 | Val Loss: 0.1955 Acc: 0.9275\n",
      "Epoch 045 | Train Loss: 0.1311 Acc: 0.9455 | Val Loss: 0.1793 Acc: 0.9300\n",
      "Epoch 046 | Train Loss: 0.1214 Acc: 0.9547 | Val Loss: 0.1914 Acc: 0.9263\n",
      "Epoch 047 | Train Loss: 0.1197 Acc: 0.9515 | Val Loss: 0.2034 Acc: 0.9209\n",
      "Epoch 048 | Train Loss: 0.1137 Acc: 0.9556 | Val Loss: 0.1674 Acc: 0.9408\n",
      "Epoch 049 | Train Loss: 0.1134 Acc: 0.9580 | Val Loss: 0.1637 Acc: 0.9396\n",
      "Epoch 050 | Train Loss: 0.0982 Acc: 0.9639 | Val Loss: 0.1758 Acc: 0.9330\n",
      "Epoch 051 | Train Loss: 0.1027 Acc: 0.9598 | Val Loss: 0.1621 Acc: 0.9396\n",
      "Epoch 052 | Train Loss: 0.1017 Acc: 0.9580 | Val Loss: 0.1811 Acc: 0.9312\n",
      "Epoch 053 | Train Loss: 0.1057 Acc: 0.9609 | Val Loss: 0.1524 Acc: 0.9408\n",
      "Epoch 054 | Train Loss: 0.0949 Acc: 0.9626 | Val Loss: 0.1613 Acc: 0.9426\n",
      "Epoch 055 | Train Loss: 0.0892 Acc: 0.9677 | Val Loss: 0.1696 Acc: 0.9251\n",
      "Epoch 056 | Train Loss: 0.0944 Acc: 0.9636 | Val Loss: 0.1565 Acc: 0.9432\n",
      "Epoch 057 | Train Loss: 0.1018 Acc: 0.9607 | Val Loss: 0.1564 Acc: 0.9450\n",
      "Epoch 058 | Train Loss: 0.0870 Acc: 0.9681 | Val Loss: 0.1653 Acc: 0.9354\n",
      "Epoch 059 | Train Loss: 0.0872 Acc: 0.9662 | Val Loss: 0.1490 Acc: 0.9450\n",
      "Epoch 060 | Train Loss: 0.0848 Acc: 0.9684 | Val Loss: 0.1510 Acc: 0.9475\n",
      "Iteration 25/40 | Best Val Loss: 0.1122 | Iter Time: 235.25s | Total Time: 104.87 min\n",
      "Epoch 001 | Train Loss: 0.6797 Acc: 0.5809 | Val Loss: 0.6778 Acc: 0.5773\n",
      "Epoch 002 | Train Loss: 0.6684 Acc: 0.5969 | Val Loss: 0.6643 Acc: 0.6008\n",
      "Epoch 003 | Train Loss: 0.6566 Acc: 0.6118 | Val Loss: 0.6518 Acc: 0.6117\n",
      "Epoch 004 | Train Loss: 0.6305 Acc: 0.6523 | Val Loss: 0.6040 Acc: 0.6715\n",
      "Epoch 005 | Train Loss: 0.5976 Acc: 0.6971 | Val Loss: 0.5842 Acc: 0.7095\n",
      "Epoch 006 | Train Loss: 0.5668 Acc: 0.7214 | Val Loss: 0.5716 Acc: 0.7150\n",
      "Epoch 007 | Train Loss: 0.5368 Acc: 0.7367 | Val Loss: 0.5584 Acc: 0.7216\n",
      "Epoch 008 | Train Loss: 0.5321 Acc: 0.7442 | Val Loss: 0.5742 Acc: 0.7174\n",
      "Epoch 009 | Train Loss: 0.5001 Acc: 0.7625 | Val Loss: 0.4822 Acc: 0.7669\n",
      "Epoch 010 | Train Loss: 0.4787 Acc: 0.7755 | Val Loss: 0.5152 Acc: 0.7548\n",
      "Epoch 011 | Train Loss: 0.4578 Acc: 0.7873 | Val Loss: 0.4702 Acc: 0.7699\n",
      "Epoch 012 | Train Loss: 0.4405 Acc: 0.7947 | Val Loss: 0.4211 Acc: 0.7965\n",
      "Epoch 013 | Train Loss: 0.4155 Acc: 0.8093 | Val Loss: 0.3848 Acc: 0.8188\n",
      "Epoch 014 | Train Loss: 0.3909 Acc: 0.8267 | Val Loss: 0.3800 Acc: 0.8285\n",
      "Epoch 015 | Train Loss: 0.3751 Acc: 0.8303 | Val Loss: 0.3549 Acc: 0.8382\n",
      "Epoch 016 | Train Loss: 0.3526 Acc: 0.8463 | Val Loss: 0.3467 Acc: 0.8454\n",
      "Epoch 017 | Train Loss: 0.3427 Acc: 0.8463 | Val Loss: 0.3421 Acc: 0.8418\n",
      "Epoch 018 | Train Loss: 0.3340 Acc: 0.8561 | Val Loss: 0.3236 Acc: 0.8539\n",
      "Epoch 019 | Train Loss: 0.3207 Acc: 0.8618 | Val Loss: 0.2855 Acc: 0.8720\n",
      "Epoch 020 | Train Loss: 0.3039 Acc: 0.8686 | Val Loss: 0.2880 Acc: 0.8708\n",
      "Epoch 021 | Train Loss: 0.2786 Acc: 0.8804 | Val Loss: 0.2859 Acc: 0.8780\n",
      "Epoch 022 | Train Loss: 0.2757 Acc: 0.8809 | Val Loss: 0.2638 Acc: 0.8955\n",
      "Epoch 023 | Train Loss: 0.2613 Acc: 0.8898 | Val Loss: 0.2645 Acc: 0.8853\n",
      "Epoch 024 | Train Loss: 0.2515 Acc: 0.8929 | Val Loss: 0.2423 Acc: 0.9046\n",
      "Epoch 025 | Train Loss: 0.2222 Acc: 0.9096 | Val Loss: 0.2492 Acc: 0.9034\n",
      "Epoch 026 | Train Loss: 0.2319 Acc: 0.9070 | Val Loss: 0.2564 Acc: 0.8925\n",
      "Epoch 027 | Train Loss: 0.2265 Acc: 0.9076 | Val Loss: 0.2299 Acc: 0.9088\n",
      "Epoch 028 | Train Loss: 0.2163 Acc: 0.9133 | Val Loss: 0.2482 Acc: 0.8979\n",
      "Epoch 029 | Train Loss: 0.2050 Acc: 0.9194 | Val Loss: 0.2198 Acc: 0.9130\n",
      "Epoch 030 | Train Loss: 0.1928 Acc: 0.9228 | Val Loss: 0.2108 Acc: 0.9167\n",
      "Epoch 031 | Train Loss: 0.1886 Acc: 0.9239 | Val Loss: 0.2190 Acc: 0.9149\n",
      "Epoch 032 | Train Loss: 0.1853 Acc: 0.9268 | Val Loss: 0.2073 Acc: 0.9155\n",
      "Epoch 033 | Train Loss: 0.1721 Acc: 0.9342 | Val Loss: 0.2020 Acc: 0.9227\n",
      "Epoch 034 | Train Loss: 0.1661 Acc: 0.9336 | Val Loss: 0.1758 Acc: 0.9342\n",
      "Epoch 035 | Train Loss: 0.1679 Acc: 0.9327 | Val Loss: 0.2168 Acc: 0.9155\n",
      "Epoch 036 | Train Loss: 0.1608 Acc: 0.9392 | Val Loss: 0.1725 Acc: 0.9360\n",
      "Epoch 037 | Train Loss: 0.1596 Acc: 0.9379 | Val Loss: 0.1860 Acc: 0.9354\n",
      "Epoch 038 | Train Loss: 0.1442 Acc: 0.9423 | Val Loss: 0.1760 Acc: 0.9354\n",
      "Epoch 039 | Train Loss: 0.1418 Acc: 0.9395 | Val Loss: 0.2085 Acc: 0.9185\n",
      "Epoch 040 | Train Loss: 0.1446 Acc: 0.9429 | Val Loss: 0.1829 Acc: 0.9348\n",
      "Epoch 041 | Train Loss: 0.1368 Acc: 0.9476 | Val Loss: 0.1638 Acc: 0.9420\n",
      "Epoch 042 | Train Loss: 0.1293 Acc: 0.9511 | Val Loss: 0.1814 Acc: 0.9366\n",
      "Epoch 043 | Train Loss: 0.1222 Acc: 0.9538 | Val Loss: 0.1664 Acc: 0.9390\n",
      "Epoch 044 | Train Loss: 0.1251 Acc: 0.9523 | Val Loss: 0.1649 Acc: 0.9414\n",
      "Epoch 045 | Train Loss: 0.1135 Acc: 0.9588 | Val Loss: 0.1577 Acc: 0.9402\n",
      "Epoch 046 | Train Loss: 0.1236 Acc: 0.9524 | Val Loss: 0.1612 Acc: 0.9396\n",
      "Epoch 047 | Train Loss: 0.1203 Acc: 0.9514 | Val Loss: 0.1810 Acc: 0.9366\n",
      "Epoch 048 | Train Loss: 0.1169 Acc: 0.9552 | Val Loss: 0.1515 Acc: 0.9457\n",
      "Epoch 049 | Train Loss: 0.1162 Acc: 0.9559 | Val Loss: 0.1513 Acc: 0.9505\n",
      "Epoch 050 | Train Loss: 0.1061 Acc: 0.9603 | Val Loss: 0.1654 Acc: 0.9420\n",
      "Epoch 051 | Train Loss: 0.1052 Acc: 0.9601 | Val Loss: 0.1456 Acc: 0.9481\n",
      "Epoch 052 | Train Loss: 0.1063 Acc: 0.9642 | Val Loss: 0.1431 Acc: 0.9487\n",
      "Epoch 053 | Train Loss: 0.1139 Acc: 0.9567 | Val Loss: 0.1454 Acc: 0.9438\n",
      "Epoch 054 | Train Loss: 0.0967 Acc: 0.9635 | Val Loss: 0.1500 Acc: 0.9505\n",
      "Epoch 055 | Train Loss: 0.1093 Acc: 0.9597 | Val Loss: 0.1528 Acc: 0.9457\n",
      "Epoch 056 | Train Loss: 0.1015 Acc: 0.9624 | Val Loss: 0.1372 Acc: 0.9529\n",
      "Epoch 057 | Train Loss: 0.0871 Acc: 0.9672 | Val Loss: 0.1481 Acc: 0.9523\n",
      "Epoch 058 | Train Loss: 0.0831 Acc: 0.9665 | Val Loss: 0.1598 Acc: 0.9523\n",
      "Epoch 059 | Train Loss: 0.0904 Acc: 0.9668 | Val Loss: 0.1492 Acc: 0.9517\n",
      "Epoch 060 | Train Loss: 0.0867 Acc: 0.9675 | Val Loss: 0.1434 Acc: 0.9511\n",
      "Epoch 001 | Train Loss: 0.6857 Acc: 0.5658 | Val Loss: 0.6813 Acc: 0.5966\n",
      "Epoch 002 | Train Loss: 0.6773 Acc: 0.5803 | Val Loss: 0.6612 Acc: 0.6111\n",
      "Epoch 003 | Train Loss: 0.6462 Acc: 0.6345 | Val Loss: 0.6130 Acc: 0.6685\n",
      "Epoch 004 | Train Loss: 0.6116 Acc: 0.6911 | Val Loss: 0.5890 Acc: 0.6890\n",
      "Epoch 005 | Train Loss: 0.5780 Acc: 0.7051 | Val Loss: 0.5947 Acc: 0.6950\n",
      "Epoch 006 | Train Loss: 0.5543 Acc: 0.7258 | Val Loss: 0.5471 Acc: 0.7222\n",
      "Epoch 007 | Train Loss: 0.5352 Acc: 0.7324 | Val Loss: 0.5199 Acc: 0.7289\n",
      "Epoch 008 | Train Loss: 0.5147 Acc: 0.7506 | Val Loss: 0.5136 Acc: 0.7458\n",
      "Epoch 009 | Train Loss: 0.4988 Acc: 0.7596 | Val Loss: 0.4831 Acc: 0.7639\n",
      "Epoch 010 | Train Loss: 0.4824 Acc: 0.7750 | Val Loss: 0.4712 Acc: 0.7838\n",
      "Epoch 011 | Train Loss: 0.4645 Acc: 0.7803 | Val Loss: 0.4460 Acc: 0.7850\n",
      "Epoch 012 | Train Loss: 0.4396 Acc: 0.7960 | Val Loss: 0.4300 Acc: 0.7917\n",
      "Epoch 013 | Train Loss: 0.4289 Acc: 0.8045 | Val Loss: 0.3890 Acc: 0.8237\n",
      "Epoch 014 | Train Loss: 0.3983 Acc: 0.8246 | Val Loss: 0.3970 Acc: 0.8122\n",
      "Epoch 015 | Train Loss: 0.3867 Acc: 0.8297 | Val Loss: 0.3585 Acc: 0.8364\n",
      "Epoch 016 | Train Loss: 0.3675 Acc: 0.8353 | Val Loss: 0.3823 Acc: 0.8370\n",
      "Epoch 017 | Train Loss: 0.3608 Acc: 0.8436 | Val Loss: 0.3382 Acc: 0.8460\n",
      "Epoch 018 | Train Loss: 0.3491 Acc: 0.8505 | Val Loss: 0.3259 Acc: 0.8678\n",
      "Epoch 019 | Train Loss: 0.3261 Acc: 0.8623 | Val Loss: 0.3300 Acc: 0.8490\n",
      "Epoch 020 | Train Loss: 0.3031 Acc: 0.8732 | Val Loss: 0.3280 Acc: 0.8726\n",
      "Epoch 021 | Train Loss: 0.2945 Acc: 0.8786 | Val Loss: 0.2679 Acc: 0.8829\n",
      "Epoch 022 | Train Loss: 0.2740 Acc: 0.8889 | Val Loss: 0.2603 Acc: 0.8883\n",
      "Epoch 023 | Train Loss: 0.2713 Acc: 0.8877 | Val Loss: 0.2991 Acc: 0.8798\n",
      "Epoch 024 | Train Loss: 0.2445 Acc: 0.8966 | Val Loss: 0.2394 Acc: 0.9143\n",
      "Epoch 025 | Train Loss: 0.2398 Acc: 0.9023 | Val Loss: 0.2471 Acc: 0.9028\n",
      "Epoch 026 | Train Loss: 0.2270 Acc: 0.9120 | Val Loss: 0.2300 Acc: 0.9064\n",
      "Epoch 027 | Train Loss: 0.2090 Acc: 0.9203 | Val Loss: 0.2234 Acc: 0.9106\n",
      "Epoch 028 | Train Loss: 0.2127 Acc: 0.9192 | Val Loss: 0.2528 Acc: 0.8961\n",
      "Epoch 029 | Train Loss: 0.2079 Acc: 0.9156 | Val Loss: 0.1869 Acc: 0.9293\n",
      "Epoch 030 | Train Loss: 0.1853 Acc: 0.9275 | Val Loss: 0.1778 Acc: 0.9293\n",
      "Epoch 031 | Train Loss: 0.1962 Acc: 0.9250 | Val Loss: 0.1747 Acc: 0.9354\n",
      "Epoch 032 | Train Loss: 0.1868 Acc: 0.9286 | Val Loss: 0.1799 Acc: 0.9300\n",
      "Epoch 033 | Train Loss: 0.1709 Acc: 0.9382 | Val Loss: 0.2179 Acc: 0.9143\n",
      "Epoch 034 | Train Loss: 0.1709 Acc: 0.9381 | Val Loss: 0.1983 Acc: 0.9324\n",
      "Epoch 035 | Train Loss: 0.1705 Acc: 0.9358 | Val Loss: 0.1716 Acc: 0.9342\n",
      "Epoch 036 | Train Loss: 0.1460 Acc: 0.9449 | Val Loss: 0.1932 Acc: 0.9281\n",
      "Epoch 037 | Train Loss: 0.1634 Acc: 0.9370 | Val Loss: 0.1613 Acc: 0.9457\n",
      "Epoch 038 | Train Loss: 0.1436 Acc: 0.9438 | Val Loss: 0.2036 Acc: 0.9287\n",
      "Epoch 039 | Train Loss: 0.1519 Acc: 0.9408 | Val Loss: 0.1660 Acc: 0.9372\n",
      "Epoch 040 | Train Loss: 0.1403 Acc: 0.9450 | Val Loss: 0.1755 Acc: 0.9312\n",
      "Epoch 041 | Train Loss: 0.1379 Acc: 0.9475 | Val Loss: 0.2120 Acc: 0.9239\n",
      "Epoch 042 | Train Loss: 0.1405 Acc: 0.9496 | Val Loss: 0.1505 Acc: 0.9444\n",
      "Epoch 043 | Train Loss: 0.1460 Acc: 0.9478 | Val Loss: 0.1804 Acc: 0.9390\n",
      "Epoch 044 | Train Loss: 0.1279 Acc: 0.9517 | Val Loss: 0.1528 Acc: 0.9469\n",
      "Epoch 045 | Train Loss: 0.1228 Acc: 0.9546 | Val Loss: 0.1782 Acc: 0.9275\n",
      "Epoch 046 | Train Loss: 0.1317 Acc: 0.9526 | Val Loss: 0.1658 Acc: 0.9396\n",
      "Epoch 047 | Train Loss: 0.1149 Acc: 0.9586 | Val Loss: 0.1541 Acc: 0.9505\n",
      "Epoch 048 | Train Loss: 0.1163 Acc: 0.9541 | Val Loss: 0.1408 Acc: 0.9481\n",
      "Epoch 049 | Train Loss: 0.1169 Acc: 0.9571 | Val Loss: 0.1662 Acc: 0.9414\n",
      "Epoch 050 | Train Loss: 0.1138 Acc: 0.9583 | Val Loss: 0.1529 Acc: 0.9414\n",
      "Epoch 051 | Train Loss: 0.1210 Acc: 0.9547 | Val Loss: 0.1406 Acc: 0.9511\n",
      "Epoch 052 | Train Loss: 0.1077 Acc: 0.9638 | Val Loss: 0.1437 Acc: 0.9463\n",
      "Epoch 053 | Train Loss: 0.1038 Acc: 0.9626 | Val Loss: 0.1650 Acc: 0.9463\n",
      "Epoch 054 | Train Loss: 0.1126 Acc: 0.9582 | Val Loss: 0.1906 Acc: 0.9438\n",
      "Epoch 055 | Train Loss: 0.0997 Acc: 0.9613 | Val Loss: 0.1609 Acc: 0.9444\n",
      "Epoch 056 | Train Loss: 0.1023 Acc: 0.9623 | Val Loss: 0.1457 Acc: 0.9487\n",
      "Epoch 057 | Train Loss: 0.1097 Acc: 0.9589 | Val Loss: 0.1439 Acc: 0.9529\n",
      "Epoch 058 | Train Loss: 0.1020 Acc: 0.9638 | Val Loss: 0.1460 Acc: 0.9475\n",
      "Epoch 059 | Train Loss: 0.0881 Acc: 0.9692 | Val Loss: 0.1759 Acc: 0.9366\n",
      "Epoch 060 | Train Loss: 0.0996 Acc: 0.9639 | Val Loss: 0.1819 Acc: 0.9444\n",
      "Epoch 001 | Train Loss: 0.6785 Acc: 0.5839 | Val Loss: 0.6760 Acc: 0.5900\n",
      "Epoch 002 | Train Loss: 0.6740 Acc: 0.5935 | Val Loss: 0.6681 Acc: 0.6002\n",
      "Epoch 003 | Train Loss: 0.6547 Acc: 0.6198 | Val Loss: 0.6265 Acc: 0.6624\n",
      "Epoch 004 | Train Loss: 0.6100 Acc: 0.6801 | Val Loss: 0.5869 Acc: 0.6884\n",
      "Epoch 005 | Train Loss: 0.5663 Acc: 0.7167 | Val Loss: 0.5663 Acc: 0.7126\n",
      "Epoch 006 | Train Loss: 0.5363 Acc: 0.7383 | Val Loss: 0.5262 Acc: 0.7385\n",
      "Epoch 007 | Train Loss: 0.5177 Acc: 0.7521 | Val Loss: 0.5079 Acc: 0.7421\n",
      "Epoch 008 | Train Loss: 0.4903 Acc: 0.7667 | Val Loss: 0.5069 Acc: 0.7494\n",
      "Epoch 009 | Train Loss: 0.4669 Acc: 0.7777 | Val Loss: 0.4775 Acc: 0.7748\n",
      "Epoch 010 | Train Loss: 0.4402 Acc: 0.7947 | Val Loss: 0.4152 Acc: 0.8092\n",
      "Epoch 011 | Train Loss: 0.4106 Acc: 0.8098 | Val Loss: 0.4275 Acc: 0.7856\n",
      "Epoch 012 | Train Loss: 0.3884 Acc: 0.8280 | Val Loss: 0.4083 Acc: 0.8019\n",
      "Epoch 013 | Train Loss: 0.3628 Acc: 0.8455 | Val Loss: 0.3866 Acc: 0.8207\n",
      "Epoch 014 | Train Loss: 0.3511 Acc: 0.8474 | Val Loss: 0.3434 Acc: 0.8436\n",
      "Epoch 015 | Train Loss: 0.3246 Acc: 0.8634 | Val Loss: 0.3561 Acc: 0.8382\n",
      "Epoch 016 | Train Loss: 0.2984 Acc: 0.8768 | Val Loss: 0.3383 Acc: 0.8472\n",
      "Epoch 017 | Train Loss: 0.2821 Acc: 0.8785 | Val Loss: 0.2864 Acc: 0.8678\n",
      "Epoch 018 | Train Loss: 0.2700 Acc: 0.8860 | Val Loss: 0.2912 Acc: 0.8702\n",
      "Epoch 019 | Train Loss: 0.2433 Acc: 0.9006 | Val Loss: 0.3300 Acc: 0.8599\n",
      "Epoch 020 | Train Loss: 0.2363 Acc: 0.9100 | Val Loss: 0.2590 Acc: 0.8943\n",
      "Epoch 021 | Train Loss: 0.2208 Acc: 0.9120 | Val Loss: 0.2321 Acc: 0.9046\n",
      "Epoch 022 | Train Loss: 0.2009 Acc: 0.9198 | Val Loss: 0.2655 Acc: 0.8955\n",
      "Epoch 023 | Train Loss: 0.1952 Acc: 0.9227 | Val Loss: 0.2142 Acc: 0.9106\n",
      "Epoch 024 | Train Loss: 0.1840 Acc: 0.9315 | Val Loss: 0.2279 Acc: 0.9052\n",
      "Epoch 025 | Train Loss: 0.1799 Acc: 0.9290 | Val Loss: 0.2294 Acc: 0.8979\n",
      "Epoch 026 | Train Loss: 0.1698 Acc: 0.9348 | Val Loss: 0.2140 Acc: 0.9088\n",
      "Epoch 027 | Train Loss: 0.1430 Acc: 0.9423 | Val Loss: 0.1964 Acc: 0.9275\n",
      "Epoch 028 | Train Loss: 0.1496 Acc: 0.9416 | Val Loss: 0.2143 Acc: 0.9179\n",
      "Epoch 029 | Train Loss: 0.1426 Acc: 0.9455 | Val Loss: 0.1769 Acc: 0.9348\n",
      "Epoch 030 | Train Loss: 0.1366 Acc: 0.9467 | Val Loss: 0.2264 Acc: 0.9100\n",
      "Epoch 031 | Train Loss: 0.1264 Acc: 0.9508 | Val Loss: 0.1766 Acc: 0.9348\n",
      "Epoch 032 | Train Loss: 0.1198 Acc: 0.9523 | Val Loss: 0.1895 Acc: 0.9275\n",
      "Epoch 033 | Train Loss: 0.1197 Acc: 0.9579 | Val Loss: 0.2251 Acc: 0.9167\n",
      "Epoch 034 | Train Loss: 0.1093 Acc: 0.9586 | Val Loss: 0.1717 Acc: 0.9312\n",
      "Epoch 035 | Train Loss: 0.1126 Acc: 0.9574 | Val Loss: 0.1726 Acc: 0.9342\n",
      "Epoch 036 | Train Loss: 0.1036 Acc: 0.9618 | Val Loss: 0.1929 Acc: 0.9293\n",
      "Epoch 037 | Train Loss: 0.0977 Acc: 0.9609 | Val Loss: 0.2181 Acc: 0.9227\n",
      "Epoch 038 | Train Loss: 0.0983 Acc: 0.9638 | Val Loss: 0.1797 Acc: 0.9378\n",
      "Epoch 039 | Train Loss: 0.0851 Acc: 0.9659 | Val Loss: 0.1683 Acc: 0.9366\n",
      "Epoch 040 | Train Loss: 0.0923 Acc: 0.9650 | Val Loss: 0.1602 Acc: 0.9432\n",
      "Epoch 041 | Train Loss: 0.0974 Acc: 0.9647 | Val Loss: 0.1789 Acc: 0.9366\n",
      "Epoch 042 | Train Loss: 0.0843 Acc: 0.9672 | Val Loss: 0.1816 Acc: 0.9408\n",
      "Epoch 043 | Train Loss: 0.0881 Acc: 0.9659 | Val Loss: 0.1757 Acc: 0.9348\n",
      "Epoch 044 | Train Loss: 0.0762 Acc: 0.9731 | Val Loss: 0.1704 Acc: 0.9330\n",
      "Epoch 045 | Train Loss: 0.0876 Acc: 0.9645 | Val Loss: 0.1763 Acc: 0.9360\n",
      "Epoch 046 | Train Loss: 0.0827 Acc: 0.9704 | Val Loss: 0.1929 Acc: 0.9426\n",
      "Epoch 047 | Train Loss: 0.0730 Acc: 0.9739 | Val Loss: 0.2109 Acc: 0.9293\n",
      "Epoch 048 | Train Loss: 0.0723 Acc: 0.9722 | Val Loss: 0.1411 Acc: 0.9547\n",
      "Epoch 049 | Train Loss: 0.0761 Acc: 0.9730 | Val Loss: 0.1821 Acc: 0.9384\n",
      "Epoch 050 | Train Loss: 0.0783 Acc: 0.9710 | Val Loss: 0.1448 Acc: 0.9499\n",
      "Epoch 051 | Train Loss: 0.0683 Acc: 0.9742 | Val Loss: 0.1564 Acc: 0.9438\n",
      "Epoch 052 | Train Loss: 0.0626 Acc: 0.9767 | Val Loss: 0.1580 Acc: 0.9390\n",
      "Epoch 053 | Train Loss: 0.0651 Acc: 0.9764 | Val Loss: 0.1277 Acc: 0.9565\n",
      "Epoch 054 | Train Loss: 0.0648 Acc: 0.9763 | Val Loss: 0.1581 Acc: 0.9505\n",
      "Epoch 055 | Train Loss: 0.0575 Acc: 0.9789 | Val Loss: 0.1691 Acc: 0.9469\n",
      "Epoch 056 | Train Loss: 0.0637 Acc: 0.9761 | Val Loss: 0.1727 Acc: 0.9499\n",
      "Epoch 057 | Train Loss: 0.0576 Acc: 0.9783 | Val Loss: 0.1583 Acc: 0.9505\n",
      "Epoch 058 | Train Loss: 0.0653 Acc: 0.9749 | Val Loss: 0.1756 Acc: 0.9469\n",
      "Epoch 059 | Train Loss: 0.0601 Acc: 0.9777 | Val Loss: 0.1640 Acc: 0.9402\n",
      "Epoch 060 | Train Loss: 0.0601 Acc: 0.9766 | Val Loss: 0.1622 Acc: 0.9396\n",
      "Epoch 001 | Train Loss: 0.6853 Acc: 0.5644 | Val Loss: 0.6862 Acc: 0.5586\n",
      "Epoch 002 | Train Loss: 0.6800 Acc: 0.5789 | Val Loss: 0.6928 Acc: 0.5568\n",
      "Epoch 003 | Train Loss: 0.6760 Acc: 0.5896 | Val Loss: 0.6737 Acc: 0.5948\n",
      "Epoch 004 | Train Loss: 0.6682 Acc: 0.6079 | Val Loss: 0.6674 Acc: 0.6039\n",
      "Epoch 005 | Train Loss: 0.6667 Acc: 0.6041 | Val Loss: 0.6644 Acc: 0.6051\n",
      "Epoch 006 | Train Loss: 0.6564 Acc: 0.6168 | Val Loss: 0.6677 Acc: 0.5966\n",
      "Epoch 007 | Train Loss: 0.6529 Acc: 0.6219 | Val Loss: 0.6483 Acc: 0.6190\n",
      "Epoch 008 | Train Loss: 0.6254 Acc: 0.6613 | Val Loss: 0.6059 Acc: 0.6908\n",
      "Epoch 009 | Train Loss: 0.5764 Acc: 0.7124 | Val Loss: 0.5880 Acc: 0.6963\n",
      "Epoch 010 | Train Loss: 0.5324 Acc: 0.7436 | Val Loss: 0.5193 Acc: 0.7440\n",
      "Epoch 011 | Train Loss: 0.5270 Acc: 0.7454 | Val Loss: 0.5291 Acc: 0.7283\n",
      "Epoch 012 | Train Loss: 0.5149 Acc: 0.7504 | Val Loss: 0.5024 Acc: 0.7560\n",
      "Epoch 013 | Train Loss: 0.4825 Acc: 0.7719 | Val Loss: 0.4804 Acc: 0.7663\n",
      "Epoch 014 | Train Loss: 0.4721 Acc: 0.7765 | Val Loss: 0.4966 Acc: 0.7597\n",
      "Epoch 015 | Train Loss: 0.4627 Acc: 0.7823 | Val Loss: 0.4548 Acc: 0.7941\n",
      "Epoch 016 | Train Loss: 0.4404 Acc: 0.7945 | Val Loss: 0.4689 Acc: 0.7681\n",
      "Epoch 017 | Train Loss: 0.4131 Acc: 0.8152 | Val Loss: 0.4021 Acc: 0.8122\n",
      "Epoch 018 | Train Loss: 0.3877 Acc: 0.8283 | Val Loss: 0.3993 Acc: 0.8134\n",
      "Epoch 019 | Train Loss: 0.3741 Acc: 0.8350 | Val Loss: 0.3608 Acc: 0.8333\n",
      "Epoch 020 | Train Loss: 0.3510 Acc: 0.8477 | Val Loss: 0.3602 Acc: 0.8484\n",
      "Epoch 021 | Train Loss: 0.3353 Acc: 0.8511 | Val Loss: 0.3180 Acc: 0.8623\n",
      "Epoch 022 | Train Loss: 0.3115 Acc: 0.8691 | Val Loss: 0.3188 Acc: 0.8587\n",
      "Epoch 023 | Train Loss: 0.3021 Acc: 0.8735 | Val Loss: 0.3610 Acc: 0.8357\n",
      "Epoch 024 | Train Loss: 0.2951 Acc: 0.8759 | Val Loss: 0.3024 Acc: 0.8768\n",
      "Epoch 025 | Train Loss: 0.2806 Acc: 0.8824 | Val Loss: 0.2968 Acc: 0.8798\n",
      "Epoch 026 | Train Loss: 0.2658 Acc: 0.8878 | Val Loss: 0.2889 Acc: 0.8786\n",
      "Epoch 027 | Train Loss: 0.2543 Acc: 0.8960 | Val Loss: 0.2823 Acc: 0.8883\n",
      "Epoch 028 | Train Loss: 0.2405 Acc: 0.9002 | Val Loss: 0.2391 Acc: 0.9064\n",
      "Epoch 029 | Train Loss: 0.2289 Acc: 0.9076 | Val Loss: 0.3308 Acc: 0.8678\n",
      "Epoch 030 | Train Loss: 0.2322 Acc: 0.9070 | Val Loss: 0.2549 Acc: 0.8955\n",
      "Epoch 031 | Train Loss: 0.2209 Acc: 0.9108 | Val Loss: 0.2633 Acc: 0.8949\n",
      "Epoch 032 | Train Loss: 0.2247 Acc: 0.9121 | Val Loss: 0.2521 Acc: 0.9010\n",
      "Epoch 033 | Train Loss: 0.2099 Acc: 0.9159 | Val Loss: 0.2153 Acc: 0.9185\n",
      "Epoch 034 | Train Loss: 0.1979 Acc: 0.9231 | Val Loss: 0.2306 Acc: 0.9118\n",
      "Epoch 035 | Train Loss: 0.1924 Acc: 0.9250 | Val Loss: 0.2267 Acc: 0.9167\n",
      "Epoch 036 | Train Loss: 0.1900 Acc: 0.9248 | Val Loss: 0.2229 Acc: 0.9118\n",
      "Epoch 037 | Train Loss: 0.1933 Acc: 0.9219 | Val Loss: 0.2433 Acc: 0.8967\n",
      "Epoch 038 | Train Loss: 0.1891 Acc: 0.9268 | Val Loss: 0.2078 Acc: 0.9209\n",
      "Epoch 039 | Train Loss: 0.1826 Acc: 0.9259 | Val Loss: 0.2125 Acc: 0.9245\n",
      "Epoch 040 | Train Loss: 0.1719 Acc: 0.9333 | Val Loss: 0.2047 Acc: 0.9185\n",
      "Epoch 041 | Train Loss: 0.1675 Acc: 0.9379 | Val Loss: 0.2011 Acc: 0.9203\n",
      "Epoch 042 | Train Loss: 0.1675 Acc: 0.9348 | Val Loss: 0.1784 Acc: 0.9342\n",
      "Epoch 043 | Train Loss: 0.1584 Acc: 0.9385 | Val Loss: 0.2200 Acc: 0.9179\n",
      "Epoch 044 | Train Loss: 0.1585 Acc: 0.9398 | Val Loss: 0.1871 Acc: 0.9366\n",
      "Epoch 045 | Train Loss: 0.1453 Acc: 0.9446 | Val Loss: 0.2332 Acc: 0.9149\n",
      "Epoch 046 | Train Loss: 0.1522 Acc: 0.9423 | Val Loss: 0.2137 Acc: 0.9215\n",
      "Epoch 047 | Train Loss: 0.1524 Acc: 0.9419 | Val Loss: 0.1889 Acc: 0.9312\n",
      "Epoch 048 | Train Loss: 0.1540 Acc: 0.9399 | Val Loss: 0.2132 Acc: 0.9227\n",
      "Epoch 049 | Train Loss: 0.1425 Acc: 0.9450 | Val Loss: 0.1895 Acc: 0.9312\n",
      "Epoch 050 | Train Loss: 0.1362 Acc: 0.9503 | Val Loss: 0.2082 Acc: 0.9257\n",
      "Epoch 051 | Train Loss: 0.1419 Acc: 0.9476 | Val Loss: 0.1918 Acc: 0.9275\n",
      "Epoch 052 | Train Loss: 0.1285 Acc: 0.9529 | Val Loss: 0.2363 Acc: 0.9130\n",
      "Early stopping triggered.\n",
      "Epoch 001 | Train Loss: 0.6779 Acc: 0.5796 | Val Loss: 0.6730 Acc: 0.5900\n",
      "Epoch 002 | Train Loss: 0.6673 Acc: 0.6015 | Val Loss: 0.6827 Acc: 0.5833\n",
      "Epoch 003 | Train Loss: 0.6582 Acc: 0.6059 | Val Loss: 0.6351 Acc: 0.6492\n",
      "Epoch 004 | Train Loss: 0.6300 Acc: 0.6653 | Val Loss: 0.6049 Acc: 0.6890\n",
      "Epoch 005 | Train Loss: 0.6067 Acc: 0.6870 | Val Loss: 0.5950 Acc: 0.6914\n",
      "Epoch 006 | Train Loss: 0.5631 Acc: 0.7201 | Val Loss: 0.5594 Acc: 0.7174\n",
      "Epoch 007 | Train Loss: 0.5469 Acc: 0.7299 | Val Loss: 0.5577 Acc: 0.7222\n",
      "Epoch 008 | Train Loss: 0.5292 Acc: 0.7436 | Val Loss: 0.5371 Acc: 0.7313\n",
      "Epoch 009 | Train Loss: 0.5111 Acc: 0.7506 | Val Loss: 0.5287 Acc: 0.7409\n",
      "Epoch 010 | Train Loss: 0.4970 Acc: 0.7574 | Val Loss: 0.5118 Acc: 0.7464\n",
      "Epoch 011 | Train Loss: 0.4813 Acc: 0.7702 | Val Loss: 0.5166 Acc: 0.7560\n",
      "Epoch 012 | Train Loss: 0.4685 Acc: 0.7741 | Val Loss: 0.5244 Acc: 0.7542\n",
      "Epoch 013 | Train Loss: 0.4566 Acc: 0.7845 | Val Loss: 0.4593 Acc: 0.7760\n",
      "Epoch 014 | Train Loss: 0.4366 Acc: 0.7962 | Val Loss: 0.4419 Acc: 0.7874\n",
      "Epoch 015 | Train Loss: 0.4085 Acc: 0.8164 | Val Loss: 0.4284 Acc: 0.8037\n",
      "Epoch 016 | Train Loss: 0.4010 Acc: 0.8214 | Val Loss: 0.4035 Acc: 0.8170\n",
      "Epoch 017 | Train Loss: 0.3795 Acc: 0.8286 | Val Loss: 0.3856 Acc: 0.8321\n",
      "Epoch 018 | Train Loss: 0.3562 Acc: 0.8469 | Val Loss: 0.4058 Acc: 0.8194\n",
      "Epoch 019 | Train Loss: 0.3404 Acc: 0.8502 | Val Loss: 0.3496 Acc: 0.8430\n",
      "Epoch 020 | Train Loss: 0.3299 Acc: 0.8597 | Val Loss: 0.3421 Acc: 0.8521\n",
      "Epoch 021 | Train Loss: 0.3051 Acc: 0.8754 | Val Loss: 0.3259 Acc: 0.8708\n",
      "Epoch 022 | Train Loss: 0.2994 Acc: 0.8769 | Val Loss: 0.3104 Acc: 0.8647\n",
      "Epoch 023 | Train Loss: 0.2905 Acc: 0.8797 | Val Loss: 0.2835 Acc: 0.8768\n",
      "Epoch 024 | Train Loss: 0.2846 Acc: 0.8818 | Val Loss: 0.3228 Acc: 0.8623\n",
      "Epoch 025 | Train Loss: 0.2684 Acc: 0.8872 | Val Loss: 0.3261 Acc: 0.8702\n",
      "Epoch 026 | Train Loss: 0.2526 Acc: 0.8942 | Val Loss: 0.2615 Acc: 0.8992\n",
      "Epoch 027 | Train Loss: 0.2443 Acc: 0.9002 | Val Loss: 0.2546 Acc: 0.8955\n",
      "Epoch 028 | Train Loss: 0.2326 Acc: 0.9067 | Val Loss: 0.2879 Acc: 0.8792\n",
      "Epoch 029 | Train Loss: 0.2281 Acc: 0.9064 | Val Loss: 0.2746 Acc: 0.8931\n",
      "Epoch 030 | Train Loss: 0.2107 Acc: 0.9139 | Val Loss: 0.2537 Acc: 0.8901\n",
      "Epoch 031 | Train Loss: 0.2024 Acc: 0.9219 | Val Loss: 0.2667 Acc: 0.8883\n",
      "Epoch 032 | Train Loss: 0.2005 Acc: 0.9195 | Val Loss: 0.2328 Acc: 0.8992\n",
      "Epoch 033 | Train Loss: 0.1948 Acc: 0.9251 | Val Loss: 0.2189 Acc: 0.9136\n",
      "Epoch 034 | Train Loss: 0.1907 Acc: 0.9233 | Val Loss: 0.2009 Acc: 0.9227\n",
      "Epoch 035 | Train Loss: 0.1813 Acc: 0.9280 | Val Loss: 0.2092 Acc: 0.9155\n",
      "Epoch 036 | Train Loss: 0.1810 Acc: 0.9253 | Val Loss: 0.2097 Acc: 0.9191\n",
      "Epoch 037 | Train Loss: 0.1666 Acc: 0.9346 | Val Loss: 0.2173 Acc: 0.9149\n",
      "Epoch 038 | Train Loss: 0.1579 Acc: 0.9373 | Val Loss: 0.2180 Acc: 0.9227\n",
      "Epoch 039 | Train Loss: 0.1640 Acc: 0.9360 | Val Loss: 0.1955 Acc: 0.9269\n",
      "Epoch 040 | Train Loss: 0.1495 Acc: 0.9402 | Val Loss: 0.1975 Acc: 0.9269\n",
      "Epoch 041 | Train Loss: 0.1487 Acc: 0.9419 | Val Loss: 0.1806 Acc: 0.9306\n",
      "Epoch 042 | Train Loss: 0.1394 Acc: 0.9455 | Val Loss: 0.1813 Acc: 0.9342\n",
      "Epoch 043 | Train Loss: 0.1384 Acc: 0.9464 | Val Loss: 0.1754 Acc: 0.9336\n",
      "Epoch 044 | Train Loss: 0.1367 Acc: 0.9459 | Val Loss: 0.1805 Acc: 0.9330\n",
      "Epoch 045 | Train Loss: 0.1354 Acc: 0.9497 | Val Loss: 0.1745 Acc: 0.9378\n",
      "Epoch 046 | Train Loss: 0.1165 Acc: 0.9543 | Val Loss: 0.1741 Acc: 0.9324\n",
      "Epoch 047 | Train Loss: 0.1318 Acc: 0.9493 | Val Loss: 0.1845 Acc: 0.9306\n",
      "Epoch 048 | Train Loss: 0.1092 Acc: 0.9580 | Val Loss: 0.1897 Acc: 0.9306\n",
      "Epoch 049 | Train Loss: 0.1141 Acc: 0.9550 | Val Loss: 0.1597 Acc: 0.9408\n",
      "Epoch 050 | Train Loss: 0.1122 Acc: 0.9576 | Val Loss: 0.1926 Acc: 0.9293\n",
      "Epoch 051 | Train Loss: 0.1198 Acc: 0.9565 | Val Loss: 0.1907 Acc: 0.9300\n",
      "Epoch 052 | Train Loss: 0.1138 Acc: 0.9583 | Val Loss: 0.1722 Acc: 0.9360\n",
      "Epoch 053 | Train Loss: 0.1115 Acc: 0.9570 | Val Loss: 0.1581 Acc: 0.9408\n",
      "Epoch 054 | Train Loss: 0.0970 Acc: 0.9642 | Val Loss: 0.1538 Acc: 0.9420\n",
      "Epoch 055 | Train Loss: 0.1008 Acc: 0.9636 | Val Loss: 0.1769 Acc: 0.9354\n",
      "Epoch 056 | Train Loss: 0.1060 Acc: 0.9595 | Val Loss: 0.1523 Acc: 0.9420\n",
      "Epoch 057 | Train Loss: 0.0960 Acc: 0.9668 | Val Loss: 0.1510 Acc: 0.9402\n",
      "Epoch 058 | Train Loss: 0.0950 Acc: 0.9639 | Val Loss: 0.1652 Acc: 0.9378\n",
      "Epoch 059 | Train Loss: 0.0934 Acc: 0.9636 | Val Loss: 0.1605 Acc: 0.9444\n",
      "Epoch 060 | Train Loss: 0.0893 Acc: 0.9677 | Val Loss: 0.1797 Acc: 0.9463\n",
      "Epoch 001 | Train Loss: 0.6818 Acc: 0.5763 | Val Loss: 0.6822 Acc: 0.5761\n",
      "Epoch 002 | Train Loss: 0.6724 Acc: 0.5943 | Val Loss: 0.6622 Acc: 0.5960\n",
      "Epoch 003 | Train Loss: 0.6343 Acc: 0.6509 | Val Loss: 0.6127 Acc: 0.6757\n",
      "Epoch 004 | Train Loss: 0.5800 Acc: 0.7063 | Val Loss: 0.5564 Acc: 0.7204\n",
      "Epoch 005 | Train Loss: 0.5466 Acc: 0.7379 | Val Loss: 0.5409 Acc: 0.7283\n",
      "Epoch 006 | Train Loss: 0.5240 Acc: 0.7515 | Val Loss: 0.5008 Acc: 0.7548\n",
      "Epoch 007 | Train Loss: 0.5014 Acc: 0.7577 | Val Loss: 0.4769 Acc: 0.7742\n",
      "Epoch 008 | Train Loss: 0.4779 Acc: 0.7743 | Val Loss: 0.4632 Acc: 0.7736\n",
      "Epoch 009 | Train Loss: 0.4520 Acc: 0.7901 | Val Loss: 0.4579 Acc: 0.7832\n",
      "Epoch 010 | Train Loss: 0.4371 Acc: 0.7998 | Val Loss: 0.4224 Acc: 0.7923\n",
      "Epoch 011 | Train Loss: 0.4149 Acc: 0.8119 | Val Loss: 0.3882 Acc: 0.8110\n",
      "Epoch 012 | Train Loss: 0.3907 Acc: 0.8227 | Val Loss: 0.4059 Acc: 0.8031\n",
      "Epoch 013 | Train Loss: 0.3569 Acc: 0.8449 | Val Loss: 0.3502 Acc: 0.8370\n",
      "Epoch 014 | Train Loss: 0.3422 Acc: 0.8520 | Val Loss: 0.3429 Acc: 0.8406\n",
      "Epoch 015 | Train Loss: 0.3408 Acc: 0.8519 | Val Loss: 0.3631 Acc: 0.8303\n",
      "Epoch 016 | Train Loss: 0.3010 Acc: 0.8686 | Val Loss: 0.2956 Acc: 0.8726\n",
      "Epoch 017 | Train Loss: 0.2833 Acc: 0.8833 | Val Loss: 0.2755 Acc: 0.8841\n",
      "Epoch 018 | Train Loss: 0.2867 Acc: 0.8803 | Val Loss: 0.2859 Acc: 0.8732\n",
      "Epoch 019 | Train Loss: 0.2550 Acc: 0.8954 | Val Loss: 0.2543 Acc: 0.8913\n",
      "Epoch 020 | Train Loss: 0.2487 Acc: 0.8969 | Val Loss: 0.2467 Acc: 0.8841\n",
      "Epoch 021 | Train Loss: 0.2345 Acc: 0.9050 | Val Loss: 0.2546 Acc: 0.8877\n",
      "Epoch 022 | Train Loss: 0.2191 Acc: 0.9153 | Val Loss: 0.2456 Acc: 0.8961\n",
      "Epoch 023 | Train Loss: 0.2134 Acc: 0.9136 | Val Loss: 0.2796 Acc: 0.8847\n",
      "Epoch 024 | Train Loss: 0.2126 Acc: 0.9162 | Val Loss: 0.2307 Acc: 0.9046\n",
      "Epoch 025 | Train Loss: 0.1965 Acc: 0.9231 | Val Loss: 0.2282 Acc: 0.9088\n",
      "Epoch 026 | Train Loss: 0.1790 Acc: 0.9310 | Val Loss: 0.2098 Acc: 0.9130\n",
      "Epoch 027 | Train Loss: 0.1760 Acc: 0.9298 | Val Loss: 0.2144 Acc: 0.9136\n",
      "Epoch 028 | Train Loss: 0.1782 Acc: 0.9330 | Val Loss: 0.2116 Acc: 0.9155\n",
      "Epoch 029 | Train Loss: 0.1615 Acc: 0.9352 | Val Loss: 0.2309 Acc: 0.9082\n",
      "Epoch 030 | Train Loss: 0.1630 Acc: 0.9367 | Val Loss: 0.1956 Acc: 0.9191\n",
      "Epoch 031 | Train Loss: 0.1445 Acc: 0.9431 | Val Loss: 0.2159 Acc: 0.9227\n",
      "Epoch 032 | Train Loss: 0.1444 Acc: 0.9431 | Val Loss: 0.2331 Acc: 0.9016\n",
      "Epoch 033 | Train Loss: 0.1420 Acc: 0.9459 | Val Loss: 0.2020 Acc: 0.9185\n",
      "Epoch 034 | Train Loss: 0.1224 Acc: 0.9515 | Val Loss: 0.1796 Acc: 0.9275\n",
      "Epoch 035 | Train Loss: 0.1368 Acc: 0.9479 | Val Loss: 0.1823 Acc: 0.9293\n",
      "Epoch 036 | Train Loss: 0.1205 Acc: 0.9541 | Val Loss: 0.2262 Acc: 0.9185\n",
      "Epoch 037 | Train Loss: 0.1302 Acc: 0.9499 | Val Loss: 0.1730 Acc: 0.9336\n",
      "Epoch 038 | Train Loss: 0.1242 Acc: 0.9497 | Val Loss: 0.1623 Acc: 0.9354\n",
      "Epoch 039 | Train Loss: 0.1031 Acc: 0.9588 | Val Loss: 0.1750 Acc: 0.9342\n",
      "Epoch 040 | Train Loss: 0.1126 Acc: 0.9577 | Val Loss: 0.1806 Acc: 0.9330\n",
      "Epoch 041 | Train Loss: 0.1104 Acc: 0.9579 | Val Loss: 0.1658 Acc: 0.9360\n",
      "Epoch 042 | Train Loss: 0.1093 Acc: 0.9591 | Val Loss: 0.1659 Acc: 0.9420\n",
      "Epoch 043 | Train Loss: 0.1003 Acc: 0.9627 | Val Loss: 0.1714 Acc: 0.9378\n",
      "Epoch 044 | Train Loss: 0.1044 Acc: 0.9618 | Val Loss: 0.1568 Acc: 0.9432\n",
      "Epoch 045 | Train Loss: 0.1006 Acc: 0.9615 | Val Loss: 0.1543 Acc: 0.9408\n",
      "Epoch 046 | Train Loss: 0.0918 Acc: 0.9659 | Val Loss: 0.1737 Acc: 0.9360\n",
      "Epoch 047 | Train Loss: 0.0946 Acc: 0.9647 | Val Loss: 0.1643 Acc: 0.9390\n",
      "Epoch 048 | Train Loss: 0.0871 Acc: 0.9672 | Val Loss: 0.1647 Acc: 0.9438\n",
      "Epoch 049 | Train Loss: 0.0920 Acc: 0.9651 | Val Loss: 0.1866 Acc: 0.9257\n",
      "Epoch 050 | Train Loss: 0.0985 Acc: 0.9645 | Val Loss: 0.1355 Acc: 0.9390\n",
      "Epoch 051 | Train Loss: 0.0845 Acc: 0.9698 | Val Loss: 0.1563 Acc: 0.9390\n",
      "Epoch 052 | Train Loss: 0.0768 Acc: 0.9721 | Val Loss: 0.2109 Acc: 0.9318\n",
      "Epoch 053 | Train Loss: 0.0791 Acc: 0.9710 | Val Loss: 0.1498 Acc: 0.9463\n",
      "Epoch 054 | Train Loss: 0.0859 Acc: 0.9681 | Val Loss: 0.1516 Acc: 0.9432\n",
      "Epoch 055 | Train Loss: 0.0770 Acc: 0.9715 | Val Loss: 0.1709 Acc: 0.9414\n",
      "Epoch 056 | Train Loss: 0.0794 Acc: 0.9722 | Val Loss: 0.1339 Acc: 0.9493\n",
      "Epoch 057 | Train Loss: 0.0801 Acc: 0.9706 | Val Loss: 0.1505 Acc: 0.9396\n",
      "Epoch 058 | Train Loss: 0.0633 Acc: 0.9760 | Val Loss: 0.2115 Acc: 0.9366\n",
      "Epoch 059 | Train Loss: 0.0757 Acc: 0.9706 | Val Loss: 0.1634 Acc: 0.9396\n",
      "Epoch 060 | Train Loss: 0.0778 Acc: 0.9700 | Val Loss: 0.1706 Acc: 0.9481\n",
      "Epoch 001 | Train Loss: 0.6830 Acc: 0.5710 | Val Loss: 0.6818 Acc: 0.5713\n",
      "Epoch 002 | Train Loss: 0.6785 Acc: 0.5895 | Val Loss: 0.6747 Acc: 0.5912\n",
      "Epoch 003 | Train Loss: 0.6707 Acc: 0.5978 | Val Loss: 0.6711 Acc: 0.5996\n",
      "Epoch 004 | Train Loss: 0.6617 Acc: 0.6104 | Val Loss: 0.6643 Acc: 0.6045\n",
      "Epoch 005 | Train Loss: 0.6446 Acc: 0.6361 | Val Loss: 0.6144 Acc: 0.6775\n",
      "Epoch 006 | Train Loss: 0.6111 Acc: 0.6751 | Val Loss: 0.6018 Acc: 0.6824\n",
      "Epoch 007 | Train Loss: 0.5835 Acc: 0.7041 | Val Loss: 0.5805 Acc: 0.6950\n",
      "Epoch 008 | Train Loss: 0.5547 Acc: 0.7249 | Val Loss: 0.5643 Acc: 0.7077\n",
      "Epoch 009 | Train Loss: 0.5424 Acc: 0.7355 | Val Loss: 0.5413 Acc: 0.7264\n",
      "Epoch 010 | Train Loss: 0.5210 Acc: 0.7468 | Val Loss: 0.5351 Acc: 0.7301\n",
      "Epoch 011 | Train Loss: 0.5143 Acc: 0.7522 | Val Loss: 0.5328 Acc: 0.7295\n",
      "Epoch 012 | Train Loss: 0.4949 Acc: 0.7632 | Val Loss: 0.5212 Acc: 0.7415\n",
      "Epoch 013 | Train Loss: 0.4863 Acc: 0.7693 | Val Loss: 0.5043 Acc: 0.7470\n",
      "Epoch 014 | Train Loss: 0.4772 Acc: 0.7740 | Val Loss: 0.5248 Acc: 0.7434\n",
      "Epoch 015 | Train Loss: 0.4642 Acc: 0.7811 | Val Loss: 0.4846 Acc: 0.7657\n",
      "Epoch 016 | Train Loss: 0.4457 Acc: 0.7903 | Val Loss: 0.4592 Acc: 0.7796\n",
      "Epoch 017 | Train Loss: 0.4266 Acc: 0.8024 | Val Loss: 0.4292 Acc: 0.7917\n",
      "Epoch 018 | Train Loss: 0.4108 Acc: 0.8113 | Val Loss: 0.4665 Acc: 0.7778\n",
      "Epoch 019 | Train Loss: 0.3894 Acc: 0.8208 | Val Loss: 0.4120 Acc: 0.8050\n",
      "Epoch 020 | Train Loss: 0.3570 Acc: 0.8416 | Val Loss: 0.3809 Acc: 0.8285\n",
      "Epoch 021 | Train Loss: 0.3504 Acc: 0.8452 | Val Loss: 0.3563 Acc: 0.8394\n",
      "Epoch 022 | Train Loss: 0.3341 Acc: 0.8573 | Val Loss: 0.3626 Acc: 0.8376\n",
      "Epoch 023 | Train Loss: 0.3070 Acc: 0.8676 | Val Loss: 0.3075 Acc: 0.8696\n",
      "Epoch 024 | Train Loss: 0.2837 Acc: 0.8785 | Val Loss: 0.3086 Acc: 0.8865\n",
      "Epoch 025 | Train Loss: 0.2715 Acc: 0.8845 | Val Loss: 0.2852 Acc: 0.8829\n",
      "Epoch 026 | Train Loss: 0.2612 Acc: 0.8892 | Val Loss: 0.2587 Acc: 0.9022\n",
      "Epoch 027 | Train Loss: 0.2407 Acc: 0.9037 | Val Loss: 0.2697 Acc: 0.8961\n",
      "Epoch 028 | Train Loss: 0.2381 Acc: 0.9049 | Val Loss: 0.2598 Acc: 0.8925\n",
      "Epoch 029 | Train Loss: 0.2160 Acc: 0.9093 | Val Loss: 0.2619 Acc: 0.8901\n",
      "Epoch 030 | Train Loss: 0.1997 Acc: 0.9219 | Val Loss: 0.2379 Acc: 0.9022\n",
      "Epoch 031 | Train Loss: 0.1977 Acc: 0.9238 | Val Loss: 0.2130 Acc: 0.9149\n",
      "Epoch 032 | Train Loss: 0.1825 Acc: 0.9241 | Val Loss: 0.2027 Acc: 0.9179\n",
      "Epoch 033 | Train Loss: 0.1755 Acc: 0.9290 | Val Loss: 0.2155 Acc: 0.9179\n",
      "Epoch 034 | Train Loss: 0.1721 Acc: 0.9343 | Val Loss: 0.1865 Acc: 0.9281\n",
      "Epoch 035 | Train Loss: 0.1668 Acc: 0.9327 | Val Loss: 0.1939 Acc: 0.9306\n",
      "Epoch 036 | Train Loss: 0.1540 Acc: 0.9393 | Val Loss: 0.2026 Acc: 0.9245\n",
      "Epoch 037 | Train Loss: 0.1405 Acc: 0.9434 | Val Loss: 0.2395 Acc: 0.9028\n",
      "Epoch 038 | Train Loss: 0.1302 Acc: 0.9467 | Val Loss: 0.1956 Acc: 0.9287\n",
      "Epoch 039 | Train Loss: 0.1271 Acc: 0.9506 | Val Loss: 0.1855 Acc: 0.9275\n",
      "Epoch 040 | Train Loss: 0.1187 Acc: 0.9556 | Val Loss: 0.1797 Acc: 0.9293\n",
      "Epoch 041 | Train Loss: 0.1192 Acc: 0.9555 | Val Loss: 0.1750 Acc: 0.9324\n",
      "Epoch 042 | Train Loss: 0.1096 Acc: 0.9573 | Val Loss: 0.1790 Acc: 0.9342\n",
      "Epoch 043 | Train Loss: 0.1114 Acc: 0.9576 | Val Loss: 0.1585 Acc: 0.9438\n",
      "Epoch 044 | Train Loss: 0.0996 Acc: 0.9641 | Val Loss: 0.1887 Acc: 0.9281\n",
      "Epoch 045 | Train Loss: 0.1052 Acc: 0.9615 | Val Loss: 0.1600 Acc: 0.9438\n",
      "Epoch 046 | Train Loss: 0.0873 Acc: 0.9680 | Val Loss: 0.1905 Acc: 0.9348\n",
      "Epoch 047 | Train Loss: 0.0804 Acc: 0.9712 | Val Loss: 0.1856 Acc: 0.9396\n",
      "Epoch 048 | Train Loss: 0.0808 Acc: 0.9690 | Val Loss: 0.1712 Acc: 0.9396\n",
      "Epoch 049 | Train Loss: 0.0830 Acc: 0.9700 | Val Loss: 0.1944 Acc: 0.9372\n",
      "Epoch 050 | Train Loss: 0.0851 Acc: 0.9695 | Val Loss: 0.1636 Acc: 0.9420\n",
      "Epoch 051 | Train Loss: 0.0812 Acc: 0.9701 | Val Loss: 0.1594 Acc: 0.9469\n",
      "Epoch 052 | Train Loss: 0.0693 Acc: 0.9745 | Val Loss: 0.1781 Acc: 0.9414\n",
      "Epoch 053 | Train Loss: 0.0789 Acc: 0.9704 | Val Loss: 0.1665 Acc: 0.9438\n",
      "Early stopping triggered.\n",
      "Epoch 001 | Train Loss: 0.6824 Acc: 0.5754 | Val Loss: 0.6751 Acc: 0.5882\n",
      "Epoch 002 | Train Loss: 0.6763 Acc: 0.5905 | Val Loss: 0.6922 Acc: 0.5640\n",
      "Epoch 003 | Train Loss: 0.6749 Acc: 0.5896 | Val Loss: 0.6817 Acc: 0.5670\n",
      "Epoch 004 | Train Loss: 0.6667 Acc: 0.6024 | Val Loss: 0.6454 Acc: 0.6171\n",
      "Epoch 005 | Train Loss: 0.6040 Acc: 0.6868 | Val Loss: 0.5898 Acc: 0.6999\n",
      "Epoch 006 | Train Loss: 0.5721 Acc: 0.7131 | Val Loss: 0.5686 Acc: 0.7059\n",
      "Epoch 007 | Train Loss: 0.5488 Acc: 0.7276 | Val Loss: 0.5429 Acc: 0.7307\n",
      "Epoch 008 | Train Loss: 0.5381 Acc: 0.7376 | Val Loss: 0.5409 Acc: 0.7246\n",
      "Epoch 009 | Train Loss: 0.5131 Acc: 0.7534 | Val Loss: 0.5021 Acc: 0.7572\n",
      "Epoch 010 | Train Loss: 0.4926 Acc: 0.7608 | Val Loss: 0.4906 Acc: 0.7615\n",
      "Epoch 011 | Train Loss: 0.4700 Acc: 0.7790 | Val Loss: 0.4760 Acc: 0.7627\n",
      "Epoch 012 | Train Loss: 0.4508 Acc: 0.7854 | Val Loss: 0.4605 Acc: 0.7868\n",
      "Epoch 013 | Train Loss: 0.4426 Acc: 0.7933 | Val Loss: 0.4359 Acc: 0.7850\n",
      "Epoch 014 | Train Loss: 0.4251 Acc: 0.8064 | Val Loss: 0.3987 Acc: 0.8013\n",
      "Epoch 015 | Train Loss: 0.3943 Acc: 0.8182 | Val Loss: 0.3699 Acc: 0.8213\n",
      "Epoch 016 | Train Loss: 0.3893 Acc: 0.8241 | Val Loss: 0.3447 Acc: 0.8351\n",
      "Epoch 017 | Train Loss: 0.3693 Acc: 0.8319 | Val Loss: 0.3553 Acc: 0.8370\n",
      "Epoch 018 | Train Loss: 0.3511 Acc: 0.8464 | Val Loss: 0.3381 Acc: 0.8484\n",
      "Epoch 019 | Train Loss: 0.3299 Acc: 0.8558 | Val Loss: 0.3103 Acc: 0.8629\n",
      "Epoch 020 | Train Loss: 0.3168 Acc: 0.8667 | Val Loss: 0.3115 Acc: 0.8635\n",
      "Epoch 021 | Train Loss: 0.3125 Acc: 0.8674 | Val Loss: 0.2973 Acc: 0.8732\n",
      "Epoch 022 | Train Loss: 0.2996 Acc: 0.8759 | Val Loss: 0.2833 Acc: 0.8847\n",
      "Epoch 023 | Train Loss: 0.2808 Acc: 0.8827 | Val Loss: 0.2521 Acc: 0.8979\n",
      "Epoch 024 | Train Loss: 0.2655 Acc: 0.8889 | Val Loss: 0.2446 Acc: 0.9028\n",
      "Epoch 025 | Train Loss: 0.2649 Acc: 0.8859 | Val Loss: 0.2663 Acc: 0.8895\n",
      "Epoch 026 | Train Loss: 0.2501 Acc: 0.8976 | Val Loss: 0.2359 Acc: 0.9070\n",
      "Epoch 027 | Train Loss: 0.2440 Acc: 0.9029 | Val Loss: 0.2409 Acc: 0.9040\n",
      "Epoch 028 | Train Loss: 0.2290 Acc: 0.9053 | Val Loss: 0.2227 Acc: 0.9124\n",
      "Epoch 029 | Train Loss: 0.2102 Acc: 0.9171 | Val Loss: 0.2401 Acc: 0.8955\n",
      "Epoch 030 | Train Loss: 0.2204 Acc: 0.9121 | Val Loss: 0.2194 Acc: 0.9173\n",
      "Epoch 031 | Train Loss: 0.2128 Acc: 0.9147 | Val Loss: 0.2002 Acc: 0.9155\n",
      "Epoch 032 | Train Loss: 0.1955 Acc: 0.9224 | Val Loss: 0.1936 Acc: 0.9221\n",
      "Epoch 033 | Train Loss: 0.1937 Acc: 0.9247 | Val Loss: 0.1910 Acc: 0.9209\n",
      "Epoch 034 | Train Loss: 0.1836 Acc: 0.9275 | Val Loss: 0.2033 Acc: 0.9161\n",
      "Epoch 035 | Train Loss: 0.1806 Acc: 0.9333 | Val Loss: 0.1808 Acc: 0.9293\n",
      "Epoch 036 | Train Loss: 0.1755 Acc: 0.9331 | Val Loss: 0.1878 Acc: 0.9221\n",
      "Epoch 037 | Train Loss: 0.1718 Acc: 0.9363 | Val Loss: 0.1965 Acc: 0.9215\n",
      "Epoch 038 | Train Loss: 0.1693 Acc: 0.9364 | Val Loss: 0.1917 Acc: 0.9300\n",
      "Epoch 039 | Train Loss: 0.1671 Acc: 0.9358 | Val Loss: 0.1779 Acc: 0.9366\n",
      "Epoch 040 | Train Loss: 0.1646 Acc: 0.9381 | Val Loss: 0.2125 Acc: 0.9185\n",
      "Epoch 041 | Train Loss: 0.1530 Acc: 0.9434 | Val Loss: 0.1695 Acc: 0.9360\n",
      "Epoch 042 | Train Loss: 0.1578 Acc: 0.9385 | Val Loss: 0.1624 Acc: 0.9408\n",
      "Epoch 043 | Train Loss: 0.1434 Acc: 0.9446 | Val Loss: 0.1579 Acc: 0.9414\n",
      "Epoch 044 | Train Loss: 0.1467 Acc: 0.9426 | Val Loss: 0.1793 Acc: 0.9287\n",
      "Epoch 045 | Train Loss: 0.1436 Acc: 0.9450 | Val Loss: 0.1584 Acc: 0.9384\n",
      "Epoch 046 | Train Loss: 0.1362 Acc: 0.9493 | Val Loss: 0.1601 Acc: 0.9372\n",
      "Epoch 047 | Train Loss: 0.1475 Acc: 0.9438 | Val Loss: 0.1449 Acc: 0.9463\n",
      "Epoch 048 | Train Loss: 0.1364 Acc: 0.9470 | Val Loss: 0.1570 Acc: 0.9390\n",
      "Epoch 049 | Train Loss: 0.1282 Acc: 0.9523 | Val Loss: 0.1545 Acc: 0.9450\n",
      "Epoch 050 | Train Loss: 0.1397 Acc: 0.9459 | Val Loss: 0.1401 Acc: 0.9408\n",
      "Epoch 051 | Train Loss: 0.1211 Acc: 0.9565 | Val Loss: 0.1519 Acc: 0.9450\n",
      "Epoch 052 | Train Loss: 0.1250 Acc: 0.9564 | Val Loss: 0.1622 Acc: 0.9372\n",
      "Epoch 053 | Train Loss: 0.1167 Acc: 0.9556 | Val Loss: 0.1411 Acc: 0.9487\n",
      "Epoch 054 | Train Loss: 0.1229 Acc: 0.9541 | Val Loss: 0.1321 Acc: 0.9553\n",
      "Epoch 055 | Train Loss: 0.1119 Acc: 0.9597 | Val Loss: 0.1896 Acc: 0.9420\n",
      "Epoch 056 | Train Loss: 0.1118 Acc: 0.9585 | Val Loss: 0.1274 Acc: 0.9523\n",
      "Epoch 057 | Train Loss: 0.1237 Acc: 0.9536 | Val Loss: 0.1204 Acc: 0.9571\n",
      "Epoch 058 | Train Loss: 0.1086 Acc: 0.9594 | Val Loss: 0.1429 Acc: 0.9493\n",
      "Epoch 059 | Train Loss: 0.1160 Acc: 0.9576 | Val Loss: 0.1255 Acc: 0.9499\n",
      "Epoch 060 | Train Loss: 0.1098 Acc: 0.9595 | Val Loss: 0.1385 Acc: 0.9469\n",
      "Epoch 001 | Train Loss: 0.6793 Acc: 0.5830 | Val Loss: 0.6773 Acc: 0.5833\n",
      "Epoch 002 | Train Loss: 0.6673 Acc: 0.5981 | Val Loss: 0.6557 Acc: 0.6063\n",
      "Epoch 003 | Train Loss: 0.6469 Acc: 0.6390 | Val Loss: 0.6165 Acc: 0.6800\n",
      "Epoch 004 | Train Loss: 0.5992 Acc: 0.7015 | Val Loss: 0.6067 Acc: 0.6709\n",
      "Epoch 005 | Train Loss: 0.5709 Acc: 0.7172 | Val Loss: 0.5660 Acc: 0.7095\n",
      "Epoch 006 | Train Loss: 0.5424 Acc: 0.7311 | Val Loss: 0.5570 Acc: 0.7246\n",
      "Epoch 007 | Train Loss: 0.5358 Acc: 0.7300 | Val Loss: 0.5467 Acc: 0.7180\n",
      "Epoch 008 | Train Loss: 0.5237 Acc: 0.7444 | Val Loss: 0.5266 Acc: 0.7222\n",
      "Epoch 009 | Train Loss: 0.4969 Acc: 0.7543 | Val Loss: 0.4996 Acc: 0.7621\n",
      "Epoch 010 | Train Loss: 0.4788 Acc: 0.7684 | Val Loss: 0.4958 Acc: 0.7482\n",
      "Epoch 011 | Train Loss: 0.4714 Acc: 0.7728 | Val Loss: 0.4589 Acc: 0.7729\n",
      "Epoch 012 | Train Loss: 0.4510 Acc: 0.7889 | Val Loss: 0.4408 Acc: 0.7995\n",
      "Epoch 013 | Train Loss: 0.4319 Acc: 0.7963 | Val Loss: 0.4333 Acc: 0.8037\n",
      "Epoch 014 | Train Loss: 0.4105 Acc: 0.8095 | Val Loss: 0.4315 Acc: 0.7935\n",
      "Epoch 015 | Train Loss: 0.3915 Acc: 0.8161 | Val Loss: 0.3857 Acc: 0.8158\n",
      "Epoch 016 | Train Loss: 0.3828 Acc: 0.8277 | Val Loss: 0.3906 Acc: 0.8158\n",
      "Epoch 017 | Train Loss: 0.3600 Acc: 0.8407 | Val Loss: 0.3375 Acc: 0.8533\n",
      "Epoch 018 | Train Loss: 0.3442 Acc: 0.8499 | Val Loss: 0.3499 Acc: 0.8460\n",
      "Epoch 019 | Train Loss: 0.3266 Acc: 0.8564 | Val Loss: 0.3662 Acc: 0.8418\n",
      "Epoch 020 | Train Loss: 0.3091 Acc: 0.8658 | Val Loss: 0.3047 Acc: 0.8678\n",
      "Epoch 021 | Train Loss: 0.2889 Acc: 0.8789 | Val Loss: 0.2886 Acc: 0.8822\n",
      "Epoch 022 | Train Loss: 0.2838 Acc: 0.8833 | Val Loss: 0.2818 Acc: 0.8738\n",
      "Epoch 023 | Train Loss: 0.2656 Acc: 0.8842 | Val Loss: 0.2989 Acc: 0.8744\n",
      "Epoch 024 | Train Loss: 0.2455 Acc: 0.8999 | Val Loss: 0.2540 Acc: 0.8919\n",
      "Epoch 025 | Train Loss: 0.2402 Acc: 0.8988 | Val Loss: 0.2347 Acc: 0.9130\n",
      "Epoch 026 | Train Loss: 0.2281 Acc: 0.9016 | Val Loss: 0.2308 Acc: 0.9112\n",
      "Epoch 027 | Train Loss: 0.2097 Acc: 0.9145 | Val Loss: 0.2226 Acc: 0.9106\n",
      "Epoch 028 | Train Loss: 0.2001 Acc: 0.9215 | Val Loss: 0.2512 Acc: 0.9016\n",
      "Epoch 029 | Train Loss: 0.2063 Acc: 0.9171 | Val Loss: 0.2292 Acc: 0.9094\n",
      "Epoch 030 | Train Loss: 0.1979 Acc: 0.9236 | Val Loss: 0.2184 Acc: 0.9034\n",
      "Epoch 031 | Train Loss: 0.1871 Acc: 0.9248 | Val Loss: 0.2168 Acc: 0.9112\n",
      "Epoch 032 | Train Loss: 0.1773 Acc: 0.9296 | Val Loss: 0.2008 Acc: 0.9197\n",
      "Epoch 033 | Train Loss: 0.1711 Acc: 0.9333 | Val Loss: 0.1928 Acc: 0.9269\n",
      "Epoch 034 | Train Loss: 0.1792 Acc: 0.9293 | Val Loss: 0.2173 Acc: 0.9124\n",
      "Epoch 035 | Train Loss: 0.1599 Acc: 0.9392 | Val Loss: 0.2034 Acc: 0.9191\n",
      "Epoch 036 | Train Loss: 0.1613 Acc: 0.9378 | Val Loss: 0.1968 Acc: 0.9312\n",
      "Epoch 037 | Train Loss: 0.1382 Acc: 0.9456 | Val Loss: 0.2026 Acc: 0.9263\n",
      "Epoch 038 | Train Loss: 0.1595 Acc: 0.9378 | Val Loss: 0.2110 Acc: 0.9173\n",
      "Epoch 039 | Train Loss: 0.1481 Acc: 0.9434 | Val Loss: 0.1873 Acc: 0.9342\n",
      "Epoch 040 | Train Loss: 0.1346 Acc: 0.9488 | Val Loss: 0.1977 Acc: 0.9293\n",
      "Epoch 041 | Train Loss: 0.1324 Acc: 0.9481 | Val Loss: 0.2012 Acc: 0.9275\n",
      "Epoch 042 | Train Loss: 0.1280 Acc: 0.9508 | Val Loss: 0.2138 Acc: 0.9281\n",
      "Epoch 043 | Train Loss: 0.1198 Acc: 0.9546 | Val Loss: 0.2191 Acc: 0.9197\n",
      "Epoch 044 | Train Loss: 0.1267 Acc: 0.9490 | Val Loss: 0.2140 Acc: 0.9173\n",
      "Epoch 045 | Train Loss: 0.1389 Acc: 0.9461 | Val Loss: 0.1976 Acc: 0.9336\n",
      "Epoch 046 | Train Loss: 0.1202 Acc: 0.9526 | Val Loss: 0.2176 Acc: 0.9215\n",
      "Epoch 047 | Train Loss: 0.1220 Acc: 0.9549 | Val Loss: 0.1804 Acc: 0.9348\n",
      "Epoch 048 | Train Loss: 0.1132 Acc: 0.9588 | Val Loss: 0.2049 Acc: 0.9263\n",
      "Epoch 049 | Train Loss: 0.1117 Acc: 0.9585 | Val Loss: 0.1901 Acc: 0.9209\n",
      "Epoch 050 | Train Loss: 0.1141 Acc: 0.9573 | Val Loss: 0.1724 Acc: 0.9414\n",
      "Epoch 051 | Train Loss: 0.1096 Acc: 0.9601 | Val Loss: 0.1625 Acc: 0.9396\n",
      "Epoch 052 | Train Loss: 0.1127 Acc: 0.9573 | Val Loss: 0.1489 Acc: 0.9463\n",
      "Epoch 053 | Train Loss: 0.0968 Acc: 0.9654 | Val Loss: 0.1642 Acc: 0.9463\n",
      "Epoch 054 | Train Loss: 0.0969 Acc: 0.9648 | Val Loss: 0.1801 Acc: 0.9414\n",
      "Epoch 055 | Train Loss: 0.0932 Acc: 0.9656 | Val Loss: 0.1458 Acc: 0.9493\n",
      "Epoch 056 | Train Loss: 0.0908 Acc: 0.9659 | Val Loss: 0.1710 Acc: 0.9444\n",
      "Epoch 057 | Train Loss: 0.1011 Acc: 0.9613 | Val Loss: 0.1913 Acc: 0.9366\n",
      "Epoch 058 | Train Loss: 0.0893 Acc: 0.9650 | Val Loss: 0.1501 Acc: 0.9420\n",
      "Epoch 059 | Train Loss: 0.0918 Acc: 0.9675 | Val Loss: 0.1424 Acc: 0.9505\n",
      "Epoch 060 | Train Loss: 0.0976 Acc: 0.9616 | Val Loss: 0.1432 Acc: 0.9457\n",
      "Epoch 001 | Train Loss: 0.6844 Acc: 0.5695 | Val Loss: 0.6863 Acc: 0.5586\n",
      "Epoch 002 | Train Loss: 0.6821 Acc: 0.5765 | Val Loss: 0.6760 Acc: 0.5912\n",
      "Epoch 003 | Train Loss: 0.6696 Acc: 0.5975 | Val Loss: 0.6661 Acc: 0.6033\n",
      "Epoch 004 | Train Loss: 0.6629 Acc: 0.6032 | Val Loss: 0.6535 Acc: 0.6135\n",
      "Epoch 005 | Train Loss: 0.6550 Acc: 0.6126 | Val Loss: 0.6481 Acc: 0.6063\n",
      "Epoch 006 | Train Loss: 0.6196 Acc: 0.6739 | Val Loss: 0.5877 Acc: 0.6999\n",
      "Epoch 007 | Train Loss: 0.5919 Acc: 0.7003 | Val Loss: 0.5807 Acc: 0.6987\n",
      "Epoch 008 | Train Loss: 0.5576 Acc: 0.7237 | Val Loss: 0.5521 Acc: 0.7168\n",
      "Epoch 009 | Train Loss: 0.5352 Acc: 0.7385 | Val Loss: 0.5320 Acc: 0.7240\n",
      "Epoch 010 | Train Loss: 0.5199 Acc: 0.7460 | Val Loss: 0.5136 Acc: 0.7355\n",
      "Epoch 011 | Train Loss: 0.5099 Acc: 0.7527 | Val Loss: 0.4960 Acc: 0.7542\n",
      "Epoch 012 | Train Loss: 0.4923 Acc: 0.7631 | Val Loss: 0.4790 Acc: 0.7669\n",
      "Epoch 013 | Train Loss: 0.4663 Acc: 0.7741 | Val Loss: 0.4804 Acc: 0.7675\n",
      "Epoch 014 | Train Loss: 0.4497 Acc: 0.7886 | Val Loss: 0.4472 Acc: 0.7832\n",
      "Epoch 015 | Train Loss: 0.4422 Acc: 0.7956 | Val Loss: 0.4594 Acc: 0.7760\n",
      "Epoch 016 | Train Loss: 0.4345 Acc: 0.7983 | Val Loss: 0.4500 Acc: 0.7899\n",
      "Epoch 017 | Train Loss: 0.4145 Acc: 0.8081 | Val Loss: 0.3817 Acc: 0.8303\n",
      "Epoch 018 | Train Loss: 0.3900 Acc: 0.8247 | Val Loss: 0.3895 Acc: 0.8188\n",
      "Epoch 019 | Train Loss: 0.3780 Acc: 0.8295 | Val Loss: 0.3838 Acc: 0.8255\n",
      "Epoch 020 | Train Loss: 0.3674 Acc: 0.8286 | Val Loss: 0.3955 Acc: 0.8237\n",
      "Epoch 021 | Train Loss: 0.3550 Acc: 0.8434 | Val Loss: 0.3550 Acc: 0.8376\n",
      "Epoch 022 | Train Loss: 0.3255 Acc: 0.8529 | Val Loss: 0.3224 Acc: 0.8454\n",
      "Epoch 023 | Train Loss: 0.3096 Acc: 0.8659 | Val Loss: 0.3091 Acc: 0.8684\n",
      "Epoch 024 | Train Loss: 0.2977 Acc: 0.8709 | Val Loss: 0.3301 Acc: 0.8605\n",
      "Epoch 025 | Train Loss: 0.3004 Acc: 0.8676 | Val Loss: 0.2736 Acc: 0.8877\n",
      "Epoch 026 | Train Loss: 0.2798 Acc: 0.8849 | Val Loss: 0.2856 Acc: 0.8720\n",
      "Epoch 027 | Train Loss: 0.2786 Acc: 0.8786 | Val Loss: 0.2905 Acc: 0.8678\n",
      "Epoch 028 | Train Loss: 0.2559 Acc: 0.8925 | Val Loss: 0.2392 Acc: 0.9040\n",
      "Epoch 029 | Train Loss: 0.2397 Acc: 0.9014 | Val Loss: 0.2383 Acc: 0.8907\n",
      "Epoch 030 | Train Loss: 0.2634 Acc: 0.8901 | Val Loss: 0.2435 Acc: 0.8931\n",
      "Epoch 031 | Train Loss: 0.2461 Acc: 0.8997 | Val Loss: 0.2256 Acc: 0.9124\n",
      "Epoch 032 | Train Loss: 0.2285 Acc: 0.9050 | Val Loss: 0.2434 Acc: 0.8949\n",
      "Epoch 033 | Train Loss: 0.2178 Acc: 0.9070 | Val Loss: 0.2104 Acc: 0.9076\n",
      "Epoch 034 | Train Loss: 0.2013 Acc: 0.9136 | Val Loss: 0.2165 Acc: 0.9149\n",
      "Epoch 035 | Train Loss: 0.1960 Acc: 0.9174 | Val Loss: 0.2003 Acc: 0.9167\n",
      "Epoch 036 | Train Loss: 0.1926 Acc: 0.9224 | Val Loss: 0.1942 Acc: 0.9185\n",
      "Epoch 037 | Train Loss: 0.1782 Acc: 0.9233 | Val Loss: 0.1824 Acc: 0.9197\n",
      "Epoch 038 | Train Loss: 0.1880 Acc: 0.9238 | Val Loss: 0.1800 Acc: 0.9318\n",
      "Epoch 039 | Train Loss: 0.1832 Acc: 0.9286 | Val Loss: 0.2400 Acc: 0.9064\n",
      "Epoch 040 | Train Loss: 0.1784 Acc: 0.9292 | Val Loss: 0.1694 Acc: 0.9378\n",
      "Epoch 041 | Train Loss: 0.1763 Acc: 0.9315 | Val Loss: 0.1681 Acc: 0.9330\n",
      "Epoch 042 | Train Loss: 0.1534 Acc: 0.9387 | Val Loss: 0.1670 Acc: 0.9420\n",
      "Epoch 043 | Train Loss: 0.1590 Acc: 0.9398 | Val Loss: 0.1606 Acc: 0.9366\n",
      "Epoch 044 | Train Loss: 0.1474 Acc: 0.9459 | Val Loss: 0.1708 Acc: 0.9360\n",
      "Epoch 045 | Train Loss: 0.1488 Acc: 0.9411 | Val Loss: 0.1501 Acc: 0.9444\n",
      "Epoch 046 | Train Loss: 0.1450 Acc: 0.9411 | Val Loss: 0.1798 Acc: 0.9306\n",
      "Epoch 047 | Train Loss: 0.1427 Acc: 0.9452 | Val Loss: 0.1581 Acc: 0.9275\n",
      "Epoch 048 | Train Loss: 0.1320 Acc: 0.9502 | Val Loss: 0.1665 Acc: 0.9348\n",
      "Epoch 049 | Train Loss: 0.1330 Acc: 0.9517 | Val Loss: 0.1540 Acc: 0.9426\n",
      "Epoch 050 | Train Loss: 0.1298 Acc: 0.9482 | Val Loss: 0.1526 Acc: 0.9444\n",
      "Epoch 051 | Train Loss: 0.1236 Acc: 0.9546 | Val Loss: 0.1570 Acc: 0.9420\n",
      "Epoch 052 | Train Loss: 0.1305 Acc: 0.9506 | Val Loss: 0.1555 Acc: 0.9408\n",
      "Epoch 053 | Train Loss: 0.1204 Acc: 0.9544 | Val Loss: 0.1468 Acc: 0.9414\n",
      "Epoch 054 | Train Loss: 0.1107 Acc: 0.9592 | Val Loss: 0.1625 Acc: 0.9372\n",
      "Epoch 055 | Train Loss: 0.1174 Acc: 0.9574 | Val Loss: 0.1644 Acc: 0.9360\n",
      "Epoch 056 | Train Loss: 0.1223 Acc: 0.9543 | Val Loss: 0.1826 Acc: 0.9318\n",
      "Epoch 057 | Train Loss: 0.1198 Acc: 0.9568 | Val Loss: 0.1445 Acc: 0.9438\n",
      "Epoch 058 | Train Loss: 0.1077 Acc: 0.9604 | Val Loss: 0.1660 Acc: 0.9384\n",
      "Epoch 059 | Train Loss: 0.0964 Acc: 0.9654 | Val Loss: 0.1510 Acc: 0.9414\n",
      "Epoch 060 | Train Loss: 0.1041 Acc: 0.9632 | Val Loss: 0.1684 Acc: 0.9414\n",
      "Iteration 26/40 | Best Val Loss: 0.1122 | Iter Time: 230.10s | Total Time: 108.71 min\n",
      "Epoch 001 | Train Loss: 0.6807 Acc: 0.5747 | Val Loss: 0.6746 Acc: 0.5876\n",
      "Epoch 002 | Train Loss: 0.6682 Acc: 0.5960 | Val Loss: 0.6623 Acc: 0.6063\n",
      "Epoch 003 | Train Loss: 0.6558 Acc: 0.6100 | Val Loss: 0.6556 Acc: 0.6063\n",
      "Epoch 004 | Train Loss: 0.6437 Acc: 0.6367 | Val Loss: 0.6245 Acc: 0.6697\n",
      "Epoch 005 | Train Loss: 0.6046 Acc: 0.6921 | Val Loss: 0.5954 Acc: 0.6860\n",
      "Epoch 006 | Train Loss: 0.5682 Acc: 0.7202 | Val Loss: 0.5580 Acc: 0.7192\n",
      "Epoch 007 | Train Loss: 0.5567 Acc: 0.7241 | Val Loss: 0.5562 Acc: 0.7150\n",
      "Epoch 008 | Train Loss: 0.5383 Acc: 0.7355 | Val Loss: 0.5367 Acc: 0.7246\n",
      "Epoch 009 | Train Loss: 0.5240 Acc: 0.7475 | Val Loss: 0.5350 Acc: 0.7301\n",
      "Epoch 010 | Train Loss: 0.5199 Acc: 0.7512 | Val Loss: 0.5299 Acc: 0.7343\n",
      "Epoch 011 | Train Loss: 0.4951 Acc: 0.7648 | Val Loss: 0.4993 Acc: 0.7597\n",
      "Epoch 012 | Train Loss: 0.4868 Acc: 0.7682 | Val Loss: 0.4874 Acc: 0.7572\n",
      "Epoch 013 | Train Loss: 0.4690 Acc: 0.7815 | Val Loss: 0.4775 Acc: 0.7754\n",
      "Epoch 014 | Train Loss: 0.4509 Acc: 0.7937 | Val Loss: 0.4956 Acc: 0.7500\n",
      "Epoch 015 | Train Loss: 0.4391 Acc: 0.8019 | Val Loss: 0.4648 Acc: 0.7766\n",
      "Epoch 016 | Train Loss: 0.4210 Acc: 0.8087 | Val Loss: 0.4354 Acc: 0.7886\n",
      "Epoch 017 | Train Loss: 0.3994 Acc: 0.8202 | Val Loss: 0.4731 Acc: 0.7723\n",
      "Epoch 018 | Train Loss: 0.3790 Acc: 0.8268 | Val Loss: 0.4024 Acc: 0.8140\n",
      "Epoch 019 | Train Loss: 0.3634 Acc: 0.8354 | Val Loss: 0.3719 Acc: 0.8297\n",
      "Epoch 020 | Train Loss: 0.3555 Acc: 0.8374 | Val Loss: 0.3791 Acc: 0.8243\n",
      "Epoch 021 | Train Loss: 0.3346 Acc: 0.8540 | Val Loss: 0.3510 Acc: 0.8376\n",
      "Epoch 022 | Train Loss: 0.3133 Acc: 0.8621 | Val Loss: 0.3215 Acc: 0.8678\n",
      "Epoch 023 | Train Loss: 0.2949 Acc: 0.8765 | Val Loss: 0.3188 Acc: 0.8671\n",
      "Epoch 024 | Train Loss: 0.2849 Acc: 0.8780 | Val Loss: 0.3134 Acc: 0.8714\n",
      "Epoch 025 | Train Loss: 0.2658 Acc: 0.8878 | Val Loss: 0.3055 Acc: 0.8647\n",
      "Epoch 026 | Train Loss: 0.2600 Acc: 0.8920 | Val Loss: 0.2881 Acc: 0.8798\n",
      "Epoch 027 | Train Loss: 0.2319 Acc: 0.9037 | Val Loss: 0.3080 Acc: 0.8744\n",
      "Epoch 028 | Train Loss: 0.2513 Acc: 0.8951 | Val Loss: 0.2674 Acc: 0.8889\n",
      "Epoch 029 | Train Loss: 0.2067 Acc: 0.9203 | Val Loss: 0.3051 Acc: 0.8774\n",
      "Epoch 030 | Train Loss: 0.2049 Acc: 0.9153 | Val Loss: 0.2520 Acc: 0.9028\n",
      "Epoch 031 | Train Loss: 0.1934 Acc: 0.9207 | Val Loss: 0.2278 Acc: 0.9094\n",
      "Epoch 032 | Train Loss: 0.1801 Acc: 0.9272 | Val Loss: 0.2468 Acc: 0.8919\n",
      "Epoch 033 | Train Loss: 0.1797 Acc: 0.9298 | Val Loss: 0.2282 Acc: 0.9094\n",
      "Epoch 034 | Train Loss: 0.1686 Acc: 0.9342 | Val Loss: 0.2507 Acc: 0.9004\n",
      "Epoch 035 | Train Loss: 0.1627 Acc: 0.9372 | Val Loss: 0.2259 Acc: 0.9052\n",
      "Epoch 036 | Train Loss: 0.1617 Acc: 0.9370 | Val Loss: 0.2397 Acc: 0.9022\n",
      "Epoch 037 | Train Loss: 0.1628 Acc: 0.9345 | Val Loss: 0.2241 Acc: 0.9112\n",
      "Epoch 038 | Train Loss: 0.1372 Acc: 0.9487 | Val Loss: 0.2218 Acc: 0.9179\n",
      "Epoch 039 | Train Loss: 0.1277 Acc: 0.9496 | Val Loss: 0.2049 Acc: 0.9215\n",
      "Epoch 040 | Train Loss: 0.1314 Acc: 0.9472 | Val Loss: 0.1965 Acc: 0.9269\n",
      "Epoch 041 | Train Loss: 0.1265 Acc: 0.9515 | Val Loss: 0.2098 Acc: 0.9161\n",
      "Epoch 042 | Train Loss: 0.1197 Acc: 0.9564 | Val Loss: 0.1973 Acc: 0.9275\n",
      "Epoch 043 | Train Loss: 0.1115 Acc: 0.9573 | Val Loss: 0.2491 Acc: 0.9052\n",
      "Epoch 044 | Train Loss: 0.1102 Acc: 0.9565 | Val Loss: 0.2297 Acc: 0.9124\n",
      "Epoch 045 | Train Loss: 0.0976 Acc: 0.9610 | Val Loss: 0.1807 Acc: 0.9342\n",
      "Epoch 046 | Train Loss: 0.1018 Acc: 0.9623 | Val Loss: 0.1818 Acc: 0.9312\n",
      "Epoch 047 | Train Loss: 0.0977 Acc: 0.9644 | Val Loss: 0.1850 Acc: 0.9342\n",
      "Epoch 048 | Train Loss: 0.0919 Acc: 0.9653 | Val Loss: 0.1876 Acc: 0.9306\n",
      "Epoch 049 | Train Loss: 0.0967 Acc: 0.9641 | Val Loss: 0.1654 Acc: 0.9396\n",
      "Epoch 050 | Train Loss: 0.0838 Acc: 0.9675 | Val Loss: 0.1899 Acc: 0.9360\n",
      "Epoch 051 | Train Loss: 0.0913 Acc: 0.9639 | Val Loss: 0.1733 Acc: 0.9366\n",
      "Epoch 052 | Train Loss: 0.0826 Acc: 0.9698 | Val Loss: 0.1836 Acc: 0.9306\n",
      "Epoch 053 | Train Loss: 0.0817 Acc: 0.9681 | Val Loss: 0.2101 Acc: 0.9251\n",
      "Epoch 054 | Train Loss: 0.0863 Acc: 0.9668 | Val Loss: 0.1679 Acc: 0.9384\n",
      "Epoch 055 | Train Loss: 0.0732 Acc: 0.9731 | Val Loss: 0.1830 Acc: 0.9420\n",
      "Epoch 056 | Train Loss: 0.0749 Acc: 0.9719 | Val Loss: 0.1916 Acc: 0.9348\n",
      "Epoch 057 | Train Loss: 0.0880 Acc: 0.9672 | Val Loss: 0.1717 Acc: 0.9348\n",
      "Epoch 058 | Train Loss: 0.0624 Acc: 0.9777 | Val Loss: 0.1952 Acc: 0.9354\n",
      "Epoch 059 | Train Loss: 0.0688 Acc: 0.9748 | Val Loss: 0.2044 Acc: 0.9336\n",
      "Early stopping triggered.\n",
      "Epoch 001 | Train Loss: 0.6754 Acc: 0.5861 | Val Loss: 0.6602 Acc: 0.5960\n",
      "Epoch 002 | Train Loss: 0.6191 Acc: 0.6684 | Val Loss: 0.5789 Acc: 0.7101\n",
      "Epoch 003 | Train Loss: 0.5636 Acc: 0.7122 | Val Loss: 0.5621 Acc: 0.7289\n",
      "Epoch 004 | Train Loss: 0.5268 Acc: 0.7417 | Val Loss: 0.5330 Acc: 0.7482\n",
      "Epoch 005 | Train Loss: 0.5078 Acc: 0.7513 | Val Loss: 0.5068 Acc: 0.7566\n",
      "Epoch 006 | Train Loss: 0.4715 Acc: 0.7761 | Val Loss: 0.4524 Acc: 0.7874\n",
      "Epoch 007 | Train Loss: 0.4461 Acc: 0.7856 | Val Loss: 0.4379 Acc: 0.7929\n",
      "Epoch 008 | Train Loss: 0.4072 Acc: 0.8184 | Val Loss: 0.4099 Acc: 0.8122\n",
      "Epoch 009 | Train Loss: 0.3809 Acc: 0.8316 | Val Loss: 0.4325 Acc: 0.8007\n",
      "Epoch 010 | Train Loss: 0.3514 Acc: 0.8446 | Val Loss: 0.3849 Acc: 0.8188\n",
      "Epoch 011 | Train Loss: 0.3187 Acc: 0.8603 | Val Loss: 0.3534 Acc: 0.8502\n",
      "Epoch 012 | Train Loss: 0.2994 Acc: 0.8691 | Val Loss: 0.3037 Acc: 0.8714\n",
      "Epoch 013 | Train Loss: 0.2640 Acc: 0.8878 | Val Loss: 0.3215 Acc: 0.8665\n",
      "Epoch 014 | Train Loss: 0.2393 Acc: 0.8978 | Val Loss: 0.2422 Acc: 0.9028\n",
      "Epoch 015 | Train Loss: 0.2327 Acc: 0.9040 | Val Loss: 0.2970 Acc: 0.8702\n",
      "Epoch 016 | Train Loss: 0.2143 Acc: 0.9127 | Val Loss: 0.2521 Acc: 0.8943\n",
      "Epoch 017 | Train Loss: 0.1909 Acc: 0.9218 | Val Loss: 0.2398 Acc: 0.8998\n",
      "Epoch 018 | Train Loss: 0.1770 Acc: 0.9308 | Val Loss: 0.2118 Acc: 0.9143\n",
      "Epoch 019 | Train Loss: 0.1820 Acc: 0.9286 | Val Loss: 0.2045 Acc: 0.9106\n",
      "Epoch 020 | Train Loss: 0.1590 Acc: 0.9375 | Val Loss: 0.2047 Acc: 0.9215\n",
      "Epoch 021 | Train Loss: 0.1641 Acc: 0.9328 | Val Loss: 0.1878 Acc: 0.9269\n",
      "Epoch 022 | Train Loss: 0.1363 Acc: 0.9493 | Val Loss: 0.2078 Acc: 0.9124\n",
      "Epoch 023 | Train Loss: 0.1331 Acc: 0.9446 | Val Loss: 0.1773 Acc: 0.9281\n",
      "Epoch 024 | Train Loss: 0.1269 Acc: 0.9508 | Val Loss: 0.1646 Acc: 0.9390\n",
      "Epoch 025 | Train Loss: 0.1200 Acc: 0.9544 | Val Loss: 0.1995 Acc: 0.9233\n",
      "Epoch 026 | Train Loss: 0.1157 Acc: 0.9530 | Val Loss: 0.1736 Acc: 0.9306\n",
      "Epoch 027 | Train Loss: 0.1037 Acc: 0.9600 | Val Loss: 0.1703 Acc: 0.9354\n",
      "Epoch 028 | Train Loss: 0.0967 Acc: 0.9648 | Val Loss: 0.1836 Acc: 0.9263\n",
      "Epoch 029 | Train Loss: 0.1019 Acc: 0.9609 | Val Loss: 0.1834 Acc: 0.9293\n",
      "Epoch 030 | Train Loss: 0.0920 Acc: 0.9660 | Val Loss: 0.2310 Acc: 0.9203\n",
      "Epoch 031 | Train Loss: 0.0874 Acc: 0.9662 | Val Loss: 0.2125 Acc: 0.9251\n",
      "Epoch 032 | Train Loss: 0.0873 Acc: 0.9686 | Val Loss: 0.1639 Acc: 0.9408\n",
      "Epoch 033 | Train Loss: 0.0762 Acc: 0.9709 | Val Loss: 0.1735 Acc: 0.9336\n",
      "Epoch 034 | Train Loss: 0.0832 Acc: 0.9695 | Val Loss: 0.1544 Acc: 0.9420\n",
      "Epoch 035 | Train Loss: 0.0757 Acc: 0.9743 | Val Loss: 0.2192 Acc: 0.9227\n",
      "Epoch 036 | Train Loss: 0.0747 Acc: 0.9731 | Val Loss: 0.1825 Acc: 0.9366\n",
      "Epoch 037 | Train Loss: 0.0677 Acc: 0.9755 | Val Loss: 0.2134 Acc: 0.9366\n",
      "Epoch 038 | Train Loss: 0.0700 Acc: 0.9736 | Val Loss: 0.1909 Acc: 0.9330\n",
      "Epoch 039 | Train Loss: 0.0695 Acc: 0.9740 | Val Loss: 0.1569 Acc: 0.9463\n",
      "Epoch 040 | Train Loss: 0.0663 Acc: 0.9745 | Val Loss: 0.1991 Acc: 0.9312\n",
      "Epoch 041 | Train Loss: 0.0727 Acc: 0.9721 | Val Loss: 0.1536 Acc: 0.9432\n",
      "Epoch 042 | Train Loss: 0.0618 Acc: 0.9749 | Val Loss: 0.1547 Acc: 0.9414\n",
      "Epoch 043 | Train Loss: 0.0514 Acc: 0.9798 | Val Loss: 0.1933 Acc: 0.9366\n",
      "Epoch 044 | Train Loss: 0.0682 Acc: 0.9752 | Val Loss: 0.1564 Acc: 0.9444\n",
      "Epoch 045 | Train Loss: 0.0645 Acc: 0.9752 | Val Loss: 0.1579 Acc: 0.9469\n",
      "Epoch 046 | Train Loss: 0.0556 Acc: 0.9793 | Val Loss: 0.1869 Acc: 0.9414\n",
      "Epoch 047 | Train Loss: 0.0658 Acc: 0.9752 | Val Loss: 0.2745 Acc: 0.9118\n",
      "Epoch 048 | Train Loss: 0.0583 Acc: 0.9786 | Val Loss: 0.1664 Acc: 0.9372\n",
      "Epoch 049 | Train Loss: 0.0599 Acc: 0.9769 | Val Loss: 0.1596 Acc: 0.9481\n",
      "Epoch 050 | Train Loss: 0.0541 Acc: 0.9805 | Val Loss: 0.1581 Acc: 0.9426\n",
      "Epoch 051 | Train Loss: 0.0482 Acc: 0.9817 | Val Loss: 0.1839 Acc: 0.9390\n",
      "Early stopping triggered.\n",
      "Epoch 001 | Train Loss: 0.6813 Acc: 0.5742 | Val Loss: 0.6795 Acc: 0.5767\n",
      "Epoch 002 | Train Loss: 0.6658 Acc: 0.5967 | Val Loss: 0.6550 Acc: 0.6232\n",
      "Epoch 003 | Train Loss: 0.6258 Acc: 0.6615 | Val Loss: 0.5979 Acc: 0.6836\n",
      "Epoch 004 | Train Loss: 0.5740 Acc: 0.7136 | Val Loss: 0.5632 Acc: 0.7204\n",
      "Epoch 005 | Train Loss: 0.5428 Acc: 0.7343 | Val Loss: 0.5434 Acc: 0.7337\n",
      "Epoch 006 | Train Loss: 0.5141 Acc: 0.7515 | Val Loss: 0.5115 Acc: 0.7500\n",
      "Epoch 007 | Train Loss: 0.4933 Acc: 0.7574 | Val Loss: 0.5002 Acc: 0.7542\n",
      "Epoch 008 | Train Loss: 0.4712 Acc: 0.7771 | Val Loss: 0.4855 Acc: 0.7452\n",
      "Epoch 009 | Train Loss: 0.4548 Acc: 0.7921 | Val Loss: 0.4618 Acc: 0.7663\n",
      "Epoch 010 | Train Loss: 0.4286 Acc: 0.8045 | Val Loss: 0.4371 Acc: 0.7850\n",
      "Epoch 011 | Train Loss: 0.3960 Acc: 0.8191 | Val Loss: 0.3985 Acc: 0.8050\n",
      "Epoch 012 | Train Loss: 0.3743 Acc: 0.8345 | Val Loss: 0.3596 Acc: 0.8309\n",
      "Epoch 013 | Train Loss: 0.3529 Acc: 0.8443 | Val Loss: 0.3455 Acc: 0.8460\n",
      "Epoch 014 | Train Loss: 0.3250 Acc: 0.8561 | Val Loss: 0.3250 Acc: 0.8436\n",
      "Epoch 015 | Train Loss: 0.3163 Acc: 0.8691 | Val Loss: 0.3072 Acc: 0.8611\n",
      "Epoch 016 | Train Loss: 0.2947 Acc: 0.8720 | Val Loss: 0.2730 Acc: 0.8895\n",
      "Epoch 017 | Train Loss: 0.2706 Acc: 0.8902 | Val Loss: 0.2768 Acc: 0.8835\n",
      "Epoch 018 | Train Loss: 0.2551 Acc: 0.8934 | Val Loss: 0.2694 Acc: 0.8907\n",
      "Epoch 019 | Train Loss: 0.2522 Acc: 0.8966 | Val Loss: 0.2451 Acc: 0.8967\n",
      "Epoch 020 | Train Loss: 0.2223 Acc: 0.9090 | Val Loss: 0.2546 Acc: 0.8955\n",
      "Epoch 021 | Train Loss: 0.2218 Acc: 0.9074 | Val Loss: 0.2560 Acc: 0.8973\n",
      "Epoch 022 | Train Loss: 0.2191 Acc: 0.9127 | Val Loss: 0.2234 Acc: 0.9149\n",
      "Epoch 023 | Train Loss: 0.1927 Acc: 0.9218 | Val Loss: 0.2093 Acc: 0.9143\n",
      "Epoch 024 | Train Loss: 0.1954 Acc: 0.9224 | Val Loss: 0.1960 Acc: 0.9179\n",
      "Epoch 025 | Train Loss: 0.1787 Acc: 0.9305 | Val Loss: 0.1918 Acc: 0.9209\n",
      "Epoch 026 | Train Loss: 0.1583 Acc: 0.9379 | Val Loss: 0.1832 Acc: 0.9330\n",
      "Epoch 027 | Train Loss: 0.1550 Acc: 0.9410 | Val Loss: 0.1830 Acc: 0.9269\n",
      "Epoch 028 | Train Loss: 0.1442 Acc: 0.9452 | Val Loss: 0.1905 Acc: 0.9197\n",
      "Epoch 029 | Train Loss: 0.1502 Acc: 0.9420 | Val Loss: 0.1941 Acc: 0.9293\n",
      "Epoch 030 | Train Loss: 0.1396 Acc: 0.9485 | Val Loss: 0.1919 Acc: 0.9227\n",
      "Epoch 031 | Train Loss: 0.1282 Acc: 0.9497 | Val Loss: 0.1846 Acc: 0.9336\n",
      "Epoch 032 | Train Loss: 0.1380 Acc: 0.9452 | Val Loss: 0.1810 Acc: 0.9306\n",
      "Epoch 033 | Train Loss: 0.1160 Acc: 0.9564 | Val Loss: 0.1664 Acc: 0.9390\n",
      "Epoch 034 | Train Loss: 0.1217 Acc: 0.9547 | Val Loss: 0.1690 Acc: 0.9402\n",
      "Epoch 035 | Train Loss: 0.1065 Acc: 0.9576 | Val Loss: 0.2379 Acc: 0.9203\n",
      "Epoch 036 | Train Loss: 0.1157 Acc: 0.9536 | Val Loss: 0.1830 Acc: 0.9306\n",
      "Epoch 037 | Train Loss: 0.1096 Acc: 0.9616 | Val Loss: 0.1961 Acc: 0.9318\n",
      "Epoch 038 | Train Loss: 0.1109 Acc: 0.9606 | Val Loss: 0.1743 Acc: 0.9414\n",
      "Epoch 039 | Train Loss: 0.0922 Acc: 0.9636 | Val Loss: 0.1521 Acc: 0.9499\n",
      "Epoch 040 | Train Loss: 0.1041 Acc: 0.9613 | Val Loss: 0.1781 Acc: 0.9420\n",
      "Epoch 041 | Train Loss: 0.0885 Acc: 0.9684 | Val Loss: 0.1573 Acc: 0.9420\n",
      "Epoch 042 | Train Loss: 0.0893 Acc: 0.9678 | Val Loss: 0.1621 Acc: 0.9438\n",
      "Epoch 043 | Train Loss: 0.0890 Acc: 0.9680 | Val Loss: 0.1527 Acc: 0.9457\n",
      "Epoch 044 | Train Loss: 0.0908 Acc: 0.9666 | Val Loss: 0.1556 Acc: 0.9469\n",
      "Epoch 045 | Train Loss: 0.0873 Acc: 0.9671 | Val Loss: 0.1453 Acc: 0.9457\n",
      "Epoch 046 | Train Loss: 0.0821 Acc: 0.9698 | Val Loss: 0.1749 Acc: 0.9402\n",
      "Epoch 047 | Train Loss: 0.0783 Acc: 0.9725 | Val Loss: 0.1605 Acc: 0.9438\n",
      "Epoch 048 | Train Loss: 0.0845 Acc: 0.9677 | Val Loss: 0.1615 Acc: 0.9469\n",
      "Epoch 049 | Train Loss: 0.0733 Acc: 0.9736 | Val Loss: 0.1499 Acc: 0.9426\n",
      "Epoch 050 | Train Loss: 0.0792 Acc: 0.9684 | Val Loss: 0.1609 Acc: 0.9426\n",
      "Epoch 051 | Train Loss: 0.0755 Acc: 0.9733 | Val Loss: 0.1337 Acc: 0.9571\n",
      "Epoch 052 | Train Loss: 0.0634 Acc: 0.9760 | Val Loss: 0.1344 Acc: 0.9481\n",
      "Epoch 053 | Train Loss: 0.0641 Acc: 0.9769 | Val Loss: 0.1369 Acc: 0.9499\n",
      "Epoch 054 | Train Loss: 0.0672 Acc: 0.9760 | Val Loss: 0.1460 Acc: 0.9487\n",
      "Epoch 055 | Train Loss: 0.0627 Acc: 0.9781 | Val Loss: 0.1392 Acc: 0.9499\n",
      "Epoch 056 | Train Loss: 0.0576 Acc: 0.9787 | Val Loss: 0.1508 Acc: 0.9505\n",
      "Epoch 057 | Train Loss: 0.0659 Acc: 0.9766 | Val Loss: 0.1436 Acc: 0.9523\n",
      "Epoch 058 | Train Loss: 0.0685 Acc: 0.9757 | Val Loss: 0.1646 Acc: 0.9438\n",
      "Epoch 059 | Train Loss: 0.0658 Acc: 0.9772 | Val Loss: 0.1282 Acc: 0.9493\n",
      "Epoch 060 | Train Loss: 0.0667 Acc: 0.9758 | Val Loss: 0.1398 Acc: 0.9499\n",
      "Epoch 001 | Train Loss: 0.6782 Acc: 0.5812 | Val Loss: 0.6688 Acc: 0.5912\n",
      "Epoch 002 | Train Loss: 0.6347 Acc: 0.6488 | Val Loss: 0.6141 Acc: 0.6697\n",
      "Epoch 003 | Train Loss: 0.5700 Acc: 0.7116 | Val Loss: 0.5584 Acc: 0.7216\n",
      "Epoch 004 | Train Loss: 0.5349 Acc: 0.7356 | Val Loss: 0.5089 Acc: 0.7470\n",
      "Epoch 005 | Train Loss: 0.4923 Acc: 0.7685 | Val Loss: 0.5087 Acc: 0.7542\n",
      "Epoch 006 | Train Loss: 0.4513 Acc: 0.7910 | Val Loss: 0.4291 Acc: 0.7983\n",
      "Epoch 007 | Train Loss: 0.4121 Acc: 0.8090 | Val Loss: 0.4136 Acc: 0.8176\n",
      "Epoch 008 | Train Loss: 0.3656 Acc: 0.8396 | Val Loss: 0.3833 Acc: 0.8207\n",
      "Epoch 009 | Train Loss: 0.3402 Acc: 0.8540 | Val Loss: 0.3425 Acc: 0.8533\n",
      "Epoch 010 | Train Loss: 0.3224 Acc: 0.8596 | Val Loss: 0.3148 Acc: 0.8647\n",
      "Epoch 011 | Train Loss: 0.2895 Acc: 0.8834 | Val Loss: 0.2896 Acc: 0.8853\n",
      "Epoch 012 | Train Loss: 0.2801 Acc: 0.8778 | Val Loss: 0.2714 Acc: 0.8810\n",
      "Epoch 013 | Train Loss: 0.2545 Acc: 0.8884 | Val Loss: 0.2573 Acc: 0.8992\n",
      "Epoch 014 | Train Loss: 0.2388 Acc: 0.9008 | Val Loss: 0.2520 Acc: 0.8979\n",
      "Epoch 015 | Train Loss: 0.2228 Acc: 0.9052 | Val Loss: 0.2682 Acc: 0.8943\n",
      "Epoch 016 | Train Loss: 0.2267 Acc: 0.9103 | Val Loss: 0.2356 Acc: 0.9076\n",
      "Epoch 017 | Train Loss: 0.2030 Acc: 0.9180 | Val Loss: 0.2577 Acc: 0.8925\n",
      "Epoch 018 | Train Loss: 0.1925 Acc: 0.9212 | Val Loss: 0.2554 Acc: 0.8943\n",
      "Epoch 019 | Train Loss: 0.1842 Acc: 0.9259 | Val Loss: 0.2435 Acc: 0.9034\n",
      "Epoch 020 | Train Loss: 0.1765 Acc: 0.9308 | Val Loss: 0.2049 Acc: 0.9149\n",
      "Epoch 021 | Train Loss: 0.1740 Acc: 0.9296 | Val Loss: 0.2335 Acc: 0.9022\n",
      "Epoch 022 | Train Loss: 0.1838 Acc: 0.9278 | Val Loss: 0.2295 Acc: 0.9076\n",
      "Epoch 023 | Train Loss: 0.1508 Acc: 0.9388 | Val Loss: 0.2237 Acc: 0.9088\n",
      "Epoch 024 | Train Loss: 0.1481 Acc: 0.9393 | Val Loss: 0.2323 Acc: 0.9058\n",
      "Epoch 025 | Train Loss: 0.1421 Acc: 0.9458 | Val Loss: 0.2063 Acc: 0.9185\n",
      "Epoch 026 | Train Loss: 0.1400 Acc: 0.9470 | Val Loss: 0.2172 Acc: 0.9221\n",
      "Epoch 027 | Train Loss: 0.1278 Acc: 0.9503 | Val Loss: 0.1813 Acc: 0.9227\n",
      "Epoch 028 | Train Loss: 0.1248 Acc: 0.9512 | Val Loss: 0.2102 Acc: 0.9215\n",
      "Epoch 029 | Train Loss: 0.1311 Acc: 0.9494 | Val Loss: 0.1974 Acc: 0.9185\n",
      "Epoch 030 | Train Loss: 0.1233 Acc: 0.9527 | Val Loss: 0.1819 Acc: 0.9300\n",
      "Epoch 031 | Train Loss: 0.1038 Acc: 0.9600 | Val Loss: 0.1874 Acc: 0.9300\n",
      "Epoch 032 | Train Loss: 0.1024 Acc: 0.9597 | Val Loss: 0.1975 Acc: 0.9239\n",
      "Epoch 033 | Train Loss: 0.1074 Acc: 0.9600 | Val Loss: 0.1941 Acc: 0.9293\n",
      "Epoch 034 | Train Loss: 0.1083 Acc: 0.9591 | Val Loss: 0.1768 Acc: 0.9348\n",
      "Epoch 035 | Train Loss: 0.1009 Acc: 0.9613 | Val Loss: 0.1616 Acc: 0.9360\n",
      "Epoch 036 | Train Loss: 0.0980 Acc: 0.9656 | Val Loss: 0.1560 Acc: 0.9390\n",
      "Epoch 037 | Train Loss: 0.1062 Acc: 0.9600 | Val Loss: 0.1667 Acc: 0.9378\n",
      "Epoch 038 | Train Loss: 0.0872 Acc: 0.9674 | Val Loss: 0.1611 Acc: 0.9396\n",
      "Epoch 039 | Train Loss: 0.0875 Acc: 0.9665 | Val Loss: 0.1570 Acc: 0.9438\n",
      "Epoch 040 | Train Loss: 0.0969 Acc: 0.9632 | Val Loss: 0.1522 Acc: 0.9384\n",
      "Epoch 041 | Train Loss: 0.0863 Acc: 0.9671 | Val Loss: 0.1654 Acc: 0.9402\n",
      "Epoch 042 | Train Loss: 0.0749 Acc: 0.9722 | Val Loss: 0.1624 Acc: 0.9414\n",
      "Epoch 043 | Train Loss: 0.0790 Acc: 0.9706 | Val Loss: 0.1692 Acc: 0.9384\n",
      "Epoch 044 | Train Loss: 0.0759 Acc: 0.9734 | Val Loss: 0.1939 Acc: 0.9354\n",
      "Epoch 045 | Train Loss: 0.0940 Acc: 0.9633 | Val Loss: 0.1895 Acc: 0.9215\n",
      "Epoch 046 | Train Loss: 0.0763 Acc: 0.9722 | Val Loss: 0.1644 Acc: 0.9354\n",
      "Epoch 047 | Train Loss: 0.0744 Acc: 0.9716 | Val Loss: 0.1699 Acc: 0.9348\n",
      "Epoch 048 | Train Loss: 0.0689 Acc: 0.9727 | Val Loss: 0.1706 Acc: 0.9312\n",
      "Epoch 049 | Train Loss: 0.0722 Acc: 0.9725 | Val Loss: 0.1502 Acc: 0.9408\n",
      "Epoch 050 | Train Loss: 0.0772 Acc: 0.9713 | Val Loss: 0.1499 Acc: 0.9420\n",
      "Epoch 051 | Train Loss: 0.0687 Acc: 0.9755 | Val Loss: 0.1652 Acc: 0.9402\n",
      "Epoch 052 | Train Loss: 0.0632 Acc: 0.9778 | Val Loss: 0.1782 Acc: 0.9408\n",
      "Epoch 053 | Train Loss: 0.0640 Acc: 0.9757 | Val Loss: 0.1913 Acc: 0.9348\n",
      "Epoch 054 | Train Loss: 0.0773 Acc: 0.9700 | Val Loss: 0.1586 Acc: 0.9366\n",
      "Epoch 055 | Train Loss: 0.0719 Acc: 0.9727 | Val Loss: 0.1676 Acc: 0.9463\n",
      "Epoch 056 | Train Loss: 0.0601 Acc: 0.9793 | Val Loss: 0.2066 Acc: 0.9318\n",
      "Epoch 057 | Train Loss: 0.0706 Acc: 0.9745 | Val Loss: 0.2016 Acc: 0.9300\n",
      "Epoch 058 | Train Loss: 0.0674 Acc: 0.9751 | Val Loss: 0.1615 Acc: 0.9414\n",
      "Epoch 059 | Train Loss: 0.0663 Acc: 0.9766 | Val Loss: 0.1376 Acc: 0.9559\n",
      "Epoch 060 | Train Loss: 0.0565 Acc: 0.9804 | Val Loss: 0.1744 Acc: 0.9372\n",
      "Epoch 001 | Train Loss: 0.6762 Acc: 0.5863 | Val Loss: 0.6737 Acc: 0.5948\n",
      "Epoch 002 | Train Loss: 0.6675 Acc: 0.5979 | Val Loss: 0.6640 Acc: 0.6039\n",
      "Epoch 003 | Train Loss: 0.6664 Acc: 0.5976 | Val Loss: 0.6638 Acc: 0.5882\n",
      "Epoch 004 | Train Loss: 0.6403 Acc: 0.6474 | Val Loss: 0.6229 Acc: 0.6630\n",
      "Epoch 005 | Train Loss: 0.6156 Acc: 0.6767 | Val Loss: 0.6196 Acc: 0.6673\n",
      "Epoch 006 | Train Loss: 0.5962 Acc: 0.6924 | Val Loss: 0.5880 Acc: 0.6800\n",
      "Epoch 007 | Train Loss: 0.5740 Acc: 0.7054 | Val Loss: 0.5739 Acc: 0.7041\n",
      "Epoch 008 | Train Loss: 0.5595 Acc: 0.7198 | Val Loss: 0.5878 Acc: 0.6872\n",
      "Epoch 009 | Train Loss: 0.5483 Acc: 0.7222 | Val Loss: 0.5619 Acc: 0.6926\n",
      "Epoch 010 | Train Loss: 0.5308 Acc: 0.7414 | Val Loss: 0.5424 Acc: 0.7252\n",
      "Epoch 011 | Train Loss: 0.5147 Acc: 0.7474 | Val Loss: 0.5050 Acc: 0.7536\n",
      "Epoch 012 | Train Loss: 0.4975 Acc: 0.7552 | Val Loss: 0.4990 Acc: 0.7482\n",
      "Epoch 013 | Train Loss: 0.4755 Acc: 0.7720 | Val Loss: 0.4806 Acc: 0.7645\n",
      "Epoch 014 | Train Loss: 0.4615 Acc: 0.7809 | Val Loss: 0.4560 Acc: 0.7699\n",
      "Epoch 015 | Train Loss: 0.4369 Acc: 0.7992 | Val Loss: 0.4289 Acc: 0.7941\n",
      "Epoch 016 | Train Loss: 0.4118 Acc: 0.8119 | Val Loss: 0.4078 Acc: 0.8043\n",
      "Epoch 017 | Train Loss: 0.3908 Acc: 0.8247 | Val Loss: 0.3799 Acc: 0.8176\n",
      "Epoch 018 | Train Loss: 0.3703 Acc: 0.8371 | Val Loss: 0.3637 Acc: 0.8297\n",
      "Epoch 019 | Train Loss: 0.3539 Acc: 0.8437 | Val Loss: 0.3837 Acc: 0.8207\n",
      "Epoch 020 | Train Loss: 0.3464 Acc: 0.8474 | Val Loss: 0.3805 Acc: 0.8213\n",
      "Epoch 021 | Train Loss: 0.3259 Acc: 0.8615 | Val Loss: 0.3157 Acc: 0.8720\n",
      "Epoch 022 | Train Loss: 0.3102 Acc: 0.8697 | Val Loss: 0.2954 Acc: 0.8678\n",
      "Epoch 023 | Train Loss: 0.3013 Acc: 0.8685 | Val Loss: 0.3066 Acc: 0.8756\n",
      "Epoch 024 | Train Loss: 0.2905 Acc: 0.8759 | Val Loss: 0.3091 Acc: 0.8617\n",
      "Epoch 025 | Train Loss: 0.2826 Acc: 0.8843 | Val Loss: 0.3023 Acc: 0.8762\n",
      "Epoch 026 | Train Loss: 0.2670 Acc: 0.8872 | Val Loss: 0.2885 Acc: 0.8810\n",
      "Epoch 027 | Train Loss: 0.2514 Acc: 0.8970 | Val Loss: 0.2588 Acc: 0.8998\n",
      "Epoch 028 | Train Loss: 0.2531 Acc: 0.8957 | Val Loss: 0.2666 Acc: 0.8895\n",
      "Epoch 029 | Train Loss: 0.2444 Acc: 0.8994 | Val Loss: 0.2498 Acc: 0.8992\n",
      "Epoch 030 | Train Loss: 0.2286 Acc: 0.9077 | Val Loss: 0.2278 Acc: 0.9040\n",
      "Epoch 031 | Train Loss: 0.2221 Acc: 0.9108 | Val Loss: 0.2352 Acc: 0.9124\n",
      "Epoch 032 | Train Loss: 0.2215 Acc: 0.9121 | Val Loss: 0.2383 Acc: 0.9143\n",
      "Epoch 033 | Train Loss: 0.2215 Acc: 0.9102 | Val Loss: 0.2108 Acc: 0.9124\n",
      "Epoch 034 | Train Loss: 0.2022 Acc: 0.9147 | Val Loss: 0.2317 Acc: 0.9040\n",
      "Epoch 035 | Train Loss: 0.2019 Acc: 0.9192 | Val Loss: 0.2043 Acc: 0.9161\n",
      "Epoch 036 | Train Loss: 0.1959 Acc: 0.9200 | Val Loss: 0.2151 Acc: 0.9185\n",
      "Epoch 037 | Train Loss: 0.1801 Acc: 0.9293 | Val Loss: 0.1949 Acc: 0.9300\n",
      "Epoch 038 | Train Loss: 0.1939 Acc: 0.9213 | Val Loss: 0.2062 Acc: 0.9221\n",
      "Epoch 039 | Train Loss: 0.1744 Acc: 0.9307 | Val Loss: 0.2101 Acc: 0.9215\n",
      "Epoch 040 | Train Loss: 0.1789 Acc: 0.9296 | Val Loss: 0.1923 Acc: 0.9275\n",
      "Epoch 041 | Train Loss: 0.1691 Acc: 0.9296 | Val Loss: 0.2027 Acc: 0.9179\n",
      "Epoch 042 | Train Loss: 0.1567 Acc: 0.9393 | Val Loss: 0.1864 Acc: 0.9293\n",
      "Epoch 043 | Train Loss: 0.1677 Acc: 0.9346 | Val Loss: 0.2361 Acc: 0.9094\n",
      "Epoch 044 | Train Loss: 0.1602 Acc: 0.9387 | Val Loss: 0.1772 Acc: 0.9342\n",
      "Epoch 045 | Train Loss: 0.1472 Acc: 0.9434 | Val Loss: 0.1762 Acc: 0.9318\n",
      "Epoch 046 | Train Loss: 0.1508 Acc: 0.9411 | Val Loss: 0.1831 Acc: 0.9281\n",
      "Epoch 047 | Train Loss: 0.1423 Acc: 0.9467 | Val Loss: 0.1754 Acc: 0.9342\n",
      "Epoch 048 | Train Loss: 0.1367 Acc: 0.9478 | Val Loss: 0.1764 Acc: 0.9354\n",
      "Epoch 049 | Train Loss: 0.1340 Acc: 0.9487 | Val Loss: 0.1904 Acc: 0.9263\n",
      "Epoch 050 | Train Loss: 0.1389 Acc: 0.9447 | Val Loss: 0.2179 Acc: 0.9179\n",
      "Epoch 051 | Train Loss: 0.1259 Acc: 0.9509 | Val Loss: 0.1760 Acc: 0.9300\n",
      "Epoch 052 | Train Loss: 0.1268 Acc: 0.9485 | Val Loss: 0.1787 Acc: 0.9330\n",
      "Epoch 053 | Train Loss: 0.1252 Acc: 0.9520 | Val Loss: 0.1667 Acc: 0.9318\n",
      "Epoch 054 | Train Loss: 0.1237 Acc: 0.9526 | Val Loss: 0.1658 Acc: 0.9450\n",
      "Epoch 055 | Train Loss: 0.1286 Acc: 0.9491 | Val Loss: 0.1787 Acc: 0.9354\n",
      "Epoch 056 | Train Loss: 0.1229 Acc: 0.9543 | Val Loss: 0.1823 Acc: 0.9354\n",
      "Epoch 057 | Train Loss: 0.1208 Acc: 0.9529 | Val Loss: 0.1612 Acc: 0.9420\n",
      "Epoch 058 | Train Loss: 0.1243 Acc: 0.9541 | Val Loss: 0.1737 Acc: 0.9414\n",
      "Epoch 059 | Train Loss: 0.1098 Acc: 0.9592 | Val Loss: 0.1562 Acc: 0.9366\n",
      "Epoch 060 | Train Loss: 0.1052 Acc: 0.9613 | Val Loss: 0.1508 Acc: 0.9475\n",
      "Epoch 001 | Train Loss: 0.6798 Acc: 0.5756 | Val Loss: 0.6798 Acc: 0.5809\n",
      "Epoch 002 | Train Loss: 0.6706 Acc: 0.5889 | Val Loss: 0.6482 Acc: 0.6202\n",
      "Epoch 003 | Train Loss: 0.6336 Acc: 0.6570 | Val Loss: 0.6177 Acc: 0.6624\n",
      "Epoch 004 | Train Loss: 0.5989 Acc: 0.6932 | Val Loss: 0.6013 Acc: 0.6806\n",
      "Epoch 005 | Train Loss: 0.5771 Acc: 0.7152 | Val Loss: 0.5661 Acc: 0.7114\n",
      "Epoch 006 | Train Loss: 0.5554 Acc: 0.7240 | Val Loss: 0.5646 Acc: 0.7126\n",
      "Epoch 007 | Train Loss: 0.5352 Acc: 0.7370 | Val Loss: 0.5293 Acc: 0.7343\n",
      "Epoch 008 | Train Loss: 0.5140 Acc: 0.7501 | Val Loss: 0.5035 Acc: 0.7512\n",
      "Epoch 009 | Train Loss: 0.4929 Acc: 0.7681 | Val Loss: 0.4935 Acc: 0.7524\n",
      "Epoch 010 | Train Loss: 0.4712 Acc: 0.7767 | Val Loss: 0.4802 Acc: 0.7669\n",
      "Epoch 011 | Train Loss: 0.4550 Acc: 0.7877 | Val Loss: 0.4300 Acc: 0.7995\n",
      "Epoch 012 | Train Loss: 0.4247 Acc: 0.8079 | Val Loss: 0.4299 Acc: 0.7880\n",
      "Epoch 013 | Train Loss: 0.4072 Acc: 0.8155 | Val Loss: 0.4064 Acc: 0.8104\n",
      "Epoch 014 | Train Loss: 0.3732 Acc: 0.8309 | Val Loss: 0.3675 Acc: 0.8382\n",
      "Epoch 015 | Train Loss: 0.3531 Acc: 0.8393 | Val Loss: 0.3478 Acc: 0.8418\n",
      "Epoch 016 | Train Loss: 0.3370 Acc: 0.8513 | Val Loss: 0.3290 Acc: 0.8496\n",
      "Epoch 017 | Train Loss: 0.3176 Acc: 0.8652 | Val Loss: 0.3291 Acc: 0.8569\n",
      "Epoch 018 | Train Loss: 0.2943 Acc: 0.8742 | Val Loss: 0.2995 Acc: 0.8816\n",
      "Epoch 019 | Train Loss: 0.2884 Acc: 0.8785 | Val Loss: 0.2780 Acc: 0.8853\n",
      "Epoch 020 | Train Loss: 0.2624 Acc: 0.8929 | Val Loss: 0.2644 Acc: 0.8973\n",
      "Epoch 021 | Train Loss: 0.2580 Acc: 0.8926 | Val Loss: 0.2732 Acc: 0.8841\n",
      "Epoch 022 | Train Loss: 0.2346 Acc: 0.9046 | Val Loss: 0.3166 Acc: 0.8539\n",
      "Epoch 023 | Train Loss: 0.2318 Acc: 0.9073 | Val Loss: 0.2292 Acc: 0.9082\n",
      "Epoch 024 | Train Loss: 0.2165 Acc: 0.9153 | Val Loss: 0.2328 Acc: 0.9028\n",
      "Epoch 025 | Train Loss: 0.2203 Acc: 0.9138 | Val Loss: 0.2236 Acc: 0.9112\n",
      "Epoch 026 | Train Loss: 0.1926 Acc: 0.9236 | Val Loss: 0.2060 Acc: 0.9191\n",
      "Epoch 027 | Train Loss: 0.1782 Acc: 0.9284 | Val Loss: 0.2164 Acc: 0.9112\n",
      "Epoch 028 | Train Loss: 0.1783 Acc: 0.9289 | Val Loss: 0.2592 Acc: 0.9058\n",
      "Epoch 029 | Train Loss: 0.1747 Acc: 0.9342 | Val Loss: 0.2302 Acc: 0.9052\n",
      "Epoch 030 | Train Loss: 0.1510 Acc: 0.9417 | Val Loss: 0.1881 Acc: 0.9251\n",
      "Epoch 031 | Train Loss: 0.1499 Acc: 0.9423 | Val Loss: 0.2119 Acc: 0.9161\n",
      "Epoch 032 | Train Loss: 0.1425 Acc: 0.9450 | Val Loss: 0.1671 Acc: 0.9324\n",
      "Epoch 033 | Train Loss: 0.1395 Acc: 0.9435 | Val Loss: 0.2510 Acc: 0.8992\n",
      "Epoch 034 | Train Loss: 0.1354 Acc: 0.9490 | Val Loss: 0.1631 Acc: 0.9372\n",
      "Epoch 035 | Train Loss: 0.1259 Acc: 0.9520 | Val Loss: 0.1897 Acc: 0.9263\n",
      "Epoch 036 | Train Loss: 0.1337 Acc: 0.9494 | Val Loss: 0.1635 Acc: 0.9414\n",
      "Epoch 037 | Train Loss: 0.1246 Acc: 0.9506 | Val Loss: 0.1441 Acc: 0.9475\n",
      "Epoch 038 | Train Loss: 0.1208 Acc: 0.9555 | Val Loss: 0.2064 Acc: 0.9136\n",
      "Epoch 039 | Train Loss: 0.1055 Acc: 0.9613 | Val Loss: 0.1467 Acc: 0.9475\n",
      "Epoch 040 | Train Loss: 0.1114 Acc: 0.9597 | Val Loss: 0.1734 Acc: 0.9360\n",
      "Epoch 041 | Train Loss: 0.1182 Acc: 0.9570 | Val Loss: 0.1702 Acc: 0.9360\n",
      "Epoch 042 | Train Loss: 0.1079 Acc: 0.9582 | Val Loss: 0.1644 Acc: 0.9330\n",
      "Epoch 043 | Train Loss: 0.1086 Acc: 0.9600 | Val Loss: 0.1477 Acc: 0.9408\n",
      "Epoch 044 | Train Loss: 0.0900 Acc: 0.9666 | Val Loss: 0.1628 Acc: 0.9366\n",
      "Epoch 045 | Train Loss: 0.0947 Acc: 0.9662 | Val Loss: 0.1814 Acc: 0.9342\n",
      "Epoch 046 | Train Loss: 0.0908 Acc: 0.9662 | Val Loss: 0.1882 Acc: 0.9348\n",
      "Epoch 047 | Train Loss: 0.0976 Acc: 0.9648 | Val Loss: 0.1335 Acc: 0.9547\n",
      "Epoch 048 | Train Loss: 0.0818 Acc: 0.9697 | Val Loss: 0.1917 Acc: 0.9372\n",
      "Epoch 049 | Train Loss: 0.0797 Acc: 0.9698 | Val Loss: 0.1773 Acc: 0.9342\n",
      "Epoch 050 | Train Loss: 0.0825 Acc: 0.9704 | Val Loss: 0.1423 Acc: 0.9499\n",
      "Epoch 051 | Train Loss: 0.0798 Acc: 0.9698 | Val Loss: 0.1541 Acc: 0.9408\n",
      "Epoch 052 | Train Loss: 0.0754 Acc: 0.9722 | Val Loss: 0.1426 Acc: 0.9469\n",
      "Epoch 053 | Train Loss: 0.0818 Acc: 0.9700 | Val Loss: 0.1519 Acc: 0.9438\n",
      "Epoch 054 | Train Loss: 0.0699 Acc: 0.9758 | Val Loss: 0.1492 Acc: 0.9523\n",
      "Epoch 055 | Train Loss: 0.0781 Acc: 0.9710 | Val Loss: 0.1615 Acc: 0.9408\n",
      "Epoch 056 | Train Loss: 0.0782 Acc: 0.9704 | Val Loss: 0.1889 Acc: 0.9269\n",
      "Epoch 057 | Train Loss: 0.0777 Acc: 0.9703 | Val Loss: 0.1516 Acc: 0.9469\n",
      "Early stopping triggered.\n",
      "Epoch 001 | Train Loss: 0.6767 Acc: 0.5886 | Val Loss: 0.6713 Acc: 0.5960\n",
      "Epoch 002 | Train Loss: 0.6623 Acc: 0.6070 | Val Loss: 0.6606 Acc: 0.6238\n",
      "Epoch 003 | Train Loss: 0.6539 Acc: 0.6159 | Val Loss: 0.6402 Acc: 0.6395\n",
      "Epoch 004 | Train Loss: 0.6057 Acc: 0.6867 | Val Loss: 0.5720 Acc: 0.7005\n",
      "Epoch 005 | Train Loss: 0.5648 Acc: 0.7201 | Val Loss: 0.5474 Acc: 0.7204\n",
      "Epoch 006 | Train Loss: 0.5333 Acc: 0.7376 | Val Loss: 0.5740 Acc: 0.7234\n",
      "Epoch 007 | Train Loss: 0.5214 Acc: 0.7468 | Val Loss: 0.5136 Acc: 0.7434\n",
      "Epoch 008 | Train Loss: 0.4787 Acc: 0.7734 | Val Loss: 0.5950 Acc: 0.6739\n",
      "Epoch 009 | Train Loss: 0.4626 Acc: 0.7886 | Val Loss: 0.4525 Acc: 0.7723\n",
      "Epoch 010 | Train Loss: 0.4286 Acc: 0.8043 | Val Loss: 0.4473 Acc: 0.7838\n",
      "Epoch 011 | Train Loss: 0.3962 Acc: 0.8218 | Val Loss: 0.4079 Acc: 0.8092\n",
      "Epoch 012 | Train Loss: 0.3840 Acc: 0.8247 | Val Loss: 0.3866 Acc: 0.8110\n",
      "Epoch 013 | Train Loss: 0.3563 Acc: 0.8398 | Val Loss: 0.3648 Acc: 0.8351\n",
      "Epoch 014 | Train Loss: 0.3274 Acc: 0.8561 | Val Loss: 0.3310 Acc: 0.8527\n",
      "Epoch 015 | Train Loss: 0.2997 Acc: 0.8730 | Val Loss: 0.3026 Acc: 0.8593\n",
      "Epoch 016 | Train Loss: 0.2828 Acc: 0.8831 | Val Loss: 0.2910 Acc: 0.8708\n",
      "Epoch 017 | Train Loss: 0.2589 Acc: 0.8928 | Val Loss: 0.2643 Acc: 0.8865\n",
      "Epoch 018 | Train Loss: 0.2518 Acc: 0.8996 | Val Loss: 0.2633 Acc: 0.8919\n",
      "Epoch 019 | Train Loss: 0.2332 Acc: 0.9068 | Val Loss: 0.2509 Acc: 0.8986\n",
      "Epoch 020 | Train Loss: 0.2144 Acc: 0.9142 | Val Loss: 0.2325 Acc: 0.9028\n",
      "Epoch 021 | Train Loss: 0.2073 Acc: 0.9161 | Val Loss: 0.2240 Acc: 0.9088\n",
      "Epoch 022 | Train Loss: 0.1900 Acc: 0.9265 | Val Loss: 0.2658 Acc: 0.8967\n",
      "Epoch 023 | Train Loss: 0.1853 Acc: 0.9272 | Val Loss: 0.2154 Acc: 0.9167\n",
      "Epoch 024 | Train Loss: 0.1755 Acc: 0.9302 | Val Loss: 0.2144 Acc: 0.9149\n",
      "Epoch 025 | Train Loss: 0.1764 Acc: 0.9293 | Val Loss: 0.1951 Acc: 0.9149\n",
      "Epoch 026 | Train Loss: 0.1492 Acc: 0.9432 | Val Loss: 0.1792 Acc: 0.9293\n",
      "Epoch 027 | Train Loss: 0.1448 Acc: 0.9426 | Val Loss: 0.2348 Acc: 0.9016\n",
      "Epoch 028 | Train Loss: 0.1364 Acc: 0.9443 | Val Loss: 0.2015 Acc: 0.9203\n",
      "Epoch 029 | Train Loss: 0.1402 Acc: 0.9462 | Val Loss: 0.2200 Acc: 0.9106\n",
      "Epoch 030 | Train Loss: 0.1348 Acc: 0.9470 | Val Loss: 0.2038 Acc: 0.9161\n",
      "Epoch 031 | Train Loss: 0.1249 Acc: 0.9541 | Val Loss: 0.1948 Acc: 0.9287\n",
      "Epoch 032 | Train Loss: 0.1180 Acc: 0.9543 | Val Loss: 0.2240 Acc: 0.9155\n",
      "Epoch 033 | Train Loss: 0.1145 Acc: 0.9555 | Val Loss: 0.1913 Acc: 0.9263\n",
      "Epoch 034 | Train Loss: 0.1140 Acc: 0.9562 | Val Loss: 0.2125 Acc: 0.9221\n",
      "Epoch 035 | Train Loss: 0.1092 Acc: 0.9571 | Val Loss: 0.2028 Acc: 0.9312\n",
      "Epoch 036 | Train Loss: 0.1082 Acc: 0.9630 | Val Loss: 0.1713 Acc: 0.9366\n",
      "Epoch 037 | Train Loss: 0.0936 Acc: 0.9672 | Val Loss: 0.1884 Acc: 0.9330\n",
      "Epoch 038 | Train Loss: 0.0926 Acc: 0.9629 | Val Loss: 0.2098 Acc: 0.9324\n",
      "Epoch 039 | Train Loss: 0.0941 Acc: 0.9650 | Val Loss: 0.2043 Acc: 0.9336\n",
      "Epoch 040 | Train Loss: 0.0945 Acc: 0.9645 | Val Loss: 0.1881 Acc: 0.9300\n",
      "Epoch 041 | Train Loss: 0.0944 Acc: 0.9641 | Val Loss: 0.2173 Acc: 0.9269\n",
      "Epoch 042 | Train Loss: 0.0890 Acc: 0.9660 | Val Loss: 0.1839 Acc: 0.9318\n",
      "Epoch 043 | Train Loss: 0.0926 Acc: 0.9663 | Val Loss: 0.1662 Acc: 0.9432\n",
      "Epoch 044 | Train Loss: 0.0798 Acc: 0.9686 | Val Loss: 0.1602 Acc: 0.9408\n",
      "Epoch 045 | Train Loss: 0.0810 Acc: 0.9697 | Val Loss: 0.1827 Acc: 0.9324\n",
      "Epoch 046 | Train Loss: 0.0767 Acc: 0.9718 | Val Loss: 0.1867 Acc: 0.9372\n",
      "Epoch 047 | Train Loss: 0.0771 Acc: 0.9725 | Val Loss: 0.1555 Acc: 0.9481\n",
      "Epoch 048 | Train Loss: 0.0704 Acc: 0.9743 | Val Loss: 0.1724 Acc: 0.9475\n",
      "Epoch 049 | Train Loss: 0.0693 Acc: 0.9736 | Val Loss: 0.1846 Acc: 0.9420\n",
      "Epoch 050 | Train Loss: 0.0734 Acc: 0.9722 | Val Loss: 0.1813 Acc: 0.9372\n",
      "Epoch 051 | Train Loss: 0.0764 Acc: 0.9727 | Val Loss: 0.1990 Acc: 0.9366\n",
      "Epoch 052 | Train Loss: 0.0674 Acc: 0.9730 | Val Loss: 0.1777 Acc: 0.9457\n",
      "Epoch 053 | Train Loss: 0.0659 Acc: 0.9755 | Val Loss: 0.1767 Acc: 0.9402\n",
      "Epoch 054 | Train Loss: 0.0752 Acc: 0.9734 | Val Loss: 0.1602 Acc: 0.9475\n",
      "Epoch 055 | Train Loss: 0.0740 Acc: 0.9752 | Val Loss: 0.1603 Acc: 0.9420\n",
      "Epoch 056 | Train Loss: 0.0614 Acc: 0.9783 | Val Loss: 0.1655 Acc: 0.9541\n",
      "Epoch 057 | Train Loss: 0.0613 Acc: 0.9769 | Val Loss: 0.1775 Acc: 0.9348\n",
      "Early stopping triggered.\n",
      "Epoch 001 | Train Loss: 0.6803 Acc: 0.5716 | Val Loss: 0.6746 Acc: 0.5930\n",
      "Epoch 002 | Train Loss: 0.6742 Acc: 0.5935 | Val Loss: 0.6738 Acc: 0.5821\n",
      "Epoch 003 | Train Loss: 0.6594 Acc: 0.6112 | Val Loss: 0.6336 Acc: 0.6437\n",
      "Epoch 004 | Train Loss: 0.6222 Acc: 0.6624 | Val Loss: 0.5976 Acc: 0.6884\n",
      "Epoch 005 | Train Loss: 0.5868 Acc: 0.6968 | Val Loss: 0.5775 Acc: 0.7071\n",
      "Epoch 006 | Train Loss: 0.5636 Acc: 0.7232 | Val Loss: 0.5480 Acc: 0.7264\n",
      "Epoch 007 | Train Loss: 0.5328 Acc: 0.7398 | Val Loss: 0.5246 Acc: 0.7397\n",
      "Epoch 008 | Train Loss: 0.5106 Acc: 0.7531 | Val Loss: 0.5132 Acc: 0.7482\n",
      "Epoch 009 | Train Loss: 0.4899 Acc: 0.7645 | Val Loss: 0.4728 Acc: 0.7693\n",
      "Epoch 010 | Train Loss: 0.4690 Acc: 0.7753 | Val Loss: 0.4559 Acc: 0.7820\n",
      "Epoch 011 | Train Loss: 0.4502 Acc: 0.7889 | Val Loss: 0.4318 Acc: 0.7935\n",
      "Epoch 012 | Train Loss: 0.4309 Acc: 0.8002 | Val Loss: 0.4434 Acc: 0.7899\n",
      "Epoch 013 | Train Loss: 0.4088 Acc: 0.8146 | Val Loss: 0.4032 Acc: 0.8013\n",
      "Epoch 014 | Train Loss: 0.3810 Acc: 0.8279 | Val Loss: 0.3733 Acc: 0.8297\n",
      "Epoch 015 | Train Loss: 0.3607 Acc: 0.8422 | Val Loss: 0.3611 Acc: 0.8273\n",
      "Epoch 016 | Train Loss: 0.3475 Acc: 0.8442 | Val Loss: 0.3453 Acc: 0.8484\n",
      "Epoch 017 | Train Loss: 0.3304 Acc: 0.8584 | Val Loss: 0.3244 Acc: 0.8635\n",
      "Epoch 018 | Train Loss: 0.3091 Acc: 0.8668 | Val Loss: 0.3142 Acc: 0.8629\n",
      "Epoch 019 | Train Loss: 0.2992 Acc: 0.8772 | Val Loss: 0.3128 Acc: 0.8575\n",
      "Epoch 020 | Train Loss: 0.2753 Acc: 0.8852 | Val Loss: 0.2876 Acc: 0.8762\n",
      "Epoch 021 | Train Loss: 0.2704 Acc: 0.8890 | Val Loss: 0.2500 Acc: 0.8943\n",
      "Epoch 022 | Train Loss: 0.2532 Acc: 0.8926 | Val Loss: 0.2398 Acc: 0.9016\n",
      "Epoch 023 | Train Loss: 0.2426 Acc: 0.9026 | Val Loss: 0.2321 Acc: 0.9052\n",
      "Epoch 024 | Train Loss: 0.2314 Acc: 0.9067 | Val Loss: 0.2551 Acc: 0.8937\n",
      "Epoch 025 | Train Loss: 0.2211 Acc: 0.9083 | Val Loss: 0.2323 Acc: 0.8967\n",
      "Epoch 026 | Train Loss: 0.2028 Acc: 0.9197 | Val Loss: 0.2250 Acc: 0.9028\n",
      "Epoch 027 | Train Loss: 0.1933 Acc: 0.9222 | Val Loss: 0.2085 Acc: 0.9149\n",
      "Epoch 028 | Train Loss: 0.1842 Acc: 0.9298 | Val Loss: 0.2164 Acc: 0.9052\n",
      "Epoch 029 | Train Loss: 0.1772 Acc: 0.9298 | Val Loss: 0.2102 Acc: 0.9155\n",
      "Epoch 030 | Train Loss: 0.1825 Acc: 0.9262 | Val Loss: 0.1949 Acc: 0.9227\n",
      "Epoch 031 | Train Loss: 0.1595 Acc: 0.9370 | Val Loss: 0.2513 Acc: 0.8901\n",
      "Epoch 032 | Train Loss: 0.1677 Acc: 0.9324 | Val Loss: 0.1918 Acc: 0.9269\n",
      "Epoch 033 | Train Loss: 0.1463 Acc: 0.9425 | Val Loss: 0.1645 Acc: 0.9390\n",
      "Epoch 034 | Train Loss: 0.1515 Acc: 0.9429 | Val Loss: 0.1637 Acc: 0.9402\n",
      "Epoch 035 | Train Loss: 0.1434 Acc: 0.9393 | Val Loss: 0.1487 Acc: 0.9438\n",
      "Epoch 036 | Train Loss: 0.1326 Acc: 0.9462 | Val Loss: 0.1581 Acc: 0.9348\n",
      "Epoch 037 | Train Loss: 0.1298 Acc: 0.9514 | Val Loss: 0.1570 Acc: 0.9384\n",
      "Epoch 038 | Train Loss: 0.1253 Acc: 0.9517 | Val Loss: 0.1454 Acc: 0.9402\n",
      "Epoch 039 | Train Loss: 0.1325 Acc: 0.9465 | Val Loss: 0.1570 Acc: 0.9408\n",
      "Epoch 040 | Train Loss: 0.1288 Acc: 0.9514 | Val Loss: 0.1366 Acc: 0.9505\n",
      "Epoch 041 | Train Loss: 0.1080 Acc: 0.9589 | Val Loss: 0.1506 Acc: 0.9426\n",
      "Epoch 042 | Train Loss: 0.1165 Acc: 0.9562 | Val Loss: 0.1343 Acc: 0.9505\n",
      "Epoch 043 | Train Loss: 0.1058 Acc: 0.9592 | Val Loss: 0.1615 Acc: 0.9420\n",
      "Epoch 044 | Train Loss: 0.1081 Acc: 0.9620 | Val Loss: 0.1500 Acc: 0.9457\n",
      "Epoch 045 | Train Loss: 0.1051 Acc: 0.9609 | Val Loss: 0.1517 Acc: 0.9432\n",
      "Epoch 046 | Train Loss: 0.1041 Acc: 0.9600 | Val Loss: 0.1499 Acc: 0.9426\n",
      "Epoch 047 | Train Loss: 0.0883 Acc: 0.9644 | Val Loss: 0.1543 Acc: 0.9408\n",
      "Epoch 048 | Train Loss: 0.1018 Acc: 0.9589 | Val Loss: 0.1529 Acc: 0.9420\n",
      "Epoch 049 | Train Loss: 0.1050 Acc: 0.9621 | Val Loss: 0.1687 Acc: 0.9306\n",
      "Epoch 050 | Train Loss: 0.1010 Acc: 0.9630 | Val Loss: 0.1290 Acc: 0.9511\n",
      "Epoch 051 | Train Loss: 0.0866 Acc: 0.9659 | Val Loss: 0.1474 Acc: 0.9469\n",
      "Epoch 052 | Train Loss: 0.0880 Acc: 0.9681 | Val Loss: 0.1318 Acc: 0.9481\n",
      "Epoch 053 | Train Loss: 0.0849 Acc: 0.9680 | Val Loss: 0.1470 Acc: 0.9487\n",
      "Epoch 054 | Train Loss: 0.0843 Acc: 0.9695 | Val Loss: 0.1433 Acc: 0.9450\n",
      "Epoch 055 | Train Loss: 0.0771 Acc: 0.9722 | Val Loss: 0.1581 Acc: 0.9420\n",
      "Epoch 056 | Train Loss: 0.0880 Acc: 0.9701 | Val Loss: 0.1392 Acc: 0.9517\n",
      "Epoch 057 | Train Loss: 0.0747 Acc: 0.9716 | Val Loss: 0.1310 Acc: 0.9559\n",
      "Epoch 058 | Train Loss: 0.0803 Acc: 0.9722 | Val Loss: 0.1333 Acc: 0.9505\n",
      "Epoch 059 | Train Loss: 0.0836 Acc: 0.9692 | Val Loss: 0.1241 Acc: 0.9553\n",
      "Epoch 060 | Train Loss: 0.0741 Acc: 0.9736 | Val Loss: 0.1388 Acc: 0.9487\n",
      "Epoch 001 | Train Loss: 0.6813 Acc: 0.5745 | Val Loss: 0.6782 Acc: 0.5912\n",
      "Epoch 002 | Train Loss: 0.6755 Acc: 0.5895 | Val Loss: 0.6796 Acc: 0.5731\n",
      "Epoch 003 | Train Loss: 0.6814 Acc: 0.5744 | Val Loss: 0.6725 Acc: 0.5894\n",
      "Epoch 004 | Train Loss: 0.6445 Acc: 0.6375 | Val Loss: 0.6109 Acc: 0.6757\n",
      "Epoch 005 | Train Loss: 0.5868 Acc: 0.7095 | Val Loss: 0.5693 Acc: 0.7101\n",
      "Epoch 006 | Train Loss: 0.5592 Acc: 0.7196 | Val Loss: 0.5444 Acc: 0.7325\n",
      "Epoch 007 | Train Loss: 0.5355 Acc: 0.7365 | Val Loss: 0.5326 Acc: 0.7452\n",
      "Epoch 008 | Train Loss: 0.5169 Acc: 0.7492 | Val Loss: 0.5138 Acc: 0.7548\n",
      "Epoch 009 | Train Loss: 0.4947 Acc: 0.7646 | Val Loss: 0.4810 Acc: 0.7621\n",
      "Epoch 010 | Train Loss: 0.4653 Acc: 0.7851 | Val Loss: 0.4572 Acc: 0.7856\n",
      "Epoch 011 | Train Loss: 0.4389 Acc: 0.7936 | Val Loss: 0.4135 Acc: 0.8025\n",
      "Epoch 012 | Train Loss: 0.4131 Acc: 0.8134 | Val Loss: 0.4488 Acc: 0.8031\n",
      "Epoch 013 | Train Loss: 0.3922 Acc: 0.8273 | Val Loss: 0.3643 Acc: 0.8436\n",
      "Epoch 014 | Train Loss: 0.3631 Acc: 0.8369 | Val Loss: 0.3545 Acc: 0.8424\n",
      "Epoch 015 | Train Loss: 0.3438 Acc: 0.8510 | Val Loss: 0.3610 Acc: 0.8442\n",
      "Epoch 016 | Train Loss: 0.3161 Acc: 0.8628 | Val Loss: 0.3226 Acc: 0.8581\n",
      "Epoch 017 | Train Loss: 0.3117 Acc: 0.8670 | Val Loss: 0.3005 Acc: 0.8671\n",
      "Epoch 018 | Train Loss: 0.2785 Acc: 0.8859 | Val Loss: 0.2924 Acc: 0.8774\n",
      "Epoch 019 | Train Loss: 0.2644 Acc: 0.8874 | Val Loss: 0.2876 Acc: 0.8822\n",
      "Epoch 020 | Train Loss: 0.2519 Acc: 0.8958 | Val Loss: 0.2452 Acc: 0.9016\n",
      "Epoch 021 | Train Loss: 0.2289 Acc: 0.9046 | Val Loss: 0.2332 Acc: 0.9106\n",
      "Epoch 022 | Train Loss: 0.2189 Acc: 0.9096 | Val Loss: 0.2216 Acc: 0.9106\n",
      "Epoch 023 | Train Loss: 0.2058 Acc: 0.9203 | Val Loss: 0.2112 Acc: 0.9149\n",
      "Epoch 024 | Train Loss: 0.1910 Acc: 0.9238 | Val Loss: 0.2775 Acc: 0.8859\n",
      "Epoch 025 | Train Loss: 0.1824 Acc: 0.9305 | Val Loss: 0.2205 Acc: 0.9149\n",
      "Epoch 026 | Train Loss: 0.1715 Acc: 0.9330 | Val Loss: 0.2019 Acc: 0.9215\n",
      "Epoch 027 | Train Loss: 0.1543 Acc: 0.9390 | Val Loss: 0.2167 Acc: 0.9185\n",
      "Epoch 028 | Train Loss: 0.1641 Acc: 0.9349 | Val Loss: 0.2053 Acc: 0.9221\n",
      "Epoch 029 | Train Loss: 0.1504 Acc: 0.9422 | Val Loss: 0.2091 Acc: 0.9179\n",
      "Epoch 030 | Train Loss: 0.1409 Acc: 0.9455 | Val Loss: 0.2188 Acc: 0.9094\n",
      "Epoch 031 | Train Loss: 0.1391 Acc: 0.9462 | Val Loss: 0.1853 Acc: 0.9318\n",
      "Epoch 032 | Train Loss: 0.1233 Acc: 0.9503 | Val Loss: 0.1687 Acc: 0.9372\n",
      "Epoch 033 | Train Loss: 0.1184 Acc: 0.9550 | Val Loss: 0.1856 Acc: 0.9318\n",
      "Epoch 034 | Train Loss: 0.1132 Acc: 0.9580 | Val Loss: 0.1623 Acc: 0.9372\n",
      "Epoch 035 | Train Loss: 0.1145 Acc: 0.9547 | Val Loss: 0.1858 Acc: 0.9281\n",
      "Epoch 036 | Train Loss: 0.1082 Acc: 0.9582 | Val Loss: 0.1687 Acc: 0.9366\n",
      "Epoch 037 | Train Loss: 0.1150 Acc: 0.9597 | Val Loss: 0.2245 Acc: 0.9118\n",
      "Epoch 038 | Train Loss: 0.1063 Acc: 0.9601 | Val Loss: 0.1650 Acc: 0.9348\n",
      "Epoch 039 | Train Loss: 0.0897 Acc: 0.9653 | Val Loss: 0.1819 Acc: 0.9336\n",
      "Epoch 040 | Train Loss: 0.1009 Acc: 0.9639 | Val Loss: 0.1648 Acc: 0.9384\n",
      "Epoch 041 | Train Loss: 0.0831 Acc: 0.9672 | Val Loss: 0.1874 Acc: 0.9336\n",
      "Epoch 042 | Train Loss: 0.0982 Acc: 0.9636 | Val Loss: 0.1775 Acc: 0.9360\n",
      "Epoch 043 | Train Loss: 0.0851 Acc: 0.9674 | Val Loss: 0.1507 Acc: 0.9414\n",
      "Epoch 044 | Train Loss: 0.0859 Acc: 0.9689 | Val Loss: 0.1660 Acc: 0.9366\n",
      "Epoch 045 | Train Loss: 0.0822 Acc: 0.9701 | Val Loss: 0.1395 Acc: 0.9450\n",
      "Epoch 046 | Train Loss: 0.0757 Acc: 0.9734 | Val Loss: 0.1743 Acc: 0.9378\n",
      "Epoch 047 | Train Loss: 0.0775 Acc: 0.9706 | Val Loss: 0.1526 Acc: 0.9438\n",
      "Epoch 048 | Train Loss: 0.0730 Acc: 0.9727 | Val Loss: 0.1468 Acc: 0.9438\n",
      "Epoch 049 | Train Loss: 0.0744 Acc: 0.9742 | Val Loss: 0.1919 Acc: 0.9348\n",
      "Epoch 050 | Train Loss: 0.0803 Acc: 0.9692 | Val Loss: 0.1702 Acc: 0.9384\n",
      "Epoch 051 | Train Loss: 0.0652 Acc: 0.9751 | Val Loss: 0.1868 Acc: 0.9330\n",
      "Epoch 052 | Train Loss: 0.0693 Acc: 0.9766 | Val Loss: 0.1401 Acc: 0.9450\n",
      "Epoch 053 | Train Loss: 0.0680 Acc: 0.9748 | Val Loss: 0.1430 Acc: 0.9450\n",
      "Epoch 054 | Train Loss: 0.0656 Acc: 0.9758 | Val Loss: 0.1977 Acc: 0.9269\n",
      "Epoch 055 | Train Loss: 0.0665 Acc: 0.9764 | Val Loss: 0.2167 Acc: 0.9251\n",
      "Early stopping triggered.\n",
      "Epoch 001 | Train Loss: 0.6789 Acc: 0.5854 | Val Loss: 0.6723 Acc: 0.5930\n",
      "Epoch 002 | Train Loss: 0.6691 Acc: 0.5966 | Val Loss: 0.6659 Acc: 0.6008\n",
      "Epoch 003 | Train Loss: 0.6604 Acc: 0.6098 | Val Loss: 0.6595 Acc: 0.5888\n",
      "Epoch 004 | Train Loss: 0.6347 Acc: 0.6455 | Val Loss: 0.6230 Acc: 0.6546\n",
      "Epoch 005 | Train Loss: 0.5837 Acc: 0.7086 | Val Loss: 0.5659 Acc: 0.7101\n",
      "Epoch 006 | Train Loss: 0.5557 Acc: 0.7210 | Val Loss: 0.5585 Acc: 0.7186\n",
      "Epoch 007 | Train Loss: 0.5308 Acc: 0.7442 | Val Loss: 0.5213 Acc: 0.7452\n",
      "Epoch 008 | Train Loss: 0.5130 Acc: 0.7583 | Val Loss: 0.5163 Acc: 0.7464\n",
      "Epoch 009 | Train Loss: 0.4935 Acc: 0.7675 | Val Loss: 0.4885 Acc: 0.7597\n",
      "Epoch 010 | Train Loss: 0.4738 Acc: 0.7737 | Val Loss: 0.4685 Acc: 0.7844\n",
      "Epoch 011 | Train Loss: 0.4636 Acc: 0.7821 | Val Loss: 0.4511 Acc: 0.7850\n",
      "Epoch 012 | Train Loss: 0.4345 Acc: 0.8046 | Val Loss: 0.4400 Acc: 0.7838\n",
      "Epoch 013 | Train Loss: 0.4258 Acc: 0.8067 | Val Loss: 0.3997 Acc: 0.8170\n",
      "Epoch 014 | Train Loss: 0.4063 Acc: 0.8188 | Val Loss: 0.4024 Acc: 0.8110\n",
      "Epoch 015 | Train Loss: 0.3877 Acc: 0.8258 | Val Loss: 0.3762 Acc: 0.8219\n",
      "Epoch 016 | Train Loss: 0.3765 Acc: 0.8381 | Val Loss: 0.3733 Acc: 0.8388\n",
      "Epoch 017 | Train Loss: 0.3475 Acc: 0.8480 | Val Loss: 0.3697 Acc: 0.8249\n",
      "Epoch 018 | Train Loss: 0.3319 Acc: 0.8543 | Val Loss: 0.3148 Acc: 0.8611\n",
      "Epoch 019 | Train Loss: 0.3058 Acc: 0.8706 | Val Loss: 0.3415 Acc: 0.8521\n",
      "Epoch 020 | Train Loss: 0.3035 Acc: 0.8668 | Val Loss: 0.3027 Acc: 0.8702\n",
      "Epoch 021 | Train Loss: 0.2911 Acc: 0.8783 | Val Loss: 0.2876 Acc: 0.8786\n",
      "Epoch 022 | Train Loss: 0.2702 Acc: 0.8866 | Val Loss: 0.2656 Acc: 0.8901\n",
      "Epoch 023 | Train Loss: 0.2600 Acc: 0.8898 | Val Loss: 0.2738 Acc: 0.8931\n",
      "Epoch 024 | Train Loss: 0.2500 Acc: 0.8958 | Val Loss: 0.2295 Acc: 0.9034\n",
      "Epoch 025 | Train Loss: 0.2475 Acc: 0.8972 | Val Loss: 0.2611 Acc: 0.8907\n",
      "Epoch 026 | Train Loss: 0.2264 Acc: 0.9087 | Val Loss: 0.2426 Acc: 0.9046\n",
      "Epoch 027 | Train Loss: 0.2133 Acc: 0.9164 | Val Loss: 0.2187 Acc: 0.9191\n",
      "Epoch 028 | Train Loss: 0.2033 Acc: 0.9188 | Val Loss: 0.2241 Acc: 0.9076\n",
      "Epoch 029 | Train Loss: 0.1843 Acc: 0.9281 | Val Loss: 0.2212 Acc: 0.9082\n",
      "Epoch 030 | Train Loss: 0.1904 Acc: 0.9263 | Val Loss: 0.2130 Acc: 0.9155\n",
      "Epoch 031 | Train Loss: 0.1761 Acc: 0.9316 | Val Loss: 0.2204 Acc: 0.9124\n",
      "Epoch 032 | Train Loss: 0.1815 Acc: 0.9275 | Val Loss: 0.2032 Acc: 0.9197\n",
      "Epoch 033 | Train Loss: 0.1678 Acc: 0.9346 | Val Loss: 0.2356 Acc: 0.9058\n",
      "Epoch 034 | Train Loss: 0.1721 Acc: 0.9333 | Val Loss: 0.1953 Acc: 0.9239\n",
      "Epoch 035 | Train Loss: 0.1456 Acc: 0.9428 | Val Loss: 0.1861 Acc: 0.9312\n",
      "Epoch 036 | Train Loss: 0.1453 Acc: 0.9420 | Val Loss: 0.1953 Acc: 0.9227\n",
      "Epoch 037 | Train Loss: 0.1429 Acc: 0.9426 | Val Loss: 0.1866 Acc: 0.9269\n",
      "Epoch 038 | Train Loss: 0.1476 Acc: 0.9410 | Val Loss: 0.1887 Acc: 0.9293\n",
      "Epoch 039 | Train Loss: 0.1291 Acc: 0.9499 | Val Loss: 0.1669 Acc: 0.9384\n",
      "Epoch 040 | Train Loss: 0.1259 Acc: 0.9496 | Val Loss: 0.2311 Acc: 0.9215\n",
      "Epoch 041 | Train Loss: 0.1226 Acc: 0.9553 | Val Loss: 0.1855 Acc: 0.9336\n",
      "Epoch 042 | Train Loss: 0.1213 Acc: 0.9530 | Val Loss: 0.1896 Acc: 0.9312\n",
      "Epoch 043 | Train Loss: 0.1279 Acc: 0.9494 | Val Loss: 0.1651 Acc: 0.9384\n",
      "Epoch 044 | Train Loss: 0.1139 Acc: 0.9565 | Val Loss: 0.1790 Acc: 0.9330\n",
      "Epoch 045 | Train Loss: 0.1167 Acc: 0.9549 | Val Loss: 0.1559 Acc: 0.9420\n",
      "Epoch 046 | Train Loss: 0.1070 Acc: 0.9595 | Val Loss: 0.1825 Acc: 0.9306\n",
      "Epoch 047 | Train Loss: 0.1044 Acc: 0.9597 | Val Loss: 0.1658 Acc: 0.9390\n",
      "Epoch 048 | Train Loss: 0.1058 Acc: 0.9597 | Val Loss: 0.2202 Acc: 0.9149\n",
      "Epoch 049 | Train Loss: 0.0910 Acc: 0.9662 | Val Loss: 0.1653 Acc: 0.9360\n",
      "Epoch 050 | Train Loss: 0.1013 Acc: 0.9613 | Val Loss: 0.1673 Acc: 0.9450\n",
      "Epoch 051 | Train Loss: 0.1027 Acc: 0.9630 | Val Loss: 0.1809 Acc: 0.9269\n",
      "Epoch 052 | Train Loss: 0.0839 Acc: 0.9687 | Val Loss: 0.1721 Acc: 0.9354\n",
      "Epoch 053 | Train Loss: 0.1003 Acc: 0.9632 | Val Loss: 0.1585 Acc: 0.9390\n",
      "Epoch 054 | Train Loss: 0.0921 Acc: 0.9678 | Val Loss: 0.1508 Acc: 0.9444\n",
      "Epoch 055 | Train Loss: 0.0854 Acc: 0.9675 | Val Loss: 0.1652 Acc: 0.9408\n",
      "Epoch 056 | Train Loss: 0.0983 Acc: 0.9627 | Val Loss: 0.1623 Acc: 0.9469\n",
      "Epoch 057 | Train Loss: 0.0803 Acc: 0.9681 | Val Loss: 0.1616 Acc: 0.9438\n",
      "Epoch 058 | Train Loss: 0.0750 Acc: 0.9734 | Val Loss: 0.1778 Acc: 0.9378\n",
      "Epoch 059 | Train Loss: 0.0896 Acc: 0.9657 | Val Loss: 0.1855 Acc: 0.9354\n",
      "Epoch 060 | Train Loss: 0.0875 Acc: 0.9683 | Val Loss: 0.1645 Acc: 0.9414\n",
      "Iteration 27/40 | Best Val Loss: 0.1122 | Iter Time: 223.61s | Total Time: 112.43 min\n",
      "Epoch 001 | Train Loss: 0.6835 Acc: 0.5686 | Val Loss: 0.6780 Acc: 0.5773\n",
      "Epoch 002 | Train Loss: 0.6730 Acc: 0.5932 | Val Loss: 0.6686 Acc: 0.5900\n",
      "Epoch 003 | Train Loss: 0.6530 Acc: 0.6175 | Val Loss: 0.6213 Acc: 0.6751\n",
      "Epoch 004 | Train Loss: 0.6107 Acc: 0.6840 | Val Loss: 0.5894 Acc: 0.6860\n",
      "Epoch 005 | Train Loss: 0.5608 Acc: 0.7237 | Val Loss: 0.5497 Acc: 0.7198\n",
      "Epoch 006 | Train Loss: 0.5369 Acc: 0.7380 | Val Loss: 0.5313 Acc: 0.7271\n",
      "Epoch 007 | Train Loss: 0.5059 Acc: 0.7575 | Val Loss: 0.5197 Acc: 0.7355\n",
      "Epoch 008 | Train Loss: 0.4819 Acc: 0.7702 | Val Loss: 0.4700 Acc: 0.7736\n",
      "Epoch 009 | Train Loss: 0.4589 Acc: 0.7859 | Val Loss: 0.4622 Acc: 0.7717\n",
      "Epoch 010 | Train Loss: 0.4354 Acc: 0.7978 | Val Loss: 0.4253 Acc: 0.7911\n",
      "Epoch 011 | Train Loss: 0.4042 Acc: 0.8125 | Val Loss: 0.4271 Acc: 0.7989\n",
      "Epoch 012 | Train Loss: 0.3904 Acc: 0.8264 | Val Loss: 0.3822 Acc: 0.8231\n",
      "Epoch 013 | Train Loss: 0.3532 Acc: 0.8492 | Val Loss: 0.3674 Acc: 0.8315\n",
      "Epoch 014 | Train Loss: 0.3370 Acc: 0.8567 | Val Loss: 0.3259 Acc: 0.8545\n",
      "Epoch 015 | Train Loss: 0.3065 Acc: 0.8673 | Val Loss: 0.3347 Acc: 0.8539\n",
      "Epoch 016 | Train Loss: 0.2896 Acc: 0.8748 | Val Loss: 0.3245 Acc: 0.8575\n",
      "Epoch 017 | Train Loss: 0.2637 Acc: 0.8914 | Val Loss: 0.3276 Acc: 0.8653\n",
      "Epoch 018 | Train Loss: 0.2516 Acc: 0.8963 | Val Loss: 0.3218 Acc: 0.8641\n",
      "Epoch 019 | Train Loss: 0.2339 Acc: 0.9058 | Val Loss: 0.2504 Acc: 0.8986\n",
      "Epoch 020 | Train Loss: 0.2145 Acc: 0.9126 | Val Loss: 0.2684 Acc: 0.8853\n",
      "Epoch 021 | Train Loss: 0.2079 Acc: 0.9144 | Val Loss: 0.2339 Acc: 0.8992\n",
      "Epoch 022 | Train Loss: 0.1877 Acc: 0.9224 | Val Loss: 0.2378 Acc: 0.9052\n",
      "Epoch 023 | Train Loss: 0.1855 Acc: 0.9244 | Val Loss: 0.2670 Acc: 0.8841\n",
      "Epoch 024 | Train Loss: 0.1655 Acc: 0.9348 | Val Loss: 0.2184 Acc: 0.9106\n",
      "Epoch 025 | Train Loss: 0.1607 Acc: 0.9411 | Val Loss: 0.2111 Acc: 0.9155\n",
      "Epoch 026 | Train Loss: 0.1512 Acc: 0.9401 | Val Loss: 0.2301 Acc: 0.9100\n",
      "Epoch 027 | Train Loss: 0.1441 Acc: 0.9429 | Val Loss: 0.2003 Acc: 0.9239\n",
      "Epoch 028 | Train Loss: 0.1379 Acc: 0.9462 | Val Loss: 0.2101 Acc: 0.9173\n",
      "Epoch 029 | Train Loss: 0.1240 Acc: 0.9538 | Val Loss: 0.1834 Acc: 0.9263\n",
      "Epoch 030 | Train Loss: 0.1145 Acc: 0.9556 | Val Loss: 0.2008 Acc: 0.9173\n",
      "Epoch 031 | Train Loss: 0.1089 Acc: 0.9567 | Val Loss: 0.2122 Acc: 0.9239\n",
      "Epoch 032 | Train Loss: 0.1024 Acc: 0.9607 | Val Loss: 0.1965 Acc: 0.9221\n",
      "Epoch 033 | Train Loss: 0.0985 Acc: 0.9624 | Val Loss: 0.1855 Acc: 0.9330\n",
      "Epoch 034 | Train Loss: 0.0950 Acc: 0.9648 | Val Loss: 0.2510 Acc: 0.9112\n",
      "Epoch 035 | Train Loss: 0.0950 Acc: 0.9636 | Val Loss: 0.1897 Acc: 0.9257\n",
      "Epoch 036 | Train Loss: 0.0802 Acc: 0.9690 | Val Loss: 0.1802 Acc: 0.9348\n",
      "Epoch 037 | Train Loss: 0.0836 Acc: 0.9678 | Val Loss: 0.1774 Acc: 0.9396\n",
      "Epoch 038 | Train Loss: 0.0796 Acc: 0.9690 | Val Loss: 0.1700 Acc: 0.9396\n",
      "Epoch 039 | Train Loss: 0.0638 Acc: 0.9775 | Val Loss: 0.1716 Acc: 0.9408\n",
      "Epoch 040 | Train Loss: 0.0652 Acc: 0.9766 | Val Loss: 0.1956 Acc: 0.9354\n",
      "Epoch 041 | Train Loss: 0.0717 Acc: 0.9706 | Val Loss: 0.1744 Acc: 0.9396\n",
      "Epoch 042 | Train Loss: 0.0663 Acc: 0.9767 | Val Loss: 0.1841 Acc: 0.9366\n",
      "Epoch 043 | Train Loss: 0.0614 Acc: 0.9761 | Val Loss: 0.1856 Acc: 0.9384\n",
      "Epoch 044 | Train Loss: 0.0621 Acc: 0.9761 | Val Loss: 0.1790 Acc: 0.9372\n",
      "Epoch 045 | Train Loss: 0.0540 Acc: 0.9799 | Val Loss: 0.1831 Acc: 0.9354\n",
      "Epoch 046 | Train Loss: 0.0521 Acc: 0.9796 | Val Loss: 0.2507 Acc: 0.9245\n",
      "Epoch 047 | Train Loss: 0.0604 Acc: 0.9770 | Val Loss: 0.1654 Acc: 0.9493\n",
      "Epoch 048 | Train Loss: 0.0514 Acc: 0.9807 | Val Loss: 0.1834 Acc: 0.9324\n",
      "Epoch 049 | Train Loss: 0.0485 Acc: 0.9823 | Val Loss: 0.1808 Acc: 0.9396\n",
      "Epoch 050 | Train Loss: 0.0485 Acc: 0.9841 | Val Loss: 0.1855 Acc: 0.9372\n",
      "Epoch 051 | Train Loss: 0.0477 Acc: 0.9837 | Val Loss: 0.1991 Acc: 0.9300\n",
      "Epoch 052 | Train Loss: 0.0514 Acc: 0.9810 | Val Loss: 0.1843 Acc: 0.9457\n",
      "Epoch 053 | Train Loss: 0.0455 Acc: 0.9831 | Val Loss: 0.1702 Acc: 0.9426\n",
      "Epoch 054 | Train Loss: 0.0391 Acc: 0.9854 | Val Loss: 0.1896 Acc: 0.9390\n",
      "Epoch 055 | Train Loss: 0.0508 Acc: 0.9820 | Val Loss: 0.2077 Acc: 0.9293\n",
      "Epoch 056 | Train Loss: 0.0505 Acc: 0.9817 | Val Loss: 0.1799 Acc: 0.9390\n",
      "Epoch 057 | Train Loss: 0.0357 Acc: 0.9879 | Val Loss: 0.2151 Acc: 0.9432\n",
      "Early stopping triggered.\n",
      "Epoch 001 | Train Loss: 0.6785 Acc: 0.5833 | Val Loss: 0.6705 Acc: 0.5930\n",
      "Epoch 002 | Train Loss: 0.6410 Acc: 0.6342 | Val Loss: 0.6146 Acc: 0.6685\n",
      "Epoch 003 | Train Loss: 0.5735 Acc: 0.7081 | Val Loss: 0.5802 Acc: 0.6987\n",
      "Epoch 004 | Train Loss: 0.5272 Acc: 0.7441 | Val Loss: 0.5098 Acc: 0.7536\n",
      "Epoch 005 | Train Loss: 0.4796 Acc: 0.7782 | Val Loss: 0.4719 Acc: 0.7711\n",
      "Epoch 006 | Train Loss: 0.4477 Acc: 0.7969 | Val Loss: 0.4506 Acc: 0.7820\n",
      "Epoch 007 | Train Loss: 0.3936 Acc: 0.8267 | Val Loss: 0.3898 Acc: 0.8225\n",
      "Epoch 008 | Train Loss: 0.3567 Acc: 0.8451 | Val Loss: 0.3613 Acc: 0.8466\n",
      "Epoch 009 | Train Loss: 0.3181 Acc: 0.8677 | Val Loss: 0.3266 Acc: 0.8551\n",
      "Epoch 010 | Train Loss: 0.2778 Acc: 0.8875 | Val Loss: 0.2962 Acc: 0.8750\n",
      "Epoch 011 | Train Loss: 0.2437 Acc: 0.9002 | Val Loss: 0.2632 Acc: 0.8973\n",
      "Epoch 012 | Train Loss: 0.2249 Acc: 0.9093 | Val Loss: 0.2898 Acc: 0.8690\n",
      "Epoch 013 | Train Loss: 0.2093 Acc: 0.9180 | Val Loss: 0.2221 Acc: 0.9149\n",
      "Epoch 014 | Train Loss: 0.1932 Acc: 0.9218 | Val Loss: 0.2310 Acc: 0.9155\n",
      "Epoch 015 | Train Loss: 0.1598 Acc: 0.9369 | Val Loss: 0.2441 Acc: 0.8998\n",
      "Epoch 016 | Train Loss: 0.1614 Acc: 0.9348 | Val Loss: 0.2131 Acc: 0.9124\n",
      "Epoch 017 | Train Loss: 0.1504 Acc: 0.9401 | Val Loss: 0.1934 Acc: 0.9215\n",
      "Epoch 018 | Train Loss: 0.1272 Acc: 0.9505 | Val Loss: 0.1993 Acc: 0.9185\n",
      "Epoch 019 | Train Loss: 0.1202 Acc: 0.9558 | Val Loss: 0.1960 Acc: 0.9239\n",
      "Epoch 020 | Train Loss: 0.1151 Acc: 0.9579 | Val Loss: 0.1679 Acc: 0.9324\n",
      "Epoch 021 | Train Loss: 0.1134 Acc: 0.9571 | Val Loss: 0.2421 Acc: 0.9203\n",
      "Epoch 022 | Train Loss: 0.1185 Acc: 0.9553 | Val Loss: 0.2255 Acc: 0.9112\n",
      "Epoch 023 | Train Loss: 0.0975 Acc: 0.9616 | Val Loss: 0.1585 Acc: 0.9444\n",
      "Epoch 024 | Train Loss: 0.0872 Acc: 0.9675 | Val Loss: 0.1855 Acc: 0.9342\n",
      "Epoch 025 | Train Loss: 0.0897 Acc: 0.9668 | Val Loss: 0.1687 Acc: 0.9390\n",
      "Epoch 026 | Train Loss: 0.0757 Acc: 0.9707 | Val Loss: 0.2079 Acc: 0.9312\n",
      "Epoch 027 | Train Loss: 0.0844 Acc: 0.9690 | Val Loss: 0.1684 Acc: 0.9342\n",
      "Epoch 028 | Train Loss: 0.0685 Acc: 0.9746 | Val Loss: 0.1718 Acc: 0.9348\n",
      "Epoch 029 | Train Loss: 0.0656 Acc: 0.9764 | Val Loss: 0.1950 Acc: 0.9396\n",
      "Epoch 030 | Train Loss: 0.0687 Acc: 0.9764 | Val Loss: 0.1532 Acc: 0.9457\n",
      "Epoch 031 | Train Loss: 0.0750 Acc: 0.9724 | Val Loss: 0.1513 Acc: 0.9402\n",
      "Epoch 032 | Train Loss: 0.0593 Acc: 0.9792 | Val Loss: 0.1813 Acc: 0.9432\n",
      "Epoch 033 | Train Loss: 0.0594 Acc: 0.9789 | Val Loss: 0.1833 Acc: 0.9450\n",
      "Epoch 034 | Train Loss: 0.0638 Acc: 0.9769 | Val Loss: 0.1774 Acc: 0.9408\n",
      "Epoch 035 | Train Loss: 0.0565 Acc: 0.9799 | Val Loss: 0.1603 Acc: 0.9463\n",
      "Epoch 036 | Train Loss: 0.0578 Acc: 0.9801 | Val Loss: 0.1574 Acc: 0.9426\n",
      "Epoch 037 | Train Loss: 0.0512 Acc: 0.9814 | Val Loss: 0.1594 Acc: 0.9457\n",
      "Epoch 038 | Train Loss: 0.0506 Acc: 0.9822 | Val Loss: 0.1737 Acc: 0.9408\n",
      "Epoch 039 | Train Loss: 0.0437 Acc: 0.9849 | Val Loss: 0.1889 Acc: 0.9450\n",
      "Epoch 040 | Train Loss: 0.0552 Acc: 0.9804 | Val Loss: 0.1442 Acc: 0.9463\n",
      "Epoch 041 | Train Loss: 0.0496 Acc: 0.9832 | Val Loss: 0.1816 Acc: 0.9402\n",
      "Epoch 042 | Train Loss: 0.0502 Acc: 0.9810 | Val Loss: 0.1956 Acc: 0.9336\n",
      "Epoch 043 | Train Loss: 0.0557 Acc: 0.9807 | Val Loss: 0.1265 Acc: 0.9541\n",
      "Epoch 044 | Train Loss: 0.0395 Acc: 0.9869 | Val Loss: 0.2128 Acc: 0.9312\n",
      "Epoch 045 | Train Loss: 0.0429 Acc: 0.9843 | Val Loss: 0.1383 Acc: 0.9535\n",
      "Epoch 046 | Train Loss: 0.0441 Acc: 0.9843 | Val Loss: 0.1662 Acc: 0.9475\n",
      "Epoch 047 | Train Loss: 0.0572 Acc: 0.9810 | Val Loss: 0.1799 Acc: 0.9366\n",
      "Epoch 048 | Train Loss: 0.0400 Acc: 0.9852 | Val Loss: 0.1943 Acc: 0.9360\n",
      "Epoch 049 | Train Loss: 0.0425 Acc: 0.9835 | Val Loss: 0.1929 Acc: 0.9354\n",
      "Epoch 050 | Train Loss: 0.0429 Acc: 0.9843 | Val Loss: 0.1608 Acc: 0.9475\n",
      "Epoch 051 | Train Loss: 0.0418 Acc: 0.9846 | Val Loss: 0.1961 Acc: 0.9396\n",
      "Epoch 052 | Train Loss: 0.0326 Acc: 0.9885 | Val Loss: 0.1595 Acc: 0.9523\n",
      "Epoch 053 | Train Loss: 0.0403 Acc: 0.9848 | Val Loss: 0.1531 Acc: 0.9523\n",
      "Early stopping triggered.\n",
      "Epoch 001 | Train Loss: 0.6814 Acc: 0.5786 | Val Loss: 0.6738 Acc: 0.5876\n",
      "Epoch 002 | Train Loss: 0.6712 Acc: 0.5963 | Val Loss: 0.6604 Acc: 0.6021\n",
      "Epoch 003 | Train Loss: 0.6324 Acc: 0.6459 | Val Loss: 0.6406 Acc: 0.6389\n",
      "Epoch 004 | Train Loss: 0.5906 Acc: 0.6992 | Val Loss: 0.5756 Acc: 0.7053\n",
      "Epoch 005 | Train Loss: 0.5535 Acc: 0.7279 | Val Loss: 0.5430 Acc: 0.7301\n",
      "Epoch 006 | Train Loss: 0.5265 Acc: 0.7438 | Val Loss: 0.5312 Acc: 0.7452\n",
      "Epoch 007 | Train Loss: 0.5050 Acc: 0.7622 | Val Loss: 0.5092 Acc: 0.7494\n",
      "Epoch 008 | Train Loss: 0.4831 Acc: 0.7753 | Val Loss: 0.4931 Acc: 0.7645\n",
      "Epoch 009 | Train Loss: 0.4583 Acc: 0.7867 | Val Loss: 0.4685 Acc: 0.7736\n",
      "Epoch 010 | Train Loss: 0.4264 Acc: 0.8049 | Val Loss: 0.4234 Acc: 0.7977\n",
      "Epoch 011 | Train Loss: 0.4047 Acc: 0.8167 | Val Loss: 0.3898 Acc: 0.8134\n",
      "Epoch 012 | Train Loss: 0.3701 Acc: 0.8380 | Val Loss: 0.3587 Acc: 0.8339\n",
      "Epoch 013 | Train Loss: 0.3468 Acc: 0.8461 | Val Loss: 0.3351 Acc: 0.8533\n",
      "Epoch 014 | Train Loss: 0.3259 Acc: 0.8629 | Val Loss: 0.3037 Acc: 0.8587\n",
      "Epoch 015 | Train Loss: 0.2955 Acc: 0.8766 | Val Loss: 0.3115 Acc: 0.8678\n",
      "Epoch 016 | Train Loss: 0.2778 Acc: 0.8871 | Val Loss: 0.2850 Acc: 0.8696\n",
      "Epoch 017 | Train Loss: 0.2530 Acc: 0.8919 | Val Loss: 0.2839 Acc: 0.8780\n",
      "Epoch 018 | Train Loss: 0.2483 Acc: 0.8948 | Val Loss: 0.2649 Acc: 0.8859\n",
      "Epoch 019 | Train Loss: 0.2297 Acc: 0.9082 | Val Loss: 0.2359 Acc: 0.8998\n",
      "Epoch 020 | Train Loss: 0.2118 Acc: 0.9145 | Val Loss: 0.2266 Acc: 0.9070\n",
      "Epoch 021 | Train Loss: 0.1945 Acc: 0.9206 | Val Loss: 0.2303 Acc: 0.9149\n",
      "Epoch 022 | Train Loss: 0.1856 Acc: 0.9278 | Val Loss: 0.1926 Acc: 0.9209\n",
      "Epoch 023 | Train Loss: 0.1775 Acc: 0.9299 | Val Loss: 0.2360 Acc: 0.8998\n",
      "Epoch 024 | Train Loss: 0.1564 Acc: 0.9414 | Val Loss: 0.2161 Acc: 0.9185\n",
      "Epoch 025 | Train Loss: 0.1567 Acc: 0.9387 | Val Loss: 0.2199 Acc: 0.9191\n",
      "Epoch 026 | Train Loss: 0.1546 Acc: 0.9407 | Val Loss: 0.2019 Acc: 0.9203\n",
      "Epoch 027 | Train Loss: 0.1546 Acc: 0.9422 | Val Loss: 0.1773 Acc: 0.9360\n",
      "Epoch 028 | Train Loss: 0.1410 Acc: 0.9459 | Val Loss: 0.1720 Acc: 0.9348\n",
      "Epoch 029 | Train Loss: 0.1239 Acc: 0.9538 | Val Loss: 0.1644 Acc: 0.9420\n",
      "Epoch 030 | Train Loss: 0.1135 Acc: 0.9586 | Val Loss: 0.1637 Acc: 0.9420\n",
      "Epoch 031 | Train Loss: 0.1100 Acc: 0.9607 | Val Loss: 0.1902 Acc: 0.9342\n",
      "Epoch 032 | Train Loss: 0.1161 Acc: 0.9585 | Val Loss: 0.1798 Acc: 0.9251\n",
      "Epoch 033 | Train Loss: 0.1106 Acc: 0.9603 | Val Loss: 0.1726 Acc: 0.9348\n",
      "Epoch 034 | Train Loss: 0.1048 Acc: 0.9632 | Val Loss: 0.1378 Acc: 0.9523\n",
      "Epoch 035 | Train Loss: 0.0968 Acc: 0.9629 | Val Loss: 0.1578 Acc: 0.9420\n",
      "Epoch 036 | Train Loss: 0.0993 Acc: 0.9621 | Val Loss: 0.1479 Acc: 0.9487\n",
      "Epoch 037 | Train Loss: 0.1028 Acc: 0.9618 | Val Loss: 0.1641 Acc: 0.9342\n",
      "Epoch 038 | Train Loss: 0.0959 Acc: 0.9648 | Val Loss: 0.1479 Acc: 0.9444\n",
      "Epoch 039 | Train Loss: 0.0860 Acc: 0.9687 | Val Loss: 0.2066 Acc: 0.9215\n",
      "Epoch 040 | Train Loss: 0.0873 Acc: 0.9675 | Val Loss: 0.1370 Acc: 0.9529\n",
      "Epoch 041 | Train Loss: 0.0824 Acc: 0.9709 | Val Loss: 0.1694 Acc: 0.9438\n",
      "Epoch 042 | Train Loss: 0.0885 Acc: 0.9686 | Val Loss: 0.1335 Acc: 0.9547\n",
      "Epoch 043 | Train Loss: 0.0783 Acc: 0.9704 | Val Loss: 0.1557 Acc: 0.9402\n",
      "Epoch 044 | Train Loss: 0.0769 Acc: 0.9725 | Val Loss: 0.1451 Acc: 0.9463\n",
      "Epoch 045 | Train Loss: 0.0834 Acc: 0.9709 | Val Loss: 0.1500 Acc: 0.9408\n",
      "Epoch 046 | Train Loss: 0.0775 Acc: 0.9704 | Val Loss: 0.1182 Acc: 0.9535\n",
      "Epoch 047 | Train Loss: 0.0726 Acc: 0.9748 | Val Loss: 0.1363 Acc: 0.9535\n",
      "Epoch 048 | Train Loss: 0.0774 Acc: 0.9734 | Val Loss: 0.1348 Acc: 0.9535\n",
      "Epoch 049 | Train Loss: 0.0788 Acc: 0.9701 | Val Loss: 0.1262 Acc: 0.9614\n",
      "Epoch 050 | Train Loss: 0.0608 Acc: 0.9774 | Val Loss: 0.1479 Acc: 0.9511\n",
      "Epoch 051 | Train Loss: 0.0687 Acc: 0.9739 | Val Loss: 0.1864 Acc: 0.9348\n",
      "Epoch 052 | Train Loss: 0.0763 Acc: 0.9695 | Val Loss: 0.1443 Acc: 0.9505\n",
      "Epoch 053 | Train Loss: 0.0663 Acc: 0.9746 | Val Loss: 0.1297 Acc: 0.9529\n",
      "Epoch 054 | Train Loss: 0.0597 Acc: 0.9783 | Val Loss: 0.1261 Acc: 0.9541\n",
      "Epoch 055 | Train Loss: 0.0631 Acc: 0.9774 | Val Loss: 0.1534 Acc: 0.9493\n",
      "Epoch 056 | Train Loss: 0.0710 Acc: 0.9728 | Val Loss: 0.1556 Acc: 0.9469\n",
      "Early stopping triggered.\n",
      "Epoch 001 | Train Loss: 0.6882 Acc: 0.5526 | Val Loss: 0.6830 Acc: 0.5731\n",
      "Epoch 002 | Train Loss: 0.6804 Acc: 0.5872 | Val Loss: 0.6774 Acc: 0.5857\n",
      "Epoch 003 | Train Loss: 0.6761 Acc: 0.5947 | Val Loss: 0.6754 Acc: 0.5888\n",
      "Epoch 004 | Train Loss: 0.6693 Acc: 0.5990 | Val Loss: 0.6653 Acc: 0.6021\n",
      "Epoch 005 | Train Loss: 0.6625 Acc: 0.6079 | Val Loss: 0.6583 Acc: 0.6057\n",
      "Epoch 006 | Train Loss: 0.6530 Acc: 0.6206 | Val Loss: 0.6428 Acc: 0.6244\n",
      "Epoch 007 | Train Loss: 0.6415 Acc: 0.6458 | Val Loss: 0.6239 Acc: 0.6709\n",
      "Epoch 008 | Train Loss: 0.6408 Acc: 0.6480 | Val Loss: 0.6222 Acc: 0.6739\n",
      "Epoch 009 | Train Loss: 0.6295 Acc: 0.6628 | Val Loss: 0.6175 Acc: 0.6763\n",
      "Epoch 010 | Train Loss: 0.6243 Acc: 0.6724 | Val Loss: 0.6374 Acc: 0.6383\n",
      "Epoch 011 | Train Loss: 0.6221 Acc: 0.6696 | Val Loss: 0.6102 Acc: 0.6866\n",
      "Epoch 012 | Train Loss: 0.6092 Acc: 0.6879 | Val Loss: 0.6003 Acc: 0.6890\n",
      "Epoch 013 | Train Loss: 0.6065 Acc: 0.6864 | Val Loss: 0.5967 Acc: 0.6914\n",
      "Epoch 014 | Train Loss: 0.6004 Acc: 0.6962 | Val Loss: 0.5914 Acc: 0.6993\n",
      "Epoch 015 | Train Loss: 0.6000 Acc: 0.6961 | Val Loss: 0.5934 Acc: 0.6938\n",
      "Epoch 016 | Train Loss: 0.5982 Acc: 0.6979 | Val Loss: 0.5935 Acc: 0.6969\n",
      "Epoch 017 | Train Loss: 0.5975 Acc: 0.6912 | Val Loss: 0.5900 Acc: 0.7011\n",
      "Epoch 018 | Train Loss: 0.5909 Acc: 0.7054 | Val Loss: 0.5840 Acc: 0.7053\n",
      "Epoch 019 | Train Loss: 0.5906 Acc: 0.7012 | Val Loss: 0.5866 Acc: 0.6896\n",
      "Epoch 020 | Train Loss: 0.5852 Acc: 0.7047 | Val Loss: 0.5882 Acc: 0.6920\n",
      "Epoch 021 | Train Loss: 0.5875 Acc: 0.7059 | Val Loss: 0.5731 Acc: 0.7095\n",
      "Epoch 022 | Train Loss: 0.5744 Acc: 0.7163 | Val Loss: 0.5705 Acc: 0.7071\n",
      "Epoch 023 | Train Loss: 0.5756 Acc: 0.7095 | Val Loss: 0.5673 Acc: 0.7089\n",
      "Epoch 024 | Train Loss: 0.5683 Acc: 0.7193 | Val Loss: 0.5857 Acc: 0.7005\n",
      "Epoch 025 | Train Loss: 0.5722 Acc: 0.7198 | Val Loss: 0.5627 Acc: 0.7144\n",
      "Epoch 026 | Train Loss: 0.5647 Acc: 0.7231 | Val Loss: 0.5600 Acc: 0.7228\n",
      "Epoch 027 | Train Loss: 0.5573 Acc: 0.7285 | Val Loss: 0.5625 Acc: 0.7222\n",
      "Epoch 028 | Train Loss: 0.5538 Acc: 0.7327 | Val Loss: 0.5653 Acc: 0.7126\n",
      "Epoch 029 | Train Loss: 0.5491 Acc: 0.7326 | Val Loss: 0.5509 Acc: 0.7216\n",
      "Epoch 030 | Train Loss: 0.5527 Acc: 0.7303 | Val Loss: 0.5466 Acc: 0.7277\n",
      "Epoch 031 | Train Loss: 0.5466 Acc: 0.7368 | Val Loss: 0.5537 Acc: 0.7174\n",
      "Epoch 032 | Train Loss: 0.5353 Acc: 0.7466 | Val Loss: 0.5514 Acc: 0.7156\n",
      "Epoch 033 | Train Loss: 0.5396 Acc: 0.7408 | Val Loss: 0.5357 Acc: 0.7325\n",
      "Epoch 034 | Train Loss: 0.5340 Acc: 0.7388 | Val Loss: 0.5506 Acc: 0.7271\n",
      "Epoch 035 | Train Loss: 0.5268 Acc: 0.7482 | Val Loss: 0.5559 Acc: 0.7216\n",
      "Epoch 036 | Train Loss: 0.5328 Acc: 0.7453 | Val Loss: 0.5299 Acc: 0.7343\n",
      "Epoch 037 | Train Loss: 0.5219 Acc: 0.7537 | Val Loss: 0.5309 Acc: 0.7385\n",
      "Epoch 038 | Train Loss: 0.5157 Acc: 0.7584 | Val Loss: 0.5252 Acc: 0.7421\n",
      "Epoch 039 | Train Loss: 0.5160 Acc: 0.7574 | Val Loss: 0.5448 Acc: 0.7234\n",
      "Epoch 040 | Train Loss: 0.5127 Acc: 0.7595 | Val Loss: 0.5204 Acc: 0.7421\n",
      "Epoch 041 | Train Loss: 0.5123 Acc: 0.7551 | Val Loss: 0.5185 Acc: 0.7452\n",
      "Epoch 042 | Train Loss: 0.5042 Acc: 0.7661 | Val Loss: 0.5183 Acc: 0.7415\n",
      "Epoch 043 | Train Loss: 0.5038 Acc: 0.7655 | Val Loss: 0.5128 Acc: 0.7428\n",
      "Epoch 044 | Train Loss: 0.4991 Acc: 0.7648 | Val Loss: 0.5133 Acc: 0.7434\n",
      "Epoch 045 | Train Loss: 0.4925 Acc: 0.7691 | Val Loss: 0.5080 Acc: 0.7446\n",
      "Epoch 046 | Train Loss: 0.4945 Acc: 0.7639 | Val Loss: 0.5111 Acc: 0.7458\n",
      "Epoch 047 | Train Loss: 0.5008 Acc: 0.7639 | Val Loss: 0.5038 Acc: 0.7464\n",
      "Epoch 048 | Train Loss: 0.4948 Acc: 0.7696 | Val Loss: 0.5033 Acc: 0.7500\n",
      "Epoch 049 | Train Loss: 0.4883 Acc: 0.7716 | Val Loss: 0.5003 Acc: 0.7506\n",
      "Epoch 050 | Train Loss: 0.4792 Acc: 0.7776 | Val Loss: 0.5008 Acc: 0.7500\n",
      "Epoch 051 | Train Loss: 0.4733 Acc: 0.7817 | Val Loss: 0.4980 Acc: 0.7530\n",
      "Epoch 052 | Train Loss: 0.4744 Acc: 0.7814 | Val Loss: 0.4933 Acc: 0.7591\n",
      "Epoch 053 | Train Loss: 0.4772 Acc: 0.7774 | Val Loss: 0.4907 Acc: 0.7488\n",
      "Epoch 054 | Train Loss: 0.4687 Acc: 0.7829 | Val Loss: 0.4897 Acc: 0.7548\n",
      "Epoch 055 | Train Loss: 0.4793 Acc: 0.7794 | Val Loss: 0.4866 Acc: 0.7681\n",
      "Epoch 056 | Train Loss: 0.4726 Acc: 0.7797 | Val Loss: 0.4926 Acc: 0.7524\n",
      "Epoch 057 | Train Loss: 0.4653 Acc: 0.7876 | Val Loss: 0.4879 Acc: 0.7542\n",
      "Epoch 058 | Train Loss: 0.4577 Acc: 0.7880 | Val Loss: 0.4776 Acc: 0.7657\n",
      "Epoch 059 | Train Loss: 0.4599 Acc: 0.7886 | Val Loss: 0.4881 Acc: 0.7530\n",
      "Epoch 060 | Train Loss: 0.4566 Acc: 0.7903 | Val Loss: 0.4757 Acc: 0.7603\n",
      "Epoch 001 | Train Loss: 0.6813 Acc: 0.5760 | Val Loss: 0.6763 Acc: 0.5906\n",
      "Epoch 002 | Train Loss: 0.6727 Acc: 0.5958 | Val Loss: 0.6677 Acc: 0.6002\n",
      "Epoch 003 | Train Loss: 0.6526 Acc: 0.6183 | Val Loss: 0.6360 Acc: 0.6534\n",
      "Epoch 004 | Train Loss: 0.6103 Acc: 0.6834 | Val Loss: 0.5906 Acc: 0.6914\n",
      "Epoch 005 | Train Loss: 0.5795 Acc: 0.7039 | Val Loss: 0.5643 Acc: 0.7120\n",
      "Epoch 006 | Train Loss: 0.5530 Acc: 0.7279 | Val Loss: 0.5562 Acc: 0.7240\n",
      "Epoch 007 | Train Loss: 0.5419 Acc: 0.7272 | Val Loss: 0.5456 Acc: 0.7271\n",
      "Epoch 008 | Train Loss: 0.5227 Acc: 0.7445 | Val Loss: 0.5265 Acc: 0.7313\n",
      "Epoch 009 | Train Loss: 0.5077 Acc: 0.7525 | Val Loss: 0.5104 Acc: 0.7506\n",
      "Epoch 010 | Train Loss: 0.4950 Acc: 0.7664 | Val Loss: 0.5080 Acc: 0.7536\n",
      "Epoch 011 | Train Loss: 0.4833 Acc: 0.7687 | Val Loss: 0.4761 Acc: 0.7687\n",
      "Epoch 012 | Train Loss: 0.4779 Acc: 0.7722 | Val Loss: 0.4721 Acc: 0.7663\n",
      "Epoch 013 | Train Loss: 0.4504 Acc: 0.7842 | Val Loss: 0.4382 Acc: 0.7868\n",
      "Epoch 014 | Train Loss: 0.4367 Acc: 0.7986 | Val Loss: 0.4470 Acc: 0.7766\n",
      "Epoch 015 | Train Loss: 0.4221 Acc: 0.8033 | Val Loss: 0.4537 Acc: 0.7657\n",
      "Epoch 016 | Train Loss: 0.3995 Acc: 0.8164 | Val Loss: 0.3974 Acc: 0.8104\n",
      "Epoch 017 | Train Loss: 0.3907 Acc: 0.8194 | Val Loss: 0.3764 Acc: 0.8207\n",
      "Epoch 018 | Train Loss: 0.3700 Acc: 0.8359 | Val Loss: 0.3726 Acc: 0.8249\n",
      "Epoch 019 | Train Loss: 0.3563 Acc: 0.8381 | Val Loss: 0.3501 Acc: 0.8406\n",
      "Epoch 020 | Train Loss: 0.3305 Acc: 0.8538 | Val Loss: 0.3264 Acc: 0.8460\n",
      "Epoch 021 | Train Loss: 0.3123 Acc: 0.8659 | Val Loss: 0.3093 Acc: 0.8647\n",
      "Epoch 022 | Train Loss: 0.3019 Acc: 0.8726 | Val Loss: 0.2758 Acc: 0.8798\n",
      "Epoch 023 | Train Loss: 0.2875 Acc: 0.8747 | Val Loss: 0.2913 Acc: 0.8756\n",
      "Epoch 024 | Train Loss: 0.2756 Acc: 0.8849 | Val Loss: 0.2625 Acc: 0.8949\n",
      "Epoch 025 | Train Loss: 0.2545 Acc: 0.8964 | Val Loss: 0.2763 Acc: 0.8841\n",
      "Epoch 026 | Train Loss: 0.2491 Acc: 0.8942 | Val Loss: 0.2408 Acc: 0.8973\n",
      "Epoch 027 | Train Loss: 0.2378 Acc: 0.9002 | Val Loss: 0.2480 Acc: 0.9070\n",
      "Epoch 028 | Train Loss: 0.2337 Acc: 0.9058 | Val Loss: 0.2578 Acc: 0.8949\n",
      "Epoch 029 | Train Loss: 0.2200 Acc: 0.9120 | Val Loss: 0.2392 Acc: 0.9040\n",
      "Epoch 030 | Train Loss: 0.2088 Acc: 0.9176 | Val Loss: 0.2342 Acc: 0.9082\n",
      "Epoch 031 | Train Loss: 0.2103 Acc: 0.9156 | Val Loss: 0.2178 Acc: 0.9191\n",
      "Epoch 032 | Train Loss: 0.1946 Acc: 0.9257 | Val Loss: 0.2166 Acc: 0.9076\n",
      "Epoch 033 | Train Loss: 0.1949 Acc: 0.9186 | Val Loss: 0.2036 Acc: 0.9191\n",
      "Epoch 034 | Train Loss: 0.1821 Acc: 0.9299 | Val Loss: 0.1934 Acc: 0.9209\n",
      "Epoch 035 | Train Loss: 0.1724 Acc: 0.9316 | Val Loss: 0.2060 Acc: 0.9209\n",
      "Epoch 036 | Train Loss: 0.1748 Acc: 0.9289 | Val Loss: 0.2054 Acc: 0.9251\n",
      "Epoch 037 | Train Loss: 0.1671 Acc: 0.9319 | Val Loss: 0.2319 Acc: 0.9040\n",
      "Epoch 038 | Train Loss: 0.1561 Acc: 0.9388 | Val Loss: 0.1758 Acc: 0.9318\n",
      "Epoch 039 | Train Loss: 0.1595 Acc: 0.9390 | Val Loss: 0.1997 Acc: 0.9143\n",
      "Epoch 040 | Train Loss: 0.1506 Acc: 0.9395 | Val Loss: 0.1890 Acc: 0.9251\n",
      "Epoch 041 | Train Loss: 0.1448 Acc: 0.9441 | Val Loss: 0.2292 Acc: 0.9161\n",
      "Epoch 042 | Train Loss: 0.1409 Acc: 0.9456 | Val Loss: 0.1785 Acc: 0.9251\n",
      "Epoch 043 | Train Loss: 0.1359 Acc: 0.9506 | Val Loss: 0.1675 Acc: 0.9312\n",
      "Epoch 044 | Train Loss: 0.1246 Acc: 0.9536 | Val Loss: 0.1893 Acc: 0.9263\n",
      "Epoch 045 | Train Loss: 0.1231 Acc: 0.9506 | Val Loss: 0.2208 Acc: 0.9167\n",
      "Epoch 046 | Train Loss: 0.1336 Acc: 0.9484 | Val Loss: 0.1881 Acc: 0.9293\n",
      "Epoch 047 | Train Loss: 0.1225 Acc: 0.9547 | Val Loss: 0.1680 Acc: 0.9312\n",
      "Epoch 048 | Train Loss: 0.1208 Acc: 0.9539 | Val Loss: 0.1561 Acc: 0.9396\n",
      "Epoch 049 | Train Loss: 0.1245 Acc: 0.9497 | Val Loss: 0.1632 Acc: 0.9390\n",
      "Epoch 050 | Train Loss: 0.1070 Acc: 0.9604 | Val Loss: 0.1390 Acc: 0.9511\n",
      "Epoch 051 | Train Loss: 0.1077 Acc: 0.9621 | Val Loss: 0.1707 Acc: 0.9306\n",
      "Epoch 052 | Train Loss: 0.1066 Acc: 0.9594 | Val Loss: 0.1679 Acc: 0.9384\n",
      "Epoch 053 | Train Loss: 0.1092 Acc: 0.9588 | Val Loss: 0.1539 Acc: 0.9481\n",
      "Epoch 054 | Train Loss: 0.1007 Acc: 0.9612 | Val Loss: 0.1710 Acc: 0.9396\n",
      "Epoch 055 | Train Loss: 0.1074 Acc: 0.9606 | Val Loss: 0.1387 Acc: 0.9457\n",
      "Epoch 056 | Train Loss: 0.0969 Acc: 0.9641 | Val Loss: 0.1735 Acc: 0.9312\n",
      "Epoch 057 | Train Loss: 0.0892 Acc: 0.9681 | Val Loss: 0.1790 Acc: 0.9312\n",
      "Epoch 058 | Train Loss: 0.0912 Acc: 0.9683 | Val Loss: 0.1373 Acc: 0.9463\n",
      "Epoch 059 | Train Loss: 0.1012 Acc: 0.9624 | Val Loss: 0.1451 Acc: 0.9420\n",
      "Epoch 060 | Train Loss: 0.0946 Acc: 0.9630 | Val Loss: 0.1817 Acc: 0.9378\n",
      "Epoch 001 | Train Loss: 0.6787 Acc: 0.5781 | Val Loss: 0.6704 Acc: 0.5954\n",
      "Epoch 002 | Train Loss: 0.6654 Acc: 0.6052 | Val Loss: 0.6617 Acc: 0.6021\n",
      "Epoch 003 | Train Loss: 0.6499 Acc: 0.6221 | Val Loss: 0.6405 Acc: 0.6353\n",
      "Epoch 004 | Train Loss: 0.6208 Acc: 0.6711 | Val Loss: 0.5986 Acc: 0.6914\n",
      "Epoch 005 | Train Loss: 0.5850 Acc: 0.6994 | Val Loss: 0.5717 Acc: 0.7041\n",
      "Epoch 006 | Train Loss: 0.5565 Acc: 0.7201 | Val Loss: 0.5852 Acc: 0.7029\n",
      "Epoch 007 | Train Loss: 0.5368 Acc: 0.7356 | Val Loss: 0.5363 Acc: 0.7271\n",
      "Epoch 008 | Train Loss: 0.5246 Acc: 0.7423 | Val Loss: 0.5257 Acc: 0.7319\n",
      "Epoch 009 | Train Loss: 0.4990 Acc: 0.7552 | Val Loss: 0.5152 Acc: 0.7379\n",
      "Epoch 010 | Train Loss: 0.4914 Acc: 0.7616 | Val Loss: 0.4924 Acc: 0.7615\n",
      "Epoch 011 | Train Loss: 0.4663 Acc: 0.7782 | Val Loss: 0.4742 Acc: 0.7778\n",
      "Epoch 012 | Train Loss: 0.4531 Acc: 0.7859 | Val Loss: 0.4448 Acc: 0.7953\n",
      "Epoch 013 | Train Loss: 0.4354 Acc: 0.7969 | Val Loss: 0.4453 Acc: 0.7905\n",
      "Epoch 014 | Train Loss: 0.4146 Acc: 0.8128 | Val Loss: 0.4396 Acc: 0.7893\n",
      "Epoch 015 | Train Loss: 0.3930 Acc: 0.8235 | Val Loss: 0.3777 Acc: 0.8297\n",
      "Epoch 016 | Train Loss: 0.3619 Acc: 0.8386 | Val Loss: 0.3678 Acc: 0.8382\n",
      "Epoch 017 | Train Loss: 0.3500 Acc: 0.8440 | Val Loss: 0.3902 Acc: 0.8213\n",
      "Epoch 018 | Train Loss: 0.3283 Acc: 0.8588 | Val Loss: 0.3376 Acc: 0.8569\n",
      "Epoch 019 | Train Loss: 0.3085 Acc: 0.8667 | Val Loss: 0.3302 Acc: 0.8575\n",
      "Epoch 020 | Train Loss: 0.2994 Acc: 0.8735 | Val Loss: 0.3229 Acc: 0.8611\n",
      "Epoch 021 | Train Loss: 0.2660 Acc: 0.8902 | Val Loss: 0.2761 Acc: 0.8907\n",
      "Epoch 022 | Train Loss: 0.2543 Acc: 0.8951 | Val Loss: 0.2843 Acc: 0.8768\n",
      "Epoch 023 | Train Loss: 0.2378 Acc: 0.9064 | Val Loss: 0.2562 Acc: 0.8907\n",
      "Epoch 024 | Train Loss: 0.2343 Acc: 0.9040 | Val Loss: 0.2880 Acc: 0.8786\n",
      "Epoch 025 | Train Loss: 0.2110 Acc: 0.9165 | Val Loss: 0.2354 Acc: 0.9064\n",
      "Epoch 026 | Train Loss: 0.2053 Acc: 0.9198 | Val Loss: 0.2272 Acc: 0.9094\n",
      "Epoch 027 | Train Loss: 0.1914 Acc: 0.9256 | Val Loss: 0.2335 Acc: 0.9004\n",
      "Epoch 028 | Train Loss: 0.1759 Acc: 0.9298 | Val Loss: 0.2213 Acc: 0.9106\n",
      "Epoch 029 | Train Loss: 0.1709 Acc: 0.9340 | Val Loss: 0.2384 Acc: 0.9088\n",
      "Epoch 030 | Train Loss: 0.1793 Acc: 0.9319 | Val Loss: 0.2126 Acc: 0.9173\n",
      "Epoch 031 | Train Loss: 0.1416 Acc: 0.9455 | Val Loss: 0.2832 Acc: 0.8973\n",
      "Epoch 032 | Train Loss: 0.1566 Acc: 0.9352 | Val Loss: 0.2108 Acc: 0.9257\n",
      "Epoch 033 | Train Loss: 0.1391 Acc: 0.9458 | Val Loss: 0.1848 Acc: 0.9324\n",
      "Epoch 034 | Train Loss: 0.1233 Acc: 0.9523 | Val Loss: 0.1975 Acc: 0.9251\n",
      "Epoch 035 | Train Loss: 0.1305 Acc: 0.9509 | Val Loss: 0.1927 Acc: 0.9245\n",
      "Epoch 036 | Train Loss: 0.1209 Acc: 0.9517 | Val Loss: 0.2069 Acc: 0.9269\n",
      "Epoch 037 | Train Loss: 0.1101 Acc: 0.9597 | Val Loss: 0.2636 Acc: 0.9076\n",
      "Epoch 038 | Train Loss: 0.1034 Acc: 0.9592 | Val Loss: 0.1815 Acc: 0.9324\n",
      "Epoch 039 | Train Loss: 0.1050 Acc: 0.9588 | Val Loss: 0.2165 Acc: 0.9239\n",
      "Epoch 040 | Train Loss: 0.0941 Acc: 0.9616 | Val Loss: 0.2443 Acc: 0.9179\n",
      "Epoch 041 | Train Loss: 0.0947 Acc: 0.9638 | Val Loss: 0.1998 Acc: 0.9269\n",
      "Epoch 042 | Train Loss: 0.0889 Acc: 0.9662 | Val Loss: 0.1807 Acc: 0.9300\n",
      "Epoch 043 | Train Loss: 0.0840 Acc: 0.9674 | Val Loss: 0.1998 Acc: 0.9257\n",
      "Epoch 044 | Train Loss: 0.0829 Acc: 0.9684 | Val Loss: 0.1824 Acc: 0.9366\n",
      "Epoch 045 | Train Loss: 0.0710 Acc: 0.9737 | Val Loss: 0.2028 Acc: 0.9318\n",
      "Epoch 046 | Train Loss: 0.0720 Acc: 0.9731 | Val Loss: 0.1795 Acc: 0.9390\n",
      "Epoch 047 | Train Loss: 0.0748 Acc: 0.9707 | Val Loss: 0.1812 Acc: 0.9408\n",
      "Epoch 048 | Train Loss: 0.0720 Acc: 0.9733 | Val Loss: 0.1644 Acc: 0.9408\n",
      "Epoch 049 | Train Loss: 0.0603 Acc: 0.9781 | Val Loss: 0.1987 Acc: 0.9402\n",
      "Epoch 050 | Train Loss: 0.0721 Acc: 0.9724 | Val Loss: 0.1997 Acc: 0.9336\n",
      "Epoch 051 | Train Loss: 0.0662 Acc: 0.9780 | Val Loss: 0.1572 Acc: 0.9426\n",
      "Epoch 052 | Train Loss: 0.0583 Acc: 0.9777 | Val Loss: 0.1809 Acc: 0.9348\n",
      "Epoch 053 | Train Loss: 0.0598 Acc: 0.9769 | Val Loss: 0.1776 Acc: 0.9390\n",
      "Epoch 054 | Train Loss: 0.0611 Acc: 0.9789 | Val Loss: 0.1553 Acc: 0.9505\n",
      "Epoch 055 | Train Loss: 0.0571 Acc: 0.9793 | Val Loss: 0.1669 Acc: 0.9450\n",
      "Epoch 056 | Train Loss: 0.0677 Acc: 0.9737 | Val Loss: 0.1762 Acc: 0.9390\n",
      "Epoch 057 | Train Loss: 0.0613 Acc: 0.9789 | Val Loss: 0.1503 Acc: 0.9475\n",
      "Epoch 058 | Train Loss: 0.0528 Acc: 0.9816 | Val Loss: 0.1821 Acc: 0.9330\n",
      "Epoch 059 | Train Loss: 0.0552 Acc: 0.9777 | Val Loss: 0.1633 Acc: 0.9426\n",
      "Epoch 060 | Train Loss: 0.0613 Acc: 0.9775 | Val Loss: 0.1507 Acc: 0.9463\n",
      "Epoch 001 | Train Loss: 0.6801 Acc: 0.5703 | Val Loss: 0.6752 Acc: 0.5900\n",
      "Epoch 002 | Train Loss: 0.6690 Acc: 0.5975 | Val Loss: 0.6579 Acc: 0.6171\n",
      "Epoch 003 | Train Loss: 0.6109 Acc: 0.6779 | Val Loss: 0.5892 Acc: 0.6969\n",
      "Epoch 004 | Train Loss: 0.5572 Acc: 0.7272 | Val Loss: 0.5496 Acc: 0.7240\n",
      "Epoch 005 | Train Loss: 0.5305 Acc: 0.7365 | Val Loss: 0.5229 Acc: 0.7325\n",
      "Epoch 006 | Train Loss: 0.5076 Acc: 0.7530 | Val Loss: 0.5555 Acc: 0.7319\n",
      "Epoch 007 | Train Loss: 0.4979 Acc: 0.7631 | Val Loss: 0.4850 Acc: 0.7657\n",
      "Epoch 008 | Train Loss: 0.4558 Acc: 0.7880 | Val Loss: 0.4651 Acc: 0.7645\n",
      "Epoch 009 | Train Loss: 0.4462 Acc: 0.7921 | Val Loss: 0.4405 Acc: 0.7880\n",
      "Epoch 010 | Train Loss: 0.4311 Acc: 0.8040 | Val Loss: 0.4279 Acc: 0.7886\n",
      "Epoch 011 | Train Loss: 0.3912 Acc: 0.8226 | Val Loss: 0.4521 Acc: 0.7971\n",
      "Epoch 012 | Train Loss: 0.3684 Acc: 0.8350 | Val Loss: 0.3740 Acc: 0.8188\n",
      "Epoch 013 | Train Loss: 0.3406 Acc: 0.8549 | Val Loss: 0.3413 Acc: 0.8448\n",
      "Epoch 014 | Train Loss: 0.3250 Acc: 0.8544 | Val Loss: 0.3086 Acc: 0.8671\n",
      "Epoch 015 | Train Loss: 0.2955 Acc: 0.8729 | Val Loss: 0.2927 Acc: 0.8617\n",
      "Epoch 016 | Train Loss: 0.2772 Acc: 0.8846 | Val Loss: 0.2731 Acc: 0.8792\n",
      "Epoch 017 | Train Loss: 0.2627 Acc: 0.8905 | Val Loss: 0.2590 Acc: 0.8883\n",
      "Epoch 018 | Train Loss: 0.2498 Acc: 0.8925 | Val Loss: 0.2313 Acc: 0.9010\n",
      "Epoch 019 | Train Loss: 0.2326 Acc: 0.9061 | Val Loss: 0.2394 Acc: 0.9058\n",
      "Epoch 020 | Train Loss: 0.2124 Acc: 0.9139 | Val Loss: 0.2283 Acc: 0.9046\n",
      "Epoch 021 | Train Loss: 0.2079 Acc: 0.9171 | Val Loss: 0.2200 Acc: 0.9058\n",
      "Epoch 022 | Train Loss: 0.2014 Acc: 0.9198 | Val Loss: 0.2015 Acc: 0.9233\n",
      "Epoch 023 | Train Loss: 0.1783 Acc: 0.9277 | Val Loss: 0.2136 Acc: 0.9064\n",
      "Epoch 024 | Train Loss: 0.1809 Acc: 0.9268 | Val Loss: 0.2205 Acc: 0.9082\n",
      "Epoch 025 | Train Loss: 0.1789 Acc: 0.9349 | Val Loss: 0.2567 Acc: 0.8871\n",
      "Epoch 026 | Train Loss: 0.1648 Acc: 0.9385 | Val Loss: 0.2147 Acc: 0.9203\n",
      "Epoch 027 | Train Loss: 0.1500 Acc: 0.9396 | Val Loss: 0.1777 Acc: 0.9281\n",
      "Epoch 028 | Train Loss: 0.1515 Acc: 0.9444 | Val Loss: 0.1798 Acc: 0.9245\n",
      "Epoch 029 | Train Loss: 0.1369 Acc: 0.9456 | Val Loss: 0.1800 Acc: 0.9287\n",
      "Epoch 030 | Train Loss: 0.1354 Acc: 0.9461 | Val Loss: 0.1916 Acc: 0.9251\n",
      "Epoch 031 | Train Loss: 0.1364 Acc: 0.9500 | Val Loss: 0.1718 Acc: 0.9293\n",
      "Epoch 032 | Train Loss: 0.1188 Acc: 0.9532 | Val Loss: 0.1776 Acc: 0.9318\n",
      "Epoch 033 | Train Loss: 0.1167 Acc: 0.9565 | Val Loss: 0.1612 Acc: 0.9432\n",
      "Epoch 034 | Train Loss: 0.1226 Acc: 0.9509 | Val Loss: 0.2270 Acc: 0.9149\n",
      "Epoch 035 | Train Loss: 0.1067 Acc: 0.9592 | Val Loss: 0.1560 Acc: 0.9348\n",
      "Epoch 036 | Train Loss: 0.1117 Acc: 0.9565 | Val Loss: 0.2028 Acc: 0.9257\n",
      "Epoch 037 | Train Loss: 0.1060 Acc: 0.9598 | Val Loss: 0.1642 Acc: 0.9426\n",
      "Epoch 038 | Train Loss: 0.1034 Acc: 0.9616 | Val Loss: 0.1580 Acc: 0.9426\n",
      "Epoch 039 | Train Loss: 0.0958 Acc: 0.9604 | Val Loss: 0.1615 Acc: 0.9408\n",
      "Epoch 040 | Train Loss: 0.0970 Acc: 0.9641 | Val Loss: 0.1634 Acc: 0.9390\n",
      "Epoch 041 | Train Loss: 0.0912 Acc: 0.9665 | Val Loss: 0.1532 Acc: 0.9420\n",
      "Epoch 042 | Train Loss: 0.0813 Acc: 0.9700 | Val Loss: 0.2115 Acc: 0.9287\n",
      "Epoch 043 | Train Loss: 0.0861 Acc: 0.9686 | Val Loss: 0.1783 Acc: 0.9324\n",
      "Epoch 044 | Train Loss: 0.0868 Acc: 0.9678 | Val Loss: 0.1582 Acc: 0.9426\n",
      "Epoch 045 | Train Loss: 0.0798 Acc: 0.9697 | Val Loss: 0.1757 Acc: 0.9408\n",
      "Epoch 046 | Train Loss: 0.0846 Acc: 0.9695 | Val Loss: 0.1833 Acc: 0.9312\n",
      "Epoch 047 | Train Loss: 0.0806 Acc: 0.9689 | Val Loss: 0.1891 Acc: 0.9324\n",
      "Epoch 048 | Train Loss: 0.0767 Acc: 0.9713 | Val Loss: 0.1806 Acc: 0.9420\n",
      "Epoch 049 | Train Loss: 0.0824 Acc: 0.9701 | Val Loss: 0.1773 Acc: 0.9336\n",
      "Epoch 050 | Train Loss: 0.0772 Acc: 0.9728 | Val Loss: 0.1746 Acc: 0.9420\n",
      "Epoch 051 | Train Loss: 0.0722 Acc: 0.9743 | Val Loss: 0.1771 Acc: 0.9481\n",
      "Early stopping triggered.\n",
      "Epoch 001 | Train Loss: 0.6832 Acc: 0.5719 | Val Loss: 0.6752 Acc: 0.5894\n",
      "Epoch 002 | Train Loss: 0.6715 Acc: 0.5898 | Val Loss: 0.6770 Acc: 0.5960\n",
      "Epoch 003 | Train Loss: 0.6564 Acc: 0.6150 | Val Loss: 0.6378 Acc: 0.6492\n",
      "Epoch 004 | Train Loss: 0.5982 Acc: 0.6887 | Val Loss: 0.5779 Acc: 0.6975\n",
      "Epoch 005 | Train Loss: 0.5641 Acc: 0.7243 | Val Loss: 0.5617 Acc: 0.7204\n",
      "Epoch 006 | Train Loss: 0.5442 Acc: 0.7340 | Val Loss: 0.5513 Acc: 0.7174\n",
      "Epoch 007 | Train Loss: 0.5306 Acc: 0.7377 | Val Loss: 0.5556 Acc: 0.7138\n",
      "Epoch 008 | Train Loss: 0.5121 Acc: 0.7542 | Val Loss: 0.5417 Acc: 0.7289\n",
      "Epoch 009 | Train Loss: 0.5004 Acc: 0.7578 | Val Loss: 0.5091 Acc: 0.7524\n",
      "Epoch 010 | Train Loss: 0.4733 Acc: 0.7756 | Val Loss: 0.5028 Acc: 0.7705\n",
      "Epoch 011 | Train Loss: 0.4495 Acc: 0.7913 | Val Loss: 0.4633 Acc: 0.7766\n",
      "Epoch 012 | Train Loss: 0.4281 Acc: 0.8036 | Val Loss: 0.4171 Acc: 0.8062\n",
      "Epoch 013 | Train Loss: 0.4122 Acc: 0.8084 | Val Loss: 0.3950 Acc: 0.8182\n",
      "Epoch 014 | Train Loss: 0.3861 Acc: 0.8258 | Val Loss: 0.3904 Acc: 0.8110\n",
      "Epoch 015 | Train Loss: 0.3548 Acc: 0.8434 | Val Loss: 0.3363 Acc: 0.8557\n",
      "Epoch 016 | Train Loss: 0.3323 Acc: 0.8555 | Val Loss: 0.3095 Acc: 0.8659\n",
      "Epoch 017 | Train Loss: 0.3105 Acc: 0.8686 | Val Loss: 0.2925 Acc: 0.8726\n",
      "Epoch 018 | Train Loss: 0.2959 Acc: 0.8774 | Val Loss: 0.2668 Acc: 0.8889\n",
      "Epoch 019 | Train Loss: 0.2687 Acc: 0.8848 | Val Loss: 0.2687 Acc: 0.8889\n",
      "Epoch 020 | Train Loss: 0.2725 Acc: 0.8860 | Val Loss: 0.2378 Acc: 0.9052\n",
      "Epoch 021 | Train Loss: 0.2419 Acc: 0.9020 | Val Loss: 0.2622 Acc: 0.8913\n",
      "Epoch 022 | Train Loss: 0.2134 Acc: 0.9138 | Val Loss: 0.2162 Acc: 0.9149\n",
      "Epoch 023 | Train Loss: 0.2015 Acc: 0.9194 | Val Loss: 0.2454 Acc: 0.9028\n",
      "Epoch 024 | Train Loss: 0.2055 Acc: 0.9162 | Val Loss: 0.2190 Acc: 0.9046\n",
      "Epoch 025 | Train Loss: 0.1899 Acc: 0.9265 | Val Loss: 0.2370 Acc: 0.9010\n",
      "Epoch 026 | Train Loss: 0.1751 Acc: 0.9311 | Val Loss: 0.1899 Acc: 0.9227\n",
      "Epoch 027 | Train Loss: 0.1853 Acc: 0.9265 | Val Loss: 0.2090 Acc: 0.9161\n",
      "Epoch 028 | Train Loss: 0.1729 Acc: 0.9325 | Val Loss: 0.2033 Acc: 0.9191\n",
      "Epoch 029 | Train Loss: 0.1547 Acc: 0.9396 | Val Loss: 0.1920 Acc: 0.9269\n",
      "Epoch 030 | Train Loss: 0.1569 Acc: 0.9384 | Val Loss: 0.1741 Acc: 0.9342\n",
      "Epoch 031 | Train Loss: 0.1411 Acc: 0.9432 | Val Loss: 0.2094 Acc: 0.9209\n",
      "Epoch 032 | Train Loss: 0.1370 Acc: 0.9465 | Val Loss: 0.1614 Acc: 0.9444\n",
      "Epoch 033 | Train Loss: 0.1295 Acc: 0.9473 | Val Loss: 0.1587 Acc: 0.9402\n",
      "Epoch 034 | Train Loss: 0.1206 Acc: 0.9530 | Val Loss: 0.1724 Acc: 0.9354\n",
      "Epoch 035 | Train Loss: 0.1223 Acc: 0.9553 | Val Loss: 0.1565 Acc: 0.9402\n",
      "Epoch 036 | Train Loss: 0.1157 Acc: 0.9570 | Val Loss: 0.1427 Acc: 0.9505\n",
      "Epoch 037 | Train Loss: 0.1174 Acc: 0.9535 | Val Loss: 0.1694 Acc: 0.9384\n",
      "Epoch 038 | Train Loss: 0.1068 Acc: 0.9598 | Val Loss: 0.1524 Acc: 0.9396\n",
      "Epoch 039 | Train Loss: 0.1053 Acc: 0.9597 | Val Loss: 0.1529 Acc: 0.9469\n",
      "Epoch 040 | Train Loss: 0.1013 Acc: 0.9620 | Val Loss: 0.1652 Acc: 0.9354\n",
      "Epoch 041 | Train Loss: 0.1003 Acc: 0.9626 | Val Loss: 0.1434 Acc: 0.9444\n",
      "Epoch 042 | Train Loss: 0.0942 Acc: 0.9635 | Val Loss: 0.1329 Acc: 0.9487\n",
      "Epoch 043 | Train Loss: 0.1105 Acc: 0.9583 | Val Loss: 0.1547 Acc: 0.9414\n",
      "Epoch 044 | Train Loss: 0.0816 Acc: 0.9703 | Val Loss: 0.1741 Acc: 0.9414\n",
      "Epoch 045 | Train Loss: 0.0958 Acc: 0.9651 | Val Loss: 0.1276 Acc: 0.9499\n",
      "Epoch 046 | Train Loss: 0.0826 Acc: 0.9712 | Val Loss: 0.1319 Acc: 0.9523\n",
      "Epoch 047 | Train Loss: 0.0926 Acc: 0.9653 | Val Loss: 0.1470 Acc: 0.9469\n",
      "Epoch 048 | Train Loss: 0.0798 Acc: 0.9704 | Val Loss: 0.1560 Acc: 0.9457\n",
      "Epoch 049 | Train Loss: 0.0748 Acc: 0.9725 | Val Loss: 0.1788 Acc: 0.9402\n",
      "Epoch 050 | Train Loss: 0.0774 Acc: 0.9687 | Val Loss: 0.1458 Acc: 0.9529\n",
      "Epoch 051 | Train Loss: 0.0773 Acc: 0.9716 | Val Loss: 0.1658 Acc: 0.9475\n",
      "Epoch 052 | Train Loss: 0.0798 Acc: 0.9697 | Val Loss: 0.1577 Acc: 0.9432\n",
      "Epoch 053 | Train Loss: 0.0752 Acc: 0.9718 | Val Loss: 0.1890 Acc: 0.9360\n",
      "Epoch 054 | Train Loss: 0.0753 Acc: 0.9728 | Val Loss: 0.1413 Acc: 0.9553\n",
      "Epoch 055 | Train Loss: 0.0715 Acc: 0.9737 | Val Loss: 0.1711 Acc: 0.9463\n",
      "Early stopping triggered.\n",
      "Epoch 001 | Train Loss: 0.6797 Acc: 0.5795 | Val Loss: 0.6681 Acc: 0.5984\n",
      "Epoch 002 | Train Loss: 0.6587 Acc: 0.6061 | Val Loss: 0.6615 Acc: 0.6008\n",
      "Epoch 003 | Train Loss: 0.6306 Acc: 0.6577 | Val Loss: 0.5950 Acc: 0.6872\n",
      "Epoch 004 | Train Loss: 0.5883 Acc: 0.6923 | Val Loss: 0.5827 Acc: 0.7035\n",
      "Epoch 005 | Train Loss: 0.5545 Acc: 0.7279 | Val Loss: 0.5689 Acc: 0.7065\n",
      "Epoch 006 | Train Loss: 0.5449 Acc: 0.7332 | Val Loss: 0.5376 Acc: 0.7240\n",
      "Epoch 007 | Train Loss: 0.5171 Acc: 0.7497 | Val Loss: 0.5229 Acc: 0.7349\n",
      "Epoch 008 | Train Loss: 0.5052 Acc: 0.7534 | Val Loss: 0.5323 Acc: 0.7301\n",
      "Epoch 009 | Train Loss: 0.4830 Acc: 0.7660 | Val Loss: 0.4891 Acc: 0.7621\n",
      "Epoch 010 | Train Loss: 0.4641 Acc: 0.7771 | Val Loss: 0.4486 Acc: 0.7723\n",
      "Epoch 011 | Train Loss: 0.4381 Acc: 0.7851 | Val Loss: 0.4386 Acc: 0.7814\n",
      "Epoch 012 | Train Loss: 0.4133 Acc: 0.8019 | Val Loss: 0.4307 Acc: 0.7856\n",
      "Epoch 013 | Train Loss: 0.3978 Acc: 0.8155 | Val Loss: 0.4219 Acc: 0.7989\n",
      "Epoch 014 | Train Loss: 0.3952 Acc: 0.8150 | Val Loss: 0.3773 Acc: 0.8321\n",
      "Epoch 015 | Train Loss: 0.3661 Acc: 0.8341 | Val Loss: 0.3807 Acc: 0.8231\n",
      "Epoch 016 | Train Loss: 0.3480 Acc: 0.8490 | Val Loss: 0.3473 Acc: 0.8418\n",
      "Epoch 017 | Train Loss: 0.3476 Acc: 0.8454 | Val Loss: 0.3618 Acc: 0.8376\n",
      "Epoch 018 | Train Loss: 0.3166 Acc: 0.8644 | Val Loss: 0.3227 Acc: 0.8635\n",
      "Epoch 019 | Train Loss: 0.3008 Acc: 0.8659 | Val Loss: 0.3526 Acc: 0.8430\n",
      "Epoch 020 | Train Loss: 0.2998 Acc: 0.8720 | Val Loss: 0.3230 Acc: 0.8599\n",
      "Epoch 021 | Train Loss: 0.2876 Acc: 0.8780 | Val Loss: 0.3017 Acc: 0.8750\n",
      "Epoch 022 | Train Loss: 0.2763 Acc: 0.8825 | Val Loss: 0.2822 Acc: 0.8786\n",
      "Epoch 023 | Train Loss: 0.2630 Acc: 0.8940 | Val Loss: 0.2860 Acc: 0.8744\n",
      "Epoch 024 | Train Loss: 0.2484 Acc: 0.8982 | Val Loss: 0.2719 Acc: 0.8786\n",
      "Epoch 025 | Train Loss: 0.2392 Acc: 0.9025 | Val Loss: 0.2616 Acc: 0.8883\n",
      "Epoch 026 | Train Loss: 0.2223 Acc: 0.9093 | Val Loss: 0.2458 Acc: 0.8986\n",
      "Epoch 027 | Train Loss: 0.2275 Acc: 0.9068 | Val Loss: 0.2566 Acc: 0.9034\n",
      "Epoch 028 | Train Loss: 0.2150 Acc: 0.9157 | Val Loss: 0.2648 Acc: 0.8901\n",
      "Epoch 029 | Train Loss: 0.1930 Acc: 0.9241 | Val Loss: 0.2585 Acc: 0.8943\n",
      "Epoch 030 | Train Loss: 0.2015 Acc: 0.9195 | Val Loss: 0.3007 Acc: 0.8756\n",
      "Epoch 031 | Train Loss: 0.1797 Acc: 0.9242 | Val Loss: 0.2439 Acc: 0.9022\n",
      "Epoch 032 | Train Loss: 0.1703 Acc: 0.9308 | Val Loss: 0.2097 Acc: 0.9143\n",
      "Epoch 033 | Train Loss: 0.1671 Acc: 0.9334 | Val Loss: 0.2160 Acc: 0.9118\n",
      "Epoch 034 | Train Loss: 0.1584 Acc: 0.9387 | Val Loss: 0.2061 Acc: 0.9197\n",
      "Epoch 035 | Train Loss: 0.1662 Acc: 0.9352 | Val Loss: 0.2574 Acc: 0.8919\n",
      "Epoch 036 | Train Loss: 0.1479 Acc: 0.9437 | Val Loss: 0.2235 Acc: 0.9124\n",
      "Epoch 037 | Train Loss: 0.1370 Acc: 0.9481 | Val Loss: 0.2409 Acc: 0.9106\n",
      "Epoch 038 | Train Loss: 0.1422 Acc: 0.9472 | Val Loss: 0.1966 Acc: 0.9161\n",
      "Epoch 039 | Train Loss: 0.1295 Acc: 0.9485 | Val Loss: 0.1852 Acc: 0.9275\n",
      "Epoch 040 | Train Loss: 0.1281 Acc: 0.9487 | Val Loss: 0.2262 Acc: 0.9143\n",
      "Epoch 041 | Train Loss: 0.1141 Acc: 0.9544 | Val Loss: 0.2572 Acc: 0.9076\n",
      "Epoch 042 | Train Loss: 0.1195 Acc: 0.9547 | Val Loss: 0.1999 Acc: 0.9318\n",
      "Epoch 043 | Train Loss: 0.1089 Acc: 0.9589 | Val Loss: 0.2007 Acc: 0.9221\n",
      "Epoch 044 | Train Loss: 0.1178 Acc: 0.9536 | Val Loss: 0.2054 Acc: 0.9281\n",
      "Epoch 045 | Train Loss: 0.1055 Acc: 0.9586 | Val Loss: 0.2097 Acc: 0.9227\n",
      "Epoch 046 | Train Loss: 0.1078 Acc: 0.9588 | Val Loss: 0.1976 Acc: 0.9221\n",
      "Epoch 047 | Train Loss: 0.0937 Acc: 0.9657 | Val Loss: 0.2432 Acc: 0.9112\n",
      "Epoch 048 | Train Loss: 0.1016 Acc: 0.9607 | Val Loss: 0.2108 Acc: 0.9275\n",
      "Epoch 049 | Train Loss: 0.0941 Acc: 0.9636 | Val Loss: 0.2125 Acc: 0.9275\n",
      "Early stopping triggered.\n",
      "Epoch 001 | Train Loss: 0.6776 Acc: 0.5864 | Val Loss: 0.6824 Acc: 0.5707\n",
      "Epoch 002 | Train Loss: 0.6632 Acc: 0.6089 | Val Loss: 0.6545 Acc: 0.6123\n",
      "Epoch 003 | Train Loss: 0.6417 Acc: 0.6363 | Val Loss: 0.6433 Acc: 0.6268\n",
      "Epoch 004 | Train Loss: 0.6007 Acc: 0.6953 | Val Loss: 0.5869 Acc: 0.6993\n",
      "Epoch 005 | Train Loss: 0.5697 Acc: 0.7163 | Val Loss: 0.5876 Acc: 0.6957\n",
      "Epoch 006 | Train Loss: 0.5596 Acc: 0.7240 | Val Loss: 0.5646 Acc: 0.7156\n",
      "Epoch 007 | Train Loss: 0.5492 Acc: 0.7290 | Val Loss: 0.5470 Acc: 0.7228\n",
      "Epoch 008 | Train Loss: 0.5336 Acc: 0.7421 | Val Loss: 0.5287 Acc: 0.7319\n",
      "Epoch 009 | Train Loss: 0.5089 Acc: 0.7521 | Val Loss: 0.5197 Acc: 0.7579\n",
      "Epoch 010 | Train Loss: 0.4901 Acc: 0.7667 | Val Loss: 0.5115 Acc: 0.7421\n",
      "Epoch 011 | Train Loss: 0.4719 Acc: 0.7758 | Val Loss: 0.4843 Acc: 0.7669\n",
      "Epoch 012 | Train Loss: 0.4607 Acc: 0.7867 | Val Loss: 0.4462 Acc: 0.7935\n",
      "Epoch 013 | Train Loss: 0.4431 Acc: 0.7928 | Val Loss: 0.4431 Acc: 0.7844\n",
      "Epoch 014 | Train Loss: 0.4203 Acc: 0.8040 | Val Loss: 0.4249 Acc: 0.7953\n",
      "Epoch 015 | Train Loss: 0.4069 Acc: 0.8135 | Val Loss: 0.4062 Acc: 0.8068\n",
      "Epoch 016 | Train Loss: 0.3947 Acc: 0.8167 | Val Loss: 0.4209 Acc: 0.7959\n",
      "Epoch 017 | Train Loss: 0.3832 Acc: 0.8291 | Val Loss: 0.3789 Acc: 0.8321\n",
      "Epoch 018 | Train Loss: 0.3552 Acc: 0.8396 | Val Loss: 0.3533 Acc: 0.8454\n",
      "Epoch 019 | Train Loss: 0.3363 Acc: 0.8540 | Val Loss: 0.3693 Acc: 0.8321\n",
      "Epoch 020 | Train Loss: 0.3280 Acc: 0.8572 | Val Loss: 0.3236 Acc: 0.8502\n",
      "Epoch 021 | Train Loss: 0.3034 Acc: 0.8745 | Val Loss: 0.2978 Acc: 0.8696\n",
      "Epoch 022 | Train Loss: 0.2970 Acc: 0.8750 | Val Loss: 0.2947 Acc: 0.8810\n",
      "Epoch 023 | Train Loss: 0.2812 Acc: 0.8792 | Val Loss: 0.2787 Acc: 0.8853\n",
      "Epoch 024 | Train Loss: 0.2666 Acc: 0.8875 | Val Loss: 0.2727 Acc: 0.8901\n",
      "Epoch 025 | Train Loss: 0.2530 Acc: 0.8951 | Val Loss: 0.2679 Acc: 0.8841\n",
      "Epoch 026 | Train Loss: 0.2286 Acc: 0.9076 | Val Loss: 0.2580 Acc: 0.8943\n",
      "Epoch 027 | Train Loss: 0.2321 Acc: 0.9023 | Val Loss: 0.2451 Acc: 0.9040\n",
      "Epoch 028 | Train Loss: 0.2087 Acc: 0.9170 | Val Loss: 0.2372 Acc: 0.8967\n",
      "Epoch 029 | Train Loss: 0.2126 Acc: 0.9139 | Val Loss: 0.2235 Acc: 0.9124\n",
      "Epoch 030 | Train Loss: 0.1999 Acc: 0.9206 | Val Loss: 0.2110 Acc: 0.9161\n",
      "Epoch 031 | Train Loss: 0.1909 Acc: 0.9283 | Val Loss: 0.2291 Acc: 0.9124\n",
      "Epoch 032 | Train Loss: 0.1829 Acc: 0.9257 | Val Loss: 0.2330 Acc: 0.9136\n",
      "Epoch 033 | Train Loss: 0.1678 Acc: 0.9345 | Val Loss: 0.2082 Acc: 0.9197\n",
      "Epoch 034 | Train Loss: 0.1695 Acc: 0.9319 | Val Loss: 0.2004 Acc: 0.9287\n",
      "Epoch 035 | Train Loss: 0.1546 Acc: 0.9398 | Val Loss: 0.1951 Acc: 0.9263\n",
      "Epoch 036 | Train Loss: 0.1630 Acc: 0.9387 | Val Loss: 0.2063 Acc: 0.9215\n",
      "Epoch 037 | Train Loss: 0.1587 Acc: 0.9395 | Val Loss: 0.2135 Acc: 0.9167\n",
      "Epoch 038 | Train Loss: 0.1426 Acc: 0.9482 | Val Loss: 0.2220 Acc: 0.9118\n",
      "Epoch 039 | Train Loss: 0.1514 Acc: 0.9399 | Val Loss: 0.2029 Acc: 0.9185\n",
      "Epoch 040 | Train Loss: 0.1325 Acc: 0.9503 | Val Loss: 0.1886 Acc: 0.9245\n",
      "Epoch 041 | Train Loss: 0.1340 Acc: 0.9472 | Val Loss: 0.1921 Acc: 0.9300\n",
      "Epoch 042 | Train Loss: 0.1209 Acc: 0.9559 | Val Loss: 0.2032 Acc: 0.9300\n",
      "Epoch 043 | Train Loss: 0.1280 Acc: 0.9514 | Val Loss: 0.1716 Acc: 0.9354\n",
      "Epoch 044 | Train Loss: 0.1305 Acc: 0.9484 | Val Loss: 0.1903 Acc: 0.9300\n",
      "Epoch 045 | Train Loss: 0.1221 Acc: 0.9535 | Val Loss: 0.1896 Acc: 0.9306\n",
      "Epoch 046 | Train Loss: 0.1095 Acc: 0.9592 | Val Loss: 0.1974 Acc: 0.9287\n",
      "Epoch 047 | Train Loss: 0.1167 Acc: 0.9556 | Val Loss: 0.1786 Acc: 0.9354\n",
      "Epoch 048 | Train Loss: 0.1069 Acc: 0.9579 | Val Loss: 0.1860 Acc: 0.9306\n",
      "Epoch 049 | Train Loss: 0.1093 Acc: 0.9595 | Val Loss: 0.1694 Acc: 0.9372\n",
      "Epoch 050 | Train Loss: 0.0969 Acc: 0.9623 | Val Loss: 0.2063 Acc: 0.9318\n",
      "Epoch 051 | Train Loss: 0.0956 Acc: 0.9644 | Val Loss: 0.1868 Acc: 0.9366\n",
      "Epoch 052 | Train Loss: 0.1076 Acc: 0.9580 | Val Loss: 0.2108 Acc: 0.9245\n",
      "Epoch 053 | Train Loss: 0.0866 Acc: 0.9651 | Val Loss: 0.2734 Acc: 0.9130\n",
      "Epoch 054 | Train Loss: 0.0889 Acc: 0.9677 | Val Loss: 0.1779 Acc: 0.9275\n",
      "Epoch 055 | Train Loss: 0.0894 Acc: 0.9659 | Val Loss: 0.1890 Acc: 0.9269\n",
      "Epoch 056 | Train Loss: 0.0907 Acc: 0.9636 | Val Loss: 0.1627 Acc: 0.9366\n",
      "Epoch 057 | Train Loss: 0.0816 Acc: 0.9686 | Val Loss: 0.1649 Acc: 0.9402\n",
      "Epoch 058 | Train Loss: 0.0844 Acc: 0.9697 | Val Loss: 0.1839 Acc: 0.9354\n",
      "Epoch 059 | Train Loss: 0.0779 Acc: 0.9686 | Val Loss: 0.2586 Acc: 0.9149\n",
      "Epoch 060 | Train Loss: 0.0858 Acc: 0.9686 | Val Loss: 0.1651 Acc: 0.9360\n",
      "Iteration 28/40 | Best Val Loss: 0.1122 | Iter Time: 220.96s | Total Time: 116.12 min\n",
      "Epoch 001 | Train Loss: 0.6813 Acc: 0.5766 | Val Loss: 0.6768 Acc: 0.5839\n",
      "Epoch 002 | Train Loss: 0.6738 Acc: 0.5919 | Val Loss: 0.6736 Acc: 0.5924\n",
      "Epoch 003 | Train Loss: 0.6636 Acc: 0.6008 | Val Loss: 0.6620 Acc: 0.6021\n",
      "Epoch 004 | Train Loss: 0.6428 Acc: 0.6405 | Val Loss: 0.6092 Acc: 0.6600\n",
      "Epoch 005 | Train Loss: 0.5802 Acc: 0.7019 | Val Loss: 0.5810 Acc: 0.7168\n",
      "Epoch 006 | Train Loss: 0.5491 Acc: 0.7314 | Val Loss: 0.5345 Acc: 0.7415\n",
      "Epoch 007 | Train Loss: 0.5244 Acc: 0.7468 | Val Loss: 0.5227 Acc: 0.7452\n",
      "Epoch 008 | Train Loss: 0.5003 Acc: 0.7666 | Val Loss: 0.5068 Acc: 0.7428\n",
      "Epoch 009 | Train Loss: 0.4699 Acc: 0.7827 | Val Loss: 0.4754 Acc: 0.7796\n",
      "Epoch 010 | Train Loss: 0.4562 Acc: 0.7854 | Val Loss: 0.4471 Acc: 0.7711\n",
      "Epoch 011 | Train Loss: 0.4151 Acc: 0.8098 | Val Loss: 0.4222 Acc: 0.7886\n",
      "Epoch 012 | Train Loss: 0.3906 Acc: 0.8203 | Val Loss: 0.3971 Acc: 0.8019\n",
      "Epoch 013 | Train Loss: 0.3739 Acc: 0.8354 | Val Loss: 0.3732 Acc: 0.8176\n",
      "Epoch 014 | Train Loss: 0.3343 Acc: 0.8531 | Val Loss: 0.3344 Acc: 0.8436\n",
      "Epoch 015 | Train Loss: 0.3183 Acc: 0.8626 | Val Loss: 0.3196 Acc: 0.8569\n",
      "Epoch 016 | Train Loss: 0.2867 Acc: 0.8769 | Val Loss: 0.3167 Acc: 0.8641\n",
      "Epoch 017 | Train Loss: 0.2693 Acc: 0.8883 | Val Loss: 0.2864 Acc: 0.8738\n",
      "Epoch 018 | Train Loss: 0.2453 Acc: 0.8981 | Val Loss: 0.2478 Acc: 0.8955\n",
      "Epoch 019 | Train Loss: 0.2304 Acc: 0.9082 | Val Loss: 0.2308 Acc: 0.9076\n",
      "Epoch 020 | Train Loss: 0.2180 Acc: 0.9142 | Val Loss: 0.2518 Acc: 0.8992\n",
      "Epoch 021 | Train Loss: 0.1897 Acc: 0.9242 | Val Loss: 0.2383 Acc: 0.9124\n",
      "Epoch 022 | Train Loss: 0.1831 Acc: 0.9289 | Val Loss: 0.2110 Acc: 0.9064\n",
      "Epoch 023 | Train Loss: 0.1696 Acc: 0.9352 | Val Loss: 0.2125 Acc: 0.9209\n",
      "Epoch 024 | Train Loss: 0.1812 Acc: 0.9318 | Val Loss: 0.2028 Acc: 0.9136\n",
      "Epoch 025 | Train Loss: 0.1532 Acc: 0.9401 | Val Loss: 0.2015 Acc: 0.9118\n",
      "Epoch 026 | Train Loss: 0.1517 Acc: 0.9426 | Val Loss: 0.2295 Acc: 0.9191\n",
      "Epoch 027 | Train Loss: 0.1404 Acc: 0.9464 | Val Loss: 0.1908 Acc: 0.9227\n",
      "Epoch 028 | Train Loss: 0.1292 Acc: 0.9521 | Val Loss: 0.2232 Acc: 0.9221\n",
      "Epoch 029 | Train Loss: 0.1256 Acc: 0.9490 | Val Loss: 0.1820 Acc: 0.9263\n",
      "Epoch 030 | Train Loss: 0.1236 Acc: 0.9521 | Val Loss: 0.2082 Acc: 0.9257\n",
      "Epoch 031 | Train Loss: 0.1189 Acc: 0.9512 | Val Loss: 0.1540 Acc: 0.9426\n",
      "Epoch 032 | Train Loss: 0.1136 Acc: 0.9564 | Val Loss: 0.1977 Acc: 0.9263\n",
      "Epoch 033 | Train Loss: 0.1085 Acc: 0.9568 | Val Loss: 0.1556 Acc: 0.9390\n",
      "Epoch 034 | Train Loss: 0.1015 Acc: 0.9621 | Val Loss: 0.1700 Acc: 0.9366\n",
      "Epoch 035 | Train Loss: 0.1018 Acc: 0.9629 | Val Loss: 0.1416 Acc: 0.9463\n",
      "Epoch 036 | Train Loss: 0.0876 Acc: 0.9671 | Val Loss: 0.1528 Acc: 0.9414\n",
      "Epoch 037 | Train Loss: 0.0951 Acc: 0.9635 | Val Loss: 0.1731 Acc: 0.9324\n",
      "Epoch 038 | Train Loss: 0.0890 Acc: 0.9689 | Val Loss: 0.1749 Acc: 0.9306\n",
      "Epoch 039 | Train Loss: 0.0902 Acc: 0.9660 | Val Loss: 0.1761 Acc: 0.9372\n",
      "Epoch 040 | Train Loss: 0.0847 Acc: 0.9690 | Val Loss: 0.1515 Acc: 0.9469\n",
      "Epoch 041 | Train Loss: 0.0816 Acc: 0.9689 | Val Loss: 0.1453 Acc: 0.9450\n",
      "Epoch 042 | Train Loss: 0.0808 Acc: 0.9707 | Val Loss: 0.1561 Acc: 0.9499\n",
      "Epoch 043 | Train Loss: 0.0894 Acc: 0.9672 | Val Loss: 0.1700 Acc: 0.9336\n",
      "Epoch 044 | Train Loss: 0.0710 Acc: 0.9746 | Val Loss: 0.1582 Acc: 0.9450\n",
      "Epoch 045 | Train Loss: 0.0691 Acc: 0.9751 | Val Loss: 0.1442 Acc: 0.9487\n",
      "Early stopping triggered.\n",
      "Epoch 001 | Train Loss: 0.6799 Acc: 0.5765 | Val Loss: 0.6764 Acc: 0.5821\n",
      "Epoch 002 | Train Loss: 0.6657 Acc: 0.6108 | Val Loss: 0.6675 Acc: 0.5960\n",
      "Epoch 003 | Train Loss: 0.6470 Acc: 0.6355 | Val Loss: 0.6304 Acc: 0.6564\n",
      "Epoch 004 | Train Loss: 0.6211 Acc: 0.6711 | Val Loss: 0.5969 Acc: 0.6775\n",
      "Epoch 005 | Train Loss: 0.5843 Acc: 0.7078 | Val Loss: 0.5724 Acc: 0.6981\n",
      "Epoch 006 | Train Loss: 0.5521 Acc: 0.7246 | Val Loss: 0.5568 Acc: 0.7156\n",
      "Epoch 007 | Train Loss: 0.5360 Acc: 0.7403 | Val Loss: 0.5240 Acc: 0.7367\n",
      "Epoch 008 | Train Loss: 0.5184 Acc: 0.7491 | Val Loss: 0.5206 Acc: 0.7361\n",
      "Epoch 009 | Train Loss: 0.4884 Acc: 0.7682 | Val Loss: 0.4769 Acc: 0.7681\n",
      "Epoch 010 | Train Loss: 0.4727 Acc: 0.7741 | Val Loss: 0.4696 Acc: 0.7790\n",
      "Epoch 011 | Train Loss: 0.4432 Acc: 0.7850 | Val Loss: 0.4431 Acc: 0.7790\n",
      "Epoch 012 | Train Loss: 0.4067 Acc: 0.8152 | Val Loss: 0.4008 Acc: 0.8056\n",
      "Epoch 013 | Train Loss: 0.3878 Acc: 0.8191 | Val Loss: 0.3986 Acc: 0.8225\n",
      "Epoch 014 | Train Loss: 0.3515 Acc: 0.8374 | Val Loss: 0.3900 Acc: 0.8152\n",
      "Epoch 015 | Train Loss: 0.3254 Acc: 0.8578 | Val Loss: 0.3317 Acc: 0.8484\n",
      "Epoch 016 | Train Loss: 0.2973 Acc: 0.8730 | Val Loss: 0.3362 Acc: 0.8557\n",
      "Epoch 017 | Train Loss: 0.2830 Acc: 0.8815 | Val Loss: 0.2970 Acc: 0.8750\n",
      "Epoch 018 | Train Loss: 0.2621 Acc: 0.8896 | Val Loss: 0.2936 Acc: 0.8762\n",
      "Epoch 019 | Train Loss: 0.2483 Acc: 0.8957 | Val Loss: 0.3122 Acc: 0.8756\n",
      "Epoch 020 | Train Loss: 0.2271 Acc: 0.9064 | Val Loss: 0.3480 Acc: 0.8527\n",
      "Epoch 021 | Train Loss: 0.2001 Acc: 0.9164 | Val Loss: 0.2450 Acc: 0.9022\n",
      "Epoch 022 | Train Loss: 0.1892 Acc: 0.9256 | Val Loss: 0.2439 Acc: 0.9022\n",
      "Epoch 023 | Train Loss: 0.1798 Acc: 0.9287 | Val Loss: 0.2731 Acc: 0.8877\n",
      "Epoch 024 | Train Loss: 0.1622 Acc: 0.9360 | Val Loss: 0.2464 Acc: 0.9064\n",
      "Epoch 025 | Train Loss: 0.1627 Acc: 0.9408 | Val Loss: 0.2207 Acc: 0.9143\n",
      "Epoch 026 | Train Loss: 0.1416 Acc: 0.9449 | Val Loss: 0.2381 Acc: 0.9010\n",
      "Epoch 027 | Train Loss: 0.1324 Acc: 0.9478 | Val Loss: 0.2448 Acc: 0.9094\n",
      "Epoch 028 | Train Loss: 0.1351 Acc: 0.9472 | Val Loss: 0.2039 Acc: 0.9239\n",
      "Epoch 029 | Train Loss: 0.1249 Acc: 0.9527 | Val Loss: 0.2591 Acc: 0.9004\n",
      "Epoch 030 | Train Loss: 0.1159 Acc: 0.9550 | Val Loss: 0.2026 Acc: 0.9191\n",
      "Epoch 031 | Train Loss: 0.1082 Acc: 0.9586 | Val Loss: 0.2294 Acc: 0.9245\n",
      "Epoch 032 | Train Loss: 0.1137 Acc: 0.9539 | Val Loss: 0.2222 Acc: 0.9269\n",
      "Epoch 033 | Train Loss: 0.1056 Acc: 0.9597 | Val Loss: 0.1815 Acc: 0.9287\n",
      "Epoch 034 | Train Loss: 0.0991 Acc: 0.9639 | Val Loss: 0.2040 Acc: 0.9269\n",
      "Epoch 035 | Train Loss: 0.0944 Acc: 0.9654 | Val Loss: 0.2105 Acc: 0.9318\n",
      "Epoch 036 | Train Loss: 0.0837 Acc: 0.9698 | Val Loss: 0.1946 Acc: 0.9324\n",
      "Epoch 037 | Train Loss: 0.0895 Acc: 0.9659 | Val Loss: 0.2597 Acc: 0.9070\n",
      "Epoch 038 | Train Loss: 0.1002 Acc: 0.9629 | Val Loss: 0.1775 Acc: 0.9390\n",
      "Epoch 039 | Train Loss: 0.0789 Acc: 0.9700 | Val Loss: 0.1738 Acc: 0.9366\n",
      "Epoch 040 | Train Loss: 0.0826 Acc: 0.9689 | Val Loss: 0.2057 Acc: 0.9306\n",
      "Epoch 041 | Train Loss: 0.0725 Acc: 0.9737 | Val Loss: 0.1773 Acc: 0.9378\n",
      "Epoch 042 | Train Loss: 0.0688 Acc: 0.9754 | Val Loss: 0.2004 Acc: 0.9366\n",
      "Epoch 043 | Train Loss: 0.0689 Acc: 0.9767 | Val Loss: 0.2571 Acc: 0.9149\n",
      "Epoch 044 | Train Loss: 0.0663 Acc: 0.9748 | Val Loss: 0.2785 Acc: 0.9161\n",
      "Epoch 045 | Train Loss: 0.0738 Acc: 0.9725 | Val Loss: 0.1805 Acc: 0.9402\n",
      "Epoch 046 | Train Loss: 0.0573 Acc: 0.9802 | Val Loss: 0.2378 Acc: 0.9275\n",
      "Epoch 047 | Train Loss: 0.0579 Acc: 0.9802 | Val Loss: 0.2117 Acc: 0.9354\n",
      "Epoch 048 | Train Loss: 0.0621 Acc: 0.9781 | Val Loss: 0.2160 Acc: 0.9324\n",
      "Epoch 049 | Train Loss: 0.0500 Acc: 0.9822 | Val Loss: 0.2198 Acc: 0.9287\n",
      "Early stopping triggered.\n",
      "Epoch 001 | Train Loss: 0.6795 Acc: 0.5784 | Val Loss: 0.6749 Acc: 0.5803\n",
      "Epoch 002 | Train Loss: 0.6679 Acc: 0.6005 | Val Loss: 0.6580 Acc: 0.6045\n",
      "Epoch 003 | Train Loss: 0.6470 Acc: 0.6314 | Val Loss: 0.6159 Acc: 0.6721\n",
      "Epoch 004 | Train Loss: 0.6178 Acc: 0.6779 | Val Loss: 0.6097 Acc: 0.6818\n",
      "Epoch 005 | Train Loss: 0.5782 Acc: 0.7115 | Val Loss: 0.5652 Acc: 0.7017\n",
      "Epoch 006 | Train Loss: 0.5580 Acc: 0.7225 | Val Loss: 0.5671 Acc: 0.7138\n",
      "Epoch 007 | Train Loss: 0.5351 Acc: 0.7382 | Val Loss: 0.5309 Acc: 0.7319\n",
      "Epoch 008 | Train Loss: 0.5106 Acc: 0.7555 | Val Loss: 0.5588 Acc: 0.7168\n",
      "Epoch 009 | Train Loss: 0.5000 Acc: 0.7613 | Val Loss: 0.5078 Acc: 0.7488\n",
      "Epoch 010 | Train Loss: 0.4747 Acc: 0.7700 | Val Loss: 0.4692 Acc: 0.7832\n",
      "Epoch 011 | Train Loss: 0.4530 Acc: 0.7873 | Val Loss: 0.4667 Acc: 0.7778\n",
      "Epoch 012 | Train Loss: 0.4387 Acc: 0.7965 | Val Loss: 0.4300 Acc: 0.7923\n",
      "Epoch 013 | Train Loss: 0.4261 Acc: 0.8011 | Val Loss: 0.4098 Acc: 0.8056\n",
      "Epoch 014 | Train Loss: 0.3991 Acc: 0.8224 | Val Loss: 0.3909 Acc: 0.8243\n",
      "Epoch 015 | Train Loss: 0.3853 Acc: 0.8324 | Val Loss: 0.3730 Acc: 0.8315\n",
      "Epoch 016 | Train Loss: 0.3559 Acc: 0.8430 | Val Loss: 0.3533 Acc: 0.8388\n",
      "Epoch 017 | Train Loss: 0.3440 Acc: 0.8496 | Val Loss: 0.3326 Acc: 0.8521\n",
      "Epoch 018 | Train Loss: 0.3364 Acc: 0.8534 | Val Loss: 0.3187 Acc: 0.8575\n",
      "Epoch 019 | Train Loss: 0.3055 Acc: 0.8724 | Val Loss: 0.3392 Acc: 0.8575\n",
      "Epoch 020 | Train Loss: 0.2907 Acc: 0.8751 | Val Loss: 0.3692 Acc: 0.8394\n",
      "Epoch 021 | Train Loss: 0.2819 Acc: 0.8792 | Val Loss: 0.2959 Acc: 0.8750\n",
      "Epoch 022 | Train Loss: 0.2661 Acc: 0.8872 | Val Loss: 0.3056 Acc: 0.8708\n",
      "Epoch 023 | Train Loss: 0.2626 Acc: 0.8895 | Val Loss: 0.3231 Acc: 0.8599\n",
      "Epoch 024 | Train Loss: 0.2394 Acc: 0.9023 | Val Loss: 0.2970 Acc: 0.8641\n",
      "Epoch 025 | Train Loss: 0.2314 Acc: 0.9074 | Val Loss: 0.2523 Acc: 0.8883\n",
      "Epoch 026 | Train Loss: 0.2244 Acc: 0.9120 | Val Loss: 0.2336 Acc: 0.9058\n",
      "Epoch 027 | Train Loss: 0.2076 Acc: 0.9156 | Val Loss: 0.2425 Acc: 0.9022\n",
      "Epoch 028 | Train Loss: 0.2046 Acc: 0.9182 | Val Loss: 0.2411 Acc: 0.8998\n",
      "Epoch 029 | Train Loss: 0.1867 Acc: 0.9257 | Val Loss: 0.2303 Acc: 0.9010\n",
      "Epoch 030 | Train Loss: 0.1983 Acc: 0.9176 | Val Loss: 0.2249 Acc: 0.9076\n",
      "Epoch 031 | Train Loss: 0.1789 Acc: 0.9328 | Val Loss: 0.2243 Acc: 0.9130\n",
      "Epoch 032 | Train Loss: 0.1771 Acc: 0.9262 | Val Loss: 0.2017 Acc: 0.9179\n",
      "Epoch 033 | Train Loss: 0.1724 Acc: 0.9334 | Val Loss: 0.2282 Acc: 0.9203\n",
      "Epoch 034 | Train Loss: 0.1601 Acc: 0.9354 | Val Loss: 0.1993 Acc: 0.9185\n",
      "Epoch 035 | Train Loss: 0.1690 Acc: 0.9295 | Val Loss: 0.1932 Acc: 0.9185\n",
      "Epoch 036 | Train Loss: 0.1472 Acc: 0.9465 | Val Loss: 0.2186 Acc: 0.9118\n",
      "Epoch 037 | Train Loss: 0.1462 Acc: 0.9408 | Val Loss: 0.1787 Acc: 0.9318\n",
      "Epoch 038 | Train Loss: 0.1385 Acc: 0.9487 | Val Loss: 0.2185 Acc: 0.9173\n",
      "Epoch 039 | Train Loss: 0.1465 Acc: 0.9411 | Val Loss: 0.2027 Acc: 0.9227\n",
      "Epoch 040 | Train Loss: 0.1356 Acc: 0.9496 | Val Loss: 0.2113 Acc: 0.9149\n",
      "Epoch 041 | Train Loss: 0.1333 Acc: 0.9503 | Val Loss: 0.1613 Acc: 0.9384\n",
      "Epoch 042 | Train Loss: 0.1403 Acc: 0.9478 | Val Loss: 0.1712 Acc: 0.9306\n",
      "Epoch 043 | Train Loss: 0.1173 Acc: 0.9561 | Val Loss: 0.1879 Acc: 0.9263\n",
      "Epoch 044 | Train Loss: 0.1203 Acc: 0.9549 | Val Loss: 0.1812 Acc: 0.9306\n",
      "Epoch 045 | Train Loss: 0.1268 Acc: 0.9484 | Val Loss: 0.1682 Acc: 0.9402\n",
      "Epoch 046 | Train Loss: 0.1253 Acc: 0.9527 | Val Loss: 0.1991 Acc: 0.9245\n",
      "Epoch 047 | Train Loss: 0.1091 Acc: 0.9574 | Val Loss: 0.1586 Acc: 0.9372\n",
      "Epoch 048 | Train Loss: 0.1092 Acc: 0.9603 | Val Loss: 0.1851 Acc: 0.9330\n",
      "Epoch 049 | Train Loss: 0.1045 Acc: 0.9594 | Val Loss: 0.1727 Acc: 0.9354\n",
      "Epoch 050 | Train Loss: 0.1038 Acc: 0.9582 | Val Loss: 0.1768 Acc: 0.9330\n",
      "Epoch 051 | Train Loss: 0.1013 Acc: 0.9609 | Val Loss: 0.1694 Acc: 0.9426\n",
      "Epoch 052 | Train Loss: 0.1046 Acc: 0.9610 | Val Loss: 0.1726 Acc: 0.9330\n",
      "Epoch 053 | Train Loss: 0.1009 Acc: 0.9626 | Val Loss: 0.1735 Acc: 0.9396\n",
      "Epoch 054 | Train Loss: 0.0920 Acc: 0.9645 | Val Loss: 0.1700 Acc: 0.9348\n",
      "Epoch 055 | Train Loss: 0.1111 Acc: 0.9552 | Val Loss: 0.1831 Acc: 0.9348\n",
      "Epoch 056 | Train Loss: 0.0925 Acc: 0.9663 | Val Loss: 0.1609 Acc: 0.9396\n",
      "Epoch 057 | Train Loss: 0.1005 Acc: 0.9616 | Val Loss: 0.1467 Acc: 0.9523\n",
      "Epoch 058 | Train Loss: 0.0830 Acc: 0.9695 | Val Loss: 0.1497 Acc: 0.9444\n",
      "Epoch 059 | Train Loss: 0.0899 Acc: 0.9656 | Val Loss: 0.1582 Acc: 0.9408\n",
      "Epoch 060 | Train Loss: 0.0970 Acc: 0.9641 | Val Loss: 0.1665 Acc: 0.9378\n",
      "Epoch 001 | Train Loss: 0.6801 Acc: 0.5777 | Val Loss: 0.6760 Acc: 0.5870\n",
      "Epoch 002 | Train Loss: 0.6754 Acc: 0.5889 | Val Loss: 0.6697 Acc: 0.5972\n",
      "Epoch 003 | Train Loss: 0.6667 Acc: 0.5972 | Val Loss: 0.6585 Acc: 0.6063\n",
      "Epoch 004 | Train Loss: 0.6511 Acc: 0.6252 | Val Loss: 0.6298 Acc: 0.6769\n",
      "Epoch 005 | Train Loss: 0.6056 Acc: 0.6844 | Val Loss: 0.5830 Acc: 0.6969\n",
      "Epoch 006 | Train Loss: 0.5750 Acc: 0.7152 | Val Loss: 0.5972 Acc: 0.6860\n",
      "Epoch 007 | Train Loss: 0.5592 Acc: 0.7244 | Val Loss: 0.5575 Acc: 0.7180\n",
      "Epoch 008 | Train Loss: 0.5351 Acc: 0.7445 | Val Loss: 0.5277 Acc: 0.7355\n",
      "Epoch 009 | Train Loss: 0.5123 Acc: 0.7509 | Val Loss: 0.5114 Acc: 0.7494\n",
      "Epoch 010 | Train Loss: 0.4998 Acc: 0.7601 | Val Loss: 0.4943 Acc: 0.7627\n",
      "Epoch 011 | Train Loss: 0.4717 Acc: 0.7851 | Val Loss: 0.4776 Acc: 0.7675\n",
      "Epoch 012 | Train Loss: 0.4549 Acc: 0.7897 | Val Loss: 0.4581 Acc: 0.7681\n",
      "Epoch 013 | Train Loss: 0.4345 Acc: 0.8025 | Val Loss: 0.4261 Acc: 0.7874\n",
      "Epoch 014 | Train Loss: 0.4106 Acc: 0.8175 | Val Loss: 0.4096 Acc: 0.8128\n",
      "Epoch 015 | Train Loss: 0.4111 Acc: 0.8138 | Val Loss: 0.4249 Acc: 0.7886\n",
      "Epoch 016 | Train Loss: 0.3854 Acc: 0.8265 | Val Loss: 0.4065 Acc: 0.7995\n",
      "Epoch 017 | Train Loss: 0.3650 Acc: 0.8407 | Val Loss: 0.3865 Acc: 0.8164\n",
      "Epoch 018 | Train Loss: 0.3470 Acc: 0.8504 | Val Loss: 0.3621 Acc: 0.8351\n",
      "Epoch 019 | Train Loss: 0.3183 Acc: 0.8662 | Val Loss: 0.3362 Acc: 0.8521\n",
      "Epoch 020 | Train Loss: 0.3191 Acc: 0.8638 | Val Loss: 0.3254 Acc: 0.8575\n",
      "Epoch 021 | Train Loss: 0.2968 Acc: 0.8827 | Val Loss: 0.3019 Acc: 0.8720\n",
      "Epoch 022 | Train Loss: 0.2617 Acc: 0.8958 | Val Loss: 0.2969 Acc: 0.8684\n",
      "Epoch 023 | Train Loss: 0.2659 Acc: 0.8913 | Val Loss: 0.3069 Acc: 0.8653\n",
      "Epoch 024 | Train Loss: 0.2521 Acc: 0.8976 | Val Loss: 0.2604 Acc: 0.8973\n",
      "Epoch 025 | Train Loss: 0.2395 Acc: 0.9085 | Val Loss: 0.2650 Acc: 0.8829\n",
      "Epoch 026 | Train Loss: 0.2237 Acc: 0.9138 | Val Loss: 0.2332 Acc: 0.9052\n",
      "Epoch 027 | Train Loss: 0.2084 Acc: 0.9194 | Val Loss: 0.2322 Acc: 0.9040\n",
      "Epoch 028 | Train Loss: 0.2184 Acc: 0.9162 | Val Loss: 0.2091 Acc: 0.9209\n",
      "Epoch 029 | Train Loss: 0.1947 Acc: 0.9292 | Val Loss: 0.2335 Acc: 0.9088\n",
      "Epoch 030 | Train Loss: 0.1918 Acc: 0.9256 | Val Loss: 0.2135 Acc: 0.9209\n",
      "Epoch 031 | Train Loss: 0.1778 Acc: 0.9357 | Val Loss: 0.2138 Acc: 0.9118\n",
      "Epoch 032 | Train Loss: 0.1780 Acc: 0.9298 | Val Loss: 0.2123 Acc: 0.9221\n",
      "Epoch 033 | Train Loss: 0.1607 Acc: 0.9373 | Val Loss: 0.2022 Acc: 0.9251\n",
      "Epoch 034 | Train Loss: 0.1523 Acc: 0.9405 | Val Loss: 0.1969 Acc: 0.9209\n",
      "Epoch 035 | Train Loss: 0.1556 Acc: 0.9413 | Val Loss: 0.2190 Acc: 0.9161\n",
      "Epoch 036 | Train Loss: 0.1506 Acc: 0.9426 | Val Loss: 0.1957 Acc: 0.9293\n",
      "Epoch 037 | Train Loss: 0.1528 Acc: 0.9440 | Val Loss: 0.1843 Acc: 0.9330\n",
      "Epoch 038 | Train Loss: 0.1325 Acc: 0.9487 | Val Loss: 0.1751 Acc: 0.9342\n",
      "Epoch 039 | Train Loss: 0.1287 Acc: 0.9517 | Val Loss: 0.1888 Acc: 0.9275\n",
      "Epoch 040 | Train Loss: 0.1230 Acc: 0.9523 | Val Loss: 0.1955 Acc: 0.9324\n",
      "Epoch 041 | Train Loss: 0.1253 Acc: 0.9532 | Val Loss: 0.1854 Acc: 0.9281\n",
      "Epoch 042 | Train Loss: 0.1238 Acc: 0.9549 | Val Loss: 0.1764 Acc: 0.9293\n",
      "Epoch 043 | Train Loss: 0.1205 Acc: 0.9529 | Val Loss: 0.2196 Acc: 0.9233\n",
      "Epoch 044 | Train Loss: 0.1153 Acc: 0.9595 | Val Loss: 0.2281 Acc: 0.9124\n",
      "Epoch 045 | Train Loss: 0.1051 Acc: 0.9604 | Val Loss: 0.1608 Acc: 0.9444\n",
      "Epoch 046 | Train Loss: 0.1028 Acc: 0.9647 | Val Loss: 0.2089 Acc: 0.9251\n",
      "Epoch 047 | Train Loss: 0.1056 Acc: 0.9618 | Val Loss: 0.1721 Acc: 0.9372\n",
      "Epoch 048 | Train Loss: 0.1036 Acc: 0.9607 | Val Loss: 0.1723 Acc: 0.9414\n",
      "Epoch 049 | Train Loss: 0.0969 Acc: 0.9639 | Val Loss: 0.1973 Acc: 0.9366\n",
      "Epoch 050 | Train Loss: 0.0913 Acc: 0.9675 | Val Loss: 0.1884 Acc: 0.9251\n",
      "Epoch 051 | Train Loss: 0.0899 Acc: 0.9678 | Val Loss: 0.1968 Acc: 0.9336\n",
      "Epoch 052 | Train Loss: 0.0882 Acc: 0.9686 | Val Loss: 0.1601 Acc: 0.9420\n",
      "Epoch 053 | Train Loss: 0.0956 Acc: 0.9644 | Val Loss: 0.1616 Acc: 0.9475\n",
      "Epoch 054 | Train Loss: 0.0812 Acc: 0.9692 | Val Loss: 0.2386 Acc: 0.9245\n",
      "Epoch 055 | Train Loss: 0.0825 Acc: 0.9719 | Val Loss: 0.1496 Acc: 0.9481\n",
      "Epoch 056 | Train Loss: 0.0842 Acc: 0.9687 | Val Loss: 0.2042 Acc: 0.9245\n",
      "Epoch 057 | Train Loss: 0.0898 Acc: 0.9687 | Val Loss: 0.1754 Acc: 0.9366\n",
      "Epoch 058 | Train Loss: 0.0871 Acc: 0.9703 | Val Loss: 0.1525 Acc: 0.9499\n",
      "Epoch 059 | Train Loss: 0.0807 Acc: 0.9736 | Val Loss: 0.1780 Acc: 0.9354\n",
      "Epoch 060 | Train Loss: 0.0809 Acc: 0.9686 | Val Loss: 0.1645 Acc: 0.9432\n",
      "Epoch 001 | Train Loss: 0.6808 Acc: 0.5759 | Val Loss: 0.6777 Acc: 0.5809\n",
      "Epoch 002 | Train Loss: 0.6713 Acc: 0.5947 | Val Loss: 0.6655 Acc: 0.6057\n",
      "Epoch 003 | Train Loss: 0.6484 Acc: 0.6313 | Val Loss: 0.6441 Acc: 0.6329\n",
      "Epoch 004 | Train Loss: 0.6065 Acc: 0.6865 | Val Loss: 0.5904 Acc: 0.7011\n",
      "Epoch 005 | Train Loss: 0.5669 Acc: 0.7177 | Val Loss: 0.5687 Acc: 0.7083\n",
      "Epoch 006 | Train Loss: 0.5542 Acc: 0.7235 | Val Loss: 0.5512 Acc: 0.7258\n",
      "Epoch 007 | Train Loss: 0.5478 Acc: 0.7264 | Val Loss: 0.5440 Acc: 0.7252\n",
      "Epoch 008 | Train Loss: 0.5267 Acc: 0.7412 | Val Loss: 0.5409 Acc: 0.7343\n",
      "Epoch 009 | Train Loss: 0.5093 Acc: 0.7549 | Val Loss: 0.5178 Acc: 0.7409\n",
      "Epoch 010 | Train Loss: 0.4921 Acc: 0.7628 | Val Loss: 0.5001 Acc: 0.7512\n",
      "Epoch 011 | Train Loss: 0.4799 Acc: 0.7722 | Val Loss: 0.5010 Acc: 0.7470\n",
      "Epoch 012 | Train Loss: 0.4545 Acc: 0.7885 | Val Loss: 0.4681 Acc: 0.7820\n",
      "Epoch 013 | Train Loss: 0.4405 Acc: 0.7975 | Val Loss: 0.4462 Acc: 0.7947\n",
      "Epoch 014 | Train Loss: 0.4258 Acc: 0.8013 | Val Loss: 0.4376 Acc: 0.7977\n",
      "Epoch 015 | Train Loss: 0.4069 Acc: 0.8178 | Val Loss: 0.4197 Acc: 0.7917\n",
      "Epoch 016 | Train Loss: 0.3959 Acc: 0.8178 | Val Loss: 0.4092 Acc: 0.7953\n",
      "Epoch 017 | Train Loss: 0.3800 Acc: 0.8298 | Val Loss: 0.3896 Acc: 0.8207\n",
      "Epoch 018 | Train Loss: 0.3589 Acc: 0.8396 | Val Loss: 0.3657 Acc: 0.8382\n",
      "Epoch 019 | Train Loss: 0.3481 Acc: 0.8480 | Val Loss: 0.3865 Acc: 0.8200\n",
      "Epoch 020 | Train Loss: 0.3363 Acc: 0.8499 | Val Loss: 0.3289 Acc: 0.8551\n",
      "Epoch 021 | Train Loss: 0.3190 Acc: 0.8637 | Val Loss: 0.3282 Acc: 0.8539\n",
      "Epoch 022 | Train Loss: 0.3032 Acc: 0.8694 | Val Loss: 0.3485 Acc: 0.8490\n",
      "Epoch 023 | Train Loss: 0.2920 Acc: 0.8774 | Val Loss: 0.3081 Acc: 0.8581\n",
      "Epoch 024 | Train Loss: 0.2719 Acc: 0.8836 | Val Loss: 0.2812 Acc: 0.8738\n",
      "Epoch 025 | Train Loss: 0.2627 Acc: 0.8883 | Val Loss: 0.2639 Acc: 0.8901\n",
      "Epoch 026 | Train Loss: 0.2547 Acc: 0.8910 | Val Loss: 0.2688 Acc: 0.8847\n",
      "Epoch 027 | Train Loss: 0.2394 Acc: 0.9025 | Val Loss: 0.2649 Acc: 0.8877\n",
      "Epoch 028 | Train Loss: 0.2389 Acc: 0.9037 | Val Loss: 0.2452 Acc: 0.9022\n",
      "Epoch 029 | Train Loss: 0.2180 Acc: 0.9093 | Val Loss: 0.2437 Acc: 0.9010\n",
      "Epoch 030 | Train Loss: 0.2205 Acc: 0.9093 | Val Loss: 0.2426 Acc: 0.8998\n",
      "Epoch 031 | Train Loss: 0.2043 Acc: 0.9171 | Val Loss: 0.2278 Acc: 0.9094\n",
      "Epoch 032 | Train Loss: 0.1994 Acc: 0.9210 | Val Loss: 0.2228 Acc: 0.9155\n",
      "Epoch 033 | Train Loss: 0.1848 Acc: 0.9244 | Val Loss: 0.3027 Acc: 0.8822\n",
      "Epoch 034 | Train Loss: 0.1945 Acc: 0.9218 | Val Loss: 0.2403 Acc: 0.9046\n",
      "Epoch 035 | Train Loss: 0.1807 Acc: 0.9253 | Val Loss: 0.2046 Acc: 0.9191\n",
      "Epoch 036 | Train Loss: 0.1684 Acc: 0.9358 | Val Loss: 0.2273 Acc: 0.9034\n",
      "Epoch 037 | Train Loss: 0.1785 Acc: 0.9290 | Val Loss: 0.2025 Acc: 0.9245\n",
      "Epoch 038 | Train Loss: 0.1552 Acc: 0.9392 | Val Loss: 0.1950 Acc: 0.9263\n",
      "Epoch 039 | Train Loss: 0.1576 Acc: 0.9405 | Val Loss: 0.2069 Acc: 0.9257\n",
      "Epoch 040 | Train Loss: 0.1641 Acc: 0.9379 | Val Loss: 0.1972 Acc: 0.9215\n",
      "Epoch 041 | Train Loss: 0.1438 Acc: 0.9475 | Val Loss: 0.1784 Acc: 0.9372\n",
      "Epoch 042 | Train Loss: 0.1410 Acc: 0.9431 | Val Loss: 0.1820 Acc: 0.9251\n",
      "Epoch 043 | Train Loss: 0.1405 Acc: 0.9452 | Val Loss: 0.1836 Acc: 0.9318\n",
      "Epoch 044 | Train Loss: 0.1305 Acc: 0.9484 | Val Loss: 0.2262 Acc: 0.9179\n",
      "Epoch 045 | Train Loss: 0.1360 Acc: 0.9475 | Val Loss: 0.1959 Acc: 0.9275\n",
      "Epoch 046 | Train Loss: 0.1301 Acc: 0.9524 | Val Loss: 0.1803 Acc: 0.9324\n",
      "Epoch 047 | Train Loss: 0.1237 Acc: 0.9499 | Val Loss: 0.2213 Acc: 0.9155\n",
      "Epoch 048 | Train Loss: 0.1320 Acc: 0.9494 | Val Loss: 0.1944 Acc: 0.9275\n",
      "Epoch 049 | Train Loss: 0.1179 Acc: 0.9567 | Val Loss: 0.1683 Acc: 0.9390\n",
      "Epoch 050 | Train Loss: 0.1090 Acc: 0.9591 | Val Loss: 0.1869 Acc: 0.9312\n",
      "Epoch 051 | Train Loss: 0.1094 Acc: 0.9595 | Val Loss: 0.1631 Acc: 0.9499\n",
      "Epoch 052 | Train Loss: 0.1100 Acc: 0.9594 | Val Loss: 0.1986 Acc: 0.9366\n",
      "Epoch 053 | Train Loss: 0.1074 Acc: 0.9597 | Val Loss: 0.1664 Acc: 0.9378\n",
      "Epoch 054 | Train Loss: 0.1078 Acc: 0.9592 | Val Loss: 0.1981 Acc: 0.9293\n",
      "Epoch 055 | Train Loss: 0.1066 Acc: 0.9601 | Val Loss: 0.1914 Acc: 0.9324\n",
      "Epoch 056 | Train Loss: 0.0982 Acc: 0.9626 | Val Loss: 0.1788 Acc: 0.9366\n",
      "Epoch 057 | Train Loss: 0.1006 Acc: 0.9618 | Val Loss: 0.1793 Acc: 0.9390\n",
      "Epoch 058 | Train Loss: 0.1064 Acc: 0.9603 | Val Loss: 0.2035 Acc: 0.9275\n",
      "Epoch 059 | Train Loss: 0.1030 Acc: 0.9565 | Val Loss: 0.1683 Acc: 0.9372\n",
      "Epoch 060 | Train Loss: 0.0932 Acc: 0.9665 | Val Loss: 0.1656 Acc: 0.9444\n",
      "Epoch 001 | Train Loss: 0.6859 Acc: 0.5638 | Val Loss: 0.6800 Acc: 0.5821\n",
      "Epoch 002 | Train Loss: 0.6770 Acc: 0.5860 | Val Loss: 0.6755 Acc: 0.5888\n",
      "Epoch 003 | Train Loss: 0.6715 Acc: 0.5964 | Val Loss: 0.6724 Acc: 0.5930\n",
      "Epoch 004 | Train Loss: 0.6645 Acc: 0.6077 | Val Loss: 0.6549 Acc: 0.6135\n",
      "Epoch 005 | Train Loss: 0.6488 Acc: 0.6316 | Val Loss: 0.6275 Acc: 0.6649\n",
      "Epoch 006 | Train Loss: 0.6259 Acc: 0.6568 | Val Loss: 0.6159 Acc: 0.6739\n",
      "Epoch 007 | Train Loss: 0.6165 Acc: 0.6708 | Val Loss: 0.6099 Acc: 0.6787\n",
      "Epoch 008 | Train Loss: 0.6044 Acc: 0.6867 | Val Loss: 0.6015 Acc: 0.6908\n",
      "Epoch 009 | Train Loss: 0.6000 Acc: 0.6947 | Val Loss: 0.5992 Acc: 0.6836\n",
      "Epoch 010 | Train Loss: 0.5904 Acc: 0.6991 | Val Loss: 0.5969 Acc: 0.6866\n",
      "Epoch 011 | Train Loss: 0.5806 Acc: 0.7071 | Val Loss: 0.5826 Acc: 0.7089\n",
      "Epoch 012 | Train Loss: 0.5727 Acc: 0.7178 | Val Loss: 0.5892 Acc: 0.6932\n",
      "Epoch 013 | Train Loss: 0.5741 Acc: 0.7175 | Val Loss: 0.5785 Acc: 0.6987\n",
      "Epoch 014 | Train Loss: 0.5655 Acc: 0.7192 | Val Loss: 0.5643 Acc: 0.7210\n",
      "Epoch 015 | Train Loss: 0.5571 Acc: 0.7320 | Val Loss: 0.5596 Acc: 0.7210\n",
      "Epoch 016 | Train Loss: 0.5533 Acc: 0.7324 | Val Loss: 0.5544 Acc: 0.7271\n",
      "Epoch 017 | Train Loss: 0.5501 Acc: 0.7297 | Val Loss: 0.5486 Acc: 0.7289\n",
      "Epoch 018 | Train Loss: 0.5380 Acc: 0.7394 | Val Loss: 0.5483 Acc: 0.7240\n",
      "Epoch 019 | Train Loss: 0.5320 Acc: 0.7401 | Val Loss: 0.5403 Acc: 0.7295\n",
      "Epoch 020 | Train Loss: 0.5268 Acc: 0.7506 | Val Loss: 0.5762 Acc: 0.7083\n",
      "Epoch 021 | Train Loss: 0.5228 Acc: 0.7518 | Val Loss: 0.5304 Acc: 0.7301\n",
      "Epoch 022 | Train Loss: 0.5126 Acc: 0.7503 | Val Loss: 0.5222 Acc: 0.7403\n",
      "Epoch 023 | Train Loss: 0.5004 Acc: 0.7628 | Val Loss: 0.5365 Acc: 0.7289\n",
      "Epoch 024 | Train Loss: 0.4996 Acc: 0.7629 | Val Loss: 0.5242 Acc: 0.7343\n",
      "Epoch 025 | Train Loss: 0.5050 Acc: 0.7571 | Val Loss: 0.5042 Acc: 0.7482\n",
      "Epoch 026 | Train Loss: 0.4832 Acc: 0.7713 | Val Loss: 0.5254 Acc: 0.7337\n",
      "Epoch 027 | Train Loss: 0.4801 Acc: 0.7738 | Val Loss: 0.5073 Acc: 0.7506\n",
      "Epoch 028 | Train Loss: 0.4804 Acc: 0.7684 | Val Loss: 0.5062 Acc: 0.7488\n",
      "Epoch 029 | Train Loss: 0.4706 Acc: 0.7808 | Val Loss: 0.4863 Acc: 0.7585\n",
      "Epoch 030 | Train Loss: 0.4640 Acc: 0.7844 | Val Loss: 0.4737 Acc: 0.7669\n",
      "Epoch 031 | Train Loss: 0.4629 Acc: 0.7814 | Val Loss: 0.4743 Acc: 0.7645\n",
      "Epoch 032 | Train Loss: 0.4559 Acc: 0.7856 | Val Loss: 0.5024 Acc: 0.7415\n",
      "Epoch 033 | Train Loss: 0.4476 Acc: 0.7877 | Val Loss: 0.4612 Acc: 0.7723\n",
      "Epoch 034 | Train Loss: 0.4391 Acc: 0.7957 | Val Loss: 0.4542 Acc: 0.7862\n",
      "Epoch 035 | Train Loss: 0.4421 Acc: 0.7927 | Val Loss: 0.4414 Acc: 0.7917\n",
      "Epoch 036 | Train Loss: 0.4288 Acc: 0.7999 | Val Loss: 0.4505 Acc: 0.7905\n",
      "Epoch 037 | Train Loss: 0.4262 Acc: 0.8011 | Val Loss: 0.4265 Acc: 0.8043\n",
      "Epoch 038 | Train Loss: 0.4134 Acc: 0.8078 | Val Loss: 0.4375 Acc: 0.7971\n",
      "Epoch 039 | Train Loss: 0.4074 Acc: 0.8137 | Val Loss: 0.4238 Acc: 0.8086\n",
      "Epoch 040 | Train Loss: 0.4070 Acc: 0.8144 | Val Loss: 0.4241 Acc: 0.8007\n",
      "Epoch 041 | Train Loss: 0.3966 Acc: 0.8181 | Val Loss: 0.4082 Acc: 0.8056\n",
      "Epoch 042 | Train Loss: 0.3946 Acc: 0.8199 | Val Loss: 0.3955 Acc: 0.8194\n",
      "Epoch 043 | Train Loss: 0.3876 Acc: 0.8235 | Val Loss: 0.3853 Acc: 0.8285\n",
      "Epoch 044 | Train Loss: 0.3902 Acc: 0.8187 | Val Loss: 0.3835 Acc: 0.8188\n",
      "Epoch 045 | Train Loss: 0.3721 Acc: 0.8309 | Val Loss: 0.3821 Acc: 0.8219\n",
      "Epoch 046 | Train Loss: 0.3673 Acc: 0.8341 | Val Loss: 0.3827 Acc: 0.8255\n",
      "Epoch 047 | Train Loss: 0.3638 Acc: 0.8374 | Val Loss: 0.3796 Acc: 0.8297\n",
      "Epoch 048 | Train Loss: 0.3531 Acc: 0.8416 | Val Loss: 0.3771 Acc: 0.8219\n",
      "Epoch 049 | Train Loss: 0.3489 Acc: 0.8412 | Val Loss: 0.3522 Acc: 0.8412\n",
      "Epoch 050 | Train Loss: 0.3492 Acc: 0.8424 | Val Loss: 0.3591 Acc: 0.8424\n",
      "Epoch 051 | Train Loss: 0.3417 Acc: 0.8469 | Val Loss: 0.3444 Acc: 0.8460\n",
      "Epoch 052 | Train Loss: 0.3387 Acc: 0.8501 | Val Loss: 0.3471 Acc: 0.8436\n",
      "Epoch 053 | Train Loss: 0.3262 Acc: 0.8561 | Val Loss: 0.3366 Acc: 0.8593\n",
      "Epoch 054 | Train Loss: 0.3203 Acc: 0.8573 | Val Loss: 0.3736 Acc: 0.8376\n",
      "Epoch 055 | Train Loss: 0.3190 Acc: 0.8634 | Val Loss: 0.3263 Acc: 0.8593\n",
      "Epoch 056 | Train Loss: 0.3097 Acc: 0.8637 | Val Loss: 0.3210 Acc: 0.8593\n",
      "Epoch 057 | Train Loss: 0.3007 Acc: 0.8732 | Val Loss: 0.3172 Acc: 0.8641\n",
      "Epoch 058 | Train Loss: 0.3032 Acc: 0.8650 | Val Loss: 0.3602 Acc: 0.8430\n",
      "Epoch 059 | Train Loss: 0.2920 Acc: 0.8700 | Val Loss: 0.3309 Acc: 0.8484\n",
      "Epoch 060 | Train Loss: 0.2909 Acc: 0.8727 | Val Loss: 0.3052 Acc: 0.8750\n",
      "Epoch 001 | Train Loss: 0.6768 Acc: 0.5833 | Val Loss: 0.6645 Acc: 0.6027\n",
      "Epoch 002 | Train Loss: 0.6502 Acc: 0.6272 | Val Loss: 0.6369 Acc: 0.6540\n",
      "Epoch 003 | Train Loss: 0.6149 Acc: 0.6795 | Val Loss: 0.5877 Acc: 0.7011\n",
      "Epoch 004 | Train Loss: 0.5787 Acc: 0.7110 | Val Loss: 0.5959 Acc: 0.6963\n",
      "Epoch 005 | Train Loss: 0.5661 Acc: 0.7152 | Val Loss: 0.5743 Acc: 0.7204\n",
      "Epoch 006 | Train Loss: 0.5369 Acc: 0.7406 | Val Loss: 0.5414 Acc: 0.7277\n",
      "Epoch 007 | Train Loss: 0.5225 Acc: 0.7478 | Val Loss: 0.5440 Acc: 0.7228\n",
      "Epoch 008 | Train Loss: 0.5093 Acc: 0.7548 | Val Loss: 0.5080 Acc: 0.7548\n",
      "Epoch 009 | Train Loss: 0.4813 Acc: 0.7738 | Val Loss: 0.4717 Acc: 0.7729\n",
      "Epoch 010 | Train Loss: 0.4739 Acc: 0.7791 | Val Loss: 0.4732 Acc: 0.7784\n",
      "Epoch 011 | Train Loss: 0.4488 Acc: 0.7889 | Val Loss: 0.4606 Acc: 0.7766\n",
      "Epoch 012 | Train Loss: 0.4394 Acc: 0.7995 | Val Loss: 0.4003 Acc: 0.8122\n",
      "Epoch 013 | Train Loss: 0.4089 Acc: 0.8104 | Val Loss: 0.4115 Acc: 0.8019\n",
      "Epoch 014 | Train Loss: 0.3798 Acc: 0.8283 | Val Loss: 0.3807 Acc: 0.8182\n",
      "Epoch 015 | Train Loss: 0.3753 Acc: 0.8291 | Val Loss: 0.3620 Acc: 0.8309\n",
      "Epoch 016 | Train Loss: 0.3466 Acc: 0.8431 | Val Loss: 0.3780 Acc: 0.8315\n",
      "Epoch 017 | Train Loss: 0.3253 Acc: 0.8535 | Val Loss: 0.3229 Acc: 0.8581\n",
      "Epoch 018 | Train Loss: 0.3107 Acc: 0.8668 | Val Loss: 0.3297 Acc: 0.8557\n",
      "Epoch 019 | Train Loss: 0.2929 Acc: 0.8739 | Val Loss: 0.2857 Acc: 0.8792\n",
      "Epoch 020 | Train Loss: 0.2882 Acc: 0.8772 | Val Loss: 0.3154 Acc: 0.8635\n",
      "Epoch 021 | Train Loss: 0.2589 Acc: 0.8893 | Val Loss: 0.2814 Acc: 0.8744\n",
      "Epoch 022 | Train Loss: 0.2577 Acc: 0.8933 | Val Loss: 0.2657 Acc: 0.8865\n",
      "Epoch 023 | Train Loss: 0.2401 Acc: 0.9006 | Val Loss: 0.3374 Acc: 0.8617\n",
      "Epoch 024 | Train Loss: 0.2352 Acc: 0.9035 | Val Loss: 0.3217 Acc: 0.8605\n",
      "Epoch 025 | Train Loss: 0.2272 Acc: 0.9074 | Val Loss: 0.2467 Acc: 0.8998\n",
      "Epoch 026 | Train Loss: 0.2163 Acc: 0.9144 | Val Loss: 0.2328 Acc: 0.9040\n",
      "Epoch 027 | Train Loss: 0.2061 Acc: 0.9173 | Val Loss: 0.2175 Acc: 0.9082\n",
      "Epoch 028 | Train Loss: 0.1872 Acc: 0.9236 | Val Loss: 0.2310 Acc: 0.9058\n",
      "Epoch 029 | Train Loss: 0.1809 Acc: 0.9278 | Val Loss: 0.2082 Acc: 0.9167\n",
      "Epoch 030 | Train Loss: 0.1792 Acc: 0.9280 | Val Loss: 0.2225 Acc: 0.9076\n",
      "Epoch 031 | Train Loss: 0.1641 Acc: 0.9366 | Val Loss: 0.2187 Acc: 0.9173\n",
      "Epoch 032 | Train Loss: 0.1621 Acc: 0.9361 | Val Loss: 0.2043 Acc: 0.9257\n",
      "Epoch 033 | Train Loss: 0.1614 Acc: 0.9375 | Val Loss: 0.1870 Acc: 0.9257\n",
      "Epoch 034 | Train Loss: 0.1562 Acc: 0.9384 | Val Loss: 0.1970 Acc: 0.9227\n",
      "Epoch 035 | Train Loss: 0.1396 Acc: 0.9465 | Val Loss: 0.1941 Acc: 0.9251\n",
      "Epoch 036 | Train Loss: 0.1397 Acc: 0.9479 | Val Loss: 0.1983 Acc: 0.9245\n",
      "Epoch 037 | Train Loss: 0.1347 Acc: 0.9484 | Val Loss: 0.1882 Acc: 0.9281\n",
      "Epoch 038 | Train Loss: 0.1128 Acc: 0.9553 | Val Loss: 0.1872 Acc: 0.9336\n",
      "Epoch 039 | Train Loss: 0.1231 Acc: 0.9549 | Val Loss: 0.1869 Acc: 0.9269\n",
      "Epoch 040 | Train Loss: 0.1163 Acc: 0.9561 | Val Loss: 0.1768 Acc: 0.9312\n",
      "Epoch 041 | Train Loss: 0.1156 Acc: 0.9556 | Val Loss: 0.1719 Acc: 0.9306\n",
      "Epoch 042 | Train Loss: 0.1099 Acc: 0.9610 | Val Loss: 0.1701 Acc: 0.9245\n",
      "Epoch 043 | Train Loss: 0.1057 Acc: 0.9620 | Val Loss: 0.1535 Acc: 0.9414\n",
      "Epoch 044 | Train Loss: 0.0975 Acc: 0.9644 | Val Loss: 0.1972 Acc: 0.9348\n",
      "Epoch 045 | Train Loss: 0.1022 Acc: 0.9624 | Val Loss: 0.1653 Acc: 0.9378\n",
      "Epoch 046 | Train Loss: 0.0925 Acc: 0.9662 | Val Loss: 0.1506 Acc: 0.9438\n",
      "Epoch 047 | Train Loss: 0.1063 Acc: 0.9610 | Val Loss: 0.1577 Acc: 0.9402\n",
      "Epoch 048 | Train Loss: 0.1006 Acc: 0.9610 | Val Loss: 0.1851 Acc: 0.9330\n",
      "Epoch 049 | Train Loss: 0.0827 Acc: 0.9715 | Val Loss: 0.1660 Acc: 0.9396\n",
      "Epoch 050 | Train Loss: 0.0878 Acc: 0.9675 | Val Loss: 0.1630 Acc: 0.9408\n",
      "Epoch 051 | Train Loss: 0.0907 Acc: 0.9648 | Val Loss: 0.1680 Acc: 0.9384\n",
      "Epoch 052 | Train Loss: 0.0820 Acc: 0.9695 | Val Loss: 0.1784 Acc: 0.9384\n",
      "Epoch 053 | Train Loss: 0.0817 Acc: 0.9686 | Val Loss: 0.1483 Acc: 0.9469\n",
      "Epoch 054 | Train Loss: 0.0825 Acc: 0.9712 | Val Loss: 0.1622 Acc: 0.9396\n",
      "Epoch 055 | Train Loss: 0.0877 Acc: 0.9648 | Val Loss: 0.1850 Acc: 0.9414\n",
      "Epoch 056 | Train Loss: 0.0739 Acc: 0.9716 | Val Loss: 0.1551 Acc: 0.9444\n",
      "Epoch 057 | Train Loss: 0.0819 Acc: 0.9692 | Val Loss: 0.1446 Acc: 0.9444\n",
      "Epoch 058 | Train Loss: 0.0750 Acc: 0.9719 | Val Loss: 0.1533 Acc: 0.9408\n",
      "Epoch 059 | Train Loss: 0.0740 Acc: 0.9722 | Val Loss: 0.1338 Acc: 0.9535\n",
      "Epoch 060 | Train Loss: 0.0730 Acc: 0.9752 | Val Loss: 0.1597 Acc: 0.9481\n",
      "Epoch 001 | Train Loss: 0.6793 Acc: 0.5834 | Val Loss: 0.6761 Acc: 0.5900\n",
      "Epoch 002 | Train Loss: 0.6704 Acc: 0.5994 | Val Loss: 0.6680 Acc: 0.5996\n",
      "Epoch 003 | Train Loss: 0.6681 Acc: 0.6002 | Val Loss: 0.6652 Acc: 0.6045\n",
      "Epoch 004 | Train Loss: 0.6670 Acc: 0.6080 | Val Loss: 0.6635 Acc: 0.6057\n",
      "Epoch 005 | Train Loss: 0.6599 Acc: 0.6121 | Val Loss: 0.6508 Acc: 0.6202\n",
      "Epoch 006 | Train Loss: 0.6504 Acc: 0.6272 | Val Loss: 0.6170 Acc: 0.6884\n",
      "Epoch 007 | Train Loss: 0.6478 Acc: 0.6379 | Val Loss: 0.6255 Acc: 0.6848\n",
      "Epoch 008 | Train Loss: 0.5985 Acc: 0.6956 | Val Loss: 0.5803 Acc: 0.7041\n",
      "Epoch 009 | Train Loss: 0.5767 Acc: 0.7196 | Val Loss: 0.5680 Acc: 0.7114\n",
      "Epoch 010 | Train Loss: 0.5710 Acc: 0.7169 | Val Loss: 0.5473 Acc: 0.7301\n",
      "Epoch 011 | Train Loss: 0.5482 Acc: 0.7320 | Val Loss: 0.5385 Acc: 0.7343\n",
      "Epoch 012 | Train Loss: 0.5359 Acc: 0.7430 | Val Loss: 0.5209 Acc: 0.7458\n",
      "Epoch 013 | Train Loss: 0.5179 Acc: 0.7519 | Val Loss: 0.5019 Acc: 0.7579\n",
      "Epoch 014 | Train Loss: 0.5028 Acc: 0.7654 | Val Loss: 0.4933 Acc: 0.7645\n",
      "Epoch 015 | Train Loss: 0.4899 Acc: 0.7605 | Val Loss: 0.4771 Acc: 0.7645\n",
      "Epoch 016 | Train Loss: 0.4656 Acc: 0.7821 | Val Loss: 0.4715 Acc: 0.7717\n",
      "Epoch 017 | Train Loss: 0.4479 Acc: 0.7891 | Val Loss: 0.4401 Acc: 0.7844\n",
      "Epoch 018 | Train Loss: 0.4406 Acc: 0.7924 | Val Loss: 0.4657 Acc: 0.7723\n",
      "Epoch 019 | Train Loss: 0.4203 Acc: 0.8045 | Val Loss: 0.4126 Acc: 0.8025\n",
      "Epoch 020 | Train Loss: 0.4000 Acc: 0.8200 | Val Loss: 0.4097 Acc: 0.8104\n",
      "Epoch 021 | Train Loss: 0.3815 Acc: 0.8300 | Val Loss: 0.3698 Acc: 0.8406\n",
      "Epoch 022 | Train Loss: 0.3757 Acc: 0.8274 | Val Loss: 0.3764 Acc: 0.8376\n",
      "Epoch 023 | Train Loss: 0.3580 Acc: 0.8403 | Val Loss: 0.3387 Acc: 0.8370\n",
      "Epoch 024 | Train Loss: 0.3289 Acc: 0.8549 | Val Loss: 0.3640 Acc: 0.8267\n",
      "Epoch 025 | Train Loss: 0.3228 Acc: 0.8614 | Val Loss: 0.2963 Acc: 0.8720\n",
      "Epoch 026 | Train Loss: 0.2999 Acc: 0.8715 | Val Loss: 0.2819 Acc: 0.8750\n",
      "Epoch 027 | Train Loss: 0.2894 Acc: 0.8798 | Val Loss: 0.2923 Acc: 0.8780\n",
      "Epoch 028 | Train Loss: 0.2695 Acc: 0.8914 | Val Loss: 0.2622 Acc: 0.8937\n",
      "Epoch 029 | Train Loss: 0.2579 Acc: 0.8923 | Val Loss: 0.2610 Acc: 0.8913\n",
      "Epoch 030 | Train Loss: 0.2466 Acc: 0.8984 | Val Loss: 0.2610 Acc: 0.8847\n",
      "Epoch 031 | Train Loss: 0.2336 Acc: 0.9013 | Val Loss: 0.2940 Acc: 0.8895\n",
      "Epoch 032 | Train Loss: 0.2292 Acc: 0.9052 | Val Loss: 0.2417 Acc: 0.9034\n",
      "Epoch 033 | Train Loss: 0.2344 Acc: 0.9065 | Val Loss: 0.2291 Acc: 0.9130\n",
      "Epoch 034 | Train Loss: 0.2038 Acc: 0.9151 | Val Loss: 0.2309 Acc: 0.9028\n",
      "Epoch 035 | Train Loss: 0.1995 Acc: 0.9222 | Val Loss: 0.2180 Acc: 0.9100\n",
      "Epoch 036 | Train Loss: 0.1934 Acc: 0.9251 | Val Loss: 0.1990 Acc: 0.9215\n",
      "Epoch 037 | Train Loss: 0.1849 Acc: 0.9311 | Val Loss: 0.2250 Acc: 0.9124\n",
      "Epoch 038 | Train Loss: 0.1883 Acc: 0.9257 | Val Loss: 0.1865 Acc: 0.9257\n",
      "Epoch 039 | Train Loss: 0.1744 Acc: 0.9337 | Val Loss: 0.2115 Acc: 0.9149\n",
      "Epoch 040 | Train Loss: 0.1613 Acc: 0.9388 | Val Loss: 0.2238 Acc: 0.9124\n",
      "Epoch 041 | Train Loss: 0.1652 Acc: 0.9372 | Val Loss: 0.1951 Acc: 0.9215\n",
      "Epoch 042 | Train Loss: 0.1464 Acc: 0.9438 | Val Loss: 0.1998 Acc: 0.9281\n",
      "Epoch 043 | Train Loss: 0.1561 Acc: 0.9431 | Val Loss: 0.1988 Acc: 0.9245\n",
      "Epoch 044 | Train Loss: 0.1448 Acc: 0.9453 | Val Loss: 0.1778 Acc: 0.9330\n",
      "Epoch 045 | Train Loss: 0.1354 Acc: 0.9494 | Val Loss: 0.1808 Acc: 0.9324\n",
      "Epoch 046 | Train Loss: 0.1432 Acc: 0.9443 | Val Loss: 0.1951 Acc: 0.9221\n",
      "Epoch 047 | Train Loss: 0.1252 Acc: 0.9518 | Val Loss: 0.2034 Acc: 0.9221\n",
      "Epoch 048 | Train Loss: 0.1255 Acc: 0.9550 | Val Loss: 0.1779 Acc: 0.9318\n",
      "Epoch 049 | Train Loss: 0.1247 Acc: 0.9517 | Val Loss: 0.1769 Acc: 0.9360\n",
      "Epoch 050 | Train Loss: 0.1233 Acc: 0.9541 | Val Loss: 0.2182 Acc: 0.9197\n",
      "Epoch 051 | Train Loss: 0.1167 Acc: 0.9552 | Val Loss: 0.1887 Acc: 0.9257\n",
      "Epoch 052 | Train Loss: 0.1184 Acc: 0.9538 | Val Loss: 0.1724 Acc: 0.9360\n",
      "Epoch 053 | Train Loss: 0.1151 Acc: 0.9567 | Val Loss: 0.1799 Acc: 0.9342\n",
      "Epoch 054 | Train Loss: 0.1021 Acc: 0.9615 | Val Loss: 0.1900 Acc: 0.9312\n",
      "Epoch 055 | Train Loss: 0.0923 Acc: 0.9672 | Val Loss: 0.1668 Acc: 0.9420\n",
      "Epoch 056 | Train Loss: 0.1092 Acc: 0.9589 | Val Loss: 0.1644 Acc: 0.9438\n",
      "Epoch 057 | Train Loss: 0.0999 Acc: 0.9615 | Val Loss: 0.2043 Acc: 0.9239\n",
      "Epoch 058 | Train Loss: 0.1041 Acc: 0.9620 | Val Loss: 0.1701 Acc: 0.9372\n",
      "Epoch 059 | Train Loss: 0.0938 Acc: 0.9678 | Val Loss: 0.1585 Acc: 0.9426\n",
      "Epoch 060 | Train Loss: 0.1024 Acc: 0.9624 | Val Loss: 0.1767 Acc: 0.9408\n",
      "Epoch 001 | Train Loss: 0.6797 Acc: 0.5828 | Val Loss: 0.6923 Acc: 0.5217\n",
      "Epoch 002 | Train Loss: 0.6652 Acc: 0.6030 | Val Loss: 0.6498 Acc: 0.6099\n",
      "Epoch 003 | Train Loss: 0.6309 Acc: 0.6490 | Val Loss: 0.5952 Acc: 0.6963\n",
      "Epoch 004 | Train Loss: 0.5909 Acc: 0.6986 | Val Loss: 0.5821 Acc: 0.7059\n",
      "Epoch 005 | Train Loss: 0.5644 Acc: 0.7228 | Val Loss: 0.5660 Acc: 0.7144\n",
      "Epoch 006 | Train Loss: 0.5418 Acc: 0.7335 | Val Loss: 0.5468 Acc: 0.7216\n",
      "Epoch 007 | Train Loss: 0.5324 Acc: 0.7358 | Val Loss: 0.5349 Acc: 0.7271\n",
      "Epoch 008 | Train Loss: 0.5126 Acc: 0.7512 | Val Loss: 0.5249 Acc: 0.7391\n",
      "Epoch 009 | Train Loss: 0.4948 Acc: 0.7620 | Val Loss: 0.5132 Acc: 0.7476\n",
      "Epoch 010 | Train Loss: 0.4750 Acc: 0.7794 | Val Loss: 0.4872 Acc: 0.7742\n",
      "Epoch 011 | Train Loss: 0.4592 Acc: 0.7818 | Val Loss: 0.4608 Acc: 0.7862\n",
      "Epoch 012 | Train Loss: 0.4416 Acc: 0.7954 | Val Loss: 0.4274 Acc: 0.8043\n",
      "Epoch 013 | Train Loss: 0.4095 Acc: 0.8123 | Val Loss: 0.4013 Acc: 0.8104\n",
      "Epoch 014 | Train Loss: 0.3956 Acc: 0.8206 | Val Loss: 0.4252 Acc: 0.7935\n",
      "Epoch 015 | Train Loss: 0.3872 Acc: 0.8239 | Val Loss: 0.3769 Acc: 0.8333\n",
      "Epoch 016 | Train Loss: 0.3599 Acc: 0.8374 | Val Loss: 0.3753 Acc: 0.8297\n",
      "Epoch 017 | Train Loss: 0.3311 Acc: 0.8608 | Val Loss: 0.3653 Acc: 0.8279\n",
      "Epoch 018 | Train Loss: 0.3234 Acc: 0.8605 | Val Loss: 0.3280 Acc: 0.8508\n",
      "Epoch 019 | Train Loss: 0.2947 Acc: 0.8750 | Val Loss: 0.3004 Acc: 0.8671\n",
      "Epoch 020 | Train Loss: 0.2918 Acc: 0.8763 | Val Loss: 0.3024 Acc: 0.8684\n",
      "Epoch 021 | Train Loss: 0.2834 Acc: 0.8777 | Val Loss: 0.3035 Acc: 0.8611\n",
      "Epoch 022 | Train Loss: 0.2580 Acc: 0.8952 | Val Loss: 0.3012 Acc: 0.8708\n",
      "Epoch 023 | Train Loss: 0.2686 Acc: 0.8884 | Val Loss: 0.2450 Acc: 0.9058\n",
      "Epoch 024 | Train Loss: 0.2294 Acc: 0.9062 | Val Loss: 0.2475 Acc: 0.9016\n",
      "Epoch 025 | Train Loss: 0.2208 Acc: 0.9080 | Val Loss: 0.3144 Acc: 0.8647\n",
      "Epoch 026 | Train Loss: 0.2312 Acc: 0.9080 | Val Loss: 0.2653 Acc: 0.8937\n",
      "Epoch 027 | Train Loss: 0.2068 Acc: 0.9179 | Val Loss: 0.2854 Acc: 0.8822\n",
      "Epoch 028 | Train Loss: 0.2005 Acc: 0.9164 | Val Loss: 0.2116 Acc: 0.9191\n",
      "Epoch 029 | Train Loss: 0.1877 Acc: 0.9269 | Val Loss: 0.2147 Acc: 0.9124\n",
      "Epoch 030 | Train Loss: 0.1731 Acc: 0.9330 | Val Loss: 0.1994 Acc: 0.9245\n",
      "Epoch 031 | Train Loss: 0.1732 Acc: 0.9311 | Val Loss: 0.2173 Acc: 0.9124\n",
      "Epoch 032 | Train Loss: 0.1603 Acc: 0.9352 | Val Loss: 0.2012 Acc: 0.9197\n",
      "Epoch 033 | Train Loss: 0.1650 Acc: 0.9361 | Val Loss: 0.2036 Acc: 0.9300\n",
      "Epoch 034 | Train Loss: 0.1692 Acc: 0.9334 | Val Loss: 0.2018 Acc: 0.9221\n",
      "Epoch 035 | Train Loss: 0.1532 Acc: 0.9366 | Val Loss: 0.1975 Acc: 0.9233\n",
      "Epoch 036 | Train Loss: 0.1373 Acc: 0.9461 | Val Loss: 0.1935 Acc: 0.9293\n",
      "Epoch 037 | Train Loss: 0.1463 Acc: 0.9450 | Val Loss: 0.1788 Acc: 0.9287\n",
      "Epoch 038 | Train Loss: 0.1339 Acc: 0.9482 | Val Loss: 0.3008 Acc: 0.8841\n",
      "Epoch 039 | Train Loss: 0.1396 Acc: 0.9475 | Val Loss: 0.1824 Acc: 0.9281\n",
      "Epoch 040 | Train Loss: 0.1241 Acc: 0.9533 | Val Loss: 0.1673 Acc: 0.9384\n",
      "Epoch 041 | Train Loss: 0.1165 Acc: 0.9571 | Val Loss: 0.1491 Acc: 0.9450\n",
      "Epoch 042 | Train Loss: 0.1079 Acc: 0.9589 | Val Loss: 0.1704 Acc: 0.9420\n",
      "Epoch 043 | Train Loss: 0.1089 Acc: 0.9582 | Val Loss: 0.1813 Acc: 0.9384\n",
      "Epoch 044 | Train Loss: 0.1194 Acc: 0.9550 | Val Loss: 0.1689 Acc: 0.9372\n",
      "Epoch 045 | Train Loss: 0.1147 Acc: 0.9533 | Val Loss: 0.1675 Acc: 0.9378\n",
      "Epoch 046 | Train Loss: 0.1094 Acc: 0.9577 | Val Loss: 0.1667 Acc: 0.9426\n",
      "Epoch 047 | Train Loss: 0.1036 Acc: 0.9607 | Val Loss: 0.1853 Acc: 0.9336\n",
      "Epoch 048 | Train Loss: 0.0905 Acc: 0.9659 | Val Loss: 0.1625 Acc: 0.9384\n",
      "Epoch 049 | Train Loss: 0.0916 Acc: 0.9653 | Val Loss: 0.2051 Acc: 0.9336\n",
      "Epoch 050 | Train Loss: 0.1037 Acc: 0.9615 | Val Loss: 0.1671 Acc: 0.9348\n",
      "Epoch 051 | Train Loss: 0.0950 Acc: 0.9678 | Val Loss: 0.1411 Acc: 0.9463\n",
      "Epoch 052 | Train Loss: 0.0833 Acc: 0.9678 | Val Loss: 0.1378 Acc: 0.9475\n",
      "Epoch 053 | Train Loss: 0.0901 Acc: 0.9642 | Val Loss: 0.1688 Acc: 0.9408\n",
      "Epoch 054 | Train Loss: 0.0774 Acc: 0.9721 | Val Loss: 0.1489 Acc: 0.9499\n",
      "Epoch 055 | Train Loss: 0.0880 Acc: 0.9669 | Val Loss: 0.1404 Acc: 0.9499\n",
      "Epoch 056 | Train Loss: 0.0775 Acc: 0.9725 | Val Loss: 0.1414 Acc: 0.9505\n",
      "Epoch 057 | Train Loss: 0.0875 Acc: 0.9687 | Val Loss: 0.1377 Acc: 0.9517\n",
      "Epoch 058 | Train Loss: 0.0770 Acc: 0.9730 | Val Loss: 0.1445 Acc: 0.9541\n",
      "Epoch 059 | Train Loss: 0.0835 Acc: 0.9701 | Val Loss: 0.1624 Acc: 0.9372\n",
      "Epoch 060 | Train Loss: 0.0802 Acc: 0.9700 | Val Loss: 0.1574 Acc: 0.9463\n",
      "Epoch 001 | Train Loss: 0.6793 Acc: 0.5809 | Val Loss: 0.6797 Acc: 0.5743\n",
      "Epoch 002 | Train Loss: 0.6692 Acc: 0.5991 | Val Loss: 0.6621 Acc: 0.6051\n",
      "Epoch 003 | Train Loss: 0.6559 Acc: 0.6188 | Val Loss: 0.6422 Acc: 0.6268\n",
      "Epoch 004 | Train Loss: 0.6329 Acc: 0.6560 | Val Loss: 0.5987 Acc: 0.6932\n",
      "Epoch 005 | Train Loss: 0.5826 Acc: 0.7101 | Val Loss: 0.5964 Acc: 0.6896\n",
      "Epoch 006 | Train Loss: 0.5616 Acc: 0.7243 | Val Loss: 0.5573 Acc: 0.7180\n",
      "Epoch 007 | Train Loss: 0.5456 Acc: 0.7272 | Val Loss: 0.5502 Acc: 0.7246\n",
      "Epoch 008 | Train Loss: 0.5351 Acc: 0.7382 | Val Loss: 0.5328 Acc: 0.7277\n",
      "Epoch 009 | Train Loss: 0.5094 Acc: 0.7548 | Val Loss: 0.5100 Acc: 0.7434\n",
      "Epoch 010 | Train Loss: 0.4913 Acc: 0.7604 | Val Loss: 0.4979 Acc: 0.7464\n",
      "Epoch 011 | Train Loss: 0.4774 Acc: 0.7679 | Val Loss: 0.4537 Acc: 0.7814\n",
      "Epoch 012 | Train Loss: 0.4488 Acc: 0.7867 | Val Loss: 0.4423 Acc: 0.7856\n",
      "Epoch 013 | Train Loss: 0.4358 Acc: 0.7936 | Val Loss: 0.4421 Acc: 0.7953\n",
      "Epoch 014 | Train Loss: 0.4069 Acc: 0.8055 | Val Loss: 0.4368 Acc: 0.7905\n",
      "Epoch 015 | Train Loss: 0.3960 Acc: 0.8149 | Val Loss: 0.4200 Acc: 0.8037\n",
      "Epoch 016 | Train Loss: 0.3695 Acc: 0.8324 | Val Loss: 0.3804 Acc: 0.8231\n",
      "Epoch 017 | Train Loss: 0.3469 Acc: 0.8475 | Val Loss: 0.3550 Acc: 0.8412\n",
      "Epoch 018 | Train Loss: 0.3380 Acc: 0.8492 | Val Loss: 0.3849 Acc: 0.8273\n",
      "Epoch 019 | Train Loss: 0.3253 Acc: 0.8605 | Val Loss: 0.3281 Acc: 0.8587\n",
      "Epoch 020 | Train Loss: 0.2895 Acc: 0.8813 | Val Loss: 0.3105 Acc: 0.8684\n",
      "Epoch 021 | Train Loss: 0.2776 Acc: 0.8840 | Val Loss: 0.2910 Acc: 0.8720\n",
      "Epoch 022 | Train Loss: 0.2586 Acc: 0.8937 | Val Loss: 0.3057 Acc: 0.8732\n",
      "Epoch 023 | Train Loss: 0.2482 Acc: 0.8999 | Val Loss: 0.2877 Acc: 0.8859\n",
      "Epoch 024 | Train Loss: 0.2357 Acc: 0.9059 | Val Loss: 0.2540 Acc: 0.8973\n",
      "Epoch 025 | Train Loss: 0.2333 Acc: 0.9049 | Val Loss: 0.2522 Acc: 0.8895\n",
      "Epoch 026 | Train Loss: 0.2204 Acc: 0.9126 | Val Loss: 0.2344 Acc: 0.9058\n",
      "Epoch 027 | Train Loss: 0.2002 Acc: 0.9207 | Val Loss: 0.2186 Acc: 0.9149\n",
      "Epoch 028 | Train Loss: 0.1898 Acc: 0.9230 | Val Loss: 0.2123 Acc: 0.9173\n",
      "Epoch 029 | Train Loss: 0.1791 Acc: 0.9265 | Val Loss: 0.2216 Acc: 0.9088\n",
      "Epoch 030 | Train Loss: 0.1822 Acc: 0.9268 | Val Loss: 0.2460 Acc: 0.9028\n",
      "Epoch 031 | Train Loss: 0.1582 Acc: 0.9369 | Val Loss: 0.1799 Acc: 0.9336\n",
      "Epoch 032 | Train Loss: 0.1548 Acc: 0.9372 | Val Loss: 0.1934 Acc: 0.9233\n",
      "Epoch 033 | Train Loss: 0.1569 Acc: 0.9381 | Val Loss: 0.2091 Acc: 0.9179\n",
      "Epoch 034 | Train Loss: 0.1436 Acc: 0.9453 | Val Loss: 0.2181 Acc: 0.9179\n",
      "Epoch 035 | Train Loss: 0.1493 Acc: 0.9417 | Val Loss: 0.1765 Acc: 0.9348\n",
      "Epoch 036 | Train Loss: 0.1394 Acc: 0.9469 | Val Loss: 0.1757 Acc: 0.9366\n",
      "Epoch 037 | Train Loss: 0.1270 Acc: 0.9518 | Val Loss: 0.1764 Acc: 0.9348\n",
      "Epoch 038 | Train Loss: 0.1254 Acc: 0.9514 | Val Loss: 0.1759 Acc: 0.9438\n",
      "Epoch 039 | Train Loss: 0.1199 Acc: 0.9517 | Val Loss: 0.1736 Acc: 0.9384\n",
      "Epoch 040 | Train Loss: 0.1133 Acc: 0.9546 | Val Loss: 0.1642 Acc: 0.9457\n",
      "Epoch 041 | Train Loss: 0.1115 Acc: 0.9567 | Val Loss: 0.2232 Acc: 0.9173\n",
      "Epoch 042 | Train Loss: 0.1139 Acc: 0.9546 | Val Loss: 0.1681 Acc: 0.9432\n",
      "Epoch 043 | Train Loss: 0.0999 Acc: 0.9607 | Val Loss: 0.1639 Acc: 0.9457\n",
      "Epoch 044 | Train Loss: 0.0997 Acc: 0.9624 | Val Loss: 0.1669 Acc: 0.9529\n",
      "Epoch 045 | Train Loss: 0.1002 Acc: 0.9630 | Val Loss: 0.1505 Acc: 0.9493\n",
      "Epoch 046 | Train Loss: 0.0918 Acc: 0.9660 | Val Loss: 0.1480 Acc: 0.9499\n",
      "Epoch 047 | Train Loss: 0.0937 Acc: 0.9636 | Val Loss: 0.1417 Acc: 0.9499\n",
      "Epoch 048 | Train Loss: 0.0877 Acc: 0.9692 | Val Loss: 0.1517 Acc: 0.9505\n",
      "Epoch 049 | Train Loss: 0.0792 Acc: 0.9710 | Val Loss: 0.1538 Acc: 0.9487\n",
      "Epoch 050 | Train Loss: 0.0702 Acc: 0.9731 | Val Loss: 0.1664 Acc: 0.9457\n",
      "Epoch 051 | Train Loss: 0.0896 Acc: 0.9656 | Val Loss: 0.1449 Acc: 0.9505\n",
      "Epoch 052 | Train Loss: 0.0820 Acc: 0.9698 | Val Loss: 0.1596 Acc: 0.9408\n",
      "Epoch 053 | Train Loss: 0.0786 Acc: 0.9719 | Val Loss: 0.1482 Acc: 0.9547\n",
      "Epoch 054 | Train Loss: 0.0739 Acc: 0.9725 | Val Loss: 0.1309 Acc: 0.9571\n",
      "Epoch 055 | Train Loss: 0.0604 Acc: 0.9786 | Val Loss: 0.1304 Acc: 0.9595\n",
      "Epoch 056 | Train Loss: 0.0614 Acc: 0.9786 | Val Loss: 0.1450 Acc: 0.9499\n",
      "Epoch 057 | Train Loss: 0.0740 Acc: 0.9710 | Val Loss: 0.1649 Acc: 0.9463\n",
      "Epoch 058 | Train Loss: 0.0668 Acc: 0.9760 | Val Loss: 0.1702 Acc: 0.9475\n",
      "Epoch 059 | Train Loss: 0.0723 Acc: 0.9722 | Val Loss: 0.1820 Acc: 0.9426\n",
      "Epoch 060 | Train Loss: 0.0584 Acc: 0.9784 | Val Loss: 0.1395 Acc: 0.9577\n",
      "Iteration 29/40 | Best Val Loss: 0.1122 | Iter Time: 230.48s | Total Time: 119.96 min\n",
      "Epoch 001 | Train Loss: 0.6851 Acc: 0.5620 | Val Loss: 0.6811 Acc: 0.5700\n",
      "Epoch 002 | Train Loss: 0.6792 Acc: 0.5795 | Val Loss: 0.6808 Acc: 0.5779\n",
      "Epoch 003 | Train Loss: 0.6692 Acc: 0.5988 | Val Loss: 0.6597 Acc: 0.6045\n",
      "Epoch 004 | Train Loss: 0.6495 Acc: 0.6280 | Val Loss: 0.6838 Acc: 0.5604\n",
      "Epoch 005 | Train Loss: 0.6394 Acc: 0.6367 | Val Loss: 0.5736 Acc: 0.7107\n",
      "Epoch 006 | Train Loss: 0.5792 Acc: 0.7086 | Val Loss: 0.5528 Acc: 0.7222\n",
      "Epoch 007 | Train Loss: 0.5523 Acc: 0.7315 | Val Loss: 0.5378 Acc: 0.7403\n",
      "Epoch 008 | Train Loss: 0.5292 Acc: 0.7441 | Val Loss: 0.5337 Acc: 0.7349\n",
      "Epoch 009 | Train Loss: 0.5145 Acc: 0.7516 | Val Loss: 0.5098 Acc: 0.7488\n",
      "Epoch 010 | Train Loss: 0.4924 Acc: 0.7642 | Val Loss: 0.4858 Acc: 0.7560\n",
      "Epoch 011 | Train Loss: 0.4755 Acc: 0.7722 | Val Loss: 0.4578 Acc: 0.7651\n",
      "Epoch 012 | Train Loss: 0.4650 Acc: 0.7818 | Val Loss: 0.4609 Acc: 0.7609\n",
      "Epoch 013 | Train Loss: 0.4441 Acc: 0.7950 | Val Loss: 0.4195 Acc: 0.7929\n",
      "Epoch 014 | Train Loss: 0.4378 Acc: 0.7980 | Val Loss: 0.4209 Acc: 0.7899\n",
      "Epoch 015 | Train Loss: 0.4354 Acc: 0.7986 | Val Loss: 0.4013 Acc: 0.8074\n",
      "Epoch 016 | Train Loss: 0.4164 Acc: 0.8110 | Val Loss: 0.3928 Acc: 0.8188\n",
      "Epoch 017 | Train Loss: 0.3959 Acc: 0.8217 | Val Loss: 0.3667 Acc: 0.8273\n",
      "Epoch 018 | Train Loss: 0.3858 Acc: 0.8230 | Val Loss: 0.4056 Acc: 0.8031\n",
      "Epoch 019 | Train Loss: 0.3745 Acc: 0.8303 | Val Loss: 0.3614 Acc: 0.8400\n",
      "Epoch 020 | Train Loss: 0.3523 Acc: 0.8448 | Val Loss: 0.3481 Acc: 0.8472\n",
      "Epoch 021 | Train Loss: 0.3469 Acc: 0.8477 | Val Loss: 0.3375 Acc: 0.8448\n",
      "Epoch 022 | Train Loss: 0.3234 Acc: 0.8602 | Val Loss: 0.3210 Acc: 0.8635\n",
      "Epoch 023 | Train Loss: 0.3179 Acc: 0.8626 | Val Loss: 0.3097 Acc: 0.8605\n",
      "Epoch 024 | Train Loss: 0.3048 Acc: 0.8723 | Val Loss: 0.3026 Acc: 0.8690\n",
      "Epoch 025 | Train Loss: 0.2931 Acc: 0.8760 | Val Loss: 0.2841 Acc: 0.8768\n",
      "Epoch 026 | Train Loss: 0.2821 Acc: 0.8824 | Val Loss: 0.3019 Acc: 0.8690\n",
      "Epoch 027 | Train Loss: 0.2801 Acc: 0.8795 | Val Loss: 0.2691 Acc: 0.8973\n",
      "Epoch 028 | Train Loss: 0.2704 Acc: 0.8854 | Val Loss: 0.2699 Acc: 0.8901\n",
      "Epoch 029 | Train Loss: 0.2648 Acc: 0.8875 | Val Loss: 0.2640 Acc: 0.8919\n",
      "Epoch 030 | Train Loss: 0.2687 Acc: 0.8872 | Val Loss: 0.2850 Acc: 0.8865\n",
      "Epoch 031 | Train Loss: 0.2519 Acc: 0.8979 | Val Loss: 0.2501 Acc: 0.9058\n",
      "Epoch 032 | Train Loss: 0.2410 Acc: 0.9050 | Val Loss: 0.2728 Acc: 0.8907\n",
      "Epoch 033 | Train Loss: 0.2367 Acc: 0.9023 | Val Loss: 0.2307 Acc: 0.9046\n",
      "Epoch 034 | Train Loss: 0.2260 Acc: 0.9087 | Val Loss: 0.2494 Acc: 0.9028\n",
      "Epoch 035 | Train Loss: 0.2303 Acc: 0.9041 | Val Loss: 0.2389 Acc: 0.8986\n",
      "Epoch 036 | Train Loss: 0.2163 Acc: 0.9142 | Val Loss: 0.2199 Acc: 0.9094\n",
      "Epoch 037 | Train Loss: 0.2153 Acc: 0.9161 | Val Loss: 0.2792 Acc: 0.8943\n",
      "Epoch 038 | Train Loss: 0.2173 Acc: 0.9145 | Val Loss: 0.2186 Acc: 0.9052\n",
      "Epoch 039 | Train Loss: 0.2032 Acc: 0.9213 | Val Loss: 0.2250 Acc: 0.9124\n",
      "Epoch 040 | Train Loss: 0.1922 Acc: 0.9253 | Val Loss: 0.2088 Acc: 0.9167\n",
      "Epoch 041 | Train Loss: 0.1915 Acc: 0.9274 | Val Loss: 0.1969 Acc: 0.9197\n",
      "Epoch 042 | Train Loss: 0.1866 Acc: 0.9278 | Val Loss: 0.2677 Acc: 0.8901\n",
      "Epoch 043 | Train Loss: 0.1849 Acc: 0.9278 | Val Loss: 0.2051 Acc: 0.9239\n",
      "Epoch 044 | Train Loss: 0.1901 Acc: 0.9241 | Val Loss: 0.2092 Acc: 0.9118\n",
      "Epoch 045 | Train Loss: 0.1826 Acc: 0.9260 | Val Loss: 0.2093 Acc: 0.9143\n",
      "Epoch 046 | Train Loss: 0.1813 Acc: 0.9293 | Val Loss: 0.1828 Acc: 0.9281\n",
      "Epoch 047 | Train Loss: 0.1615 Acc: 0.9358 | Val Loss: 0.2267 Acc: 0.9124\n",
      "Epoch 048 | Train Loss: 0.1656 Acc: 0.9366 | Val Loss: 0.2154 Acc: 0.9161\n",
      "Epoch 049 | Train Loss: 0.1549 Acc: 0.9375 | Val Loss: 0.2013 Acc: 0.9245\n",
      "Epoch 050 | Train Loss: 0.1640 Acc: 0.9345 | Val Loss: 0.1794 Acc: 0.9293\n",
      "Epoch 051 | Train Loss: 0.1666 Acc: 0.9331 | Val Loss: 0.1813 Acc: 0.9348\n",
      "Epoch 052 | Train Loss: 0.1499 Acc: 0.9399 | Val Loss: 0.1798 Acc: 0.9324\n",
      "Epoch 053 | Train Loss: 0.1694 Acc: 0.9355 | Val Loss: 0.2057 Acc: 0.9161\n",
      "Epoch 054 | Train Loss: 0.1664 Acc: 0.9342 | Val Loss: 0.1686 Acc: 0.9348\n",
      "Epoch 055 | Train Loss: 0.1548 Acc: 0.9413 | Val Loss: 0.1939 Acc: 0.9209\n",
      "Epoch 056 | Train Loss: 0.1479 Acc: 0.9443 | Val Loss: 0.1878 Acc: 0.9227\n",
      "Epoch 057 | Train Loss: 0.1457 Acc: 0.9434 | Val Loss: 0.1669 Acc: 0.9408\n",
      "Epoch 058 | Train Loss: 0.1525 Acc: 0.9440 | Val Loss: 0.2243 Acc: 0.9239\n",
      "Epoch 059 | Train Loss: 0.1422 Acc: 0.9447 | Val Loss: 0.1917 Acc: 0.9239\n",
      "Epoch 060 | Train Loss: 0.1379 Acc: 0.9472 | Val Loss: 0.2069 Acc: 0.9239\n",
      "Epoch 001 | Train Loss: 0.6835 Acc: 0.5697 | Val Loss: 0.6788 Acc: 0.5809\n",
      "Epoch 002 | Train Loss: 0.6770 Acc: 0.5883 | Val Loss: 0.6754 Acc: 0.5864\n",
      "Epoch 003 | Train Loss: 0.6665 Acc: 0.6046 | Val Loss: 0.6665 Acc: 0.6033\n",
      "Epoch 004 | Train Loss: 0.6508 Acc: 0.6292 | Val Loss: 0.6406 Acc: 0.6377\n",
      "Epoch 005 | Train Loss: 0.6117 Acc: 0.6736 | Val Loss: 0.6177 Acc: 0.6715\n",
      "Epoch 006 | Train Loss: 0.5941 Acc: 0.7013 | Val Loss: 0.5714 Acc: 0.7144\n",
      "Epoch 007 | Train Loss: 0.5570 Acc: 0.7300 | Val Loss: 0.5967 Acc: 0.6969\n",
      "Epoch 008 | Train Loss: 0.5379 Acc: 0.7379 | Val Loss: 0.5280 Acc: 0.7379\n",
      "Epoch 009 | Train Loss: 0.5161 Acc: 0.7530 | Val Loss: 0.5525 Acc: 0.7295\n",
      "Epoch 010 | Train Loss: 0.5029 Acc: 0.7607 | Val Loss: 0.5033 Acc: 0.7548\n",
      "Epoch 011 | Train Loss: 0.4842 Acc: 0.7726 | Val Loss: 0.4922 Acc: 0.7669\n",
      "Epoch 012 | Train Loss: 0.4679 Acc: 0.7864 | Val Loss: 0.4639 Acc: 0.7832\n",
      "Epoch 013 | Train Loss: 0.4536 Acc: 0.7885 | Val Loss: 0.4497 Acc: 0.7886\n",
      "Epoch 014 | Train Loss: 0.4270 Acc: 0.8066 | Val Loss: 0.4636 Acc: 0.7778\n",
      "Epoch 015 | Train Loss: 0.4125 Acc: 0.8111 | Val Loss: 0.4403 Acc: 0.7935\n",
      "Epoch 016 | Train Loss: 0.4020 Acc: 0.8221 | Val Loss: 0.3959 Acc: 0.8110\n",
      "Epoch 017 | Train Loss: 0.3850 Acc: 0.8244 | Val Loss: 0.3744 Acc: 0.8285\n",
      "Epoch 018 | Train Loss: 0.3512 Acc: 0.8415 | Val Loss: 0.4259 Acc: 0.7953\n",
      "Epoch 019 | Train Loss: 0.3552 Acc: 0.8393 | Val Loss: 0.3298 Acc: 0.8551\n",
      "Epoch 020 | Train Loss: 0.3276 Acc: 0.8549 | Val Loss: 0.3292 Acc: 0.8569\n",
      "Epoch 021 | Train Loss: 0.3088 Acc: 0.8634 | Val Loss: 0.3405 Acc: 0.8418\n",
      "Epoch 022 | Train Loss: 0.2888 Acc: 0.8801 | Val Loss: 0.2806 Acc: 0.8961\n",
      "Epoch 023 | Train Loss: 0.2864 Acc: 0.8768 | Val Loss: 0.2891 Acc: 0.8798\n",
      "Epoch 024 | Train Loss: 0.2659 Acc: 0.8880 | Val Loss: 0.2735 Acc: 0.8931\n",
      "Epoch 025 | Train Loss: 0.2581 Acc: 0.8902 | Val Loss: 0.2450 Acc: 0.9016\n",
      "Epoch 026 | Train Loss: 0.2438 Acc: 0.9022 | Val Loss: 0.2499 Acc: 0.9034\n",
      "Epoch 027 | Train Loss: 0.2233 Acc: 0.9065 | Val Loss: 0.2629 Acc: 0.8955\n",
      "Epoch 028 | Train Loss: 0.2121 Acc: 0.9168 | Val Loss: 0.2364 Acc: 0.9100\n",
      "Epoch 029 | Train Loss: 0.2065 Acc: 0.9179 | Val Loss: 0.2042 Acc: 0.9197\n",
      "Epoch 030 | Train Loss: 0.2051 Acc: 0.9162 | Val Loss: 0.2856 Acc: 0.8865\n",
      "Epoch 031 | Train Loss: 0.1992 Acc: 0.9221 | Val Loss: 0.2024 Acc: 0.9130\n",
      "Epoch 032 | Train Loss: 0.1820 Acc: 0.9280 | Val Loss: 0.2297 Acc: 0.9064\n",
      "Epoch 033 | Train Loss: 0.1736 Acc: 0.9301 | Val Loss: 0.1870 Acc: 0.9354\n",
      "Epoch 034 | Train Loss: 0.1703 Acc: 0.9337 | Val Loss: 0.1895 Acc: 0.9257\n",
      "Epoch 035 | Train Loss: 0.1620 Acc: 0.9358 | Val Loss: 0.1646 Acc: 0.9378\n",
      "Epoch 036 | Train Loss: 0.1639 Acc: 0.9349 | Val Loss: 0.1874 Acc: 0.9281\n",
      "Epoch 037 | Train Loss: 0.1496 Acc: 0.9423 | Val Loss: 0.1577 Acc: 0.9438\n",
      "Epoch 038 | Train Loss: 0.1477 Acc: 0.9441 | Val Loss: 0.1795 Acc: 0.9312\n",
      "Epoch 039 | Train Loss: 0.1533 Acc: 0.9425 | Val Loss: 0.1756 Acc: 0.9348\n",
      "Epoch 040 | Train Loss: 0.1432 Acc: 0.9437 | Val Loss: 0.1863 Acc: 0.9293\n",
      "Epoch 041 | Train Loss: 0.1329 Acc: 0.9511 | Val Loss: 0.2101 Acc: 0.9191\n",
      "Epoch 042 | Train Loss: 0.1360 Acc: 0.9494 | Val Loss: 0.1853 Acc: 0.9360\n",
      "Epoch 043 | Train Loss: 0.1257 Acc: 0.9527 | Val Loss: 0.1712 Acc: 0.9336\n",
      "Epoch 044 | Train Loss: 0.1341 Acc: 0.9499 | Val Loss: 0.1680 Acc: 0.9354\n",
      "Epoch 045 | Train Loss: 0.1206 Acc: 0.9553 | Val Loss: 0.1623 Acc: 0.9378\n",
      "Epoch 046 | Train Loss: 0.1217 Acc: 0.9524 | Val Loss: 0.1933 Acc: 0.9257\n",
      "Epoch 047 | Train Loss: 0.1057 Acc: 0.9620 | Val Loss: 0.1726 Acc: 0.9408\n",
      "Early stopping triggered.\n",
      "Epoch 001 | Train Loss: 0.6797 Acc: 0.5803 | Val Loss: 0.6786 Acc: 0.5803\n",
      "Epoch 002 | Train Loss: 0.6761 Acc: 0.5887 | Val Loss: 0.6761 Acc: 0.5894\n",
      "Epoch 003 | Train Loss: 0.6567 Acc: 0.6136 | Val Loss: 0.6259 Acc: 0.6606\n",
      "Epoch 004 | Train Loss: 0.6025 Acc: 0.6894 | Val Loss: 0.5681 Acc: 0.7301\n",
      "Epoch 005 | Train Loss: 0.5558 Acc: 0.7225 | Val Loss: 0.5589 Acc: 0.7186\n",
      "Epoch 006 | Train Loss: 0.5291 Acc: 0.7451 | Val Loss: 0.5492 Acc: 0.7385\n",
      "Epoch 007 | Train Loss: 0.5094 Acc: 0.7555 | Val Loss: 0.4937 Acc: 0.7705\n",
      "Epoch 008 | Train Loss: 0.4780 Acc: 0.7770 | Val Loss: 0.4773 Acc: 0.7736\n",
      "Epoch 009 | Train Loss: 0.4584 Acc: 0.7880 | Val Loss: 0.4432 Acc: 0.7832\n",
      "Epoch 010 | Train Loss: 0.4239 Acc: 0.8072 | Val Loss: 0.4061 Acc: 0.8037\n",
      "Epoch 011 | Train Loss: 0.4065 Acc: 0.8140 | Val Loss: 0.4278 Acc: 0.8025\n",
      "Epoch 012 | Train Loss: 0.3699 Acc: 0.8342 | Val Loss: 0.3616 Acc: 0.8315\n",
      "Epoch 013 | Train Loss: 0.3616 Acc: 0.8439 | Val Loss: 0.3611 Acc: 0.8448\n",
      "Epoch 014 | Train Loss: 0.3227 Acc: 0.8637 | Val Loss: 0.3347 Acc: 0.8496\n",
      "Epoch 015 | Train Loss: 0.3040 Acc: 0.8721 | Val Loss: 0.2952 Acc: 0.8708\n",
      "Epoch 016 | Train Loss: 0.2862 Acc: 0.8827 | Val Loss: 0.2746 Acc: 0.8901\n",
      "Epoch 017 | Train Loss: 0.2651 Acc: 0.8913 | Val Loss: 0.2875 Acc: 0.8816\n",
      "Epoch 018 | Train Loss: 0.2460 Acc: 0.8985 | Val Loss: 0.2558 Acc: 0.8871\n",
      "Epoch 019 | Train Loss: 0.2272 Acc: 0.9076 | Val Loss: 0.2328 Acc: 0.9034\n",
      "Epoch 020 | Train Loss: 0.2177 Acc: 0.9124 | Val Loss: 0.2151 Acc: 0.9088\n",
      "Epoch 021 | Train Loss: 0.1877 Acc: 0.9269 | Val Loss: 0.2329 Acc: 0.9034\n",
      "Epoch 022 | Train Loss: 0.1805 Acc: 0.9280 | Val Loss: 0.2211 Acc: 0.9149\n",
      "Epoch 023 | Train Loss: 0.1785 Acc: 0.9292 | Val Loss: 0.2003 Acc: 0.9149\n",
      "Epoch 024 | Train Loss: 0.1789 Acc: 0.9296 | Val Loss: 0.2215 Acc: 0.9100\n",
      "Epoch 025 | Train Loss: 0.1624 Acc: 0.9363 | Val Loss: 0.2113 Acc: 0.9106\n",
      "Epoch 026 | Train Loss: 0.1486 Acc: 0.9417 | Val Loss: 0.2032 Acc: 0.9227\n",
      "Epoch 027 | Train Loss: 0.1506 Acc: 0.9408 | Val Loss: 0.2184 Acc: 0.9100\n",
      "Epoch 028 | Train Loss: 0.1348 Acc: 0.9503 | Val Loss: 0.2048 Acc: 0.9215\n",
      "Epoch 029 | Train Loss: 0.1293 Acc: 0.9527 | Val Loss: 0.2099 Acc: 0.9287\n",
      "Epoch 030 | Train Loss: 0.1271 Acc: 0.9555 | Val Loss: 0.1771 Acc: 0.9306\n",
      "Epoch 031 | Train Loss: 0.1201 Acc: 0.9558 | Val Loss: 0.1820 Acc: 0.9372\n",
      "Epoch 032 | Train Loss: 0.1248 Acc: 0.9521 | Val Loss: 0.2100 Acc: 0.9227\n",
      "Epoch 033 | Train Loss: 0.1148 Acc: 0.9556 | Val Loss: 0.1847 Acc: 0.9312\n",
      "Epoch 034 | Train Loss: 0.0983 Acc: 0.9630 | Val Loss: 0.1738 Acc: 0.9384\n",
      "Epoch 035 | Train Loss: 0.1015 Acc: 0.9618 | Val Loss: 0.1583 Acc: 0.9366\n",
      "Epoch 036 | Train Loss: 0.1030 Acc: 0.9624 | Val Loss: 0.1578 Acc: 0.9444\n",
      "Epoch 037 | Train Loss: 0.1065 Acc: 0.9585 | Val Loss: 0.1845 Acc: 0.9281\n",
      "Epoch 038 | Train Loss: 0.0900 Acc: 0.9678 | Val Loss: 0.1953 Acc: 0.9312\n",
      "Epoch 039 | Train Loss: 0.0924 Acc: 0.9668 | Val Loss: 0.1685 Acc: 0.9420\n",
      "Epoch 040 | Train Loss: 0.0858 Acc: 0.9680 | Val Loss: 0.1549 Acc: 0.9408\n",
      "Epoch 041 | Train Loss: 0.0736 Acc: 0.9728 | Val Loss: 0.1596 Acc: 0.9414\n",
      "Epoch 042 | Train Loss: 0.0858 Acc: 0.9662 | Val Loss: 0.1812 Acc: 0.9354\n",
      "Epoch 043 | Train Loss: 0.0833 Acc: 0.9704 | Val Loss: 0.1746 Acc: 0.9342\n",
      "Epoch 044 | Train Loss: 0.0730 Acc: 0.9734 | Val Loss: 0.1705 Acc: 0.9438\n",
      "Epoch 045 | Train Loss: 0.0844 Acc: 0.9684 | Val Loss: 0.1597 Acc: 0.9450\n",
      "Epoch 046 | Train Loss: 0.0607 Acc: 0.9757 | Val Loss: 0.1491 Acc: 0.9463\n",
      "Epoch 047 | Train Loss: 0.0781 Acc: 0.9725 | Val Loss: 0.1569 Acc: 0.9444\n",
      "Epoch 048 | Train Loss: 0.0674 Acc: 0.9755 | Val Loss: 0.1824 Acc: 0.9432\n",
      "Epoch 049 | Train Loss: 0.0692 Acc: 0.9734 | Val Loss: 0.1591 Acc: 0.9499\n",
      "Epoch 050 | Train Loss: 0.0675 Acc: 0.9774 | Val Loss: 0.1498 Acc: 0.9444\n",
      "Epoch 051 | Train Loss: 0.0587 Acc: 0.9801 | Val Loss: 0.1526 Acc: 0.9505\n",
      "Epoch 052 | Train Loss: 0.0670 Acc: 0.9778 | Val Loss: 0.1329 Acc: 0.9487\n",
      "Epoch 053 | Train Loss: 0.0676 Acc: 0.9734 | Val Loss: 0.1575 Acc: 0.9463\n",
      "Epoch 054 | Train Loss: 0.0568 Acc: 0.9793 | Val Loss: 0.1601 Acc: 0.9457\n",
      "Epoch 055 | Train Loss: 0.0705 Acc: 0.9728 | Val Loss: 0.1862 Acc: 0.9378\n",
      "Epoch 056 | Train Loss: 0.0616 Acc: 0.9787 | Val Loss: 0.1469 Acc: 0.9505\n",
      "Epoch 057 | Train Loss: 0.0568 Acc: 0.9813 | Val Loss: 0.1395 Acc: 0.9559\n",
      "Epoch 058 | Train Loss: 0.0567 Acc: 0.9798 | Val Loss: 0.1595 Acc: 0.9511\n",
      "Epoch 059 | Train Loss: 0.0545 Acc: 0.9801 | Val Loss: 0.1543 Acc: 0.9547\n",
      "Epoch 060 | Train Loss: 0.0530 Acc: 0.9808 | Val Loss: 0.1734 Acc: 0.9420\n",
      "Epoch 001 | Train Loss: 0.6802 Acc: 0.5787 | Val Loss: 0.6738 Acc: 0.5882\n",
      "Epoch 002 | Train Loss: 0.6738 Acc: 0.5946 | Val Loss: 0.6579 Acc: 0.6014\n",
      "Epoch 003 | Train Loss: 0.6573 Acc: 0.6189 | Val Loss: 0.6408 Acc: 0.6359\n",
      "Epoch 004 | Train Loss: 0.6169 Acc: 0.6826 | Val Loss: 0.6144 Acc: 0.6769\n",
      "Epoch 005 | Train Loss: 0.5806 Acc: 0.7151 | Val Loss: 0.5649 Acc: 0.7059\n",
      "Epoch 006 | Train Loss: 0.5695 Acc: 0.7164 | Val Loss: 0.5799 Acc: 0.7077\n",
      "Epoch 007 | Train Loss: 0.5482 Acc: 0.7365 | Val Loss: 0.5493 Acc: 0.7180\n",
      "Epoch 008 | Train Loss: 0.5462 Acc: 0.7349 | Val Loss: 0.5493 Acc: 0.7156\n",
      "Epoch 009 | Train Loss: 0.5354 Acc: 0.7401 | Val Loss: 0.5350 Acc: 0.7428\n",
      "Epoch 010 | Train Loss: 0.5153 Acc: 0.7534 | Val Loss: 0.5472 Acc: 0.7295\n",
      "Epoch 011 | Train Loss: 0.5087 Acc: 0.7571 | Val Loss: 0.5139 Acc: 0.7409\n",
      "Epoch 012 | Train Loss: 0.4909 Acc: 0.7679 | Val Loss: 0.4969 Acc: 0.7560\n",
      "Epoch 013 | Train Loss: 0.4774 Acc: 0.7729 | Val Loss: 0.4919 Acc: 0.7736\n",
      "Epoch 014 | Train Loss: 0.4702 Acc: 0.7791 | Val Loss: 0.4718 Acc: 0.7766\n",
      "Epoch 015 | Train Loss: 0.4539 Acc: 0.7904 | Val Loss: 0.4501 Acc: 0.7832\n",
      "Epoch 016 | Train Loss: 0.4402 Acc: 0.7953 | Val Loss: 0.4671 Acc: 0.7681\n",
      "Epoch 017 | Train Loss: 0.4232 Acc: 0.8102 | Val Loss: 0.4299 Acc: 0.7911\n",
      "Epoch 018 | Train Loss: 0.3949 Acc: 0.8241 | Val Loss: 0.4040 Acc: 0.8158\n",
      "Epoch 019 | Train Loss: 0.3956 Acc: 0.8230 | Val Loss: 0.4096 Acc: 0.8062\n",
      "Epoch 020 | Train Loss: 0.3833 Acc: 0.8318 | Val Loss: 0.3906 Acc: 0.8200\n",
      "Epoch 021 | Train Loss: 0.3593 Acc: 0.8410 | Val Loss: 0.4016 Acc: 0.8188\n",
      "Epoch 022 | Train Loss: 0.3498 Acc: 0.8428 | Val Loss: 0.3670 Acc: 0.8243\n",
      "Epoch 023 | Train Loss: 0.3355 Acc: 0.8555 | Val Loss: 0.3669 Acc: 0.8351\n",
      "Epoch 024 | Train Loss: 0.3323 Acc: 0.8564 | Val Loss: 0.2977 Acc: 0.8714\n",
      "Epoch 025 | Train Loss: 0.3095 Acc: 0.8709 | Val Loss: 0.3139 Acc: 0.8665\n",
      "Epoch 026 | Train Loss: 0.3005 Acc: 0.8760 | Val Loss: 0.3188 Acc: 0.8696\n",
      "Epoch 027 | Train Loss: 0.2788 Acc: 0.8869 | Val Loss: 0.3046 Acc: 0.8738\n",
      "Epoch 028 | Train Loss: 0.2859 Acc: 0.8801 | Val Loss: 0.3001 Acc: 0.8623\n",
      "Epoch 029 | Train Loss: 0.2614 Acc: 0.8925 | Val Loss: 0.2862 Acc: 0.8786\n",
      "Epoch 030 | Train Loss: 0.2577 Acc: 0.8926 | Val Loss: 0.2466 Acc: 0.8925\n",
      "Epoch 031 | Train Loss: 0.2392 Acc: 0.9083 | Val Loss: 0.2641 Acc: 0.8859\n",
      "Epoch 032 | Train Loss: 0.2397 Acc: 0.9067 | Val Loss: 0.2505 Acc: 0.8919\n",
      "Epoch 033 | Train Loss: 0.2276 Acc: 0.9108 | Val Loss: 0.2400 Acc: 0.8961\n",
      "Epoch 034 | Train Loss: 0.2221 Acc: 0.9138 | Val Loss: 0.2701 Acc: 0.8925\n",
      "Epoch 035 | Train Loss: 0.2162 Acc: 0.9141 | Val Loss: 0.2539 Acc: 0.9046\n",
      "Epoch 036 | Train Loss: 0.2022 Acc: 0.9194 | Val Loss: 0.2346 Acc: 0.9094\n",
      "Epoch 037 | Train Loss: 0.2046 Acc: 0.9206 | Val Loss: 0.2252 Acc: 0.9136\n",
      "Epoch 038 | Train Loss: 0.1903 Acc: 0.9238 | Val Loss: 0.2398 Acc: 0.9064\n",
      "Epoch 039 | Train Loss: 0.1780 Acc: 0.9275 | Val Loss: 0.2380 Acc: 0.9040\n",
      "Epoch 040 | Train Loss: 0.1822 Acc: 0.9318 | Val Loss: 0.2348 Acc: 0.9052\n",
      "Epoch 041 | Train Loss: 0.1867 Acc: 0.9293 | Val Loss: 0.3524 Acc: 0.8635\n",
      "Epoch 042 | Train Loss: 0.1850 Acc: 0.9286 | Val Loss: 0.2162 Acc: 0.9161\n",
      "Epoch 043 | Train Loss: 0.1779 Acc: 0.9322 | Val Loss: 0.2094 Acc: 0.9245\n",
      "Epoch 044 | Train Loss: 0.1711 Acc: 0.9351 | Val Loss: 0.2090 Acc: 0.9227\n",
      "Epoch 045 | Train Loss: 0.1649 Acc: 0.9381 | Val Loss: 0.2180 Acc: 0.9245\n",
      "Epoch 046 | Train Loss: 0.1504 Acc: 0.9434 | Val Loss: 0.2611 Acc: 0.9082\n",
      "Epoch 047 | Train Loss: 0.1505 Acc: 0.9419 | Val Loss: 0.2076 Acc: 0.9215\n",
      "Epoch 048 | Train Loss: 0.1550 Acc: 0.9428 | Val Loss: 0.1845 Acc: 0.9354\n",
      "Epoch 049 | Train Loss: 0.1410 Acc: 0.9491 | Val Loss: 0.1983 Acc: 0.9191\n",
      "Epoch 050 | Train Loss: 0.1427 Acc: 0.9485 | Val Loss: 0.1954 Acc: 0.9215\n",
      "Epoch 051 | Train Loss: 0.1365 Acc: 0.9470 | Val Loss: 0.2298 Acc: 0.9281\n",
      "Epoch 052 | Train Loss: 0.1367 Acc: 0.9481 | Val Loss: 0.1972 Acc: 0.9281\n",
      "Epoch 053 | Train Loss: 0.1392 Acc: 0.9469 | Val Loss: 0.1940 Acc: 0.9251\n",
      "Epoch 054 | Train Loss: 0.1356 Acc: 0.9497 | Val Loss: 0.1837 Acc: 0.9348\n",
      "Epoch 055 | Train Loss: 0.1384 Acc: 0.9459 | Val Loss: 0.1839 Acc: 0.9366\n",
      "Epoch 056 | Train Loss: 0.1240 Acc: 0.9580 | Val Loss: 0.1725 Acc: 0.9366\n",
      "Epoch 057 | Train Loss: 0.1287 Acc: 0.9506 | Val Loss: 0.1907 Acc: 0.9330\n",
      "Epoch 058 | Train Loss: 0.1277 Acc: 0.9473 | Val Loss: 0.1723 Acc: 0.9360\n",
      "Epoch 059 | Train Loss: 0.1295 Acc: 0.9539 | Val Loss: 0.1820 Acc: 0.9426\n",
      "Epoch 060 | Train Loss: 0.1138 Acc: 0.9603 | Val Loss: 0.1796 Acc: 0.9324\n",
      "Epoch 001 | Train Loss: 0.6812 Acc: 0.5716 | Val Loss: 0.6834 Acc: 0.5743\n",
      "Epoch 002 | Train Loss: 0.6776 Acc: 0.5886 | Val Loss: 0.6749 Acc: 0.5821\n",
      "Epoch 003 | Train Loss: 0.6698 Acc: 0.5973 | Val Loss: 0.6609 Acc: 0.6027\n",
      "Epoch 004 | Train Loss: 0.6551 Acc: 0.6169 | Val Loss: 0.6306 Acc: 0.6588\n",
      "Epoch 005 | Train Loss: 0.6113 Acc: 0.6791 | Val Loss: 0.5913 Acc: 0.7005\n",
      "Epoch 006 | Train Loss: 0.5703 Acc: 0.7175 | Val Loss: 0.5657 Acc: 0.7053\n",
      "Epoch 007 | Train Loss: 0.5556 Acc: 0.7223 | Val Loss: 0.5494 Acc: 0.7150\n",
      "Epoch 008 | Train Loss: 0.5337 Acc: 0.7424 | Val Loss: 0.5234 Acc: 0.7367\n",
      "Epoch 009 | Train Loss: 0.5216 Acc: 0.7450 | Val Loss: 0.5225 Acc: 0.7313\n",
      "Epoch 010 | Train Loss: 0.5065 Acc: 0.7555 | Val Loss: 0.5510 Acc: 0.7162\n",
      "Epoch 011 | Train Loss: 0.4936 Acc: 0.7622 | Val Loss: 0.4906 Acc: 0.7512\n",
      "Epoch 012 | Train Loss: 0.4686 Acc: 0.7756 | Val Loss: 0.4686 Acc: 0.7651\n",
      "Epoch 013 | Train Loss: 0.4657 Acc: 0.7743 | Val Loss: 0.4872 Acc: 0.7597\n",
      "Epoch 014 | Train Loss: 0.4495 Acc: 0.7865 | Val Loss: 0.4264 Acc: 0.8001\n",
      "Epoch 015 | Train Loss: 0.4262 Acc: 0.7986 | Val Loss: 0.4591 Acc: 0.7663\n",
      "Epoch 016 | Train Loss: 0.4164 Acc: 0.8051 | Val Loss: 0.4077 Acc: 0.8092\n",
      "Epoch 017 | Train Loss: 0.4165 Acc: 0.8054 | Val Loss: 0.4182 Acc: 0.8037\n",
      "Epoch 018 | Train Loss: 0.3863 Acc: 0.8247 | Val Loss: 0.3700 Acc: 0.8357\n",
      "Epoch 019 | Train Loss: 0.3646 Acc: 0.8359 | Val Loss: 0.3559 Acc: 0.8448\n",
      "Epoch 020 | Train Loss: 0.3403 Acc: 0.8520 | Val Loss: 0.3488 Acc: 0.8502\n",
      "Epoch 021 | Train Loss: 0.3432 Acc: 0.8504 | Val Loss: 0.3273 Acc: 0.8629\n",
      "Epoch 022 | Train Loss: 0.3129 Acc: 0.8685 | Val Loss: 0.3116 Acc: 0.8635\n",
      "Epoch 023 | Train Loss: 0.3065 Acc: 0.8712 | Val Loss: 0.2982 Acc: 0.8732\n",
      "Epoch 024 | Train Loss: 0.2937 Acc: 0.8748 | Val Loss: 0.2946 Acc: 0.8696\n",
      "Epoch 025 | Train Loss: 0.2819 Acc: 0.8803 | Val Loss: 0.2886 Acc: 0.8804\n",
      "Epoch 026 | Train Loss: 0.2682 Acc: 0.8893 | Val Loss: 0.2756 Acc: 0.8865\n",
      "Epoch 027 | Train Loss: 0.2534 Acc: 0.8981 | Val Loss: 0.2643 Acc: 0.8907\n",
      "Epoch 028 | Train Loss: 0.2510 Acc: 0.8972 | Val Loss: 0.2587 Acc: 0.8967\n",
      "Epoch 029 | Train Loss: 0.2477 Acc: 0.8981 | Val Loss: 0.2518 Acc: 0.8979\n",
      "Epoch 030 | Train Loss: 0.2262 Acc: 0.9103 | Val Loss: 0.2283 Acc: 0.9040\n",
      "Epoch 031 | Train Loss: 0.2218 Acc: 0.9096 | Val Loss: 0.2633 Acc: 0.8949\n",
      "Epoch 032 | Train Loss: 0.2232 Acc: 0.9071 | Val Loss: 0.2321 Acc: 0.9076\n",
      "Epoch 033 | Train Loss: 0.2095 Acc: 0.9162 | Val Loss: 0.2399 Acc: 0.8937\n",
      "Epoch 034 | Train Loss: 0.2133 Acc: 0.9135 | Val Loss: 0.2148 Acc: 0.9100\n",
      "Epoch 035 | Train Loss: 0.1928 Acc: 0.9209 | Val Loss: 0.2306 Acc: 0.9100\n",
      "Epoch 036 | Train Loss: 0.1967 Acc: 0.9203 | Val Loss: 0.2321 Acc: 0.9100\n",
      "Epoch 037 | Train Loss: 0.1777 Acc: 0.9328 | Val Loss: 0.2245 Acc: 0.9082\n",
      "Epoch 038 | Train Loss: 0.1804 Acc: 0.9299 | Val Loss: 0.2156 Acc: 0.9088\n",
      "Epoch 039 | Train Loss: 0.1681 Acc: 0.9328 | Val Loss: 0.2080 Acc: 0.9233\n",
      "Epoch 040 | Train Loss: 0.1606 Acc: 0.9381 | Val Loss: 0.1943 Acc: 0.9221\n",
      "Epoch 041 | Train Loss: 0.1503 Acc: 0.9407 | Val Loss: 0.2353 Acc: 0.9173\n",
      "Epoch 042 | Train Loss: 0.1596 Acc: 0.9378 | Val Loss: 0.2172 Acc: 0.9124\n",
      "Epoch 043 | Train Loss: 0.1457 Acc: 0.9428 | Val Loss: 0.2118 Acc: 0.9185\n",
      "Epoch 044 | Train Loss: 0.1586 Acc: 0.9396 | Val Loss: 0.1839 Acc: 0.9330\n",
      "Epoch 045 | Train Loss: 0.1367 Acc: 0.9490 | Val Loss: 0.2187 Acc: 0.9130\n",
      "Epoch 046 | Train Loss: 0.1241 Acc: 0.9503 | Val Loss: 0.2001 Acc: 0.9330\n",
      "Epoch 047 | Train Loss: 0.1350 Acc: 0.9493 | Val Loss: 0.2047 Acc: 0.9245\n",
      "Epoch 048 | Train Loss: 0.1315 Acc: 0.9485 | Val Loss: 0.2059 Acc: 0.9203\n",
      "Epoch 049 | Train Loss: 0.1360 Acc: 0.9447 | Val Loss: 0.1806 Acc: 0.9306\n",
      "Epoch 050 | Train Loss: 0.1218 Acc: 0.9562 | Val Loss: 0.2106 Acc: 0.9275\n",
      "Epoch 051 | Train Loss: 0.1347 Acc: 0.9455 | Val Loss: 0.1765 Acc: 0.9354\n",
      "Epoch 052 | Train Loss: 0.1098 Acc: 0.9592 | Val Loss: 0.2258 Acc: 0.9197\n",
      "Epoch 053 | Train Loss: 0.1230 Acc: 0.9535 | Val Loss: 0.1741 Acc: 0.9372\n",
      "Epoch 054 | Train Loss: 0.1151 Acc: 0.9562 | Val Loss: 0.1705 Acc: 0.9420\n",
      "Epoch 055 | Train Loss: 0.1143 Acc: 0.9564 | Val Loss: 0.1646 Acc: 0.9366\n",
      "Epoch 056 | Train Loss: 0.1047 Acc: 0.9620 | Val Loss: 0.1783 Acc: 0.9384\n",
      "Epoch 057 | Train Loss: 0.1226 Acc: 0.9532 | Val Loss: 0.1844 Acc: 0.9366\n",
      "Epoch 058 | Train Loss: 0.1080 Acc: 0.9583 | Val Loss: 0.2011 Acc: 0.9215\n",
      "Epoch 059 | Train Loss: 0.1070 Acc: 0.9623 | Val Loss: 0.1935 Acc: 0.9275\n",
      "Epoch 060 | Train Loss: 0.1004 Acc: 0.9610 | Val Loss: 0.1852 Acc: 0.9330\n",
      "Epoch 001 | Train Loss: 0.6793 Acc: 0.5792 | Val Loss: 0.6839 Acc: 0.5610\n",
      "Epoch 002 | Train Loss: 0.6748 Acc: 0.5922 | Val Loss: 0.6735 Acc: 0.5857\n",
      "Epoch 003 | Train Loss: 0.6655 Acc: 0.6020 | Val Loss: 0.6289 Acc: 0.6624\n",
      "Epoch 004 | Train Loss: 0.6048 Acc: 0.6852 | Val Loss: 0.5907 Acc: 0.6920\n",
      "Epoch 005 | Train Loss: 0.5498 Acc: 0.7243 | Val Loss: 0.5513 Acc: 0.7234\n",
      "Epoch 006 | Train Loss: 0.5289 Acc: 0.7442 | Val Loss: 0.5271 Acc: 0.7391\n",
      "Epoch 007 | Train Loss: 0.5055 Acc: 0.7592 | Val Loss: 0.4939 Acc: 0.7651\n",
      "Epoch 008 | Train Loss: 0.4867 Acc: 0.7649 | Val Loss: 0.4693 Acc: 0.7790\n",
      "Epoch 009 | Train Loss: 0.4601 Acc: 0.7859 | Val Loss: 0.4448 Acc: 0.7893\n",
      "Epoch 010 | Train Loss: 0.4395 Acc: 0.7983 | Val Loss: 0.4295 Acc: 0.7935\n",
      "Epoch 011 | Train Loss: 0.4203 Acc: 0.8102 | Val Loss: 0.4332 Acc: 0.7929\n",
      "Epoch 012 | Train Loss: 0.4005 Acc: 0.8190 | Val Loss: 0.3845 Acc: 0.8068\n",
      "Epoch 013 | Train Loss: 0.3905 Acc: 0.8252 | Val Loss: 0.3766 Acc: 0.8225\n",
      "Epoch 014 | Train Loss: 0.3638 Acc: 0.8404 | Val Loss: 0.3278 Acc: 0.8472\n",
      "Epoch 015 | Train Loss: 0.3296 Acc: 0.8585 | Val Loss: 0.3145 Acc: 0.8581\n",
      "Epoch 016 | Train Loss: 0.3058 Acc: 0.8712 | Val Loss: 0.3029 Acc: 0.8611\n",
      "Epoch 017 | Train Loss: 0.2859 Acc: 0.8780 | Val Loss: 0.2969 Acc: 0.8647\n",
      "Epoch 018 | Train Loss: 0.2745 Acc: 0.8886 | Val Loss: 0.2753 Acc: 0.8792\n",
      "Epoch 019 | Train Loss: 0.2546 Acc: 0.8946 | Val Loss: 0.2661 Acc: 0.8847\n",
      "Epoch 020 | Train Loss: 0.2322 Acc: 0.9073 | Val Loss: 0.2506 Acc: 0.8931\n",
      "Epoch 021 | Train Loss: 0.2251 Acc: 0.9073 | Val Loss: 0.2194 Acc: 0.9124\n",
      "Epoch 022 | Train Loss: 0.2045 Acc: 0.9204 | Val Loss: 0.2070 Acc: 0.9118\n",
      "Epoch 023 | Train Loss: 0.2003 Acc: 0.9177 | Val Loss: 0.2380 Acc: 0.8986\n",
      "Epoch 024 | Train Loss: 0.1905 Acc: 0.9253 | Val Loss: 0.2186 Acc: 0.9076\n",
      "Epoch 025 | Train Loss: 0.1885 Acc: 0.9233 | Val Loss: 0.2183 Acc: 0.9143\n",
      "Epoch 026 | Train Loss: 0.1650 Acc: 0.9325 | Val Loss: 0.2179 Acc: 0.9082\n",
      "Epoch 027 | Train Loss: 0.1521 Acc: 0.9414 | Val Loss: 0.2241 Acc: 0.9058\n",
      "Epoch 028 | Train Loss: 0.1585 Acc: 0.9393 | Val Loss: 0.2102 Acc: 0.9155\n",
      "Epoch 029 | Train Loss: 0.1414 Acc: 0.9465 | Val Loss: 0.1958 Acc: 0.9209\n",
      "Epoch 030 | Train Loss: 0.1549 Acc: 0.9401 | Val Loss: 0.1797 Acc: 0.9281\n",
      "Epoch 031 | Train Loss: 0.1272 Acc: 0.9509 | Val Loss: 0.1903 Acc: 0.9330\n",
      "Epoch 032 | Train Loss: 0.1249 Acc: 0.9526 | Val Loss: 0.1622 Acc: 0.9396\n",
      "Epoch 033 | Train Loss: 0.1276 Acc: 0.9526 | Val Loss: 0.1725 Acc: 0.9300\n",
      "Epoch 034 | Train Loss: 0.1266 Acc: 0.9550 | Val Loss: 0.1581 Acc: 0.9372\n",
      "Epoch 035 | Train Loss: 0.1312 Acc: 0.9515 | Val Loss: 0.1911 Acc: 0.9251\n",
      "Epoch 036 | Train Loss: 0.1096 Acc: 0.9586 | Val Loss: 0.1662 Acc: 0.9366\n",
      "Epoch 037 | Train Loss: 0.1076 Acc: 0.9601 | Val Loss: 0.1814 Acc: 0.9300\n",
      "Epoch 038 | Train Loss: 0.1001 Acc: 0.9592 | Val Loss: 0.1910 Acc: 0.9306\n",
      "Epoch 039 | Train Loss: 0.1064 Acc: 0.9582 | Val Loss: 0.1637 Acc: 0.9306\n",
      "Epoch 040 | Train Loss: 0.1081 Acc: 0.9576 | Val Loss: 0.1642 Acc: 0.9414\n",
      "Epoch 041 | Train Loss: 0.0971 Acc: 0.9653 | Val Loss: 0.1613 Acc: 0.9420\n",
      "Epoch 042 | Train Loss: 0.0949 Acc: 0.9665 | Val Loss: 0.1836 Acc: 0.9330\n",
      "Epoch 043 | Train Loss: 0.0981 Acc: 0.9638 | Val Loss: 0.1575 Acc: 0.9414\n",
      "Epoch 044 | Train Loss: 0.1055 Acc: 0.9603 | Val Loss: 0.1549 Acc: 0.9390\n",
      "Epoch 045 | Train Loss: 0.0943 Acc: 0.9638 | Val Loss: 0.1377 Acc: 0.9450\n",
      "Epoch 046 | Train Loss: 0.0892 Acc: 0.9675 | Val Loss: 0.1565 Acc: 0.9438\n",
      "Epoch 047 | Train Loss: 0.0868 Acc: 0.9656 | Val Loss: 0.1266 Acc: 0.9481\n",
      "Epoch 048 | Train Loss: 0.0891 Acc: 0.9660 | Val Loss: 0.1306 Acc: 0.9505\n",
      "Epoch 049 | Train Loss: 0.0750 Acc: 0.9686 | Val Loss: 0.1383 Acc: 0.9444\n",
      "Epoch 050 | Train Loss: 0.0876 Acc: 0.9674 | Val Loss: 0.1513 Acc: 0.9360\n",
      "Epoch 051 | Train Loss: 0.0864 Acc: 0.9690 | Val Loss: 0.1329 Acc: 0.9444\n",
      "Epoch 052 | Train Loss: 0.0744 Acc: 0.9728 | Val Loss: 0.1469 Acc: 0.9444\n",
      "Epoch 053 | Train Loss: 0.0853 Acc: 0.9689 | Val Loss: 0.1137 Acc: 0.9553\n",
      "Epoch 054 | Train Loss: 0.0692 Acc: 0.9709 | Val Loss: 0.1588 Acc: 0.9372\n",
      "Epoch 055 | Train Loss: 0.0797 Acc: 0.9703 | Val Loss: 0.1586 Acc: 0.9438\n",
      "Epoch 056 | Train Loss: 0.0760 Acc: 0.9713 | Val Loss: 0.1323 Acc: 0.9463\n",
      "Epoch 057 | Train Loss: 0.0661 Acc: 0.9774 | Val Loss: 0.1340 Acc: 0.9475\n",
      "Epoch 058 | Train Loss: 0.0746 Acc: 0.9734 | Val Loss: 0.1361 Acc: 0.9487\n",
      "Epoch 059 | Train Loss: 0.0703 Acc: 0.9731 | Val Loss: 0.1803 Acc: 0.9324\n",
      "Epoch 060 | Train Loss: 0.0778 Acc: 0.9719 | Val Loss: 0.1285 Acc: 0.9493\n",
      "Epoch 001 | Train Loss: 0.6801 Acc: 0.5819 | Val Loss: 0.6745 Acc: 0.5894\n",
      "Epoch 002 | Train Loss: 0.6704 Acc: 0.5964 | Val Loss: 0.6698 Acc: 0.5978\n",
      "Epoch 003 | Train Loss: 0.6549 Acc: 0.6258 | Val Loss: 0.6341 Acc: 0.6588\n",
      "Epoch 004 | Train Loss: 0.6311 Acc: 0.6556 | Val Loss: 0.6296 Acc: 0.6594\n",
      "Epoch 005 | Train Loss: 0.5984 Acc: 0.6941 | Val Loss: 0.5881 Acc: 0.6993\n",
      "Epoch 006 | Train Loss: 0.5658 Acc: 0.7190 | Val Loss: 0.5728 Acc: 0.7071\n",
      "Epoch 007 | Train Loss: 0.5421 Acc: 0.7321 | Val Loss: 0.5449 Acc: 0.7240\n",
      "Epoch 008 | Train Loss: 0.5197 Acc: 0.7539 | Val Loss: 0.5229 Acc: 0.7355\n",
      "Epoch 009 | Train Loss: 0.5019 Acc: 0.7625 | Val Loss: 0.4910 Acc: 0.7609\n",
      "Epoch 010 | Train Loss: 0.4717 Acc: 0.7791 | Val Loss: 0.4700 Acc: 0.7711\n",
      "Epoch 011 | Train Loss: 0.4501 Acc: 0.7968 | Val Loss: 0.4422 Acc: 0.7820\n",
      "Epoch 012 | Train Loss: 0.4281 Acc: 0.8037 | Val Loss: 0.4087 Acc: 0.8122\n",
      "Epoch 013 | Train Loss: 0.4052 Acc: 0.8164 | Val Loss: 0.4194 Acc: 0.8007\n",
      "Epoch 014 | Train Loss: 0.3781 Acc: 0.8286 | Val Loss: 0.3848 Acc: 0.8237\n",
      "Epoch 015 | Train Loss: 0.3631 Acc: 0.8380 | Val Loss: 0.3761 Acc: 0.8382\n",
      "Epoch 016 | Train Loss: 0.3420 Acc: 0.8510 | Val Loss: 0.3511 Acc: 0.8563\n",
      "Epoch 017 | Train Loss: 0.3160 Acc: 0.8588 | Val Loss: 0.3244 Acc: 0.8605\n",
      "Epoch 018 | Train Loss: 0.2912 Acc: 0.8772 | Val Loss: 0.2896 Acc: 0.8762\n",
      "Epoch 019 | Train Loss: 0.2713 Acc: 0.8904 | Val Loss: 0.3033 Acc: 0.8629\n",
      "Epoch 020 | Train Loss: 0.2498 Acc: 0.8946 | Val Loss: 0.2565 Acc: 0.8943\n",
      "Epoch 021 | Train Loss: 0.2452 Acc: 0.8976 | Val Loss: 0.2712 Acc: 0.8798\n",
      "Epoch 022 | Train Loss: 0.2362 Acc: 0.9031 | Val Loss: 0.2543 Acc: 0.8901\n",
      "Epoch 023 | Train Loss: 0.2055 Acc: 0.9185 | Val Loss: 0.2531 Acc: 0.8955\n",
      "Epoch 024 | Train Loss: 0.1954 Acc: 0.9212 | Val Loss: 0.2162 Acc: 0.9094\n",
      "Epoch 025 | Train Loss: 0.1915 Acc: 0.9242 | Val Loss: 0.2184 Acc: 0.9100\n",
      "Epoch 026 | Train Loss: 0.1739 Acc: 0.9313 | Val Loss: 0.1953 Acc: 0.9257\n",
      "Epoch 027 | Train Loss: 0.1624 Acc: 0.9358 | Val Loss: 0.2138 Acc: 0.9167\n",
      "Epoch 028 | Train Loss: 0.1597 Acc: 0.9376 | Val Loss: 0.1870 Acc: 0.9251\n",
      "Epoch 029 | Train Loss: 0.1451 Acc: 0.9440 | Val Loss: 0.1875 Acc: 0.9227\n",
      "Epoch 030 | Train Loss: 0.1467 Acc: 0.9458 | Val Loss: 0.1813 Acc: 0.9287\n",
      "Epoch 031 | Train Loss: 0.1380 Acc: 0.9464 | Val Loss: 0.1707 Acc: 0.9306\n",
      "Epoch 032 | Train Loss: 0.1213 Acc: 0.9530 | Val Loss: 0.1709 Acc: 0.9336\n",
      "Epoch 033 | Train Loss: 0.1310 Acc: 0.9506 | Val Loss: 0.1693 Acc: 0.9378\n",
      "Epoch 034 | Train Loss: 0.1130 Acc: 0.9564 | Val Loss: 0.1665 Acc: 0.9390\n",
      "Epoch 035 | Train Loss: 0.1097 Acc: 0.9583 | Val Loss: 0.1640 Acc: 0.9408\n",
      "Epoch 036 | Train Loss: 0.1069 Acc: 0.9600 | Val Loss: 0.1814 Acc: 0.9293\n",
      "Epoch 037 | Train Loss: 0.1011 Acc: 0.9616 | Val Loss: 0.1429 Acc: 0.9438\n",
      "Epoch 038 | Train Loss: 0.0959 Acc: 0.9629 | Val Loss: 0.1363 Acc: 0.9475\n",
      "Epoch 039 | Train Loss: 0.0817 Acc: 0.9677 | Val Loss: 0.1691 Acc: 0.9390\n",
      "Epoch 040 | Train Loss: 0.1031 Acc: 0.9609 | Val Loss: 0.1486 Acc: 0.9438\n",
      "Epoch 041 | Train Loss: 0.0836 Acc: 0.9681 | Val Loss: 0.1347 Acc: 0.9523\n",
      "Epoch 042 | Train Loss: 0.0790 Acc: 0.9695 | Val Loss: 0.1443 Acc: 0.9493\n",
      "Epoch 043 | Train Loss: 0.0861 Acc: 0.9672 | Val Loss: 0.1452 Acc: 0.9463\n",
      "Epoch 044 | Train Loss: 0.0785 Acc: 0.9721 | Val Loss: 0.2092 Acc: 0.9167\n",
      "Epoch 045 | Train Loss: 0.0808 Acc: 0.9703 | Val Loss: 0.1594 Acc: 0.9487\n",
      "Epoch 046 | Train Loss: 0.0766 Acc: 0.9698 | Val Loss: 0.1576 Acc: 0.9450\n",
      "Epoch 047 | Train Loss: 0.0695 Acc: 0.9745 | Val Loss: 0.1867 Acc: 0.9293\n",
      "Epoch 048 | Train Loss: 0.0651 Acc: 0.9767 | Val Loss: 0.1596 Acc: 0.9499\n",
      "Epoch 049 | Train Loss: 0.0691 Acc: 0.9767 | Val Loss: 0.1567 Acc: 0.9475\n",
      "Epoch 050 | Train Loss: 0.0704 Acc: 0.9734 | Val Loss: 0.1403 Acc: 0.9535\n",
      "Epoch 051 | Train Loss: 0.0651 Acc: 0.9766 | Val Loss: 0.1464 Acc: 0.9535\n",
      "Early stopping triggered.\n",
      "Epoch 001 | Train Loss: 0.6808 Acc: 0.5765 | Val Loss: 0.6713 Acc: 0.5924\n",
      "Epoch 002 | Train Loss: 0.6696 Acc: 0.6000 | Val Loss: 0.6671 Acc: 0.6002\n",
      "Epoch 003 | Train Loss: 0.6588 Acc: 0.6159 | Val Loss: 0.6489 Acc: 0.6383\n",
      "Epoch 004 | Train Loss: 0.6299 Acc: 0.6618 | Val Loss: 0.6164 Acc: 0.6715\n",
      "Epoch 005 | Train Loss: 0.6207 Acc: 0.6727 | Val Loss: 0.6281 Acc: 0.6540\n",
      "Epoch 006 | Train Loss: 0.6081 Acc: 0.6896 | Val Loss: 0.5921 Acc: 0.7029\n",
      "Epoch 007 | Train Loss: 0.5699 Acc: 0.7228 | Val Loss: 0.5568 Acc: 0.7204\n",
      "Epoch 008 | Train Loss: 0.5557 Acc: 0.7377 | Val Loss: 0.5506 Acc: 0.7313\n",
      "Epoch 009 | Train Loss: 0.5428 Acc: 0.7417 | Val Loss: 0.5245 Acc: 0.7343\n",
      "Epoch 010 | Train Loss: 0.5234 Acc: 0.7475 | Val Loss: 0.5086 Acc: 0.7440\n",
      "Epoch 011 | Train Loss: 0.5195 Acc: 0.7501 | Val Loss: 0.5114 Acc: 0.7458\n",
      "Epoch 012 | Train Loss: 0.4960 Acc: 0.7658 | Val Loss: 0.4955 Acc: 0.7554\n",
      "Epoch 013 | Train Loss: 0.4899 Acc: 0.7670 | Val Loss: 0.4813 Acc: 0.7579\n",
      "Epoch 014 | Train Loss: 0.4692 Acc: 0.7800 | Val Loss: 0.4811 Acc: 0.7645\n",
      "Epoch 015 | Train Loss: 0.4632 Acc: 0.7853 | Val Loss: 0.4509 Acc: 0.7862\n",
      "Epoch 016 | Train Loss: 0.4537 Acc: 0.7903 | Val Loss: 0.4293 Acc: 0.7923\n",
      "Epoch 017 | Train Loss: 0.4367 Acc: 0.8034 | Val Loss: 0.4492 Acc: 0.7880\n",
      "Epoch 018 | Train Loss: 0.4290 Acc: 0.8028 | Val Loss: 0.4091 Acc: 0.8001\n",
      "Epoch 019 | Train Loss: 0.4199 Acc: 0.8088 | Val Loss: 0.4206 Acc: 0.7965\n",
      "Epoch 020 | Train Loss: 0.4010 Acc: 0.8165 | Val Loss: 0.4114 Acc: 0.7983\n",
      "Epoch 021 | Train Loss: 0.3858 Acc: 0.8270 | Val Loss: 0.3705 Acc: 0.8128\n",
      "Epoch 022 | Train Loss: 0.3800 Acc: 0.8286 | Val Loss: 0.3528 Acc: 0.8436\n",
      "Epoch 023 | Train Loss: 0.3583 Acc: 0.8396 | Val Loss: 0.3517 Acc: 0.8357\n",
      "Epoch 024 | Train Loss: 0.3687 Acc: 0.8365 | Val Loss: 0.3700 Acc: 0.8158\n",
      "Epoch 025 | Train Loss: 0.3422 Acc: 0.8505 | Val Loss: 0.3670 Acc: 0.8321\n",
      "Epoch 026 | Train Loss: 0.3292 Acc: 0.8603 | Val Loss: 0.3237 Acc: 0.8418\n",
      "Epoch 027 | Train Loss: 0.3236 Acc: 0.8603 | Val Loss: 0.3381 Acc: 0.8454\n",
      "Epoch 028 | Train Loss: 0.3102 Acc: 0.8644 | Val Loss: 0.2977 Acc: 0.8678\n",
      "Epoch 029 | Train Loss: 0.3079 Acc: 0.8686 | Val Loss: 0.3014 Acc: 0.8690\n",
      "Epoch 030 | Train Loss: 0.3019 Acc: 0.8727 | Val Loss: 0.3319 Acc: 0.8484\n",
      "Epoch 031 | Train Loss: 0.2888 Acc: 0.8775 | Val Loss: 0.3315 Acc: 0.8605\n",
      "Epoch 032 | Train Loss: 0.2678 Acc: 0.8857 | Val Loss: 0.2848 Acc: 0.8816\n",
      "Epoch 033 | Train Loss: 0.2609 Acc: 0.8911 | Val Loss: 0.2505 Acc: 0.8998\n",
      "Epoch 034 | Train Loss: 0.2664 Acc: 0.8848 | Val Loss: 0.2549 Acc: 0.8937\n",
      "Epoch 035 | Train Loss: 0.2544 Acc: 0.8961 | Val Loss: 0.2627 Acc: 0.8919\n",
      "Epoch 036 | Train Loss: 0.2618 Acc: 0.8923 | Val Loss: 0.2309 Acc: 0.9094\n",
      "Epoch 037 | Train Loss: 0.2451 Acc: 0.8997 | Val Loss: 0.2542 Acc: 0.9022\n",
      "Epoch 038 | Train Loss: 0.2352 Acc: 0.9053 | Val Loss: 0.2570 Acc: 0.8961\n",
      "Epoch 039 | Train Loss: 0.2364 Acc: 0.9032 | Val Loss: 0.2441 Acc: 0.9040\n",
      "Epoch 040 | Train Loss: 0.2337 Acc: 0.9043 | Val Loss: 0.2276 Acc: 0.9155\n",
      "Epoch 041 | Train Loss: 0.2231 Acc: 0.9088 | Val Loss: 0.2352 Acc: 0.9106\n",
      "Epoch 042 | Train Loss: 0.2356 Acc: 0.9022 | Val Loss: 0.2109 Acc: 0.9167\n",
      "Epoch 043 | Train Loss: 0.2073 Acc: 0.9198 | Val Loss: 0.2458 Acc: 0.8961\n",
      "Epoch 044 | Train Loss: 0.2079 Acc: 0.9180 | Val Loss: 0.2536 Acc: 0.8889\n",
      "Epoch 045 | Train Loss: 0.2097 Acc: 0.9173 | Val Loss: 0.2402 Acc: 0.9022\n",
      "Epoch 046 | Train Loss: 0.2055 Acc: 0.9141 | Val Loss: 0.2107 Acc: 0.9155\n",
      "Epoch 047 | Train Loss: 0.2000 Acc: 0.9230 | Val Loss: 0.2066 Acc: 0.9209\n",
      "Epoch 048 | Train Loss: 0.2062 Acc: 0.9161 | Val Loss: 0.2288 Acc: 0.9088\n",
      "Epoch 049 | Train Loss: 0.1896 Acc: 0.9239 | Val Loss: 0.2194 Acc: 0.9143\n",
      "Epoch 050 | Train Loss: 0.1917 Acc: 0.9278 | Val Loss: 0.2149 Acc: 0.9197\n",
      "Epoch 051 | Train Loss: 0.1763 Acc: 0.9345 | Val Loss: 0.2105 Acc: 0.9227\n",
      "Epoch 052 | Train Loss: 0.2033 Acc: 0.9198 | Val Loss: 0.2047 Acc: 0.9203\n",
      "Epoch 053 | Train Loss: 0.1688 Acc: 0.9333 | Val Loss: 0.2192 Acc: 0.9155\n",
      "Epoch 054 | Train Loss: 0.1827 Acc: 0.9289 | Val Loss: 0.2490 Acc: 0.9004\n",
      "Epoch 055 | Train Loss: 0.1684 Acc: 0.9370 | Val Loss: 0.2357 Acc: 0.9022\n",
      "Epoch 056 | Train Loss: 0.1749 Acc: 0.9367 | Val Loss: 0.2088 Acc: 0.9155\n",
      "Epoch 057 | Train Loss: 0.1737 Acc: 0.9304 | Val Loss: 0.1724 Acc: 0.9318\n",
      "Epoch 058 | Train Loss: 0.1610 Acc: 0.9360 | Val Loss: 0.2043 Acc: 0.9227\n",
      "Epoch 059 | Train Loss: 0.1501 Acc: 0.9402 | Val Loss: 0.2453 Acc: 0.8979\n",
      "Epoch 060 | Train Loss: 0.1568 Acc: 0.9349 | Val Loss: 0.1821 Acc: 0.9287\n",
      "Epoch 001 | Train Loss: 0.6820 Acc: 0.5673 | Val Loss: 0.6787 Acc: 0.5888\n",
      "Epoch 002 | Train Loss: 0.6712 Acc: 0.5975 | Val Loss: 0.6630 Acc: 0.6051\n",
      "Epoch 003 | Train Loss: 0.6245 Acc: 0.6607 | Val Loss: 0.5965 Acc: 0.6890\n",
      "Epoch 004 | Train Loss: 0.5762 Acc: 0.7075 | Val Loss: 0.5753 Acc: 0.7138\n",
      "Epoch 005 | Train Loss: 0.5459 Acc: 0.7335 | Val Loss: 0.5410 Acc: 0.7482\n",
      "Epoch 006 | Train Loss: 0.5170 Acc: 0.7510 | Val Loss: 0.5184 Acc: 0.7566\n",
      "Epoch 007 | Train Loss: 0.5018 Acc: 0.7548 | Val Loss: 0.5041 Acc: 0.7542\n",
      "Epoch 008 | Train Loss: 0.4781 Acc: 0.7720 | Val Loss: 0.4794 Acc: 0.7681\n",
      "Epoch 009 | Train Loss: 0.4553 Acc: 0.7924 | Val Loss: 0.4508 Acc: 0.7880\n",
      "Epoch 010 | Train Loss: 0.4315 Acc: 0.8042 | Val Loss: 0.4146 Acc: 0.8025\n",
      "Epoch 011 | Train Loss: 0.3950 Acc: 0.8232 | Val Loss: 0.3940 Acc: 0.8182\n",
      "Epoch 012 | Train Loss: 0.3743 Acc: 0.8378 | Val Loss: 0.3747 Acc: 0.8333\n",
      "Epoch 013 | Train Loss: 0.3470 Acc: 0.8502 | Val Loss: 0.3565 Acc: 0.8478\n",
      "Epoch 014 | Train Loss: 0.3117 Acc: 0.8664 | Val Loss: 0.3120 Acc: 0.8684\n",
      "Epoch 015 | Train Loss: 0.2931 Acc: 0.8751 | Val Loss: 0.2929 Acc: 0.8726\n",
      "Epoch 016 | Train Loss: 0.2889 Acc: 0.8795 | Val Loss: 0.3242 Acc: 0.8629\n",
      "Epoch 017 | Train Loss: 0.2556 Acc: 0.8969 | Val Loss: 0.2602 Acc: 0.8925\n",
      "Epoch 018 | Train Loss: 0.2402 Acc: 0.9010 | Val Loss: 0.2424 Acc: 0.8913\n",
      "Epoch 019 | Train Loss: 0.2339 Acc: 0.9047 | Val Loss: 0.2322 Acc: 0.9028\n",
      "Epoch 020 | Train Loss: 0.2190 Acc: 0.9133 | Val Loss: 0.2365 Acc: 0.9016\n",
      "Epoch 021 | Train Loss: 0.2023 Acc: 0.9224 | Val Loss: 0.2148 Acc: 0.9136\n",
      "Epoch 022 | Train Loss: 0.1854 Acc: 0.9275 | Val Loss: 0.2704 Acc: 0.8992\n",
      "Epoch 023 | Train Loss: 0.1777 Acc: 0.9275 | Val Loss: 0.1951 Acc: 0.9233\n",
      "Epoch 024 | Train Loss: 0.1660 Acc: 0.9358 | Val Loss: 0.1764 Acc: 0.9287\n",
      "Epoch 025 | Train Loss: 0.1643 Acc: 0.9345 | Val Loss: 0.2228 Acc: 0.9124\n",
      "Epoch 026 | Train Loss: 0.1601 Acc: 0.9369 | Val Loss: 0.1902 Acc: 0.9173\n",
      "Epoch 027 | Train Loss: 0.1397 Acc: 0.9467 | Val Loss: 0.1787 Acc: 0.9300\n",
      "Epoch 028 | Train Loss: 0.1370 Acc: 0.9505 | Val Loss: 0.1907 Acc: 0.9287\n",
      "Epoch 029 | Train Loss: 0.1261 Acc: 0.9494 | Val Loss: 0.2365 Acc: 0.9076\n",
      "Epoch 030 | Train Loss: 0.1163 Acc: 0.9562 | Val Loss: 0.1593 Acc: 0.9372\n",
      "Epoch 031 | Train Loss: 0.1266 Acc: 0.9505 | Val Loss: 0.1490 Acc: 0.9360\n",
      "Epoch 032 | Train Loss: 0.1145 Acc: 0.9564 | Val Loss: 0.1756 Acc: 0.9318\n",
      "Epoch 033 | Train Loss: 0.1031 Acc: 0.9582 | Val Loss: 0.1570 Acc: 0.9414\n",
      "Epoch 034 | Train Loss: 0.1080 Acc: 0.9597 | Val Loss: 0.1636 Acc: 0.9396\n",
      "Epoch 035 | Train Loss: 0.1004 Acc: 0.9612 | Val Loss: 0.1875 Acc: 0.9251\n",
      "Epoch 036 | Train Loss: 0.0968 Acc: 0.9616 | Val Loss: 0.1646 Acc: 0.9372\n",
      "Epoch 037 | Train Loss: 0.0878 Acc: 0.9675 | Val Loss: 0.1689 Acc: 0.9390\n",
      "Epoch 038 | Train Loss: 0.0992 Acc: 0.9635 | Val Loss: 0.1452 Acc: 0.9426\n",
      "Epoch 039 | Train Loss: 0.0880 Acc: 0.9651 | Val Loss: 0.1787 Acc: 0.9336\n",
      "Epoch 040 | Train Loss: 0.0874 Acc: 0.9662 | Val Loss: 0.1737 Acc: 0.9360\n",
      "Epoch 041 | Train Loss: 0.0780 Acc: 0.9707 | Val Loss: 0.1488 Acc: 0.9475\n",
      "Epoch 042 | Train Loss: 0.0810 Acc: 0.9701 | Val Loss: 0.1508 Acc: 0.9390\n",
      "Epoch 043 | Train Loss: 0.0815 Acc: 0.9675 | Val Loss: 0.1688 Acc: 0.9372\n",
      "Epoch 044 | Train Loss: 0.0796 Acc: 0.9718 | Val Loss: 0.1590 Acc: 0.9360\n",
      "Epoch 045 | Train Loss: 0.0644 Acc: 0.9755 | Val Loss: 0.1664 Acc: 0.9444\n",
      "Epoch 046 | Train Loss: 0.0767 Acc: 0.9704 | Val Loss: 0.1759 Acc: 0.9318\n",
      "Epoch 047 | Train Loss: 0.0811 Acc: 0.9704 | Val Loss: 0.1399 Acc: 0.9402\n",
      "Epoch 048 | Train Loss: 0.0657 Acc: 0.9743 | Val Loss: 0.1559 Acc: 0.9444\n",
      "Epoch 049 | Train Loss: 0.0657 Acc: 0.9764 | Val Loss: 0.1730 Acc: 0.9408\n",
      "Epoch 050 | Train Loss: 0.0758 Acc: 0.9740 | Val Loss: 0.1661 Acc: 0.9432\n",
      "Epoch 051 | Train Loss: 0.0689 Acc: 0.9752 | Val Loss: 0.1460 Acc: 0.9505\n",
      "Epoch 052 | Train Loss: 0.0733 Acc: 0.9725 | Val Loss: 0.1554 Acc: 0.9372\n",
      "Epoch 053 | Train Loss: 0.0661 Acc: 0.9748 | Val Loss: 0.1629 Acc: 0.9396\n",
      "Epoch 054 | Train Loss: 0.0538 Acc: 0.9811 | Val Loss: 0.1568 Acc: 0.9450\n",
      "Epoch 055 | Train Loss: 0.0657 Acc: 0.9767 | Val Loss: 0.1272 Acc: 0.9457\n",
      "Epoch 056 | Train Loss: 0.0584 Acc: 0.9801 | Val Loss: 0.1872 Acc: 0.9342\n",
      "Epoch 057 | Train Loss: 0.0693 Acc: 0.9730 | Val Loss: 0.1393 Acc: 0.9499\n",
      "Epoch 058 | Train Loss: 0.0523 Acc: 0.9790 | Val Loss: 0.1466 Acc: 0.9505\n",
      "Epoch 059 | Train Loss: 0.0630 Acc: 0.9775 | Val Loss: 0.1473 Acc: 0.9529\n",
      "Epoch 060 | Train Loss: 0.0548 Acc: 0.9810 | Val Loss: 0.1773 Acc: 0.9414\n",
      "Epoch 001 | Train Loss: 0.6795 Acc: 0.5804 | Val Loss: 0.6728 Acc: 0.5906\n",
      "Epoch 002 | Train Loss: 0.6645 Acc: 0.6098 | Val Loss: 0.6463 Acc: 0.6564\n",
      "Epoch 003 | Train Loss: 0.6439 Acc: 0.6363 | Val Loss: 0.6099 Acc: 0.6733\n",
      "Epoch 004 | Train Loss: 0.6017 Acc: 0.6868 | Val Loss: 0.5884 Acc: 0.6963\n",
      "Epoch 005 | Train Loss: 0.5720 Acc: 0.7074 | Val Loss: 0.5625 Acc: 0.7077\n",
      "Epoch 006 | Train Loss: 0.5552 Acc: 0.7270 | Val Loss: 0.5586 Acc: 0.7107\n",
      "Epoch 007 | Train Loss: 0.5331 Acc: 0.7423 | Val Loss: 0.5433 Acc: 0.7258\n",
      "Epoch 008 | Train Loss: 0.5187 Acc: 0.7468 | Val Loss: 0.5118 Acc: 0.7542\n",
      "Epoch 009 | Train Loss: 0.4915 Acc: 0.7661 | Val Loss: 0.4902 Acc: 0.7621\n",
      "Epoch 010 | Train Loss: 0.4815 Acc: 0.7716 | Val Loss: 0.4683 Acc: 0.7820\n",
      "Epoch 011 | Train Loss: 0.4519 Acc: 0.7906 | Val Loss: 0.4385 Acc: 0.7953\n",
      "Epoch 012 | Train Loss: 0.4409 Acc: 0.7947 | Val Loss: 0.5108 Acc: 0.7536\n",
      "Epoch 013 | Train Loss: 0.4176 Acc: 0.8063 | Val Loss: 0.4327 Acc: 0.8007\n",
      "Epoch 014 | Train Loss: 0.3970 Acc: 0.8153 | Val Loss: 0.4069 Acc: 0.7995\n",
      "Epoch 015 | Train Loss: 0.3668 Acc: 0.8310 | Val Loss: 0.3440 Acc: 0.8478\n",
      "Epoch 016 | Train Loss: 0.3485 Acc: 0.8455 | Val Loss: 0.4324 Acc: 0.8219\n",
      "Epoch 017 | Train Loss: 0.3412 Acc: 0.8519 | Val Loss: 0.3399 Acc: 0.8454\n",
      "Epoch 018 | Train Loss: 0.3162 Acc: 0.8623 | Val Loss: 0.3411 Acc: 0.8424\n",
      "Epoch 019 | Train Loss: 0.3064 Acc: 0.8661 | Val Loss: 0.3379 Acc: 0.8430\n",
      "Epoch 020 | Train Loss: 0.2829 Acc: 0.8833 | Val Loss: 0.3095 Acc: 0.8617\n",
      "Epoch 021 | Train Loss: 0.2734 Acc: 0.8824 | Val Loss: 0.2881 Acc: 0.8816\n",
      "Epoch 022 | Train Loss: 0.2550 Acc: 0.8948 | Val Loss: 0.2934 Acc: 0.8702\n",
      "Epoch 023 | Train Loss: 0.2365 Acc: 0.9022 | Val Loss: 0.2531 Acc: 0.8992\n",
      "Epoch 024 | Train Loss: 0.2454 Acc: 0.8985 | Val Loss: 0.2412 Acc: 0.8998\n",
      "Epoch 025 | Train Loss: 0.2246 Acc: 0.9102 | Val Loss: 0.2408 Acc: 0.9034\n",
      "Epoch 026 | Train Loss: 0.2164 Acc: 0.9133 | Val Loss: 0.2122 Acc: 0.9106\n",
      "Epoch 027 | Train Loss: 0.2076 Acc: 0.9151 | Val Loss: 0.2315 Acc: 0.9016\n",
      "Epoch 028 | Train Loss: 0.1927 Acc: 0.9212 | Val Loss: 0.2140 Acc: 0.9118\n",
      "Epoch 029 | Train Loss: 0.1796 Acc: 0.9321 | Val Loss: 0.2959 Acc: 0.8895\n",
      "Epoch 030 | Train Loss: 0.1790 Acc: 0.9278 | Val Loss: 0.2105 Acc: 0.9197\n",
      "Epoch 031 | Train Loss: 0.1632 Acc: 0.9343 | Val Loss: 0.2200 Acc: 0.9124\n",
      "Epoch 032 | Train Loss: 0.1560 Acc: 0.9395 | Val Loss: 0.2268 Acc: 0.9124\n",
      "Epoch 033 | Train Loss: 0.1581 Acc: 0.9401 | Val Loss: 0.1866 Acc: 0.9263\n",
      "Epoch 034 | Train Loss: 0.1372 Acc: 0.9456 | Val Loss: 0.1758 Acc: 0.9197\n",
      "Epoch 035 | Train Loss: 0.1444 Acc: 0.9462 | Val Loss: 0.1891 Acc: 0.9263\n",
      "Epoch 036 | Train Loss: 0.1464 Acc: 0.9440 | Val Loss: 0.1812 Acc: 0.9281\n",
      "Epoch 037 | Train Loss: 0.1326 Acc: 0.9479 | Val Loss: 0.2043 Acc: 0.9191\n",
      "Epoch 038 | Train Loss: 0.1359 Acc: 0.9462 | Val Loss: 0.1841 Acc: 0.9300\n",
      "Epoch 039 | Train Loss: 0.1375 Acc: 0.9493 | Val Loss: 0.1759 Acc: 0.9354\n",
      "Epoch 040 | Train Loss: 0.1247 Acc: 0.9530 | Val Loss: 0.1932 Acc: 0.9318\n",
      "Epoch 041 | Train Loss: 0.1167 Acc: 0.9553 | Val Loss: 0.1775 Acc: 0.9366\n",
      "Epoch 042 | Train Loss: 0.1133 Acc: 0.9589 | Val Loss: 0.1879 Acc: 0.9293\n",
      "Epoch 043 | Train Loss: 0.0989 Acc: 0.9610 | Val Loss: 0.2260 Acc: 0.9239\n",
      "Epoch 044 | Train Loss: 0.1014 Acc: 0.9612 | Val Loss: 0.1740 Acc: 0.9336\n",
      "Epoch 045 | Train Loss: 0.0991 Acc: 0.9635 | Val Loss: 0.2039 Acc: 0.9245\n",
      "Epoch 046 | Train Loss: 0.1088 Acc: 0.9597 | Val Loss: 0.2015 Acc: 0.9281\n",
      "Epoch 047 | Train Loss: 0.0983 Acc: 0.9618 | Val Loss: 0.1984 Acc: 0.9245\n",
      "Epoch 048 | Train Loss: 0.0930 Acc: 0.9650 | Val Loss: 0.1966 Acc: 0.9263\n",
      "Epoch 049 | Train Loss: 0.0912 Acc: 0.9650 | Val Loss: 0.1665 Acc: 0.9360\n",
      "Epoch 050 | Train Loss: 0.1006 Acc: 0.9627 | Val Loss: 0.1771 Acc: 0.9390\n",
      "Epoch 051 | Train Loss: 0.0848 Acc: 0.9678 | Val Loss: 0.1582 Acc: 0.9414\n",
      "Epoch 052 | Train Loss: 0.0871 Acc: 0.9678 | Val Loss: 0.1582 Acc: 0.9384\n",
      "Epoch 053 | Train Loss: 0.0815 Acc: 0.9686 | Val Loss: 0.1492 Acc: 0.9396\n",
      "Epoch 054 | Train Loss: 0.0739 Acc: 0.9718 | Val Loss: 0.1992 Acc: 0.9354\n",
      "Epoch 055 | Train Loss: 0.0871 Acc: 0.9678 | Val Loss: 0.1562 Acc: 0.9372\n",
      "Epoch 056 | Train Loss: 0.0678 Acc: 0.9757 | Val Loss: 0.1522 Acc: 0.9450\n",
      "Epoch 057 | Train Loss: 0.0683 Acc: 0.9739 | Val Loss: 0.1634 Acc: 0.9426\n",
      "Epoch 058 | Train Loss: 0.0717 Acc: 0.9743 | Val Loss: 0.2033 Acc: 0.9324\n",
      "Epoch 059 | Train Loss: 0.0805 Acc: 0.9712 | Val Loss: 0.1481 Acc: 0.9438\n",
      "Epoch 060 | Train Loss: 0.0629 Acc: 0.9772 | Val Loss: 0.2539 Acc: 0.9209\n",
      "Iteration 30/40 | Best Val Loss: 0.1122 | Iter Time: 231.32s | Total Time: 123.81 min\n",
      "Epoch 001 | Train Loss: 0.6813 Acc: 0.5751 | Val Loss: 0.7003 Acc: 0.5713\n",
      "Epoch 002 | Train Loss: 0.6777 Acc: 0.5928 | Val Loss: 0.6830 Acc: 0.5749\n",
      "Epoch 003 | Train Loss: 0.6692 Acc: 0.5991 | Val Loss: 0.6602 Acc: 0.6057\n",
      "Epoch 004 | Train Loss: 0.6405 Acc: 0.6488 | Val Loss: 0.6204 Acc: 0.6606\n",
      "Epoch 005 | Train Loss: 0.6011 Acc: 0.6865 | Val Loss: 0.5769 Acc: 0.6999\n",
      "Epoch 006 | Train Loss: 0.5700 Acc: 0.7146 | Val Loss: 0.5540 Acc: 0.7198\n",
      "Epoch 007 | Train Loss: 0.5419 Acc: 0.7379 | Val Loss: 0.5208 Acc: 0.7428\n",
      "Epoch 008 | Train Loss: 0.5073 Acc: 0.7617 | Val Loss: 0.5039 Acc: 0.7627\n",
      "Epoch 009 | Train Loss: 0.4748 Acc: 0.7711 | Val Loss: 0.4622 Acc: 0.7814\n",
      "Epoch 010 | Train Loss: 0.4419 Acc: 0.7922 | Val Loss: 0.4158 Acc: 0.8019\n",
      "Epoch 011 | Train Loss: 0.3999 Acc: 0.8229 | Val Loss: 0.3655 Acc: 0.8382\n",
      "Epoch 012 | Train Loss: 0.3795 Acc: 0.8329 | Val Loss: 0.3768 Acc: 0.8315\n",
      "Epoch 013 | Train Loss: 0.3660 Acc: 0.8448 | Val Loss: 0.3287 Acc: 0.8527\n",
      "Epoch 014 | Train Loss: 0.3229 Acc: 0.8677 | Val Loss: 0.2885 Acc: 0.8883\n",
      "Epoch 015 | Train Loss: 0.3085 Acc: 0.8708 | Val Loss: 0.3608 Acc: 0.8508\n",
      "Epoch 016 | Train Loss: 0.3016 Acc: 0.8729 | Val Loss: 0.2827 Acc: 0.8835\n",
      "Epoch 017 | Train Loss: 0.2835 Acc: 0.8822 | Val Loss: 0.2431 Acc: 0.9052\n",
      "Epoch 018 | Train Loss: 0.2555 Acc: 0.8976 | Val Loss: 0.2407 Acc: 0.9016\n",
      "Epoch 019 | Train Loss: 0.2471 Acc: 0.8985 | Val Loss: 0.2405 Acc: 0.9010\n",
      "Epoch 020 | Train Loss: 0.2238 Acc: 0.9123 | Val Loss: 0.2598 Acc: 0.8943\n",
      "Epoch 021 | Train Loss: 0.2251 Acc: 0.9118 | Val Loss: 0.2251 Acc: 0.9100\n",
      "Epoch 022 | Train Loss: 0.2112 Acc: 0.9139 | Val Loss: 0.2614 Acc: 0.8992\n",
      "Epoch 023 | Train Loss: 0.1868 Acc: 0.9234 | Val Loss: 0.2281 Acc: 0.9058\n",
      "Epoch 024 | Train Loss: 0.1879 Acc: 0.9250 | Val Loss: 0.2053 Acc: 0.9197\n",
      "Epoch 025 | Train Loss: 0.1925 Acc: 0.9219 | Val Loss: 0.2177 Acc: 0.9149\n",
      "Epoch 026 | Train Loss: 0.1698 Acc: 0.9322 | Val Loss: 0.1743 Acc: 0.9300\n",
      "Epoch 027 | Train Loss: 0.1566 Acc: 0.9407 | Val Loss: 0.1668 Acc: 0.9384\n",
      "Epoch 028 | Train Loss: 0.1661 Acc: 0.9349 | Val Loss: 0.1856 Acc: 0.9287\n",
      "Epoch 029 | Train Loss: 0.1490 Acc: 0.9437 | Val Loss: 0.1947 Acc: 0.9179\n",
      "Epoch 030 | Train Loss: 0.1405 Acc: 0.9441 | Val Loss: 0.1820 Acc: 0.9281\n",
      "Epoch 031 | Train Loss: 0.1456 Acc: 0.9440 | Val Loss: 0.1671 Acc: 0.9318\n",
      "Epoch 032 | Train Loss: 0.1326 Acc: 0.9500 | Val Loss: 0.1643 Acc: 0.9402\n",
      "Epoch 033 | Train Loss: 0.1360 Acc: 0.9469 | Val Loss: 0.1453 Acc: 0.9396\n",
      "Epoch 034 | Train Loss: 0.1275 Acc: 0.9506 | Val Loss: 0.1603 Acc: 0.9475\n",
      "Epoch 035 | Train Loss: 0.1203 Acc: 0.9543 | Val Loss: 0.1412 Acc: 0.9396\n",
      "Epoch 036 | Train Loss: 0.1184 Acc: 0.9556 | Val Loss: 0.1272 Acc: 0.9535\n",
      "Epoch 037 | Train Loss: 0.1063 Acc: 0.9601 | Val Loss: 0.1629 Acc: 0.9366\n",
      "Epoch 038 | Train Loss: 0.1115 Acc: 0.9591 | Val Loss: 0.1525 Acc: 0.9378\n",
      "Epoch 039 | Train Loss: 0.1004 Acc: 0.9598 | Val Loss: 0.1923 Acc: 0.9269\n",
      "Epoch 040 | Train Loss: 0.0984 Acc: 0.9623 | Val Loss: 0.1725 Acc: 0.9432\n",
      "Epoch 041 | Train Loss: 0.1102 Acc: 0.9571 | Val Loss: 0.1614 Acc: 0.9414\n",
      "Epoch 042 | Train Loss: 0.1036 Acc: 0.9635 | Val Loss: 0.1351 Acc: 0.9493\n",
      "Epoch 043 | Train Loss: 0.0881 Acc: 0.9680 | Val Loss: 0.1924 Acc: 0.9396\n",
      "Epoch 044 | Train Loss: 0.0915 Acc: 0.9668 | Val Loss: 0.1857 Acc: 0.9306\n",
      "Epoch 045 | Train Loss: 0.0905 Acc: 0.9665 | Val Loss: 0.1622 Acc: 0.9444\n",
      "Epoch 046 | Train Loss: 0.0844 Acc: 0.9666 | Val Loss: 0.1294 Acc: 0.9523\n",
      "Early stopping triggered.\n",
      "Epoch 001 | Train Loss: 0.6779 Acc: 0.5848 | Val Loss: 0.6717 Acc: 0.5924\n",
      "Epoch 002 | Train Loss: 0.6686 Acc: 0.6000 | Val Loss: 0.6651 Acc: 0.6014\n",
      "Epoch 003 | Train Loss: 0.6595 Acc: 0.6111 | Val Loss: 0.6551 Acc: 0.6111\n",
      "Epoch 004 | Train Loss: 0.6410 Acc: 0.6361 | Val Loss: 0.6571 Acc: 0.6274\n",
      "Epoch 005 | Train Loss: 0.5999 Acc: 0.6924 | Val Loss: 0.5740 Acc: 0.7150\n",
      "Epoch 006 | Train Loss: 0.5665 Acc: 0.7177 | Val Loss: 0.5799 Acc: 0.7114\n",
      "Epoch 007 | Train Loss: 0.5418 Acc: 0.7374 | Val Loss: 0.5592 Acc: 0.7114\n",
      "Epoch 008 | Train Loss: 0.5184 Acc: 0.7504 | Val Loss: 0.5124 Acc: 0.7488\n",
      "Epoch 009 | Train Loss: 0.5044 Acc: 0.7623 | Val Loss: 0.5059 Acc: 0.7470\n",
      "Epoch 010 | Train Loss: 0.4904 Acc: 0.7654 | Val Loss: 0.4892 Acc: 0.7597\n",
      "Epoch 011 | Train Loss: 0.4573 Acc: 0.7856 | Val Loss: 0.4658 Acc: 0.7711\n",
      "Epoch 012 | Train Loss: 0.4297 Acc: 0.8070 | Val Loss: 0.4522 Acc: 0.7796\n",
      "Epoch 013 | Train Loss: 0.4005 Acc: 0.8188 | Val Loss: 0.4046 Acc: 0.8176\n",
      "Epoch 014 | Train Loss: 0.3929 Acc: 0.8267 | Val Loss: 0.4023 Acc: 0.8297\n",
      "Epoch 015 | Train Loss: 0.3589 Acc: 0.8407 | Val Loss: 0.3735 Acc: 0.8267\n",
      "Epoch 016 | Train Loss: 0.3459 Acc: 0.8523 | Val Loss: 0.3463 Acc: 0.8388\n",
      "Epoch 017 | Train Loss: 0.3320 Acc: 0.8564 | Val Loss: 0.3418 Acc: 0.8382\n",
      "Epoch 018 | Train Loss: 0.3067 Acc: 0.8688 | Val Loss: 0.3108 Acc: 0.8629\n",
      "Epoch 019 | Train Loss: 0.2873 Acc: 0.8753 | Val Loss: 0.3105 Acc: 0.8696\n",
      "Epoch 020 | Train Loss: 0.2788 Acc: 0.8833 | Val Loss: 0.2762 Acc: 0.8822\n",
      "Epoch 021 | Train Loss: 0.2602 Acc: 0.8984 | Val Loss: 0.2773 Acc: 0.8883\n",
      "Epoch 022 | Train Loss: 0.2476 Acc: 0.9010 | Val Loss: 0.3058 Acc: 0.8732\n",
      "Epoch 023 | Train Loss: 0.2518 Acc: 0.8898 | Val Loss: 0.2603 Acc: 0.8943\n",
      "Epoch 024 | Train Loss: 0.2350 Acc: 0.9022 | Val Loss: 0.2394 Acc: 0.8979\n",
      "Epoch 025 | Train Loss: 0.2198 Acc: 0.9147 | Val Loss: 0.2371 Acc: 0.9076\n",
      "Epoch 026 | Train Loss: 0.2160 Acc: 0.9148 | Val Loss: 0.2498 Acc: 0.8943\n",
      "Epoch 027 | Train Loss: 0.2057 Acc: 0.9207 | Val Loss: 0.2002 Acc: 0.9215\n",
      "Epoch 028 | Train Loss: 0.1854 Acc: 0.9260 | Val Loss: 0.2112 Acc: 0.9118\n",
      "Epoch 029 | Train Loss: 0.1972 Acc: 0.9225 | Val Loss: 0.2033 Acc: 0.9239\n",
      "Epoch 030 | Train Loss: 0.1796 Acc: 0.9269 | Val Loss: 0.2269 Acc: 0.9070\n",
      "Epoch 031 | Train Loss: 0.1731 Acc: 0.9277 | Val Loss: 0.1921 Acc: 0.9293\n",
      "Epoch 032 | Train Loss: 0.1711 Acc: 0.9307 | Val Loss: 0.2064 Acc: 0.9191\n",
      "Epoch 033 | Train Loss: 0.1780 Acc: 0.9315 | Val Loss: 0.2036 Acc: 0.9221\n",
      "Epoch 034 | Train Loss: 0.1529 Acc: 0.9395 | Val Loss: 0.2066 Acc: 0.9275\n",
      "Epoch 035 | Train Loss: 0.1531 Acc: 0.9417 | Val Loss: 0.2013 Acc: 0.9203\n",
      "Epoch 036 | Train Loss: 0.1425 Acc: 0.9484 | Val Loss: 0.1820 Acc: 0.9281\n",
      "Epoch 037 | Train Loss: 0.1493 Acc: 0.9434 | Val Loss: 0.1760 Acc: 0.9354\n",
      "Epoch 038 | Train Loss: 0.1391 Acc: 0.9444 | Val Loss: 0.1763 Acc: 0.9360\n",
      "Epoch 039 | Train Loss: 0.1375 Acc: 0.9494 | Val Loss: 0.1736 Acc: 0.9360\n",
      "Epoch 040 | Train Loss: 0.1189 Acc: 0.9535 | Val Loss: 0.1558 Acc: 0.9384\n",
      "Epoch 041 | Train Loss: 0.1215 Acc: 0.9526 | Val Loss: 0.1788 Acc: 0.9378\n",
      "Epoch 042 | Train Loss: 0.1209 Acc: 0.9547 | Val Loss: 0.1778 Acc: 0.9300\n",
      "Epoch 043 | Train Loss: 0.1152 Acc: 0.9586 | Val Loss: 0.1824 Acc: 0.9306\n",
      "Epoch 044 | Train Loss: 0.1177 Acc: 0.9562 | Val Loss: 0.1978 Acc: 0.9354\n",
      "Epoch 045 | Train Loss: 0.1192 Acc: 0.9539 | Val Loss: 0.1667 Acc: 0.9390\n",
      "Epoch 046 | Train Loss: 0.1076 Acc: 0.9603 | Val Loss: 0.1688 Acc: 0.9384\n",
      "Epoch 047 | Train Loss: 0.1104 Acc: 0.9585 | Val Loss: 0.2027 Acc: 0.9263\n",
      "Epoch 048 | Train Loss: 0.1080 Acc: 0.9586 | Val Loss: 0.1463 Acc: 0.9444\n",
      "Epoch 049 | Train Loss: 0.1026 Acc: 0.9613 | Val Loss: 0.1654 Acc: 0.9444\n",
      "Epoch 050 | Train Loss: 0.0944 Acc: 0.9665 | Val Loss: 0.1549 Acc: 0.9426\n",
      "Epoch 051 | Train Loss: 0.1039 Acc: 0.9633 | Val Loss: 0.1516 Acc: 0.9475\n",
      "Epoch 052 | Train Loss: 0.0955 Acc: 0.9621 | Val Loss: 0.1619 Acc: 0.9372\n",
      "Epoch 053 | Train Loss: 0.0914 Acc: 0.9666 | Val Loss: 0.2371 Acc: 0.9106\n",
      "Epoch 054 | Train Loss: 0.0937 Acc: 0.9644 | Val Loss: 0.1734 Acc: 0.9366\n",
      "Epoch 055 | Train Loss: 0.0844 Acc: 0.9686 | Val Loss: 0.1445 Acc: 0.9529\n",
      "Epoch 056 | Train Loss: 0.0770 Acc: 0.9718 | Val Loss: 0.1504 Acc: 0.9535\n",
      "Epoch 057 | Train Loss: 0.0819 Acc: 0.9703 | Val Loss: 0.1477 Acc: 0.9481\n",
      "Epoch 058 | Train Loss: 0.0815 Acc: 0.9710 | Val Loss: 0.1344 Acc: 0.9487\n",
      "Epoch 059 | Train Loss: 0.0900 Acc: 0.9659 | Val Loss: 0.1649 Acc: 0.9402\n",
      "Epoch 060 | Train Loss: 0.0849 Acc: 0.9701 | Val Loss: 0.1676 Acc: 0.9414\n",
      "Epoch 001 | Train Loss: 0.6797 Acc: 0.5765 | Val Loss: 0.6792 Acc: 0.5773\n",
      "Epoch 002 | Train Loss: 0.6682 Acc: 0.5981 | Val Loss: 0.6612 Acc: 0.6069\n",
      "Epoch 003 | Train Loss: 0.6396 Acc: 0.6491 | Val Loss: 0.6012 Acc: 0.6842\n",
      "Epoch 004 | Train Loss: 0.5975 Acc: 0.6897 | Val Loss: 0.5868 Acc: 0.6914\n",
      "Epoch 005 | Train Loss: 0.5615 Acc: 0.7196 | Val Loss: 0.5490 Acc: 0.7246\n",
      "Epoch 006 | Train Loss: 0.5363 Acc: 0.7392 | Val Loss: 0.5316 Acc: 0.7313\n",
      "Epoch 007 | Train Loss: 0.5154 Acc: 0.7537 | Val Loss: 0.5501 Acc: 0.7373\n",
      "Epoch 008 | Train Loss: 0.5011 Acc: 0.7616 | Val Loss: 0.4887 Acc: 0.7657\n",
      "Epoch 009 | Train Loss: 0.4887 Acc: 0.7646 | Val Loss: 0.5069 Acc: 0.7452\n",
      "Epoch 010 | Train Loss: 0.4564 Acc: 0.7845 | Val Loss: 0.4562 Acc: 0.7754\n",
      "Epoch 011 | Train Loss: 0.4385 Acc: 0.7987 | Val Loss: 0.3957 Acc: 0.8146\n",
      "Epoch 012 | Train Loss: 0.4132 Acc: 0.8122 | Val Loss: 0.4455 Acc: 0.7880\n",
      "Epoch 013 | Train Loss: 0.3787 Acc: 0.8286 | Val Loss: 0.3855 Acc: 0.8200\n",
      "Epoch 014 | Train Loss: 0.3752 Acc: 0.8303 | Val Loss: 0.3241 Acc: 0.8599\n",
      "Epoch 015 | Train Loss: 0.3410 Acc: 0.8522 | Val Loss: 0.3156 Acc: 0.8720\n",
      "Epoch 016 | Train Loss: 0.3116 Acc: 0.8686 | Val Loss: 0.2936 Acc: 0.8804\n",
      "Epoch 017 | Train Loss: 0.3031 Acc: 0.8747 | Val Loss: 0.2934 Acc: 0.8768\n",
      "Epoch 018 | Train Loss: 0.2997 Acc: 0.8750 | Val Loss: 0.2857 Acc: 0.8780\n",
      "Epoch 019 | Train Loss: 0.2659 Acc: 0.8899 | Val Loss: 0.3146 Acc: 0.8684\n",
      "Epoch 020 | Train Loss: 0.2644 Acc: 0.8923 | Val Loss: 0.2877 Acc: 0.8762\n",
      "Epoch 021 | Train Loss: 0.2520 Acc: 0.8964 | Val Loss: 0.2293 Acc: 0.9118\n",
      "Epoch 022 | Train Loss: 0.2280 Acc: 0.9082 | Val Loss: 0.2262 Acc: 0.9094\n",
      "Epoch 023 | Train Loss: 0.2167 Acc: 0.9141 | Val Loss: 0.2244 Acc: 0.9124\n",
      "Epoch 024 | Train Loss: 0.2026 Acc: 0.9204 | Val Loss: 0.2096 Acc: 0.9130\n",
      "Epoch 025 | Train Loss: 0.2059 Acc: 0.9179 | Val Loss: 0.2184 Acc: 0.9130\n",
      "Epoch 026 | Train Loss: 0.1982 Acc: 0.9221 | Val Loss: 0.2150 Acc: 0.9161\n",
      "Epoch 027 | Train Loss: 0.1936 Acc: 0.9215 | Val Loss: 0.1914 Acc: 0.9300\n",
      "Epoch 028 | Train Loss: 0.1863 Acc: 0.9244 | Val Loss: 0.2135 Acc: 0.9112\n",
      "Epoch 029 | Train Loss: 0.1748 Acc: 0.9289 | Val Loss: 0.1792 Acc: 0.9306\n",
      "Epoch 030 | Train Loss: 0.1616 Acc: 0.9392 | Val Loss: 0.1980 Acc: 0.9143\n",
      "Epoch 031 | Train Loss: 0.1625 Acc: 0.9355 | Val Loss: 0.1690 Acc: 0.9420\n",
      "Epoch 032 | Train Loss: 0.1652 Acc: 0.9318 | Val Loss: 0.1923 Acc: 0.9263\n",
      "Epoch 033 | Train Loss: 0.1503 Acc: 0.9417 | Val Loss: 0.1918 Acc: 0.9281\n",
      "Epoch 034 | Train Loss: 0.1416 Acc: 0.9435 | Val Loss: 0.2633 Acc: 0.9046\n",
      "Epoch 035 | Train Loss: 0.1423 Acc: 0.9456 | Val Loss: 0.1721 Acc: 0.9293\n",
      "Epoch 036 | Train Loss: 0.1375 Acc: 0.9478 | Val Loss: 0.1718 Acc: 0.9372\n",
      "Epoch 037 | Train Loss: 0.1279 Acc: 0.9517 | Val Loss: 0.1421 Acc: 0.9463\n",
      "Epoch 038 | Train Loss: 0.1281 Acc: 0.9523 | Val Loss: 0.1637 Acc: 0.9396\n",
      "Epoch 039 | Train Loss: 0.1150 Acc: 0.9558 | Val Loss: 0.1401 Acc: 0.9493\n",
      "Epoch 040 | Train Loss: 0.1261 Acc: 0.9523 | Val Loss: 0.1735 Acc: 0.9360\n",
      "Epoch 041 | Train Loss: 0.1208 Acc: 0.9524 | Val Loss: 0.1524 Acc: 0.9438\n",
      "Epoch 042 | Train Loss: 0.1092 Acc: 0.9603 | Val Loss: 0.1638 Acc: 0.9390\n",
      "Epoch 043 | Train Loss: 0.1242 Acc: 0.9529 | Val Loss: 0.1671 Acc: 0.9342\n",
      "Epoch 044 | Train Loss: 0.1089 Acc: 0.9573 | Val Loss: 0.1461 Acc: 0.9475\n",
      "Epoch 045 | Train Loss: 0.1186 Acc: 0.9565 | Val Loss: 0.1507 Acc: 0.9475\n",
      "Epoch 046 | Train Loss: 0.1013 Acc: 0.9598 | Val Loss: 0.1351 Acc: 0.9523\n",
      "Epoch 047 | Train Loss: 0.0999 Acc: 0.9612 | Val Loss: 0.1333 Acc: 0.9523\n",
      "Epoch 048 | Train Loss: 0.1064 Acc: 0.9629 | Val Loss: 0.1401 Acc: 0.9463\n",
      "Epoch 049 | Train Loss: 0.0949 Acc: 0.9636 | Val Loss: 0.1542 Acc: 0.9426\n",
      "Epoch 050 | Train Loss: 0.1022 Acc: 0.9636 | Val Loss: 0.1253 Acc: 0.9553\n",
      "Epoch 051 | Train Loss: 0.0971 Acc: 0.9656 | Val Loss: 0.1781 Acc: 0.9354\n",
      "Epoch 052 | Train Loss: 0.0973 Acc: 0.9648 | Val Loss: 0.1865 Acc: 0.9336\n",
      "Epoch 053 | Train Loss: 0.0930 Acc: 0.9663 | Val Loss: 0.1424 Acc: 0.9487\n",
      "Epoch 054 | Train Loss: 0.0866 Acc: 0.9665 | Val Loss: 0.1402 Acc: 0.9547\n",
      "Epoch 055 | Train Loss: 0.0840 Acc: 0.9697 | Val Loss: 0.1309 Acc: 0.9523\n",
      "Epoch 056 | Train Loss: 0.0804 Acc: 0.9709 | Val Loss: 0.1727 Acc: 0.9402\n",
      "Epoch 057 | Train Loss: 0.0868 Acc: 0.9678 | Val Loss: 0.2060 Acc: 0.9245\n",
      "Epoch 058 | Train Loss: 0.0799 Acc: 0.9690 | Val Loss: 0.1203 Acc: 0.9571\n",
      "Epoch 059 | Train Loss: 0.0873 Acc: 0.9684 | Val Loss: 0.1346 Acc: 0.9553\n",
      "Epoch 060 | Train Loss: 0.0742 Acc: 0.9722 | Val Loss: 0.1440 Acc: 0.9553\n",
      "Epoch 001 | Train Loss: 0.6816 Acc: 0.5724 | Val Loss: 0.6736 Acc: 0.5906\n",
      "Epoch 002 | Train Loss: 0.6722 Acc: 0.5969 | Val Loss: 0.6712 Acc: 0.6008\n",
      "Epoch 003 | Train Loss: 0.6677 Acc: 0.5996 | Val Loss: 0.6705 Acc: 0.5906\n",
      "Epoch 004 | Train Loss: 0.6626 Acc: 0.6062 | Val Loss: 0.6618 Acc: 0.6063\n",
      "Epoch 005 | Train Loss: 0.6517 Acc: 0.6234 | Val Loss: 0.6137 Acc: 0.6733\n",
      "Epoch 006 | Train Loss: 0.6141 Acc: 0.6823 | Val Loss: 0.5946 Acc: 0.6920\n",
      "Epoch 007 | Train Loss: 0.5710 Acc: 0.7166 | Val Loss: 0.5646 Acc: 0.7065\n",
      "Epoch 008 | Train Loss: 0.5516 Acc: 0.7315 | Val Loss: 0.5475 Acc: 0.7234\n",
      "Epoch 009 | Train Loss: 0.5283 Acc: 0.7365 | Val Loss: 0.5365 Acc: 0.7271\n",
      "Epoch 010 | Train Loss: 0.5057 Acc: 0.7572 | Val Loss: 0.5002 Acc: 0.7560\n",
      "Epoch 011 | Train Loss: 0.4888 Acc: 0.7744 | Val Loss: 0.4847 Acc: 0.7705\n",
      "Epoch 012 | Train Loss: 0.4788 Acc: 0.7756 | Val Loss: 0.4776 Acc: 0.7754\n",
      "Epoch 013 | Train Loss: 0.4523 Acc: 0.7864 | Val Loss: 0.4724 Acc: 0.7736\n",
      "Epoch 014 | Train Loss: 0.4341 Acc: 0.7999 | Val Loss: 0.4320 Acc: 0.7965\n",
      "Epoch 015 | Train Loss: 0.4162 Acc: 0.8114 | Val Loss: 0.4194 Acc: 0.7935\n",
      "Epoch 016 | Train Loss: 0.3775 Acc: 0.8333 | Val Loss: 0.3745 Acc: 0.8279\n",
      "Epoch 017 | Train Loss: 0.3600 Acc: 0.8412 | Val Loss: 0.3531 Acc: 0.8412\n",
      "Epoch 018 | Train Loss: 0.3505 Acc: 0.8481 | Val Loss: 0.3307 Acc: 0.8460\n",
      "Epoch 019 | Train Loss: 0.3228 Acc: 0.8624 | Val Loss: 0.3297 Acc: 0.8545\n",
      "Epoch 020 | Train Loss: 0.3085 Acc: 0.8667 | Val Loss: 0.3127 Acc: 0.8641\n",
      "Epoch 021 | Train Loss: 0.2914 Acc: 0.8759 | Val Loss: 0.2896 Acc: 0.8762\n",
      "Epoch 022 | Train Loss: 0.2862 Acc: 0.8822 | Val Loss: 0.2870 Acc: 0.8774\n",
      "Epoch 023 | Train Loss: 0.2636 Acc: 0.8877 | Val Loss: 0.3005 Acc: 0.8792\n",
      "Epoch 024 | Train Loss: 0.2511 Acc: 0.8952 | Val Loss: 0.2708 Acc: 0.8780\n",
      "Epoch 025 | Train Loss: 0.2379 Acc: 0.9034 | Val Loss: 0.2835 Acc: 0.8829\n",
      "Epoch 026 | Train Loss: 0.2274 Acc: 0.9065 | Val Loss: 0.2415 Acc: 0.9010\n",
      "Epoch 027 | Train Loss: 0.2204 Acc: 0.9088 | Val Loss: 0.2292 Acc: 0.9064\n",
      "Epoch 028 | Train Loss: 0.2106 Acc: 0.9103 | Val Loss: 0.2475 Acc: 0.8986\n",
      "Epoch 029 | Train Loss: 0.2068 Acc: 0.9192 | Val Loss: 0.2184 Acc: 0.9130\n",
      "Epoch 030 | Train Loss: 0.1916 Acc: 0.9263 | Val Loss: 0.2424 Acc: 0.9046\n",
      "Epoch 031 | Train Loss: 0.1981 Acc: 0.9244 | Val Loss: 0.2225 Acc: 0.9118\n",
      "Epoch 032 | Train Loss: 0.1860 Acc: 0.9295 | Val Loss: 0.2014 Acc: 0.9245\n",
      "Epoch 033 | Train Loss: 0.1717 Acc: 0.9302 | Val Loss: 0.2060 Acc: 0.9167\n",
      "Epoch 034 | Train Loss: 0.1754 Acc: 0.9346 | Val Loss: 0.2355 Acc: 0.9064\n",
      "Epoch 035 | Train Loss: 0.1670 Acc: 0.9333 | Val Loss: 0.2099 Acc: 0.9221\n",
      "Epoch 036 | Train Loss: 0.1615 Acc: 0.9360 | Val Loss: 0.1924 Acc: 0.9239\n",
      "Epoch 037 | Train Loss: 0.1562 Acc: 0.9381 | Val Loss: 0.2704 Acc: 0.8931\n",
      "Epoch 038 | Train Loss: 0.1623 Acc: 0.9375 | Val Loss: 0.2069 Acc: 0.9179\n",
      "Epoch 039 | Train Loss: 0.1394 Acc: 0.9458 | Val Loss: 0.1672 Acc: 0.9390\n",
      "Epoch 040 | Train Loss: 0.1424 Acc: 0.9423 | Val Loss: 0.1867 Acc: 0.9281\n",
      "Epoch 041 | Train Loss: 0.1388 Acc: 0.9479 | Val Loss: 0.1807 Acc: 0.9306\n",
      "Epoch 042 | Train Loss: 0.1344 Acc: 0.9503 | Val Loss: 0.1950 Acc: 0.9269\n",
      "Epoch 043 | Train Loss: 0.1322 Acc: 0.9502 | Val Loss: 0.1964 Acc: 0.9209\n",
      "Epoch 044 | Train Loss: 0.1344 Acc: 0.9490 | Val Loss: 0.1842 Acc: 0.9221\n",
      "Epoch 045 | Train Loss: 0.1265 Acc: 0.9524 | Val Loss: 0.2031 Acc: 0.9161\n",
      "Epoch 046 | Train Loss: 0.1282 Acc: 0.9500 | Val Loss: 0.2157 Acc: 0.9167\n",
      "Epoch 047 | Train Loss: 0.1190 Acc: 0.9517 | Val Loss: 0.1731 Acc: 0.9342\n",
      "Epoch 048 | Train Loss: 0.1111 Acc: 0.9585 | Val Loss: 0.1913 Acc: 0.9312\n",
      "Epoch 049 | Train Loss: 0.1248 Acc: 0.9524 | Val Loss: 0.1807 Acc: 0.9336\n",
      "Early stopping triggered.\n",
      "Epoch 001 | Train Loss: 0.6804 Acc: 0.5759 | Val Loss: 0.6768 Acc: 0.5845\n",
      "Epoch 002 | Train Loss: 0.6782 Acc: 0.5818 | Val Loss: 0.6839 Acc: 0.5809\n",
      "Epoch 003 | Train Loss: 0.6737 Acc: 0.5901 | Val Loss: 0.6716 Acc: 0.5707\n",
      "Epoch 004 | Train Loss: 0.6332 Acc: 0.6582 | Val Loss: 0.6244 Acc: 0.6630\n",
      "Epoch 005 | Train Loss: 0.6001 Acc: 0.6977 | Val Loss: 0.5821 Acc: 0.6975\n",
      "Epoch 006 | Train Loss: 0.5664 Acc: 0.7158 | Val Loss: 0.5700 Acc: 0.7114\n",
      "Epoch 007 | Train Loss: 0.5391 Acc: 0.7302 | Val Loss: 0.5446 Acc: 0.7234\n",
      "Epoch 008 | Train Loss: 0.5224 Acc: 0.7468 | Val Loss: 0.5292 Acc: 0.7440\n",
      "Epoch 009 | Train Loss: 0.5032 Acc: 0.7572 | Val Loss: 0.4895 Acc: 0.7639\n",
      "Epoch 010 | Train Loss: 0.4750 Acc: 0.7759 | Val Loss: 0.4846 Acc: 0.7566\n",
      "Epoch 011 | Train Loss: 0.4763 Acc: 0.7753 | Val Loss: 0.4809 Acc: 0.7729\n",
      "Epoch 012 | Train Loss: 0.4421 Acc: 0.7975 | Val Loss: 0.4115 Acc: 0.8176\n",
      "Epoch 013 | Train Loss: 0.4148 Acc: 0.8104 | Val Loss: 0.4090 Acc: 0.8007\n",
      "Epoch 014 | Train Loss: 0.4103 Acc: 0.8073 | Val Loss: 0.3880 Acc: 0.8237\n",
      "Epoch 015 | Train Loss: 0.3777 Acc: 0.8321 | Val Loss: 0.3952 Acc: 0.8062\n",
      "Epoch 016 | Train Loss: 0.3660 Acc: 0.8380 | Val Loss: 0.3389 Acc: 0.8436\n",
      "Epoch 017 | Train Loss: 0.3373 Acc: 0.8507 | Val Loss: 0.3251 Acc: 0.8678\n",
      "Epoch 018 | Train Loss: 0.3231 Acc: 0.8578 | Val Loss: 0.2975 Acc: 0.8804\n",
      "Epoch 019 | Train Loss: 0.3027 Acc: 0.8671 | Val Loss: 0.2881 Acc: 0.8750\n",
      "Epoch 020 | Train Loss: 0.2799 Acc: 0.8807 | Val Loss: 0.2769 Acc: 0.8871\n",
      "Epoch 021 | Train Loss: 0.2703 Acc: 0.8851 | Val Loss: 0.2947 Acc: 0.8835\n",
      "Epoch 022 | Train Loss: 0.2556 Acc: 0.8914 | Val Loss: 0.2816 Acc: 0.8726\n",
      "Epoch 023 | Train Loss: 0.2360 Acc: 0.9017 | Val Loss: 0.2539 Acc: 0.8925\n",
      "Epoch 024 | Train Loss: 0.2443 Acc: 0.9017 | Val Loss: 0.2166 Acc: 0.9161\n",
      "Epoch 025 | Train Loss: 0.2313 Acc: 0.9079 | Val Loss: 0.2263 Acc: 0.9082\n",
      "Epoch 026 | Train Loss: 0.2160 Acc: 0.9154 | Val Loss: 0.2179 Acc: 0.9155\n",
      "Epoch 027 | Train Loss: 0.2041 Acc: 0.9197 | Val Loss: 0.2081 Acc: 0.9179\n",
      "Epoch 028 | Train Loss: 0.2091 Acc: 0.9180 | Val Loss: 0.2260 Acc: 0.9058\n",
      "Epoch 029 | Train Loss: 0.1919 Acc: 0.9236 | Val Loss: 0.2059 Acc: 0.9245\n",
      "Epoch 030 | Train Loss: 0.1922 Acc: 0.9213 | Val Loss: 0.2080 Acc: 0.9215\n",
      "Epoch 031 | Train Loss: 0.1810 Acc: 0.9278 | Val Loss: 0.1976 Acc: 0.9251\n",
      "Epoch 032 | Train Loss: 0.1615 Acc: 0.9346 | Val Loss: 0.2533 Acc: 0.9034\n",
      "Epoch 033 | Train Loss: 0.1699 Acc: 0.9337 | Val Loss: 0.2189 Acc: 0.9136\n",
      "Epoch 034 | Train Loss: 0.1608 Acc: 0.9360 | Val Loss: 0.1684 Acc: 0.9414\n",
      "Epoch 035 | Train Loss: 0.1559 Acc: 0.9408 | Val Loss: 0.2130 Acc: 0.9227\n",
      "Epoch 036 | Train Loss: 0.1472 Acc: 0.9441 | Val Loss: 0.1922 Acc: 0.9245\n",
      "Epoch 037 | Train Loss: 0.1448 Acc: 0.9426 | Val Loss: 0.1729 Acc: 0.9324\n",
      "Epoch 038 | Train Loss: 0.1464 Acc: 0.9434 | Val Loss: 0.1705 Acc: 0.9354\n",
      "Epoch 039 | Train Loss: 0.1352 Acc: 0.9490 | Val Loss: 0.1993 Acc: 0.9245\n",
      "Epoch 040 | Train Loss: 0.1438 Acc: 0.9429 | Val Loss: 0.1853 Acc: 0.9281\n",
      "Epoch 041 | Train Loss: 0.1279 Acc: 0.9505 | Val Loss: 0.1744 Acc: 0.9318\n",
      "Epoch 042 | Train Loss: 0.1227 Acc: 0.9546 | Val Loss: 0.1668 Acc: 0.9402\n",
      "Epoch 043 | Train Loss: 0.1262 Acc: 0.9499 | Val Loss: 0.1865 Acc: 0.9366\n",
      "Epoch 044 | Train Loss: 0.1270 Acc: 0.9512 | Val Loss: 0.1892 Acc: 0.9348\n",
      "Epoch 045 | Train Loss: 0.1104 Acc: 0.9598 | Val Loss: 0.1730 Acc: 0.9342\n",
      "Epoch 046 | Train Loss: 0.1066 Acc: 0.9601 | Val Loss: 0.1570 Acc: 0.9408\n",
      "Epoch 047 | Train Loss: 0.1048 Acc: 0.9601 | Val Loss: 0.1655 Acc: 0.9378\n",
      "Epoch 048 | Train Loss: 0.1078 Acc: 0.9591 | Val Loss: 0.1493 Acc: 0.9414\n",
      "Epoch 049 | Train Loss: 0.1070 Acc: 0.9618 | Val Loss: 0.1665 Acc: 0.9372\n",
      "Epoch 050 | Train Loss: 0.1038 Acc: 0.9580 | Val Loss: 0.1621 Acc: 0.9342\n",
      "Epoch 051 | Train Loss: 0.1058 Acc: 0.9610 | Val Loss: 0.1443 Acc: 0.9499\n",
      "Epoch 052 | Train Loss: 0.0897 Acc: 0.9671 | Val Loss: 0.2024 Acc: 0.9300\n",
      "Epoch 053 | Train Loss: 0.0901 Acc: 0.9651 | Val Loss: 0.1632 Acc: 0.9499\n",
      "Epoch 054 | Train Loss: 0.1099 Acc: 0.9555 | Val Loss: 0.1360 Acc: 0.9444\n",
      "Epoch 055 | Train Loss: 0.0966 Acc: 0.9633 | Val Loss: 0.1467 Acc: 0.9481\n",
      "Epoch 056 | Train Loss: 0.0891 Acc: 0.9647 | Val Loss: 0.1446 Acc: 0.9499\n",
      "Epoch 057 | Train Loss: 0.0933 Acc: 0.9657 | Val Loss: 0.1582 Acc: 0.9396\n",
      "Epoch 058 | Train Loss: 0.0843 Acc: 0.9689 | Val Loss: 0.1437 Acc: 0.9511\n",
      "Epoch 059 | Train Loss: 0.0827 Acc: 0.9672 | Val Loss: 0.1341 Acc: 0.9523\n",
      "Epoch 060 | Train Loss: 0.0766 Acc: 0.9740 | Val Loss: 0.1557 Acc: 0.9475\n",
      "Epoch 001 | Train Loss: 0.6809 Acc: 0.5716 | Val Loss: 0.6754 Acc: 0.5864\n",
      "Epoch 002 | Train Loss: 0.6696 Acc: 0.5944 | Val Loss: 0.6379 Acc: 0.6455\n",
      "Epoch 003 | Train Loss: 0.6232 Acc: 0.6713 | Val Loss: 0.5915 Acc: 0.6969\n",
      "Epoch 004 | Train Loss: 0.5768 Acc: 0.7134 | Val Loss: 0.5641 Acc: 0.7180\n",
      "Epoch 005 | Train Loss: 0.5471 Acc: 0.7312 | Val Loss: 0.5488 Acc: 0.7198\n",
      "Epoch 006 | Train Loss: 0.5267 Acc: 0.7426 | Val Loss: 0.5281 Acc: 0.7476\n",
      "Epoch 007 | Train Loss: 0.5102 Acc: 0.7555 | Val Loss: 0.5123 Acc: 0.7518\n",
      "Epoch 008 | Train Loss: 0.4813 Acc: 0.7652 | Val Loss: 0.4764 Acc: 0.7796\n",
      "Epoch 009 | Train Loss: 0.4827 Acc: 0.7780 | Val Loss: 0.4419 Acc: 0.7911\n",
      "Epoch 010 | Train Loss: 0.4419 Acc: 0.7937 | Val Loss: 0.4379 Acc: 0.7917\n",
      "Epoch 011 | Train Loss: 0.4152 Acc: 0.8099 | Val Loss: 0.4391 Acc: 0.7868\n",
      "Epoch 012 | Train Loss: 0.4008 Acc: 0.8175 | Val Loss: 0.3936 Acc: 0.8080\n",
      "Epoch 013 | Train Loss: 0.3802 Acc: 0.8307 | Val Loss: 0.3575 Acc: 0.8345\n",
      "Epoch 014 | Train Loss: 0.3578 Acc: 0.8433 | Val Loss: 0.3404 Acc: 0.8424\n",
      "Epoch 015 | Train Loss: 0.3301 Acc: 0.8591 | Val Loss: 0.3311 Acc: 0.8593\n",
      "Epoch 016 | Train Loss: 0.3096 Acc: 0.8668 | Val Loss: 0.2971 Acc: 0.8690\n",
      "Epoch 017 | Train Loss: 0.3047 Acc: 0.8706 | Val Loss: 0.2681 Acc: 0.8955\n",
      "Epoch 018 | Train Loss: 0.2887 Acc: 0.8824 | Val Loss: 0.2585 Acc: 0.8943\n",
      "Epoch 019 | Train Loss: 0.2628 Acc: 0.8925 | Val Loss: 0.2464 Acc: 0.9004\n",
      "Epoch 020 | Train Loss: 0.2649 Acc: 0.8869 | Val Loss: 0.2757 Acc: 0.8865\n",
      "Epoch 021 | Train Loss: 0.2582 Acc: 0.8905 | Val Loss: 0.2399 Acc: 0.8998\n",
      "Epoch 022 | Train Loss: 0.2399 Acc: 0.9050 | Val Loss: 0.2483 Acc: 0.9010\n",
      "Epoch 023 | Train Loss: 0.2383 Acc: 0.9020 | Val Loss: 0.2333 Acc: 0.9088\n",
      "Epoch 024 | Train Loss: 0.2023 Acc: 0.9174 | Val Loss: 0.2225 Acc: 0.9094\n",
      "Epoch 025 | Train Loss: 0.2246 Acc: 0.9071 | Val Loss: 0.2351 Acc: 0.9034\n",
      "Epoch 026 | Train Loss: 0.2109 Acc: 0.9164 | Val Loss: 0.2226 Acc: 0.9076\n",
      "Epoch 027 | Train Loss: 0.2024 Acc: 0.9164 | Val Loss: 0.2028 Acc: 0.9239\n",
      "Epoch 028 | Train Loss: 0.2040 Acc: 0.9186 | Val Loss: 0.1882 Acc: 0.9197\n",
      "Epoch 029 | Train Loss: 0.1928 Acc: 0.9221 | Val Loss: 0.2251 Acc: 0.9185\n",
      "Epoch 030 | Train Loss: 0.1832 Acc: 0.9280 | Val Loss: 0.2431 Acc: 0.9010\n",
      "Epoch 031 | Train Loss: 0.1847 Acc: 0.9278 | Val Loss: 0.1880 Acc: 0.9312\n",
      "Epoch 032 | Train Loss: 0.1704 Acc: 0.9349 | Val Loss: 0.1785 Acc: 0.9287\n",
      "Epoch 033 | Train Loss: 0.1771 Acc: 0.9339 | Val Loss: 0.1900 Acc: 0.9269\n",
      "Epoch 034 | Train Loss: 0.1736 Acc: 0.9307 | Val Loss: 0.2060 Acc: 0.9221\n",
      "Epoch 035 | Train Loss: 0.1614 Acc: 0.9379 | Val Loss: 0.1835 Acc: 0.9306\n",
      "Epoch 036 | Train Loss: 0.1552 Acc: 0.9404 | Val Loss: 0.1678 Acc: 0.9312\n",
      "Epoch 037 | Train Loss: 0.1502 Acc: 0.9423 | Val Loss: 0.1709 Acc: 0.9366\n",
      "Epoch 038 | Train Loss: 0.1579 Acc: 0.9407 | Val Loss: 0.1696 Acc: 0.9372\n",
      "Epoch 039 | Train Loss: 0.1381 Acc: 0.9491 | Val Loss: 0.1744 Acc: 0.9378\n",
      "Epoch 040 | Train Loss: 0.1474 Acc: 0.9416 | Val Loss: 0.1932 Acc: 0.9221\n",
      "Epoch 041 | Train Loss: 0.1470 Acc: 0.9452 | Val Loss: 0.2256 Acc: 0.9167\n",
      "Epoch 042 | Train Loss: 0.1351 Acc: 0.9485 | Val Loss: 0.1672 Acc: 0.9366\n",
      "Epoch 043 | Train Loss: 0.1380 Acc: 0.9505 | Val Loss: 0.1880 Acc: 0.9263\n",
      "Epoch 044 | Train Loss: 0.1415 Acc: 0.9470 | Val Loss: 0.1645 Acc: 0.9420\n",
      "Epoch 045 | Train Loss: 0.1306 Acc: 0.9539 | Val Loss: 0.1654 Acc: 0.9384\n",
      "Epoch 046 | Train Loss: 0.1201 Acc: 0.9559 | Val Loss: 0.1791 Acc: 0.9372\n",
      "Epoch 047 | Train Loss: 0.1290 Acc: 0.9509 | Val Loss: 0.1927 Acc: 0.9293\n",
      "Epoch 048 | Train Loss: 0.1300 Acc: 0.9503 | Val Loss: 0.1764 Acc: 0.9281\n",
      "Epoch 049 | Train Loss: 0.1210 Acc: 0.9552 | Val Loss: 0.1701 Acc: 0.9444\n",
      "Epoch 050 | Train Loss: 0.1224 Acc: 0.9511 | Val Loss: 0.1812 Acc: 0.9336\n",
      "Epoch 051 | Train Loss: 0.1181 Acc: 0.9597 | Val Loss: 0.1597 Acc: 0.9475\n",
      "Epoch 052 | Train Loss: 0.1278 Acc: 0.9514 | Val Loss: 0.1677 Acc: 0.9384\n",
      "Epoch 053 | Train Loss: 0.1163 Acc: 0.9567 | Val Loss: 0.1653 Acc: 0.9402\n",
      "Epoch 054 | Train Loss: 0.1160 Acc: 0.9561 | Val Loss: 0.1636 Acc: 0.9408\n",
      "Epoch 055 | Train Loss: 0.1070 Acc: 0.9579 | Val Loss: 0.1367 Acc: 0.9463\n",
      "Epoch 056 | Train Loss: 0.1164 Acc: 0.9573 | Val Loss: 0.1811 Acc: 0.9330\n",
      "Epoch 057 | Train Loss: 0.1049 Acc: 0.9598 | Val Loss: 0.2380 Acc: 0.9300\n",
      "Epoch 058 | Train Loss: 0.1071 Acc: 0.9595 | Val Loss: 0.1502 Acc: 0.9457\n",
      "Epoch 059 | Train Loss: 0.1078 Acc: 0.9589 | Val Loss: 0.1951 Acc: 0.9312\n",
      "Epoch 060 | Train Loss: 0.1148 Acc: 0.9574 | Val Loss: 0.1471 Acc: 0.9438\n",
      "Epoch 001 | Train Loss: 0.6805 Acc: 0.5736 | Val Loss: 0.6754 Acc: 0.5912\n",
      "Epoch 002 | Train Loss: 0.6742 Acc: 0.5923 | Val Loss: 0.6787 Acc: 0.5809\n",
      "Epoch 003 | Train Loss: 0.6672 Acc: 0.6012 | Val Loss: 0.6602 Acc: 0.6021\n",
      "Epoch 004 | Train Loss: 0.6491 Acc: 0.6268 | Val Loss: 0.6366 Acc: 0.6461\n",
      "Epoch 005 | Train Loss: 0.6148 Acc: 0.6751 | Val Loss: 0.5878 Acc: 0.6938\n",
      "Epoch 006 | Train Loss: 0.5745 Acc: 0.7152 | Val Loss: 0.5635 Acc: 0.7180\n",
      "Epoch 007 | Train Loss: 0.5557 Acc: 0.7229 | Val Loss: 0.5564 Acc: 0.7138\n",
      "Epoch 008 | Train Loss: 0.5295 Acc: 0.7403 | Val Loss: 0.5270 Acc: 0.7301\n",
      "Epoch 009 | Train Loss: 0.5192 Acc: 0.7512 | Val Loss: 0.5191 Acc: 0.7397\n",
      "Epoch 010 | Train Loss: 0.5010 Acc: 0.7586 | Val Loss: 0.4966 Acc: 0.7609\n",
      "Epoch 011 | Train Loss: 0.4769 Acc: 0.7782 | Val Loss: 0.4811 Acc: 0.7603\n",
      "Epoch 012 | Train Loss: 0.4584 Acc: 0.7865 | Val Loss: 0.4778 Acc: 0.7760\n",
      "Epoch 013 | Train Loss: 0.4324 Acc: 0.8022 | Val Loss: 0.4121 Acc: 0.8025\n",
      "Epoch 014 | Train Loss: 0.4179 Acc: 0.8048 | Val Loss: 0.3983 Acc: 0.8273\n",
      "Epoch 015 | Train Loss: 0.3937 Acc: 0.8170 | Val Loss: 0.3908 Acc: 0.8146\n",
      "Epoch 016 | Train Loss: 0.3713 Acc: 0.8312 | Val Loss: 0.3678 Acc: 0.8303\n",
      "Epoch 017 | Train Loss: 0.3471 Acc: 0.8433 | Val Loss: 0.3402 Acc: 0.8514\n",
      "Epoch 018 | Train Loss: 0.3275 Acc: 0.8566 | Val Loss: 0.3257 Acc: 0.8563\n",
      "Epoch 019 | Train Loss: 0.3039 Acc: 0.8677 | Val Loss: 0.3136 Acc: 0.8617\n",
      "Epoch 020 | Train Loss: 0.3077 Acc: 0.8683 | Val Loss: 0.3297 Acc: 0.8484\n",
      "Epoch 021 | Train Loss: 0.2769 Acc: 0.8819 | Val Loss: 0.3147 Acc: 0.8599\n",
      "Epoch 022 | Train Loss: 0.2685 Acc: 0.8857 | Val Loss: 0.3153 Acc: 0.8635\n",
      "Epoch 023 | Train Loss: 0.2508 Acc: 0.8936 | Val Loss: 0.2627 Acc: 0.8877\n",
      "Epoch 024 | Train Loss: 0.2441 Acc: 0.8979 | Val Loss: 0.2681 Acc: 0.8895\n",
      "Epoch 025 | Train Loss: 0.2308 Acc: 0.9034 | Val Loss: 0.2461 Acc: 0.9070\n",
      "Epoch 026 | Train Loss: 0.2205 Acc: 0.9103 | Val Loss: 0.2831 Acc: 0.8810\n",
      "Epoch 027 | Train Loss: 0.2251 Acc: 0.9065 | Val Loss: 0.2416 Acc: 0.9022\n",
      "Epoch 028 | Train Loss: 0.1891 Acc: 0.9212 | Val Loss: 0.2303 Acc: 0.9070\n",
      "Epoch 029 | Train Loss: 0.1876 Acc: 0.9227 | Val Loss: 0.2681 Acc: 0.8955\n",
      "Epoch 030 | Train Loss: 0.1847 Acc: 0.9274 | Val Loss: 0.2160 Acc: 0.9130\n",
      "Epoch 031 | Train Loss: 0.1659 Acc: 0.9358 | Val Loss: 0.1957 Acc: 0.9203\n",
      "Epoch 032 | Train Loss: 0.1603 Acc: 0.9363 | Val Loss: 0.2274 Acc: 0.9118\n",
      "Epoch 033 | Train Loss: 0.1694 Acc: 0.9345 | Val Loss: 0.1867 Acc: 0.9293\n",
      "Epoch 034 | Train Loss: 0.1577 Acc: 0.9405 | Val Loss: 0.2327 Acc: 0.9022\n",
      "Epoch 035 | Train Loss: 0.1535 Acc: 0.9407 | Val Loss: 0.2035 Acc: 0.9197\n",
      "Epoch 036 | Train Loss: 0.1487 Acc: 0.9440 | Val Loss: 0.1748 Acc: 0.9312\n",
      "Epoch 037 | Train Loss: 0.1333 Acc: 0.9470 | Val Loss: 0.1975 Acc: 0.9209\n",
      "Epoch 038 | Train Loss: 0.1220 Acc: 0.9520 | Val Loss: 0.1442 Acc: 0.9481\n",
      "Epoch 039 | Train Loss: 0.1238 Acc: 0.9523 | Val Loss: 0.1986 Acc: 0.9221\n",
      "Epoch 040 | Train Loss: 0.1185 Acc: 0.9512 | Val Loss: 0.1555 Acc: 0.9402\n",
      "Epoch 041 | Train Loss: 0.1108 Acc: 0.9592 | Val Loss: 0.1629 Acc: 0.9390\n",
      "Epoch 042 | Train Loss: 0.1153 Acc: 0.9539 | Val Loss: 0.1579 Acc: 0.9457\n",
      "Epoch 043 | Train Loss: 0.1070 Acc: 0.9591 | Val Loss: 0.1553 Acc: 0.9432\n",
      "Epoch 044 | Train Loss: 0.0986 Acc: 0.9627 | Val Loss: 0.2092 Acc: 0.9263\n",
      "Epoch 045 | Train Loss: 0.1073 Acc: 0.9577 | Val Loss: 0.1589 Acc: 0.9438\n",
      "Epoch 046 | Train Loss: 0.0938 Acc: 0.9635 | Val Loss: 0.1663 Acc: 0.9366\n",
      "Epoch 047 | Train Loss: 0.0949 Acc: 0.9668 | Val Loss: 0.1780 Acc: 0.9330\n",
      "Epoch 048 | Train Loss: 0.0866 Acc: 0.9665 | Val Loss: 0.1236 Acc: 0.9511\n",
      "Epoch 049 | Train Loss: 0.0898 Acc: 0.9674 | Val Loss: 0.1760 Acc: 0.9336\n",
      "Epoch 050 | Train Loss: 0.0893 Acc: 0.9629 | Val Loss: 0.1329 Acc: 0.9487\n",
      "Epoch 051 | Train Loss: 0.0873 Acc: 0.9666 | Val Loss: 0.1125 Acc: 0.9614\n",
      "Epoch 052 | Train Loss: 0.0864 Acc: 0.9674 | Val Loss: 0.1388 Acc: 0.9499\n",
      "Epoch 053 | Train Loss: 0.0853 Acc: 0.9669 | Val Loss: 0.1450 Acc: 0.9481\n",
      "Epoch 054 | Train Loss: 0.0848 Acc: 0.9707 | Val Loss: 0.1682 Acc: 0.9366\n",
      "Epoch 055 | Train Loss: 0.0773 Acc: 0.9700 | Val Loss: 0.1735 Acc: 0.9438\n",
      "Epoch 056 | Train Loss: 0.0870 Acc: 0.9683 | Val Loss: 0.1381 Acc: 0.9463\n",
      "Epoch 057 | Train Loss: 0.0723 Acc: 0.9707 | Val Loss: 0.1897 Acc: 0.9366\n",
      "Epoch 058 | Train Loss: 0.0732 Acc: 0.9731 | Val Loss: 0.1738 Acc: 0.9426\n",
      "Epoch 059 | Train Loss: 0.0655 Acc: 0.9770 | Val Loss: 0.1770 Acc: 0.9420\n",
      "Epoch 060 | Train Loss: 0.0751 Acc: 0.9707 | Val Loss: 0.1396 Acc: 0.9487\n",
      "Epoch 001 | Train Loss: 0.6792 Acc: 0.5803 | Val Loss: 0.6775 Acc: 0.5857\n",
      "Epoch 002 | Train Loss: 0.6706 Acc: 0.5922 | Val Loss: 0.6694 Acc: 0.6021\n",
      "Epoch 003 | Train Loss: 0.6581 Acc: 0.6129 | Val Loss: 0.6419 Acc: 0.6643\n",
      "Epoch 004 | Train Loss: 0.6210 Acc: 0.6752 | Val Loss: 0.6074 Acc: 0.6842\n",
      "Epoch 005 | Train Loss: 0.5864 Acc: 0.7071 | Val Loss: 0.5648 Acc: 0.7101\n",
      "Epoch 006 | Train Loss: 0.5681 Acc: 0.7177 | Val Loss: 0.5629 Acc: 0.7095\n",
      "Epoch 007 | Train Loss: 0.5398 Acc: 0.7380 | Val Loss: 0.5477 Acc: 0.7174\n",
      "Epoch 008 | Train Loss: 0.5390 Acc: 0.7358 | Val Loss: 0.5452 Acc: 0.7168\n",
      "Epoch 009 | Train Loss: 0.5140 Acc: 0.7492 | Val Loss: 0.5391 Acc: 0.7174\n",
      "Epoch 010 | Train Loss: 0.5056 Acc: 0.7572 | Val Loss: 0.4913 Acc: 0.7566\n",
      "Epoch 011 | Train Loss: 0.4860 Acc: 0.7649 | Val Loss: 0.4717 Acc: 0.7699\n",
      "Epoch 012 | Train Loss: 0.4692 Acc: 0.7749 | Val Loss: 0.4574 Acc: 0.7760\n",
      "Epoch 013 | Train Loss: 0.4575 Acc: 0.7823 | Val Loss: 0.4387 Acc: 0.7947\n",
      "Epoch 014 | Train Loss: 0.4461 Acc: 0.7913 | Val Loss: 0.4502 Acc: 0.7868\n",
      "Epoch 015 | Train Loss: 0.4263 Acc: 0.8013 | Val Loss: 0.4200 Acc: 0.8037\n",
      "Epoch 016 | Train Loss: 0.4112 Acc: 0.8105 | Val Loss: 0.4115 Acc: 0.8080\n",
      "Epoch 017 | Train Loss: 0.4063 Acc: 0.8132 | Val Loss: 0.3805 Acc: 0.8243\n",
      "Epoch 018 | Train Loss: 0.3849 Acc: 0.8255 | Val Loss: 0.3637 Acc: 0.8460\n",
      "Epoch 019 | Train Loss: 0.3756 Acc: 0.8318 | Val Loss: 0.3588 Acc: 0.8333\n",
      "Epoch 020 | Train Loss: 0.3548 Acc: 0.8454 | Val Loss: 0.3459 Acc: 0.8490\n",
      "Epoch 021 | Train Loss: 0.3470 Acc: 0.8467 | Val Loss: 0.3489 Acc: 0.8436\n",
      "Epoch 022 | Train Loss: 0.3270 Acc: 0.8594 | Val Loss: 0.3141 Acc: 0.8708\n",
      "Epoch 023 | Train Loss: 0.3176 Acc: 0.8620 | Val Loss: 0.3161 Acc: 0.8623\n",
      "Epoch 024 | Train Loss: 0.3001 Acc: 0.8692 | Val Loss: 0.3084 Acc: 0.8653\n",
      "Epoch 025 | Train Loss: 0.2855 Acc: 0.8798 | Val Loss: 0.2782 Acc: 0.8895\n",
      "Epoch 026 | Train Loss: 0.2761 Acc: 0.8856 | Val Loss: 0.2603 Acc: 0.8943\n",
      "Epoch 027 | Train Loss: 0.2661 Acc: 0.8893 | Val Loss: 0.2719 Acc: 0.8835\n",
      "Epoch 028 | Train Loss: 0.2582 Acc: 0.8958 | Val Loss: 0.2831 Acc: 0.8774\n",
      "Epoch 029 | Train Loss: 0.2413 Acc: 0.8990 | Val Loss: 0.2458 Acc: 0.8967\n",
      "Epoch 030 | Train Loss: 0.2414 Acc: 0.9016 | Val Loss: 0.2363 Acc: 0.9028\n",
      "Epoch 031 | Train Loss: 0.2320 Acc: 0.9055 | Val Loss: 0.2669 Acc: 0.8829\n",
      "Epoch 032 | Train Loss: 0.2265 Acc: 0.9062 | Val Loss: 0.2459 Acc: 0.8986\n",
      "Epoch 033 | Train Loss: 0.2169 Acc: 0.9135 | Val Loss: 0.2902 Acc: 0.8895\n",
      "Epoch 034 | Train Loss: 0.2090 Acc: 0.9156 | Val Loss: 0.2488 Acc: 0.8955\n",
      "Epoch 035 | Train Loss: 0.2015 Acc: 0.9254 | Val Loss: 0.2215 Acc: 0.9130\n",
      "Epoch 036 | Train Loss: 0.1987 Acc: 0.9183 | Val Loss: 0.2077 Acc: 0.9136\n",
      "Epoch 037 | Train Loss: 0.1899 Acc: 0.9251 | Val Loss: 0.2053 Acc: 0.9221\n",
      "Epoch 038 | Train Loss: 0.1702 Acc: 0.9361 | Val Loss: 0.2008 Acc: 0.9227\n",
      "Epoch 039 | Train Loss: 0.1804 Acc: 0.9287 | Val Loss: 0.1972 Acc: 0.9215\n",
      "Epoch 040 | Train Loss: 0.1792 Acc: 0.9296 | Val Loss: 0.1963 Acc: 0.9257\n",
      "Epoch 041 | Train Loss: 0.1724 Acc: 0.9307 | Val Loss: 0.1755 Acc: 0.9245\n",
      "Epoch 042 | Train Loss: 0.1621 Acc: 0.9355 | Val Loss: 0.2045 Acc: 0.9197\n",
      "Epoch 043 | Train Loss: 0.1640 Acc: 0.9364 | Val Loss: 0.1975 Acc: 0.9161\n",
      "Epoch 044 | Train Loss: 0.1623 Acc: 0.9388 | Val Loss: 0.1798 Acc: 0.9300\n",
      "Epoch 045 | Train Loss: 0.1567 Acc: 0.9395 | Val Loss: 0.2161 Acc: 0.9070\n",
      "Epoch 046 | Train Loss: 0.1377 Acc: 0.9465 | Val Loss: 0.1804 Acc: 0.9257\n",
      "Epoch 047 | Train Loss: 0.1485 Acc: 0.9408 | Val Loss: 0.1837 Acc: 0.9227\n",
      "Epoch 048 | Train Loss: 0.1331 Acc: 0.9491 | Val Loss: 0.1776 Acc: 0.9336\n",
      "Epoch 049 | Train Loss: 0.1350 Acc: 0.9487 | Val Loss: 0.1628 Acc: 0.9306\n",
      "Epoch 050 | Train Loss: 0.1235 Acc: 0.9538 | Val Loss: 0.2087 Acc: 0.9221\n",
      "Epoch 051 | Train Loss: 0.1235 Acc: 0.9550 | Val Loss: 0.1977 Acc: 0.9275\n",
      "Epoch 052 | Train Loss: 0.1318 Acc: 0.9521 | Val Loss: 0.1687 Acc: 0.9318\n",
      "Epoch 053 | Train Loss: 0.1142 Acc: 0.9544 | Val Loss: 0.1883 Acc: 0.9281\n",
      "Epoch 054 | Train Loss: 0.1096 Acc: 0.9567 | Val Loss: 0.1497 Acc: 0.9444\n",
      "Epoch 055 | Train Loss: 0.1245 Acc: 0.9547 | Val Loss: 0.1681 Acc: 0.9318\n",
      "Epoch 056 | Train Loss: 0.1212 Acc: 0.9529 | Val Loss: 0.1539 Acc: 0.9348\n",
      "Epoch 057 | Train Loss: 0.1109 Acc: 0.9591 | Val Loss: 0.1491 Acc: 0.9408\n",
      "Epoch 058 | Train Loss: 0.1110 Acc: 0.9580 | Val Loss: 0.1607 Acc: 0.9408\n",
      "Epoch 059 | Train Loss: 0.1116 Acc: 0.9607 | Val Loss: 0.1615 Acc: 0.9330\n",
      "Epoch 060 | Train Loss: 0.0975 Acc: 0.9630 | Val Loss: 0.1580 Acc: 0.9372\n",
      "Epoch 001 | Train Loss: 0.6796 Acc: 0.5810 | Val Loss: 0.6770 Acc: 0.5870\n",
      "Epoch 002 | Train Loss: 0.6773 Acc: 0.5854 | Val Loss: 0.6777 Acc: 0.5833\n",
      "Epoch 003 | Train Loss: 0.6744 Acc: 0.5861 | Val Loss: 0.6783 Acc: 0.5948\n",
      "Epoch 004 | Train Loss: 0.6661 Acc: 0.6014 | Val Loss: 0.6534 Acc: 0.6081\n",
      "Epoch 005 | Train Loss: 0.6277 Acc: 0.6565 | Val Loss: 0.5952 Acc: 0.6944\n",
      "Epoch 006 | Train Loss: 0.5797 Acc: 0.7038 | Val Loss: 0.5553 Acc: 0.7210\n",
      "Epoch 007 | Train Loss: 0.5534 Acc: 0.7226 | Val Loss: 0.5357 Acc: 0.7307\n",
      "Epoch 008 | Train Loss: 0.5333 Acc: 0.7364 | Val Loss: 0.5291 Acc: 0.7325\n",
      "Epoch 009 | Train Loss: 0.5210 Acc: 0.7510 | Val Loss: 0.5386 Acc: 0.7258\n",
      "Epoch 010 | Train Loss: 0.5067 Acc: 0.7560 | Val Loss: 0.5158 Acc: 0.7470\n",
      "Epoch 011 | Train Loss: 0.4768 Acc: 0.7728 | Val Loss: 0.4640 Acc: 0.7760\n",
      "Epoch 012 | Train Loss: 0.4567 Acc: 0.7907 | Val Loss: 0.4588 Acc: 0.7802\n",
      "Epoch 013 | Train Loss: 0.4326 Acc: 0.8013 | Val Loss: 0.4199 Acc: 0.8128\n",
      "Epoch 014 | Train Loss: 0.4059 Acc: 0.8167 | Val Loss: 0.4093 Acc: 0.8194\n",
      "Epoch 015 | Train Loss: 0.4004 Acc: 0.8196 | Val Loss: 0.3565 Acc: 0.8545\n",
      "Epoch 016 | Train Loss: 0.3613 Acc: 0.8427 | Val Loss: 0.3539 Acc: 0.8370\n",
      "Epoch 017 | Train Loss: 0.3440 Acc: 0.8516 | Val Loss: 0.3401 Acc: 0.8388\n",
      "Epoch 018 | Train Loss: 0.3381 Acc: 0.8567 | Val Loss: 0.3394 Acc: 0.8545\n",
      "Epoch 019 | Train Loss: 0.3135 Acc: 0.8664 | Val Loss: 0.2992 Acc: 0.8732\n",
      "Epoch 020 | Train Loss: 0.3122 Acc: 0.8611 | Val Loss: 0.3036 Acc: 0.8635\n",
      "Epoch 021 | Train Loss: 0.2858 Acc: 0.8765 | Val Loss: 0.2837 Acc: 0.8810\n",
      "Epoch 022 | Train Loss: 0.2772 Acc: 0.8836 | Val Loss: 0.2872 Acc: 0.8804\n",
      "Epoch 023 | Train Loss: 0.2630 Acc: 0.8862 | Val Loss: 0.2473 Acc: 0.9028\n",
      "Epoch 024 | Train Loss: 0.2534 Acc: 0.8949 | Val Loss: 0.2500 Acc: 0.9034\n",
      "Epoch 025 | Train Loss: 0.2496 Acc: 0.8940 | Val Loss: 0.2314 Acc: 0.9191\n",
      "Epoch 026 | Train Loss: 0.2270 Acc: 0.9049 | Val Loss: 0.2493 Acc: 0.9034\n",
      "Epoch 027 | Train Loss: 0.2279 Acc: 0.9065 | Val Loss: 0.2312 Acc: 0.9106\n",
      "Epoch 028 | Train Loss: 0.2085 Acc: 0.9123 | Val Loss: 0.2286 Acc: 0.9076\n",
      "Epoch 029 | Train Loss: 0.2168 Acc: 0.9115 | Val Loss: 0.2103 Acc: 0.9143\n",
      "Epoch 030 | Train Loss: 0.2002 Acc: 0.9206 | Val Loss: 0.2279 Acc: 0.9173\n",
      "Epoch 031 | Train Loss: 0.1911 Acc: 0.9244 | Val Loss: 0.2218 Acc: 0.9100\n",
      "Epoch 032 | Train Loss: 0.1877 Acc: 0.9250 | Val Loss: 0.1998 Acc: 0.9275\n",
      "Epoch 033 | Train Loss: 0.1801 Acc: 0.9283 | Val Loss: 0.2006 Acc: 0.9173\n",
      "Epoch 034 | Train Loss: 0.1812 Acc: 0.9284 | Val Loss: 0.2094 Acc: 0.9191\n",
      "Epoch 035 | Train Loss: 0.1642 Acc: 0.9358 | Val Loss: 0.1859 Acc: 0.9263\n",
      "Epoch 036 | Train Loss: 0.1656 Acc: 0.9361 | Val Loss: 0.1899 Acc: 0.9263\n",
      "Epoch 037 | Train Loss: 0.1606 Acc: 0.9379 | Val Loss: 0.1687 Acc: 0.9396\n",
      "Epoch 038 | Train Loss: 0.1498 Acc: 0.9428 | Val Loss: 0.1790 Acc: 0.9281\n",
      "Epoch 039 | Train Loss: 0.1591 Acc: 0.9407 | Val Loss: 0.1987 Acc: 0.9251\n",
      "Epoch 040 | Train Loss: 0.1468 Acc: 0.9461 | Val Loss: 0.1642 Acc: 0.9360\n",
      "Epoch 041 | Train Loss: 0.1364 Acc: 0.9446 | Val Loss: 0.1811 Acc: 0.9354\n",
      "Epoch 042 | Train Loss: 0.1306 Acc: 0.9491 | Val Loss: 0.1876 Acc: 0.9336\n",
      "Epoch 043 | Train Loss: 0.1317 Acc: 0.9499 | Val Loss: 0.1990 Acc: 0.9275\n",
      "Epoch 044 | Train Loss: 0.1401 Acc: 0.9465 | Val Loss: 0.1553 Acc: 0.9396\n",
      "Epoch 045 | Train Loss: 0.1241 Acc: 0.9549 | Val Loss: 0.1652 Acc: 0.9330\n",
      "Epoch 046 | Train Loss: 0.1210 Acc: 0.9535 | Val Loss: 0.1467 Acc: 0.9517\n",
      "Epoch 047 | Train Loss: 0.1181 Acc: 0.9570 | Val Loss: 0.1657 Acc: 0.9348\n",
      "Epoch 048 | Train Loss: 0.1138 Acc: 0.9573 | Val Loss: 0.1823 Acc: 0.9354\n",
      "Epoch 049 | Train Loss: 0.1093 Acc: 0.9594 | Val Loss: 0.1623 Acc: 0.9414\n",
      "Epoch 050 | Train Loss: 0.1094 Acc: 0.9567 | Val Loss: 0.1454 Acc: 0.9499\n",
      "Epoch 051 | Train Loss: 0.1195 Acc: 0.9561 | Val Loss: 0.1578 Acc: 0.9372\n",
      "Epoch 052 | Train Loss: 0.0981 Acc: 0.9624 | Val Loss: 0.1402 Acc: 0.9559\n",
      "Epoch 053 | Train Loss: 0.1048 Acc: 0.9588 | Val Loss: 0.1397 Acc: 0.9499\n",
      "Epoch 054 | Train Loss: 0.0942 Acc: 0.9650 | Val Loss: 0.1686 Acc: 0.9402\n",
      "Epoch 055 | Train Loss: 0.1097 Acc: 0.9589 | Val Loss: 0.1312 Acc: 0.9517\n",
      "Epoch 056 | Train Loss: 0.1021 Acc: 0.9610 | Val Loss: 0.1395 Acc: 0.9475\n",
      "Epoch 057 | Train Loss: 0.1038 Acc: 0.9609 | Val Loss: 0.1409 Acc: 0.9390\n",
      "Epoch 058 | Train Loss: 0.0911 Acc: 0.9672 | Val Loss: 0.1379 Acc: 0.9450\n",
      "Epoch 059 | Train Loss: 0.0876 Acc: 0.9663 | Val Loss: 0.1327 Acc: 0.9559\n",
      "Epoch 060 | Train Loss: 0.0876 Acc: 0.9686 | Val Loss: 0.1441 Acc: 0.9499\n",
      "Epoch 001 | Train Loss: 0.6752 Acc: 0.5858 | Val Loss: 0.6807 Acc: 0.5785\n",
      "Epoch 002 | Train Loss: 0.6598 Acc: 0.6118 | Val Loss: 0.6445 Acc: 0.6286\n",
      "Epoch 003 | Train Loss: 0.6406 Acc: 0.6474 | Val Loss: 0.6171 Acc: 0.6739\n",
      "Epoch 004 | Train Loss: 0.5938 Acc: 0.6971 | Val Loss: 0.5692 Acc: 0.7156\n",
      "Epoch 005 | Train Loss: 0.5635 Acc: 0.7161 | Val Loss: 0.5699 Acc: 0.7041\n",
      "Epoch 006 | Train Loss: 0.5284 Acc: 0.7377 | Val Loss: 0.5364 Acc: 0.7258\n",
      "Epoch 007 | Train Loss: 0.5095 Acc: 0.7555 | Val Loss: 0.4948 Acc: 0.7585\n",
      "Epoch 008 | Train Loss: 0.4846 Acc: 0.7608 | Val Loss: 0.5383 Acc: 0.7234\n",
      "Epoch 009 | Train Loss: 0.4751 Acc: 0.7732 | Val Loss: 0.4812 Acc: 0.7542\n",
      "Epoch 010 | Train Loss: 0.4487 Acc: 0.7835 | Val Loss: 0.4535 Acc: 0.7832\n",
      "Epoch 011 | Train Loss: 0.4271 Acc: 0.7980 | Val Loss: 0.4357 Acc: 0.7965\n",
      "Epoch 012 | Train Loss: 0.3941 Acc: 0.8156 | Val Loss: 0.4069 Acc: 0.8050\n",
      "Epoch 013 | Train Loss: 0.3929 Acc: 0.8191 | Val Loss: 0.4007 Acc: 0.8213\n",
      "Epoch 014 | Train Loss: 0.3693 Acc: 0.8365 | Val Loss: 0.3750 Acc: 0.8448\n",
      "Epoch 015 | Train Loss: 0.3569 Acc: 0.8422 | Val Loss: 0.3413 Acc: 0.8496\n",
      "Epoch 016 | Train Loss: 0.3194 Acc: 0.8655 | Val Loss: 0.3495 Acc: 0.8394\n",
      "Epoch 017 | Train Loss: 0.2910 Acc: 0.8777 | Val Loss: 0.4069 Acc: 0.8170\n",
      "Epoch 018 | Train Loss: 0.2778 Acc: 0.8842 | Val Loss: 0.3211 Acc: 0.8581\n",
      "Epoch 019 | Train Loss: 0.2477 Acc: 0.8969 | Val Loss: 0.3968 Acc: 0.8466\n",
      "Epoch 020 | Train Loss: 0.2349 Acc: 0.9079 | Val Loss: 0.2240 Acc: 0.9106\n",
      "Epoch 021 | Train Loss: 0.2030 Acc: 0.9171 | Val Loss: 0.2490 Acc: 0.8998\n",
      "Epoch 022 | Train Loss: 0.2131 Acc: 0.9117 | Val Loss: 0.2266 Acc: 0.9052\n",
      "Epoch 023 | Train Loss: 0.1872 Acc: 0.9280 | Val Loss: 0.2152 Acc: 0.9185\n",
      "Epoch 024 | Train Loss: 0.1742 Acc: 0.9286 | Val Loss: 0.1987 Acc: 0.9281\n",
      "Epoch 025 | Train Loss: 0.1648 Acc: 0.9355 | Val Loss: 0.2165 Acc: 0.9155\n",
      "Epoch 026 | Train Loss: 0.1539 Acc: 0.9375 | Val Loss: 0.2259 Acc: 0.9076\n",
      "Epoch 027 | Train Loss: 0.1388 Acc: 0.9469 | Val Loss: 0.1825 Acc: 0.9318\n",
      "Epoch 028 | Train Loss: 0.1405 Acc: 0.9470 | Val Loss: 0.1905 Acc: 0.9300\n",
      "Epoch 029 | Train Loss: 0.1277 Acc: 0.9484 | Val Loss: 0.1629 Acc: 0.9354\n",
      "Epoch 030 | Train Loss: 0.1230 Acc: 0.9520 | Val Loss: 0.1841 Acc: 0.9245\n",
      "Epoch 031 | Train Loss: 0.1222 Acc: 0.9520 | Val Loss: 0.1758 Acc: 0.9360\n",
      "Epoch 032 | Train Loss: 0.1156 Acc: 0.9543 | Val Loss: 0.2294 Acc: 0.9221\n",
      "Epoch 033 | Train Loss: 0.1251 Acc: 0.9476 | Val Loss: 0.2039 Acc: 0.9227\n",
      "Epoch 034 | Train Loss: 0.1053 Acc: 0.9585 | Val Loss: 0.1939 Acc: 0.9300\n",
      "Epoch 035 | Train Loss: 0.0890 Acc: 0.9651 | Val Loss: 0.1797 Acc: 0.9336\n",
      "Epoch 036 | Train Loss: 0.1031 Acc: 0.9600 | Val Loss: 0.1618 Acc: 0.9360\n",
      "Epoch 037 | Train Loss: 0.0939 Acc: 0.9657 | Val Loss: 0.2066 Acc: 0.9324\n",
      "Epoch 038 | Train Loss: 0.0812 Acc: 0.9687 | Val Loss: 0.1756 Acc: 0.9432\n",
      "Epoch 039 | Train Loss: 0.0771 Acc: 0.9739 | Val Loss: 0.1808 Acc: 0.9360\n",
      "Epoch 040 | Train Loss: 0.0837 Acc: 0.9680 | Val Loss: 0.2744 Acc: 0.9136\n",
      "Epoch 041 | Train Loss: 0.0771 Acc: 0.9722 | Val Loss: 0.1904 Acc: 0.9330\n",
      "Epoch 042 | Train Loss: 0.0784 Acc: 0.9703 | Val Loss: 0.1691 Acc: 0.9457\n",
      "Epoch 043 | Train Loss: 0.0729 Acc: 0.9712 | Val Loss: 0.1588 Acc: 0.9396\n",
      "Epoch 044 | Train Loss: 0.0714 Acc: 0.9722 | Val Loss: 0.1561 Acc: 0.9438\n",
      "Epoch 045 | Train Loss: 0.0693 Acc: 0.9739 | Val Loss: 0.1449 Acc: 0.9517\n",
      "Epoch 046 | Train Loss: 0.0681 Acc: 0.9739 | Val Loss: 0.1812 Acc: 0.9372\n",
      "Epoch 047 | Train Loss: 0.0697 Acc: 0.9745 | Val Loss: 0.1761 Acc: 0.9384\n",
      "Epoch 048 | Train Loss: 0.0654 Acc: 0.9761 | Val Loss: 0.2055 Acc: 0.9281\n",
      "Epoch 049 | Train Loss: 0.0698 Acc: 0.9722 | Val Loss: 0.2032 Acc: 0.9372\n",
      "Epoch 050 | Train Loss: 0.0717 Acc: 0.9739 | Val Loss: 0.1865 Acc: 0.9312\n",
      "Epoch 051 | Train Loss: 0.0656 Acc: 0.9769 | Val Loss: 0.1829 Acc: 0.9396\n",
      "Epoch 052 | Train Loss: 0.0513 Acc: 0.9811 | Val Loss: 0.1627 Acc: 0.9481\n",
      "Epoch 053 | Train Loss: 0.0575 Acc: 0.9781 | Val Loss: 0.1441 Acc: 0.9505\n",
      "Epoch 054 | Train Loss: 0.0573 Acc: 0.9783 | Val Loss: 0.1393 Acc: 0.9505\n",
      "Epoch 055 | Train Loss: 0.0481 Acc: 0.9819 | Val Loss: 0.1702 Acc: 0.9475\n",
      "Epoch 056 | Train Loss: 0.0471 Acc: 0.9825 | Val Loss: 0.2258 Acc: 0.9300\n",
      "Epoch 057 | Train Loss: 0.0614 Acc: 0.9766 | Val Loss: 0.1261 Acc: 0.9583\n",
      "Epoch 058 | Train Loss: 0.0543 Acc: 0.9808 | Val Loss: 0.1458 Acc: 0.9529\n",
      "Epoch 059 | Train Loss: 0.0517 Acc: 0.9829 | Val Loss: 0.1158 Acc: 0.9577\n",
      "Epoch 060 | Train Loss: 0.0587 Acc: 0.9777 | Val Loss: 0.1398 Acc: 0.9517\n",
      "Iteration 31/40 | Best Val Loss: 0.1122 | Iter Time: 222.05s | Total Time: 127.51 min\n",
      "Epoch 001 | Train Loss: 0.6779 Acc: 0.5851 | Val Loss: 0.6732 Acc: 0.5918\n",
      "Epoch 002 | Train Loss: 0.6776 Acc: 0.5799 | Val Loss: 0.6757 Acc: 0.5815\n",
      "Epoch 003 | Train Loss: 0.6695 Acc: 0.5958 | Val Loss: 0.6708 Acc: 0.6008\n",
      "Epoch 004 | Train Loss: 0.6612 Acc: 0.6043 | Val Loss: 0.6652 Acc: 0.6063\n",
      "Epoch 005 | Train Loss: 0.6539 Acc: 0.6142 | Val Loss: 0.6496 Acc: 0.6486\n",
      "Epoch 006 | Train Loss: 0.6280 Acc: 0.6619 | Val Loss: 0.6143 Acc: 0.6697\n",
      "Epoch 007 | Train Loss: 0.6104 Acc: 0.6861 | Val Loss: 0.5987 Acc: 0.6866\n",
      "Epoch 008 | Train Loss: 0.5790 Acc: 0.7109 | Val Loss: 0.5813 Acc: 0.6993\n",
      "Epoch 009 | Train Loss: 0.5636 Acc: 0.7198 | Val Loss: 0.5584 Acc: 0.7156\n",
      "Epoch 010 | Train Loss: 0.5381 Acc: 0.7380 | Val Loss: 0.5437 Acc: 0.7228\n",
      "Epoch 011 | Train Loss: 0.5295 Acc: 0.7420 | Val Loss: 0.5391 Acc: 0.7144\n",
      "Epoch 012 | Train Loss: 0.5164 Acc: 0.7435 | Val Loss: 0.5222 Acc: 0.7355\n",
      "Epoch 013 | Train Loss: 0.4996 Acc: 0.7549 | Val Loss: 0.5376 Acc: 0.7198\n",
      "Epoch 014 | Train Loss: 0.4880 Acc: 0.7699 | Val Loss: 0.4959 Acc: 0.7615\n",
      "Epoch 015 | Train Loss: 0.4694 Acc: 0.7805 | Val Loss: 0.5045 Acc: 0.7530\n",
      "Epoch 016 | Train Loss: 0.4589 Acc: 0.7820 | Val Loss: 0.4616 Acc: 0.7802\n",
      "Epoch 017 | Train Loss: 0.4420 Acc: 0.7956 | Val Loss: 0.4361 Acc: 0.7971\n",
      "Epoch 018 | Train Loss: 0.4221 Acc: 0.8034 | Val Loss: 0.4186 Acc: 0.8062\n",
      "Epoch 019 | Train Loss: 0.4048 Acc: 0.8144 | Val Loss: 0.3879 Acc: 0.8200\n",
      "Epoch 020 | Train Loss: 0.3808 Acc: 0.8288 | Val Loss: 0.3810 Acc: 0.8267\n",
      "Epoch 021 | Train Loss: 0.3667 Acc: 0.8368 | Val Loss: 0.4058 Acc: 0.8146\n",
      "Epoch 022 | Train Loss: 0.3494 Acc: 0.8474 | Val Loss: 0.3456 Acc: 0.8478\n",
      "Epoch 023 | Train Loss: 0.3473 Acc: 0.8458 | Val Loss: 0.3486 Acc: 0.8400\n",
      "Epoch 024 | Train Loss: 0.3205 Acc: 0.8641 | Val Loss: 0.3469 Acc: 0.8370\n",
      "Epoch 025 | Train Loss: 0.3154 Acc: 0.8679 | Val Loss: 0.3055 Acc: 0.8635\n",
      "Epoch 026 | Train Loss: 0.2860 Acc: 0.8815 | Val Loss: 0.3400 Acc: 0.8557\n",
      "Epoch 027 | Train Loss: 0.2874 Acc: 0.8754 | Val Loss: 0.2907 Acc: 0.8792\n",
      "Epoch 028 | Train Loss: 0.2613 Acc: 0.8926 | Val Loss: 0.3243 Acc: 0.8641\n",
      "Epoch 029 | Train Loss: 0.2601 Acc: 0.8936 | Val Loss: 0.2529 Acc: 0.8865\n",
      "Epoch 030 | Train Loss: 0.2499 Acc: 0.8955 | Val Loss: 0.2779 Acc: 0.8829\n",
      "Epoch 031 | Train Loss: 0.2387 Acc: 0.9031 | Val Loss: 0.2945 Acc: 0.8653\n",
      "Epoch 032 | Train Loss: 0.2312 Acc: 0.9028 | Val Loss: 0.2575 Acc: 0.8901\n",
      "Epoch 033 | Train Loss: 0.2223 Acc: 0.9115 | Val Loss: 0.2494 Acc: 0.8835\n",
      "Epoch 034 | Train Loss: 0.2067 Acc: 0.9132 | Val Loss: 0.2291 Acc: 0.9052\n",
      "Epoch 035 | Train Loss: 0.2087 Acc: 0.9168 | Val Loss: 0.2482 Acc: 0.8937\n",
      "Epoch 036 | Train Loss: 0.1986 Acc: 0.9201 | Val Loss: 0.2262 Acc: 0.9088\n",
      "Epoch 037 | Train Loss: 0.1900 Acc: 0.9245 | Val Loss: 0.2150 Acc: 0.9118\n",
      "Epoch 038 | Train Loss: 0.1902 Acc: 0.9256 | Val Loss: 0.2424 Acc: 0.8961\n",
      "Epoch 039 | Train Loss: 0.1872 Acc: 0.9278 | Val Loss: 0.2360 Acc: 0.9088\n",
      "Epoch 040 | Train Loss: 0.1670 Acc: 0.9348 | Val Loss: 0.2208 Acc: 0.9124\n",
      "Epoch 041 | Train Loss: 0.1677 Acc: 0.9361 | Val Loss: 0.2109 Acc: 0.9124\n",
      "Epoch 042 | Train Loss: 0.1641 Acc: 0.9319 | Val Loss: 0.2182 Acc: 0.9161\n",
      "Epoch 043 | Train Loss: 0.1560 Acc: 0.9419 | Val Loss: 0.2274 Acc: 0.9100\n",
      "Epoch 044 | Train Loss: 0.1599 Acc: 0.9348 | Val Loss: 0.2258 Acc: 0.9076\n",
      "Epoch 045 | Train Loss: 0.1518 Acc: 0.9392 | Val Loss: 0.2684 Acc: 0.8979\n",
      "Epoch 046 | Train Loss: 0.1387 Acc: 0.9462 | Val Loss: 0.2470 Acc: 0.9076\n",
      "Epoch 047 | Train Loss: 0.1379 Acc: 0.9481 | Val Loss: 0.1929 Acc: 0.9251\n",
      "Epoch 048 | Train Loss: 0.1363 Acc: 0.9472 | Val Loss: 0.1878 Acc: 0.9263\n",
      "Epoch 049 | Train Loss: 0.1309 Acc: 0.9482 | Val Loss: 0.2183 Acc: 0.9209\n",
      "Epoch 050 | Train Loss: 0.1378 Acc: 0.9465 | Val Loss: 0.1842 Acc: 0.9257\n",
      "Epoch 051 | Train Loss: 0.1302 Acc: 0.9476 | Val Loss: 0.2543 Acc: 0.9130\n",
      "Epoch 052 | Train Loss: 0.1238 Acc: 0.9541 | Val Loss: 0.2006 Acc: 0.9318\n",
      "Epoch 053 | Train Loss: 0.1276 Acc: 0.9500 | Val Loss: 0.2031 Acc: 0.9239\n",
      "Epoch 054 | Train Loss: 0.1212 Acc: 0.9518 | Val Loss: 0.1875 Acc: 0.9306\n",
      "Epoch 055 | Train Loss: 0.1141 Acc: 0.9556 | Val Loss: 0.1863 Acc: 0.9287\n",
      "Epoch 056 | Train Loss: 0.1108 Acc: 0.9564 | Val Loss: 0.1592 Acc: 0.9354\n",
      "Epoch 057 | Train Loss: 0.1175 Acc: 0.9553 | Val Loss: 0.2019 Acc: 0.9233\n",
      "Epoch 058 | Train Loss: 0.1020 Acc: 0.9612 | Val Loss: 0.1597 Acc: 0.9438\n",
      "Epoch 059 | Train Loss: 0.1023 Acc: 0.9592 | Val Loss: 0.1795 Acc: 0.9281\n",
      "Epoch 060 | Train Loss: 0.1080 Acc: 0.9582 | Val Loss: 0.1783 Acc: 0.9318\n",
      "Epoch 001 | Train Loss: 0.6780 Acc: 0.5864 | Val Loss: 0.6771 Acc: 0.5779\n",
      "Epoch 002 | Train Loss: 0.6823 Acc: 0.5719 | Val Loss: 0.6849 Acc: 0.5586\n",
      "Epoch 003 | Train Loss: 0.6760 Acc: 0.5836 | Val Loss: 0.6577 Acc: 0.5972\n",
      "Epoch 004 | Train Loss: 0.6382 Acc: 0.6453 | Val Loss: 0.6455 Acc: 0.6606\n",
      "Epoch 005 | Train Loss: 0.5964 Acc: 0.6888 | Val Loss: 0.5918 Acc: 0.6902\n",
      "Epoch 006 | Train Loss: 0.5590 Acc: 0.7225 | Val Loss: 0.5517 Acc: 0.7180\n",
      "Epoch 007 | Train Loss: 0.5344 Acc: 0.7365 | Val Loss: 0.5425 Acc: 0.7228\n",
      "Epoch 008 | Train Loss: 0.5161 Acc: 0.7465 | Val Loss: 0.5218 Acc: 0.7343\n",
      "Epoch 009 | Train Loss: 0.4783 Acc: 0.7699 | Val Loss: 0.4783 Acc: 0.7784\n",
      "Epoch 010 | Train Loss: 0.4632 Acc: 0.7814 | Val Loss: 0.4435 Acc: 0.7844\n",
      "Epoch 011 | Train Loss: 0.4298 Acc: 0.8045 | Val Loss: 0.4401 Acc: 0.8092\n",
      "Epoch 012 | Train Loss: 0.3981 Acc: 0.8202 | Val Loss: 0.3760 Acc: 0.8345\n",
      "Epoch 013 | Train Loss: 0.3741 Acc: 0.8313 | Val Loss: 0.3494 Acc: 0.8478\n",
      "Epoch 014 | Train Loss: 0.3405 Acc: 0.8505 | Val Loss: 0.3293 Acc: 0.8593\n",
      "Epoch 015 | Train Loss: 0.3329 Acc: 0.8543 | Val Loss: 0.3065 Acc: 0.8641\n",
      "Epoch 016 | Train Loss: 0.3017 Acc: 0.8729 | Val Loss: 0.3084 Acc: 0.8690\n",
      "Epoch 017 | Train Loss: 0.2912 Acc: 0.8768 | Val Loss: 0.3013 Acc: 0.8847\n",
      "Epoch 018 | Train Loss: 0.2630 Acc: 0.8898 | Val Loss: 0.2875 Acc: 0.8847\n",
      "Epoch 019 | Train Loss: 0.2435 Acc: 0.9067 | Val Loss: 0.2779 Acc: 0.8841\n",
      "Epoch 020 | Train Loss: 0.2376 Acc: 0.9038 | Val Loss: 0.2847 Acc: 0.8925\n",
      "Epoch 021 | Train Loss: 0.2378 Acc: 0.9077 | Val Loss: 0.2371 Acc: 0.9100\n",
      "Epoch 022 | Train Loss: 0.2209 Acc: 0.9065 | Val Loss: 0.2441 Acc: 0.9004\n",
      "Epoch 023 | Train Loss: 0.2013 Acc: 0.9192 | Val Loss: 0.2349 Acc: 0.9197\n",
      "Epoch 024 | Train Loss: 0.1929 Acc: 0.9260 | Val Loss: 0.2142 Acc: 0.9215\n",
      "Epoch 025 | Train Loss: 0.1858 Acc: 0.9266 | Val Loss: 0.2560 Acc: 0.9070\n",
      "Epoch 026 | Train Loss: 0.1774 Acc: 0.9318 | Val Loss: 0.2266 Acc: 0.9130\n",
      "Epoch 027 | Train Loss: 0.1674 Acc: 0.9318 | Val Loss: 0.1891 Acc: 0.9306\n",
      "Epoch 028 | Train Loss: 0.1549 Acc: 0.9393 | Val Loss: 0.2223 Acc: 0.9124\n",
      "Epoch 029 | Train Loss: 0.1542 Acc: 0.9413 | Val Loss: 0.2149 Acc: 0.9197\n",
      "Epoch 030 | Train Loss: 0.1525 Acc: 0.9408 | Val Loss: 0.1878 Acc: 0.9269\n",
      "Epoch 031 | Train Loss: 0.1467 Acc: 0.9458 | Val Loss: 0.1931 Acc: 0.9306\n",
      "Epoch 032 | Train Loss: 0.1401 Acc: 0.9465 | Val Loss: 0.1951 Acc: 0.9215\n",
      "Epoch 033 | Train Loss: 0.1340 Acc: 0.9481 | Val Loss: 0.1851 Acc: 0.9275\n",
      "Epoch 034 | Train Loss: 0.1320 Acc: 0.9488 | Val Loss: 0.1959 Acc: 0.9330\n",
      "Epoch 035 | Train Loss: 0.1227 Acc: 0.9523 | Val Loss: 0.1691 Acc: 0.9396\n",
      "Epoch 036 | Train Loss: 0.1171 Acc: 0.9553 | Val Loss: 0.1966 Acc: 0.9203\n",
      "Epoch 037 | Train Loss: 0.1177 Acc: 0.9553 | Val Loss: 0.1806 Acc: 0.9390\n",
      "Epoch 038 | Train Loss: 0.1193 Acc: 0.9543 | Val Loss: 0.1653 Acc: 0.9408\n",
      "Epoch 039 | Train Loss: 0.1039 Acc: 0.9600 | Val Loss: 0.2025 Acc: 0.9275\n",
      "Epoch 040 | Train Loss: 0.1044 Acc: 0.9623 | Val Loss: 0.1800 Acc: 0.9360\n",
      "Epoch 041 | Train Loss: 0.1042 Acc: 0.9626 | Val Loss: 0.2130 Acc: 0.9233\n",
      "Epoch 042 | Train Loss: 0.0995 Acc: 0.9627 | Val Loss: 0.1733 Acc: 0.9408\n",
      "Epoch 043 | Train Loss: 0.1008 Acc: 0.9624 | Val Loss: 0.1856 Acc: 0.9354\n",
      "Epoch 044 | Train Loss: 0.0929 Acc: 0.9665 | Val Loss: 0.2045 Acc: 0.9257\n",
      "Epoch 045 | Train Loss: 0.0881 Acc: 0.9663 | Val Loss: 0.1890 Acc: 0.9293\n",
      "Epoch 046 | Train Loss: 0.0915 Acc: 0.9647 | Val Loss: 0.1654 Acc: 0.9457\n",
      "Epoch 047 | Train Loss: 0.0853 Acc: 0.9695 | Val Loss: 0.1681 Acc: 0.9396\n",
      "Epoch 048 | Train Loss: 0.0900 Acc: 0.9674 | Val Loss: 0.2111 Acc: 0.9269\n",
      "Early stopping triggered.\n",
      "Epoch 001 | Train Loss: 0.6793 Acc: 0.5763 | Val Loss: 0.6757 Acc: 0.5918\n",
      "Epoch 002 | Train Loss: 0.6721 Acc: 0.5964 | Val Loss: 0.6843 Acc: 0.5483\n",
      "Epoch 003 | Train Loss: 0.6686 Acc: 0.5964 | Val Loss: 0.6640 Acc: 0.5978\n",
      "Epoch 004 | Train Loss: 0.6500 Acc: 0.6151 | Val Loss: 0.6323 Acc: 0.6528\n",
      "Epoch 005 | Train Loss: 0.6005 Acc: 0.6909 | Val Loss: 0.5754 Acc: 0.7071\n",
      "Epoch 006 | Train Loss: 0.5673 Acc: 0.7217 | Val Loss: 0.5707 Acc: 0.7126\n",
      "Epoch 007 | Train Loss: 0.5537 Acc: 0.7270 | Val Loss: 0.5569 Acc: 0.7204\n",
      "Epoch 008 | Train Loss: 0.5366 Acc: 0.7380 | Val Loss: 0.5517 Acc: 0.7283\n",
      "Epoch 009 | Train Loss: 0.5175 Acc: 0.7457 | Val Loss: 0.5257 Acc: 0.7482\n",
      "Epoch 010 | Train Loss: 0.5034 Acc: 0.7581 | Val Loss: 0.5137 Acc: 0.7421\n",
      "Epoch 011 | Train Loss: 0.4774 Acc: 0.7725 | Val Loss: 0.4794 Acc: 0.7723\n",
      "Epoch 012 | Train Loss: 0.4634 Acc: 0.7886 | Val Loss: 0.4765 Acc: 0.7802\n",
      "Epoch 013 | Train Loss: 0.4422 Acc: 0.7922 | Val Loss: 0.4354 Acc: 0.8013\n",
      "Epoch 014 | Train Loss: 0.4187 Acc: 0.8058 | Val Loss: 0.4262 Acc: 0.8086\n",
      "Epoch 015 | Train Loss: 0.4090 Acc: 0.8135 | Val Loss: 0.3904 Acc: 0.8267\n",
      "Epoch 016 | Train Loss: 0.3884 Acc: 0.8261 | Val Loss: 0.3850 Acc: 0.8261\n",
      "Epoch 017 | Train Loss: 0.3717 Acc: 0.8338 | Val Loss: 0.3744 Acc: 0.8225\n",
      "Epoch 018 | Train Loss: 0.3487 Acc: 0.8446 | Val Loss: 0.3660 Acc: 0.8454\n",
      "Epoch 019 | Train Loss: 0.3198 Acc: 0.8587 | Val Loss: 0.3616 Acc: 0.8430\n",
      "Epoch 020 | Train Loss: 0.3068 Acc: 0.8659 | Val Loss: 0.3329 Acc: 0.8442\n",
      "Epoch 021 | Train Loss: 0.2949 Acc: 0.8756 | Val Loss: 0.3099 Acc: 0.8665\n",
      "Epoch 022 | Train Loss: 0.2736 Acc: 0.8851 | Val Loss: 0.2938 Acc: 0.8768\n",
      "Epoch 023 | Train Loss: 0.2530 Acc: 0.9002 | Val Loss: 0.3320 Acc: 0.8690\n",
      "Epoch 024 | Train Loss: 0.2561 Acc: 0.8967 | Val Loss: 0.2759 Acc: 0.8847\n",
      "Epoch 025 | Train Loss: 0.2368 Acc: 0.9034 | Val Loss: 0.2835 Acc: 0.8804\n",
      "Epoch 026 | Train Loss: 0.2121 Acc: 0.9151 | Val Loss: 0.2433 Acc: 0.9028\n",
      "Epoch 027 | Train Loss: 0.2104 Acc: 0.9157 | Val Loss: 0.2381 Acc: 0.9040\n",
      "Epoch 028 | Train Loss: 0.1948 Acc: 0.9239 | Val Loss: 0.2225 Acc: 0.9191\n",
      "Epoch 029 | Train Loss: 0.1896 Acc: 0.9231 | Val Loss: 0.2711 Acc: 0.8853\n",
      "Epoch 030 | Train Loss: 0.1786 Acc: 0.9318 | Val Loss: 0.2690 Acc: 0.8822\n",
      "Epoch 031 | Train Loss: 0.1726 Acc: 0.9302 | Val Loss: 0.2391 Acc: 0.9106\n",
      "Epoch 032 | Train Loss: 0.1785 Acc: 0.9290 | Val Loss: 0.2538 Acc: 0.9022\n",
      "Epoch 033 | Train Loss: 0.1691 Acc: 0.9339 | Val Loss: 0.2406 Acc: 0.9076\n",
      "Epoch 034 | Train Loss: 0.1540 Acc: 0.9367 | Val Loss: 0.2685 Acc: 0.9034\n",
      "Epoch 035 | Train Loss: 0.1645 Acc: 0.9345 | Val Loss: 0.2896 Acc: 0.8901\n",
      "Epoch 036 | Train Loss: 0.1523 Acc: 0.9419 | Val Loss: 0.2441 Acc: 0.9112\n",
      "Epoch 037 | Train Loss: 0.1421 Acc: 0.9446 | Val Loss: 0.1865 Acc: 0.9257\n",
      "Epoch 038 | Train Loss: 0.1309 Acc: 0.9496 | Val Loss: 0.2158 Acc: 0.9161\n",
      "Epoch 039 | Train Loss: 0.1446 Acc: 0.9447 | Val Loss: 0.1828 Acc: 0.9275\n",
      "Epoch 040 | Train Loss: 0.1248 Acc: 0.9532 | Val Loss: 0.2233 Acc: 0.9149\n",
      "Epoch 041 | Train Loss: 0.1200 Acc: 0.9524 | Val Loss: 0.1926 Acc: 0.9348\n",
      "Epoch 042 | Train Loss: 0.1302 Acc: 0.9494 | Val Loss: 0.1823 Acc: 0.9293\n",
      "Epoch 043 | Train Loss: 0.1096 Acc: 0.9594 | Val Loss: 0.1683 Acc: 0.9366\n",
      "Epoch 044 | Train Loss: 0.1127 Acc: 0.9561 | Val Loss: 0.1820 Acc: 0.9269\n",
      "Epoch 045 | Train Loss: 0.1038 Acc: 0.9607 | Val Loss: 0.2085 Acc: 0.9227\n",
      "Epoch 046 | Train Loss: 0.1052 Acc: 0.9604 | Val Loss: 0.1927 Acc: 0.9197\n",
      "Epoch 047 | Train Loss: 0.0988 Acc: 0.9633 | Val Loss: 0.1811 Acc: 0.9293\n",
      "Epoch 048 | Train Loss: 0.0995 Acc: 0.9626 | Val Loss: 0.1914 Acc: 0.9342\n",
      "Epoch 049 | Train Loss: 0.1051 Acc: 0.9583 | Val Loss: 0.1552 Acc: 0.9396\n",
      "Epoch 050 | Train Loss: 0.0977 Acc: 0.9606 | Val Loss: 0.1821 Acc: 0.9330\n",
      "Epoch 051 | Train Loss: 0.0905 Acc: 0.9651 | Val Loss: 0.1728 Acc: 0.9438\n",
      "Epoch 052 | Train Loss: 0.0850 Acc: 0.9701 | Val Loss: 0.1718 Acc: 0.9438\n",
      "Epoch 053 | Train Loss: 0.0930 Acc: 0.9648 | Val Loss: 0.1663 Acc: 0.9457\n",
      "Epoch 054 | Train Loss: 0.0816 Acc: 0.9693 | Val Loss: 0.1903 Acc: 0.9348\n",
      "Epoch 055 | Train Loss: 0.0952 Acc: 0.9621 | Val Loss: 0.1754 Acc: 0.9384\n",
      "Epoch 056 | Train Loss: 0.0795 Acc: 0.9719 | Val Loss: 0.1814 Acc: 0.9372\n",
      "Epoch 057 | Train Loss: 0.0820 Acc: 0.9680 | Val Loss: 0.1619 Acc: 0.9402\n",
      "Epoch 058 | Train Loss: 0.0802 Acc: 0.9692 | Val Loss: 0.2569 Acc: 0.9233\n",
      "Epoch 059 | Train Loss: 0.0806 Acc: 0.9681 | Val Loss: 0.1388 Acc: 0.9499\n",
      "Epoch 060 | Train Loss: 0.0813 Acc: 0.9684 | Val Loss: 0.1623 Acc: 0.9469\n",
      "Epoch 001 | Train Loss: 0.6815 Acc: 0.5783 | Val Loss: 0.6751 Acc: 0.5797\n",
      "Epoch 002 | Train Loss: 0.6632 Acc: 0.6080 | Val Loss: 0.6479 Acc: 0.6455\n",
      "Epoch 003 | Train Loss: 0.6118 Acc: 0.6751 | Val Loss: 0.5934 Acc: 0.6957\n",
      "Epoch 004 | Train Loss: 0.5768 Acc: 0.7084 | Val Loss: 0.5621 Acc: 0.7114\n",
      "Epoch 005 | Train Loss: 0.5437 Acc: 0.7352 | Val Loss: 0.5487 Acc: 0.7240\n",
      "Epoch 006 | Train Loss: 0.5185 Acc: 0.7468 | Val Loss: 0.5233 Acc: 0.7385\n",
      "Epoch 007 | Train Loss: 0.4999 Acc: 0.7642 | Val Loss: 0.4948 Acc: 0.7663\n",
      "Epoch 008 | Train Loss: 0.4640 Acc: 0.7808 | Val Loss: 0.4767 Acc: 0.7615\n",
      "Epoch 009 | Train Loss: 0.4395 Acc: 0.7922 | Val Loss: 0.4254 Acc: 0.7923\n",
      "Epoch 010 | Train Loss: 0.4056 Acc: 0.8088 | Val Loss: 0.3761 Acc: 0.8200\n",
      "Epoch 011 | Train Loss: 0.3750 Acc: 0.8351 | Val Loss: 0.3525 Acc: 0.8388\n",
      "Epoch 012 | Train Loss: 0.3492 Acc: 0.8483 | Val Loss: 0.3225 Acc: 0.8527\n",
      "Epoch 013 | Train Loss: 0.3180 Acc: 0.8617 | Val Loss: 0.2937 Acc: 0.8816\n",
      "Epoch 014 | Train Loss: 0.2897 Acc: 0.8791 | Val Loss: 0.2879 Acc: 0.8859\n",
      "Epoch 015 | Train Loss: 0.2723 Acc: 0.8833 | Val Loss: 0.2911 Acc: 0.8792\n",
      "Epoch 016 | Train Loss: 0.2566 Acc: 0.8931 | Val Loss: 0.2885 Acc: 0.8714\n",
      "Epoch 017 | Train Loss: 0.2461 Acc: 0.8955 | Val Loss: 0.2603 Acc: 0.8895\n",
      "Epoch 018 | Train Loss: 0.2159 Acc: 0.9123 | Val Loss: 0.2513 Acc: 0.8973\n",
      "Epoch 019 | Train Loss: 0.2054 Acc: 0.9144 | Val Loss: 0.2144 Acc: 0.9124\n",
      "Epoch 020 | Train Loss: 0.1975 Acc: 0.9209 | Val Loss: 0.2297 Acc: 0.9070\n",
      "Epoch 021 | Train Loss: 0.1841 Acc: 0.9260 | Val Loss: 0.2039 Acc: 0.9155\n",
      "Epoch 022 | Train Loss: 0.1647 Acc: 0.9360 | Val Loss: 0.2186 Acc: 0.9191\n",
      "Epoch 023 | Train Loss: 0.1715 Acc: 0.9307 | Val Loss: 0.2055 Acc: 0.9173\n",
      "Epoch 024 | Train Loss: 0.1450 Acc: 0.9407 | Val Loss: 0.1999 Acc: 0.9179\n",
      "Epoch 025 | Train Loss: 0.1385 Acc: 0.9485 | Val Loss: 0.1904 Acc: 0.9275\n",
      "Epoch 026 | Train Loss: 0.1412 Acc: 0.9456 | Val Loss: 0.1722 Acc: 0.9300\n",
      "Epoch 027 | Train Loss: 0.1189 Acc: 0.9523 | Val Loss: 0.1932 Acc: 0.9257\n",
      "Epoch 028 | Train Loss: 0.1071 Acc: 0.9589 | Val Loss: 0.1771 Acc: 0.9372\n",
      "Epoch 029 | Train Loss: 0.1172 Acc: 0.9536 | Val Loss: 0.1569 Acc: 0.9457\n",
      "Epoch 030 | Train Loss: 0.1089 Acc: 0.9583 | Val Loss: 0.1642 Acc: 0.9360\n",
      "Epoch 031 | Train Loss: 0.0993 Acc: 0.9607 | Val Loss: 0.2013 Acc: 0.9269\n",
      "Epoch 032 | Train Loss: 0.1103 Acc: 0.9591 | Val Loss: 0.1748 Acc: 0.9390\n",
      "Epoch 033 | Train Loss: 0.1002 Acc: 0.9626 | Val Loss: 0.1716 Acc: 0.9330\n",
      "Epoch 034 | Train Loss: 0.0845 Acc: 0.9672 | Val Loss: 0.1722 Acc: 0.9402\n",
      "Epoch 035 | Train Loss: 0.0835 Acc: 0.9686 | Val Loss: 0.1601 Acc: 0.9450\n",
      "Epoch 036 | Train Loss: 0.0770 Acc: 0.9731 | Val Loss: 0.1868 Acc: 0.9300\n",
      "Epoch 037 | Train Loss: 0.0722 Acc: 0.9749 | Val Loss: 0.1790 Acc: 0.9342\n",
      "Epoch 038 | Train Loss: 0.0741 Acc: 0.9721 | Val Loss: 0.1810 Acc: 0.9366\n",
      "Epoch 039 | Train Loss: 0.0705 Acc: 0.9724 | Val Loss: 0.2387 Acc: 0.9251\n",
      "Early stopping triggered.\n",
      "Epoch 001 | Train Loss: 0.6806 Acc: 0.5813 | Val Loss: 0.6722 Acc: 0.5900\n",
      "Epoch 002 | Train Loss: 0.6633 Acc: 0.6038 | Val Loss: 0.6326 Acc: 0.6461\n",
      "Epoch 003 | Train Loss: 0.6066 Acc: 0.6817 | Val Loss: 0.5959 Acc: 0.6987\n",
      "Epoch 004 | Train Loss: 0.5625 Acc: 0.7193 | Val Loss: 0.5545 Acc: 0.7186\n",
      "Epoch 005 | Train Loss: 0.5315 Acc: 0.7433 | Val Loss: 0.5456 Acc: 0.7307\n",
      "Epoch 006 | Train Loss: 0.5124 Acc: 0.7512 | Val Loss: 0.4951 Acc: 0.7585\n",
      "Epoch 007 | Train Loss: 0.4828 Acc: 0.7717 | Val Loss: 0.4787 Acc: 0.7699\n",
      "Epoch 008 | Train Loss: 0.4657 Acc: 0.7841 | Val Loss: 0.4830 Acc: 0.7627\n",
      "Epoch 009 | Train Loss: 0.4456 Acc: 0.7950 | Val Loss: 0.4648 Acc: 0.7838\n",
      "Epoch 010 | Train Loss: 0.4320 Acc: 0.8063 | Val Loss: 0.4360 Acc: 0.7929\n",
      "Epoch 011 | Train Loss: 0.4065 Acc: 0.8155 | Val Loss: 0.4499 Acc: 0.7820\n",
      "Epoch 012 | Train Loss: 0.3907 Acc: 0.8255 | Val Loss: 0.3660 Acc: 0.8309\n",
      "Epoch 013 | Train Loss: 0.3579 Acc: 0.8381 | Val Loss: 0.3454 Acc: 0.8490\n",
      "Epoch 014 | Train Loss: 0.3445 Acc: 0.8493 | Val Loss: 0.3703 Acc: 0.8200\n",
      "Epoch 015 | Train Loss: 0.3383 Acc: 0.8522 | Val Loss: 0.3489 Acc: 0.8315\n",
      "Epoch 016 | Train Loss: 0.3071 Acc: 0.8698 | Val Loss: 0.3063 Acc: 0.8684\n",
      "Epoch 017 | Train Loss: 0.2954 Acc: 0.8762 | Val Loss: 0.2729 Acc: 0.8847\n",
      "Epoch 018 | Train Loss: 0.2869 Acc: 0.8795 | Val Loss: 0.2776 Acc: 0.8756\n",
      "Epoch 019 | Train Loss: 0.2619 Acc: 0.8899 | Val Loss: 0.3108 Acc: 0.8539\n",
      "Epoch 020 | Train Loss: 0.2647 Acc: 0.8919 | Val Loss: 0.2406 Acc: 0.9064\n",
      "Epoch 021 | Train Loss: 0.2369 Acc: 0.9061 | Val Loss: 0.2568 Acc: 0.8943\n",
      "Epoch 022 | Train Loss: 0.2247 Acc: 0.9105 | Val Loss: 0.2171 Acc: 0.9118\n",
      "Epoch 023 | Train Loss: 0.2158 Acc: 0.9133 | Val Loss: 0.2398 Acc: 0.9052\n",
      "Epoch 024 | Train Loss: 0.2057 Acc: 0.9188 | Val Loss: 0.2350 Acc: 0.9046\n",
      "Epoch 025 | Train Loss: 0.2105 Acc: 0.9188 | Val Loss: 0.2158 Acc: 0.9124\n",
      "Epoch 026 | Train Loss: 0.1875 Acc: 0.9213 | Val Loss: 0.2145 Acc: 0.9118\n",
      "Epoch 027 | Train Loss: 0.1772 Acc: 0.9352 | Val Loss: 0.2072 Acc: 0.9167\n",
      "Epoch 028 | Train Loss: 0.1810 Acc: 0.9304 | Val Loss: 0.1994 Acc: 0.9197\n",
      "Epoch 029 | Train Loss: 0.1696 Acc: 0.9324 | Val Loss: 0.2102 Acc: 0.9118\n",
      "Epoch 030 | Train Loss: 0.1590 Acc: 0.9390 | Val Loss: 0.2013 Acc: 0.9221\n",
      "Epoch 031 | Train Loss: 0.1468 Acc: 0.9446 | Val Loss: 0.1704 Acc: 0.9330\n",
      "Epoch 032 | Train Loss: 0.1474 Acc: 0.9420 | Val Loss: 0.1740 Acc: 0.9342\n",
      "Epoch 033 | Train Loss: 0.1348 Acc: 0.9508 | Val Loss: 0.1792 Acc: 0.9336\n",
      "Epoch 034 | Train Loss: 0.1246 Acc: 0.9514 | Val Loss: 0.1759 Acc: 0.9330\n",
      "Epoch 035 | Train Loss: 0.1263 Acc: 0.9532 | Val Loss: 0.1743 Acc: 0.9390\n",
      "Epoch 036 | Train Loss: 0.1193 Acc: 0.9562 | Val Loss: 0.1636 Acc: 0.9408\n",
      "Epoch 037 | Train Loss: 0.1233 Acc: 0.9499 | Val Loss: 0.1528 Acc: 0.9432\n",
      "Epoch 038 | Train Loss: 0.1255 Acc: 0.9511 | Val Loss: 0.1450 Acc: 0.9463\n",
      "Epoch 039 | Train Loss: 0.1054 Acc: 0.9616 | Val Loss: 0.1777 Acc: 0.9396\n",
      "Epoch 040 | Train Loss: 0.1291 Acc: 0.9546 | Val Loss: 0.1562 Acc: 0.9444\n",
      "Epoch 041 | Train Loss: 0.1126 Acc: 0.9549 | Val Loss: 0.1954 Acc: 0.9324\n",
      "Epoch 042 | Train Loss: 0.1049 Acc: 0.9594 | Val Loss: 0.1598 Acc: 0.9360\n",
      "Epoch 043 | Train Loss: 0.0980 Acc: 0.9641 | Val Loss: 0.1917 Acc: 0.9293\n",
      "Epoch 044 | Train Loss: 0.1109 Acc: 0.9586 | Val Loss: 0.1692 Acc: 0.9402\n",
      "Epoch 045 | Train Loss: 0.0869 Acc: 0.9672 | Val Loss: 0.1922 Acc: 0.9336\n",
      "Epoch 046 | Train Loss: 0.1042 Acc: 0.9627 | Val Loss: 0.1701 Acc: 0.9384\n",
      "Epoch 047 | Train Loss: 0.0904 Acc: 0.9677 | Val Loss: 0.1421 Acc: 0.9475\n",
      "Epoch 048 | Train Loss: 0.0893 Acc: 0.9653 | Val Loss: 0.1480 Acc: 0.9396\n",
      "Epoch 049 | Train Loss: 0.0917 Acc: 0.9663 | Val Loss: 0.1470 Acc: 0.9493\n",
      "Epoch 050 | Train Loss: 0.0888 Acc: 0.9665 | Val Loss: 0.1454 Acc: 0.9463\n",
      "Epoch 051 | Train Loss: 0.0893 Acc: 0.9659 | Val Loss: 0.1850 Acc: 0.9408\n",
      "Epoch 052 | Train Loss: 0.0911 Acc: 0.9659 | Val Loss: 0.1635 Acc: 0.9402\n",
      "Epoch 053 | Train Loss: 0.0771 Acc: 0.9730 | Val Loss: 0.1805 Acc: 0.9384\n",
      "Epoch 054 | Train Loss: 0.0799 Acc: 0.9700 | Val Loss: 0.1362 Acc: 0.9505\n",
      "Epoch 055 | Train Loss: 0.0728 Acc: 0.9719 | Val Loss: 0.1396 Acc: 0.9517\n",
      "Epoch 056 | Train Loss: 0.0620 Acc: 0.9764 | Val Loss: 0.1429 Acc: 0.9493\n",
      "Epoch 057 | Train Loss: 0.0777 Acc: 0.9712 | Val Loss: 0.1920 Acc: 0.9384\n",
      "Epoch 058 | Train Loss: 0.0756 Acc: 0.9737 | Val Loss: 0.1540 Acc: 0.9469\n",
      "Epoch 059 | Train Loss: 0.0650 Acc: 0.9777 | Val Loss: 0.1958 Acc: 0.9438\n",
      "Epoch 060 | Train Loss: 0.0697 Acc: 0.9764 | Val Loss: 0.1823 Acc: 0.9469\n",
      "Epoch 001 | Train Loss: 0.6822 Acc: 0.5768 | Val Loss: 0.6813 Acc: 0.5713\n",
      "Epoch 002 | Train Loss: 0.6739 Acc: 0.5887 | Val Loss: 0.6690 Acc: 0.5978\n",
      "Epoch 003 | Train Loss: 0.6715 Acc: 0.5950 | Val Loss: 0.6743 Acc: 0.5912\n",
      "Epoch 004 | Train Loss: 0.6667 Acc: 0.6037 | Val Loss: 0.6683 Acc: 0.5906\n",
      "Epoch 005 | Train Loss: 0.6540 Acc: 0.6172 | Val Loss: 0.6365 Acc: 0.6558\n",
      "Epoch 006 | Train Loss: 0.6204 Acc: 0.6705 | Val Loss: 0.5882 Acc: 0.6926\n",
      "Epoch 007 | Train Loss: 0.5769 Acc: 0.7093 | Val Loss: 0.5671 Acc: 0.7150\n",
      "Epoch 008 | Train Loss: 0.5526 Acc: 0.7249 | Val Loss: 0.5446 Acc: 0.7283\n",
      "Epoch 009 | Train Loss: 0.5211 Acc: 0.7442 | Val Loss: 0.5418 Acc: 0.7222\n",
      "Epoch 010 | Train Loss: 0.5119 Acc: 0.7521 | Val Loss: 0.5065 Acc: 0.7458\n",
      "Epoch 011 | Train Loss: 0.4990 Acc: 0.7590 | Val Loss: 0.5688 Acc: 0.7222\n",
      "Epoch 012 | Train Loss: 0.4839 Acc: 0.7628 | Val Loss: 0.4975 Acc: 0.7536\n",
      "Epoch 013 | Train Loss: 0.4674 Acc: 0.7782 | Val Loss: 0.4592 Acc: 0.7748\n",
      "Epoch 014 | Train Loss: 0.4386 Acc: 0.7941 | Val Loss: 0.4288 Acc: 0.7935\n",
      "Epoch 015 | Train Loss: 0.4207 Acc: 0.8073 | Val Loss: 0.4271 Acc: 0.7989\n",
      "Epoch 016 | Train Loss: 0.4003 Acc: 0.8129 | Val Loss: 0.3945 Acc: 0.8237\n",
      "Epoch 017 | Train Loss: 0.3757 Acc: 0.8315 | Val Loss: 0.3932 Acc: 0.8213\n",
      "Epoch 018 | Train Loss: 0.3579 Acc: 0.8415 | Val Loss: 0.3864 Acc: 0.8279\n",
      "Epoch 019 | Train Loss: 0.3362 Acc: 0.8517 | Val Loss: 0.3286 Acc: 0.8490\n",
      "Epoch 020 | Train Loss: 0.3179 Acc: 0.8652 | Val Loss: 0.3168 Acc: 0.8599\n",
      "Epoch 021 | Train Loss: 0.2952 Acc: 0.8718 | Val Loss: 0.3429 Acc: 0.8587\n",
      "Epoch 022 | Train Loss: 0.3007 Acc: 0.8718 | Val Loss: 0.3325 Acc: 0.8587\n",
      "Epoch 023 | Train Loss: 0.2727 Acc: 0.8824 | Val Loss: 0.2874 Acc: 0.8756\n",
      "Epoch 024 | Train Loss: 0.2530 Acc: 0.8969 | Val Loss: 0.2790 Acc: 0.8913\n",
      "Epoch 025 | Train Loss: 0.2413 Acc: 0.9044 | Val Loss: 0.2507 Acc: 0.8955\n",
      "Epoch 026 | Train Loss: 0.2340 Acc: 0.9005 | Val Loss: 0.2489 Acc: 0.8998\n",
      "Epoch 027 | Train Loss: 0.2270 Acc: 0.9091 | Val Loss: 0.2441 Acc: 0.8961\n",
      "Epoch 028 | Train Loss: 0.2079 Acc: 0.9180 | Val Loss: 0.2252 Acc: 0.9064\n",
      "Epoch 029 | Train Loss: 0.2037 Acc: 0.9167 | Val Loss: 0.2269 Acc: 0.9058\n",
      "Epoch 030 | Train Loss: 0.1959 Acc: 0.9206 | Val Loss: 0.2268 Acc: 0.9118\n",
      "Epoch 031 | Train Loss: 0.1860 Acc: 0.9253 | Val Loss: 0.2423 Acc: 0.9004\n",
      "Epoch 032 | Train Loss: 0.1871 Acc: 0.9254 | Val Loss: 0.2152 Acc: 0.9082\n",
      "Epoch 033 | Train Loss: 0.1678 Acc: 0.9337 | Val Loss: 0.2807 Acc: 0.8949\n",
      "Epoch 034 | Train Loss: 0.1728 Acc: 0.9324 | Val Loss: 0.1857 Acc: 0.9281\n",
      "Epoch 035 | Train Loss: 0.1581 Acc: 0.9360 | Val Loss: 0.1820 Acc: 0.9312\n",
      "Epoch 036 | Train Loss: 0.1549 Acc: 0.9373 | Val Loss: 0.2149 Acc: 0.9209\n",
      "Epoch 037 | Train Loss: 0.1642 Acc: 0.9345 | Val Loss: 0.2182 Acc: 0.9034\n",
      "Epoch 038 | Train Loss: 0.1436 Acc: 0.9453 | Val Loss: 0.2164 Acc: 0.9179\n",
      "Epoch 039 | Train Loss: 0.1378 Acc: 0.9475 | Val Loss: 0.1920 Acc: 0.9239\n",
      "Epoch 040 | Train Loss: 0.1425 Acc: 0.9462 | Val Loss: 0.1858 Acc: 0.9293\n",
      "Epoch 041 | Train Loss: 0.1410 Acc: 0.9458 | Val Loss: 0.2120 Acc: 0.9161\n",
      "Epoch 042 | Train Loss: 0.1229 Acc: 0.9535 | Val Loss: 0.1969 Acc: 0.9251\n",
      "Epoch 043 | Train Loss: 0.1168 Acc: 0.9574 | Val Loss: 0.1746 Acc: 0.9378\n",
      "Epoch 044 | Train Loss: 0.1241 Acc: 0.9515 | Val Loss: 0.1606 Acc: 0.9360\n",
      "Epoch 045 | Train Loss: 0.1273 Acc: 0.9524 | Val Loss: 0.1765 Acc: 0.9318\n",
      "Epoch 046 | Train Loss: 0.1065 Acc: 0.9583 | Val Loss: 0.1922 Acc: 0.9330\n",
      "Epoch 047 | Train Loss: 0.1084 Acc: 0.9594 | Val Loss: 0.1905 Acc: 0.9330\n",
      "Epoch 048 | Train Loss: 0.1030 Acc: 0.9627 | Val Loss: 0.1832 Acc: 0.9336\n",
      "Epoch 049 | Train Loss: 0.1158 Acc: 0.9579 | Val Loss: 0.2017 Acc: 0.9215\n",
      "Epoch 050 | Train Loss: 0.1217 Acc: 0.9571 | Val Loss: 0.1680 Acc: 0.9336\n",
      "Epoch 051 | Train Loss: 0.0964 Acc: 0.9644 | Val Loss: 0.2256 Acc: 0.9215\n",
      "Epoch 052 | Train Loss: 0.0973 Acc: 0.9620 | Val Loss: 0.2209 Acc: 0.9227\n",
      "Epoch 053 | Train Loss: 0.1047 Acc: 0.9601 | Val Loss: 0.2233 Acc: 0.9257\n",
      "Epoch 054 | Train Loss: 0.0937 Acc: 0.9632 | Val Loss: 0.1779 Acc: 0.9408\n",
      "Early stopping triggered.\n",
      "Epoch 001 | Train Loss: 0.6817 Acc: 0.5771 | Val Loss: 0.6785 Acc: 0.5839\n",
      "Epoch 002 | Train Loss: 0.6749 Acc: 0.5913 | Val Loss: 0.6770 Acc: 0.5839\n",
      "Epoch 003 | Train Loss: 0.6612 Acc: 0.6073 | Val Loss: 0.6478 Acc: 0.6467\n",
      "Epoch 004 | Train Loss: 0.6082 Acc: 0.6811 | Val Loss: 0.5777 Acc: 0.7053\n",
      "Epoch 005 | Train Loss: 0.5592 Acc: 0.7228 | Val Loss: 0.5490 Acc: 0.7216\n",
      "Epoch 006 | Train Loss: 0.5322 Acc: 0.7383 | Val Loss: 0.5321 Acc: 0.7271\n",
      "Epoch 007 | Train Loss: 0.5039 Acc: 0.7542 | Val Loss: 0.5079 Acc: 0.7379\n",
      "Epoch 008 | Train Loss: 0.4807 Acc: 0.7682 | Val Loss: 0.4762 Acc: 0.7609\n",
      "Epoch 009 | Train Loss: 0.4482 Acc: 0.7850 | Val Loss: 0.4717 Acc: 0.7705\n",
      "Epoch 010 | Train Loss: 0.4331 Acc: 0.7963 | Val Loss: 0.4468 Acc: 0.7899\n",
      "Epoch 011 | Train Loss: 0.4064 Acc: 0.8126 | Val Loss: 0.4230 Acc: 0.7947\n",
      "Epoch 012 | Train Loss: 0.3921 Acc: 0.8147 | Val Loss: 0.3802 Acc: 0.8134\n",
      "Epoch 013 | Train Loss: 0.3686 Acc: 0.8333 | Val Loss: 0.3915 Acc: 0.8122\n",
      "Epoch 014 | Train Loss: 0.3588 Acc: 0.8413 | Val Loss: 0.3618 Acc: 0.8309\n",
      "Epoch 015 | Train Loss: 0.3233 Acc: 0.8606 | Val Loss: 0.3190 Acc: 0.8502\n",
      "Epoch 016 | Train Loss: 0.3101 Acc: 0.8701 | Val Loss: 0.3513 Acc: 0.8484\n",
      "Epoch 017 | Train Loss: 0.2991 Acc: 0.8751 | Val Loss: 0.3059 Acc: 0.8690\n",
      "Epoch 018 | Train Loss: 0.2788 Acc: 0.8833 | Val Loss: 0.2876 Acc: 0.8732\n",
      "Epoch 019 | Train Loss: 0.2523 Acc: 0.8985 | Val Loss: 0.2565 Acc: 0.8925\n",
      "Epoch 020 | Train Loss: 0.2523 Acc: 0.8964 | Val Loss: 0.2607 Acc: 0.8859\n",
      "Epoch 021 | Train Loss: 0.2271 Acc: 0.9094 | Val Loss: 0.2534 Acc: 0.8925\n",
      "Epoch 022 | Train Loss: 0.2251 Acc: 0.9126 | Val Loss: 0.2542 Acc: 0.8919\n",
      "Epoch 023 | Train Loss: 0.2069 Acc: 0.9168 | Val Loss: 0.2276 Acc: 0.8998\n",
      "Epoch 024 | Train Loss: 0.1915 Acc: 0.9247 | Val Loss: 0.2686 Acc: 0.8883\n",
      "Epoch 025 | Train Loss: 0.1814 Acc: 0.9266 | Val Loss: 0.2237 Acc: 0.9106\n",
      "Epoch 026 | Train Loss: 0.1830 Acc: 0.9277 | Val Loss: 0.2316 Acc: 0.9022\n",
      "Epoch 027 | Train Loss: 0.1552 Acc: 0.9393 | Val Loss: 0.2104 Acc: 0.9118\n",
      "Epoch 028 | Train Loss: 0.1546 Acc: 0.9407 | Val Loss: 0.2030 Acc: 0.9167\n",
      "Epoch 029 | Train Loss: 0.1490 Acc: 0.9407 | Val Loss: 0.1992 Acc: 0.9191\n",
      "Epoch 030 | Train Loss: 0.1432 Acc: 0.9437 | Val Loss: 0.1990 Acc: 0.9203\n",
      "Epoch 031 | Train Loss: 0.1426 Acc: 0.9443 | Val Loss: 0.2014 Acc: 0.9173\n",
      "Epoch 032 | Train Loss: 0.1375 Acc: 0.9475 | Val Loss: 0.2217 Acc: 0.9130\n",
      "Epoch 033 | Train Loss: 0.1155 Acc: 0.9552 | Val Loss: 0.1982 Acc: 0.9287\n",
      "Epoch 034 | Train Loss: 0.1162 Acc: 0.9559 | Val Loss: 0.2117 Acc: 0.9209\n",
      "Epoch 035 | Train Loss: 0.1062 Acc: 0.9604 | Val Loss: 0.1889 Acc: 0.9239\n",
      "Epoch 036 | Train Loss: 0.1131 Acc: 0.9573 | Val Loss: 0.1810 Acc: 0.9281\n",
      "Epoch 037 | Train Loss: 0.1073 Acc: 0.9583 | Val Loss: 0.1895 Acc: 0.9263\n",
      "Epoch 038 | Train Loss: 0.0949 Acc: 0.9654 | Val Loss: 0.1772 Acc: 0.9330\n",
      "Epoch 039 | Train Loss: 0.1045 Acc: 0.9600 | Val Loss: 0.1830 Acc: 0.9239\n",
      "Epoch 040 | Train Loss: 0.0981 Acc: 0.9624 | Val Loss: 0.1652 Acc: 0.9372\n",
      "Epoch 041 | Train Loss: 0.0948 Acc: 0.9654 | Val Loss: 0.1610 Acc: 0.9390\n",
      "Epoch 042 | Train Loss: 0.0888 Acc: 0.9668 | Val Loss: 0.1731 Acc: 0.9300\n",
      "Epoch 043 | Train Loss: 0.0815 Acc: 0.9703 | Val Loss: 0.1859 Acc: 0.9360\n",
      "Epoch 044 | Train Loss: 0.0826 Acc: 0.9669 | Val Loss: 0.1631 Acc: 0.9360\n",
      "Epoch 045 | Train Loss: 0.0727 Acc: 0.9736 | Val Loss: 0.1576 Acc: 0.9438\n",
      "Epoch 046 | Train Loss: 0.0801 Acc: 0.9700 | Val Loss: 0.1912 Acc: 0.9336\n",
      "Epoch 047 | Train Loss: 0.0846 Acc: 0.9654 | Val Loss: 0.1978 Acc: 0.9306\n",
      "Epoch 048 | Train Loss: 0.0793 Acc: 0.9722 | Val Loss: 0.1775 Acc: 0.9318\n",
      "Epoch 049 | Train Loss: 0.0770 Acc: 0.9721 | Val Loss: 0.1688 Acc: 0.9348\n",
      "Epoch 050 | Train Loss: 0.0686 Acc: 0.9758 | Val Loss: 0.1793 Acc: 0.9396\n",
      "Epoch 051 | Train Loss: 0.0666 Acc: 0.9761 | Val Loss: 0.1600 Acc: 0.9390\n",
      "Epoch 052 | Train Loss: 0.0723 Acc: 0.9724 | Val Loss: 0.1412 Acc: 0.9444\n",
      "Epoch 053 | Train Loss: 0.0550 Acc: 0.9796 | Val Loss: 0.1796 Acc: 0.9336\n",
      "Epoch 054 | Train Loss: 0.0792 Acc: 0.9703 | Val Loss: 0.1615 Acc: 0.9384\n",
      "Epoch 055 | Train Loss: 0.0649 Acc: 0.9769 | Val Loss: 0.1574 Acc: 0.9426\n",
      "Epoch 056 | Train Loss: 0.0700 Acc: 0.9742 | Val Loss: 0.1587 Acc: 0.9390\n",
      "Epoch 057 | Train Loss: 0.0593 Acc: 0.9772 | Val Loss: 0.1553 Acc: 0.9432\n",
      "Epoch 058 | Train Loss: 0.0632 Acc: 0.9764 | Val Loss: 0.1548 Acc: 0.9390\n",
      "Epoch 059 | Train Loss: 0.0602 Acc: 0.9781 | Val Loss: 0.1498 Acc: 0.9420\n",
      "Epoch 060 | Train Loss: 0.0675 Acc: 0.9727 | Val Loss: 0.1436 Acc: 0.9432\n",
      "Epoch 001 | Train Loss: 0.6794 Acc: 0.5789 | Val Loss: 0.6759 Acc: 0.5870\n",
      "Epoch 002 | Train Loss: 0.6724 Acc: 0.5950 | Val Loss: 0.6661 Acc: 0.6039\n",
      "Epoch 003 | Train Loss: 0.6645 Acc: 0.6064 | Val Loss: 0.6684 Acc: 0.5990\n",
      "Epoch 004 | Train Loss: 0.6501 Acc: 0.6248 | Val Loss: 0.6337 Acc: 0.6486\n",
      "Epoch 005 | Train Loss: 0.6156 Acc: 0.6796 | Val Loss: 0.5952 Acc: 0.6944\n",
      "Epoch 006 | Train Loss: 0.5850 Acc: 0.7071 | Val Loss: 0.5646 Acc: 0.7132\n",
      "Epoch 007 | Train Loss: 0.5535 Acc: 0.7284 | Val Loss: 0.5777 Acc: 0.7144\n",
      "Epoch 008 | Train Loss: 0.5474 Acc: 0.7296 | Val Loss: 0.5328 Acc: 0.7331\n",
      "Epoch 009 | Train Loss: 0.5336 Acc: 0.7371 | Val Loss: 0.5316 Acc: 0.7367\n",
      "Epoch 010 | Train Loss: 0.5215 Acc: 0.7537 | Val Loss: 0.5080 Acc: 0.7500\n",
      "Epoch 011 | Train Loss: 0.4999 Acc: 0.7566 | Val Loss: 0.4970 Acc: 0.7518\n",
      "Epoch 012 | Train Loss: 0.4833 Acc: 0.7709 | Val Loss: 0.4485 Acc: 0.7784\n",
      "Epoch 013 | Train Loss: 0.4630 Acc: 0.7838 | Val Loss: 0.4579 Acc: 0.7778\n",
      "Epoch 014 | Train Loss: 0.4447 Acc: 0.7922 | Val Loss: 0.4440 Acc: 0.7814\n",
      "Epoch 015 | Train Loss: 0.4299 Acc: 0.7990 | Val Loss: 0.4232 Acc: 0.7983\n",
      "Epoch 016 | Train Loss: 0.4031 Acc: 0.8218 | Val Loss: 0.3817 Acc: 0.8255\n",
      "Epoch 017 | Train Loss: 0.3981 Acc: 0.8169 | Val Loss: 0.3754 Acc: 0.8219\n",
      "Epoch 018 | Train Loss: 0.3819 Acc: 0.8297 | Val Loss: 0.3863 Acc: 0.8255\n",
      "Epoch 019 | Train Loss: 0.3713 Acc: 0.8366 | Val Loss: 0.3588 Acc: 0.8345\n",
      "Epoch 020 | Train Loss: 0.3429 Acc: 0.8484 | Val Loss: 0.3471 Acc: 0.8370\n",
      "Epoch 021 | Train Loss: 0.3290 Acc: 0.8564 | Val Loss: 0.3413 Acc: 0.8448\n",
      "Epoch 022 | Train Loss: 0.3091 Acc: 0.8692 | Val Loss: 0.3074 Acc: 0.8708\n",
      "Epoch 023 | Train Loss: 0.2933 Acc: 0.8738 | Val Loss: 0.2944 Acc: 0.8750\n",
      "Epoch 024 | Train Loss: 0.2908 Acc: 0.8822 | Val Loss: 0.2868 Acc: 0.8774\n",
      "Epoch 025 | Train Loss: 0.2752 Acc: 0.8828 | Val Loss: 0.2792 Acc: 0.8835\n",
      "Epoch 026 | Train Loss: 0.2648 Acc: 0.8890 | Val Loss: 0.2499 Acc: 0.8973\n",
      "Epoch 027 | Train Loss: 0.2574 Acc: 0.8945 | Val Loss: 0.2486 Acc: 0.8949\n",
      "Epoch 028 | Train Loss: 0.2523 Acc: 0.8969 | Val Loss: 0.2260 Acc: 0.9076\n",
      "Epoch 029 | Train Loss: 0.2398 Acc: 0.9029 | Val Loss: 0.2233 Acc: 0.9124\n",
      "Epoch 030 | Train Loss: 0.2314 Acc: 0.9047 | Val Loss: 0.2248 Acc: 0.9136\n",
      "Epoch 031 | Train Loss: 0.2360 Acc: 0.9026 | Val Loss: 0.2128 Acc: 0.9209\n",
      "Epoch 032 | Train Loss: 0.2038 Acc: 0.9236 | Val Loss: 0.2070 Acc: 0.9179\n",
      "Epoch 033 | Train Loss: 0.2110 Acc: 0.9130 | Val Loss: 0.2367 Acc: 0.9100\n",
      "Epoch 034 | Train Loss: 0.1969 Acc: 0.9204 | Val Loss: 0.1988 Acc: 0.9312\n",
      "Epoch 035 | Train Loss: 0.1910 Acc: 0.9197 | Val Loss: 0.1895 Acc: 0.9269\n",
      "Epoch 036 | Train Loss: 0.1800 Acc: 0.9247 | Val Loss: 0.2935 Acc: 0.8696\n",
      "Epoch 037 | Train Loss: 0.1828 Acc: 0.9242 | Val Loss: 0.1890 Acc: 0.9275\n",
      "Epoch 038 | Train Loss: 0.1726 Acc: 0.9342 | Val Loss: 0.2028 Acc: 0.9227\n",
      "Epoch 039 | Train Loss: 0.1745 Acc: 0.9337 | Val Loss: 0.1785 Acc: 0.9312\n",
      "Epoch 040 | Train Loss: 0.1716 Acc: 0.9345 | Val Loss: 0.1800 Acc: 0.9312\n",
      "Epoch 041 | Train Loss: 0.1520 Acc: 0.9411 | Val Loss: 0.1663 Acc: 0.9354\n",
      "Epoch 042 | Train Loss: 0.1542 Acc: 0.9411 | Val Loss: 0.1626 Acc: 0.9384\n",
      "Epoch 043 | Train Loss: 0.1546 Acc: 0.9387 | Val Loss: 0.1774 Acc: 0.9287\n",
      "Epoch 044 | Train Loss: 0.1432 Acc: 0.9449 | Val Loss: 0.1538 Acc: 0.9408\n",
      "Epoch 045 | Train Loss: 0.1437 Acc: 0.9441 | Val Loss: 0.2037 Acc: 0.9197\n",
      "Epoch 046 | Train Loss: 0.1387 Acc: 0.9473 | Val Loss: 0.1676 Acc: 0.9324\n",
      "Epoch 047 | Train Loss: 0.1275 Acc: 0.9527 | Val Loss: 0.1566 Acc: 0.9426\n",
      "Epoch 048 | Train Loss: 0.1339 Acc: 0.9487 | Val Loss: 0.1506 Acc: 0.9432\n",
      "Epoch 049 | Train Loss: 0.1403 Acc: 0.9429 | Val Loss: 0.1404 Acc: 0.9444\n",
      "Epoch 050 | Train Loss: 0.1305 Acc: 0.9508 | Val Loss: 0.1780 Acc: 0.9306\n",
      "Epoch 051 | Train Loss: 0.1355 Acc: 0.9494 | Val Loss: 0.1540 Acc: 0.9444\n",
      "Epoch 052 | Train Loss: 0.1311 Acc: 0.9524 | Val Loss: 0.1659 Acc: 0.9360\n",
      "Epoch 053 | Train Loss: 0.1173 Acc: 0.9544 | Val Loss: 0.1529 Acc: 0.9450\n",
      "Epoch 054 | Train Loss: 0.1153 Acc: 0.9564 | Val Loss: 0.1356 Acc: 0.9481\n",
      "Epoch 055 | Train Loss: 0.1245 Acc: 0.9546 | Val Loss: 0.1625 Acc: 0.9342\n",
      "Epoch 056 | Train Loss: 0.1382 Acc: 0.9456 | Val Loss: 0.1375 Acc: 0.9463\n",
      "Epoch 057 | Train Loss: 0.1090 Acc: 0.9597 | Val Loss: 0.1453 Acc: 0.9487\n",
      "Epoch 058 | Train Loss: 0.1165 Acc: 0.9538 | Val Loss: 0.1605 Acc: 0.9336\n",
      "Epoch 059 | Train Loss: 0.1182 Acc: 0.9543 | Val Loss: 0.1431 Acc: 0.9469\n",
      "Epoch 060 | Train Loss: 0.1065 Acc: 0.9604 | Val Loss: 0.1326 Acc: 0.9559\n",
      "Epoch 001 | Train Loss: 0.6796 Acc: 0.5815 | Val Loss: 0.6767 Acc: 0.5845\n",
      "Epoch 002 | Train Loss: 0.6683 Acc: 0.5996 | Val Loss: 0.6633 Acc: 0.6039\n",
      "Epoch 003 | Train Loss: 0.6635 Acc: 0.6062 | Val Loss: 0.6535 Acc: 0.6105\n",
      "Epoch 004 | Train Loss: 0.6362 Acc: 0.6503 | Val Loss: 0.6119 Acc: 0.6896\n",
      "Epoch 005 | Train Loss: 0.5866 Acc: 0.7071 | Val Loss: 0.5734 Acc: 0.7041\n",
      "Epoch 006 | Train Loss: 0.5514 Acc: 0.7305 | Val Loss: 0.5508 Acc: 0.7192\n",
      "Epoch 007 | Train Loss: 0.5363 Acc: 0.7460 | Val Loss: 0.5324 Acc: 0.7319\n",
      "Epoch 008 | Train Loss: 0.5225 Acc: 0.7488 | Val Loss: 0.5254 Acc: 0.7391\n",
      "Epoch 009 | Train Loss: 0.5044 Acc: 0.7643 | Val Loss: 0.5032 Acc: 0.7512\n",
      "Epoch 010 | Train Loss: 0.4833 Acc: 0.7705 | Val Loss: 0.4884 Acc: 0.7566\n",
      "Epoch 011 | Train Loss: 0.4672 Acc: 0.7803 | Val Loss: 0.4723 Acc: 0.7633\n",
      "Epoch 012 | Train Loss: 0.4517 Acc: 0.7876 | Val Loss: 0.4307 Acc: 0.7995\n",
      "Epoch 013 | Train Loss: 0.4204 Acc: 0.8016 | Val Loss: 0.4320 Acc: 0.7953\n",
      "Epoch 014 | Train Loss: 0.4103 Acc: 0.8122 | Val Loss: 0.4166 Acc: 0.8080\n",
      "Epoch 015 | Train Loss: 0.3908 Acc: 0.8227 | Val Loss: 0.3906 Acc: 0.8243\n",
      "Epoch 016 | Train Loss: 0.3817 Acc: 0.8271 | Val Loss: 0.4175 Acc: 0.8086\n",
      "Epoch 017 | Train Loss: 0.3564 Acc: 0.8413 | Val Loss: 0.3767 Acc: 0.8231\n",
      "Epoch 018 | Train Loss: 0.3423 Acc: 0.8478 | Val Loss: 0.3667 Acc: 0.8339\n",
      "Epoch 019 | Train Loss: 0.3161 Acc: 0.8581 | Val Loss: 0.3207 Acc: 0.8557\n",
      "Epoch 020 | Train Loss: 0.2972 Acc: 0.8717 | Val Loss: 0.2768 Acc: 0.8865\n",
      "Epoch 021 | Train Loss: 0.2824 Acc: 0.8804 | Val Loss: 0.3181 Acc: 0.8575\n",
      "Epoch 022 | Train Loss: 0.2674 Acc: 0.8905 | Val Loss: 0.2548 Acc: 0.8973\n",
      "Epoch 023 | Train Loss: 0.2472 Acc: 0.8975 | Val Loss: 0.2512 Acc: 0.8907\n",
      "Epoch 024 | Train Loss: 0.2299 Acc: 0.9041 | Val Loss: 0.2383 Acc: 0.8967\n",
      "Epoch 025 | Train Loss: 0.2306 Acc: 0.9038 | Val Loss: 0.2685 Acc: 0.8829\n",
      "Epoch 026 | Train Loss: 0.2178 Acc: 0.9139 | Val Loss: 0.2123 Acc: 0.9191\n",
      "Epoch 027 | Train Loss: 0.2062 Acc: 0.9195 | Val Loss: 0.2191 Acc: 0.9161\n",
      "Epoch 028 | Train Loss: 0.1916 Acc: 0.9262 | Val Loss: 0.2241 Acc: 0.9088\n",
      "Epoch 029 | Train Loss: 0.1827 Acc: 0.9296 | Val Loss: 0.2001 Acc: 0.9191\n",
      "Epoch 030 | Train Loss: 0.1790 Acc: 0.9319 | Val Loss: 0.2123 Acc: 0.9167\n",
      "Epoch 031 | Train Loss: 0.1607 Acc: 0.9385 | Val Loss: 0.2256 Acc: 0.9136\n",
      "Epoch 032 | Train Loss: 0.1724 Acc: 0.9307 | Val Loss: 0.1872 Acc: 0.9263\n",
      "Epoch 033 | Train Loss: 0.1535 Acc: 0.9404 | Val Loss: 0.1956 Acc: 0.9185\n",
      "Epoch 034 | Train Loss: 0.1495 Acc: 0.9407 | Val Loss: 0.1783 Acc: 0.9281\n",
      "Epoch 035 | Train Loss: 0.1458 Acc: 0.9423 | Val Loss: 0.1941 Acc: 0.9257\n",
      "Epoch 036 | Train Loss: 0.1443 Acc: 0.9420 | Val Loss: 0.1907 Acc: 0.9257\n",
      "Epoch 037 | Train Loss: 0.1420 Acc: 0.9459 | Val Loss: 0.1718 Acc: 0.9312\n",
      "Epoch 038 | Train Loss: 0.1262 Acc: 0.9506 | Val Loss: 0.1832 Acc: 0.9312\n",
      "Epoch 039 | Train Loss: 0.1298 Acc: 0.9502 | Val Loss: 0.1998 Acc: 0.9221\n",
      "Epoch 040 | Train Loss: 0.1365 Acc: 0.9458 | Val Loss: 0.1907 Acc: 0.9209\n",
      "Epoch 041 | Train Loss: 0.1340 Acc: 0.9502 | Val Loss: 0.1661 Acc: 0.9318\n",
      "Epoch 042 | Train Loss: 0.1155 Acc: 0.9558 | Val Loss: 0.1696 Acc: 0.9384\n",
      "Epoch 043 | Train Loss: 0.1134 Acc: 0.9561 | Val Loss: 0.1724 Acc: 0.9312\n",
      "Epoch 044 | Train Loss: 0.1127 Acc: 0.9553 | Val Loss: 0.1492 Acc: 0.9444\n",
      "Epoch 045 | Train Loss: 0.1014 Acc: 0.9600 | Val Loss: 0.1988 Acc: 0.9173\n",
      "Epoch 046 | Train Loss: 0.1038 Acc: 0.9600 | Val Loss: 0.1949 Acc: 0.9269\n",
      "Epoch 047 | Train Loss: 0.1010 Acc: 0.9588 | Val Loss: 0.1621 Acc: 0.9378\n",
      "Epoch 048 | Train Loss: 0.0919 Acc: 0.9674 | Val Loss: 0.1817 Acc: 0.9330\n",
      "Epoch 049 | Train Loss: 0.1000 Acc: 0.9606 | Val Loss: 0.1680 Acc: 0.9342\n",
      "Epoch 050 | Train Loss: 0.0842 Acc: 0.9704 | Val Loss: 0.1716 Acc: 0.9378\n",
      "Epoch 051 | Train Loss: 0.0960 Acc: 0.9636 | Val Loss: 0.1570 Acc: 0.9444\n",
      "Epoch 052 | Train Loss: 0.0907 Acc: 0.9665 | Val Loss: 0.1769 Acc: 0.9366\n",
      "Epoch 053 | Train Loss: 0.0868 Acc: 0.9659 | Val Loss: 0.1904 Acc: 0.9330\n",
      "Epoch 054 | Train Loss: 0.0943 Acc: 0.9648 | Val Loss: 0.1855 Acc: 0.9420\n",
      "Early stopping triggered.\n",
      "Epoch 001 | Train Loss: 0.6786 Acc: 0.5851 | Val Loss: 0.6739 Acc: 0.5924\n",
      "Epoch 002 | Train Loss: 0.6735 Acc: 0.5935 | Val Loss: 0.6755 Acc: 0.5833\n",
      "Epoch 003 | Train Loss: 0.6548 Acc: 0.6201 | Val Loss: 0.6273 Acc: 0.6455\n",
      "Epoch 004 | Train Loss: 0.6098 Acc: 0.6776 | Val Loss: 0.5675 Acc: 0.7071\n",
      "Epoch 005 | Train Loss: 0.5592 Acc: 0.7263 | Val Loss: 0.5674 Acc: 0.6993\n",
      "Epoch 006 | Train Loss: 0.5292 Acc: 0.7436 | Val Loss: 0.5135 Acc: 0.7506\n",
      "Epoch 007 | Train Loss: 0.5035 Acc: 0.7555 | Val Loss: 0.5262 Acc: 0.7409\n",
      "Epoch 008 | Train Loss: 0.4847 Acc: 0.7670 | Val Loss: 0.4612 Acc: 0.7742\n",
      "Epoch 009 | Train Loss: 0.4543 Acc: 0.7857 | Val Loss: 0.4565 Acc: 0.7723\n",
      "Epoch 010 | Train Loss: 0.4383 Acc: 0.7962 | Val Loss: 0.4576 Acc: 0.7886\n",
      "Epoch 011 | Train Loss: 0.4204 Acc: 0.8055 | Val Loss: 0.4343 Acc: 0.7953\n",
      "Epoch 012 | Train Loss: 0.4024 Acc: 0.8172 | Val Loss: 0.3910 Acc: 0.8194\n",
      "Epoch 013 | Train Loss: 0.3883 Acc: 0.8197 | Val Loss: 0.3606 Acc: 0.8231\n",
      "Epoch 014 | Train Loss: 0.3549 Acc: 0.8430 | Val Loss: 0.4046 Acc: 0.8140\n",
      "Epoch 015 | Train Loss: 0.3360 Acc: 0.8551 | Val Loss: 0.3379 Acc: 0.8442\n",
      "Epoch 016 | Train Loss: 0.3150 Acc: 0.8628 | Val Loss: 0.3376 Acc: 0.8551\n",
      "Epoch 017 | Train Loss: 0.2998 Acc: 0.8736 | Val Loss: 0.3030 Acc: 0.8641\n",
      "Epoch 018 | Train Loss: 0.2804 Acc: 0.8848 | Val Loss: 0.3081 Acc: 0.8605\n",
      "Epoch 019 | Train Loss: 0.2659 Acc: 0.8886 | Val Loss: 0.2765 Acc: 0.8774\n",
      "Epoch 020 | Train Loss: 0.2476 Acc: 0.8969 | Val Loss: 0.2875 Acc: 0.8738\n",
      "Epoch 021 | Train Loss: 0.2383 Acc: 0.9035 | Val Loss: 0.2433 Acc: 0.9028\n",
      "Epoch 022 | Train Loss: 0.2311 Acc: 0.9077 | Val Loss: 0.2222 Acc: 0.9064\n",
      "Epoch 023 | Train Loss: 0.2145 Acc: 0.9094 | Val Loss: 0.2486 Acc: 0.8943\n",
      "Epoch 024 | Train Loss: 0.2010 Acc: 0.9207 | Val Loss: 0.1986 Acc: 0.9167\n",
      "Epoch 025 | Train Loss: 0.1888 Acc: 0.9231 | Val Loss: 0.2176 Acc: 0.9046\n",
      "Epoch 026 | Train Loss: 0.1881 Acc: 0.9244 | Val Loss: 0.2188 Acc: 0.9088\n",
      "Epoch 027 | Train Loss: 0.1727 Acc: 0.9322 | Val Loss: 0.2496 Acc: 0.8979\n",
      "Epoch 028 | Train Loss: 0.1656 Acc: 0.9364 | Val Loss: 0.2065 Acc: 0.9203\n",
      "Epoch 029 | Train Loss: 0.1630 Acc: 0.9384 | Val Loss: 0.1994 Acc: 0.9215\n",
      "Epoch 030 | Train Loss: 0.1530 Acc: 0.9416 | Val Loss: 0.2149 Acc: 0.9185\n",
      "Epoch 031 | Train Loss: 0.1492 Acc: 0.9407 | Val Loss: 0.2110 Acc: 0.9209\n",
      "Epoch 032 | Train Loss: 0.1478 Acc: 0.9432 | Val Loss: 0.2488 Acc: 0.8998\n",
      "Epoch 033 | Train Loss: 0.1474 Acc: 0.9426 | Val Loss: 0.1940 Acc: 0.9215\n",
      "Epoch 034 | Train Loss: 0.1357 Acc: 0.9479 | Val Loss: 0.2152 Acc: 0.9179\n",
      "Epoch 035 | Train Loss: 0.1281 Acc: 0.9497 | Val Loss: 0.1949 Acc: 0.9293\n",
      "Epoch 036 | Train Loss: 0.1167 Acc: 0.9546 | Val Loss: 0.1958 Acc: 0.9275\n",
      "Epoch 037 | Train Loss: 0.1184 Acc: 0.9553 | Val Loss: 0.1609 Acc: 0.9354\n",
      "Epoch 038 | Train Loss: 0.1189 Acc: 0.9573 | Val Loss: 0.1626 Acc: 0.9384\n",
      "Epoch 039 | Train Loss: 0.1150 Acc: 0.9568 | Val Loss: 0.1790 Acc: 0.9281\n",
      "Epoch 040 | Train Loss: 0.1057 Acc: 0.9571 | Val Loss: 0.1902 Acc: 0.9293\n",
      "Epoch 041 | Train Loss: 0.1038 Acc: 0.9615 | Val Loss: 0.1593 Acc: 0.9378\n",
      "Epoch 042 | Train Loss: 0.1018 Acc: 0.9644 | Val Loss: 0.1658 Acc: 0.9420\n",
      "Epoch 043 | Train Loss: 0.1009 Acc: 0.9609 | Val Loss: 0.1769 Acc: 0.9372\n",
      "Epoch 044 | Train Loss: 0.1079 Acc: 0.9620 | Val Loss: 0.2006 Acc: 0.9300\n",
      "Epoch 045 | Train Loss: 0.0947 Acc: 0.9629 | Val Loss: 0.1705 Acc: 0.9390\n",
      "Epoch 046 | Train Loss: 0.1019 Acc: 0.9601 | Val Loss: 0.1672 Acc: 0.9402\n",
      "Epoch 047 | Train Loss: 0.0921 Acc: 0.9659 | Val Loss: 0.1685 Acc: 0.9330\n",
      "Epoch 048 | Train Loss: 0.0870 Acc: 0.9672 | Val Loss: 0.1642 Acc: 0.9396\n",
      "Epoch 049 | Train Loss: 0.0949 Acc: 0.9660 | Val Loss: 0.1567 Acc: 0.9348\n",
      "Epoch 050 | Train Loss: 0.0748 Acc: 0.9746 | Val Loss: 0.1635 Acc: 0.9414\n",
      "Epoch 051 | Train Loss: 0.0890 Acc: 0.9662 | Val Loss: 0.1657 Acc: 0.9463\n",
      "Epoch 052 | Train Loss: 0.0875 Acc: 0.9653 | Val Loss: 0.2027 Acc: 0.9179\n",
      "Epoch 053 | Train Loss: 0.0836 Acc: 0.9695 | Val Loss: 0.1633 Acc: 0.9438\n",
      "Epoch 054 | Train Loss: 0.0736 Acc: 0.9713 | Val Loss: 0.1588 Acc: 0.9457\n",
      "Epoch 055 | Train Loss: 0.0749 Acc: 0.9713 | Val Loss: 0.1584 Acc: 0.9414\n",
      "Epoch 056 | Train Loss: 0.0721 Acc: 0.9760 | Val Loss: 0.1659 Acc: 0.9444\n",
      "Epoch 057 | Train Loss: 0.0791 Acc: 0.9733 | Val Loss: 0.2044 Acc: 0.9293\n",
      "Epoch 058 | Train Loss: 0.0706 Acc: 0.9734 | Val Loss: 0.1789 Acc: 0.9336\n",
      "Epoch 059 | Train Loss: 0.0763 Acc: 0.9715 | Val Loss: 0.2046 Acc: 0.9372\n",
      "Early stopping triggered.\n",
      "Iteration 32/40 | Best Val Loss: 0.1122 | Iter Time: 214.36s | Total Time: 131.09 min\n",
      "Epoch 001 | Train Loss: 0.6763 Acc: 0.5855 | Val Loss: 0.6723 Acc: 0.5876\n",
      "Epoch 002 | Train Loss: 0.6693 Acc: 0.5982 | Val Loss: 0.6630 Acc: 0.6045\n",
      "Epoch 003 | Train Loss: 0.6599 Acc: 0.6082 | Val Loss: 0.6704 Acc: 0.5833\n",
      "Epoch 004 | Train Loss: 0.6412 Acc: 0.6390 | Val Loss: 0.6029 Acc: 0.6938\n",
      "Epoch 005 | Train Loss: 0.6006 Acc: 0.6932 | Val Loss: 0.6215 Acc: 0.6655\n",
      "Epoch 006 | Train Loss: 0.5844 Acc: 0.7083 | Val Loss: 0.5677 Acc: 0.7120\n",
      "Epoch 007 | Train Loss: 0.5384 Acc: 0.7412 | Val Loss: 0.5394 Acc: 0.7331\n",
      "Epoch 008 | Train Loss: 0.5257 Acc: 0.7503 | Val Loss: 0.5454 Acc: 0.7234\n",
      "Epoch 009 | Train Loss: 0.5054 Acc: 0.7625 | Val Loss: 0.5174 Acc: 0.7452\n",
      "Epoch 010 | Train Loss: 0.4900 Acc: 0.7722 | Val Loss: 0.4974 Acc: 0.7585\n",
      "Epoch 011 | Train Loss: 0.4662 Acc: 0.7842 | Val Loss: 0.4973 Acc: 0.7627\n",
      "Epoch 012 | Train Loss: 0.4506 Acc: 0.7962 | Val Loss: 0.4585 Acc: 0.7796\n",
      "Epoch 013 | Train Loss: 0.4180 Acc: 0.8096 | Val Loss: 0.4463 Acc: 0.7905\n",
      "Epoch 014 | Train Loss: 0.4017 Acc: 0.8138 | Val Loss: 0.4114 Acc: 0.8219\n",
      "Epoch 015 | Train Loss: 0.3731 Acc: 0.8354 | Val Loss: 0.4480 Acc: 0.8037\n",
      "Epoch 016 | Train Loss: 0.3476 Acc: 0.8446 | Val Loss: 0.3705 Acc: 0.8309\n",
      "Epoch 017 | Train Loss: 0.3205 Acc: 0.8631 | Val Loss: 0.3389 Acc: 0.8502\n",
      "Epoch 018 | Train Loss: 0.3081 Acc: 0.8679 | Val Loss: 0.3108 Acc: 0.8653\n",
      "Epoch 019 | Train Loss: 0.2794 Acc: 0.8839 | Val Loss: 0.2986 Acc: 0.8659\n",
      "Epoch 020 | Train Loss: 0.2673 Acc: 0.8881 | Val Loss: 0.2966 Acc: 0.8816\n",
      "Epoch 021 | Train Loss: 0.2457 Acc: 0.9006 | Val Loss: 0.2810 Acc: 0.8768\n",
      "Epoch 022 | Train Loss: 0.2217 Acc: 0.9076 | Val Loss: 0.2754 Acc: 0.8877\n",
      "Epoch 023 | Train Loss: 0.2155 Acc: 0.9136 | Val Loss: 0.2399 Acc: 0.8986\n",
      "Epoch 024 | Train Loss: 0.1895 Acc: 0.9284 | Val Loss: 0.2481 Acc: 0.8949\n",
      "Epoch 025 | Train Loss: 0.1760 Acc: 0.9280 | Val Loss: 0.2976 Acc: 0.8871\n",
      "Epoch 026 | Train Loss: 0.1685 Acc: 0.9290 | Val Loss: 0.2258 Acc: 0.9070\n",
      "Epoch 027 | Train Loss: 0.1540 Acc: 0.9395 | Val Loss: 0.2037 Acc: 0.9209\n",
      "Epoch 028 | Train Loss: 0.1463 Acc: 0.9435 | Val Loss: 0.2566 Acc: 0.9082\n",
      "Epoch 029 | Train Loss: 0.1378 Acc: 0.9452 | Val Loss: 0.2258 Acc: 0.9016\n",
      "Epoch 030 | Train Loss: 0.1384 Acc: 0.9478 | Val Loss: 0.2016 Acc: 0.9191\n",
      "Epoch 031 | Train Loss: 0.1263 Acc: 0.9518 | Val Loss: 0.2102 Acc: 0.9179\n",
      "Epoch 032 | Train Loss: 0.1289 Acc: 0.9506 | Val Loss: 0.2104 Acc: 0.9155\n",
      "Epoch 033 | Train Loss: 0.1038 Acc: 0.9598 | Val Loss: 0.2177 Acc: 0.9112\n",
      "Epoch 034 | Train Loss: 0.1136 Acc: 0.9577 | Val Loss: 0.2035 Acc: 0.9275\n",
      "Epoch 035 | Train Loss: 0.0949 Acc: 0.9645 | Val Loss: 0.2006 Acc: 0.9318\n",
      "Epoch 036 | Train Loss: 0.0971 Acc: 0.9621 | Val Loss: 0.1862 Acc: 0.9354\n",
      "Epoch 037 | Train Loss: 0.0877 Acc: 0.9678 | Val Loss: 0.1894 Acc: 0.9324\n",
      "Epoch 038 | Train Loss: 0.0831 Acc: 0.9687 | Val Loss: 0.1959 Acc: 0.9312\n",
      "Epoch 039 | Train Loss: 0.0786 Acc: 0.9716 | Val Loss: 0.2187 Acc: 0.9263\n",
      "Epoch 040 | Train Loss: 0.0853 Acc: 0.9703 | Val Loss: 0.1794 Acc: 0.9324\n",
      "Epoch 041 | Train Loss: 0.0681 Acc: 0.9761 | Val Loss: 0.2255 Acc: 0.9293\n",
      "Epoch 042 | Train Loss: 0.0734 Acc: 0.9743 | Val Loss: 0.1794 Acc: 0.9426\n",
      "Epoch 043 | Train Loss: 0.0701 Acc: 0.9752 | Val Loss: 0.2020 Acc: 0.9348\n",
      "Epoch 044 | Train Loss: 0.0759 Acc: 0.9715 | Val Loss: 0.1854 Acc: 0.9390\n",
      "Epoch 045 | Train Loss: 0.0642 Acc: 0.9786 | Val Loss: 0.2021 Acc: 0.9354\n",
      "Epoch 046 | Train Loss: 0.0602 Acc: 0.9790 | Val Loss: 0.2070 Acc: 0.9312\n",
      "Epoch 047 | Train Loss: 0.0553 Acc: 0.9792 | Val Loss: 0.1921 Acc: 0.9354\n",
      "Epoch 048 | Train Loss: 0.0512 Acc: 0.9805 | Val Loss: 0.2158 Acc: 0.9354\n",
      "Epoch 049 | Train Loss: 0.0551 Acc: 0.9802 | Val Loss: 0.1995 Acc: 0.9378\n",
      "Epoch 050 | Train Loss: 0.0516 Acc: 0.9807 | Val Loss: 0.1971 Acc: 0.9408\n",
      "Early stopping triggered.\n",
      "Epoch 001 | Train Loss: 0.6805 Acc: 0.5815 | Val Loss: 0.6775 Acc: 0.5773\n",
      "Epoch 002 | Train Loss: 0.6688 Acc: 0.5972 | Val Loss: 0.6549 Acc: 0.6099\n",
      "Epoch 003 | Train Loss: 0.6475 Acc: 0.6310 | Val Loss: 0.6179 Acc: 0.6775\n",
      "Epoch 004 | Train Loss: 0.5956 Acc: 0.7041 | Val Loss: 0.6006 Acc: 0.6878\n",
      "Epoch 005 | Train Loss: 0.5650 Acc: 0.7240 | Val Loss: 0.5480 Acc: 0.7222\n",
      "Epoch 006 | Train Loss: 0.5270 Acc: 0.7482 | Val Loss: 0.5224 Acc: 0.7476\n",
      "Epoch 007 | Train Loss: 0.5064 Acc: 0.7619 | Val Loss: 0.4987 Acc: 0.7560\n",
      "Epoch 008 | Train Loss: 0.4830 Acc: 0.7783 | Val Loss: 0.4922 Acc: 0.7717\n",
      "Epoch 009 | Train Loss: 0.4666 Acc: 0.7916 | Val Loss: 0.4587 Acc: 0.7802\n",
      "Epoch 010 | Train Loss: 0.4367 Acc: 0.8028 | Val Loss: 0.4771 Acc: 0.7633\n",
      "Epoch 011 | Train Loss: 0.4322 Acc: 0.8042 | Val Loss: 0.4329 Acc: 0.7977\n",
      "Epoch 012 | Train Loss: 0.3988 Acc: 0.8227 | Val Loss: 0.4102 Acc: 0.8098\n",
      "Epoch 013 | Train Loss: 0.3826 Acc: 0.8335 | Val Loss: 0.4041 Acc: 0.8080\n",
      "Epoch 014 | Train Loss: 0.3716 Acc: 0.8416 | Val Loss: 0.3671 Acc: 0.8333\n",
      "Epoch 015 | Train Loss: 0.3400 Acc: 0.8520 | Val Loss: 0.3511 Acc: 0.8357\n",
      "Epoch 016 | Train Loss: 0.3216 Acc: 0.8638 | Val Loss: 0.3641 Acc: 0.8376\n",
      "Epoch 017 | Train Loss: 0.3001 Acc: 0.8736 | Val Loss: 0.3129 Acc: 0.8569\n",
      "Epoch 018 | Train Loss: 0.2873 Acc: 0.8777 | Val Loss: 0.2783 Acc: 0.8859\n",
      "Epoch 019 | Train Loss: 0.2602 Acc: 0.8910 | Val Loss: 0.2598 Acc: 0.8919\n",
      "Epoch 020 | Train Loss: 0.2395 Acc: 0.9067 | Val Loss: 0.3120 Acc: 0.8678\n",
      "Epoch 021 | Train Loss: 0.2340 Acc: 0.9073 | Val Loss: 0.2334 Acc: 0.9052\n",
      "Epoch 022 | Train Loss: 0.2064 Acc: 0.9200 | Val Loss: 0.2987 Acc: 0.8690\n",
      "Epoch 023 | Train Loss: 0.2006 Acc: 0.9191 | Val Loss: 0.2543 Acc: 0.8973\n",
      "Epoch 024 | Train Loss: 0.1931 Acc: 0.9238 | Val Loss: 0.2450 Acc: 0.9028\n",
      "Epoch 025 | Train Loss: 0.1730 Acc: 0.9325 | Val Loss: 0.2294 Acc: 0.9112\n",
      "Epoch 026 | Train Loss: 0.1619 Acc: 0.9379 | Val Loss: 0.2656 Acc: 0.8961\n",
      "Epoch 027 | Train Loss: 0.1605 Acc: 0.9390 | Val Loss: 0.2341 Acc: 0.9070\n",
      "Epoch 028 | Train Loss: 0.1520 Acc: 0.9414 | Val Loss: 0.2458 Acc: 0.8992\n",
      "Epoch 029 | Train Loss: 0.1537 Acc: 0.9390 | Val Loss: 0.2512 Acc: 0.9094\n",
      "Epoch 030 | Train Loss: 0.1309 Acc: 0.9499 | Val Loss: 0.2173 Acc: 0.9185\n",
      "Epoch 031 | Train Loss: 0.1341 Acc: 0.9500 | Val Loss: 0.2199 Acc: 0.9124\n",
      "Epoch 032 | Train Loss: 0.1171 Acc: 0.9579 | Val Loss: 0.2479 Acc: 0.9124\n",
      "Epoch 033 | Train Loss: 0.1296 Acc: 0.9512 | Val Loss: 0.1980 Acc: 0.9227\n",
      "Epoch 034 | Train Loss: 0.1103 Acc: 0.9594 | Val Loss: 0.1783 Acc: 0.9324\n",
      "Epoch 035 | Train Loss: 0.1050 Acc: 0.9588 | Val Loss: 0.2236 Acc: 0.9143\n",
      "Epoch 036 | Train Loss: 0.1135 Acc: 0.9567 | Val Loss: 0.1853 Acc: 0.9275\n",
      "Epoch 037 | Train Loss: 0.0996 Acc: 0.9639 | Val Loss: 0.1834 Acc: 0.9245\n",
      "Epoch 038 | Train Loss: 0.0853 Acc: 0.9680 | Val Loss: 0.2194 Acc: 0.9209\n",
      "Epoch 039 | Train Loss: 0.0855 Acc: 0.9692 | Val Loss: 0.1629 Acc: 0.9396\n",
      "Epoch 040 | Train Loss: 0.0852 Acc: 0.9671 | Val Loss: 0.1594 Acc: 0.9475\n",
      "Epoch 041 | Train Loss: 0.0837 Acc: 0.9706 | Val Loss: 0.1969 Acc: 0.9245\n",
      "Epoch 042 | Train Loss: 0.0793 Acc: 0.9690 | Val Loss: 0.1778 Acc: 0.9312\n",
      "Epoch 043 | Train Loss: 0.0799 Acc: 0.9716 | Val Loss: 0.1776 Acc: 0.9324\n",
      "Epoch 044 | Train Loss: 0.0823 Acc: 0.9689 | Val Loss: 0.1962 Acc: 0.9293\n",
      "Epoch 045 | Train Loss: 0.0715 Acc: 0.9740 | Val Loss: 0.2013 Acc: 0.9269\n",
      "Epoch 046 | Train Loss: 0.0776 Acc: 0.9707 | Val Loss: 0.1848 Acc: 0.9318\n",
      "Epoch 047 | Train Loss: 0.0720 Acc: 0.9733 | Val Loss: 0.1930 Acc: 0.9287\n",
      "Epoch 048 | Train Loss: 0.0672 Acc: 0.9743 | Val Loss: 0.2100 Acc: 0.9269\n",
      "Epoch 049 | Train Loss: 0.0732 Acc: 0.9710 | Val Loss: 0.2110 Acc: 0.9306\n",
      "Epoch 050 | Train Loss: 0.0693 Acc: 0.9755 | Val Loss: 0.1931 Acc: 0.9354\n",
      "Early stopping triggered.\n",
      "Epoch 001 | Train Loss: 0.6844 Acc: 0.5721 | Val Loss: 0.6842 Acc: 0.5658\n",
      "Epoch 002 | Train Loss: 0.6775 Acc: 0.5852 | Val Loss: 0.6762 Acc: 0.5924\n",
      "Epoch 003 | Train Loss: 0.6755 Acc: 0.5922 | Val Loss: 0.6728 Acc: 0.5924\n",
      "Epoch 004 | Train Loss: 0.6704 Acc: 0.5987 | Val Loss: 0.6693 Acc: 0.5972\n",
      "Epoch 005 | Train Loss: 0.6639 Acc: 0.6059 | Val Loss: 0.6595 Acc: 0.6159\n",
      "Epoch 006 | Train Loss: 0.6284 Acc: 0.6563 | Val Loss: 0.7041 Acc: 0.6123\n",
      "Epoch 007 | Train Loss: 0.5934 Acc: 0.7004 | Val Loss: 0.5653 Acc: 0.7138\n",
      "Epoch 008 | Train Loss: 0.5620 Acc: 0.7208 | Val Loss: 0.5568 Acc: 0.7150\n",
      "Epoch 009 | Train Loss: 0.5358 Acc: 0.7349 | Val Loss: 0.5487 Acc: 0.7301\n",
      "Epoch 010 | Train Loss: 0.5199 Acc: 0.7500 | Val Loss: 0.5115 Acc: 0.7458\n",
      "Epoch 011 | Train Loss: 0.4910 Acc: 0.7675 | Val Loss: 0.5392 Acc: 0.7409\n",
      "Epoch 012 | Train Loss: 0.4758 Acc: 0.7790 | Val Loss: 0.5106 Acc: 0.7440\n",
      "Epoch 013 | Train Loss: 0.4525 Acc: 0.7842 | Val Loss: 0.4348 Acc: 0.7953\n",
      "Epoch 014 | Train Loss: 0.4244 Acc: 0.7984 | Val Loss: 0.4323 Acc: 0.8019\n",
      "Epoch 015 | Train Loss: 0.3987 Acc: 0.8212 | Val Loss: 0.4030 Acc: 0.8104\n",
      "Epoch 016 | Train Loss: 0.3837 Acc: 0.8259 | Val Loss: 0.4100 Acc: 0.8110\n",
      "Epoch 017 | Train Loss: 0.3661 Acc: 0.8347 | Val Loss: 0.4120 Acc: 0.8231\n",
      "Epoch 018 | Train Loss: 0.3522 Acc: 0.8434 | Val Loss: 0.3589 Acc: 0.8412\n",
      "Epoch 019 | Train Loss: 0.3254 Acc: 0.8540 | Val Loss: 0.3337 Acc: 0.8490\n",
      "Epoch 020 | Train Loss: 0.3136 Acc: 0.8664 | Val Loss: 0.3017 Acc: 0.8792\n",
      "Epoch 021 | Train Loss: 0.2931 Acc: 0.8744 | Val Loss: 0.3186 Acc: 0.8702\n",
      "Epoch 022 | Train Loss: 0.2775 Acc: 0.8840 | Val Loss: 0.2856 Acc: 0.8780\n",
      "Epoch 023 | Train Loss: 0.2851 Acc: 0.8792 | Val Loss: 0.2999 Acc: 0.8665\n",
      "Epoch 024 | Train Loss: 0.2639 Acc: 0.8872 | Val Loss: 0.2664 Acc: 0.8925\n",
      "Epoch 025 | Train Loss: 0.2481 Acc: 0.8994 | Val Loss: 0.2649 Acc: 0.8925\n",
      "Epoch 026 | Train Loss: 0.2477 Acc: 0.8999 | Val Loss: 0.2915 Acc: 0.8786\n",
      "Epoch 027 | Train Loss: 0.2215 Acc: 0.9148 | Val Loss: 0.3020 Acc: 0.8798\n",
      "Epoch 028 | Train Loss: 0.2086 Acc: 0.9161 | Val Loss: 0.2323 Acc: 0.9088\n",
      "Epoch 029 | Train Loss: 0.2008 Acc: 0.9215 | Val Loss: 0.2520 Acc: 0.8913\n",
      "Epoch 030 | Train Loss: 0.1883 Acc: 0.9254 | Val Loss: 0.1954 Acc: 0.9227\n",
      "Epoch 031 | Train Loss: 0.1817 Acc: 0.9313 | Val Loss: 0.2107 Acc: 0.9088\n",
      "Epoch 032 | Train Loss: 0.1937 Acc: 0.9238 | Val Loss: 0.2231 Acc: 0.9100\n",
      "Epoch 033 | Train Loss: 0.1718 Acc: 0.9304 | Val Loss: 0.2097 Acc: 0.9088\n",
      "Epoch 034 | Train Loss: 0.1653 Acc: 0.9325 | Val Loss: 0.1913 Acc: 0.9263\n",
      "Epoch 035 | Train Loss: 0.1595 Acc: 0.9379 | Val Loss: 0.2116 Acc: 0.9149\n",
      "Epoch 036 | Train Loss: 0.1533 Acc: 0.9393 | Val Loss: 0.1939 Acc: 0.9330\n",
      "Epoch 037 | Train Loss: 0.1330 Acc: 0.9497 | Val Loss: 0.1797 Acc: 0.9257\n",
      "Epoch 038 | Train Loss: 0.1418 Acc: 0.9449 | Val Loss: 0.2136 Acc: 0.9197\n",
      "Epoch 039 | Train Loss: 0.1354 Acc: 0.9444 | Val Loss: 0.1919 Acc: 0.9251\n",
      "Epoch 040 | Train Loss: 0.1424 Acc: 0.9467 | Val Loss: 0.1669 Acc: 0.9384\n",
      "Epoch 041 | Train Loss: 0.1392 Acc: 0.9490 | Val Loss: 0.1815 Acc: 0.9263\n",
      "Epoch 042 | Train Loss: 0.1306 Acc: 0.9494 | Val Loss: 0.1616 Acc: 0.9348\n",
      "Epoch 043 | Train Loss: 0.1143 Acc: 0.9570 | Val Loss: 0.1850 Acc: 0.9342\n",
      "Epoch 044 | Train Loss: 0.1300 Acc: 0.9514 | Val Loss: 0.1555 Acc: 0.9396\n",
      "Epoch 045 | Train Loss: 0.1180 Acc: 0.9523 | Val Loss: 0.1575 Acc: 0.9366\n",
      "Epoch 046 | Train Loss: 0.1237 Acc: 0.9561 | Val Loss: 0.1819 Acc: 0.9287\n",
      "Epoch 047 | Train Loss: 0.1126 Acc: 0.9597 | Val Loss: 0.1487 Acc: 0.9420\n",
      "Epoch 048 | Train Loss: 0.1028 Acc: 0.9623 | Val Loss: 0.1702 Acc: 0.9408\n",
      "Epoch 049 | Train Loss: 0.1031 Acc: 0.9609 | Val Loss: 0.1439 Acc: 0.9487\n",
      "Epoch 050 | Train Loss: 0.1087 Acc: 0.9606 | Val Loss: 0.1595 Acc: 0.9354\n",
      "Epoch 051 | Train Loss: 0.0927 Acc: 0.9633 | Val Loss: 0.1481 Acc: 0.9493\n",
      "Epoch 052 | Train Loss: 0.0954 Acc: 0.9648 | Val Loss: 0.1644 Acc: 0.9390\n",
      "Epoch 053 | Train Loss: 0.1005 Acc: 0.9644 | Val Loss: 0.1613 Acc: 0.9396\n",
      "Epoch 054 | Train Loss: 0.0915 Acc: 0.9651 | Val Loss: 0.1881 Acc: 0.9263\n",
      "Epoch 055 | Train Loss: 0.0933 Acc: 0.9627 | Val Loss: 0.1563 Acc: 0.9463\n",
      "Epoch 056 | Train Loss: 0.0868 Acc: 0.9666 | Val Loss: 0.1808 Acc: 0.9281\n",
      "Epoch 057 | Train Loss: 0.0960 Acc: 0.9620 | Val Loss: 0.2148 Acc: 0.9251\n",
      "Epoch 058 | Train Loss: 0.0875 Acc: 0.9680 | Val Loss: 0.1469 Acc: 0.9450\n",
      "Epoch 059 | Train Loss: 0.0837 Acc: 0.9689 | Val Loss: 0.1425 Acc: 0.9499\n",
      "Epoch 060 | Train Loss: 0.0877 Acc: 0.9668 | Val Loss: 0.1480 Acc: 0.9450\n",
      "Epoch 001 | Train Loss: 0.6816 Acc: 0.5732 | Val Loss: 0.6754 Acc: 0.5882\n",
      "Epoch 002 | Train Loss: 0.6682 Acc: 0.5975 | Val Loss: 0.6555 Acc: 0.6075\n",
      "Epoch 003 | Train Loss: 0.6652 Acc: 0.5982 | Val Loss: 0.6559 Acc: 0.6111\n",
      "Epoch 004 | Train Loss: 0.6294 Acc: 0.6579 | Val Loss: 0.5954 Acc: 0.6806\n",
      "Epoch 005 | Train Loss: 0.5944 Acc: 0.6949 | Val Loss: 0.5747 Acc: 0.7029\n",
      "Epoch 006 | Train Loss: 0.5616 Acc: 0.7181 | Val Loss: 0.5501 Acc: 0.7138\n",
      "Epoch 007 | Train Loss: 0.5414 Acc: 0.7373 | Val Loss: 0.5488 Acc: 0.7192\n",
      "Epoch 008 | Train Loss: 0.5168 Acc: 0.7536 | Val Loss: 0.5133 Acc: 0.7464\n",
      "Epoch 009 | Train Loss: 0.5000 Acc: 0.7655 | Val Loss: 0.4929 Acc: 0.7621\n",
      "Epoch 010 | Train Loss: 0.4838 Acc: 0.7634 | Val Loss: 0.5429 Acc: 0.7397\n",
      "Epoch 011 | Train Loss: 0.4642 Acc: 0.7842 | Val Loss: 0.4585 Acc: 0.7772\n",
      "Epoch 012 | Train Loss: 0.4504 Acc: 0.7903 | Val Loss: 0.4730 Acc: 0.7844\n",
      "Epoch 013 | Train Loss: 0.4331 Acc: 0.7983 | Val Loss: 0.4458 Acc: 0.7874\n",
      "Epoch 014 | Train Loss: 0.4123 Acc: 0.8147 | Val Loss: 0.4335 Acc: 0.7856\n",
      "Epoch 015 | Train Loss: 0.3852 Acc: 0.8233 | Val Loss: 0.3777 Acc: 0.8219\n",
      "Epoch 016 | Train Loss: 0.3704 Acc: 0.8377 | Val Loss: 0.3654 Acc: 0.8291\n",
      "Epoch 017 | Train Loss: 0.3569 Acc: 0.8461 | Val Loss: 0.3509 Acc: 0.8430\n",
      "Epoch 018 | Train Loss: 0.3296 Acc: 0.8566 | Val Loss: 0.3235 Acc: 0.8460\n",
      "Epoch 019 | Train Loss: 0.3263 Acc: 0.8596 | Val Loss: 0.3192 Acc: 0.8557\n",
      "Epoch 020 | Train Loss: 0.3103 Acc: 0.8638 | Val Loss: 0.3082 Acc: 0.8684\n",
      "Epoch 021 | Train Loss: 0.2968 Acc: 0.8792 | Val Loss: 0.2916 Acc: 0.8720\n",
      "Epoch 022 | Train Loss: 0.2821 Acc: 0.8809 | Val Loss: 0.2948 Acc: 0.8659\n",
      "Epoch 023 | Train Loss: 0.2474 Acc: 0.8979 | Val Loss: 0.2542 Acc: 0.8949\n",
      "Epoch 024 | Train Loss: 0.2577 Acc: 0.8955 | Val Loss: 0.2605 Acc: 0.8871\n",
      "Epoch 025 | Train Loss: 0.2394 Acc: 0.9043 | Val Loss: 0.2821 Acc: 0.8835\n",
      "Epoch 026 | Train Loss: 0.2379 Acc: 0.9010 | Val Loss: 0.2333 Acc: 0.9016\n",
      "Epoch 027 | Train Loss: 0.2273 Acc: 0.9061 | Val Loss: 0.2511 Acc: 0.9016\n",
      "Epoch 028 | Train Loss: 0.2023 Acc: 0.9198 | Val Loss: 0.2116 Acc: 0.9173\n",
      "Epoch 029 | Train Loss: 0.1986 Acc: 0.9207 | Val Loss: 0.2180 Acc: 0.9076\n",
      "Epoch 030 | Train Loss: 0.1851 Acc: 0.9293 | Val Loss: 0.2400 Acc: 0.9004\n",
      "Epoch 031 | Train Loss: 0.1789 Acc: 0.9304 | Val Loss: 0.1878 Acc: 0.9221\n",
      "Epoch 032 | Train Loss: 0.1783 Acc: 0.9315 | Val Loss: 0.2198 Acc: 0.9100\n",
      "Epoch 033 | Train Loss: 0.1725 Acc: 0.9358 | Val Loss: 0.1902 Acc: 0.9263\n",
      "Epoch 034 | Train Loss: 0.1559 Acc: 0.9425 | Val Loss: 0.2025 Acc: 0.9185\n",
      "Epoch 035 | Train Loss: 0.1630 Acc: 0.9361 | Val Loss: 0.1903 Acc: 0.9263\n",
      "Epoch 036 | Train Loss: 0.1458 Acc: 0.9452 | Val Loss: 0.2806 Acc: 0.8937\n",
      "Epoch 037 | Train Loss: 0.1435 Acc: 0.9428 | Val Loss: 0.2002 Acc: 0.9149\n",
      "Epoch 038 | Train Loss: 0.1429 Acc: 0.9465 | Val Loss: 0.1815 Acc: 0.9281\n",
      "Epoch 039 | Train Loss: 0.1313 Acc: 0.9479 | Val Loss: 0.1705 Acc: 0.9354\n",
      "Epoch 040 | Train Loss: 0.1317 Acc: 0.9508 | Val Loss: 0.1915 Acc: 0.9257\n",
      "Epoch 041 | Train Loss: 0.1233 Acc: 0.9553 | Val Loss: 0.1846 Acc: 0.9251\n",
      "Epoch 042 | Train Loss: 0.1178 Acc: 0.9543 | Val Loss: 0.1415 Acc: 0.9511\n",
      "Epoch 043 | Train Loss: 0.1228 Acc: 0.9567 | Val Loss: 0.1758 Acc: 0.9348\n",
      "Epoch 044 | Train Loss: 0.1024 Acc: 0.9654 | Val Loss: 0.1555 Acc: 0.9481\n",
      "Epoch 045 | Train Loss: 0.1013 Acc: 0.9627 | Val Loss: 0.1379 Acc: 0.9499\n",
      "Epoch 046 | Train Loss: 0.1074 Acc: 0.9576 | Val Loss: 0.1631 Acc: 0.9384\n",
      "Epoch 047 | Train Loss: 0.1042 Acc: 0.9621 | Val Loss: 0.1498 Acc: 0.9426\n",
      "Epoch 048 | Train Loss: 0.1042 Acc: 0.9654 | Val Loss: 0.1613 Acc: 0.9396\n",
      "Epoch 049 | Train Loss: 0.1007 Acc: 0.9624 | Val Loss: 0.1428 Acc: 0.9450\n",
      "Epoch 050 | Train Loss: 0.0960 Acc: 0.9641 | Val Loss: 0.1459 Acc: 0.9432\n",
      "Epoch 051 | Train Loss: 0.0965 Acc: 0.9651 | Val Loss: 0.1528 Acc: 0.9463\n",
      "Epoch 052 | Train Loss: 0.0874 Acc: 0.9680 | Val Loss: 0.1372 Acc: 0.9475\n",
      "Epoch 053 | Train Loss: 0.0842 Acc: 0.9686 | Val Loss: 0.1372 Acc: 0.9529\n",
      "Epoch 054 | Train Loss: 0.0810 Acc: 0.9707 | Val Loss: 0.1290 Acc: 0.9523\n",
      "Epoch 055 | Train Loss: 0.0786 Acc: 0.9712 | Val Loss: 0.1392 Acc: 0.9499\n",
      "Epoch 056 | Train Loss: 0.0743 Acc: 0.9727 | Val Loss: 0.1494 Acc: 0.9487\n",
      "Epoch 057 | Train Loss: 0.0807 Acc: 0.9704 | Val Loss: 0.1257 Acc: 0.9583\n",
      "Epoch 058 | Train Loss: 0.0784 Acc: 0.9700 | Val Loss: 0.1378 Acc: 0.9535\n",
      "Epoch 059 | Train Loss: 0.0693 Acc: 0.9742 | Val Loss: 0.1236 Acc: 0.9559\n",
      "Epoch 060 | Train Loss: 0.0795 Acc: 0.9706 | Val Loss: 0.1363 Acc: 0.9511\n",
      "Epoch 001 | Train Loss: 0.6792 Acc: 0.5827 | Val Loss: 0.6777 Acc: 0.5954\n",
      "Epoch 002 | Train Loss: 0.6642 Acc: 0.6024 | Val Loss: 0.6495 Acc: 0.6401\n",
      "Epoch 003 | Train Loss: 0.6076 Acc: 0.6872 | Val Loss: 0.5653 Acc: 0.7126\n",
      "Epoch 004 | Train Loss: 0.5575 Acc: 0.7232 | Val Loss: 0.5615 Acc: 0.7180\n",
      "Epoch 005 | Train Loss: 0.5314 Acc: 0.7439 | Val Loss: 0.5118 Acc: 0.7494\n",
      "Epoch 006 | Train Loss: 0.5073 Acc: 0.7545 | Val Loss: 0.4948 Acc: 0.7597\n",
      "Epoch 007 | Train Loss: 0.4692 Acc: 0.7811 | Val Loss: 0.4651 Acc: 0.7748\n",
      "Epoch 008 | Train Loss: 0.4456 Acc: 0.7925 | Val Loss: 0.4345 Acc: 0.7893\n",
      "Epoch 009 | Train Loss: 0.4305 Acc: 0.8022 | Val Loss: 0.4515 Acc: 0.7832\n",
      "Epoch 010 | Train Loss: 0.3935 Acc: 0.8214 | Val Loss: 0.3993 Acc: 0.8164\n",
      "Epoch 011 | Train Loss: 0.3770 Acc: 0.8372 | Val Loss: 0.3871 Acc: 0.8207\n",
      "Epoch 012 | Train Loss: 0.3582 Acc: 0.8396 | Val Loss: 0.3398 Acc: 0.8466\n",
      "Epoch 013 | Train Loss: 0.3362 Acc: 0.8567 | Val Loss: 0.3388 Acc: 0.8527\n",
      "Epoch 014 | Train Loss: 0.3111 Acc: 0.8680 | Val Loss: 0.3030 Acc: 0.8720\n",
      "Epoch 015 | Train Loss: 0.2867 Acc: 0.8798 | Val Loss: 0.2897 Acc: 0.8780\n",
      "Epoch 016 | Train Loss: 0.2657 Acc: 0.8934 | Val Loss: 0.3161 Acc: 0.8635\n",
      "Epoch 017 | Train Loss: 0.2508 Acc: 0.8975 | Val Loss: 0.2674 Acc: 0.8853\n",
      "Epoch 018 | Train Loss: 0.2462 Acc: 0.8975 | Val Loss: 0.2406 Acc: 0.8973\n",
      "Epoch 019 | Train Loss: 0.2246 Acc: 0.9080 | Val Loss: 0.2529 Acc: 0.9022\n",
      "Epoch 020 | Train Loss: 0.2076 Acc: 0.9174 | Val Loss: 0.2197 Acc: 0.9040\n",
      "Epoch 021 | Train Loss: 0.2035 Acc: 0.9176 | Val Loss: 0.2676 Acc: 0.8907\n",
      "Epoch 022 | Train Loss: 0.1960 Acc: 0.9244 | Val Loss: 0.1801 Acc: 0.9306\n",
      "Epoch 023 | Train Loss: 0.1898 Acc: 0.9230 | Val Loss: 0.2035 Acc: 0.9203\n",
      "Epoch 024 | Train Loss: 0.1774 Acc: 0.9280 | Val Loss: 0.1954 Acc: 0.9239\n",
      "Epoch 025 | Train Loss: 0.1564 Acc: 0.9402 | Val Loss: 0.1886 Acc: 0.9281\n",
      "Epoch 026 | Train Loss: 0.1558 Acc: 0.9434 | Val Loss: 0.1758 Acc: 0.9396\n",
      "Epoch 027 | Train Loss: 0.1440 Acc: 0.9434 | Val Loss: 0.1714 Acc: 0.9281\n",
      "Epoch 028 | Train Loss: 0.1525 Acc: 0.9422 | Val Loss: 0.1838 Acc: 0.9293\n",
      "Epoch 029 | Train Loss: 0.1355 Acc: 0.9484 | Val Loss: 0.1961 Acc: 0.9275\n",
      "Epoch 030 | Train Loss: 0.1372 Acc: 0.9490 | Val Loss: 0.1709 Acc: 0.9354\n",
      "Epoch 031 | Train Loss: 0.1252 Acc: 0.9535 | Val Loss: 0.1812 Acc: 0.9306\n",
      "Epoch 032 | Train Loss: 0.1168 Acc: 0.9574 | Val Loss: 0.1663 Acc: 0.9414\n",
      "Epoch 033 | Train Loss: 0.1221 Acc: 0.9499 | Val Loss: 0.1598 Acc: 0.9390\n",
      "Epoch 034 | Train Loss: 0.1156 Acc: 0.9574 | Val Loss: 0.1738 Acc: 0.9366\n",
      "Epoch 035 | Train Loss: 0.1048 Acc: 0.9609 | Val Loss: 0.1671 Acc: 0.9444\n",
      "Epoch 036 | Train Loss: 0.1022 Acc: 0.9610 | Val Loss: 0.1558 Acc: 0.9390\n",
      "Epoch 037 | Train Loss: 0.0983 Acc: 0.9623 | Val Loss: 0.1541 Acc: 0.9444\n",
      "Epoch 038 | Train Loss: 0.1005 Acc: 0.9633 | Val Loss: 0.1947 Acc: 0.9300\n",
      "Epoch 039 | Train Loss: 0.0944 Acc: 0.9639 | Val Loss: 0.1442 Acc: 0.9493\n",
      "Epoch 040 | Train Loss: 0.0865 Acc: 0.9671 | Val Loss: 0.1731 Acc: 0.9366\n",
      "Epoch 041 | Train Loss: 0.0805 Acc: 0.9701 | Val Loss: 0.1509 Acc: 0.9511\n",
      "Epoch 042 | Train Loss: 0.0849 Acc: 0.9675 | Val Loss: 0.1628 Acc: 0.9396\n",
      "Epoch 043 | Train Loss: 0.0720 Acc: 0.9740 | Val Loss: 0.1527 Acc: 0.9493\n",
      "Epoch 044 | Train Loss: 0.0749 Acc: 0.9725 | Val Loss: 0.1566 Acc: 0.9535\n",
      "Epoch 045 | Train Loss: 0.0872 Acc: 0.9678 | Val Loss: 0.1770 Acc: 0.9348\n",
      "Epoch 046 | Train Loss: 0.0835 Acc: 0.9697 | Val Loss: 0.1457 Acc: 0.9481\n",
      "Epoch 047 | Train Loss: 0.0836 Acc: 0.9703 | Val Loss: 0.1468 Acc: 0.9529\n",
      "Epoch 048 | Train Loss: 0.0689 Acc: 0.9751 | Val Loss: 0.1561 Acc: 0.9541\n",
      "Epoch 049 | Train Loss: 0.0707 Acc: 0.9749 | Val Loss: 0.1714 Acc: 0.9414\n",
      "Early stopping triggered.\n",
      "Epoch 001 | Train Loss: 0.6795 Acc: 0.5796 | Val Loss: 0.6816 Acc: 0.5694\n",
      "Epoch 002 | Train Loss: 0.6730 Acc: 0.5923 | Val Loss: 0.6710 Acc: 0.5996\n",
      "Epoch 003 | Train Loss: 0.6675 Acc: 0.6002 | Val Loss: 0.6653 Acc: 0.5948\n",
      "Epoch 004 | Train Loss: 0.6455 Acc: 0.6345 | Val Loss: 0.6309 Acc: 0.6594\n",
      "Epoch 005 | Train Loss: 0.6147 Acc: 0.6731 | Val Loss: 0.5983 Acc: 0.6872\n",
      "Epoch 006 | Train Loss: 0.5916 Acc: 0.6947 | Val Loss: 0.5794 Acc: 0.6950\n",
      "Epoch 007 | Train Loss: 0.5661 Acc: 0.7198 | Val Loss: 0.5661 Acc: 0.7114\n",
      "Epoch 008 | Train Loss: 0.5467 Acc: 0.7237 | Val Loss: 0.5488 Acc: 0.7198\n",
      "Epoch 009 | Train Loss: 0.5337 Acc: 0.7436 | Val Loss: 0.5423 Acc: 0.7234\n",
      "Epoch 010 | Train Loss: 0.5225 Acc: 0.7478 | Val Loss: 0.5319 Acc: 0.7264\n",
      "Epoch 011 | Train Loss: 0.4995 Acc: 0.7614 | Val Loss: 0.5117 Acc: 0.7530\n",
      "Epoch 012 | Train Loss: 0.4863 Acc: 0.7719 | Val Loss: 0.5010 Acc: 0.7591\n",
      "Epoch 013 | Train Loss: 0.4733 Acc: 0.7758 | Val Loss: 0.4684 Acc: 0.7742\n",
      "Epoch 014 | Train Loss: 0.4551 Acc: 0.7850 | Val Loss: 0.4538 Acc: 0.7838\n",
      "Epoch 015 | Train Loss: 0.4431 Acc: 0.7980 | Val Loss: 0.4466 Acc: 0.7862\n",
      "Epoch 016 | Train Loss: 0.4200 Acc: 0.8046 | Val Loss: 0.4164 Acc: 0.8056\n",
      "Epoch 017 | Train Loss: 0.4039 Acc: 0.8165 | Val Loss: 0.4762 Acc: 0.7717\n",
      "Epoch 018 | Train Loss: 0.3892 Acc: 0.8232 | Val Loss: 0.3982 Acc: 0.8194\n",
      "Epoch 019 | Train Loss: 0.3757 Acc: 0.8276 | Val Loss: 0.3814 Acc: 0.8219\n",
      "Epoch 020 | Train Loss: 0.3566 Acc: 0.8378 | Val Loss: 0.3728 Acc: 0.8315\n",
      "Epoch 021 | Train Loss: 0.3430 Acc: 0.8470 | Val Loss: 0.3585 Acc: 0.8333\n",
      "Epoch 022 | Train Loss: 0.3226 Acc: 0.8611 | Val Loss: 0.3453 Acc: 0.8490\n",
      "Epoch 023 | Train Loss: 0.2905 Acc: 0.8756 | Val Loss: 0.2978 Acc: 0.8774\n",
      "Epoch 024 | Train Loss: 0.2873 Acc: 0.8783 | Val Loss: 0.3417 Acc: 0.8496\n",
      "Epoch 025 | Train Loss: 0.2765 Acc: 0.8803 | Val Loss: 0.2808 Acc: 0.8847\n",
      "Epoch 026 | Train Loss: 0.2530 Acc: 0.8942 | Val Loss: 0.3096 Acc: 0.8653\n",
      "Epoch 027 | Train Loss: 0.2516 Acc: 0.8954 | Val Loss: 0.2609 Acc: 0.8931\n",
      "Epoch 028 | Train Loss: 0.2251 Acc: 0.9082 | Val Loss: 0.2722 Acc: 0.8847\n",
      "Epoch 029 | Train Loss: 0.2131 Acc: 0.9115 | Val Loss: 0.2309 Acc: 0.9028\n",
      "Epoch 030 | Train Loss: 0.2056 Acc: 0.9164 | Val Loss: 0.2086 Acc: 0.9130\n",
      "Epoch 031 | Train Loss: 0.1994 Acc: 0.9215 | Val Loss: 0.2064 Acc: 0.9179\n",
      "Epoch 032 | Train Loss: 0.1769 Acc: 0.9299 | Val Loss: 0.2140 Acc: 0.9094\n",
      "Epoch 033 | Train Loss: 0.1668 Acc: 0.9355 | Val Loss: 0.2098 Acc: 0.9215\n",
      "Epoch 034 | Train Loss: 0.1573 Acc: 0.9372 | Val Loss: 0.2081 Acc: 0.9143\n",
      "Epoch 035 | Train Loss: 0.1461 Acc: 0.9414 | Val Loss: 0.2020 Acc: 0.9179\n",
      "Epoch 036 | Train Loss: 0.1446 Acc: 0.9422 | Val Loss: 0.1854 Acc: 0.9239\n",
      "Epoch 037 | Train Loss: 0.1493 Acc: 0.9419 | Val Loss: 0.1777 Acc: 0.9269\n",
      "Epoch 038 | Train Loss: 0.1395 Acc: 0.9428 | Val Loss: 0.1796 Acc: 0.9366\n",
      "Epoch 039 | Train Loss: 0.1399 Acc: 0.9470 | Val Loss: 0.2092 Acc: 0.9233\n",
      "Epoch 040 | Train Loss: 0.1214 Acc: 0.9530 | Val Loss: 0.2216 Acc: 0.9124\n",
      "Epoch 041 | Train Loss: 0.1178 Acc: 0.9576 | Val Loss: 0.1850 Acc: 0.9257\n",
      "Epoch 042 | Train Loss: 0.1117 Acc: 0.9558 | Val Loss: 0.1646 Acc: 0.9432\n",
      "Epoch 043 | Train Loss: 0.1139 Acc: 0.9592 | Val Loss: 0.1727 Acc: 0.9384\n",
      "Epoch 044 | Train Loss: 0.1111 Acc: 0.9555 | Val Loss: 0.1676 Acc: 0.9402\n",
      "Epoch 045 | Train Loss: 0.0984 Acc: 0.9663 | Val Loss: 0.1933 Acc: 0.9324\n",
      "Epoch 046 | Train Loss: 0.1044 Acc: 0.9603 | Val Loss: 0.1843 Acc: 0.9384\n",
      "Epoch 047 | Train Loss: 0.0914 Acc: 0.9659 | Val Loss: 0.1741 Acc: 0.9384\n",
      "Epoch 048 | Train Loss: 0.0915 Acc: 0.9662 | Val Loss: 0.1603 Acc: 0.9438\n",
      "Epoch 049 | Train Loss: 0.0837 Acc: 0.9680 | Val Loss: 0.1929 Acc: 0.9414\n",
      "Epoch 050 | Train Loss: 0.0907 Acc: 0.9686 | Val Loss: 0.1753 Acc: 0.9402\n",
      "Epoch 051 | Train Loss: 0.0814 Acc: 0.9697 | Val Loss: 0.1847 Acc: 0.9330\n",
      "Epoch 052 | Train Loss: 0.0792 Acc: 0.9690 | Val Loss: 0.1752 Acc: 0.9396\n",
      "Epoch 053 | Train Loss: 0.0878 Acc: 0.9683 | Val Loss: 0.1738 Acc: 0.9450\n",
      "Epoch 054 | Train Loss: 0.0667 Acc: 0.9774 | Val Loss: 0.1573 Acc: 0.9523\n",
      "Epoch 055 | Train Loss: 0.0770 Acc: 0.9722 | Val Loss: 0.1672 Acc: 0.9463\n",
      "Epoch 056 | Train Loss: 0.0750 Acc: 0.9719 | Val Loss: 0.1645 Acc: 0.9438\n",
      "Epoch 057 | Train Loss: 0.0702 Acc: 0.9718 | Val Loss: 0.1725 Acc: 0.9463\n",
      "Epoch 058 | Train Loss: 0.0702 Acc: 0.9749 | Val Loss: 0.1560 Acc: 0.9450\n",
      "Epoch 059 | Train Loss: 0.0760 Acc: 0.9719 | Val Loss: 0.1485 Acc: 0.9505\n",
      "Epoch 060 | Train Loss: 0.0690 Acc: 0.9749 | Val Loss: 0.1715 Acc: 0.9408\n",
      "Epoch 001 | Train Loss: 0.6801 Acc: 0.5766 | Val Loss: 0.6711 Acc: 0.5882\n",
      "Epoch 002 | Train Loss: 0.6640 Acc: 0.6071 | Val Loss: 0.6635 Acc: 0.6063\n",
      "Epoch 003 | Train Loss: 0.6446 Acc: 0.6391 | Val Loss: 0.6401 Acc: 0.6461\n",
      "Epoch 004 | Train Loss: 0.6079 Acc: 0.6831 | Val Loss: 0.6607 Acc: 0.6709\n",
      "Epoch 005 | Train Loss: 0.5786 Acc: 0.7100 | Val Loss: 0.5857 Acc: 0.7059\n",
      "Epoch 006 | Train Loss: 0.5506 Acc: 0.7332 | Val Loss: 0.5511 Acc: 0.7216\n",
      "Epoch 007 | Train Loss: 0.5197 Acc: 0.7501 | Val Loss: 0.5126 Acc: 0.7403\n",
      "Epoch 008 | Train Loss: 0.4968 Acc: 0.7685 | Val Loss: 0.4984 Acc: 0.7548\n",
      "Epoch 009 | Train Loss: 0.4731 Acc: 0.7797 | Val Loss: 0.4753 Acc: 0.7645\n",
      "Epoch 010 | Train Loss: 0.4413 Acc: 0.7960 | Val Loss: 0.4320 Acc: 0.7959\n",
      "Epoch 011 | Train Loss: 0.4189 Acc: 0.8099 | Val Loss: 0.4068 Acc: 0.8116\n",
      "Epoch 012 | Train Loss: 0.4029 Acc: 0.8188 | Val Loss: 0.4035 Acc: 0.8074\n",
      "Epoch 013 | Train Loss: 0.3949 Acc: 0.8252 | Val Loss: 0.4342 Acc: 0.7899\n",
      "Epoch 014 | Train Loss: 0.3712 Acc: 0.8369 | Val Loss: 0.3602 Acc: 0.8412\n",
      "Epoch 015 | Train Loss: 0.3573 Acc: 0.8442 | Val Loss: 0.3482 Acc: 0.8430\n",
      "Epoch 016 | Train Loss: 0.3313 Acc: 0.8538 | Val Loss: 0.3591 Acc: 0.8400\n",
      "Epoch 017 | Train Loss: 0.3166 Acc: 0.8650 | Val Loss: 0.3119 Acc: 0.8599\n",
      "Epoch 018 | Train Loss: 0.2985 Acc: 0.8789 | Val Loss: 0.2952 Acc: 0.8659\n",
      "Epoch 019 | Train Loss: 0.2774 Acc: 0.8846 | Val Loss: 0.2977 Acc: 0.8629\n",
      "Epoch 020 | Train Loss: 0.2635 Acc: 0.8880 | Val Loss: 0.3204 Acc: 0.8623\n",
      "Epoch 021 | Train Loss: 0.2573 Acc: 0.8916 | Val Loss: 0.2466 Acc: 0.8979\n",
      "Epoch 022 | Train Loss: 0.2343 Acc: 0.9065 | Val Loss: 0.2637 Acc: 0.8895\n",
      "Epoch 023 | Train Loss: 0.2343 Acc: 0.9025 | Val Loss: 0.2250 Acc: 0.9076\n",
      "Epoch 024 | Train Loss: 0.2143 Acc: 0.9117 | Val Loss: 0.2423 Acc: 0.8961\n",
      "Epoch 025 | Train Loss: 0.2168 Acc: 0.9130 | Val Loss: 0.2221 Acc: 0.9046\n",
      "Epoch 026 | Train Loss: 0.2034 Acc: 0.9183 | Val Loss: 0.2130 Acc: 0.9118\n",
      "Epoch 027 | Train Loss: 0.1902 Acc: 0.9225 | Val Loss: 0.2197 Acc: 0.9143\n",
      "Epoch 028 | Train Loss: 0.1798 Acc: 0.9277 | Val Loss: 0.1945 Acc: 0.9191\n",
      "Epoch 029 | Train Loss: 0.1703 Acc: 0.9346 | Val Loss: 0.2246 Acc: 0.9118\n",
      "Epoch 030 | Train Loss: 0.1688 Acc: 0.9363 | Val Loss: 0.1894 Acc: 0.9203\n",
      "Epoch 031 | Train Loss: 0.1573 Acc: 0.9392 | Val Loss: 0.1997 Acc: 0.9215\n",
      "Epoch 032 | Train Loss: 0.1588 Acc: 0.9373 | Val Loss: 0.2155 Acc: 0.9143\n",
      "Epoch 033 | Train Loss: 0.1478 Acc: 0.9435 | Val Loss: 0.1740 Acc: 0.9330\n",
      "Epoch 034 | Train Loss: 0.1547 Acc: 0.9425 | Val Loss: 0.1811 Acc: 0.9269\n",
      "Epoch 035 | Train Loss: 0.1416 Acc: 0.9453 | Val Loss: 0.1920 Acc: 0.9269\n",
      "Epoch 036 | Train Loss: 0.1278 Acc: 0.9514 | Val Loss: 0.1528 Acc: 0.9414\n",
      "Epoch 037 | Train Loss: 0.1207 Acc: 0.9552 | Val Loss: 0.1549 Acc: 0.9420\n",
      "Epoch 038 | Train Loss: 0.1222 Acc: 0.9529 | Val Loss: 0.1793 Acc: 0.9209\n",
      "Epoch 039 | Train Loss: 0.1291 Acc: 0.9487 | Val Loss: 0.1811 Acc: 0.9275\n",
      "Epoch 040 | Train Loss: 0.1216 Acc: 0.9524 | Val Loss: 0.1741 Acc: 0.9354\n",
      "Epoch 041 | Train Loss: 0.1241 Acc: 0.9511 | Val Loss: 0.1426 Acc: 0.9463\n",
      "Epoch 042 | Train Loss: 0.1183 Acc: 0.9571 | Val Loss: 0.1651 Acc: 0.9330\n",
      "Epoch 043 | Train Loss: 0.1014 Acc: 0.9597 | Val Loss: 0.1814 Acc: 0.9336\n",
      "Epoch 044 | Train Loss: 0.0997 Acc: 0.9656 | Val Loss: 0.1793 Acc: 0.9336\n",
      "Epoch 045 | Train Loss: 0.1106 Acc: 0.9564 | Val Loss: 0.1829 Acc: 0.9312\n",
      "Epoch 046 | Train Loss: 0.0967 Acc: 0.9639 | Val Loss: 0.1813 Acc: 0.9354\n",
      "Epoch 047 | Train Loss: 0.1001 Acc: 0.9650 | Val Loss: 0.1667 Acc: 0.9402\n",
      "Epoch 048 | Train Loss: 0.1019 Acc: 0.9623 | Val Loss: 0.1481 Acc: 0.9420\n",
      "Epoch 049 | Train Loss: 0.0885 Acc: 0.9671 | Val Loss: 0.1355 Acc: 0.9493\n",
      "Epoch 050 | Train Loss: 0.1006 Acc: 0.9612 | Val Loss: 0.1831 Acc: 0.9330\n",
      "Epoch 051 | Train Loss: 0.0884 Acc: 0.9674 | Val Loss: 0.1428 Acc: 0.9450\n",
      "Epoch 052 | Train Loss: 0.0878 Acc: 0.9666 | Val Loss: 0.1548 Acc: 0.9432\n",
      "Epoch 053 | Train Loss: 0.0849 Acc: 0.9697 | Val Loss: 0.1604 Acc: 0.9390\n",
      "Epoch 054 | Train Loss: 0.0907 Acc: 0.9656 | Val Loss: 0.1712 Acc: 0.9390\n",
      "Epoch 055 | Train Loss: 0.0769 Acc: 0.9715 | Val Loss: 0.1574 Acc: 0.9402\n",
      "Epoch 056 | Train Loss: 0.0792 Acc: 0.9709 | Val Loss: 0.1358 Acc: 0.9571\n",
      "Epoch 057 | Train Loss: 0.0861 Acc: 0.9687 | Val Loss: 0.1856 Acc: 0.9390\n",
      "Epoch 058 | Train Loss: 0.0872 Acc: 0.9669 | Val Loss: 0.1460 Acc: 0.9444\n",
      "Epoch 059 | Train Loss: 0.0816 Acc: 0.9710 | Val Loss: 0.1769 Acc: 0.9293\n",
      "Early stopping triggered.\n",
      "Epoch 001 | Train Loss: 0.6796 Acc: 0.5824 | Val Loss: 0.6743 Acc: 0.5930\n",
      "Epoch 002 | Train Loss: 0.6746 Acc: 0.5940 | Val Loss: 0.6865 Acc: 0.5586\n",
      "Epoch 003 | Train Loss: 0.6813 Acc: 0.5747 | Val Loss: 0.6747 Acc: 0.5900\n",
      "Epoch 004 | Train Loss: 0.6716 Acc: 0.5972 | Val Loss: 0.6835 Acc: 0.5550\n",
      "Epoch 005 | Train Loss: 0.6723 Acc: 0.5993 | Val Loss: 0.6709 Acc: 0.5876\n",
      "Epoch 006 | Train Loss: 0.6627 Acc: 0.6080 | Val Loss: 0.6573 Acc: 0.6123\n",
      "Epoch 007 | Train Loss: 0.6359 Acc: 0.6385 | Val Loss: 0.6419 Acc: 0.6479\n",
      "Epoch 008 | Train Loss: 0.6018 Acc: 0.6924 | Val Loss: 0.6058 Acc: 0.7011\n",
      "Epoch 009 | Train Loss: 0.5800 Acc: 0.7110 | Val Loss: 0.5644 Acc: 0.7101\n",
      "Epoch 010 | Train Loss: 0.5444 Acc: 0.7356 | Val Loss: 0.5448 Acc: 0.7252\n",
      "Epoch 011 | Train Loss: 0.5290 Acc: 0.7468 | Val Loss: 0.5218 Acc: 0.7379\n",
      "Epoch 012 | Train Loss: 0.5132 Acc: 0.7552 | Val Loss: 0.5000 Acc: 0.7524\n",
      "Epoch 013 | Train Loss: 0.4921 Acc: 0.7696 | Val Loss: 0.4868 Acc: 0.7699\n",
      "Epoch 014 | Train Loss: 0.4689 Acc: 0.7839 | Val Loss: 0.4528 Acc: 0.7814\n",
      "Epoch 015 | Train Loss: 0.4521 Acc: 0.7860 | Val Loss: 0.4654 Acc: 0.7911\n",
      "Epoch 016 | Train Loss: 0.4380 Acc: 0.8004 | Val Loss: 0.4246 Acc: 0.7995\n",
      "Epoch 017 | Train Loss: 0.4125 Acc: 0.8111 | Val Loss: 0.4014 Acc: 0.8182\n",
      "Epoch 018 | Train Loss: 0.3907 Acc: 0.8208 | Val Loss: 0.3961 Acc: 0.8152\n",
      "Epoch 019 | Train Loss: 0.3654 Acc: 0.8372 | Val Loss: 0.3837 Acc: 0.8333\n",
      "Epoch 020 | Train Loss: 0.3594 Acc: 0.8418 | Val Loss: 0.3539 Acc: 0.8376\n",
      "Epoch 021 | Train Loss: 0.3309 Acc: 0.8593 | Val Loss: 0.3782 Acc: 0.8382\n",
      "Epoch 022 | Train Loss: 0.3363 Acc: 0.8547 | Val Loss: 0.3444 Acc: 0.8418\n",
      "Epoch 023 | Train Loss: 0.3065 Acc: 0.8721 | Val Loss: 0.3917 Acc: 0.8194\n",
      "Epoch 024 | Train Loss: 0.3034 Acc: 0.8754 | Val Loss: 0.3078 Acc: 0.8665\n",
      "Epoch 025 | Train Loss: 0.2722 Acc: 0.8913 | Val Loss: 0.2561 Acc: 0.8937\n",
      "Epoch 026 | Train Loss: 0.2619 Acc: 0.8945 | Val Loss: 0.2712 Acc: 0.8829\n",
      "Epoch 027 | Train Loss: 0.2391 Acc: 0.9020 | Val Loss: 0.2636 Acc: 0.8829\n",
      "Epoch 028 | Train Loss: 0.2303 Acc: 0.9099 | Val Loss: 0.2602 Acc: 0.8835\n",
      "Epoch 029 | Train Loss: 0.2225 Acc: 0.9114 | Val Loss: 0.2982 Acc: 0.8732\n",
      "Epoch 030 | Train Loss: 0.2220 Acc: 0.9150 | Val Loss: 0.2664 Acc: 0.8835\n",
      "Epoch 031 | Train Loss: 0.2051 Acc: 0.9195 | Val Loss: 0.2624 Acc: 0.8949\n",
      "Epoch 032 | Train Loss: 0.2040 Acc: 0.9219 | Val Loss: 0.2356 Acc: 0.9070\n",
      "Epoch 033 | Train Loss: 0.1926 Acc: 0.9266 | Val Loss: 0.2316 Acc: 0.9076\n",
      "Epoch 034 | Train Loss: 0.1753 Acc: 0.9340 | Val Loss: 0.2048 Acc: 0.9149\n",
      "Epoch 035 | Train Loss: 0.1732 Acc: 0.9349 | Val Loss: 0.2697 Acc: 0.8822\n",
      "Epoch 036 | Train Loss: 0.1942 Acc: 0.9253 | Val Loss: 0.2033 Acc: 0.9155\n",
      "Epoch 037 | Train Loss: 0.1720 Acc: 0.9328 | Val Loss: 0.2167 Acc: 0.9022\n",
      "Epoch 038 | Train Loss: 0.1596 Acc: 0.9387 | Val Loss: 0.2234 Acc: 0.9106\n",
      "Epoch 039 | Train Loss: 0.1527 Acc: 0.9387 | Val Loss: 0.1935 Acc: 0.9239\n",
      "Epoch 040 | Train Loss: 0.1410 Acc: 0.9481 | Val Loss: 0.1953 Acc: 0.9173\n",
      "Epoch 041 | Train Loss: 0.1444 Acc: 0.9493 | Val Loss: 0.1967 Acc: 0.9221\n",
      "Epoch 042 | Train Loss: 0.1558 Acc: 0.9410 | Val Loss: 0.2083 Acc: 0.9173\n",
      "Epoch 043 | Train Loss: 0.1291 Acc: 0.9532 | Val Loss: 0.1983 Acc: 0.9239\n",
      "Epoch 044 | Train Loss: 0.1226 Acc: 0.9544 | Val Loss: 0.2078 Acc: 0.9197\n",
      "Epoch 045 | Train Loss: 0.1285 Acc: 0.9518 | Val Loss: 0.1701 Acc: 0.9300\n",
      "Epoch 046 | Train Loss: 0.1211 Acc: 0.9538 | Val Loss: 0.1738 Acc: 0.9366\n",
      "Epoch 047 | Train Loss: 0.1102 Acc: 0.9598 | Val Loss: 0.1625 Acc: 0.9306\n",
      "Epoch 048 | Train Loss: 0.1158 Acc: 0.9573 | Val Loss: 0.1677 Acc: 0.9330\n",
      "Epoch 049 | Train Loss: 0.1046 Acc: 0.9635 | Val Loss: 0.1768 Acc: 0.9342\n",
      "Epoch 050 | Train Loss: 0.1122 Acc: 0.9565 | Val Loss: 0.1794 Acc: 0.9300\n",
      "Epoch 051 | Train Loss: 0.1078 Acc: 0.9582 | Val Loss: 0.1610 Acc: 0.9372\n",
      "Epoch 052 | Train Loss: 0.0979 Acc: 0.9627 | Val Loss: 0.2098 Acc: 0.9378\n",
      "Epoch 053 | Train Loss: 0.1029 Acc: 0.9618 | Val Loss: 0.2461 Acc: 0.9179\n",
      "Epoch 054 | Train Loss: 0.0922 Acc: 0.9680 | Val Loss: 0.1869 Acc: 0.9293\n",
      "Epoch 055 | Train Loss: 0.0915 Acc: 0.9687 | Val Loss: 0.1845 Acc: 0.9348\n",
      "Epoch 056 | Train Loss: 0.0861 Acc: 0.9683 | Val Loss: 0.2009 Acc: 0.9324\n",
      "Epoch 057 | Train Loss: 0.0962 Acc: 0.9650 | Val Loss: 0.2044 Acc: 0.9251\n",
      "Epoch 058 | Train Loss: 0.0910 Acc: 0.9665 | Val Loss: 0.1727 Acc: 0.9324\n",
      "Epoch 059 | Train Loss: 0.0991 Acc: 0.9629 | Val Loss: 0.1624 Acc: 0.9336\n",
      "Epoch 060 | Train Loss: 0.0901 Acc: 0.9668 | Val Loss: 0.1581 Acc: 0.9438\n",
      "Epoch 001 | Train Loss: 0.6771 Acc: 0.5830 | Val Loss: 0.6860 Acc: 0.5707\n",
      "Epoch 002 | Train Loss: 0.6699 Acc: 0.5988 | Val Loss: 0.6657 Acc: 0.6033\n",
      "Epoch 003 | Train Loss: 0.6640 Acc: 0.6064 | Val Loss: 0.6620 Acc: 0.6033\n",
      "Epoch 004 | Train Loss: 0.6509 Acc: 0.6234 | Val Loss: 0.6246 Acc: 0.6685\n",
      "Epoch 005 | Train Loss: 0.6077 Acc: 0.6795 | Val Loss: 0.5947 Acc: 0.7029\n",
      "Epoch 006 | Train Loss: 0.5740 Acc: 0.7115 | Val Loss: 0.5659 Acc: 0.7138\n",
      "Epoch 007 | Train Loss: 0.5571 Acc: 0.7213 | Val Loss: 0.5510 Acc: 0.7168\n",
      "Epoch 008 | Train Loss: 0.5493 Acc: 0.7306 | Val Loss: 0.5627 Acc: 0.7186\n",
      "Epoch 009 | Train Loss: 0.5309 Acc: 0.7457 | Val Loss: 0.5207 Acc: 0.7409\n",
      "Epoch 010 | Train Loss: 0.4961 Acc: 0.7595 | Val Loss: 0.5120 Acc: 0.7367\n",
      "Epoch 011 | Train Loss: 0.4877 Acc: 0.7691 | Val Loss: 0.4938 Acc: 0.7488\n",
      "Epoch 012 | Train Loss: 0.4683 Acc: 0.7765 | Val Loss: 0.4715 Acc: 0.7669\n",
      "Epoch 013 | Train Loss: 0.4431 Acc: 0.7912 | Val Loss: 0.4559 Acc: 0.7723\n",
      "Epoch 014 | Train Loss: 0.4270 Acc: 0.7995 | Val Loss: 0.4364 Acc: 0.7850\n",
      "Epoch 015 | Train Loss: 0.4066 Acc: 0.8078 | Val Loss: 0.4215 Acc: 0.8001\n",
      "Epoch 016 | Train Loss: 0.3843 Acc: 0.8232 | Val Loss: 0.4100 Acc: 0.8200\n",
      "Epoch 017 | Train Loss: 0.3687 Acc: 0.8342 | Val Loss: 0.4022 Acc: 0.7983\n",
      "Epoch 018 | Train Loss: 0.3579 Acc: 0.8425 | Val Loss: 0.3283 Acc: 0.8502\n",
      "Epoch 019 | Train Loss: 0.3296 Acc: 0.8534 | Val Loss: 0.3353 Acc: 0.8490\n",
      "Epoch 020 | Train Loss: 0.3198 Acc: 0.8602 | Val Loss: 0.3352 Acc: 0.8466\n",
      "Epoch 021 | Train Loss: 0.3017 Acc: 0.8692 | Val Loss: 0.3403 Acc: 0.8539\n",
      "Epoch 022 | Train Loss: 0.2988 Acc: 0.8801 | Val Loss: 0.3024 Acc: 0.8696\n",
      "Epoch 023 | Train Loss: 0.2741 Acc: 0.8816 | Val Loss: 0.2864 Acc: 0.8750\n",
      "Epoch 024 | Train Loss: 0.2524 Acc: 0.8898 | Val Loss: 0.3178 Acc: 0.8696\n",
      "Epoch 025 | Train Loss: 0.2541 Acc: 0.8954 | Val Loss: 0.2739 Acc: 0.8853\n",
      "Epoch 026 | Train Loss: 0.2331 Acc: 0.9044 | Val Loss: 0.2782 Acc: 0.8774\n",
      "Epoch 027 | Train Loss: 0.2353 Acc: 0.9076 | Val Loss: 0.2595 Acc: 0.8949\n",
      "Epoch 028 | Train Loss: 0.2262 Acc: 0.9077 | Val Loss: 0.2430 Acc: 0.9022\n",
      "Epoch 029 | Train Loss: 0.2160 Acc: 0.9108 | Val Loss: 0.2468 Acc: 0.8979\n",
      "Epoch 030 | Train Loss: 0.2074 Acc: 0.9188 | Val Loss: 0.2502 Acc: 0.8943\n",
      "Epoch 031 | Train Loss: 0.1926 Acc: 0.9225 | Val Loss: 0.2314 Acc: 0.9118\n",
      "Epoch 032 | Train Loss: 0.1869 Acc: 0.9251 | Val Loss: 0.2540 Acc: 0.8901\n",
      "Epoch 033 | Train Loss: 0.1729 Acc: 0.9340 | Val Loss: 0.2300 Acc: 0.9112\n",
      "Epoch 034 | Train Loss: 0.1828 Acc: 0.9265 | Val Loss: 0.2237 Acc: 0.9118\n",
      "Epoch 035 | Train Loss: 0.1658 Acc: 0.9360 | Val Loss: 0.2384 Acc: 0.9100\n",
      "Epoch 036 | Train Loss: 0.1611 Acc: 0.9319 | Val Loss: 0.2433 Acc: 0.9088\n",
      "Epoch 037 | Train Loss: 0.1483 Acc: 0.9455 | Val Loss: 0.2054 Acc: 0.9227\n",
      "Epoch 038 | Train Loss: 0.1541 Acc: 0.9407 | Val Loss: 0.2244 Acc: 0.9179\n",
      "Epoch 039 | Train Loss: 0.1448 Acc: 0.9428 | Val Loss: 0.2481 Acc: 0.9136\n",
      "Epoch 040 | Train Loss: 0.1420 Acc: 0.9429 | Val Loss: 0.2211 Acc: 0.9124\n",
      "Epoch 041 | Train Loss: 0.1427 Acc: 0.9423 | Val Loss: 0.2171 Acc: 0.9185\n",
      "Epoch 042 | Train Loss: 0.1400 Acc: 0.9472 | Val Loss: 0.2168 Acc: 0.9191\n",
      "Epoch 043 | Train Loss: 0.1342 Acc: 0.9494 | Val Loss: 0.2078 Acc: 0.9197\n",
      "Epoch 044 | Train Loss: 0.1374 Acc: 0.9467 | Val Loss: 0.2053 Acc: 0.9149\n",
      "Epoch 045 | Train Loss: 0.1264 Acc: 0.9543 | Val Loss: 0.2325 Acc: 0.9136\n",
      "Epoch 046 | Train Loss: 0.1285 Acc: 0.9535 | Val Loss: 0.2041 Acc: 0.9245\n",
      "Epoch 047 | Train Loss: 0.1220 Acc: 0.9544 | Val Loss: 0.1980 Acc: 0.9263\n",
      "Epoch 048 | Train Loss: 0.1245 Acc: 0.9511 | Val Loss: 0.1952 Acc: 0.9281\n",
      "Epoch 049 | Train Loss: 0.1190 Acc: 0.9524 | Val Loss: 0.2381 Acc: 0.9130\n",
      "Epoch 050 | Train Loss: 0.1065 Acc: 0.9610 | Val Loss: 0.1810 Acc: 0.9342\n",
      "Epoch 051 | Train Loss: 0.1050 Acc: 0.9610 | Val Loss: 0.2207 Acc: 0.9215\n",
      "Epoch 052 | Train Loss: 0.1085 Acc: 0.9579 | Val Loss: 0.1872 Acc: 0.9348\n",
      "Epoch 053 | Train Loss: 0.0996 Acc: 0.9642 | Val Loss: 0.1945 Acc: 0.9287\n",
      "Epoch 054 | Train Loss: 0.0965 Acc: 0.9641 | Val Loss: 0.1961 Acc: 0.9318\n",
      "Epoch 055 | Train Loss: 0.1058 Acc: 0.9621 | Val Loss: 0.2288 Acc: 0.9221\n",
      "Epoch 056 | Train Loss: 0.1028 Acc: 0.9616 | Val Loss: 0.1784 Acc: 0.9336\n",
      "Epoch 057 | Train Loss: 0.0953 Acc: 0.9645 | Val Loss: 0.1847 Acc: 0.9336\n",
      "Epoch 058 | Train Loss: 0.0991 Acc: 0.9665 | Val Loss: 0.1938 Acc: 0.9342\n",
      "Epoch 059 | Train Loss: 0.0838 Acc: 0.9713 | Val Loss: 0.1937 Acc: 0.9378\n",
      "Epoch 060 | Train Loss: 0.0987 Acc: 0.9647 | Val Loss: 0.1869 Acc: 0.9342\n",
      "Epoch 001 | Train Loss: 0.6811 Acc: 0.5798 | Val Loss: 0.6786 Acc: 0.5870\n",
      "Epoch 002 | Train Loss: 0.6729 Acc: 0.5957 | Val Loss: 0.6736 Acc: 0.5894\n",
      "Epoch 003 | Train Loss: 0.6704 Acc: 0.5957 | Val Loss: 0.6712 Acc: 0.5912\n",
      "Epoch 004 | Train Loss: 0.6658 Acc: 0.6011 | Val Loss: 0.6674 Acc: 0.5948\n",
      "Epoch 005 | Train Loss: 0.6447 Acc: 0.6287 | Val Loss: 0.6294 Acc: 0.6461\n",
      "Epoch 006 | Train Loss: 0.6109 Acc: 0.6804 | Val Loss: 0.5953 Acc: 0.6860\n",
      "Epoch 007 | Train Loss: 0.5670 Acc: 0.7199 | Val Loss: 0.5706 Acc: 0.7017\n",
      "Epoch 008 | Train Loss: 0.5403 Acc: 0.7373 | Val Loss: 0.5441 Acc: 0.7222\n",
      "Epoch 009 | Train Loss: 0.5111 Acc: 0.7574 | Val Loss: 0.5028 Acc: 0.7560\n",
      "Epoch 010 | Train Loss: 0.4874 Acc: 0.7667 | Val Loss: 0.4543 Acc: 0.7886\n",
      "Epoch 011 | Train Loss: 0.4464 Acc: 0.7944 | Val Loss: 0.4405 Acc: 0.7880\n",
      "Epoch 012 | Train Loss: 0.4214 Acc: 0.8024 | Val Loss: 0.4107 Acc: 0.8092\n",
      "Epoch 013 | Train Loss: 0.3985 Acc: 0.8178 | Val Loss: 0.3907 Acc: 0.8261\n",
      "Epoch 014 | Train Loss: 0.3767 Acc: 0.8341 | Val Loss: 0.3659 Acc: 0.8315\n",
      "Epoch 015 | Train Loss: 0.3393 Acc: 0.8540 | Val Loss: 0.3624 Acc: 0.8364\n",
      "Epoch 016 | Train Loss: 0.3112 Acc: 0.8670 | Val Loss: 0.3486 Acc: 0.8424\n",
      "Epoch 017 | Train Loss: 0.2972 Acc: 0.8759 | Val Loss: 0.3197 Acc: 0.8551\n",
      "Epoch 018 | Train Loss: 0.2696 Acc: 0.8905 | Val Loss: 0.3087 Acc: 0.8641\n",
      "Epoch 019 | Train Loss: 0.2700 Acc: 0.8875 | Val Loss: 0.2854 Acc: 0.8804\n",
      "Epoch 020 | Train Loss: 0.2412 Acc: 0.9006 | Val Loss: 0.2810 Acc: 0.8816\n",
      "Epoch 021 | Train Loss: 0.2268 Acc: 0.9085 | Val Loss: 0.2464 Acc: 0.8913\n",
      "Epoch 022 | Train Loss: 0.2048 Acc: 0.9189 | Val Loss: 0.2482 Acc: 0.8979\n",
      "Epoch 023 | Train Loss: 0.2020 Acc: 0.9204 | Val Loss: 0.2544 Acc: 0.8992\n",
      "Epoch 024 | Train Loss: 0.1912 Acc: 0.9268 | Val Loss: 0.2049 Acc: 0.9221\n",
      "Epoch 025 | Train Loss: 0.1597 Acc: 0.9407 | Val Loss: 0.2571 Acc: 0.8943\n",
      "Epoch 026 | Train Loss: 0.1759 Acc: 0.9316 | Val Loss: 0.2188 Acc: 0.9106\n",
      "Epoch 027 | Train Loss: 0.1693 Acc: 0.9334 | Val Loss: 0.2215 Acc: 0.9191\n",
      "Epoch 028 | Train Loss: 0.1498 Acc: 0.9441 | Val Loss: 0.1936 Acc: 0.9306\n",
      "Epoch 029 | Train Loss: 0.1509 Acc: 0.9426 | Val Loss: 0.1988 Acc: 0.9257\n",
      "Epoch 030 | Train Loss: 0.1403 Acc: 0.9479 | Val Loss: 0.2128 Acc: 0.9143\n",
      "Epoch 031 | Train Loss: 0.1249 Acc: 0.9536 | Val Loss: 0.2016 Acc: 0.9191\n",
      "Epoch 032 | Train Loss: 0.1276 Acc: 0.9530 | Val Loss: 0.1897 Acc: 0.9203\n",
      "Epoch 033 | Train Loss: 0.1179 Acc: 0.9550 | Val Loss: 0.1935 Acc: 0.9233\n",
      "Epoch 034 | Train Loss: 0.1217 Acc: 0.9533 | Val Loss: 0.1736 Acc: 0.9318\n",
      "Epoch 035 | Train Loss: 0.1041 Acc: 0.9618 | Val Loss: 0.1667 Acc: 0.9336\n",
      "Epoch 036 | Train Loss: 0.1055 Acc: 0.9600 | Val Loss: 0.2059 Acc: 0.9161\n",
      "Epoch 037 | Train Loss: 0.1029 Acc: 0.9616 | Val Loss: 0.1842 Acc: 0.9287\n",
      "Epoch 038 | Train Loss: 0.0887 Acc: 0.9671 | Val Loss: 0.1826 Acc: 0.9324\n",
      "Epoch 039 | Train Loss: 0.0810 Acc: 0.9693 | Val Loss: 0.1896 Acc: 0.9275\n",
      "Epoch 040 | Train Loss: 0.0858 Acc: 0.9677 | Val Loss: 0.1668 Acc: 0.9366\n",
      "Epoch 041 | Train Loss: 0.0798 Acc: 0.9689 | Val Loss: 0.1624 Acc: 0.9457\n",
      "Epoch 042 | Train Loss: 0.0737 Acc: 0.9712 | Val Loss: 0.2035 Acc: 0.9257\n",
      "Epoch 043 | Train Loss: 0.0775 Acc: 0.9728 | Val Loss: 0.1598 Acc: 0.9432\n",
      "Epoch 044 | Train Loss: 0.0809 Acc: 0.9695 | Val Loss: 0.1823 Acc: 0.9402\n",
      "Epoch 045 | Train Loss: 0.0813 Acc: 0.9706 | Val Loss: 0.1899 Acc: 0.9324\n",
      "Epoch 046 | Train Loss: 0.0728 Acc: 0.9725 | Val Loss: 0.1740 Acc: 0.9336\n",
      "Epoch 047 | Train Loss: 0.0715 Acc: 0.9733 | Val Loss: 0.1598 Acc: 0.9432\n",
      "Epoch 048 | Train Loss: 0.0671 Acc: 0.9780 | Val Loss: 0.1836 Acc: 0.9336\n",
      "Epoch 049 | Train Loss: 0.0618 Acc: 0.9787 | Val Loss: 0.2126 Acc: 0.9324\n",
      "Epoch 050 | Train Loss: 0.0678 Acc: 0.9742 | Val Loss: 0.1855 Acc: 0.9336\n",
      "Epoch 051 | Train Loss: 0.0665 Acc: 0.9751 | Val Loss: 0.1762 Acc: 0.9354\n",
      "Epoch 052 | Train Loss: 0.0631 Acc: 0.9778 | Val Loss: 0.2015 Acc: 0.9354\n",
      "Epoch 053 | Train Loss: 0.0559 Acc: 0.9789 | Val Loss: 0.1597 Acc: 0.9475\n",
      "Epoch 054 | Train Loss: 0.0531 Acc: 0.9816 | Val Loss: 0.1887 Acc: 0.9396\n",
      "Epoch 055 | Train Loss: 0.0686 Acc: 0.9740 | Val Loss: 0.1874 Acc: 0.9366\n",
      "Epoch 056 | Train Loss: 0.0604 Acc: 0.9817 | Val Loss: 0.1610 Acc: 0.9463\n",
      "Epoch 057 | Train Loss: 0.0662 Acc: 0.9758 | Val Loss: 0.1758 Acc: 0.9469\n",
      "Epoch 058 | Train Loss: 0.0587 Acc: 0.9781 | Val Loss: 0.1487 Acc: 0.9475\n",
      "Epoch 059 | Train Loss: 0.0455 Acc: 0.9834 | Val Loss: 0.1624 Acc: 0.9523\n",
      "Epoch 060 | Train Loss: 0.0593 Acc: 0.9784 | Val Loss: 0.1826 Acc: 0.9402\n",
      "Iteration 33/40 | Best Val Loss: 0.1122 | Iter Time: 224.11s | Total Time: 134.82 min\n",
      "Epoch 001 | Train Loss: 0.6821 Acc: 0.5763 | Val Loss: 0.6772 Acc: 0.5900\n",
      "Epoch 002 | Train Loss: 0.6714 Acc: 0.5946 | Val Loss: 0.6705 Acc: 0.5942\n",
      "Epoch 003 | Train Loss: 0.6484 Acc: 0.6301 | Val Loss: 0.6446 Acc: 0.6292\n",
      "Epoch 004 | Train Loss: 0.5998 Acc: 0.6938 | Val Loss: 0.5716 Acc: 0.7071\n",
      "Epoch 005 | Train Loss: 0.5570 Acc: 0.7254 | Val Loss: 0.5544 Acc: 0.7162\n",
      "Epoch 006 | Train Loss: 0.5442 Acc: 0.7346 | Val Loss: 0.5824 Acc: 0.7089\n",
      "Epoch 007 | Train Loss: 0.5189 Acc: 0.7521 | Val Loss: 0.5470 Acc: 0.7325\n",
      "Epoch 008 | Train Loss: 0.4929 Acc: 0.7687 | Val Loss: 0.5189 Acc: 0.7446\n",
      "Epoch 009 | Train Loss: 0.4655 Acc: 0.7903 | Val Loss: 0.4654 Acc: 0.7802\n",
      "Epoch 010 | Train Loss: 0.4370 Acc: 0.7998 | Val Loss: 0.4661 Acc: 0.7868\n",
      "Epoch 011 | Train Loss: 0.4220 Acc: 0.8117 | Val Loss: 0.4268 Acc: 0.7995\n",
      "Epoch 012 | Train Loss: 0.3876 Acc: 0.8242 | Val Loss: 0.4027 Acc: 0.8237\n",
      "Epoch 013 | Train Loss: 0.3714 Acc: 0.8313 | Val Loss: 0.3809 Acc: 0.8243\n",
      "Epoch 014 | Train Loss: 0.3401 Acc: 0.8523 | Val Loss: 0.3403 Acc: 0.8508\n",
      "Epoch 015 | Train Loss: 0.3148 Acc: 0.8628 | Val Loss: 0.3029 Acc: 0.8702\n",
      "Epoch 016 | Train Loss: 0.3039 Acc: 0.8683 | Val Loss: 0.3318 Acc: 0.8521\n",
      "Epoch 017 | Train Loss: 0.2697 Acc: 0.8868 | Val Loss: 0.3307 Acc: 0.8611\n",
      "Epoch 018 | Train Loss: 0.2690 Acc: 0.8890 | Val Loss: 0.2784 Acc: 0.8871\n",
      "Epoch 019 | Train Loss: 0.2499 Acc: 0.8951 | Val Loss: 0.2597 Acc: 0.8919\n",
      "Epoch 020 | Train Loss: 0.2372 Acc: 0.9017 | Val Loss: 0.2488 Acc: 0.9052\n",
      "Epoch 021 | Train Loss: 0.2191 Acc: 0.9105 | Val Loss: 0.3218 Acc: 0.8641\n",
      "Epoch 022 | Train Loss: 0.2127 Acc: 0.9118 | Val Loss: 0.2393 Acc: 0.9022\n",
      "Epoch 023 | Train Loss: 0.1985 Acc: 0.9219 | Val Loss: 0.2329 Acc: 0.9118\n",
      "Epoch 024 | Train Loss: 0.1943 Acc: 0.9244 | Val Loss: 0.2269 Acc: 0.9058\n",
      "Epoch 025 | Train Loss: 0.1784 Acc: 0.9289 | Val Loss: 0.2301 Acc: 0.9088\n",
      "Epoch 026 | Train Loss: 0.1720 Acc: 0.9336 | Val Loss: 0.2195 Acc: 0.9124\n",
      "Epoch 027 | Train Loss: 0.1693 Acc: 0.9330 | Val Loss: 0.2521 Acc: 0.8986\n",
      "Epoch 028 | Train Loss: 0.1542 Acc: 0.9420 | Val Loss: 0.2209 Acc: 0.9167\n",
      "Epoch 029 | Train Loss: 0.1502 Acc: 0.9432 | Val Loss: 0.2031 Acc: 0.9233\n",
      "Epoch 030 | Train Loss: 0.1426 Acc: 0.9473 | Val Loss: 0.2135 Acc: 0.9124\n",
      "Epoch 031 | Train Loss: 0.1386 Acc: 0.9493 | Val Loss: 0.2068 Acc: 0.9269\n",
      "Epoch 032 | Train Loss: 0.1322 Acc: 0.9499 | Val Loss: 0.1936 Acc: 0.9263\n",
      "Epoch 033 | Train Loss: 0.1237 Acc: 0.9547 | Val Loss: 0.2288 Acc: 0.9227\n",
      "Epoch 034 | Train Loss: 0.1223 Acc: 0.9526 | Val Loss: 0.2014 Acc: 0.9197\n",
      "Epoch 035 | Train Loss: 0.1187 Acc: 0.9511 | Val Loss: 0.1749 Acc: 0.9324\n",
      "Epoch 036 | Train Loss: 0.1128 Acc: 0.9585 | Val Loss: 0.1997 Acc: 0.9245\n",
      "Epoch 037 | Train Loss: 0.1146 Acc: 0.9573 | Val Loss: 0.2010 Acc: 0.9239\n",
      "Epoch 038 | Train Loss: 0.1126 Acc: 0.9576 | Val Loss: 0.1972 Acc: 0.9342\n",
      "Epoch 039 | Train Loss: 0.1185 Acc: 0.9546 | Val Loss: 0.1765 Acc: 0.9360\n",
      "Epoch 040 | Train Loss: 0.0860 Acc: 0.9657 | Val Loss: 0.2025 Acc: 0.9300\n",
      "Epoch 041 | Train Loss: 0.0906 Acc: 0.9666 | Val Loss: 0.1791 Acc: 0.9432\n",
      "Epoch 042 | Train Loss: 0.1175 Acc: 0.9570 | Val Loss: 0.1904 Acc: 0.9263\n",
      "Epoch 043 | Train Loss: 0.0893 Acc: 0.9683 | Val Loss: 0.2071 Acc: 0.9293\n",
      "Epoch 044 | Train Loss: 0.0969 Acc: 0.9647 | Val Loss: 0.1870 Acc: 0.9372\n",
      "Epoch 045 | Train Loss: 0.0810 Acc: 0.9712 | Val Loss: 0.1667 Acc: 0.9426\n",
      "Epoch 046 | Train Loss: 0.0831 Acc: 0.9680 | Val Loss: 0.1768 Acc: 0.9306\n",
      "Epoch 047 | Train Loss: 0.0955 Acc: 0.9636 | Val Loss: 0.1723 Acc: 0.9330\n",
      "Epoch 048 | Train Loss: 0.0873 Acc: 0.9681 | Val Loss: 0.1599 Acc: 0.9378\n",
      "Epoch 049 | Train Loss: 0.0704 Acc: 0.9763 | Val Loss: 0.1910 Acc: 0.9263\n",
      "Epoch 050 | Train Loss: 0.0715 Acc: 0.9725 | Val Loss: 0.1949 Acc: 0.9390\n",
      "Epoch 051 | Train Loss: 0.0888 Acc: 0.9672 | Val Loss: 0.1616 Acc: 0.9372\n",
      "Epoch 052 | Train Loss: 0.0751 Acc: 0.9718 | Val Loss: 0.1880 Acc: 0.9348\n",
      "Epoch 053 | Train Loss: 0.0766 Acc: 0.9716 | Val Loss: 0.1892 Acc: 0.9390\n",
      "Epoch 054 | Train Loss: 0.0775 Acc: 0.9713 | Val Loss: 0.1788 Acc: 0.9360\n",
      "Epoch 055 | Train Loss: 0.0814 Acc: 0.9693 | Val Loss: 0.1746 Acc: 0.9372\n",
      "Epoch 056 | Train Loss: 0.0705 Acc: 0.9749 | Val Loss: 0.1624 Acc: 0.9354\n",
      "Epoch 057 | Train Loss: 0.0692 Acc: 0.9754 | Val Loss: 0.1963 Acc: 0.9354\n",
      "Epoch 058 | Train Loss: 0.0789 Acc: 0.9703 | Val Loss: 0.1575 Acc: 0.9457\n",
      "Epoch 059 | Train Loss: 0.0632 Acc: 0.9772 | Val Loss: 0.1678 Acc: 0.9426\n",
      "Epoch 060 | Train Loss: 0.0613 Acc: 0.9774 | Val Loss: 0.2401 Acc: 0.9251\n",
      "Epoch 001 | Train Loss: 0.6798 Acc: 0.5792 | Val Loss: 0.6806 Acc: 0.5857\n",
      "Epoch 002 | Train Loss: 0.6750 Acc: 0.5895 | Val Loss: 0.6691 Acc: 0.5954\n",
      "Epoch 003 | Train Loss: 0.6396 Acc: 0.6426 | Val Loss: 0.6162 Acc: 0.6751\n",
      "Epoch 004 | Train Loss: 0.5885 Acc: 0.7068 | Val Loss: 0.5750 Acc: 0.7095\n",
      "Epoch 005 | Train Loss: 0.5560 Acc: 0.7267 | Val Loss: 0.5488 Acc: 0.7325\n",
      "Epoch 006 | Train Loss: 0.5359 Acc: 0.7365 | Val Loss: 0.5534 Acc: 0.7343\n",
      "Epoch 007 | Train Loss: 0.5147 Acc: 0.7521 | Val Loss: 0.5137 Acc: 0.7512\n",
      "Epoch 008 | Train Loss: 0.4905 Acc: 0.7655 | Val Loss: 0.4895 Acc: 0.7579\n",
      "Epoch 009 | Train Loss: 0.4623 Acc: 0.7806 | Val Loss: 0.4526 Acc: 0.7766\n",
      "Epoch 010 | Train Loss: 0.4362 Acc: 0.7954 | Val Loss: 0.4257 Acc: 0.7977\n",
      "Epoch 011 | Train Loss: 0.4182 Acc: 0.8075 | Val Loss: 0.4053 Acc: 0.8080\n",
      "Epoch 012 | Train Loss: 0.3804 Acc: 0.8323 | Val Loss: 0.3644 Acc: 0.8267\n",
      "Epoch 013 | Train Loss: 0.3647 Acc: 0.8389 | Val Loss: 0.3862 Acc: 0.8146\n",
      "Epoch 014 | Train Loss: 0.3283 Acc: 0.8537 | Val Loss: 0.3288 Acc: 0.8527\n",
      "Epoch 015 | Train Loss: 0.3129 Acc: 0.8649 | Val Loss: 0.3436 Acc: 0.8460\n",
      "Epoch 016 | Train Loss: 0.2969 Acc: 0.8759 | Val Loss: 0.2837 Acc: 0.8702\n",
      "Epoch 017 | Train Loss: 0.2651 Acc: 0.8905 | Val Loss: 0.2624 Acc: 0.8822\n",
      "Epoch 018 | Train Loss: 0.2601 Acc: 0.8951 | Val Loss: 0.2341 Acc: 0.8992\n",
      "Epoch 019 | Train Loss: 0.2313 Acc: 0.9090 | Val Loss: 0.2235 Acc: 0.9082\n",
      "Epoch 020 | Train Loss: 0.2187 Acc: 0.9129 | Val Loss: 0.2536 Acc: 0.8937\n",
      "Epoch 021 | Train Loss: 0.2151 Acc: 0.9170 | Val Loss: 0.2370 Acc: 0.9010\n",
      "Epoch 022 | Train Loss: 0.2072 Acc: 0.9157 | Val Loss: 0.2231 Acc: 0.9076\n",
      "Epoch 023 | Train Loss: 0.1938 Acc: 0.9256 | Val Loss: 0.2093 Acc: 0.9136\n",
      "Epoch 024 | Train Loss: 0.1824 Acc: 0.9292 | Val Loss: 0.2214 Acc: 0.9070\n",
      "Epoch 025 | Train Loss: 0.1663 Acc: 0.9385 | Val Loss: 0.1743 Acc: 0.9233\n",
      "Epoch 026 | Train Loss: 0.1625 Acc: 0.9370 | Val Loss: 0.1972 Acc: 0.9179\n",
      "Epoch 027 | Train Loss: 0.1536 Acc: 0.9435 | Val Loss: 0.1982 Acc: 0.9149\n",
      "Epoch 028 | Train Loss: 0.1443 Acc: 0.9452 | Val Loss: 0.1786 Acc: 0.9233\n",
      "Epoch 029 | Train Loss: 0.1421 Acc: 0.9461 | Val Loss: 0.1816 Acc: 0.9233\n",
      "Epoch 030 | Train Loss: 0.1346 Acc: 0.9469 | Val Loss: 0.1687 Acc: 0.9293\n",
      "Epoch 031 | Train Loss: 0.1230 Acc: 0.9533 | Val Loss: 0.2222 Acc: 0.9179\n",
      "Epoch 032 | Train Loss: 0.1241 Acc: 0.9520 | Val Loss: 0.1854 Acc: 0.9287\n",
      "Epoch 033 | Train Loss: 0.1141 Acc: 0.9576 | Val Loss: 0.1616 Acc: 0.9390\n",
      "Epoch 034 | Train Loss: 0.1175 Acc: 0.9546 | Val Loss: 0.2009 Acc: 0.9221\n",
      "Epoch 035 | Train Loss: 0.1092 Acc: 0.9570 | Val Loss: 0.1701 Acc: 0.9300\n",
      "Epoch 036 | Train Loss: 0.1137 Acc: 0.9582 | Val Loss: 0.1764 Acc: 0.9366\n",
      "Epoch 037 | Train Loss: 0.1026 Acc: 0.9624 | Val Loss: 0.1577 Acc: 0.9420\n",
      "Epoch 038 | Train Loss: 0.1067 Acc: 0.9606 | Val Loss: 0.1962 Acc: 0.9287\n",
      "Epoch 039 | Train Loss: 0.1008 Acc: 0.9615 | Val Loss: 0.1528 Acc: 0.9463\n",
      "Epoch 040 | Train Loss: 0.0947 Acc: 0.9615 | Val Loss: 0.1510 Acc: 0.9384\n",
      "Epoch 041 | Train Loss: 0.0993 Acc: 0.9653 | Val Loss: 0.1672 Acc: 0.9402\n",
      "Epoch 042 | Train Loss: 0.0887 Acc: 0.9672 | Val Loss: 0.1913 Acc: 0.9318\n",
      "Epoch 043 | Train Loss: 0.0866 Acc: 0.9683 | Val Loss: 0.1649 Acc: 0.9354\n",
      "Epoch 044 | Train Loss: 0.0872 Acc: 0.9671 | Val Loss: 0.1627 Acc: 0.9444\n",
      "Epoch 045 | Train Loss: 0.0756 Acc: 0.9728 | Val Loss: 0.1831 Acc: 0.9348\n",
      "Epoch 046 | Train Loss: 0.0779 Acc: 0.9712 | Val Loss: 0.1839 Acc: 0.9336\n",
      "Epoch 047 | Train Loss: 0.0748 Acc: 0.9718 | Val Loss: 0.1494 Acc: 0.9481\n",
      "Epoch 048 | Train Loss: 0.0696 Acc: 0.9727 | Val Loss: 0.1758 Acc: 0.9420\n",
      "Epoch 049 | Train Loss: 0.0759 Acc: 0.9698 | Val Loss: 0.1517 Acc: 0.9444\n",
      "Epoch 050 | Train Loss: 0.0777 Acc: 0.9713 | Val Loss: 0.1616 Acc: 0.9438\n",
      "Epoch 051 | Train Loss: 0.0730 Acc: 0.9743 | Val Loss: 0.1601 Acc: 0.9469\n",
      "Epoch 052 | Train Loss: 0.0707 Acc: 0.9736 | Val Loss: 0.1891 Acc: 0.9372\n",
      "Epoch 053 | Train Loss: 0.0594 Acc: 0.9795 | Val Loss: 0.1846 Acc: 0.9408\n",
      "Epoch 054 | Train Loss: 0.0699 Acc: 0.9721 | Val Loss: 0.1263 Acc: 0.9505\n",
      "Epoch 055 | Train Loss: 0.0611 Acc: 0.9781 | Val Loss: 0.1822 Acc: 0.9372\n",
      "Epoch 056 | Train Loss: 0.0649 Acc: 0.9772 | Val Loss: 0.1694 Acc: 0.9330\n",
      "Epoch 057 | Train Loss: 0.0609 Acc: 0.9802 | Val Loss: 0.1960 Acc: 0.9354\n",
      "Epoch 058 | Train Loss: 0.0670 Acc: 0.9739 | Val Loss: 0.1608 Acc: 0.9475\n",
      "Epoch 059 | Train Loss: 0.0607 Acc: 0.9781 | Val Loss: 0.1519 Acc: 0.9432\n",
      "Epoch 060 | Train Loss: 0.0607 Acc: 0.9799 | Val Loss: 0.1554 Acc: 0.9450\n",
      "Epoch 001 | Train Loss: 0.6810 Acc: 0.5709 | Val Loss: 0.6764 Acc: 0.5876\n",
      "Epoch 002 | Train Loss: 0.6738 Acc: 0.5946 | Val Loss: 0.6654 Acc: 0.5972\n",
      "Epoch 003 | Train Loss: 0.6394 Acc: 0.6431 | Val Loss: 0.6147 Acc: 0.6818\n",
      "Epoch 004 | Train Loss: 0.5899 Acc: 0.7030 | Val Loss: 0.5862 Acc: 0.6981\n",
      "Epoch 005 | Train Loss: 0.5572 Acc: 0.7235 | Val Loss: 0.5366 Acc: 0.7283\n",
      "Epoch 006 | Train Loss: 0.5282 Acc: 0.7445 | Val Loss: 0.5454 Acc: 0.7373\n",
      "Epoch 007 | Train Loss: 0.5076 Acc: 0.7623 | Val Loss: 0.4853 Acc: 0.7639\n",
      "Epoch 008 | Train Loss: 0.4844 Acc: 0.7743 | Val Loss: 0.4800 Acc: 0.7802\n",
      "Epoch 009 | Train Loss: 0.4733 Acc: 0.7797 | Val Loss: 0.4780 Acc: 0.7645\n",
      "Epoch 010 | Train Loss: 0.4509 Acc: 0.7921 | Val Loss: 0.4355 Acc: 0.7965\n",
      "Epoch 011 | Train Loss: 0.4227 Acc: 0.8104 | Val Loss: 0.3931 Acc: 0.8194\n",
      "Epoch 012 | Train Loss: 0.4050 Acc: 0.8197 | Val Loss: 0.3845 Acc: 0.8207\n",
      "Epoch 013 | Train Loss: 0.3907 Acc: 0.8276 | Val Loss: 0.3628 Acc: 0.8315\n",
      "Epoch 014 | Train Loss: 0.3728 Acc: 0.8380 | Val Loss: 0.3733 Acc: 0.8285\n",
      "Epoch 015 | Train Loss: 0.3417 Acc: 0.8535 | Val Loss: 0.3200 Acc: 0.8496\n",
      "Epoch 016 | Train Loss: 0.3226 Acc: 0.8620 | Val Loss: 0.3147 Acc: 0.8599\n",
      "Epoch 017 | Train Loss: 0.3103 Acc: 0.8667 | Val Loss: 0.3266 Acc: 0.8521\n",
      "Epoch 018 | Train Loss: 0.2893 Acc: 0.8809 | Val Loss: 0.2883 Acc: 0.8774\n",
      "Epoch 019 | Train Loss: 0.2884 Acc: 0.8792 | Val Loss: 0.3317 Acc: 0.8545\n",
      "Epoch 020 | Train Loss: 0.2684 Acc: 0.8868 | Val Loss: 0.2712 Acc: 0.8816\n",
      "Epoch 021 | Train Loss: 0.2649 Acc: 0.8872 | Val Loss: 0.2478 Acc: 0.8998\n",
      "Epoch 022 | Train Loss: 0.2467 Acc: 0.9014 | Val Loss: 0.3008 Acc: 0.8653\n",
      "Epoch 023 | Train Loss: 0.2329 Acc: 0.9032 | Val Loss: 0.2350 Acc: 0.9028\n",
      "Epoch 024 | Train Loss: 0.2162 Acc: 0.9133 | Val Loss: 0.2328 Acc: 0.9082\n",
      "Epoch 025 | Train Loss: 0.2149 Acc: 0.9120 | Val Loss: 0.2494 Acc: 0.8895\n",
      "Epoch 026 | Train Loss: 0.2019 Acc: 0.9201 | Val Loss: 0.2175 Acc: 0.9149\n",
      "Epoch 027 | Train Loss: 0.1938 Acc: 0.9209 | Val Loss: 0.2229 Acc: 0.9088\n",
      "Epoch 028 | Train Loss: 0.1912 Acc: 0.9239 | Val Loss: 0.2162 Acc: 0.9149\n",
      "Epoch 029 | Train Loss: 0.1622 Acc: 0.9352 | Val Loss: 0.2132 Acc: 0.9136\n",
      "Epoch 030 | Train Loss: 0.1789 Acc: 0.9293 | Val Loss: 0.2301 Acc: 0.9130\n",
      "Epoch 031 | Train Loss: 0.1692 Acc: 0.9364 | Val Loss: 0.1920 Acc: 0.9275\n",
      "Epoch 032 | Train Loss: 0.1547 Acc: 0.9375 | Val Loss: 0.1859 Acc: 0.9263\n",
      "Epoch 033 | Train Loss: 0.1602 Acc: 0.9361 | Val Loss: 0.1821 Acc: 0.9287\n",
      "Epoch 034 | Train Loss: 0.1505 Acc: 0.9423 | Val Loss: 0.1888 Acc: 0.9330\n",
      "Epoch 035 | Train Loss: 0.1395 Acc: 0.9481 | Val Loss: 0.1877 Acc: 0.9227\n",
      "Epoch 036 | Train Loss: 0.1492 Acc: 0.9431 | Val Loss: 0.1672 Acc: 0.9390\n",
      "Epoch 037 | Train Loss: 0.1379 Acc: 0.9467 | Val Loss: 0.1871 Acc: 0.9263\n",
      "Epoch 038 | Train Loss: 0.1377 Acc: 0.9443 | Val Loss: 0.1722 Acc: 0.9324\n",
      "Epoch 039 | Train Loss: 0.1338 Acc: 0.9488 | Val Loss: 0.1833 Acc: 0.9287\n",
      "Epoch 040 | Train Loss: 0.1146 Acc: 0.9555 | Val Loss: 0.1781 Acc: 0.9360\n",
      "Epoch 041 | Train Loss: 0.1203 Acc: 0.9538 | Val Loss: 0.2011 Acc: 0.9275\n",
      "Epoch 042 | Train Loss: 0.1202 Acc: 0.9547 | Val Loss: 0.1798 Acc: 0.9306\n",
      "Epoch 043 | Train Loss: 0.1118 Acc: 0.9564 | Val Loss: 0.1719 Acc: 0.9293\n",
      "Epoch 044 | Train Loss: 0.1096 Acc: 0.9583 | Val Loss: 0.1749 Acc: 0.9366\n",
      "Epoch 045 | Train Loss: 0.1056 Acc: 0.9597 | Val Loss: 0.1660 Acc: 0.9438\n",
      "Epoch 046 | Train Loss: 0.1055 Acc: 0.9600 | Val Loss: 0.1975 Acc: 0.9312\n",
      "Epoch 047 | Train Loss: 0.1088 Acc: 0.9576 | Val Loss: 0.1775 Acc: 0.9306\n",
      "Epoch 048 | Train Loss: 0.1066 Acc: 0.9588 | Val Loss: 0.1532 Acc: 0.9402\n",
      "Epoch 049 | Train Loss: 0.0962 Acc: 0.9638 | Val Loss: 0.1660 Acc: 0.9348\n",
      "Epoch 050 | Train Loss: 0.1042 Acc: 0.9621 | Val Loss: 0.1812 Acc: 0.9366\n",
      "Epoch 051 | Train Loss: 0.0875 Acc: 0.9687 | Val Loss: 0.1604 Acc: 0.9378\n",
      "Epoch 052 | Train Loss: 0.1004 Acc: 0.9600 | Val Loss: 0.1604 Acc: 0.9420\n",
      "Epoch 053 | Train Loss: 0.0976 Acc: 0.9647 | Val Loss: 0.1744 Acc: 0.9420\n",
      "Epoch 054 | Train Loss: 0.0963 Acc: 0.9657 | Val Loss: 0.1897 Acc: 0.9330\n",
      "Epoch 055 | Train Loss: 0.0891 Acc: 0.9672 | Val Loss: 0.1884 Acc: 0.9408\n",
      "Epoch 056 | Train Loss: 0.0920 Acc: 0.9674 | Val Loss: 0.2025 Acc: 0.9318\n",
      "Epoch 057 | Train Loss: 0.0894 Acc: 0.9692 | Val Loss: 0.1677 Acc: 0.9438\n",
      "Epoch 058 | Train Loss: 0.0795 Acc: 0.9698 | Val Loss: 0.1642 Acc: 0.9457\n",
      "Early stopping triggered.\n",
      "Epoch 001 | Train Loss: 0.6790 Acc: 0.5813 | Val Loss: 0.6739 Acc: 0.5900\n",
      "Epoch 002 | Train Loss: 0.6712 Acc: 0.5928 | Val Loss: 0.6711 Acc: 0.5930\n",
      "Epoch 003 | Train Loss: 0.6684 Acc: 0.6015 | Val Loss: 0.6674 Acc: 0.5984\n",
      "Epoch 004 | Train Loss: 0.6618 Acc: 0.6091 | Val Loss: 0.6700 Acc: 0.5906\n",
      "Epoch 005 | Train Loss: 0.6511 Acc: 0.6246 | Val Loss: 0.6108 Acc: 0.6830\n",
      "Epoch 006 | Train Loss: 0.6216 Acc: 0.6695 | Val Loss: 0.6131 Acc: 0.6721\n",
      "Epoch 007 | Train Loss: 0.5834 Acc: 0.7090 | Val Loss: 0.5660 Acc: 0.7264\n",
      "Epoch 008 | Train Loss: 0.5541 Acc: 0.7297 | Val Loss: 0.5560 Acc: 0.7210\n",
      "Epoch 009 | Train Loss: 0.5343 Acc: 0.7475 | Val Loss: 0.5177 Acc: 0.7476\n",
      "Epoch 010 | Train Loss: 0.5037 Acc: 0.7611 | Val Loss: 0.5262 Acc: 0.7488\n",
      "Epoch 011 | Train Loss: 0.4772 Acc: 0.7737 | Val Loss: 0.5024 Acc: 0.7458\n",
      "Epoch 012 | Train Loss: 0.4608 Acc: 0.7879 | Val Loss: 0.4637 Acc: 0.7693\n",
      "Epoch 013 | Train Loss: 0.4353 Acc: 0.8027 | Val Loss: 0.4206 Acc: 0.7947\n",
      "Epoch 014 | Train Loss: 0.4153 Acc: 0.8165 | Val Loss: 0.4274 Acc: 0.7959\n",
      "Epoch 015 | Train Loss: 0.3837 Acc: 0.8312 | Val Loss: 0.3855 Acc: 0.8273\n",
      "Epoch 016 | Train Loss: 0.3718 Acc: 0.8372 | Val Loss: 0.3955 Acc: 0.8261\n",
      "Epoch 017 | Train Loss: 0.3526 Acc: 0.8478 | Val Loss: 0.3946 Acc: 0.8200\n",
      "Epoch 018 | Train Loss: 0.3316 Acc: 0.8561 | Val Loss: 0.3772 Acc: 0.8327\n",
      "Epoch 019 | Train Loss: 0.3212 Acc: 0.8650 | Val Loss: 0.3636 Acc: 0.8345\n",
      "Epoch 020 | Train Loss: 0.3014 Acc: 0.8744 | Val Loss: 0.3304 Acc: 0.8629\n",
      "Epoch 021 | Train Loss: 0.2843 Acc: 0.8839 | Val Loss: 0.3734 Acc: 0.8394\n",
      "Epoch 022 | Train Loss: 0.2784 Acc: 0.8905 | Val Loss: 0.3044 Acc: 0.8690\n",
      "Epoch 023 | Train Loss: 0.2720 Acc: 0.8917 | Val Loss: 0.2967 Acc: 0.8684\n",
      "Epoch 024 | Train Loss: 0.2458 Acc: 0.9026 | Val Loss: 0.3029 Acc: 0.8768\n",
      "Epoch 025 | Train Loss: 0.2433 Acc: 0.9025 | Val Loss: 0.2900 Acc: 0.8756\n",
      "Epoch 026 | Train Loss: 0.2286 Acc: 0.9070 | Val Loss: 0.3367 Acc: 0.8653\n",
      "Epoch 027 | Train Loss: 0.2273 Acc: 0.9097 | Val Loss: 0.2882 Acc: 0.8768\n",
      "Epoch 028 | Train Loss: 0.2101 Acc: 0.9145 | Val Loss: 0.2773 Acc: 0.8949\n",
      "Epoch 029 | Train Loss: 0.2037 Acc: 0.9212 | Val Loss: 0.2478 Acc: 0.9040\n",
      "Epoch 030 | Train Loss: 0.1836 Acc: 0.9281 | Val Loss: 0.2673 Acc: 0.8919\n",
      "Epoch 031 | Train Loss: 0.1763 Acc: 0.9321 | Val Loss: 0.2745 Acc: 0.8955\n",
      "Epoch 032 | Train Loss: 0.1788 Acc: 0.9313 | Val Loss: 0.2497 Acc: 0.8961\n",
      "Epoch 033 | Train Loss: 0.1695 Acc: 0.9354 | Val Loss: 0.2471 Acc: 0.9058\n",
      "Epoch 034 | Train Loss: 0.1649 Acc: 0.9401 | Val Loss: 0.2455 Acc: 0.9040\n",
      "Epoch 035 | Train Loss: 0.1559 Acc: 0.9398 | Val Loss: 0.2492 Acc: 0.8967\n",
      "Epoch 036 | Train Loss: 0.1590 Acc: 0.9410 | Val Loss: 0.2594 Acc: 0.8883\n",
      "Epoch 037 | Train Loss: 0.1467 Acc: 0.9455 | Val Loss: 0.2982 Acc: 0.8931\n",
      "Epoch 038 | Train Loss: 0.1585 Acc: 0.9390 | Val Loss: 0.2072 Acc: 0.9233\n",
      "Epoch 039 | Train Loss: 0.1385 Acc: 0.9462 | Val Loss: 0.2352 Acc: 0.9100\n",
      "Epoch 040 | Train Loss: 0.1426 Acc: 0.9472 | Val Loss: 0.2169 Acc: 0.9167\n",
      "Epoch 041 | Train Loss: 0.1258 Acc: 0.9517 | Val Loss: 0.2285 Acc: 0.9100\n",
      "Epoch 042 | Train Loss: 0.1247 Acc: 0.9532 | Val Loss: 0.2337 Acc: 0.9161\n",
      "Epoch 043 | Train Loss: 0.1234 Acc: 0.9546 | Val Loss: 0.2079 Acc: 0.9251\n",
      "Epoch 044 | Train Loss: 0.1220 Acc: 0.9533 | Val Loss: 0.2314 Acc: 0.9100\n",
      "Epoch 045 | Train Loss: 0.1175 Acc: 0.9547 | Val Loss: 0.2194 Acc: 0.9209\n",
      "Epoch 046 | Train Loss: 0.1106 Acc: 0.9558 | Val Loss: 0.2329 Acc: 0.9227\n",
      "Epoch 047 | Train Loss: 0.1220 Acc: 0.9526 | Val Loss: 0.2218 Acc: 0.9167\n",
      "Epoch 048 | Train Loss: 0.1109 Acc: 0.9613 | Val Loss: 0.2452 Acc: 0.9046\n",
      "Early stopping triggered.\n",
      "Epoch 001 | Train Loss: 0.6791 Acc: 0.5781 | Val Loss: 0.6762 Acc: 0.5876\n",
      "Epoch 002 | Train Loss: 0.6752 Acc: 0.5902 | Val Loss: 0.6800 Acc: 0.5713\n",
      "Epoch 003 | Train Loss: 0.6676 Acc: 0.6044 | Val Loss: 0.6672 Acc: 0.6002\n",
      "Epoch 004 | Train Loss: 0.6598 Acc: 0.6088 | Val Loss: 0.6513 Acc: 0.6069\n",
      "Epoch 005 | Train Loss: 0.6254 Acc: 0.6683 | Val Loss: 0.6097 Acc: 0.6751\n",
      "Epoch 006 | Train Loss: 0.5878 Acc: 0.7080 | Val Loss: 0.5605 Acc: 0.7132\n",
      "Epoch 007 | Train Loss: 0.5476 Acc: 0.7302 | Val Loss: 0.5404 Acc: 0.7295\n",
      "Epoch 008 | Train Loss: 0.5270 Acc: 0.7457 | Val Loss: 0.5447 Acc: 0.7216\n",
      "Epoch 009 | Train Loss: 0.5122 Acc: 0.7525 | Val Loss: 0.5008 Acc: 0.7560\n",
      "Epoch 010 | Train Loss: 0.4876 Acc: 0.7713 | Val Loss: 0.5037 Acc: 0.7530\n",
      "Epoch 011 | Train Loss: 0.4693 Acc: 0.7788 | Val Loss: 0.5368 Acc: 0.7349\n",
      "Epoch 012 | Train Loss: 0.4628 Acc: 0.7832 | Val Loss: 0.4795 Acc: 0.7494\n",
      "Epoch 013 | Train Loss: 0.4345 Acc: 0.8022 | Val Loss: 0.4245 Acc: 0.7983\n",
      "Epoch 014 | Train Loss: 0.4129 Acc: 0.8085 | Val Loss: 0.5014 Acc: 0.7554\n",
      "Epoch 015 | Train Loss: 0.4021 Acc: 0.8138 | Val Loss: 0.3737 Acc: 0.8315\n",
      "Epoch 016 | Train Loss: 0.3816 Acc: 0.8297 | Val Loss: 0.3969 Acc: 0.8098\n",
      "Epoch 017 | Train Loss: 0.3571 Acc: 0.8412 | Val Loss: 0.3607 Acc: 0.8345\n",
      "Epoch 018 | Train Loss: 0.3519 Acc: 0.8467 | Val Loss: 0.3613 Acc: 0.8285\n",
      "Epoch 019 | Train Loss: 0.3302 Acc: 0.8593 | Val Loss: 0.3566 Acc: 0.8376\n",
      "Epoch 020 | Train Loss: 0.3065 Acc: 0.8689 | Val Loss: 0.2889 Acc: 0.8708\n",
      "Epoch 021 | Train Loss: 0.2909 Acc: 0.8757 | Val Loss: 0.3075 Acc: 0.8702\n",
      "Epoch 022 | Train Loss: 0.2861 Acc: 0.8830 | Val Loss: 0.2787 Acc: 0.8798\n",
      "Epoch 023 | Train Loss: 0.2655 Acc: 0.8875 | Val Loss: 0.2619 Acc: 0.8841\n",
      "Epoch 024 | Train Loss: 0.2496 Acc: 0.8973 | Val Loss: 0.2754 Acc: 0.8744\n",
      "Epoch 025 | Train Loss: 0.2548 Acc: 0.8964 | Val Loss: 0.2616 Acc: 0.8937\n",
      "Epoch 026 | Train Loss: 0.2501 Acc: 0.8969 | Val Loss: 0.2502 Acc: 0.8955\n",
      "Epoch 027 | Train Loss: 0.2107 Acc: 0.9153 | Val Loss: 0.2185 Acc: 0.9106\n",
      "Epoch 028 | Train Loss: 0.2148 Acc: 0.9167 | Val Loss: 0.2221 Acc: 0.9130\n",
      "Epoch 029 | Train Loss: 0.2005 Acc: 0.9167 | Val Loss: 0.1977 Acc: 0.9251\n",
      "Epoch 030 | Train Loss: 0.2044 Acc: 0.9216 | Val Loss: 0.2091 Acc: 0.9155\n",
      "Epoch 031 | Train Loss: 0.1804 Acc: 0.9262 | Val Loss: 0.2120 Acc: 0.9094\n",
      "Epoch 032 | Train Loss: 0.1882 Acc: 0.9247 | Val Loss: 0.2138 Acc: 0.9149\n",
      "Epoch 033 | Train Loss: 0.1740 Acc: 0.9340 | Val Loss: 0.2083 Acc: 0.9167\n",
      "Epoch 034 | Train Loss: 0.1635 Acc: 0.9367 | Val Loss: 0.2039 Acc: 0.9136\n",
      "Epoch 035 | Train Loss: 0.1495 Acc: 0.9414 | Val Loss: 0.2001 Acc: 0.9155\n",
      "Epoch 036 | Train Loss: 0.1635 Acc: 0.9393 | Val Loss: 0.1693 Acc: 0.9384\n",
      "Epoch 037 | Train Loss: 0.1454 Acc: 0.9453 | Val Loss: 0.1894 Acc: 0.9324\n",
      "Epoch 038 | Train Loss: 0.1415 Acc: 0.9455 | Val Loss: 0.2047 Acc: 0.9227\n",
      "Epoch 039 | Train Loss: 0.1271 Acc: 0.9512 | Val Loss: 0.1733 Acc: 0.9366\n",
      "Epoch 040 | Train Loss: 0.1328 Acc: 0.9506 | Val Loss: 0.2019 Acc: 0.9233\n",
      "Epoch 041 | Train Loss: 0.1282 Acc: 0.9481 | Val Loss: 0.1855 Acc: 0.9287\n",
      "Epoch 042 | Train Loss: 0.1306 Acc: 0.9485 | Val Loss: 0.2155 Acc: 0.9161\n",
      "Epoch 043 | Train Loss: 0.1180 Acc: 0.9549 | Val Loss: 0.1754 Acc: 0.9312\n",
      "Epoch 044 | Train Loss: 0.1099 Acc: 0.9579 | Val Loss: 0.1733 Acc: 0.9348\n",
      "Epoch 045 | Train Loss: 0.1124 Acc: 0.9553 | Val Loss: 0.1496 Acc: 0.9444\n",
      "Epoch 046 | Train Loss: 0.1267 Acc: 0.9502 | Val Loss: 0.1635 Acc: 0.9366\n",
      "Epoch 047 | Train Loss: 0.1025 Acc: 0.9618 | Val Loss: 0.1755 Acc: 0.9342\n",
      "Epoch 048 | Train Loss: 0.1131 Acc: 0.9552 | Val Loss: 0.1994 Acc: 0.9312\n",
      "Epoch 049 | Train Loss: 0.1246 Acc: 0.9535 | Val Loss: 0.1757 Acc: 0.9318\n",
      "Epoch 050 | Train Loss: 0.0949 Acc: 0.9629 | Val Loss: 0.1550 Acc: 0.9450\n",
      "Epoch 051 | Train Loss: 0.0978 Acc: 0.9656 | Val Loss: 0.1495 Acc: 0.9426\n",
      "Epoch 052 | Train Loss: 0.0901 Acc: 0.9687 | Val Loss: 0.1796 Acc: 0.9378\n",
      "Epoch 053 | Train Loss: 0.0942 Acc: 0.9623 | Val Loss: 0.1435 Acc: 0.9499\n",
      "Epoch 054 | Train Loss: 0.0906 Acc: 0.9657 | Val Loss: 0.1779 Acc: 0.9360\n",
      "Epoch 055 | Train Loss: 0.0927 Acc: 0.9674 | Val Loss: 0.1495 Acc: 0.9366\n",
      "Epoch 056 | Train Loss: 0.0927 Acc: 0.9654 | Val Loss: 0.1683 Acc: 0.9438\n",
      "Epoch 057 | Train Loss: 0.0909 Acc: 0.9674 | Val Loss: 0.1916 Acc: 0.9330\n",
      "Epoch 058 | Train Loss: 0.0828 Acc: 0.9692 | Val Loss: 0.1382 Acc: 0.9523\n",
      "Epoch 059 | Train Loss: 0.0870 Acc: 0.9684 | Val Loss: 0.1632 Acc: 0.9402\n",
      "Epoch 060 | Train Loss: 0.0769 Acc: 0.9725 | Val Loss: 0.1292 Acc: 0.9511\n",
      "Epoch 001 | Train Loss: 0.6825 Acc: 0.5721 | Val Loss: 0.6764 Acc: 0.5876\n",
      "Epoch 002 | Train Loss: 0.6734 Acc: 0.5928 | Val Loss: 0.6679 Acc: 0.6033\n",
      "Epoch 003 | Train Loss: 0.6627 Acc: 0.6055 | Val Loss: 0.6828 Acc: 0.5839\n",
      "Epoch 004 | Train Loss: 0.6430 Acc: 0.6413 | Val Loss: 0.6065 Acc: 0.6806\n",
      "Epoch 005 | Train Loss: 0.5914 Acc: 0.7003 | Val Loss: 0.5837 Acc: 0.7071\n",
      "Epoch 006 | Train Loss: 0.5696 Acc: 0.7187 | Val Loss: 0.5661 Acc: 0.7174\n",
      "Epoch 007 | Train Loss: 0.5554 Acc: 0.7287 | Val Loss: 0.5588 Acc: 0.7210\n",
      "Epoch 008 | Train Loss: 0.5387 Acc: 0.7394 | Val Loss: 0.5408 Acc: 0.7204\n",
      "Epoch 009 | Train Loss: 0.5209 Acc: 0.7515 | Val Loss: 0.5615 Acc: 0.7077\n",
      "Epoch 010 | Train Loss: 0.5140 Acc: 0.7495 | Val Loss: 0.5334 Acc: 0.7331\n",
      "Epoch 011 | Train Loss: 0.4979 Acc: 0.7574 | Val Loss: 0.5183 Acc: 0.7440\n",
      "Epoch 012 | Train Loss: 0.4811 Acc: 0.7743 | Val Loss: 0.4827 Acc: 0.7548\n",
      "Epoch 013 | Train Loss: 0.4732 Acc: 0.7809 | Val Loss: 0.4713 Acc: 0.7687\n",
      "Epoch 014 | Train Loss: 0.4552 Acc: 0.7818 | Val Loss: 0.4635 Acc: 0.7790\n",
      "Epoch 015 | Train Loss: 0.4395 Acc: 0.7930 | Val Loss: 0.4405 Acc: 0.7959\n",
      "Epoch 016 | Train Loss: 0.4240 Acc: 0.7992 | Val Loss: 0.4235 Acc: 0.7983\n",
      "Epoch 017 | Train Loss: 0.4046 Acc: 0.8152 | Val Loss: 0.3910 Acc: 0.8164\n",
      "Epoch 018 | Train Loss: 0.3977 Acc: 0.8221 | Val Loss: 0.3848 Acc: 0.8213\n",
      "Epoch 019 | Train Loss: 0.3677 Acc: 0.8350 | Val Loss: 0.3613 Acc: 0.8406\n",
      "Epoch 020 | Train Loss: 0.3551 Acc: 0.8398 | Val Loss: 0.3479 Acc: 0.8484\n",
      "Epoch 021 | Train Loss: 0.3410 Acc: 0.8519 | Val Loss: 0.3090 Acc: 0.8738\n",
      "Epoch 022 | Train Loss: 0.3268 Acc: 0.8585 | Val Loss: 0.3594 Acc: 0.8460\n",
      "Epoch 023 | Train Loss: 0.3132 Acc: 0.8676 | Val Loss: 0.2986 Acc: 0.8708\n",
      "Epoch 024 | Train Loss: 0.2876 Acc: 0.8803 | Val Loss: 0.3150 Acc: 0.8623\n",
      "Epoch 025 | Train Loss: 0.2836 Acc: 0.8807 | Val Loss: 0.2669 Acc: 0.8919\n",
      "Epoch 026 | Train Loss: 0.2658 Acc: 0.8874 | Val Loss: 0.2761 Acc: 0.8847\n",
      "Epoch 027 | Train Loss: 0.2561 Acc: 0.8978 | Val Loss: 0.3042 Acc: 0.8647\n",
      "Epoch 028 | Train Loss: 0.2526 Acc: 0.8967 | Val Loss: 0.2513 Acc: 0.8955\n",
      "Epoch 029 | Train Loss: 0.2333 Acc: 0.9013 | Val Loss: 0.2383 Acc: 0.9070\n",
      "Epoch 030 | Train Loss: 0.2306 Acc: 0.9085 | Val Loss: 0.2360 Acc: 0.9034\n",
      "Epoch 031 | Train Loss: 0.2121 Acc: 0.9167 | Val Loss: 0.2246 Acc: 0.9076\n",
      "Epoch 032 | Train Loss: 0.2032 Acc: 0.9174 | Val Loss: 0.2464 Acc: 0.9046\n",
      "Epoch 033 | Train Loss: 0.1939 Acc: 0.9286 | Val Loss: 0.1967 Acc: 0.9245\n",
      "Epoch 034 | Train Loss: 0.1969 Acc: 0.9191 | Val Loss: 0.2115 Acc: 0.9143\n",
      "Epoch 035 | Train Loss: 0.1826 Acc: 0.9277 | Val Loss: 0.2155 Acc: 0.9161\n",
      "Epoch 036 | Train Loss: 0.1797 Acc: 0.9269 | Val Loss: 0.2455 Acc: 0.9070\n",
      "Epoch 037 | Train Loss: 0.1677 Acc: 0.9340 | Val Loss: 0.1857 Acc: 0.9215\n",
      "Epoch 038 | Train Loss: 0.1681 Acc: 0.9311 | Val Loss: 0.1854 Acc: 0.9281\n",
      "Epoch 039 | Train Loss: 0.1610 Acc: 0.9372 | Val Loss: 0.1833 Acc: 0.9245\n",
      "Epoch 040 | Train Loss: 0.1519 Acc: 0.9393 | Val Loss: 0.1708 Acc: 0.9318\n",
      "Epoch 041 | Train Loss: 0.1449 Acc: 0.9443 | Val Loss: 0.1991 Acc: 0.9233\n",
      "Epoch 042 | Train Loss: 0.1451 Acc: 0.9440 | Val Loss: 0.1780 Acc: 0.9324\n",
      "Epoch 043 | Train Loss: 0.1365 Acc: 0.9497 | Val Loss: 0.1811 Acc: 0.9306\n",
      "Epoch 044 | Train Loss: 0.1390 Acc: 0.9452 | Val Loss: 0.1715 Acc: 0.9318\n",
      "Epoch 045 | Train Loss: 0.1336 Acc: 0.9503 | Val Loss: 0.1722 Acc: 0.9336\n",
      "Epoch 046 | Train Loss: 0.1248 Acc: 0.9530 | Val Loss: 0.1661 Acc: 0.9360\n",
      "Epoch 047 | Train Loss: 0.1343 Acc: 0.9500 | Val Loss: 0.1828 Acc: 0.9275\n",
      "Epoch 048 | Train Loss: 0.1178 Acc: 0.9543 | Val Loss: 0.1561 Acc: 0.9366\n",
      "Epoch 049 | Train Loss: 0.1157 Acc: 0.9564 | Val Loss: 0.1520 Acc: 0.9463\n",
      "Epoch 050 | Train Loss: 0.1114 Acc: 0.9600 | Val Loss: 0.1589 Acc: 0.9408\n",
      "Epoch 051 | Train Loss: 0.1056 Acc: 0.9629 | Val Loss: 0.1820 Acc: 0.9390\n",
      "Epoch 052 | Train Loss: 0.1045 Acc: 0.9597 | Val Loss: 0.1710 Acc: 0.9372\n",
      "Epoch 053 | Train Loss: 0.1092 Acc: 0.9592 | Val Loss: 0.1884 Acc: 0.9342\n",
      "Epoch 054 | Train Loss: 0.1088 Acc: 0.9586 | Val Loss: 0.1931 Acc: 0.9306\n",
      "Epoch 055 | Train Loss: 0.1018 Acc: 0.9615 | Val Loss: 0.1841 Acc: 0.9336\n",
      "Epoch 056 | Train Loss: 0.1026 Acc: 0.9580 | Val Loss: 0.1506 Acc: 0.9426\n",
      "Epoch 057 | Train Loss: 0.1012 Acc: 0.9610 | Val Loss: 0.1599 Acc: 0.9408\n",
      "Epoch 058 | Train Loss: 0.0946 Acc: 0.9627 | Val Loss: 0.1399 Acc: 0.9475\n",
      "Epoch 059 | Train Loss: 0.0926 Acc: 0.9650 | Val Loss: 0.2026 Acc: 0.9239\n",
      "Epoch 060 | Train Loss: 0.0871 Acc: 0.9665 | Val Loss: 0.1588 Acc: 0.9438\n",
      "Epoch 001 | Train Loss: 0.6787 Acc: 0.5787 | Val Loss: 0.6726 Acc: 0.5882\n",
      "Epoch 002 | Train Loss: 0.6640 Acc: 0.6035 | Val Loss: 0.6420 Acc: 0.6316\n",
      "Epoch 003 | Train Loss: 0.6247 Acc: 0.6654 | Val Loss: 0.5845 Acc: 0.7023\n",
      "Epoch 004 | Train Loss: 0.5617 Acc: 0.7235 | Val Loss: 0.5581 Acc: 0.7144\n",
      "Epoch 005 | Train Loss: 0.5386 Acc: 0.7426 | Val Loss: 0.5490 Acc: 0.7144\n",
      "Epoch 006 | Train Loss: 0.5228 Acc: 0.7471 | Val Loss: 0.5334 Acc: 0.7349\n",
      "Epoch 007 | Train Loss: 0.4938 Acc: 0.7649 | Val Loss: 0.4979 Acc: 0.7470\n",
      "Epoch 008 | Train Loss: 0.4679 Acc: 0.7767 | Val Loss: 0.4623 Acc: 0.7669\n",
      "Epoch 009 | Train Loss: 0.4467 Acc: 0.7882 | Val Loss: 0.4354 Acc: 0.7850\n",
      "Epoch 010 | Train Loss: 0.4274 Acc: 0.8076 | Val Loss: 0.4399 Acc: 0.7784\n",
      "Epoch 011 | Train Loss: 0.4048 Acc: 0.8212 | Val Loss: 0.4033 Acc: 0.8092\n",
      "Epoch 012 | Train Loss: 0.3916 Acc: 0.8267 | Val Loss: 0.3743 Acc: 0.8285\n",
      "Epoch 013 | Train Loss: 0.3714 Acc: 0.8366 | Val Loss: 0.3885 Acc: 0.8176\n",
      "Epoch 014 | Train Loss: 0.3510 Acc: 0.8475 | Val Loss: 0.3547 Acc: 0.8345\n",
      "Epoch 015 | Train Loss: 0.3362 Acc: 0.8511 | Val Loss: 0.3458 Acc: 0.8376\n",
      "Epoch 016 | Train Loss: 0.3100 Acc: 0.8652 | Val Loss: 0.3489 Acc: 0.8370\n",
      "Epoch 017 | Train Loss: 0.3060 Acc: 0.8741 | Val Loss: 0.3056 Acc: 0.8708\n",
      "Epoch 018 | Train Loss: 0.2862 Acc: 0.8851 | Val Loss: 0.3111 Acc: 0.8599\n",
      "Epoch 019 | Train Loss: 0.2686 Acc: 0.8871 | Val Loss: 0.2647 Acc: 0.8859\n",
      "Epoch 020 | Train Loss: 0.2613 Acc: 0.8904 | Val Loss: 0.2624 Acc: 0.8901\n",
      "Epoch 021 | Train Loss: 0.2405 Acc: 0.8994 | Val Loss: 0.2473 Acc: 0.8937\n",
      "Epoch 022 | Train Loss: 0.2437 Acc: 0.9008 | Val Loss: 0.2715 Acc: 0.8889\n",
      "Epoch 023 | Train Loss: 0.2183 Acc: 0.9094 | Val Loss: 0.2874 Acc: 0.8859\n",
      "Epoch 024 | Train Loss: 0.2084 Acc: 0.9164 | Val Loss: 0.2334 Acc: 0.9028\n",
      "Epoch 025 | Train Loss: 0.2062 Acc: 0.9194 | Val Loss: 0.2240 Acc: 0.9118\n",
      "Epoch 026 | Train Loss: 0.1974 Acc: 0.9207 | Val Loss: 0.2294 Acc: 0.9094\n",
      "Epoch 027 | Train Loss: 0.1867 Acc: 0.9310 | Val Loss: 0.2230 Acc: 0.9118\n",
      "Epoch 028 | Train Loss: 0.1857 Acc: 0.9280 | Val Loss: 0.2077 Acc: 0.9185\n",
      "Epoch 029 | Train Loss: 0.1698 Acc: 0.9315 | Val Loss: 0.2182 Acc: 0.9155\n",
      "Epoch 030 | Train Loss: 0.1630 Acc: 0.9370 | Val Loss: 0.2189 Acc: 0.9130\n",
      "Epoch 031 | Train Loss: 0.1723 Acc: 0.9330 | Val Loss: 0.2088 Acc: 0.9179\n",
      "Epoch 032 | Train Loss: 0.1509 Acc: 0.9419 | Val Loss: 0.2019 Acc: 0.9197\n",
      "Epoch 033 | Train Loss: 0.1398 Acc: 0.9473 | Val Loss: 0.1900 Acc: 0.9293\n",
      "Epoch 034 | Train Loss: 0.1481 Acc: 0.9420 | Val Loss: 0.2472 Acc: 0.9052\n",
      "Epoch 035 | Train Loss: 0.1355 Acc: 0.9458 | Val Loss: 0.1938 Acc: 0.9360\n",
      "Epoch 036 | Train Loss: 0.1407 Acc: 0.9465 | Val Loss: 0.1808 Acc: 0.9275\n",
      "Epoch 037 | Train Loss: 0.1276 Acc: 0.9538 | Val Loss: 0.1771 Acc: 0.9300\n",
      "Epoch 038 | Train Loss: 0.1171 Acc: 0.9539 | Val Loss: 0.1852 Acc: 0.9324\n",
      "Epoch 039 | Train Loss: 0.1180 Acc: 0.9523 | Val Loss: 0.1940 Acc: 0.9300\n",
      "Epoch 040 | Train Loss: 0.1098 Acc: 0.9580 | Val Loss: 0.1758 Acc: 0.9330\n",
      "Epoch 041 | Train Loss: 0.1059 Acc: 0.9615 | Val Loss: 0.1819 Acc: 0.9312\n",
      "Epoch 042 | Train Loss: 0.1110 Acc: 0.9589 | Val Loss: 0.1879 Acc: 0.9281\n",
      "Epoch 043 | Train Loss: 0.0996 Acc: 0.9633 | Val Loss: 0.2183 Acc: 0.9227\n",
      "Epoch 044 | Train Loss: 0.0872 Acc: 0.9675 | Val Loss: 0.1969 Acc: 0.9330\n",
      "Epoch 045 | Train Loss: 0.0983 Acc: 0.9633 | Val Loss: 0.2179 Acc: 0.9221\n",
      "Epoch 046 | Train Loss: 0.0972 Acc: 0.9641 | Val Loss: 0.1809 Acc: 0.9360\n",
      "Epoch 047 | Train Loss: 0.0908 Acc: 0.9657 | Val Loss: 0.2323 Acc: 0.9221\n",
      "Epoch 048 | Train Loss: 0.0943 Acc: 0.9656 | Val Loss: 0.1643 Acc: 0.9378\n",
      "Epoch 049 | Train Loss: 0.0815 Acc: 0.9725 | Val Loss: 0.1576 Acc: 0.9438\n",
      "Epoch 050 | Train Loss: 0.0926 Acc: 0.9675 | Val Loss: 0.1674 Acc: 0.9450\n",
      "Epoch 051 | Train Loss: 0.0800 Acc: 0.9689 | Val Loss: 0.1837 Acc: 0.9384\n",
      "Epoch 052 | Train Loss: 0.0753 Acc: 0.9722 | Val Loss: 0.2049 Acc: 0.9287\n",
      "Epoch 053 | Train Loss: 0.0846 Acc: 0.9671 | Val Loss: 0.1660 Acc: 0.9450\n",
      "Epoch 054 | Train Loss: 0.0682 Acc: 0.9748 | Val Loss: 0.1711 Acc: 0.9408\n",
      "Epoch 055 | Train Loss: 0.0878 Acc: 0.9672 | Val Loss: 0.1834 Acc: 0.9372\n",
      "Epoch 056 | Train Loss: 0.0775 Acc: 0.9719 | Val Loss: 0.1761 Acc: 0.9444\n",
      "Epoch 057 | Train Loss: 0.0713 Acc: 0.9733 | Val Loss: 0.1574 Acc: 0.9499\n",
      "Epoch 058 | Train Loss: 0.0722 Acc: 0.9722 | Val Loss: 0.1645 Acc: 0.9469\n",
      "Epoch 059 | Train Loss: 0.0687 Acc: 0.9749 | Val Loss: 0.1587 Acc: 0.9438\n",
      "Epoch 060 | Train Loss: 0.0715 Acc: 0.9742 | Val Loss: 0.1651 Acc: 0.9463\n",
      "Epoch 001 | Train Loss: 0.6832 Acc: 0.5697 | Val Loss: 0.6751 Acc: 0.5900\n",
      "Epoch 002 | Train Loss: 0.6719 Acc: 0.5935 | Val Loss: 0.6850 Acc: 0.5586\n",
      "Epoch 003 | Train Loss: 0.6704 Acc: 0.5973 | Val Loss: 0.6380 Acc: 0.6461\n",
      "Epoch 004 | Train Loss: 0.6303 Acc: 0.6704 | Val Loss: 0.6270 Acc: 0.6781\n",
      "Epoch 005 | Train Loss: 0.5993 Acc: 0.6956 | Val Loss: 0.5809 Acc: 0.7041\n",
      "Epoch 006 | Train Loss: 0.5904 Acc: 0.7013 | Val Loss: 0.5683 Acc: 0.7053\n",
      "Epoch 007 | Train Loss: 0.5628 Acc: 0.7225 | Val Loss: 0.5606 Acc: 0.7114\n",
      "Epoch 008 | Train Loss: 0.5486 Acc: 0.7306 | Val Loss: 0.5529 Acc: 0.7198\n",
      "Epoch 009 | Train Loss: 0.5386 Acc: 0.7341 | Val Loss: 0.5774 Acc: 0.7319\n",
      "Epoch 010 | Train Loss: 0.5266 Acc: 0.7457 | Val Loss: 0.5320 Acc: 0.7367\n",
      "Epoch 011 | Train Loss: 0.5048 Acc: 0.7551 | Val Loss: 0.5047 Acc: 0.7434\n",
      "Epoch 012 | Train Loss: 0.4924 Acc: 0.7661 | Val Loss: 0.4984 Acc: 0.7482\n",
      "Epoch 013 | Train Loss: 0.4687 Acc: 0.7777 | Val Loss: 0.4861 Acc: 0.7742\n",
      "Epoch 014 | Train Loss: 0.4543 Acc: 0.7897 | Val Loss: 0.4644 Acc: 0.7868\n",
      "Epoch 015 | Train Loss: 0.4394 Acc: 0.7934 | Val Loss: 0.4368 Acc: 0.7947\n",
      "Epoch 016 | Train Loss: 0.4257 Acc: 0.8093 | Val Loss: 0.4231 Acc: 0.8056\n",
      "Epoch 017 | Train Loss: 0.4025 Acc: 0.8156 | Val Loss: 0.3928 Acc: 0.8249\n",
      "Epoch 018 | Train Loss: 0.3917 Acc: 0.8233 | Val Loss: 0.3685 Acc: 0.8303\n",
      "Epoch 019 | Train Loss: 0.3619 Acc: 0.8446 | Val Loss: 0.4034 Acc: 0.8146\n",
      "Epoch 020 | Train Loss: 0.3557 Acc: 0.8425 | Val Loss: 0.3454 Acc: 0.8527\n",
      "Epoch 021 | Train Loss: 0.3373 Acc: 0.8564 | Val Loss: 0.3208 Acc: 0.8647\n",
      "Epoch 022 | Train Loss: 0.3092 Acc: 0.8721 | Val Loss: 0.3371 Acc: 0.8478\n",
      "Epoch 023 | Train Loss: 0.3050 Acc: 0.8720 | Val Loss: 0.3401 Acc: 0.8484\n",
      "Epoch 024 | Train Loss: 0.3014 Acc: 0.8791 | Val Loss: 0.3340 Acc: 0.8593\n",
      "Epoch 025 | Train Loss: 0.2821 Acc: 0.8839 | Val Loss: 0.2623 Acc: 0.8925\n",
      "Epoch 026 | Train Loss: 0.2557 Acc: 0.8972 | Val Loss: 0.2957 Acc: 0.8780\n",
      "Epoch 027 | Train Loss: 0.2535 Acc: 0.9016 | Val Loss: 0.2661 Acc: 0.8895\n",
      "Epoch 028 | Train Loss: 0.2359 Acc: 0.9055 | Val Loss: 0.2574 Acc: 0.9088\n",
      "Epoch 029 | Train Loss: 0.2321 Acc: 0.9093 | Val Loss: 0.3275 Acc: 0.8690\n",
      "Epoch 030 | Train Loss: 0.2297 Acc: 0.9106 | Val Loss: 0.3132 Acc: 0.8816\n",
      "Epoch 031 | Train Loss: 0.2120 Acc: 0.9170 | Val Loss: 0.2254 Acc: 0.9130\n",
      "Epoch 032 | Train Loss: 0.2034 Acc: 0.9171 | Val Loss: 0.2260 Acc: 0.9143\n",
      "Epoch 033 | Train Loss: 0.2123 Acc: 0.9165 | Val Loss: 0.2109 Acc: 0.9124\n",
      "Epoch 034 | Train Loss: 0.2003 Acc: 0.9207 | Val Loss: 0.2198 Acc: 0.9082\n",
      "Epoch 035 | Train Loss: 0.1886 Acc: 0.9262 | Val Loss: 0.2133 Acc: 0.9191\n",
      "Epoch 036 | Train Loss: 0.1868 Acc: 0.9281 | Val Loss: 0.2130 Acc: 0.9209\n",
      "Epoch 037 | Train Loss: 0.1792 Acc: 0.9305 | Val Loss: 0.2034 Acc: 0.9233\n",
      "Epoch 038 | Train Loss: 0.1762 Acc: 0.9315 | Val Loss: 0.1962 Acc: 0.9233\n",
      "Epoch 039 | Train Loss: 0.1596 Acc: 0.9384 | Val Loss: 0.2163 Acc: 0.9233\n",
      "Epoch 040 | Train Loss: 0.1697 Acc: 0.9376 | Val Loss: 0.2064 Acc: 0.9215\n",
      "Epoch 041 | Train Loss: 0.1586 Acc: 0.9399 | Val Loss: 0.2065 Acc: 0.9281\n",
      "Epoch 042 | Train Loss: 0.1568 Acc: 0.9384 | Val Loss: 0.2029 Acc: 0.9239\n",
      "Epoch 043 | Train Loss: 0.1536 Acc: 0.9408 | Val Loss: 0.2029 Acc: 0.9287\n",
      "Epoch 044 | Train Loss: 0.1499 Acc: 0.9434 | Val Loss: 0.1919 Acc: 0.9330\n",
      "Epoch 045 | Train Loss: 0.1418 Acc: 0.9481 | Val Loss: 0.1820 Acc: 0.9293\n",
      "Epoch 046 | Train Loss: 0.1415 Acc: 0.9458 | Val Loss: 0.2280 Acc: 0.9124\n",
      "Epoch 047 | Train Loss: 0.1451 Acc: 0.9456 | Val Loss: 0.1871 Acc: 0.9336\n",
      "Epoch 048 | Train Loss: 0.1425 Acc: 0.9479 | Val Loss: 0.1822 Acc: 0.9336\n",
      "Epoch 049 | Train Loss: 0.1351 Acc: 0.9479 | Val Loss: 0.2472 Acc: 0.9124\n",
      "Epoch 050 | Train Loss: 0.1273 Acc: 0.9524 | Val Loss: 0.1954 Acc: 0.9269\n",
      "Epoch 051 | Train Loss: 0.1250 Acc: 0.9520 | Val Loss: 0.1736 Acc: 0.9396\n",
      "Epoch 052 | Train Loss: 0.1195 Acc: 0.9576 | Val Loss: 0.2163 Acc: 0.9245\n",
      "Epoch 053 | Train Loss: 0.1162 Acc: 0.9568 | Val Loss: 0.1814 Acc: 0.9360\n",
      "Epoch 054 | Train Loss: 0.1243 Acc: 0.9515 | Val Loss: 0.1796 Acc: 0.9384\n",
      "Epoch 055 | Train Loss: 0.1097 Acc: 0.9601 | Val Loss: 0.1895 Acc: 0.9354\n",
      "Epoch 056 | Train Loss: 0.1063 Acc: 0.9603 | Val Loss: 0.1777 Acc: 0.9336\n",
      "Epoch 057 | Train Loss: 0.1128 Acc: 0.9553 | Val Loss: 0.1929 Acc: 0.9360\n",
      "Epoch 058 | Train Loss: 0.1320 Acc: 0.9509 | Val Loss: 0.1590 Acc: 0.9408\n",
      "Epoch 059 | Train Loss: 0.1157 Acc: 0.9529 | Val Loss: 0.1697 Acc: 0.9390\n",
      "Epoch 060 | Train Loss: 0.1119 Acc: 0.9594 | Val Loss: 0.1487 Acc: 0.9366\n",
      "Epoch 001 | Train Loss: 0.6777 Acc: 0.5831 | Val Loss: 0.6730 Acc: 0.5888\n",
      "Epoch 002 | Train Loss: 0.6708 Acc: 0.5938 | Val Loss: 0.6731 Acc: 0.5894\n",
      "Epoch 003 | Train Loss: 0.6636 Acc: 0.6052 | Val Loss: 0.6646 Acc: 0.6021\n",
      "Epoch 004 | Train Loss: 0.6372 Acc: 0.6400 | Val Loss: 0.5984 Acc: 0.6963\n",
      "Epoch 005 | Train Loss: 0.5817 Acc: 0.7016 | Val Loss: 0.5901 Acc: 0.6914\n",
      "Epoch 006 | Train Loss: 0.5543 Acc: 0.7272 | Val Loss: 0.5581 Acc: 0.7168\n",
      "Epoch 007 | Train Loss: 0.5303 Acc: 0.7408 | Val Loss: 0.5332 Acc: 0.7385\n",
      "Epoch 008 | Train Loss: 0.5133 Acc: 0.7468 | Val Loss: 0.5467 Acc: 0.7180\n",
      "Epoch 009 | Train Loss: 0.5020 Acc: 0.7601 | Val Loss: 0.5186 Acc: 0.7440\n",
      "Epoch 010 | Train Loss: 0.4744 Acc: 0.7797 | Val Loss: 0.4782 Acc: 0.7645\n",
      "Epoch 011 | Train Loss: 0.4621 Acc: 0.7832 | Val Loss: 0.4578 Acc: 0.7778\n",
      "Epoch 012 | Train Loss: 0.4518 Acc: 0.7898 | Val Loss: 0.4403 Acc: 0.7911\n",
      "Epoch 013 | Train Loss: 0.4281 Acc: 0.7998 | Val Loss: 0.4281 Acc: 0.7911\n",
      "Epoch 014 | Train Loss: 0.4000 Acc: 0.8203 | Val Loss: 0.4258 Acc: 0.7989\n",
      "Epoch 015 | Train Loss: 0.3860 Acc: 0.8247 | Val Loss: 0.3637 Acc: 0.8436\n",
      "Epoch 016 | Train Loss: 0.3657 Acc: 0.8338 | Val Loss: 0.3623 Acc: 0.8436\n",
      "Epoch 017 | Train Loss: 0.3353 Acc: 0.8505 | Val Loss: 0.3724 Acc: 0.8436\n",
      "Epoch 018 | Train Loss: 0.3306 Acc: 0.8573 | Val Loss: 0.3724 Acc: 0.8285\n",
      "Epoch 019 | Train Loss: 0.2964 Acc: 0.8780 | Val Loss: 0.3220 Acc: 0.8635\n",
      "Epoch 020 | Train Loss: 0.2749 Acc: 0.8822 | Val Loss: 0.2835 Acc: 0.8841\n",
      "Epoch 021 | Train Loss: 0.2744 Acc: 0.8856 | Val Loss: 0.2688 Acc: 0.8859\n",
      "Epoch 022 | Train Loss: 0.2483 Acc: 0.8949 | Val Loss: 0.2737 Acc: 0.8853\n",
      "Epoch 023 | Train Loss: 0.2438 Acc: 0.8994 | Val Loss: 0.2533 Acc: 0.8907\n",
      "Epoch 024 | Train Loss: 0.2266 Acc: 0.9061 | Val Loss: 0.2537 Acc: 0.8961\n",
      "Epoch 025 | Train Loss: 0.2302 Acc: 0.9061 | Val Loss: 0.2585 Acc: 0.8937\n",
      "Epoch 026 | Train Loss: 0.2118 Acc: 0.9165 | Val Loss: 0.2415 Acc: 0.8986\n",
      "Epoch 027 | Train Loss: 0.2037 Acc: 0.9188 | Val Loss: 0.2734 Acc: 0.8841\n",
      "Epoch 028 | Train Loss: 0.1954 Acc: 0.9248 | Val Loss: 0.2429 Acc: 0.8992\n",
      "Epoch 029 | Train Loss: 0.1959 Acc: 0.9230 | Val Loss: 0.2170 Acc: 0.9136\n",
      "Epoch 030 | Train Loss: 0.1803 Acc: 0.9301 | Val Loss: 0.2146 Acc: 0.9136\n",
      "Epoch 031 | Train Loss: 0.1732 Acc: 0.9313 | Val Loss: 0.2101 Acc: 0.9179\n",
      "Epoch 032 | Train Loss: 0.1563 Acc: 0.9417 | Val Loss: 0.2689 Acc: 0.8901\n",
      "Epoch 033 | Train Loss: 0.1670 Acc: 0.9366 | Val Loss: 0.2113 Acc: 0.9118\n",
      "Epoch 034 | Train Loss: 0.1643 Acc: 0.9339 | Val Loss: 0.1992 Acc: 0.9221\n",
      "Epoch 035 | Train Loss: 0.1582 Acc: 0.9408 | Val Loss: 0.2082 Acc: 0.9209\n",
      "Epoch 036 | Train Loss: 0.1496 Acc: 0.9425 | Val Loss: 0.2032 Acc: 0.9197\n",
      "Epoch 037 | Train Loss: 0.1282 Acc: 0.9521 | Val Loss: 0.2128 Acc: 0.9227\n",
      "Epoch 038 | Train Loss: 0.1316 Acc: 0.9499 | Val Loss: 0.2164 Acc: 0.9112\n",
      "Epoch 039 | Train Loss: 0.1359 Acc: 0.9462 | Val Loss: 0.2465 Acc: 0.9088\n",
      "Epoch 040 | Train Loss: 0.1292 Acc: 0.9505 | Val Loss: 0.2189 Acc: 0.9124\n",
      "Epoch 041 | Train Loss: 0.1228 Acc: 0.9514 | Val Loss: 0.2088 Acc: 0.9203\n",
      "Epoch 042 | Train Loss: 0.1231 Acc: 0.9526 | Val Loss: 0.2226 Acc: 0.9179\n",
      "Epoch 043 | Train Loss: 0.1080 Acc: 0.9594 | Val Loss: 0.2059 Acc: 0.9239\n",
      "Epoch 044 | Train Loss: 0.1110 Acc: 0.9585 | Val Loss: 0.1908 Acc: 0.9336\n",
      "Epoch 045 | Train Loss: 0.1075 Acc: 0.9591 | Val Loss: 0.1909 Acc: 0.9300\n",
      "Epoch 046 | Train Loss: 0.1093 Acc: 0.9598 | Val Loss: 0.2156 Acc: 0.9215\n",
      "Epoch 047 | Train Loss: 0.1054 Acc: 0.9589 | Val Loss: 0.1936 Acc: 0.9281\n",
      "Epoch 048 | Train Loss: 0.1099 Acc: 0.9589 | Val Loss: 0.2410 Acc: 0.9185\n",
      "Epoch 049 | Train Loss: 0.0937 Acc: 0.9659 | Val Loss: 0.1692 Acc: 0.9348\n",
      "Epoch 050 | Train Loss: 0.0946 Acc: 0.9641 | Val Loss: 0.1917 Acc: 0.9306\n",
      "Epoch 051 | Train Loss: 0.0929 Acc: 0.9642 | Val Loss: 0.2116 Acc: 0.9275\n",
      "Epoch 052 | Train Loss: 0.1088 Acc: 0.9559 | Val Loss: 0.1799 Acc: 0.9366\n",
      "Epoch 053 | Train Loss: 0.0950 Acc: 0.9638 | Val Loss: 0.1524 Acc: 0.9463\n",
      "Epoch 054 | Train Loss: 0.0872 Acc: 0.9669 | Val Loss: 0.2030 Acc: 0.9257\n",
      "Epoch 055 | Train Loss: 0.0874 Acc: 0.9669 | Val Loss: 0.1615 Acc: 0.9408\n",
      "Epoch 056 | Train Loss: 0.0801 Acc: 0.9693 | Val Loss: 0.1653 Acc: 0.9414\n",
      "Epoch 057 | Train Loss: 0.0787 Acc: 0.9709 | Val Loss: 0.1616 Acc: 0.9378\n",
      "Epoch 058 | Train Loss: 0.0847 Acc: 0.9698 | Val Loss: 0.1610 Acc: 0.9378\n",
      "Epoch 059 | Train Loss: 0.0786 Acc: 0.9728 | Val Loss: 0.2026 Acc: 0.9306\n",
      "Epoch 060 | Train Loss: 0.0698 Acc: 0.9736 | Val Loss: 0.1743 Acc: 0.9378\n",
      "Epoch 001 | Train Loss: 0.6821 Acc: 0.5736 | Val Loss: 0.6768 Acc: 0.5906\n",
      "Epoch 002 | Train Loss: 0.6688 Acc: 0.5972 | Val Loss: 0.6629 Acc: 0.6051\n",
      "Epoch 003 | Train Loss: 0.6521 Acc: 0.6216 | Val Loss: 0.6275 Acc: 0.6600\n",
      "Epoch 004 | Train Loss: 0.6128 Acc: 0.6785 | Val Loss: 0.6159 Acc: 0.6703\n",
      "Epoch 005 | Train Loss: 0.5756 Acc: 0.7155 | Val Loss: 0.5627 Acc: 0.7150\n",
      "Epoch 006 | Train Loss: 0.5657 Acc: 0.7130 | Val Loss: 0.5446 Acc: 0.7252\n",
      "Epoch 007 | Train Loss: 0.5389 Acc: 0.7346 | Val Loss: 0.5354 Acc: 0.7264\n",
      "Epoch 008 | Train Loss: 0.5176 Acc: 0.7539 | Val Loss: 0.5080 Acc: 0.7500\n",
      "Epoch 009 | Train Loss: 0.5039 Acc: 0.7571 | Val Loss: 0.5068 Acc: 0.7524\n",
      "Epoch 010 | Train Loss: 0.4829 Acc: 0.7664 | Val Loss: 0.4773 Acc: 0.7645\n",
      "Epoch 011 | Train Loss: 0.4611 Acc: 0.7835 | Val Loss: 0.4840 Acc: 0.7530\n",
      "Epoch 012 | Train Loss: 0.4495 Acc: 0.7962 | Val Loss: 0.4260 Acc: 0.8068\n",
      "Epoch 013 | Train Loss: 0.4291 Acc: 0.8011 | Val Loss: 0.4224 Acc: 0.8092\n",
      "Epoch 014 | Train Loss: 0.4159 Acc: 0.8108 | Val Loss: 0.4146 Acc: 0.7983\n",
      "Epoch 015 | Train Loss: 0.3901 Acc: 0.8233 | Val Loss: 0.4102 Acc: 0.8104\n",
      "Epoch 016 | Train Loss: 0.3677 Acc: 0.8404 | Val Loss: 0.3954 Acc: 0.8128\n",
      "Epoch 017 | Train Loss: 0.3393 Acc: 0.8493 | Val Loss: 0.3732 Acc: 0.8333\n",
      "Epoch 018 | Train Loss: 0.3250 Acc: 0.8563 | Val Loss: 0.3674 Acc: 0.8400\n",
      "Epoch 019 | Train Loss: 0.3140 Acc: 0.8697 | Val Loss: 0.3250 Acc: 0.8557\n",
      "Epoch 020 | Train Loss: 0.3035 Acc: 0.8705 | Val Loss: 0.3227 Acc: 0.8605\n",
      "Epoch 021 | Train Loss: 0.2818 Acc: 0.8762 | Val Loss: 0.3025 Acc: 0.8653\n",
      "Epoch 022 | Train Loss: 0.2608 Acc: 0.8923 | Val Loss: 0.2869 Acc: 0.8829\n",
      "Epoch 023 | Train Loss: 0.2618 Acc: 0.8856 | Val Loss: 0.2708 Acc: 0.8829\n",
      "Epoch 024 | Train Loss: 0.2391 Acc: 0.9017 | Val Loss: 0.2629 Acc: 0.8889\n",
      "Epoch 025 | Train Loss: 0.2454 Acc: 0.9037 | Val Loss: 0.2522 Acc: 0.8949\n",
      "Epoch 026 | Train Loss: 0.2094 Acc: 0.9159 | Val Loss: 0.2480 Acc: 0.8943\n",
      "Epoch 027 | Train Loss: 0.2019 Acc: 0.9147 | Val Loss: 0.2794 Acc: 0.8871\n",
      "Epoch 028 | Train Loss: 0.2072 Acc: 0.9197 | Val Loss: 0.2283 Acc: 0.9082\n",
      "Epoch 029 | Train Loss: 0.1900 Acc: 0.9206 | Val Loss: 0.2271 Acc: 0.9064\n",
      "Epoch 030 | Train Loss: 0.1815 Acc: 0.9262 | Val Loss: 0.2420 Acc: 0.9016\n",
      "Epoch 031 | Train Loss: 0.1739 Acc: 0.9321 | Val Loss: 0.2443 Acc: 0.9118\n",
      "Epoch 032 | Train Loss: 0.1675 Acc: 0.9361 | Val Loss: 0.2334 Acc: 0.9112\n",
      "Epoch 033 | Train Loss: 0.1689 Acc: 0.9366 | Val Loss: 0.2462 Acc: 0.8925\n",
      "Epoch 034 | Train Loss: 0.1505 Acc: 0.9405 | Val Loss: 0.2506 Acc: 0.9016\n",
      "Epoch 035 | Train Loss: 0.1455 Acc: 0.9429 | Val Loss: 0.2291 Acc: 0.9149\n",
      "Epoch 036 | Train Loss: 0.1484 Acc: 0.9444 | Val Loss: 0.1995 Acc: 0.9185\n",
      "Epoch 037 | Train Loss: 0.1278 Acc: 0.9503 | Val Loss: 0.2222 Acc: 0.9173\n",
      "Epoch 038 | Train Loss: 0.1403 Acc: 0.9472 | Val Loss: 0.2119 Acc: 0.9179\n",
      "Epoch 039 | Train Loss: 0.1278 Acc: 0.9490 | Val Loss: 0.2394 Acc: 0.9070\n",
      "Epoch 040 | Train Loss: 0.1290 Acc: 0.9494 | Val Loss: 0.1956 Acc: 0.9221\n",
      "Epoch 041 | Train Loss: 0.1221 Acc: 0.9544 | Val Loss: 0.1831 Acc: 0.9348\n",
      "Epoch 042 | Train Loss: 0.1286 Acc: 0.9503 | Val Loss: 0.1845 Acc: 0.9275\n",
      "Epoch 043 | Train Loss: 0.1235 Acc: 0.9533 | Val Loss: 0.1892 Acc: 0.9251\n",
      "Epoch 044 | Train Loss: 0.1130 Acc: 0.9574 | Val Loss: 0.2229 Acc: 0.9221\n",
      "Epoch 045 | Train Loss: 0.1155 Acc: 0.9550 | Val Loss: 0.2160 Acc: 0.9251\n",
      "Epoch 046 | Train Loss: 0.1100 Acc: 0.9624 | Val Loss: 0.1932 Acc: 0.9300\n",
      "Epoch 047 | Train Loss: 0.1003 Acc: 0.9604 | Val Loss: 0.1967 Acc: 0.9300\n",
      "Epoch 048 | Train Loss: 0.0903 Acc: 0.9647 | Val Loss: 0.2091 Acc: 0.9203\n",
      "Epoch 049 | Train Loss: 0.0944 Acc: 0.9624 | Val Loss: 0.1917 Acc: 0.9300\n",
      "Epoch 050 | Train Loss: 0.0903 Acc: 0.9647 | Val Loss: 0.1880 Acc: 0.9306\n",
      "Epoch 051 | Train Loss: 0.0923 Acc: 0.9659 | Val Loss: 0.1822 Acc: 0.9336\n",
      "Epoch 052 | Train Loss: 0.0948 Acc: 0.9641 | Val Loss: 0.1819 Acc: 0.9257\n",
      "Epoch 053 | Train Loss: 0.0901 Acc: 0.9648 | Val Loss: 0.1726 Acc: 0.9378\n",
      "Epoch 054 | Train Loss: 0.0826 Acc: 0.9692 | Val Loss: 0.1541 Acc: 0.9457\n",
      "Epoch 055 | Train Loss: 0.0843 Acc: 0.9693 | Val Loss: 0.2006 Acc: 0.9275\n",
      "Epoch 056 | Train Loss: 0.0835 Acc: 0.9681 | Val Loss: 0.1727 Acc: 0.9414\n",
      "Epoch 057 | Train Loss: 0.0811 Acc: 0.9710 | Val Loss: 0.1940 Acc: 0.9300\n",
      "Epoch 058 | Train Loss: 0.0953 Acc: 0.9635 | Val Loss: 0.2631 Acc: 0.9022\n",
      "Epoch 059 | Train Loss: 0.0834 Acc: 0.9698 | Val Loss: 0.1628 Acc: 0.9420\n",
      "Epoch 060 | Train Loss: 0.0804 Acc: 0.9733 | Val Loss: 0.1745 Acc: 0.9408\n",
      "Iteration 34/40 | Best Val Loss: 0.1122 | Iter Time: 231.12s | Total Time: 138.67 min\n",
      "Epoch 001 | Train Loss: 0.6804 Acc: 0.5775 | Val Loss: 0.6693 Acc: 0.5924\n",
      "Epoch 002 | Train Loss: 0.6662 Acc: 0.6101 | Val Loss: 0.6393 Acc: 0.6479\n",
      "Epoch 003 | Train Loss: 0.5995 Acc: 0.6882 | Val Loss: 0.5899 Acc: 0.6908\n",
      "Epoch 004 | Train Loss: 0.5694 Acc: 0.7184 | Val Loss: 0.5565 Acc: 0.7144\n",
      "Epoch 005 | Train Loss: 0.5413 Acc: 0.7338 | Val Loss: 0.5254 Acc: 0.7319\n",
      "Epoch 006 | Train Loss: 0.5166 Acc: 0.7486 | Val Loss: 0.5136 Acc: 0.7458\n",
      "Epoch 007 | Train Loss: 0.5000 Acc: 0.7595 | Val Loss: 0.4777 Acc: 0.7699\n",
      "Epoch 008 | Train Loss: 0.4819 Acc: 0.7676 | Val Loss: 0.4597 Acc: 0.7844\n",
      "Epoch 009 | Train Loss: 0.4519 Acc: 0.7856 | Val Loss: 0.4599 Acc: 0.7808\n",
      "Epoch 010 | Train Loss: 0.4227 Acc: 0.8084 | Val Loss: 0.4223 Acc: 0.7893\n",
      "Epoch 011 | Train Loss: 0.4127 Acc: 0.8120 | Val Loss: 0.3673 Acc: 0.8400\n",
      "Epoch 012 | Train Loss: 0.3820 Acc: 0.8339 | Val Loss: 0.4163 Acc: 0.8074\n",
      "Epoch 013 | Train Loss: 0.3616 Acc: 0.8415 | Val Loss: 0.3564 Acc: 0.8394\n",
      "Epoch 014 | Train Loss: 0.3450 Acc: 0.8505 | Val Loss: 0.3396 Acc: 0.8533\n",
      "Epoch 015 | Train Loss: 0.3116 Acc: 0.8695 | Val Loss: 0.2947 Acc: 0.8798\n",
      "Epoch 016 | Train Loss: 0.2946 Acc: 0.8763 | Val Loss: 0.2698 Acc: 0.8937\n",
      "Epoch 017 | Train Loss: 0.2880 Acc: 0.8812 | Val Loss: 0.2965 Acc: 0.8756\n",
      "Epoch 018 | Train Loss: 0.2763 Acc: 0.8840 | Val Loss: 0.3084 Acc: 0.8726\n",
      "Epoch 019 | Train Loss: 0.2705 Acc: 0.8904 | Val Loss: 0.2424 Acc: 0.9034\n",
      "Epoch 020 | Train Loss: 0.2450 Acc: 0.8973 | Val Loss: 0.2310 Acc: 0.9076\n",
      "Epoch 021 | Train Loss: 0.2270 Acc: 0.9127 | Val Loss: 0.2183 Acc: 0.9136\n",
      "Epoch 022 | Train Loss: 0.2334 Acc: 0.9099 | Val Loss: 0.2096 Acc: 0.9155\n",
      "Epoch 023 | Train Loss: 0.1998 Acc: 0.9212 | Val Loss: 0.2007 Acc: 0.9269\n",
      "Epoch 024 | Train Loss: 0.2208 Acc: 0.9130 | Val Loss: 0.2066 Acc: 0.9239\n",
      "Epoch 025 | Train Loss: 0.1959 Acc: 0.9219 | Val Loss: 0.2091 Acc: 0.9239\n",
      "Epoch 026 | Train Loss: 0.1869 Acc: 0.9254 | Val Loss: 0.1909 Acc: 0.9239\n",
      "Epoch 027 | Train Loss: 0.1809 Acc: 0.9304 | Val Loss: 0.2210 Acc: 0.9191\n",
      "Epoch 028 | Train Loss: 0.1637 Acc: 0.9343 | Val Loss: 0.1836 Acc: 0.9293\n",
      "Epoch 029 | Train Loss: 0.1723 Acc: 0.9330 | Val Loss: 0.2131 Acc: 0.9257\n",
      "Epoch 030 | Train Loss: 0.1661 Acc: 0.9354 | Val Loss: 0.1891 Acc: 0.9354\n",
      "Epoch 031 | Train Loss: 0.1610 Acc: 0.9399 | Val Loss: 0.1686 Acc: 0.9324\n",
      "Epoch 032 | Train Loss: 0.1526 Acc: 0.9390 | Val Loss: 0.1873 Acc: 0.9318\n",
      "Epoch 033 | Train Loss: 0.1490 Acc: 0.9438 | Val Loss: 0.1888 Acc: 0.9342\n",
      "Epoch 034 | Train Loss: 0.1409 Acc: 0.9446 | Val Loss: 0.1701 Acc: 0.9396\n",
      "Epoch 035 | Train Loss: 0.1397 Acc: 0.9470 | Val Loss: 0.1560 Acc: 0.9408\n",
      "Epoch 036 | Train Loss: 0.1340 Acc: 0.9505 | Val Loss: 0.1512 Acc: 0.9432\n",
      "Epoch 037 | Train Loss: 0.1422 Acc: 0.9459 | Val Loss: 0.1632 Acc: 0.9378\n",
      "Epoch 038 | Train Loss: 0.1246 Acc: 0.9536 | Val Loss: 0.1758 Acc: 0.9408\n",
      "Epoch 039 | Train Loss: 0.1287 Acc: 0.9478 | Val Loss: 0.1447 Acc: 0.9469\n",
      "Epoch 040 | Train Loss: 0.1212 Acc: 0.9547 | Val Loss: 0.1723 Acc: 0.9457\n",
      "Epoch 041 | Train Loss: 0.1251 Acc: 0.9524 | Val Loss: 0.1441 Acc: 0.9408\n",
      "Epoch 042 | Train Loss: 0.1098 Acc: 0.9579 | Val Loss: 0.1364 Acc: 0.9541\n",
      "Epoch 043 | Train Loss: 0.1110 Acc: 0.9577 | Val Loss: 0.1447 Acc: 0.9450\n",
      "Epoch 044 | Train Loss: 0.1134 Acc: 0.9580 | Val Loss: 0.1379 Acc: 0.9517\n",
      "Epoch 045 | Train Loss: 0.1192 Acc: 0.9559 | Val Loss: 0.1388 Acc: 0.9469\n",
      "Epoch 046 | Train Loss: 0.1029 Acc: 0.9615 | Val Loss: 0.1611 Acc: 0.9444\n",
      "Epoch 047 | Train Loss: 0.1126 Acc: 0.9574 | Val Loss: 0.1345 Acc: 0.9517\n",
      "Epoch 048 | Train Loss: 0.1025 Acc: 0.9632 | Val Loss: 0.1337 Acc: 0.9547\n",
      "Epoch 049 | Train Loss: 0.1008 Acc: 0.9607 | Val Loss: 0.1386 Acc: 0.9559\n",
      "Epoch 050 | Train Loss: 0.0982 Acc: 0.9665 | Val Loss: 0.2110 Acc: 0.9354\n",
      "Epoch 051 | Train Loss: 0.1050 Acc: 0.9597 | Val Loss: 0.1487 Acc: 0.9469\n",
      "Epoch 052 | Train Loss: 0.0857 Acc: 0.9674 | Val Loss: 0.1487 Acc: 0.9511\n",
      "Epoch 053 | Train Loss: 0.1030 Acc: 0.9606 | Val Loss: 0.1227 Acc: 0.9589\n",
      "Epoch 054 | Train Loss: 0.0903 Acc: 0.9645 | Val Loss: 0.1392 Acc: 0.9547\n",
      "Epoch 055 | Train Loss: 0.0945 Acc: 0.9651 | Val Loss: 0.1659 Acc: 0.9450\n",
      "Epoch 056 | Train Loss: 0.0961 Acc: 0.9648 | Val Loss: 0.1231 Acc: 0.9571\n",
      "Epoch 057 | Train Loss: 0.0887 Acc: 0.9657 | Val Loss: 0.1366 Acc: 0.9535\n",
      "Epoch 058 | Train Loss: 0.0887 Acc: 0.9657 | Val Loss: 0.1200 Acc: 0.9595\n",
      "Epoch 059 | Train Loss: 0.0838 Acc: 0.9692 | Val Loss: 0.1207 Acc: 0.9607\n",
      "Epoch 060 | Train Loss: 0.0865 Acc: 0.9672 | Val Loss: 0.1607 Acc: 0.9402\n",
      "Epoch 001 | Train Loss: 0.6807 Acc: 0.5704 | Val Loss: 0.6837 Acc: 0.5537\n",
      "Epoch 002 | Train Loss: 0.6669 Acc: 0.6009 | Val Loss: 0.6399 Acc: 0.6467\n",
      "Epoch 003 | Train Loss: 0.6100 Acc: 0.6754 | Val Loss: 0.5819 Acc: 0.7053\n",
      "Epoch 004 | Train Loss: 0.5683 Acc: 0.7116 | Val Loss: 0.5705 Acc: 0.6969\n",
      "Epoch 005 | Train Loss: 0.5516 Acc: 0.7287 | Val Loss: 0.5402 Acc: 0.7289\n",
      "Epoch 006 | Train Loss: 0.5259 Acc: 0.7441 | Val Loss: 0.5294 Acc: 0.7325\n",
      "Epoch 007 | Train Loss: 0.5058 Acc: 0.7521 | Val Loss: 0.5282 Acc: 0.7301\n",
      "Epoch 008 | Train Loss: 0.4917 Acc: 0.7685 | Val Loss: 0.4913 Acc: 0.7560\n",
      "Epoch 009 | Train Loss: 0.4731 Acc: 0.7756 | Val Loss: 0.4636 Acc: 0.7669\n",
      "Epoch 010 | Train Loss: 0.4490 Acc: 0.7912 | Val Loss: 0.4190 Acc: 0.7977\n",
      "Epoch 011 | Train Loss: 0.4252 Acc: 0.8046 | Val Loss: 0.4205 Acc: 0.8013\n",
      "Epoch 012 | Train Loss: 0.4128 Acc: 0.8108 | Val Loss: 0.4099 Acc: 0.8007\n",
      "Epoch 013 | Train Loss: 0.3935 Acc: 0.8247 | Val Loss: 0.3892 Acc: 0.8231\n",
      "Epoch 014 | Train Loss: 0.3794 Acc: 0.8309 | Val Loss: 0.3896 Acc: 0.8170\n",
      "Epoch 015 | Train Loss: 0.3675 Acc: 0.8386 | Val Loss: 0.3783 Acc: 0.8249\n",
      "Epoch 016 | Train Loss: 0.3553 Acc: 0.8424 | Val Loss: 0.3650 Acc: 0.8430\n",
      "Epoch 017 | Train Loss: 0.3395 Acc: 0.8490 | Val Loss: 0.3487 Acc: 0.8454\n",
      "Epoch 018 | Train Loss: 0.3202 Acc: 0.8659 | Val Loss: 0.3201 Acc: 0.8587\n",
      "Epoch 019 | Train Loss: 0.3150 Acc: 0.8689 | Val Loss: 0.4022 Acc: 0.8255\n",
      "Epoch 020 | Train Loss: 0.3018 Acc: 0.8715 | Val Loss: 0.3305 Acc: 0.8496\n",
      "Epoch 021 | Train Loss: 0.2871 Acc: 0.8786 | Val Loss: 0.2975 Acc: 0.8762\n",
      "Epoch 022 | Train Loss: 0.2720 Acc: 0.8819 | Val Loss: 0.2653 Acc: 0.8889\n",
      "Epoch 023 | Train Loss: 0.2494 Acc: 0.8973 | Val Loss: 0.2819 Acc: 0.8792\n",
      "Epoch 024 | Train Loss: 0.2566 Acc: 0.8914 | Val Loss: 0.3021 Acc: 0.8720\n",
      "Epoch 025 | Train Loss: 0.2382 Acc: 0.9013 | Val Loss: 0.2596 Acc: 0.8961\n",
      "Epoch 026 | Train Loss: 0.2260 Acc: 0.9071 | Val Loss: 0.2410 Acc: 0.9028\n",
      "Epoch 027 | Train Loss: 0.2144 Acc: 0.9138 | Val Loss: 0.2781 Acc: 0.8841\n",
      "Epoch 028 | Train Loss: 0.2235 Acc: 0.9108 | Val Loss: 0.2409 Acc: 0.9004\n",
      "Epoch 029 | Train Loss: 0.2178 Acc: 0.9087 | Val Loss: 0.2357 Acc: 0.9016\n",
      "Epoch 030 | Train Loss: 0.2008 Acc: 0.9180 | Val Loss: 0.2532 Acc: 0.8925\n",
      "Epoch 031 | Train Loss: 0.2007 Acc: 0.9225 | Val Loss: 0.2169 Acc: 0.9118\n",
      "Epoch 032 | Train Loss: 0.1836 Acc: 0.9296 | Val Loss: 0.2343 Acc: 0.9064\n",
      "Epoch 033 | Train Loss: 0.1824 Acc: 0.9290 | Val Loss: 0.2034 Acc: 0.9167\n",
      "Epoch 034 | Train Loss: 0.1705 Acc: 0.9357 | Val Loss: 0.2158 Acc: 0.9088\n",
      "Epoch 035 | Train Loss: 0.1744 Acc: 0.9305 | Val Loss: 0.2204 Acc: 0.9143\n",
      "Epoch 036 | Train Loss: 0.1713 Acc: 0.9302 | Val Loss: 0.2112 Acc: 0.9161\n",
      "Epoch 037 | Train Loss: 0.1687 Acc: 0.9337 | Val Loss: 0.2382 Acc: 0.9028\n",
      "Epoch 038 | Train Loss: 0.1630 Acc: 0.9366 | Val Loss: 0.2617 Acc: 0.8961\n",
      "Epoch 039 | Train Loss: 0.1498 Acc: 0.9419 | Val Loss: 0.2055 Acc: 0.9293\n",
      "Epoch 040 | Train Loss: 0.1433 Acc: 0.9476 | Val Loss: 0.2021 Acc: 0.9227\n",
      "Epoch 041 | Train Loss: 0.1545 Acc: 0.9416 | Val Loss: 0.1857 Acc: 0.9269\n",
      "Epoch 042 | Train Loss: 0.1383 Acc: 0.9469 | Val Loss: 0.2084 Acc: 0.9179\n",
      "Epoch 043 | Train Loss: 0.1329 Acc: 0.9482 | Val Loss: 0.1755 Acc: 0.9275\n",
      "Epoch 044 | Train Loss: 0.1398 Acc: 0.9482 | Val Loss: 0.2137 Acc: 0.9118\n",
      "Epoch 045 | Train Loss: 0.1314 Acc: 0.9505 | Val Loss: 0.2003 Acc: 0.9275\n",
      "Epoch 046 | Train Loss: 0.1314 Acc: 0.9493 | Val Loss: 0.1834 Acc: 0.9372\n",
      "Epoch 047 | Train Loss: 0.1314 Acc: 0.9496 | Val Loss: 0.1749 Acc: 0.9306\n",
      "Epoch 048 | Train Loss: 0.1157 Acc: 0.9598 | Val Loss: 0.1684 Acc: 0.9312\n",
      "Epoch 049 | Train Loss: 0.1127 Acc: 0.9577 | Val Loss: 0.1496 Acc: 0.9426\n",
      "Epoch 050 | Train Loss: 0.1158 Acc: 0.9527 | Val Loss: 0.1884 Acc: 0.9306\n",
      "Epoch 051 | Train Loss: 0.1070 Acc: 0.9583 | Val Loss: 0.1672 Acc: 0.9318\n",
      "Epoch 052 | Train Loss: 0.1137 Acc: 0.9571 | Val Loss: 0.1920 Acc: 0.9300\n",
      "Epoch 053 | Train Loss: 0.1020 Acc: 0.9632 | Val Loss: 0.1627 Acc: 0.9372\n",
      "Epoch 054 | Train Loss: 0.0950 Acc: 0.9647 | Val Loss: 0.2410 Acc: 0.9185\n",
      "Epoch 055 | Train Loss: 0.1026 Acc: 0.9616 | Val Loss: 0.1419 Acc: 0.9475\n",
      "Epoch 056 | Train Loss: 0.0917 Acc: 0.9648 | Val Loss: 0.1863 Acc: 0.9354\n",
      "Epoch 057 | Train Loss: 0.0991 Acc: 0.9630 | Val Loss: 0.1860 Acc: 0.9342\n",
      "Epoch 058 | Train Loss: 0.1068 Acc: 0.9612 | Val Loss: 0.1510 Acc: 0.9432\n",
      "Epoch 059 | Train Loss: 0.0958 Acc: 0.9650 | Val Loss: 0.1602 Acc: 0.9426\n",
      "Epoch 060 | Train Loss: 0.0940 Acc: 0.9654 | Val Loss: 0.1599 Acc: 0.9426\n",
      "Epoch 001 | Train Loss: 0.6843 Acc: 0.5673 | Val Loss: 0.6771 Acc: 0.5857\n",
      "Epoch 002 | Train Loss: 0.6737 Acc: 0.5932 | Val Loss: 0.6689 Acc: 0.5996\n",
      "Epoch 003 | Train Loss: 0.6673 Acc: 0.6029 | Val Loss: 0.6674 Acc: 0.5990\n",
      "Epoch 004 | Train Loss: 0.6614 Acc: 0.6115 | Val Loss: 0.6581 Acc: 0.6129\n",
      "Epoch 005 | Train Loss: 0.6407 Acc: 0.6379 | Val Loss: 0.6112 Acc: 0.6902\n",
      "Epoch 006 | Train Loss: 0.5923 Acc: 0.6949 | Val Loss: 0.5758 Acc: 0.7132\n",
      "Epoch 007 | Train Loss: 0.5553 Acc: 0.7220 | Val Loss: 0.5780 Acc: 0.7144\n",
      "Epoch 008 | Train Loss: 0.5259 Acc: 0.7492 | Val Loss: 0.5200 Acc: 0.7373\n",
      "Epoch 009 | Train Loss: 0.5008 Acc: 0.7614 | Val Loss: 0.4974 Acc: 0.7536\n",
      "Epoch 010 | Train Loss: 0.4762 Acc: 0.7777 | Val Loss: 0.4665 Acc: 0.7669\n",
      "Epoch 011 | Train Loss: 0.4469 Acc: 0.7900 | Val Loss: 0.4580 Acc: 0.7717\n",
      "Epoch 012 | Train Loss: 0.4225 Acc: 0.8081 | Val Loss: 0.4193 Acc: 0.7947\n",
      "Epoch 013 | Train Loss: 0.3945 Acc: 0.8226 | Val Loss: 0.4179 Acc: 0.8037\n",
      "Epoch 014 | Train Loss: 0.3747 Acc: 0.8335 | Val Loss: 0.3923 Acc: 0.8231\n",
      "Epoch 015 | Train Loss: 0.3563 Acc: 0.8415 | Val Loss: 0.3683 Acc: 0.8382\n",
      "Epoch 016 | Train Loss: 0.3390 Acc: 0.8510 | Val Loss: 0.3431 Acc: 0.8539\n",
      "Epoch 017 | Train Loss: 0.3159 Acc: 0.8682 | Val Loss: 0.3680 Acc: 0.8382\n",
      "Epoch 018 | Train Loss: 0.2895 Acc: 0.8763 | Val Loss: 0.3333 Acc: 0.8629\n",
      "Epoch 019 | Train Loss: 0.2832 Acc: 0.8803 | Val Loss: 0.3191 Acc: 0.8575\n",
      "Epoch 020 | Train Loss: 0.2605 Acc: 0.8922 | Val Loss: 0.2731 Acc: 0.8883\n",
      "Epoch 021 | Train Loss: 0.2518 Acc: 0.8940 | Val Loss: 0.3899 Acc: 0.8309\n",
      "Epoch 022 | Train Loss: 0.2445 Acc: 0.9028 | Val Loss: 0.2762 Acc: 0.8847\n",
      "Epoch 023 | Train Loss: 0.2226 Acc: 0.9109 | Val Loss: 0.2504 Acc: 0.8955\n",
      "Epoch 024 | Train Loss: 0.2160 Acc: 0.9129 | Val Loss: 0.2554 Acc: 0.8998\n",
      "Epoch 025 | Train Loss: 0.2099 Acc: 0.9156 | Val Loss: 0.2436 Acc: 0.8955\n",
      "Epoch 026 | Train Loss: 0.1928 Acc: 0.9227 | Val Loss: 0.2391 Acc: 0.9028\n",
      "Epoch 027 | Train Loss: 0.1766 Acc: 0.9299 | Val Loss: 0.2199 Acc: 0.9136\n",
      "Epoch 028 | Train Loss: 0.1679 Acc: 0.9339 | Val Loss: 0.2269 Acc: 0.9136\n",
      "Epoch 029 | Train Loss: 0.1734 Acc: 0.9305 | Val Loss: 0.2366 Acc: 0.9034\n",
      "Epoch 030 | Train Loss: 0.1584 Acc: 0.9367 | Val Loss: 0.1997 Acc: 0.9239\n",
      "Epoch 031 | Train Loss: 0.1598 Acc: 0.9390 | Val Loss: 0.2248 Acc: 0.9088\n",
      "Epoch 032 | Train Loss: 0.1493 Acc: 0.9444 | Val Loss: 0.1978 Acc: 0.9227\n",
      "Epoch 033 | Train Loss: 0.1383 Acc: 0.9465 | Val Loss: 0.2397 Acc: 0.9088\n",
      "Epoch 034 | Train Loss: 0.1454 Acc: 0.9435 | Val Loss: 0.1848 Acc: 0.9348\n",
      "Epoch 035 | Train Loss: 0.1381 Acc: 0.9461 | Val Loss: 0.2031 Acc: 0.9251\n",
      "Epoch 036 | Train Loss: 0.1150 Acc: 0.9567 | Val Loss: 0.1983 Acc: 0.9221\n",
      "Epoch 037 | Train Loss: 0.1238 Acc: 0.9535 | Val Loss: 0.2073 Acc: 0.9191\n",
      "Epoch 038 | Train Loss: 0.1258 Acc: 0.9532 | Val Loss: 0.1838 Acc: 0.9330\n",
      "Epoch 039 | Train Loss: 0.1111 Acc: 0.9565 | Val Loss: 0.2293 Acc: 0.9173\n",
      "Epoch 040 | Train Loss: 0.1149 Acc: 0.9576 | Val Loss: 0.2128 Acc: 0.9330\n",
      "Epoch 041 | Train Loss: 0.1110 Acc: 0.9586 | Val Loss: 0.1842 Acc: 0.9293\n",
      "Epoch 042 | Train Loss: 0.1016 Acc: 0.9623 | Val Loss: 0.1984 Acc: 0.9293\n",
      "Epoch 043 | Train Loss: 0.1014 Acc: 0.9612 | Val Loss: 0.1971 Acc: 0.9330\n",
      "Epoch 044 | Train Loss: 0.1011 Acc: 0.9626 | Val Loss: 0.1897 Acc: 0.9275\n",
      "Epoch 045 | Train Loss: 0.1004 Acc: 0.9615 | Val Loss: 0.1652 Acc: 0.9414\n",
      "Epoch 046 | Train Loss: 0.0942 Acc: 0.9624 | Val Loss: 0.1993 Acc: 0.9318\n",
      "Epoch 047 | Train Loss: 0.0932 Acc: 0.9644 | Val Loss: 0.1873 Acc: 0.9342\n",
      "Epoch 048 | Train Loss: 0.0849 Acc: 0.9680 | Val Loss: 0.1710 Acc: 0.9414\n",
      "Epoch 049 | Train Loss: 0.0955 Acc: 0.9647 | Val Loss: 0.1608 Acc: 0.9372\n",
      "Epoch 050 | Train Loss: 0.0800 Acc: 0.9690 | Val Loss: 0.1702 Acc: 0.9402\n",
      "Epoch 051 | Train Loss: 0.0779 Acc: 0.9724 | Val Loss: 0.2176 Acc: 0.9239\n",
      "Epoch 052 | Train Loss: 0.0828 Acc: 0.9709 | Val Loss: 0.1721 Acc: 0.9378\n",
      "Epoch 053 | Train Loss: 0.0858 Acc: 0.9668 | Val Loss: 0.2125 Acc: 0.9191\n",
      "Epoch 054 | Train Loss: 0.0835 Acc: 0.9675 | Val Loss: 0.1668 Acc: 0.9402\n",
      "Epoch 055 | Train Loss: 0.0783 Acc: 0.9706 | Val Loss: 0.2079 Acc: 0.9336\n",
      "Epoch 056 | Train Loss: 0.0748 Acc: 0.9734 | Val Loss: 0.2059 Acc: 0.9360\n",
      "Epoch 057 | Train Loss: 0.0734 Acc: 0.9724 | Val Loss: 0.2086 Acc: 0.9221\n",
      "Epoch 058 | Train Loss: 0.0748 Acc: 0.9754 | Val Loss: 0.1692 Acc: 0.9457\n",
      "Epoch 059 | Train Loss: 0.0749 Acc: 0.9733 | Val Loss: 0.1929 Acc: 0.9360\n",
      "Early stopping triggered.\n",
      "Epoch 001 | Train Loss: 0.6802 Acc: 0.5790 | Val Loss: 0.6773 Acc: 0.5833\n",
      "Epoch 002 | Train Loss: 0.6709 Acc: 0.5960 | Val Loss: 0.6613 Acc: 0.6184\n",
      "Epoch 003 | Train Loss: 0.6333 Acc: 0.6527 | Val Loss: 0.6067 Acc: 0.6721\n",
      "Epoch 004 | Train Loss: 0.5778 Acc: 0.7143 | Val Loss: 0.5677 Acc: 0.7222\n",
      "Epoch 005 | Train Loss: 0.5509 Acc: 0.7329 | Val Loss: 0.5415 Acc: 0.7295\n",
      "Epoch 006 | Train Loss: 0.5187 Acc: 0.7527 | Val Loss: 0.5476 Acc: 0.7440\n",
      "Epoch 007 | Train Loss: 0.5090 Acc: 0.7549 | Val Loss: 0.5003 Acc: 0.7560\n",
      "Epoch 008 | Train Loss: 0.4757 Acc: 0.7762 | Val Loss: 0.4906 Acc: 0.7615\n",
      "Epoch 009 | Train Loss: 0.4517 Acc: 0.7894 | Val Loss: 0.4311 Acc: 0.7886\n",
      "Epoch 010 | Train Loss: 0.4344 Acc: 0.7977 | Val Loss: 0.4126 Acc: 0.7923\n",
      "Epoch 011 | Train Loss: 0.4101 Acc: 0.8167 | Val Loss: 0.3774 Acc: 0.8213\n",
      "Epoch 012 | Train Loss: 0.3825 Acc: 0.8286 | Val Loss: 0.3757 Acc: 0.8333\n",
      "Epoch 013 | Train Loss: 0.3716 Acc: 0.8371 | Val Loss: 0.3487 Acc: 0.8394\n",
      "Epoch 014 | Train Loss: 0.3527 Acc: 0.8464 | Val Loss: 0.3573 Acc: 0.8412\n",
      "Epoch 015 | Train Loss: 0.3332 Acc: 0.8591 | Val Loss: 0.3271 Acc: 0.8617\n",
      "Epoch 016 | Train Loss: 0.3027 Acc: 0.8703 | Val Loss: 0.2872 Acc: 0.8792\n",
      "Epoch 017 | Train Loss: 0.2814 Acc: 0.8831 | Val Loss: 0.2946 Acc: 0.8762\n",
      "Epoch 018 | Train Loss: 0.2799 Acc: 0.8834 | Val Loss: 0.3179 Acc: 0.8635\n",
      "Epoch 019 | Train Loss: 0.2610 Acc: 0.8907 | Val Loss: 0.2725 Acc: 0.8859\n",
      "Epoch 020 | Train Loss: 0.2421 Acc: 0.9003 | Val Loss: 0.2348 Acc: 0.9016\n",
      "Epoch 021 | Train Loss: 0.2346 Acc: 0.9076 | Val Loss: 0.3199 Acc: 0.8671\n",
      "Epoch 022 | Train Loss: 0.2253 Acc: 0.9141 | Val Loss: 0.2399 Acc: 0.9064\n",
      "Epoch 023 | Train Loss: 0.2018 Acc: 0.9206 | Val Loss: 0.2672 Acc: 0.8907\n",
      "Epoch 024 | Train Loss: 0.2030 Acc: 0.9195 | Val Loss: 0.2220 Acc: 0.9094\n",
      "Epoch 025 | Train Loss: 0.1918 Acc: 0.9260 | Val Loss: 0.2197 Acc: 0.9179\n",
      "Epoch 026 | Train Loss: 0.1878 Acc: 0.9289 | Val Loss: 0.2043 Acc: 0.9221\n",
      "Epoch 027 | Train Loss: 0.1807 Acc: 0.9293 | Val Loss: 0.2087 Acc: 0.9209\n",
      "Epoch 028 | Train Loss: 0.1731 Acc: 0.9301 | Val Loss: 0.2136 Acc: 0.9124\n",
      "Epoch 029 | Train Loss: 0.1599 Acc: 0.9366 | Val Loss: 0.1985 Acc: 0.9215\n",
      "Epoch 030 | Train Loss: 0.1533 Acc: 0.9384 | Val Loss: 0.2111 Acc: 0.9185\n",
      "Epoch 031 | Train Loss: 0.1508 Acc: 0.9426 | Val Loss: 0.2024 Acc: 0.9215\n",
      "Epoch 032 | Train Loss: 0.1501 Acc: 0.9428 | Val Loss: 0.1996 Acc: 0.9197\n",
      "Epoch 033 | Train Loss: 0.1330 Acc: 0.9476 | Val Loss: 0.1774 Acc: 0.9402\n",
      "Epoch 034 | Train Loss: 0.1356 Acc: 0.9476 | Val Loss: 0.2077 Acc: 0.9233\n",
      "Epoch 035 | Train Loss: 0.1323 Acc: 0.9512 | Val Loss: 0.1790 Acc: 0.9342\n",
      "Epoch 036 | Train Loss: 0.1363 Acc: 0.9481 | Val Loss: 0.1891 Acc: 0.9269\n",
      "Epoch 037 | Train Loss: 0.1179 Acc: 0.9549 | Val Loss: 0.1774 Acc: 0.9420\n",
      "Epoch 038 | Train Loss: 0.1181 Acc: 0.9552 | Val Loss: 0.1911 Acc: 0.9275\n",
      "Epoch 039 | Train Loss: 0.1253 Acc: 0.9524 | Val Loss: 0.1973 Acc: 0.9281\n",
      "Epoch 040 | Train Loss: 0.1214 Acc: 0.9517 | Val Loss: 0.1938 Acc: 0.9263\n",
      "Epoch 041 | Train Loss: 0.1108 Acc: 0.9594 | Val Loss: 0.1821 Acc: 0.9342\n",
      "Epoch 042 | Train Loss: 0.1127 Acc: 0.9579 | Val Loss: 0.2159 Acc: 0.9330\n",
      "Epoch 043 | Train Loss: 0.1217 Acc: 0.9539 | Val Loss: 0.1614 Acc: 0.9457\n",
      "Epoch 044 | Train Loss: 0.1067 Acc: 0.9604 | Val Loss: 0.1475 Acc: 0.9505\n",
      "Epoch 045 | Train Loss: 0.0933 Acc: 0.9627 | Val Loss: 0.1817 Acc: 0.9312\n",
      "Epoch 046 | Train Loss: 0.0895 Acc: 0.9693 | Val Loss: 0.1698 Acc: 0.9384\n",
      "Epoch 047 | Train Loss: 0.0967 Acc: 0.9616 | Val Loss: 0.2186 Acc: 0.9263\n",
      "Epoch 048 | Train Loss: 0.0975 Acc: 0.9638 | Val Loss: 0.1972 Acc: 0.9390\n",
      "Epoch 049 | Train Loss: 0.0833 Acc: 0.9692 | Val Loss: 0.1939 Acc: 0.9390\n",
      "Epoch 050 | Train Loss: 0.0946 Acc: 0.9671 | Val Loss: 0.1630 Acc: 0.9426\n",
      "Epoch 051 | Train Loss: 0.0805 Acc: 0.9712 | Val Loss: 0.1606 Acc: 0.9481\n",
      "Epoch 052 | Train Loss: 0.0928 Acc: 0.9678 | Val Loss: 0.1812 Acc: 0.9354\n",
      "Epoch 053 | Train Loss: 0.0870 Acc: 0.9674 | Val Loss: 0.1636 Acc: 0.9420\n",
      "Epoch 054 | Train Loss: 0.0804 Acc: 0.9701 | Val Loss: 0.1693 Acc: 0.9481\n",
      "Early stopping triggered.\n",
      "Epoch 001 | Train Loss: 0.6811 Acc: 0.5777 | Val Loss: 0.6883 Acc: 0.5598\n",
      "Epoch 002 | Train Loss: 0.6711 Acc: 0.5908 | Val Loss: 0.6622 Acc: 0.5960\n",
      "Epoch 003 | Train Loss: 0.6449 Acc: 0.6277 | Val Loss: 0.6252 Acc: 0.6492\n",
      "Epoch 004 | Train Loss: 0.6006 Acc: 0.6870 | Val Loss: 0.5996 Acc: 0.6830\n",
      "Epoch 005 | Train Loss: 0.5700 Acc: 0.7110 | Val Loss: 0.5534 Acc: 0.7156\n",
      "Epoch 006 | Train Loss: 0.5455 Acc: 0.7300 | Val Loss: 0.5363 Acc: 0.7301\n",
      "Epoch 007 | Train Loss: 0.5201 Acc: 0.7494 | Val Loss: 0.5077 Acc: 0.7548\n",
      "Epoch 008 | Train Loss: 0.4913 Acc: 0.7655 | Val Loss: 0.4845 Acc: 0.7560\n",
      "Epoch 009 | Train Loss: 0.4628 Acc: 0.7823 | Val Loss: 0.4746 Acc: 0.7711\n",
      "Epoch 010 | Train Loss: 0.4382 Acc: 0.8004 | Val Loss: 0.4202 Acc: 0.8019\n",
      "Epoch 011 | Train Loss: 0.4223 Acc: 0.8079 | Val Loss: 0.4138 Acc: 0.8050\n",
      "Epoch 012 | Train Loss: 0.3899 Acc: 0.8256 | Val Loss: 0.4276 Acc: 0.7941\n",
      "Epoch 013 | Train Loss: 0.3680 Acc: 0.8377 | Val Loss: 0.3451 Acc: 0.8545\n",
      "Epoch 014 | Train Loss: 0.3327 Acc: 0.8531 | Val Loss: 0.3539 Acc: 0.8388\n",
      "Epoch 015 | Train Loss: 0.3209 Acc: 0.8593 | Val Loss: 0.3139 Acc: 0.8581\n",
      "Epoch 016 | Train Loss: 0.3002 Acc: 0.8718 | Val Loss: 0.3014 Acc: 0.8708\n",
      "Epoch 017 | Train Loss: 0.2863 Acc: 0.8775 | Val Loss: 0.2838 Acc: 0.8762\n",
      "Epoch 018 | Train Loss: 0.2628 Acc: 0.8946 | Val Loss: 0.2521 Acc: 0.8931\n",
      "Epoch 019 | Train Loss: 0.2432 Acc: 0.9028 | Val Loss: 0.2790 Acc: 0.8768\n",
      "Epoch 020 | Train Loss: 0.2291 Acc: 0.9070 | Val Loss: 0.2416 Acc: 0.9004\n",
      "Epoch 021 | Train Loss: 0.2227 Acc: 0.9112 | Val Loss: 0.2460 Acc: 0.8973\n",
      "Epoch 022 | Train Loss: 0.2005 Acc: 0.9191 | Val Loss: 0.2574 Acc: 0.8907\n",
      "Epoch 023 | Train Loss: 0.1990 Acc: 0.9201 | Val Loss: 0.2352 Acc: 0.9052\n",
      "Epoch 024 | Train Loss: 0.1771 Acc: 0.9283 | Val Loss: 0.2017 Acc: 0.9167\n",
      "Epoch 025 | Train Loss: 0.1781 Acc: 0.9293 | Val Loss: 0.2478 Acc: 0.9088\n",
      "Epoch 026 | Train Loss: 0.1646 Acc: 0.9340 | Val Loss: 0.1808 Acc: 0.9281\n",
      "Epoch 027 | Train Loss: 0.1599 Acc: 0.9392 | Val Loss: 0.1967 Acc: 0.9197\n",
      "Epoch 028 | Train Loss: 0.1597 Acc: 0.9373 | Val Loss: 0.2263 Acc: 0.9155\n",
      "Epoch 029 | Train Loss: 0.1465 Acc: 0.9419 | Val Loss: 0.2157 Acc: 0.9173\n",
      "Epoch 030 | Train Loss: 0.1482 Acc: 0.9417 | Val Loss: 0.1800 Acc: 0.9293\n",
      "Epoch 031 | Train Loss: 0.1228 Acc: 0.9549 | Val Loss: 0.1597 Acc: 0.9372\n",
      "Epoch 032 | Train Loss: 0.1217 Acc: 0.9529 | Val Loss: 0.1823 Acc: 0.9257\n",
      "Epoch 033 | Train Loss: 0.1250 Acc: 0.9547 | Val Loss: 0.1742 Acc: 0.9300\n",
      "Epoch 034 | Train Loss: 0.1177 Acc: 0.9532 | Val Loss: 0.1737 Acc: 0.9293\n",
      "Epoch 035 | Train Loss: 0.1152 Acc: 0.9549 | Val Loss: 0.1664 Acc: 0.9312\n",
      "Epoch 036 | Train Loss: 0.1061 Acc: 0.9606 | Val Loss: 0.1594 Acc: 0.9396\n",
      "Epoch 037 | Train Loss: 0.1110 Acc: 0.9600 | Val Loss: 0.1612 Acc: 0.9390\n",
      "Epoch 038 | Train Loss: 0.1007 Acc: 0.9654 | Val Loss: 0.1459 Acc: 0.9396\n",
      "Epoch 039 | Train Loss: 0.0975 Acc: 0.9627 | Val Loss: 0.1709 Acc: 0.9372\n",
      "Epoch 040 | Train Loss: 0.0892 Acc: 0.9657 | Val Loss: 0.1952 Acc: 0.9342\n",
      "Epoch 041 | Train Loss: 0.0889 Acc: 0.9647 | Val Loss: 0.1536 Acc: 0.9372\n",
      "Epoch 042 | Train Loss: 0.0823 Acc: 0.9677 | Val Loss: 0.1884 Acc: 0.9324\n",
      "Epoch 043 | Train Loss: 0.0917 Acc: 0.9683 | Val Loss: 0.1486 Acc: 0.9469\n",
      "Epoch 044 | Train Loss: 0.0844 Acc: 0.9689 | Val Loss: 0.1842 Acc: 0.9300\n",
      "Epoch 045 | Train Loss: 0.0784 Acc: 0.9678 | Val Loss: 0.1436 Acc: 0.9481\n",
      "Epoch 046 | Train Loss: 0.0799 Acc: 0.9703 | Val Loss: 0.1701 Acc: 0.9378\n",
      "Epoch 047 | Train Loss: 0.0890 Acc: 0.9663 | Val Loss: 0.1718 Acc: 0.9348\n",
      "Epoch 048 | Train Loss: 0.0771 Acc: 0.9740 | Val Loss: 0.1476 Acc: 0.9457\n",
      "Epoch 049 | Train Loss: 0.0738 Acc: 0.9736 | Val Loss: 0.1755 Acc: 0.9342\n",
      "Epoch 050 | Train Loss: 0.0673 Acc: 0.9748 | Val Loss: 0.1725 Acc: 0.9463\n",
      "Epoch 051 | Train Loss: 0.0658 Acc: 0.9767 | Val Loss: 0.1640 Acc: 0.9402\n",
      "Epoch 052 | Train Loss: 0.0751 Acc: 0.9736 | Val Loss: 0.1461 Acc: 0.9450\n",
      "Epoch 053 | Train Loss: 0.0671 Acc: 0.9760 | Val Loss: 0.1709 Acc: 0.9426\n",
      "Epoch 054 | Train Loss: 0.0652 Acc: 0.9761 | Val Loss: 0.1664 Acc: 0.9402\n",
      "Epoch 055 | Train Loss: 0.0665 Acc: 0.9767 | Val Loss: 0.1333 Acc: 0.9487\n",
      "Epoch 056 | Train Loss: 0.0653 Acc: 0.9770 | Val Loss: 0.1600 Acc: 0.9450\n",
      "Epoch 057 | Train Loss: 0.0620 Acc: 0.9760 | Val Loss: 0.1622 Acc: 0.9420\n",
      "Epoch 058 | Train Loss: 0.0625 Acc: 0.9770 | Val Loss: 0.1629 Acc: 0.9450\n",
      "Epoch 059 | Train Loss: 0.0681 Acc: 0.9774 | Val Loss: 0.1793 Acc: 0.9420\n",
      "Epoch 060 | Train Loss: 0.0613 Acc: 0.9778 | Val Loss: 0.1320 Acc: 0.9529\n",
      "Epoch 001 | Train Loss: 0.6802 Acc: 0.5795 | Val Loss: 0.6774 Acc: 0.5833\n",
      "Epoch 002 | Train Loss: 0.6772 Acc: 0.5883 | Val Loss: 0.6777 Acc: 0.5845\n",
      "Epoch 003 | Train Loss: 0.6702 Acc: 0.6003 | Val Loss: 0.6682 Acc: 0.6008\n",
      "Epoch 004 | Train Loss: 0.6637 Acc: 0.6067 | Val Loss: 0.6600 Acc: 0.6093\n",
      "Epoch 005 | Train Loss: 0.6475 Acc: 0.6310 | Val Loss: 0.6314 Acc: 0.6594\n",
      "Epoch 006 | Train Loss: 0.6013 Acc: 0.6903 | Val Loss: 0.5845 Acc: 0.6938\n",
      "Epoch 007 | Train Loss: 0.5604 Acc: 0.7198 | Val Loss: 0.5552 Acc: 0.7192\n",
      "Epoch 008 | Train Loss: 0.5455 Acc: 0.7320 | Val Loss: 0.5352 Acc: 0.7264\n",
      "Epoch 009 | Train Loss: 0.5163 Acc: 0.7542 | Val Loss: 0.5100 Acc: 0.7518\n",
      "Epoch 010 | Train Loss: 0.4813 Acc: 0.7708 | Val Loss: 0.4766 Acc: 0.7675\n",
      "Epoch 011 | Train Loss: 0.4614 Acc: 0.7827 | Val Loss: 0.4624 Acc: 0.7802\n",
      "Epoch 012 | Train Loss: 0.4231 Acc: 0.8126 | Val Loss: 0.3937 Acc: 0.8158\n",
      "Epoch 013 | Train Loss: 0.4137 Acc: 0.8144 | Val Loss: 0.3860 Acc: 0.8134\n",
      "Epoch 014 | Train Loss: 0.3821 Acc: 0.8303 | Val Loss: 0.3593 Acc: 0.8315\n",
      "Epoch 015 | Train Loss: 0.3543 Acc: 0.8477 | Val Loss: 0.3220 Acc: 0.8533\n",
      "Epoch 016 | Train Loss: 0.3088 Acc: 0.8662 | Val Loss: 0.3225 Acc: 0.8563\n",
      "Epoch 017 | Train Loss: 0.2910 Acc: 0.8751 | Val Loss: 0.3456 Acc: 0.8436\n",
      "Epoch 018 | Train Loss: 0.2824 Acc: 0.8812 | Val Loss: 0.2766 Acc: 0.8883\n",
      "Epoch 019 | Train Loss: 0.2587 Acc: 0.8905 | Val Loss: 0.2571 Acc: 0.9004\n",
      "Epoch 020 | Train Loss: 0.2485 Acc: 0.8993 | Val Loss: 0.2793 Acc: 0.8835\n",
      "Epoch 021 | Train Loss: 0.2370 Acc: 0.9028 | Val Loss: 0.3086 Acc: 0.8744\n",
      "Epoch 022 | Train Loss: 0.2279 Acc: 0.9062 | Val Loss: 0.2310 Acc: 0.9064\n",
      "Epoch 023 | Train Loss: 0.2040 Acc: 0.9170 | Val Loss: 0.2273 Acc: 0.9100\n",
      "Epoch 024 | Train Loss: 0.2087 Acc: 0.9176 | Val Loss: 0.2139 Acc: 0.9124\n",
      "Epoch 025 | Train Loss: 0.1906 Acc: 0.9260 | Val Loss: 0.2162 Acc: 0.9149\n",
      "Epoch 026 | Train Loss: 0.1830 Acc: 0.9262 | Val Loss: 0.2019 Acc: 0.9269\n",
      "Epoch 027 | Train Loss: 0.1626 Acc: 0.9382 | Val Loss: 0.2223 Acc: 0.9161\n",
      "Epoch 028 | Train Loss: 0.1635 Acc: 0.9369 | Val Loss: 0.2077 Acc: 0.9179\n",
      "Epoch 029 | Train Loss: 0.1525 Acc: 0.9411 | Val Loss: 0.2162 Acc: 0.9215\n",
      "Epoch 030 | Train Loss: 0.1659 Acc: 0.9357 | Val Loss: 0.1834 Acc: 0.9293\n",
      "Epoch 031 | Train Loss: 0.1386 Acc: 0.9469 | Val Loss: 0.1768 Acc: 0.9318\n",
      "Epoch 032 | Train Loss: 0.1430 Acc: 0.9450 | Val Loss: 0.2319 Acc: 0.9022\n",
      "Epoch 033 | Train Loss: 0.1371 Acc: 0.9476 | Val Loss: 0.1931 Acc: 0.9287\n",
      "Epoch 034 | Train Loss: 0.1344 Acc: 0.9465 | Val Loss: 0.1970 Acc: 0.9251\n",
      "Epoch 035 | Train Loss: 0.1272 Acc: 0.9512 | Val Loss: 0.1695 Acc: 0.9366\n",
      "Epoch 036 | Train Loss: 0.1191 Acc: 0.9561 | Val Loss: 0.2080 Acc: 0.9287\n",
      "Epoch 037 | Train Loss: 0.1208 Acc: 0.9552 | Val Loss: 0.1649 Acc: 0.9408\n",
      "Epoch 038 | Train Loss: 0.1209 Acc: 0.9561 | Val Loss: 0.1990 Acc: 0.9233\n",
      "Epoch 039 | Train Loss: 0.0973 Acc: 0.9636 | Val Loss: 0.2008 Acc: 0.9287\n",
      "Epoch 040 | Train Loss: 0.1070 Acc: 0.9592 | Val Loss: 0.1875 Acc: 0.9269\n",
      "Epoch 041 | Train Loss: 0.1010 Acc: 0.9618 | Val Loss: 0.1393 Acc: 0.9481\n",
      "Epoch 042 | Train Loss: 0.1082 Acc: 0.9609 | Val Loss: 0.1352 Acc: 0.9493\n",
      "Epoch 043 | Train Loss: 0.0990 Acc: 0.9595 | Val Loss: 0.1536 Acc: 0.9432\n",
      "Epoch 044 | Train Loss: 0.0985 Acc: 0.9630 | Val Loss: 0.1680 Acc: 0.9408\n",
      "Epoch 045 | Train Loss: 0.0962 Acc: 0.9620 | Val Loss: 0.1704 Acc: 0.9438\n",
      "Epoch 046 | Train Loss: 0.0886 Acc: 0.9687 | Val Loss: 0.1553 Acc: 0.9535\n",
      "Epoch 047 | Train Loss: 0.0900 Acc: 0.9662 | Val Loss: 0.1824 Acc: 0.9408\n",
      "Epoch 048 | Train Loss: 0.0906 Acc: 0.9629 | Val Loss: 0.1386 Acc: 0.9529\n",
      "Epoch 049 | Train Loss: 0.0963 Acc: 0.9662 | Val Loss: 0.1390 Acc: 0.9553\n",
      "Epoch 050 | Train Loss: 0.0826 Acc: 0.9680 | Val Loss: 0.1735 Acc: 0.9402\n",
      "Epoch 051 | Train Loss: 0.0868 Acc: 0.9692 | Val Loss: 0.1472 Acc: 0.9529\n",
      "Epoch 052 | Train Loss: 0.0766 Acc: 0.9704 | Val Loss: 0.1459 Acc: 0.9432\n",
      "Early stopping triggered.\n",
      "Epoch 001 | Train Loss: 0.6818 Acc: 0.5744 | Val Loss: 0.6748 Acc: 0.5924\n",
      "Epoch 002 | Train Loss: 0.6716 Acc: 0.5960 | Val Loss: 0.6634 Acc: 0.6081\n",
      "Epoch 003 | Train Loss: 0.6596 Acc: 0.6088 | Val Loss: 0.6475 Acc: 0.6383\n",
      "Epoch 004 | Train Loss: 0.6262 Acc: 0.6588 | Val Loss: 0.6102 Acc: 0.6787\n",
      "Epoch 005 | Train Loss: 0.5905 Acc: 0.6986 | Val Loss: 0.5759 Acc: 0.7095\n",
      "Epoch 006 | Train Loss: 0.5544 Acc: 0.7258 | Val Loss: 0.5567 Acc: 0.7156\n",
      "Epoch 007 | Train Loss: 0.5391 Acc: 0.7423 | Val Loss: 0.5538 Acc: 0.7132\n",
      "Epoch 008 | Train Loss: 0.5249 Acc: 0.7373 | Val Loss: 0.5294 Acc: 0.7355\n",
      "Epoch 009 | Train Loss: 0.5126 Acc: 0.7539 | Val Loss: 0.5051 Acc: 0.7476\n",
      "Epoch 010 | Train Loss: 0.4864 Acc: 0.7676 | Val Loss: 0.4979 Acc: 0.7603\n",
      "Epoch 011 | Train Loss: 0.4790 Acc: 0.7752 | Val Loss: 0.4971 Acc: 0.7572\n",
      "Epoch 012 | Train Loss: 0.4676 Acc: 0.7803 | Val Loss: 0.4578 Acc: 0.7784\n",
      "Epoch 013 | Train Loss: 0.4395 Acc: 0.7999 | Val Loss: 0.4358 Acc: 0.8001\n",
      "Epoch 014 | Train Loss: 0.4080 Acc: 0.8140 | Val Loss: 0.4019 Acc: 0.8207\n",
      "Epoch 015 | Train Loss: 0.4050 Acc: 0.8162 | Val Loss: 0.3970 Acc: 0.8207\n",
      "Epoch 016 | Train Loss: 0.3778 Acc: 0.8301 | Val Loss: 0.3761 Acc: 0.8267\n",
      "Epoch 017 | Train Loss: 0.3568 Acc: 0.8461 | Val Loss: 0.3581 Acc: 0.8376\n",
      "Epoch 018 | Train Loss: 0.3522 Acc: 0.8477 | Val Loss: 0.3535 Acc: 0.8448\n",
      "Epoch 019 | Train Loss: 0.3299 Acc: 0.8501 | Val Loss: 0.3243 Acc: 0.8605\n",
      "Epoch 020 | Train Loss: 0.3188 Acc: 0.8620 | Val Loss: 0.4061 Acc: 0.8249\n",
      "Epoch 021 | Train Loss: 0.2924 Acc: 0.8741 | Val Loss: 0.2985 Acc: 0.8671\n",
      "Epoch 022 | Train Loss: 0.2705 Acc: 0.8842 | Val Loss: 0.2744 Acc: 0.8774\n",
      "Epoch 023 | Train Loss: 0.2622 Acc: 0.8878 | Val Loss: 0.2625 Acc: 0.8943\n",
      "Epoch 024 | Train Loss: 0.2397 Acc: 0.9022 | Val Loss: 0.2740 Acc: 0.8835\n",
      "Epoch 025 | Train Loss: 0.2341 Acc: 0.9028 | Val Loss: 0.2503 Acc: 0.8816\n",
      "Epoch 026 | Train Loss: 0.2156 Acc: 0.9118 | Val Loss: 0.2292 Acc: 0.9064\n",
      "Epoch 027 | Train Loss: 0.2029 Acc: 0.9188 | Val Loss: 0.2362 Acc: 0.8973\n",
      "Epoch 028 | Train Loss: 0.1983 Acc: 0.9198 | Val Loss: 0.2242 Acc: 0.9064\n",
      "Epoch 029 | Train Loss: 0.1846 Acc: 0.9266 | Val Loss: 0.2228 Acc: 0.9100\n",
      "Epoch 030 | Train Loss: 0.1905 Acc: 0.9224 | Val Loss: 0.2156 Acc: 0.9179\n",
      "Epoch 031 | Train Loss: 0.1721 Acc: 0.9325 | Val Loss: 0.1960 Acc: 0.9185\n",
      "Epoch 032 | Train Loss: 0.1546 Acc: 0.9401 | Val Loss: 0.1977 Acc: 0.9167\n",
      "Epoch 033 | Train Loss: 0.1513 Acc: 0.9398 | Val Loss: 0.2206 Acc: 0.9167\n",
      "Epoch 034 | Train Loss: 0.1427 Acc: 0.9419 | Val Loss: 0.1876 Acc: 0.9203\n",
      "Epoch 035 | Train Loss: 0.1465 Acc: 0.9428 | Val Loss: 0.1984 Acc: 0.9263\n",
      "Epoch 036 | Train Loss: 0.1512 Acc: 0.9398 | Val Loss: 0.1782 Acc: 0.9275\n",
      "Epoch 037 | Train Loss: 0.1285 Acc: 0.9503 | Val Loss: 0.2298 Acc: 0.9034\n",
      "Epoch 038 | Train Loss: 0.1431 Acc: 0.9419 | Val Loss: 0.1923 Acc: 0.9263\n",
      "Epoch 039 | Train Loss: 0.1145 Acc: 0.9553 | Val Loss: 0.2187 Acc: 0.9203\n",
      "Epoch 040 | Train Loss: 0.1252 Acc: 0.9505 | Val Loss: 0.1901 Acc: 0.9293\n",
      "Epoch 041 | Train Loss: 0.1066 Acc: 0.9601 | Val Loss: 0.1736 Acc: 0.9318\n",
      "Epoch 042 | Train Loss: 0.1128 Acc: 0.9585 | Val Loss: 0.1705 Acc: 0.9354\n",
      "Epoch 043 | Train Loss: 0.1106 Acc: 0.9580 | Val Loss: 0.1996 Acc: 0.9203\n",
      "Epoch 044 | Train Loss: 0.0989 Acc: 0.9627 | Val Loss: 0.1884 Acc: 0.9287\n",
      "Epoch 045 | Train Loss: 0.1045 Acc: 0.9626 | Val Loss: 0.1535 Acc: 0.9372\n",
      "Epoch 046 | Train Loss: 0.0916 Acc: 0.9641 | Val Loss: 0.1675 Acc: 0.9366\n",
      "Epoch 047 | Train Loss: 0.0985 Acc: 0.9647 | Val Loss: 0.1756 Acc: 0.9318\n",
      "Epoch 048 | Train Loss: 0.0826 Acc: 0.9681 | Val Loss: 0.1743 Acc: 0.9342\n",
      "Epoch 049 | Train Loss: 0.0821 Acc: 0.9683 | Val Loss: 0.2161 Acc: 0.9215\n",
      "Epoch 050 | Train Loss: 0.0883 Acc: 0.9665 | Val Loss: 0.1701 Acc: 0.9457\n",
      "Epoch 051 | Train Loss: 0.0863 Acc: 0.9666 | Val Loss: 0.1843 Acc: 0.9420\n",
      "Epoch 052 | Train Loss: 0.0785 Acc: 0.9704 | Val Loss: 0.1784 Acc: 0.9408\n",
      "Epoch 053 | Train Loss: 0.0752 Acc: 0.9722 | Val Loss: 0.1637 Acc: 0.9457\n",
      "Epoch 054 | Train Loss: 0.0732 Acc: 0.9707 | Val Loss: 0.1714 Acc: 0.9384\n",
      "Epoch 055 | Train Loss: 0.0709 Acc: 0.9733 | Val Loss: 0.1806 Acc: 0.9408\n",
      "Early stopping triggered.\n",
      "Epoch 001 | Train Loss: 0.6803 Acc: 0.5783 | Val Loss: 0.6741 Acc: 0.5936\n",
      "Epoch 002 | Train Loss: 0.6727 Acc: 0.5947 | Val Loss: 0.6670 Acc: 0.6014\n",
      "Epoch 003 | Train Loss: 0.6665 Acc: 0.6053 | Val Loss: 0.6618 Acc: 0.6063\n",
      "Epoch 004 | Train Loss: 0.6532 Acc: 0.6215 | Val Loss: 0.6567 Acc: 0.6178\n",
      "Epoch 005 | Train Loss: 0.6107 Acc: 0.6722 | Val Loss: 0.6185 Acc: 0.6836\n",
      "Epoch 006 | Train Loss: 0.5846 Acc: 0.7081 | Val Loss: 0.5890 Acc: 0.7083\n",
      "Epoch 007 | Train Loss: 0.5463 Acc: 0.7355 | Val Loss: 0.5450 Acc: 0.7204\n",
      "Epoch 008 | Train Loss: 0.5289 Acc: 0.7494 | Val Loss: 0.5286 Acc: 0.7361\n",
      "Epoch 009 | Train Loss: 0.5165 Acc: 0.7491 | Val Loss: 0.5294 Acc: 0.7434\n",
      "Epoch 010 | Train Loss: 0.5015 Acc: 0.7636 | Val Loss: 0.5007 Acc: 0.7518\n",
      "Epoch 011 | Train Loss: 0.4909 Acc: 0.7729 | Val Loss: 0.5028 Acc: 0.7585\n",
      "Epoch 012 | Train Loss: 0.4697 Acc: 0.7787 | Val Loss: 0.4636 Acc: 0.7723\n",
      "Epoch 013 | Train Loss: 0.4543 Acc: 0.7845 | Val Loss: 0.4716 Acc: 0.7766\n",
      "Epoch 014 | Train Loss: 0.4409 Acc: 0.7963 | Val Loss: 0.4351 Acc: 0.7905\n",
      "Epoch 015 | Train Loss: 0.4179 Acc: 0.8082 | Val Loss: 0.4483 Acc: 0.7766\n",
      "Epoch 016 | Train Loss: 0.4058 Acc: 0.8170 | Val Loss: 0.4262 Acc: 0.7880\n",
      "Epoch 017 | Train Loss: 0.3925 Acc: 0.8242 | Val Loss: 0.4247 Acc: 0.7886\n",
      "Epoch 018 | Train Loss: 0.3623 Acc: 0.8419 | Val Loss: 0.3949 Acc: 0.8255\n",
      "Epoch 019 | Train Loss: 0.3511 Acc: 0.8489 | Val Loss: 0.3759 Acc: 0.8315\n",
      "Epoch 020 | Train Loss: 0.3243 Acc: 0.8600 | Val Loss: 0.3571 Acc: 0.8382\n",
      "Epoch 021 | Train Loss: 0.3221 Acc: 0.8617 | Val Loss: 0.3441 Acc: 0.8460\n",
      "Epoch 022 | Train Loss: 0.2957 Acc: 0.8709 | Val Loss: 0.3313 Acc: 0.8496\n",
      "Epoch 023 | Train Loss: 0.2733 Acc: 0.8877 | Val Loss: 0.3260 Acc: 0.8599\n",
      "Epoch 024 | Train Loss: 0.2699 Acc: 0.8839 | Val Loss: 0.2912 Acc: 0.8714\n",
      "Epoch 025 | Train Loss: 0.2644 Acc: 0.8933 | Val Loss: 0.3193 Acc: 0.8617\n",
      "Epoch 026 | Train Loss: 0.2453 Acc: 0.8999 | Val Loss: 0.2589 Acc: 0.8931\n",
      "Epoch 027 | Train Loss: 0.2274 Acc: 0.9059 | Val Loss: 0.2668 Acc: 0.8919\n",
      "Epoch 028 | Train Loss: 0.2260 Acc: 0.9082 | Val Loss: 0.2894 Acc: 0.8883\n",
      "Epoch 029 | Train Loss: 0.2184 Acc: 0.9117 | Val Loss: 0.2405 Acc: 0.9052\n",
      "Epoch 030 | Train Loss: 0.1970 Acc: 0.9233 | Val Loss: 0.2385 Acc: 0.9100\n",
      "Epoch 031 | Train Loss: 0.1912 Acc: 0.9234 | Val Loss: 0.2305 Acc: 0.9106\n",
      "Epoch 032 | Train Loss: 0.1930 Acc: 0.9209 | Val Loss: 0.2400 Acc: 0.9034\n",
      "Epoch 033 | Train Loss: 0.1933 Acc: 0.9212 | Val Loss: 0.2185 Acc: 0.9136\n",
      "Epoch 034 | Train Loss: 0.1740 Acc: 0.9325 | Val Loss: 0.2341 Acc: 0.9070\n",
      "Epoch 035 | Train Loss: 0.1629 Acc: 0.9361 | Val Loss: 0.2191 Acc: 0.9185\n",
      "Epoch 036 | Train Loss: 0.1589 Acc: 0.9384 | Val Loss: 0.2190 Acc: 0.9149\n",
      "Epoch 037 | Train Loss: 0.1632 Acc: 0.9375 | Val Loss: 0.1868 Acc: 0.9293\n",
      "Epoch 038 | Train Loss: 0.1491 Acc: 0.9441 | Val Loss: 0.2031 Acc: 0.9209\n",
      "Epoch 039 | Train Loss: 0.1392 Acc: 0.9449 | Val Loss: 0.2160 Acc: 0.9293\n",
      "Epoch 040 | Train Loss: 0.1375 Acc: 0.9470 | Val Loss: 0.2085 Acc: 0.9251\n",
      "Epoch 041 | Train Loss: 0.1304 Acc: 0.9482 | Val Loss: 0.1856 Acc: 0.9263\n",
      "Epoch 042 | Train Loss: 0.1325 Acc: 0.9476 | Val Loss: 0.1907 Acc: 0.9312\n",
      "Epoch 043 | Train Loss: 0.1288 Acc: 0.9499 | Val Loss: 0.2035 Acc: 0.9275\n",
      "Epoch 044 | Train Loss: 0.1180 Acc: 0.9568 | Val Loss: 0.1772 Acc: 0.9348\n",
      "Epoch 045 | Train Loss: 0.1168 Acc: 0.9556 | Val Loss: 0.1708 Acc: 0.9318\n",
      "Epoch 046 | Train Loss: 0.1181 Acc: 0.9538 | Val Loss: 0.1816 Acc: 0.9348\n",
      "Epoch 047 | Train Loss: 0.1151 Acc: 0.9539 | Val Loss: 0.1895 Acc: 0.9293\n",
      "Epoch 048 | Train Loss: 0.1128 Acc: 0.9558 | Val Loss: 0.1919 Acc: 0.9348\n",
      "Epoch 049 | Train Loss: 0.1013 Acc: 0.9623 | Val Loss: 0.1723 Acc: 0.9457\n",
      "Epoch 050 | Train Loss: 0.1105 Acc: 0.9595 | Val Loss: 0.1700 Acc: 0.9408\n",
      "Epoch 051 | Train Loss: 0.0997 Acc: 0.9627 | Val Loss: 0.1906 Acc: 0.9324\n",
      "Epoch 052 | Train Loss: 0.1009 Acc: 0.9616 | Val Loss: 0.1733 Acc: 0.9354\n",
      "Epoch 053 | Train Loss: 0.1051 Acc: 0.9606 | Val Loss: 0.1595 Acc: 0.9438\n",
      "Epoch 054 | Train Loss: 0.0907 Acc: 0.9657 | Val Loss: 0.1755 Acc: 0.9300\n",
      "Epoch 055 | Train Loss: 0.0991 Acc: 0.9645 | Val Loss: 0.1828 Acc: 0.9426\n",
      "Epoch 056 | Train Loss: 0.0801 Acc: 0.9706 | Val Loss: 0.2010 Acc: 0.9275\n",
      "Epoch 057 | Train Loss: 0.0932 Acc: 0.9647 | Val Loss: 0.1669 Acc: 0.9390\n",
      "Epoch 058 | Train Loss: 0.0881 Acc: 0.9671 | Val Loss: 0.2022 Acc: 0.9354\n",
      "Epoch 059 | Train Loss: 0.0938 Acc: 0.9651 | Val Loss: 0.2068 Acc: 0.9257\n",
      "Epoch 060 | Train Loss: 0.0894 Acc: 0.9660 | Val Loss: 0.1858 Acc: 0.9378\n",
      "Epoch 001 | Train Loss: 0.6833 Acc: 0.5639 | Val Loss: 0.6778 Acc: 0.5900\n",
      "Epoch 002 | Train Loss: 0.6735 Acc: 0.5872 | Val Loss: 0.6693 Acc: 0.5791\n",
      "Epoch 003 | Train Loss: 0.6407 Acc: 0.6384 | Val Loss: 0.6246 Acc: 0.6522\n",
      "Epoch 004 | Train Loss: 0.5742 Acc: 0.7071 | Val Loss: 0.5574 Acc: 0.7204\n",
      "Epoch 005 | Train Loss: 0.5407 Acc: 0.7309 | Val Loss: 0.5470 Acc: 0.7204\n",
      "Epoch 006 | Train Loss: 0.5164 Acc: 0.7512 | Val Loss: 0.5096 Acc: 0.7452\n",
      "Epoch 007 | Train Loss: 0.4794 Acc: 0.7737 | Val Loss: 0.4911 Acc: 0.7560\n",
      "Epoch 008 | Train Loss: 0.4432 Acc: 0.7874 | Val Loss: 0.4368 Acc: 0.7917\n",
      "Epoch 009 | Train Loss: 0.4239 Acc: 0.8018 | Val Loss: 0.3950 Acc: 0.8158\n",
      "Epoch 010 | Train Loss: 0.3815 Acc: 0.8309 | Val Loss: 0.3697 Acc: 0.8255\n",
      "Epoch 011 | Train Loss: 0.3665 Acc: 0.8424 | Val Loss: 0.3484 Acc: 0.8527\n",
      "Epoch 012 | Train Loss: 0.3225 Acc: 0.8628 | Val Loss: 0.3618 Acc: 0.8339\n",
      "Epoch 013 | Train Loss: 0.3001 Acc: 0.8750 | Val Loss: 0.2959 Acc: 0.8659\n",
      "Epoch 014 | Train Loss: 0.2700 Acc: 0.8895 | Val Loss: 0.2538 Acc: 0.8913\n",
      "Epoch 015 | Train Loss: 0.2459 Acc: 0.9029 | Val Loss: 0.2557 Acc: 0.8871\n",
      "Epoch 016 | Train Loss: 0.2467 Acc: 0.9013 | Val Loss: 0.2688 Acc: 0.8871\n",
      "Epoch 017 | Train Loss: 0.2215 Acc: 0.9127 | Val Loss: 0.2216 Acc: 0.9143\n",
      "Epoch 018 | Train Loss: 0.1918 Acc: 0.9247 | Val Loss: 0.2102 Acc: 0.9118\n",
      "Epoch 019 | Train Loss: 0.1907 Acc: 0.9239 | Val Loss: 0.2019 Acc: 0.9173\n",
      "Epoch 020 | Train Loss: 0.1775 Acc: 0.9339 | Val Loss: 0.2338 Acc: 0.9100\n",
      "Epoch 021 | Train Loss: 0.1567 Acc: 0.9395 | Val Loss: 0.1895 Acc: 0.9269\n",
      "Epoch 022 | Train Loss: 0.1592 Acc: 0.9395 | Val Loss: 0.2059 Acc: 0.9203\n",
      "Epoch 023 | Train Loss: 0.1363 Acc: 0.9488 | Val Loss: 0.1901 Acc: 0.9300\n",
      "Epoch 024 | Train Loss: 0.1379 Acc: 0.9473 | Val Loss: 0.1887 Acc: 0.9348\n",
      "Epoch 025 | Train Loss: 0.1358 Acc: 0.9478 | Val Loss: 0.2045 Acc: 0.9215\n",
      "Epoch 026 | Train Loss: 0.1254 Acc: 0.9508 | Val Loss: 0.1983 Acc: 0.9306\n",
      "Epoch 027 | Train Loss: 0.1205 Acc: 0.9541 | Val Loss: 0.1892 Acc: 0.9287\n",
      "Epoch 028 | Train Loss: 0.1122 Acc: 0.9561 | Val Loss: 0.1578 Acc: 0.9414\n",
      "Epoch 029 | Train Loss: 0.1082 Acc: 0.9570 | Val Loss: 0.1657 Acc: 0.9330\n",
      "Epoch 030 | Train Loss: 0.1032 Acc: 0.9629 | Val Loss: 0.1958 Acc: 0.9293\n",
      "Epoch 031 | Train Loss: 0.0995 Acc: 0.9618 | Val Loss: 0.1841 Acc: 0.9396\n",
      "Epoch 032 | Train Loss: 0.1039 Acc: 0.9597 | Val Loss: 0.1733 Acc: 0.9366\n",
      "Epoch 033 | Train Loss: 0.0999 Acc: 0.9627 | Val Loss: 0.1708 Acc: 0.9432\n",
      "Epoch 034 | Train Loss: 0.0875 Acc: 0.9663 | Val Loss: 0.1913 Acc: 0.9336\n",
      "Epoch 035 | Train Loss: 0.0893 Acc: 0.9659 | Val Loss: 0.1587 Acc: 0.9432\n",
      "Epoch 036 | Train Loss: 0.0840 Acc: 0.9700 | Val Loss: 0.1800 Acc: 0.9372\n",
      "Epoch 037 | Train Loss: 0.0814 Acc: 0.9693 | Val Loss: 0.1956 Acc: 0.9318\n",
      "Epoch 038 | Train Loss: 0.0891 Acc: 0.9671 | Val Loss: 0.1906 Acc: 0.9354\n",
      "Early stopping triggered.\n",
      "Epoch 001 | Train Loss: 0.6799 Acc: 0.5828 | Val Loss: 0.6804 Acc: 0.5749\n",
      "Epoch 002 | Train Loss: 0.6725 Acc: 0.5957 | Val Loss: 0.6669 Acc: 0.5984\n",
      "Epoch 003 | Train Loss: 0.6665 Acc: 0.5987 | Val Loss: 0.6545 Acc: 0.6045\n",
      "Epoch 004 | Train Loss: 0.6257 Acc: 0.6597 | Val Loss: 0.5842 Acc: 0.6932\n",
      "Epoch 005 | Train Loss: 0.5673 Acc: 0.7154 | Val Loss: 0.5681 Acc: 0.7210\n",
      "Epoch 006 | Train Loss: 0.5470 Acc: 0.7294 | Val Loss: 0.5452 Acc: 0.7319\n",
      "Epoch 007 | Train Loss: 0.5177 Acc: 0.7483 | Val Loss: 0.5244 Acc: 0.7397\n",
      "Epoch 008 | Train Loss: 0.4999 Acc: 0.7581 | Val Loss: 0.5346 Acc: 0.7361\n",
      "Epoch 009 | Train Loss: 0.4782 Acc: 0.7779 | Val Loss: 0.4893 Acc: 0.7639\n",
      "Epoch 010 | Train Loss: 0.4489 Acc: 0.7931 | Val Loss: 0.4445 Acc: 0.7844\n",
      "Epoch 011 | Train Loss: 0.4265 Acc: 0.7992 | Val Loss: 0.4444 Acc: 0.7905\n",
      "Epoch 012 | Train Loss: 0.4082 Acc: 0.8114 | Val Loss: 0.4137 Acc: 0.8098\n",
      "Epoch 013 | Train Loss: 0.3864 Acc: 0.8202 | Val Loss: 0.3897 Acc: 0.8170\n",
      "Epoch 014 | Train Loss: 0.3741 Acc: 0.8312 | Val Loss: 0.3879 Acc: 0.8237\n",
      "Epoch 015 | Train Loss: 0.3596 Acc: 0.8389 | Val Loss: 0.3537 Acc: 0.8436\n",
      "Epoch 016 | Train Loss: 0.3490 Acc: 0.8434 | Val Loss: 0.3906 Acc: 0.8176\n",
      "Epoch 017 | Train Loss: 0.3222 Acc: 0.8599 | Val Loss: 0.3180 Acc: 0.8581\n",
      "Epoch 018 | Train Loss: 0.3050 Acc: 0.8655 | Val Loss: 0.3035 Acc: 0.8738\n",
      "Epoch 019 | Train Loss: 0.2784 Acc: 0.8840 | Val Loss: 0.2901 Acc: 0.8774\n",
      "Epoch 020 | Train Loss: 0.2643 Acc: 0.8908 | Val Loss: 0.2793 Acc: 0.8756\n",
      "Epoch 021 | Train Loss: 0.2563 Acc: 0.8901 | Val Loss: 0.2664 Acc: 0.8883\n",
      "Epoch 022 | Train Loss: 0.2298 Acc: 0.9061 | Val Loss: 0.2331 Acc: 0.9082\n",
      "Epoch 023 | Train Loss: 0.2138 Acc: 0.9147 | Val Loss: 0.2312 Acc: 0.9136\n",
      "Epoch 024 | Train Loss: 0.2141 Acc: 0.9094 | Val Loss: 0.2173 Acc: 0.9179\n",
      "Epoch 025 | Train Loss: 0.2021 Acc: 0.9177 | Val Loss: 0.2301 Acc: 0.9155\n",
      "Epoch 026 | Train Loss: 0.1827 Acc: 0.9304 | Val Loss: 0.2261 Acc: 0.9118\n",
      "Epoch 027 | Train Loss: 0.1787 Acc: 0.9321 | Val Loss: 0.2225 Acc: 0.9112\n",
      "Epoch 028 | Train Loss: 0.1725 Acc: 0.9321 | Val Loss: 0.2004 Acc: 0.9275\n",
      "Epoch 029 | Train Loss: 0.1623 Acc: 0.9387 | Val Loss: 0.2085 Acc: 0.9197\n",
      "Epoch 030 | Train Loss: 0.1521 Acc: 0.9419 | Val Loss: 0.1785 Acc: 0.9342\n",
      "Epoch 031 | Train Loss: 0.1507 Acc: 0.9419 | Val Loss: 0.2157 Acc: 0.9245\n",
      "Epoch 032 | Train Loss: 0.1522 Acc: 0.9443 | Val Loss: 0.1914 Acc: 0.9269\n",
      "Epoch 033 | Train Loss: 0.1401 Acc: 0.9493 | Val Loss: 0.1882 Acc: 0.9263\n",
      "Epoch 034 | Train Loss: 0.1330 Acc: 0.9458 | Val Loss: 0.1993 Acc: 0.9281\n",
      "Epoch 035 | Train Loss: 0.1280 Acc: 0.9520 | Val Loss: 0.1842 Acc: 0.9312\n",
      "Epoch 036 | Train Loss: 0.1314 Acc: 0.9487 | Val Loss: 0.1664 Acc: 0.9432\n",
      "Epoch 037 | Train Loss: 0.1145 Acc: 0.9574 | Val Loss: 0.1854 Acc: 0.9300\n",
      "Epoch 038 | Train Loss: 0.1087 Acc: 0.9576 | Val Loss: 0.2331 Acc: 0.9239\n",
      "Epoch 039 | Train Loss: 0.1106 Acc: 0.9597 | Val Loss: 0.1587 Acc: 0.9444\n",
      "Epoch 040 | Train Loss: 0.0957 Acc: 0.9671 | Val Loss: 0.1498 Acc: 0.9523\n",
      "Epoch 041 | Train Loss: 0.0987 Acc: 0.9668 | Val Loss: 0.2232 Acc: 0.9306\n",
      "Epoch 042 | Train Loss: 0.1059 Acc: 0.9626 | Val Loss: 0.1942 Acc: 0.9227\n",
      "Epoch 043 | Train Loss: 0.1045 Acc: 0.9597 | Val Loss: 0.1881 Acc: 0.9330\n",
      "Epoch 044 | Train Loss: 0.1007 Acc: 0.9621 | Val Loss: 0.1864 Acc: 0.9312\n",
      "Epoch 045 | Train Loss: 0.0867 Acc: 0.9683 | Val Loss: 0.1555 Acc: 0.9481\n",
      "Epoch 046 | Train Loss: 0.0920 Acc: 0.9668 | Val Loss: 0.1629 Acc: 0.9396\n",
      "Epoch 047 | Train Loss: 0.0876 Acc: 0.9690 | Val Loss: 0.1903 Acc: 0.9372\n",
      "Epoch 048 | Train Loss: 0.0835 Acc: 0.9692 | Val Loss: 0.1463 Acc: 0.9408\n",
      "Epoch 049 | Train Loss: 0.0859 Acc: 0.9672 | Val Loss: 0.1497 Acc: 0.9481\n",
      "Epoch 050 | Train Loss: 0.0723 Acc: 0.9751 | Val Loss: 0.1753 Acc: 0.9414\n",
      "Epoch 051 | Train Loss: 0.0719 Acc: 0.9730 | Val Loss: 0.1372 Acc: 0.9511\n",
      "Epoch 052 | Train Loss: 0.0740 Acc: 0.9721 | Val Loss: 0.1282 Acc: 0.9481\n",
      "Epoch 053 | Train Loss: 0.0734 Acc: 0.9761 | Val Loss: 0.1253 Acc: 0.9595\n",
      "Epoch 054 | Train Loss: 0.0754 Acc: 0.9719 | Val Loss: 0.1258 Acc: 0.9577\n",
      "Epoch 055 | Train Loss: 0.0699 Acc: 0.9748 | Val Loss: 0.1457 Acc: 0.9493\n",
      "Epoch 056 | Train Loss: 0.0712 Acc: 0.9746 | Val Loss: 0.1451 Acc: 0.9547\n",
      "Epoch 057 | Train Loss: 0.0583 Acc: 0.9796 | Val Loss: 0.1646 Acc: 0.9523\n",
      "Epoch 058 | Train Loss: 0.0733 Acc: 0.9731 | Val Loss: 0.1230 Acc: 0.9553\n",
      "Epoch 059 | Train Loss: 0.0714 Acc: 0.9739 | Val Loss: 0.1616 Acc: 0.9469\n",
      "Epoch 060 | Train Loss: 0.0603 Acc: 0.9764 | Val Loss: 0.1244 Acc: 0.9547\n",
      "Iteration 35/40 | Best Val Loss: 0.1122 | Iter Time: 224.17s | Total Time: 142.41 min\n",
      "Epoch 001 | Train Loss: 0.6843 Acc: 0.5686 | Val Loss: 0.6790 Acc: 0.5803\n",
      "Epoch 002 | Train Loss: 0.6777 Acc: 0.5869 | Val Loss: 0.6830 Acc: 0.5791\n",
      "Epoch 003 | Train Loss: 0.6786 Acc: 0.5883 | Val Loss: 0.6725 Acc: 0.5978\n",
      "Epoch 004 | Train Loss: 0.6727 Acc: 0.5887 | Val Loss: 0.6728 Acc: 0.5809\n",
      "Epoch 005 | Train Loss: 0.6229 Acc: 0.6601 | Val Loss: 0.6061 Acc: 0.6787\n",
      "Epoch 006 | Train Loss: 0.5811 Acc: 0.7115 | Val Loss: 0.5665 Acc: 0.7144\n",
      "Epoch 007 | Train Loss: 0.5559 Acc: 0.7267 | Val Loss: 0.5572 Acc: 0.7319\n",
      "Epoch 008 | Train Loss: 0.5355 Acc: 0.7442 | Val Loss: 0.5328 Acc: 0.7403\n",
      "Epoch 009 | Train Loss: 0.5146 Acc: 0.7563 | Val Loss: 0.5024 Acc: 0.7621\n",
      "Epoch 010 | Train Loss: 0.5001 Acc: 0.7657 | Val Loss: 0.4898 Acc: 0.7663\n",
      "Epoch 011 | Train Loss: 0.4856 Acc: 0.7679 | Val Loss: 0.4757 Acc: 0.7754\n",
      "Epoch 012 | Train Loss: 0.4808 Acc: 0.7725 | Val Loss: 0.4791 Acc: 0.7748\n",
      "Epoch 013 | Train Loss: 0.4635 Acc: 0.7871 | Val Loss: 0.4756 Acc: 0.7760\n",
      "Epoch 014 | Train Loss: 0.4506 Acc: 0.7903 | Val Loss: 0.4578 Acc: 0.7742\n",
      "Epoch 015 | Train Loss: 0.4330 Acc: 0.8001 | Val Loss: 0.4276 Acc: 0.7965\n",
      "Epoch 016 | Train Loss: 0.4133 Acc: 0.8126 | Val Loss: 0.4087 Acc: 0.8037\n",
      "Epoch 017 | Train Loss: 0.4073 Acc: 0.8208 | Val Loss: 0.4049 Acc: 0.8170\n",
      "Epoch 018 | Train Loss: 0.3888 Acc: 0.8256 | Val Loss: 0.3690 Acc: 0.8267\n",
      "Epoch 019 | Train Loss: 0.3858 Acc: 0.8258 | Val Loss: 0.3756 Acc: 0.8321\n",
      "Epoch 020 | Train Loss: 0.3436 Acc: 0.8489 | Val Loss: 0.3425 Acc: 0.8484\n",
      "Epoch 021 | Train Loss: 0.3439 Acc: 0.8484 | Val Loss: 0.3545 Acc: 0.8364\n",
      "Epoch 022 | Train Loss: 0.3292 Acc: 0.8591 | Val Loss: 0.3114 Acc: 0.8659\n",
      "Epoch 023 | Train Loss: 0.3235 Acc: 0.8632 | Val Loss: 0.3254 Acc: 0.8508\n",
      "Epoch 024 | Train Loss: 0.3138 Acc: 0.8641 | Val Loss: 0.3251 Acc: 0.8521\n",
      "Epoch 025 | Train Loss: 0.3142 Acc: 0.8695 | Val Loss: 0.2999 Acc: 0.8641\n",
      "Epoch 026 | Train Loss: 0.2915 Acc: 0.8798 | Val Loss: 0.2990 Acc: 0.8690\n",
      "Epoch 027 | Train Loss: 0.2740 Acc: 0.8845 | Val Loss: 0.2753 Acc: 0.8841\n",
      "Epoch 028 | Train Loss: 0.2702 Acc: 0.8869 | Val Loss: 0.2607 Acc: 0.8913\n",
      "Epoch 029 | Train Loss: 0.2641 Acc: 0.8890 | Val Loss: 0.2435 Acc: 0.8973\n",
      "Epoch 030 | Train Loss: 0.2548 Acc: 0.8987 | Val Loss: 0.2759 Acc: 0.8847\n",
      "Epoch 031 | Train Loss: 0.2531 Acc: 0.8984 | Val Loss: 0.2311 Acc: 0.9094\n",
      "Epoch 032 | Train Loss: 0.2390 Acc: 0.9035 | Val Loss: 0.2757 Acc: 0.8871\n",
      "Epoch 033 | Train Loss: 0.2348 Acc: 0.9025 | Val Loss: 0.2372 Acc: 0.9058\n",
      "Epoch 034 | Train Loss: 0.2217 Acc: 0.9100 | Val Loss: 0.2255 Acc: 0.9058\n",
      "Epoch 035 | Train Loss: 0.2196 Acc: 0.9091 | Val Loss: 0.2265 Acc: 0.9016\n",
      "Epoch 036 | Train Loss: 0.2146 Acc: 0.9127 | Val Loss: 0.2252 Acc: 0.9034\n",
      "Epoch 037 | Train Loss: 0.2049 Acc: 0.9179 | Val Loss: 0.2175 Acc: 0.9179\n",
      "Epoch 038 | Train Loss: 0.1954 Acc: 0.9209 | Val Loss: 0.1899 Acc: 0.9293\n",
      "Epoch 039 | Train Loss: 0.1935 Acc: 0.9215 | Val Loss: 0.2046 Acc: 0.9130\n",
      "Epoch 040 | Train Loss: 0.1935 Acc: 0.9215 | Val Loss: 0.2022 Acc: 0.9251\n",
      "Epoch 041 | Train Loss: 0.1751 Acc: 0.9280 | Val Loss: 0.1874 Acc: 0.9227\n",
      "Epoch 042 | Train Loss: 0.1747 Acc: 0.9369 | Val Loss: 0.1911 Acc: 0.9293\n",
      "Epoch 043 | Train Loss: 0.1794 Acc: 0.9308 | Val Loss: 0.1869 Acc: 0.9257\n",
      "Epoch 044 | Train Loss: 0.1704 Acc: 0.9321 | Val Loss: 0.2151 Acc: 0.9197\n",
      "Epoch 045 | Train Loss: 0.1664 Acc: 0.9360 | Val Loss: 0.1899 Acc: 0.9318\n",
      "Epoch 046 | Train Loss: 0.1655 Acc: 0.9363 | Val Loss: 0.2119 Acc: 0.9185\n",
      "Epoch 047 | Train Loss: 0.1680 Acc: 0.9357 | Val Loss: 0.1882 Acc: 0.9330\n",
      "Epoch 048 | Train Loss: 0.1697 Acc: 0.9330 | Val Loss: 0.1934 Acc: 0.9191\n",
      "Epoch 049 | Train Loss: 0.1628 Acc: 0.9428 | Val Loss: 0.1606 Acc: 0.9390\n",
      "Epoch 050 | Train Loss: 0.1560 Acc: 0.9392 | Val Loss: 0.1568 Acc: 0.9378\n",
      "Epoch 051 | Train Loss: 0.1549 Acc: 0.9379 | Val Loss: 0.1797 Acc: 0.9275\n",
      "Epoch 052 | Train Loss: 0.1392 Acc: 0.9479 | Val Loss: 0.1657 Acc: 0.9330\n",
      "Epoch 053 | Train Loss: 0.1538 Acc: 0.9373 | Val Loss: 0.1676 Acc: 0.9354\n",
      "Epoch 054 | Train Loss: 0.1357 Acc: 0.9465 | Val Loss: 0.1596 Acc: 0.9402\n",
      "Epoch 055 | Train Loss: 0.1501 Acc: 0.9395 | Val Loss: 0.1716 Acc: 0.9360\n",
      "Epoch 056 | Train Loss: 0.1267 Acc: 0.9497 | Val Loss: 0.1902 Acc: 0.9306\n",
      "Epoch 057 | Train Loss: 0.1378 Acc: 0.9453 | Val Loss: 0.1577 Acc: 0.9360\n",
      "Epoch 058 | Train Loss: 0.1332 Acc: 0.9487 | Val Loss: 0.1840 Acc: 0.9269\n",
      "Epoch 059 | Train Loss: 0.1315 Acc: 0.9487 | Val Loss: 0.1963 Acc: 0.9161\n",
      "Epoch 060 | Train Loss: 0.1343 Acc: 0.9508 | Val Loss: 0.1919 Acc: 0.9318\n",
      "Early stopping triggered.\n",
      "Epoch 001 | Train Loss: 0.6834 Acc: 0.5719 | Val Loss: 0.6762 Acc: 0.5888\n",
      "Epoch 002 | Train Loss: 0.6728 Acc: 0.5978 | Val Loss: 0.6656 Acc: 0.6008\n",
      "Epoch 003 | Train Loss: 0.6240 Acc: 0.6619 | Val Loss: 0.5881 Acc: 0.6987\n",
      "Epoch 004 | Train Loss: 0.5660 Acc: 0.7250 | Val Loss: 0.5648 Acc: 0.7174\n",
      "Epoch 005 | Train Loss: 0.5504 Acc: 0.7320 | Val Loss: 0.5515 Acc: 0.7331\n",
      "Epoch 006 | Train Loss: 0.5216 Acc: 0.7546 | Val Loss: 0.5381 Acc: 0.7421\n",
      "Epoch 007 | Train Loss: 0.5210 Acc: 0.7510 | Val Loss: 0.5362 Acc: 0.7512\n",
      "Epoch 008 | Train Loss: 0.4951 Acc: 0.7691 | Val Loss: 0.5103 Acc: 0.7536\n",
      "Epoch 009 | Train Loss: 0.4707 Acc: 0.7832 | Val Loss: 0.4756 Acc: 0.7705\n",
      "Epoch 010 | Train Loss: 0.4509 Acc: 0.7947 | Val Loss: 0.4481 Acc: 0.7832\n",
      "Epoch 011 | Train Loss: 0.4378 Acc: 0.8043 | Val Loss: 0.4218 Acc: 0.7971\n",
      "Epoch 012 | Train Loss: 0.4080 Acc: 0.8132 | Val Loss: 0.3954 Acc: 0.8146\n",
      "Epoch 013 | Train Loss: 0.3799 Acc: 0.8341 | Val Loss: 0.3808 Acc: 0.8357\n",
      "Epoch 014 | Train Loss: 0.3542 Acc: 0.8529 | Val Loss: 0.3341 Acc: 0.8527\n",
      "Epoch 015 | Train Loss: 0.3207 Acc: 0.8682 | Val Loss: 0.3472 Acc: 0.8376\n",
      "Epoch 016 | Train Loss: 0.3006 Acc: 0.8765 | Val Loss: 0.3212 Acc: 0.8629\n",
      "Epoch 017 | Train Loss: 0.2777 Acc: 0.8874 | Val Loss: 0.3101 Acc: 0.8696\n",
      "Epoch 018 | Train Loss: 0.2617 Acc: 0.8919 | Val Loss: 0.3029 Acc: 0.8768\n",
      "Epoch 019 | Train Loss: 0.2419 Acc: 0.9011 | Val Loss: 0.2935 Acc: 0.8798\n",
      "Epoch 020 | Train Loss: 0.2394 Acc: 0.9031 | Val Loss: 0.2329 Acc: 0.9058\n",
      "Epoch 021 | Train Loss: 0.2100 Acc: 0.9170 | Val Loss: 0.2497 Acc: 0.9052\n",
      "Epoch 022 | Train Loss: 0.1996 Acc: 0.9209 | Val Loss: 0.2806 Acc: 0.8895\n",
      "Epoch 023 | Train Loss: 0.1917 Acc: 0.9244 | Val Loss: 0.2503 Acc: 0.9076\n",
      "Epoch 024 | Train Loss: 0.1871 Acc: 0.9257 | Val Loss: 0.2185 Acc: 0.9130\n",
      "Epoch 025 | Train Loss: 0.1611 Acc: 0.9379 | Val Loss: 0.2137 Acc: 0.9130\n",
      "Epoch 026 | Train Loss: 0.1616 Acc: 0.9378 | Val Loss: 0.2099 Acc: 0.9293\n",
      "Epoch 027 | Train Loss: 0.1566 Acc: 0.9425 | Val Loss: 0.2032 Acc: 0.9143\n",
      "Epoch 028 | Train Loss: 0.1452 Acc: 0.9456 | Val Loss: 0.2068 Acc: 0.9167\n",
      "Epoch 029 | Train Loss: 0.1405 Acc: 0.9450 | Val Loss: 0.2167 Acc: 0.9233\n",
      "Epoch 030 | Train Loss: 0.1279 Acc: 0.9518 | Val Loss: 0.1996 Acc: 0.9245\n",
      "Epoch 031 | Train Loss: 0.1432 Acc: 0.9464 | Val Loss: 0.2155 Acc: 0.9185\n",
      "Epoch 032 | Train Loss: 0.1235 Acc: 0.9503 | Val Loss: 0.2532 Acc: 0.9016\n",
      "Epoch 033 | Train Loss: 0.1210 Acc: 0.9523 | Val Loss: 0.2068 Acc: 0.9287\n",
      "Epoch 034 | Train Loss: 0.1137 Acc: 0.9570 | Val Loss: 0.2088 Acc: 0.9203\n",
      "Epoch 035 | Train Loss: 0.1070 Acc: 0.9606 | Val Loss: 0.1697 Acc: 0.9318\n",
      "Epoch 036 | Train Loss: 0.0979 Acc: 0.9638 | Val Loss: 0.2315 Acc: 0.9269\n",
      "Epoch 037 | Train Loss: 0.1006 Acc: 0.9618 | Val Loss: 0.1693 Acc: 0.9378\n",
      "Epoch 038 | Train Loss: 0.1027 Acc: 0.9636 | Val Loss: 0.1757 Acc: 0.9318\n",
      "Epoch 039 | Train Loss: 0.0942 Acc: 0.9626 | Val Loss: 0.1853 Acc: 0.9300\n",
      "Epoch 040 | Train Loss: 0.0918 Acc: 0.9662 | Val Loss: 0.1713 Acc: 0.9348\n",
      "Epoch 041 | Train Loss: 0.0875 Acc: 0.9654 | Val Loss: 0.2148 Acc: 0.9312\n",
      "Epoch 042 | Train Loss: 0.0856 Acc: 0.9654 | Val Loss: 0.1848 Acc: 0.9306\n",
      "Epoch 043 | Train Loss: 0.0948 Acc: 0.9639 | Val Loss: 0.1607 Acc: 0.9463\n",
      "Epoch 044 | Train Loss: 0.0847 Acc: 0.9669 | Val Loss: 0.1650 Acc: 0.9408\n",
      "Epoch 045 | Train Loss: 0.0941 Acc: 0.9660 | Val Loss: 0.1745 Acc: 0.9426\n",
      "Epoch 046 | Train Loss: 0.0791 Acc: 0.9725 | Val Loss: 0.2001 Acc: 0.9257\n",
      "Epoch 047 | Train Loss: 0.0767 Acc: 0.9695 | Val Loss: 0.1858 Acc: 0.9354\n",
      "Epoch 048 | Train Loss: 0.0756 Acc: 0.9713 | Val Loss: 0.1998 Acc: 0.9366\n",
      "Epoch 049 | Train Loss: 0.0725 Acc: 0.9742 | Val Loss: 0.1826 Acc: 0.9366\n",
      "Epoch 050 | Train Loss: 0.0776 Acc: 0.9715 | Val Loss: 0.1775 Acc: 0.9372\n",
      "Epoch 051 | Train Loss: 0.0756 Acc: 0.9722 | Val Loss: 0.1834 Acc: 0.9366\n",
      "Epoch 052 | Train Loss: 0.0666 Acc: 0.9745 | Val Loss: 0.1708 Acc: 0.9396\n",
      "Epoch 053 | Train Loss: 0.0662 Acc: 0.9766 | Val Loss: 0.1909 Acc: 0.9300\n",
      "Early stopping triggered.\n",
      "Epoch 001 | Train Loss: 0.6813 Acc: 0.5727 | Val Loss: 0.6782 Acc: 0.5791\n",
      "Epoch 002 | Train Loss: 0.6701 Acc: 0.5901 | Val Loss: 0.6460 Acc: 0.6425\n",
      "Epoch 003 | Train Loss: 0.6147 Acc: 0.6769 | Val Loss: 0.5856 Acc: 0.6938\n",
      "Epoch 004 | Train Loss: 0.5737 Acc: 0.7125 | Val Loss: 0.5567 Acc: 0.7156\n",
      "Epoch 005 | Train Loss: 0.5415 Acc: 0.7386 | Val Loss: 0.5447 Acc: 0.7295\n",
      "Epoch 006 | Train Loss: 0.5179 Acc: 0.7539 | Val Loss: 0.5056 Acc: 0.7506\n",
      "Epoch 007 | Train Loss: 0.5023 Acc: 0.7617 | Val Loss: 0.4834 Acc: 0.7687\n",
      "Epoch 008 | Train Loss: 0.4731 Acc: 0.7780 | Val Loss: 0.4671 Acc: 0.7820\n",
      "Epoch 009 | Train Loss: 0.4615 Acc: 0.7867 | Val Loss: 0.4491 Acc: 0.7880\n",
      "Epoch 010 | Train Loss: 0.4304 Acc: 0.8043 | Val Loss: 0.4398 Acc: 0.7886\n",
      "Epoch 011 | Train Loss: 0.4172 Acc: 0.8137 | Val Loss: 0.3936 Acc: 0.8074\n",
      "Epoch 012 | Train Loss: 0.3868 Acc: 0.8279 | Val Loss: 0.3800 Acc: 0.8176\n",
      "Epoch 013 | Train Loss: 0.3714 Acc: 0.8354 | Val Loss: 0.3755 Acc: 0.8261\n",
      "Epoch 014 | Train Loss: 0.3502 Acc: 0.8454 | Val Loss: 0.3477 Acc: 0.8370\n",
      "Epoch 015 | Train Loss: 0.3317 Acc: 0.8567 | Val Loss: 0.3596 Acc: 0.8364\n",
      "Epoch 016 | Train Loss: 0.3202 Acc: 0.8603 | Val Loss: 0.2919 Acc: 0.8635\n",
      "Epoch 017 | Train Loss: 0.3006 Acc: 0.8745 | Val Loss: 0.2852 Acc: 0.8762\n",
      "Epoch 018 | Train Loss: 0.2812 Acc: 0.8842 | Val Loss: 0.2398 Acc: 0.9040\n",
      "Epoch 019 | Train Loss: 0.2571 Acc: 0.8976 | Val Loss: 0.2575 Acc: 0.8871\n",
      "Epoch 020 | Train Loss: 0.2521 Acc: 0.8972 | Val Loss: 0.2475 Acc: 0.8961\n",
      "Epoch 021 | Train Loss: 0.2281 Acc: 0.9073 | Val Loss: 0.3112 Acc: 0.8786\n",
      "Epoch 022 | Train Loss: 0.2338 Acc: 0.9035 | Val Loss: 0.2694 Acc: 0.8732\n",
      "Epoch 023 | Train Loss: 0.2139 Acc: 0.9173 | Val Loss: 0.2103 Acc: 0.9185\n",
      "Epoch 024 | Train Loss: 0.1961 Acc: 0.9206 | Val Loss: 0.2389 Acc: 0.9088\n",
      "Epoch 025 | Train Loss: 0.1921 Acc: 0.9198 | Val Loss: 0.2015 Acc: 0.9173\n",
      "Epoch 026 | Train Loss: 0.1857 Acc: 0.9284 | Val Loss: 0.1729 Acc: 0.9336\n",
      "Epoch 027 | Train Loss: 0.1713 Acc: 0.9340 | Val Loss: 0.1960 Acc: 0.9215\n",
      "Epoch 028 | Train Loss: 0.1617 Acc: 0.9363 | Val Loss: 0.1709 Acc: 0.9275\n",
      "Epoch 029 | Train Loss: 0.1521 Acc: 0.9413 | Val Loss: 0.1674 Acc: 0.9293\n",
      "Epoch 030 | Train Loss: 0.1546 Acc: 0.9402 | Val Loss: 0.1783 Acc: 0.9312\n",
      "Epoch 031 | Train Loss: 0.1486 Acc: 0.9413 | Val Loss: 0.1753 Acc: 0.9287\n",
      "Epoch 032 | Train Loss: 0.1408 Acc: 0.9494 | Val Loss: 0.1587 Acc: 0.9336\n",
      "Epoch 033 | Train Loss: 0.1231 Acc: 0.9518 | Val Loss: 0.1608 Acc: 0.9438\n",
      "Epoch 034 | Train Loss: 0.1292 Acc: 0.9503 | Val Loss: 0.1978 Acc: 0.9239\n",
      "Epoch 035 | Train Loss: 0.1220 Acc: 0.9524 | Val Loss: 0.1524 Acc: 0.9384\n",
      "Epoch 036 | Train Loss: 0.1112 Acc: 0.9585 | Val Loss: 0.1692 Acc: 0.9366\n",
      "Epoch 037 | Train Loss: 0.1150 Acc: 0.9550 | Val Loss: 0.1524 Acc: 0.9420\n",
      "Epoch 038 | Train Loss: 0.1138 Acc: 0.9570 | Val Loss: 0.1429 Acc: 0.9450\n",
      "Epoch 039 | Train Loss: 0.1027 Acc: 0.9597 | Val Loss: 0.1366 Acc: 0.9475\n",
      "Epoch 040 | Train Loss: 0.1125 Acc: 0.9562 | Val Loss: 0.1717 Acc: 0.9372\n",
      "Epoch 041 | Train Loss: 0.0982 Acc: 0.9642 | Val Loss: 0.1453 Acc: 0.9432\n",
      "Epoch 042 | Train Loss: 0.0904 Acc: 0.9660 | Val Loss: 0.1456 Acc: 0.9517\n",
      "Epoch 043 | Train Loss: 0.0936 Acc: 0.9681 | Val Loss: 0.1613 Acc: 0.9366\n",
      "Epoch 044 | Train Loss: 0.0859 Acc: 0.9680 | Val Loss: 0.1804 Acc: 0.9366\n",
      "Epoch 045 | Train Loss: 0.0889 Acc: 0.9668 | Val Loss: 0.1716 Acc: 0.9372\n",
      "Epoch 046 | Train Loss: 0.0863 Acc: 0.9681 | Val Loss: 0.1651 Acc: 0.9342\n",
      "Epoch 047 | Train Loss: 0.0834 Acc: 0.9706 | Val Loss: 0.1522 Acc: 0.9469\n",
      "Epoch 048 | Train Loss: 0.0835 Acc: 0.9660 | Val Loss: 0.1530 Acc: 0.9450\n",
      "Epoch 049 | Train Loss: 0.0999 Acc: 0.9610 | Val Loss: 0.1473 Acc: 0.9523\n",
      "Early stopping triggered.\n",
      "Epoch 001 | Train Loss: 0.6790 Acc: 0.5831 | Val Loss: 0.6757 Acc: 0.5912\n",
      "Epoch 002 | Train Loss: 0.6734 Acc: 0.5931 | Val Loss: 0.6666 Acc: 0.6021\n",
      "Epoch 003 | Train Loss: 0.6664 Acc: 0.6058 | Val Loss: 0.6648 Acc: 0.6008\n",
      "Epoch 004 | Train Loss: 0.6559 Acc: 0.6185 | Val Loss: 0.6566 Acc: 0.6051\n",
      "Epoch 005 | Train Loss: 0.6537 Acc: 0.6201 | Val Loss: 0.6192 Acc: 0.6691\n",
      "Epoch 006 | Train Loss: 0.6143 Acc: 0.6832 | Val Loss: 0.5909 Acc: 0.7017\n",
      "Epoch 007 | Train Loss: 0.5698 Acc: 0.7154 | Val Loss: 0.5722 Acc: 0.7083\n",
      "Epoch 008 | Train Loss: 0.5545 Acc: 0.7225 | Val Loss: 0.5710 Acc: 0.7059\n",
      "Epoch 009 | Train Loss: 0.5422 Acc: 0.7365 | Val Loss: 0.5428 Acc: 0.7216\n",
      "Epoch 010 | Train Loss: 0.5223 Acc: 0.7465 | Val Loss: 0.5287 Acc: 0.7331\n",
      "Epoch 011 | Train Loss: 0.5101 Acc: 0.7525 | Val Loss: 0.5187 Acc: 0.7572\n",
      "Epoch 012 | Train Loss: 0.4975 Acc: 0.7657 | Val Loss: 0.5068 Acc: 0.7446\n",
      "Epoch 013 | Train Loss: 0.4811 Acc: 0.7747 | Val Loss: 0.4693 Acc: 0.7766\n",
      "Epoch 014 | Train Loss: 0.4479 Acc: 0.7867 | Val Loss: 0.4640 Acc: 0.7850\n",
      "Epoch 015 | Train Loss: 0.4322 Acc: 0.8046 | Val Loss: 0.4246 Acc: 0.8007\n",
      "Epoch 016 | Train Loss: 0.4063 Acc: 0.8128 | Val Loss: 0.4063 Acc: 0.8110\n",
      "Epoch 017 | Train Loss: 0.3811 Acc: 0.8291 | Val Loss: 0.3905 Acc: 0.8237\n",
      "Epoch 018 | Train Loss: 0.3680 Acc: 0.8347 | Val Loss: 0.3848 Acc: 0.8207\n",
      "Epoch 019 | Train Loss: 0.3401 Acc: 0.8511 | Val Loss: 0.3735 Acc: 0.8388\n",
      "Epoch 020 | Train Loss: 0.3372 Acc: 0.8516 | Val Loss: 0.3601 Acc: 0.8412\n",
      "Epoch 021 | Train Loss: 0.2981 Acc: 0.8780 | Val Loss: 0.2975 Acc: 0.8792\n",
      "Epoch 022 | Train Loss: 0.2884 Acc: 0.8795 | Val Loss: 0.2935 Acc: 0.8798\n",
      "Epoch 023 | Train Loss: 0.2832 Acc: 0.8827 | Val Loss: 0.2845 Acc: 0.8768\n",
      "Epoch 024 | Train Loss: 0.2713 Acc: 0.8862 | Val Loss: 0.2996 Acc: 0.8883\n",
      "Epoch 025 | Train Loss: 0.2607 Acc: 0.8984 | Val Loss: 0.2773 Acc: 0.8865\n",
      "Epoch 026 | Train Loss: 0.2370 Acc: 0.9025 | Val Loss: 0.2626 Acc: 0.8901\n",
      "Epoch 027 | Train Loss: 0.2284 Acc: 0.9031 | Val Loss: 0.2818 Acc: 0.8889\n",
      "Epoch 028 | Train Loss: 0.2272 Acc: 0.9085 | Val Loss: 0.2328 Acc: 0.9034\n",
      "Epoch 029 | Train Loss: 0.2025 Acc: 0.9185 | Val Loss: 0.2622 Acc: 0.8883\n",
      "Epoch 030 | Train Loss: 0.2209 Acc: 0.9088 | Val Loss: 0.2475 Acc: 0.9016\n",
      "Epoch 031 | Train Loss: 0.1885 Acc: 0.9239 | Val Loss: 0.2457 Acc: 0.9094\n",
      "Epoch 032 | Train Loss: 0.1949 Acc: 0.9265 | Val Loss: 0.2314 Acc: 0.9088\n",
      "Epoch 033 | Train Loss: 0.1777 Acc: 0.9295 | Val Loss: 0.2240 Acc: 0.9185\n",
      "Epoch 034 | Train Loss: 0.1816 Acc: 0.9304 | Val Loss: 0.2088 Acc: 0.9203\n",
      "Epoch 035 | Train Loss: 0.1679 Acc: 0.9364 | Val Loss: 0.2087 Acc: 0.9149\n",
      "Epoch 036 | Train Loss: 0.1618 Acc: 0.9367 | Val Loss: 0.2148 Acc: 0.9130\n",
      "Epoch 037 | Train Loss: 0.1545 Acc: 0.9402 | Val Loss: 0.2136 Acc: 0.9155\n",
      "Epoch 038 | Train Loss: 0.1457 Acc: 0.9440 | Val Loss: 0.2278 Acc: 0.9191\n",
      "Epoch 039 | Train Loss: 0.1428 Acc: 0.9450 | Val Loss: 0.1918 Acc: 0.9233\n",
      "Epoch 040 | Train Loss: 0.1439 Acc: 0.9426 | Val Loss: 0.2146 Acc: 0.9233\n",
      "Epoch 041 | Train Loss: 0.1418 Acc: 0.9452 | Val Loss: 0.1822 Acc: 0.9372\n",
      "Epoch 042 | Train Loss: 0.1338 Acc: 0.9469 | Val Loss: 0.1961 Acc: 0.9342\n",
      "Epoch 043 | Train Loss: 0.1261 Acc: 0.9527 | Val Loss: 0.2254 Acc: 0.9124\n",
      "Epoch 044 | Train Loss: 0.1220 Acc: 0.9521 | Val Loss: 0.1857 Acc: 0.9336\n",
      "Epoch 045 | Train Loss: 0.1230 Acc: 0.9508 | Val Loss: 0.1801 Acc: 0.9306\n",
      "Epoch 046 | Train Loss: 0.1193 Acc: 0.9568 | Val Loss: 0.1947 Acc: 0.9233\n",
      "Epoch 047 | Train Loss: 0.1279 Acc: 0.9496 | Val Loss: 0.1779 Acc: 0.9378\n",
      "Epoch 048 | Train Loss: 0.1156 Acc: 0.9559 | Val Loss: 0.1934 Acc: 0.9396\n",
      "Epoch 049 | Train Loss: 0.1119 Acc: 0.9567 | Val Loss: 0.1713 Acc: 0.9396\n",
      "Epoch 050 | Train Loss: 0.1050 Acc: 0.9592 | Val Loss: 0.2281 Acc: 0.9275\n",
      "Epoch 051 | Train Loss: 0.1085 Acc: 0.9583 | Val Loss: 0.1906 Acc: 0.9396\n",
      "Epoch 052 | Train Loss: 0.1088 Acc: 0.9598 | Val Loss: 0.1990 Acc: 0.9330\n",
      "Epoch 053 | Train Loss: 0.0985 Acc: 0.9635 | Val Loss: 0.1792 Acc: 0.9408\n",
      "Epoch 054 | Train Loss: 0.0872 Acc: 0.9663 | Val Loss: 0.1681 Acc: 0.9372\n",
      "Epoch 055 | Train Loss: 0.1016 Acc: 0.9585 | Val Loss: 0.2045 Acc: 0.9245\n",
      "Epoch 056 | Train Loss: 0.0872 Acc: 0.9650 | Val Loss: 0.1919 Acc: 0.9348\n",
      "Epoch 057 | Train Loss: 0.1013 Acc: 0.9642 | Val Loss: 0.1671 Acc: 0.9414\n",
      "Epoch 058 | Train Loss: 0.0971 Acc: 0.9657 | Val Loss: 0.1874 Acc: 0.9330\n",
      "Epoch 059 | Train Loss: 0.0838 Acc: 0.9689 | Val Loss: 0.1515 Acc: 0.9493\n",
      "Epoch 060 | Train Loss: 0.0801 Acc: 0.9695 | Val Loss: 0.1786 Acc: 0.9366\n",
      "Epoch 001 | Train Loss: 0.6781 Acc: 0.5818 | Val Loss: 0.6779 Acc: 0.5773\n",
      "Epoch 002 | Train Loss: 0.6697 Acc: 0.6012 | Val Loss: 0.6647 Acc: 0.6027\n",
      "Epoch 003 | Train Loss: 0.6594 Acc: 0.6074 | Val Loss: 0.6507 Acc: 0.6111\n",
      "Epoch 004 | Train Loss: 0.6273 Acc: 0.6550 | Val Loss: 0.5959 Acc: 0.6902\n",
      "Epoch 005 | Train Loss: 0.5785 Acc: 0.7096 | Val Loss: 0.5899 Acc: 0.7114\n",
      "Epoch 006 | Train Loss: 0.5610 Acc: 0.7258 | Val Loss: 0.5821 Acc: 0.7107\n",
      "Epoch 007 | Train Loss: 0.5457 Acc: 0.7341 | Val Loss: 0.5798 Acc: 0.7150\n",
      "Epoch 008 | Train Loss: 0.5221 Acc: 0.7497 | Val Loss: 0.5120 Acc: 0.7530\n",
      "Epoch 009 | Train Loss: 0.4972 Acc: 0.7620 | Val Loss: 0.4849 Acc: 0.7639\n",
      "Epoch 010 | Train Loss: 0.4804 Acc: 0.7773 | Val Loss: 0.4842 Acc: 0.7639\n",
      "Epoch 011 | Train Loss: 0.4575 Acc: 0.7897 | Val Loss: 0.4378 Acc: 0.7989\n",
      "Epoch 012 | Train Loss: 0.4268 Acc: 0.8057 | Val Loss: 0.4359 Acc: 0.7874\n",
      "Epoch 013 | Train Loss: 0.4073 Acc: 0.8173 | Val Loss: 0.4200 Acc: 0.8092\n",
      "Epoch 014 | Train Loss: 0.3969 Acc: 0.8218 | Val Loss: 0.3841 Acc: 0.8237\n",
      "Epoch 015 | Train Loss: 0.3661 Acc: 0.8395 | Val Loss: 0.3656 Acc: 0.8315\n",
      "Epoch 016 | Train Loss: 0.3554 Acc: 0.8511 | Val Loss: 0.3577 Acc: 0.8364\n",
      "Epoch 017 | Train Loss: 0.3334 Acc: 0.8605 | Val Loss: 0.3218 Acc: 0.8671\n",
      "Epoch 018 | Train Loss: 0.3151 Acc: 0.8643 | Val Loss: 0.3452 Acc: 0.8448\n",
      "Epoch 019 | Train Loss: 0.3016 Acc: 0.8757 | Val Loss: 0.3183 Acc: 0.8720\n",
      "Epoch 020 | Train Loss: 0.2779 Acc: 0.8839 | Val Loss: 0.2707 Acc: 0.8822\n",
      "Epoch 021 | Train Loss: 0.2688 Acc: 0.8907 | Val Loss: 0.2787 Acc: 0.8865\n",
      "Epoch 022 | Train Loss: 0.2677 Acc: 0.8899 | Val Loss: 0.2519 Acc: 0.9010\n",
      "Epoch 023 | Train Loss: 0.2458 Acc: 0.9003 | Val Loss: 0.2672 Acc: 0.8937\n",
      "Epoch 024 | Train Loss: 0.2285 Acc: 0.9073 | Val Loss: 0.2607 Acc: 0.8986\n",
      "Epoch 025 | Train Loss: 0.2251 Acc: 0.9090 | Val Loss: 0.2618 Acc: 0.8907\n",
      "Epoch 026 | Train Loss: 0.2204 Acc: 0.9132 | Val Loss: 0.2372 Acc: 0.9076\n",
      "Epoch 027 | Train Loss: 0.1986 Acc: 0.9231 | Val Loss: 0.2056 Acc: 0.9215\n",
      "Epoch 028 | Train Loss: 0.2006 Acc: 0.9225 | Val Loss: 0.2304 Acc: 0.9094\n",
      "Epoch 029 | Train Loss: 0.2015 Acc: 0.9218 | Val Loss: 0.2238 Acc: 0.9028\n",
      "Epoch 030 | Train Loss: 0.1810 Acc: 0.9283 | Val Loss: 0.2208 Acc: 0.9088\n",
      "Epoch 031 | Train Loss: 0.1755 Acc: 0.9337 | Val Loss: 0.2212 Acc: 0.9155\n",
      "Epoch 032 | Train Loss: 0.1686 Acc: 0.9336 | Val Loss: 0.2262 Acc: 0.9203\n",
      "Epoch 033 | Train Loss: 0.1640 Acc: 0.9369 | Val Loss: 0.2278 Acc: 0.9118\n",
      "Epoch 034 | Train Loss: 0.1556 Acc: 0.9364 | Val Loss: 0.1928 Acc: 0.9287\n",
      "Epoch 035 | Train Loss: 0.1616 Acc: 0.9384 | Val Loss: 0.1993 Acc: 0.9233\n",
      "Epoch 036 | Train Loss: 0.1552 Acc: 0.9390 | Val Loss: 0.1915 Acc: 0.9281\n",
      "Epoch 037 | Train Loss: 0.1421 Acc: 0.9447 | Val Loss: 0.2179 Acc: 0.9215\n",
      "Epoch 038 | Train Loss: 0.1236 Acc: 0.9491 | Val Loss: 0.2090 Acc: 0.9251\n",
      "Epoch 039 | Train Loss: 0.1434 Acc: 0.9461 | Val Loss: 0.1787 Acc: 0.9366\n",
      "Epoch 040 | Train Loss: 0.1273 Acc: 0.9529 | Val Loss: 0.1892 Acc: 0.9360\n",
      "Epoch 041 | Train Loss: 0.1262 Acc: 0.9505 | Val Loss: 0.1807 Acc: 0.9348\n",
      "Epoch 042 | Train Loss: 0.1230 Acc: 0.9518 | Val Loss: 0.2034 Acc: 0.9215\n",
      "Epoch 043 | Train Loss: 0.1213 Acc: 0.9568 | Val Loss: 0.1886 Acc: 0.9312\n",
      "Epoch 044 | Train Loss: 0.1171 Acc: 0.9558 | Val Loss: 0.1920 Acc: 0.9318\n",
      "Epoch 045 | Train Loss: 0.1235 Acc: 0.9524 | Val Loss: 0.1706 Acc: 0.9414\n",
      "Epoch 046 | Train Loss: 0.0939 Acc: 0.9636 | Val Loss: 0.1603 Acc: 0.9438\n",
      "Epoch 047 | Train Loss: 0.1097 Acc: 0.9598 | Val Loss: 0.1699 Acc: 0.9414\n",
      "Epoch 048 | Train Loss: 0.1001 Acc: 0.9616 | Val Loss: 0.1698 Acc: 0.9432\n",
      "Epoch 049 | Train Loss: 0.1159 Acc: 0.9544 | Val Loss: 0.1719 Acc: 0.9360\n",
      "Epoch 050 | Train Loss: 0.1072 Acc: 0.9598 | Val Loss: 0.1813 Acc: 0.9408\n",
      "Epoch 051 | Train Loss: 0.0957 Acc: 0.9629 | Val Loss: 0.1741 Acc: 0.9408\n",
      "Epoch 052 | Train Loss: 0.1067 Acc: 0.9607 | Val Loss: 0.2252 Acc: 0.9227\n",
      "Epoch 053 | Train Loss: 0.1002 Acc: 0.9636 | Val Loss: 0.1590 Acc: 0.9493\n",
      "Epoch 054 | Train Loss: 0.0941 Acc: 0.9662 | Val Loss: 0.1665 Acc: 0.9408\n",
      "Epoch 055 | Train Loss: 0.0926 Acc: 0.9636 | Val Loss: 0.1805 Acc: 0.9366\n",
      "Epoch 056 | Train Loss: 0.0902 Acc: 0.9668 | Val Loss: 0.1616 Acc: 0.9523\n",
      "Epoch 057 | Train Loss: 0.0950 Acc: 0.9645 | Val Loss: 0.2127 Acc: 0.9221\n",
      "Epoch 058 | Train Loss: 0.0757 Acc: 0.9712 | Val Loss: 0.1808 Acc: 0.9354\n",
      "Epoch 059 | Train Loss: 0.0879 Acc: 0.9665 | Val Loss: 0.1633 Acc: 0.9438\n",
      "Epoch 060 | Train Loss: 0.0837 Acc: 0.9692 | Val Loss: 0.1536 Acc: 0.9535\n",
      "Epoch 001 | Train Loss: 0.6809 Acc: 0.5774 | Val Loss: 0.6744 Acc: 0.5833\n",
      "Epoch 002 | Train Loss: 0.6672 Acc: 0.5952 | Val Loss: 0.6454 Acc: 0.6141\n",
      "Epoch 003 | Train Loss: 0.5995 Acc: 0.6921 | Val Loss: 0.5595 Acc: 0.7246\n",
      "Epoch 004 | Train Loss: 0.5464 Acc: 0.7349 | Val Loss: 0.5307 Acc: 0.7361\n",
      "Epoch 005 | Train Loss: 0.5148 Acc: 0.7584 | Val Loss: 0.5437 Acc: 0.7264\n",
      "Epoch 006 | Train Loss: 0.4994 Acc: 0.7626 | Val Loss: 0.4724 Acc: 0.7639\n",
      "Epoch 007 | Train Loss: 0.4699 Acc: 0.7811 | Val Loss: 0.4463 Acc: 0.7838\n",
      "Epoch 008 | Train Loss: 0.4445 Acc: 0.7980 | Val Loss: 0.4311 Acc: 0.7959\n",
      "Epoch 009 | Train Loss: 0.4104 Acc: 0.8152 | Val Loss: 0.4211 Acc: 0.7965\n",
      "Epoch 010 | Train Loss: 0.3844 Acc: 0.8285 | Val Loss: 0.4123 Acc: 0.7983\n",
      "Epoch 011 | Train Loss: 0.3594 Acc: 0.8419 | Val Loss: 0.3590 Acc: 0.8339\n",
      "Epoch 012 | Train Loss: 0.3394 Acc: 0.8549 | Val Loss: 0.3311 Acc: 0.8587\n",
      "Epoch 013 | Train Loss: 0.3215 Acc: 0.8652 | Val Loss: 0.3574 Acc: 0.8327\n",
      "Epoch 014 | Train Loss: 0.3019 Acc: 0.8732 | Val Loss: 0.3070 Acc: 0.8653\n",
      "Epoch 015 | Train Loss: 0.2792 Acc: 0.8854 | Val Loss: 0.2749 Acc: 0.8901\n",
      "Epoch 016 | Train Loss: 0.2537 Acc: 0.8967 | Val Loss: 0.3097 Acc: 0.8696\n",
      "Epoch 017 | Train Loss: 0.2369 Acc: 0.9025 | Val Loss: 0.2734 Acc: 0.8889\n",
      "Epoch 018 | Train Loss: 0.2199 Acc: 0.9103 | Val Loss: 0.2206 Acc: 0.9082\n",
      "Epoch 019 | Train Loss: 0.2207 Acc: 0.9132 | Val Loss: 0.2824 Acc: 0.8877\n",
      "Epoch 020 | Train Loss: 0.2044 Acc: 0.9185 | Val Loss: 0.2289 Acc: 0.9064\n",
      "Epoch 021 | Train Loss: 0.2022 Acc: 0.9219 | Val Loss: 0.2198 Acc: 0.9094\n",
      "Epoch 022 | Train Loss: 0.1875 Acc: 0.9272 | Val Loss: 0.2336 Acc: 0.8967\n",
      "Epoch 023 | Train Loss: 0.1703 Acc: 0.9340 | Val Loss: 0.2306 Acc: 0.9076\n",
      "Epoch 024 | Train Loss: 0.1658 Acc: 0.9360 | Val Loss: 0.2304 Acc: 0.9034\n",
      "Epoch 025 | Train Loss: 0.1611 Acc: 0.9364 | Val Loss: 0.2264 Acc: 0.9034\n",
      "Epoch 026 | Train Loss: 0.1584 Acc: 0.9419 | Val Loss: 0.1942 Acc: 0.9185\n",
      "Epoch 027 | Train Loss: 0.1393 Acc: 0.9484 | Val Loss: 0.2089 Acc: 0.9203\n",
      "Epoch 028 | Train Loss: 0.1416 Acc: 0.9440 | Val Loss: 0.2151 Acc: 0.9173\n",
      "Epoch 029 | Train Loss: 0.1381 Acc: 0.9478 | Val Loss: 0.2321 Acc: 0.9094\n",
      "Epoch 030 | Train Loss: 0.1407 Acc: 0.9456 | Val Loss: 0.2001 Acc: 0.9233\n",
      "Epoch 031 | Train Loss: 0.1170 Acc: 0.9570 | Val Loss: 0.2247 Acc: 0.9100\n",
      "Epoch 032 | Train Loss: 0.1259 Acc: 0.9506 | Val Loss: 0.1910 Acc: 0.9233\n",
      "Epoch 033 | Train Loss: 0.1152 Acc: 0.9574 | Val Loss: 0.2126 Acc: 0.9185\n",
      "Epoch 034 | Train Loss: 0.1096 Acc: 0.9585 | Val Loss: 0.1634 Acc: 0.9336\n",
      "Epoch 035 | Train Loss: 0.1014 Acc: 0.9610 | Val Loss: 0.1700 Acc: 0.9354\n",
      "Epoch 036 | Train Loss: 0.1054 Acc: 0.9615 | Val Loss: 0.1921 Acc: 0.9293\n",
      "Epoch 037 | Train Loss: 0.1050 Acc: 0.9604 | Val Loss: 0.1845 Acc: 0.9378\n",
      "Epoch 038 | Train Loss: 0.1024 Acc: 0.9609 | Val Loss: 0.1800 Acc: 0.9342\n",
      "Epoch 039 | Train Loss: 0.1025 Acc: 0.9623 | Val Loss: 0.1596 Acc: 0.9402\n",
      "Epoch 040 | Train Loss: 0.0878 Acc: 0.9686 | Val Loss: 0.1603 Acc: 0.9426\n",
      "Epoch 041 | Train Loss: 0.0887 Acc: 0.9651 | Val Loss: 0.1905 Acc: 0.9318\n",
      "Epoch 042 | Train Loss: 0.0928 Acc: 0.9639 | Val Loss: 0.1754 Acc: 0.9384\n",
      "Epoch 043 | Train Loss: 0.0917 Acc: 0.9645 | Val Loss: 0.1501 Acc: 0.9420\n",
      "Epoch 044 | Train Loss: 0.0929 Acc: 0.9647 | Val Loss: 0.1623 Acc: 0.9384\n",
      "Epoch 045 | Train Loss: 0.0844 Acc: 0.9695 | Val Loss: 0.1667 Acc: 0.9354\n",
      "Epoch 046 | Train Loss: 0.0789 Acc: 0.9718 | Val Loss: 0.1734 Acc: 0.9293\n",
      "Epoch 047 | Train Loss: 0.0858 Acc: 0.9683 | Val Loss: 0.1888 Acc: 0.9293\n",
      "Epoch 048 | Train Loss: 0.0904 Acc: 0.9669 | Val Loss: 0.1415 Acc: 0.9475\n",
      "Epoch 049 | Train Loss: 0.0758 Acc: 0.9703 | Val Loss: 0.2102 Acc: 0.9306\n",
      "Epoch 050 | Train Loss: 0.0814 Acc: 0.9710 | Val Loss: 0.1607 Acc: 0.9396\n",
      "Epoch 051 | Train Loss: 0.0789 Acc: 0.9725 | Val Loss: 0.1680 Acc: 0.9432\n",
      "Epoch 052 | Train Loss: 0.0736 Acc: 0.9745 | Val Loss: 0.1681 Acc: 0.9426\n",
      "Epoch 053 | Train Loss: 0.0754 Acc: 0.9725 | Val Loss: 0.1698 Acc: 0.9402\n",
      "Epoch 054 | Train Loss: 0.0691 Acc: 0.9733 | Val Loss: 0.1643 Acc: 0.9450\n",
      "Epoch 055 | Train Loss: 0.0746 Acc: 0.9724 | Val Loss: 0.1474 Acc: 0.9426\n",
      "Epoch 056 | Train Loss: 0.0738 Acc: 0.9722 | Val Loss: 0.1557 Acc: 0.9475\n",
      "Epoch 057 | Train Loss: 0.0741 Acc: 0.9724 | Val Loss: 0.1569 Acc: 0.9426\n",
      "Epoch 058 | Train Loss: 0.0695 Acc: 0.9752 | Val Loss: 0.1844 Acc: 0.9366\n",
      "Early stopping triggered.\n",
      "Epoch 001 | Train Loss: 0.6834 Acc: 0.5676 | Val Loss: 0.6790 Acc: 0.5761\n",
      "Epoch 002 | Train Loss: 0.6727 Acc: 0.5910 | Val Loss: 0.6689 Acc: 0.5948\n",
      "Epoch 003 | Train Loss: 0.6525 Acc: 0.6181 | Val Loss: 0.6172 Acc: 0.6655\n",
      "Epoch 004 | Train Loss: 0.5950 Acc: 0.6912 | Val Loss: 0.5608 Acc: 0.7198\n",
      "Epoch 005 | Train Loss: 0.5564 Acc: 0.7207 | Val Loss: 0.5426 Acc: 0.7277\n",
      "Epoch 006 | Train Loss: 0.5247 Acc: 0.7404 | Val Loss: 0.5177 Acc: 0.7434\n",
      "Epoch 007 | Train Loss: 0.5013 Acc: 0.7623 | Val Loss: 0.4998 Acc: 0.7494\n",
      "Epoch 008 | Train Loss: 0.4799 Acc: 0.7732 | Val Loss: 0.4776 Acc: 0.7699\n",
      "Epoch 009 | Train Loss: 0.4671 Acc: 0.7832 | Val Loss: 0.4523 Acc: 0.7850\n",
      "Epoch 010 | Train Loss: 0.4369 Acc: 0.8067 | Val Loss: 0.4477 Acc: 0.7977\n",
      "Epoch 011 | Train Loss: 0.4170 Acc: 0.8067 | Val Loss: 0.4083 Acc: 0.8056\n",
      "Epoch 012 | Train Loss: 0.3974 Acc: 0.8202 | Val Loss: 0.3951 Acc: 0.8134\n",
      "Epoch 013 | Train Loss: 0.3679 Acc: 0.8351 | Val Loss: 0.4035 Acc: 0.8164\n",
      "Epoch 014 | Train Loss: 0.3604 Acc: 0.8418 | Val Loss: 0.3662 Acc: 0.8345\n",
      "Epoch 015 | Train Loss: 0.3454 Acc: 0.8477 | Val Loss: 0.3423 Acc: 0.8321\n",
      "Epoch 016 | Train Loss: 0.3190 Acc: 0.8602 | Val Loss: 0.3299 Acc: 0.8581\n",
      "Epoch 017 | Train Loss: 0.2909 Acc: 0.8780 | Val Loss: 0.2990 Acc: 0.8690\n",
      "Epoch 018 | Train Loss: 0.2847 Acc: 0.8815 | Val Loss: 0.3038 Acc: 0.8623\n",
      "Epoch 019 | Train Loss: 0.2677 Acc: 0.8898 | Val Loss: 0.3474 Acc: 0.8581\n",
      "Epoch 020 | Train Loss: 0.2566 Acc: 0.8948 | Val Loss: 0.2597 Acc: 0.8822\n",
      "Epoch 021 | Train Loss: 0.2346 Acc: 0.9040 | Val Loss: 0.2603 Acc: 0.8859\n",
      "Epoch 022 | Train Loss: 0.2213 Acc: 0.9132 | Val Loss: 0.2973 Acc: 0.8756\n",
      "Epoch 023 | Train Loss: 0.2164 Acc: 0.9074 | Val Loss: 0.2472 Acc: 0.8998\n",
      "Epoch 024 | Train Loss: 0.2086 Acc: 0.9142 | Val Loss: 0.2233 Acc: 0.9040\n",
      "Epoch 025 | Train Loss: 0.1875 Acc: 0.9266 | Val Loss: 0.2263 Acc: 0.9034\n",
      "Epoch 026 | Train Loss: 0.1745 Acc: 0.9334 | Val Loss: 0.2504 Acc: 0.8955\n",
      "Epoch 027 | Train Loss: 0.1750 Acc: 0.9322 | Val Loss: 0.2098 Acc: 0.9149\n",
      "Epoch 028 | Train Loss: 0.1650 Acc: 0.9360 | Val Loss: 0.2038 Acc: 0.9130\n",
      "Epoch 029 | Train Loss: 0.1496 Acc: 0.9441 | Val Loss: 0.2073 Acc: 0.9227\n",
      "Epoch 030 | Train Loss: 0.1481 Acc: 0.9417 | Val Loss: 0.1814 Acc: 0.9227\n",
      "Epoch 031 | Train Loss: 0.1377 Acc: 0.9476 | Val Loss: 0.2129 Acc: 0.9118\n",
      "Epoch 032 | Train Loss: 0.1328 Acc: 0.9481 | Val Loss: 0.1842 Acc: 0.9293\n",
      "Epoch 033 | Train Loss: 0.1226 Acc: 0.9535 | Val Loss: 0.2309 Acc: 0.9064\n",
      "Epoch 034 | Train Loss: 0.1272 Acc: 0.9541 | Val Loss: 0.1825 Acc: 0.9306\n",
      "Epoch 035 | Train Loss: 0.1199 Acc: 0.9533 | Val Loss: 0.1918 Acc: 0.9275\n",
      "Epoch 036 | Train Loss: 0.1123 Acc: 0.9546 | Val Loss: 0.2161 Acc: 0.9155\n",
      "Epoch 037 | Train Loss: 0.1063 Acc: 0.9579 | Val Loss: 0.1800 Acc: 0.9342\n",
      "Epoch 038 | Train Loss: 0.1069 Acc: 0.9592 | Val Loss: 0.1881 Acc: 0.9281\n",
      "Epoch 039 | Train Loss: 0.0907 Acc: 0.9668 | Val Loss: 0.1634 Acc: 0.9396\n",
      "Epoch 040 | Train Loss: 0.0958 Acc: 0.9612 | Val Loss: 0.1913 Acc: 0.9366\n",
      "Epoch 041 | Train Loss: 0.0926 Acc: 0.9657 | Val Loss: 0.1992 Acc: 0.9269\n",
      "Epoch 042 | Train Loss: 0.1061 Acc: 0.9613 | Val Loss: 0.1485 Acc: 0.9414\n",
      "Epoch 043 | Train Loss: 0.0801 Acc: 0.9706 | Val Loss: 0.1856 Acc: 0.9318\n",
      "Epoch 044 | Train Loss: 0.0960 Acc: 0.9662 | Val Loss: 0.1945 Acc: 0.9287\n",
      "Epoch 045 | Train Loss: 0.0918 Acc: 0.9647 | Val Loss: 0.1508 Acc: 0.9438\n",
      "Epoch 046 | Train Loss: 0.0735 Acc: 0.9731 | Val Loss: 0.1747 Acc: 0.9354\n",
      "Epoch 047 | Train Loss: 0.0791 Acc: 0.9721 | Val Loss: 0.2706 Acc: 0.9094\n",
      "Epoch 048 | Train Loss: 0.0768 Acc: 0.9727 | Val Loss: 0.1595 Acc: 0.9426\n",
      "Epoch 049 | Train Loss: 0.0723 Acc: 0.9725 | Val Loss: 0.1704 Acc: 0.9366\n",
      "Epoch 050 | Train Loss: 0.0611 Acc: 0.9770 | Val Loss: 0.1681 Acc: 0.9402\n",
      "Epoch 051 | Train Loss: 0.0693 Acc: 0.9731 | Val Loss: 0.1532 Acc: 0.9414\n",
      "Epoch 052 | Train Loss: 0.0665 Acc: 0.9761 | Val Loss: 0.1680 Acc: 0.9420\n",
      "Early stopping triggered.\n",
      "Epoch 001 | Train Loss: 0.6831 Acc: 0.5682 | Val Loss: 0.6797 Acc: 0.5773\n",
      "Epoch 002 | Train Loss: 0.6699 Acc: 0.5993 | Val Loss: 0.6865 Acc: 0.5827\n",
      "Epoch 003 | Train Loss: 0.6497 Acc: 0.6216 | Val Loss: 0.6239 Acc: 0.6661\n",
      "Epoch 004 | Train Loss: 0.6065 Acc: 0.6865 | Val Loss: 0.5912 Acc: 0.7047\n",
      "Epoch 005 | Train Loss: 0.5669 Acc: 0.7257 | Val Loss: 0.5749 Acc: 0.7065\n",
      "Epoch 006 | Train Loss: 0.5573 Acc: 0.7276 | Val Loss: 0.5446 Acc: 0.7258\n",
      "Epoch 007 | Train Loss: 0.5358 Acc: 0.7414 | Val Loss: 0.5356 Acc: 0.7325\n",
      "Epoch 008 | Train Loss: 0.5182 Acc: 0.7548 | Val Loss: 0.5103 Acc: 0.7548\n",
      "Epoch 009 | Train Loss: 0.5023 Acc: 0.7649 | Val Loss: 0.4976 Acc: 0.7651\n",
      "Epoch 010 | Train Loss: 0.4882 Acc: 0.7684 | Val Loss: 0.4945 Acc: 0.7675\n",
      "Epoch 011 | Train Loss: 0.4727 Acc: 0.7821 | Val Loss: 0.4770 Acc: 0.7778\n",
      "Epoch 012 | Train Loss: 0.4548 Acc: 0.7900 | Val Loss: 0.4419 Acc: 0.7874\n",
      "Epoch 013 | Train Loss: 0.4522 Acc: 0.7924 | Val Loss: 0.4486 Acc: 0.7826\n",
      "Epoch 014 | Train Loss: 0.4273 Acc: 0.8046 | Val Loss: 0.4465 Acc: 0.7911\n",
      "Epoch 015 | Train Loss: 0.4105 Acc: 0.8098 | Val Loss: 0.4325 Acc: 0.7905\n",
      "Epoch 016 | Train Loss: 0.3885 Acc: 0.8242 | Val Loss: 0.4191 Acc: 0.8128\n",
      "Epoch 017 | Train Loss: 0.3831 Acc: 0.8265 | Val Loss: 0.4138 Acc: 0.8025\n",
      "Epoch 018 | Train Loss: 0.3593 Acc: 0.8409 | Val Loss: 0.3576 Acc: 0.8339\n",
      "Epoch 019 | Train Loss: 0.3382 Acc: 0.8546 | Val Loss: 0.3372 Acc: 0.8466\n",
      "Epoch 020 | Train Loss: 0.3260 Acc: 0.8614 | Val Loss: 0.3202 Acc: 0.8678\n",
      "Epoch 021 | Train Loss: 0.3041 Acc: 0.8706 | Val Loss: 0.3266 Acc: 0.8605\n",
      "Epoch 022 | Train Loss: 0.2874 Acc: 0.8803 | Val Loss: 0.2888 Acc: 0.8750\n",
      "Epoch 023 | Train Loss: 0.2744 Acc: 0.8857 | Val Loss: 0.2686 Acc: 0.8877\n",
      "Epoch 024 | Train Loss: 0.2595 Acc: 0.8936 | Val Loss: 0.2765 Acc: 0.8865\n",
      "Epoch 025 | Train Loss: 0.2383 Acc: 0.9026 | Val Loss: 0.2785 Acc: 0.8883\n",
      "Epoch 026 | Train Loss: 0.2435 Acc: 0.9008 | Val Loss: 0.2618 Acc: 0.8889\n",
      "Epoch 027 | Train Loss: 0.2163 Acc: 0.9117 | Val Loss: 0.2571 Acc: 0.9094\n",
      "Epoch 028 | Train Loss: 0.2122 Acc: 0.9159 | Val Loss: 0.2475 Acc: 0.9058\n",
      "Epoch 029 | Train Loss: 0.2112 Acc: 0.9171 | Val Loss: 0.2302 Acc: 0.9082\n",
      "Epoch 030 | Train Loss: 0.1902 Acc: 0.9278 | Val Loss: 0.2211 Acc: 0.9143\n",
      "Epoch 031 | Train Loss: 0.1991 Acc: 0.9192 | Val Loss: 0.2194 Acc: 0.9155\n",
      "Epoch 032 | Train Loss: 0.1851 Acc: 0.9244 | Val Loss: 0.2332 Acc: 0.9064\n",
      "Epoch 033 | Train Loss: 0.1765 Acc: 0.9269 | Val Loss: 0.2219 Acc: 0.9197\n",
      "Epoch 034 | Train Loss: 0.1701 Acc: 0.9324 | Val Loss: 0.2075 Acc: 0.9149\n",
      "Epoch 035 | Train Loss: 0.1607 Acc: 0.9384 | Val Loss: 0.1987 Acc: 0.9306\n",
      "Epoch 036 | Train Loss: 0.1722 Acc: 0.9286 | Val Loss: 0.2323 Acc: 0.9106\n",
      "Epoch 037 | Train Loss: 0.1473 Acc: 0.9437 | Val Loss: 0.1920 Acc: 0.9300\n",
      "Epoch 038 | Train Loss: 0.1423 Acc: 0.9423 | Val Loss: 0.2016 Acc: 0.9251\n",
      "Epoch 039 | Train Loss: 0.1504 Acc: 0.9419 | Val Loss: 0.1893 Acc: 0.9318\n",
      "Epoch 040 | Train Loss: 0.1416 Acc: 0.9449 | Val Loss: 0.2845 Acc: 0.8901\n",
      "Epoch 041 | Train Loss: 0.1431 Acc: 0.9455 | Val Loss: 0.2254 Acc: 0.9209\n",
      "Epoch 042 | Train Loss: 0.1273 Acc: 0.9547 | Val Loss: 0.2129 Acc: 0.9221\n",
      "Epoch 043 | Train Loss: 0.1356 Acc: 0.9479 | Val Loss: 0.1967 Acc: 0.9342\n",
      "Epoch 044 | Train Loss: 0.1281 Acc: 0.9538 | Val Loss: 0.1844 Acc: 0.9348\n",
      "Epoch 045 | Train Loss: 0.1204 Acc: 0.9532 | Val Loss: 0.1667 Acc: 0.9444\n",
      "Epoch 046 | Train Loss: 0.1213 Acc: 0.9530 | Val Loss: 0.1983 Acc: 0.9245\n",
      "Epoch 047 | Train Loss: 0.1269 Acc: 0.9512 | Val Loss: 0.2107 Acc: 0.9233\n",
      "Epoch 048 | Train Loss: 0.1043 Acc: 0.9588 | Val Loss: 0.1706 Acc: 0.9384\n",
      "Epoch 049 | Train Loss: 0.1140 Acc: 0.9565 | Val Loss: 0.1911 Acc: 0.9281\n",
      "Epoch 050 | Train Loss: 0.1104 Acc: 0.9585 | Val Loss: 0.1836 Acc: 0.9372\n",
      "Epoch 051 | Train Loss: 0.1092 Acc: 0.9586 | Val Loss: 0.1671 Acc: 0.9426\n",
      "Epoch 052 | Train Loss: 0.1149 Acc: 0.9561 | Val Loss: 0.1522 Acc: 0.9463\n",
      "Epoch 053 | Train Loss: 0.1041 Acc: 0.9612 | Val Loss: 0.2054 Acc: 0.9275\n",
      "Epoch 054 | Train Loss: 0.0986 Acc: 0.9639 | Val Loss: 0.1651 Acc: 0.9420\n",
      "Epoch 055 | Train Loss: 0.0984 Acc: 0.9626 | Val Loss: 0.1554 Acc: 0.9438\n",
      "Epoch 056 | Train Loss: 0.0944 Acc: 0.9663 | Val Loss: 0.1552 Acc: 0.9438\n",
      "Epoch 057 | Train Loss: 0.0883 Acc: 0.9669 | Val Loss: 0.1626 Acc: 0.9475\n",
      "Epoch 058 | Train Loss: 0.0876 Acc: 0.9668 | Val Loss: 0.1664 Acc: 0.9481\n",
      "Epoch 059 | Train Loss: 0.0910 Acc: 0.9674 | Val Loss: 0.1782 Acc: 0.9432\n",
      "Epoch 060 | Train Loss: 0.0850 Acc: 0.9672 | Val Loss: 0.1565 Acc: 0.9487\n",
      "Epoch 001 | Train Loss: 0.6799 Acc: 0.5822 | Val Loss: 0.6782 Acc: 0.5882\n",
      "Epoch 002 | Train Loss: 0.6769 Acc: 0.5870 | Val Loss: 0.6734 Acc: 0.5882\n",
      "Epoch 003 | Train Loss: 0.6663 Acc: 0.6073 | Val Loss: 0.6670 Acc: 0.6045\n",
      "Epoch 004 | Train Loss: 0.6626 Acc: 0.6070 | Val Loss: 0.6499 Acc: 0.6171\n",
      "Epoch 005 | Train Loss: 0.6525 Acc: 0.6234 | Val Loss: 0.6508 Acc: 0.6171\n",
      "Epoch 006 | Train Loss: 0.6105 Acc: 0.6891 | Val Loss: 0.6033 Acc: 0.6932\n",
      "Epoch 007 | Train Loss: 0.5582 Acc: 0.7208 | Val Loss: 0.5422 Acc: 0.7325\n",
      "Epoch 008 | Train Loss: 0.5385 Acc: 0.7415 | Val Loss: 0.5229 Acc: 0.7434\n",
      "Epoch 009 | Train Loss: 0.5071 Acc: 0.7604 | Val Loss: 0.4939 Acc: 0.7482\n",
      "Epoch 010 | Train Loss: 0.4754 Acc: 0.7759 | Val Loss: 0.4702 Acc: 0.7681\n",
      "Epoch 011 | Train Loss: 0.4566 Acc: 0.7860 | Val Loss: 0.4333 Acc: 0.8007\n",
      "Epoch 012 | Train Loss: 0.4197 Acc: 0.8078 | Val Loss: 0.4116 Acc: 0.8086\n",
      "Epoch 013 | Train Loss: 0.3986 Acc: 0.8191 | Val Loss: 0.3839 Acc: 0.8267\n",
      "Epoch 014 | Train Loss: 0.3613 Acc: 0.8434 | Val Loss: 0.3495 Acc: 0.8460\n",
      "Epoch 015 | Train Loss: 0.3406 Acc: 0.8540 | Val Loss: 0.3298 Acc: 0.8533\n",
      "Epoch 016 | Train Loss: 0.3404 Acc: 0.8547 | Val Loss: 0.3178 Acc: 0.8629\n",
      "Epoch 017 | Train Loss: 0.3128 Acc: 0.8640 | Val Loss: 0.3130 Acc: 0.8671\n",
      "Epoch 018 | Train Loss: 0.2892 Acc: 0.8783 | Val Loss: 0.2888 Acc: 0.8786\n",
      "Epoch 019 | Train Loss: 0.2741 Acc: 0.8868 | Val Loss: 0.2856 Acc: 0.8786\n",
      "Epoch 020 | Train Loss: 0.2465 Acc: 0.8957 | Val Loss: 0.2557 Acc: 0.8883\n",
      "Epoch 021 | Train Loss: 0.2550 Acc: 0.8976 | Val Loss: 0.2663 Acc: 0.8895\n",
      "Epoch 022 | Train Loss: 0.2472 Acc: 0.8988 | Val Loss: 0.2571 Acc: 0.8949\n",
      "Epoch 023 | Train Loss: 0.2151 Acc: 0.9145 | Val Loss: 0.2732 Acc: 0.8907\n",
      "Epoch 024 | Train Loss: 0.2113 Acc: 0.9151 | Val Loss: 0.2190 Acc: 0.9106\n",
      "Epoch 025 | Train Loss: 0.1926 Acc: 0.9233 | Val Loss: 0.2667 Acc: 0.8919\n",
      "Epoch 026 | Train Loss: 0.1855 Acc: 0.9253 | Val Loss: 0.1952 Acc: 0.9185\n",
      "Epoch 027 | Train Loss: 0.1794 Acc: 0.9310 | Val Loss: 0.2345 Acc: 0.9064\n",
      "Epoch 028 | Train Loss: 0.1747 Acc: 0.9330 | Val Loss: 0.1953 Acc: 0.9191\n",
      "Epoch 029 | Train Loss: 0.1597 Acc: 0.9363 | Val Loss: 0.1927 Acc: 0.9239\n",
      "Epoch 030 | Train Loss: 0.1643 Acc: 0.9354 | Val Loss: 0.2000 Acc: 0.9233\n",
      "Epoch 031 | Train Loss: 0.1546 Acc: 0.9405 | Val Loss: 0.1752 Acc: 0.9287\n",
      "Epoch 032 | Train Loss: 0.1292 Acc: 0.9526 | Val Loss: 0.1831 Acc: 0.9330\n",
      "Epoch 033 | Train Loss: 0.1451 Acc: 0.9419 | Val Loss: 0.2094 Acc: 0.9143\n",
      "Epoch 034 | Train Loss: 0.1367 Acc: 0.9462 | Val Loss: 0.1979 Acc: 0.9306\n",
      "Epoch 035 | Train Loss: 0.1308 Acc: 0.9494 | Val Loss: 0.2018 Acc: 0.9293\n",
      "Epoch 036 | Train Loss: 0.1311 Acc: 0.9500 | Val Loss: 0.1688 Acc: 0.9348\n",
      "Epoch 037 | Train Loss: 0.1194 Acc: 0.9549 | Val Loss: 0.2520 Acc: 0.9070\n",
      "Epoch 038 | Train Loss: 0.1125 Acc: 0.9555 | Val Loss: 0.1588 Acc: 0.9420\n",
      "Epoch 039 | Train Loss: 0.1090 Acc: 0.9601 | Val Loss: 0.1642 Acc: 0.9402\n",
      "Epoch 040 | Train Loss: 0.1092 Acc: 0.9564 | Val Loss: 0.1709 Acc: 0.9414\n",
      "Epoch 041 | Train Loss: 0.1118 Acc: 0.9546 | Val Loss: 0.1700 Acc: 0.9396\n",
      "Epoch 042 | Train Loss: 0.1056 Acc: 0.9600 | Val Loss: 0.1645 Acc: 0.9414\n",
      "Epoch 043 | Train Loss: 0.1032 Acc: 0.9610 | Val Loss: 0.1690 Acc: 0.9330\n",
      "Epoch 044 | Train Loss: 0.0944 Acc: 0.9641 | Val Loss: 0.1712 Acc: 0.9372\n",
      "Epoch 045 | Train Loss: 0.0969 Acc: 0.9621 | Val Loss: 0.1544 Acc: 0.9396\n",
      "Epoch 046 | Train Loss: 0.0860 Acc: 0.9671 | Val Loss: 0.1672 Acc: 0.9426\n",
      "Epoch 047 | Train Loss: 0.0846 Acc: 0.9660 | Val Loss: 0.1635 Acc: 0.9457\n",
      "Epoch 048 | Train Loss: 0.0766 Acc: 0.9718 | Val Loss: 0.1892 Acc: 0.9348\n",
      "Epoch 049 | Train Loss: 0.0774 Acc: 0.9727 | Val Loss: 0.2085 Acc: 0.9257\n",
      "Epoch 050 | Train Loss: 0.0787 Acc: 0.9690 | Val Loss: 0.2862 Acc: 0.9221\n",
      "Epoch 051 | Train Loss: 0.0859 Acc: 0.9657 | Val Loss: 0.2104 Acc: 0.9324\n",
      "Epoch 052 | Train Loss: 0.0815 Acc: 0.9709 | Val Loss: 0.1759 Acc: 0.9420\n",
      "Epoch 053 | Train Loss: 0.0714 Acc: 0.9737 | Val Loss: 0.1294 Acc: 0.9547\n",
      "Epoch 054 | Train Loss: 0.0809 Acc: 0.9704 | Val Loss: 0.1524 Acc: 0.9420\n",
      "Epoch 055 | Train Loss: 0.0787 Acc: 0.9704 | Val Loss: 0.1481 Acc: 0.9432\n",
      "Epoch 056 | Train Loss: 0.0676 Acc: 0.9757 | Val Loss: 0.1519 Acc: 0.9487\n",
      "Epoch 057 | Train Loss: 0.0814 Acc: 0.9687 | Val Loss: 0.1520 Acc: 0.9420\n",
      "Epoch 058 | Train Loss: 0.0797 Acc: 0.9736 | Val Loss: 0.1966 Acc: 0.9342\n",
      "Epoch 059 | Train Loss: 0.0666 Acc: 0.9786 | Val Loss: 0.1661 Acc: 0.9493\n",
      "Epoch 060 | Train Loss: 0.0689 Acc: 0.9742 | Val Loss: 0.1547 Acc: 0.9444\n",
      "Epoch 001 | Train Loss: 0.6803 Acc: 0.5766 | Val Loss: 0.6788 Acc: 0.5797\n",
      "Epoch 002 | Train Loss: 0.6734 Acc: 0.5935 | Val Loss: 0.6689 Acc: 0.5996\n",
      "Epoch 003 | Train Loss: 0.6534 Acc: 0.6216 | Val Loss: 0.6194 Acc: 0.6703\n",
      "Epoch 004 | Train Loss: 0.5770 Acc: 0.7134 | Val Loss: 0.5616 Acc: 0.7114\n",
      "Epoch 005 | Train Loss: 0.5435 Acc: 0.7324 | Val Loss: 0.5375 Acc: 0.7331\n",
      "Epoch 006 | Train Loss: 0.5186 Acc: 0.7519 | Val Loss: 0.5313 Acc: 0.7482\n",
      "Epoch 007 | Train Loss: 0.5080 Acc: 0.7580 | Val Loss: 0.5068 Acc: 0.7548\n",
      "Epoch 008 | Train Loss: 0.4822 Acc: 0.7702 | Val Loss: 0.4907 Acc: 0.7609\n",
      "Epoch 009 | Train Loss: 0.4722 Acc: 0.7793 | Val Loss: 0.4601 Acc: 0.7826\n",
      "Epoch 010 | Train Loss: 0.4492 Acc: 0.7894 | Val Loss: 0.4420 Acc: 0.7911\n",
      "Epoch 011 | Train Loss: 0.4256 Acc: 0.8122 | Val Loss: 0.4305 Acc: 0.7953\n",
      "Epoch 012 | Train Loss: 0.4031 Acc: 0.8185 | Val Loss: 0.3886 Acc: 0.8297\n",
      "Epoch 013 | Train Loss: 0.3859 Acc: 0.8303 | Val Loss: 0.4092 Acc: 0.8219\n",
      "Epoch 014 | Train Loss: 0.3554 Acc: 0.8487 | Val Loss: 0.3549 Acc: 0.8436\n",
      "Epoch 015 | Train Loss: 0.3279 Acc: 0.8541 | Val Loss: 0.2973 Acc: 0.8780\n",
      "Epoch 016 | Train Loss: 0.3024 Acc: 0.8723 | Val Loss: 0.2844 Acc: 0.8810\n",
      "Epoch 017 | Train Loss: 0.2910 Acc: 0.8750 | Val Loss: 0.2787 Acc: 0.8841\n",
      "Epoch 018 | Train Loss: 0.2880 Acc: 0.8768 | Val Loss: 0.3132 Acc: 0.8617\n",
      "Epoch 019 | Train Loss: 0.2444 Acc: 0.9006 | Val Loss: 0.2576 Acc: 0.8937\n",
      "Epoch 020 | Train Loss: 0.2306 Acc: 0.9094 | Val Loss: 0.2357 Acc: 0.8992\n",
      "Epoch 021 | Train Loss: 0.2252 Acc: 0.9090 | Val Loss: 0.2552 Acc: 0.9016\n",
      "Epoch 022 | Train Loss: 0.2203 Acc: 0.9127 | Val Loss: 0.2327 Acc: 0.9022\n",
      "Epoch 023 | Train Loss: 0.2132 Acc: 0.9164 | Val Loss: 0.2715 Acc: 0.8859\n",
      "Epoch 024 | Train Loss: 0.1876 Acc: 0.9233 | Val Loss: 0.2234 Acc: 0.9046\n",
      "Epoch 025 | Train Loss: 0.1914 Acc: 0.9236 | Val Loss: 0.2093 Acc: 0.9136\n",
      "Epoch 026 | Train Loss: 0.1769 Acc: 0.9302 | Val Loss: 0.2288 Acc: 0.9082\n",
      "Epoch 027 | Train Loss: 0.1764 Acc: 0.9352 | Val Loss: 0.2158 Acc: 0.9185\n",
      "Epoch 028 | Train Loss: 0.1660 Acc: 0.9334 | Val Loss: 0.2118 Acc: 0.9149\n",
      "Epoch 029 | Train Loss: 0.1614 Acc: 0.9396 | Val Loss: 0.2145 Acc: 0.9112\n",
      "Epoch 030 | Train Loss: 0.1530 Acc: 0.9381 | Val Loss: 0.1886 Acc: 0.9203\n",
      "Epoch 031 | Train Loss: 0.1433 Acc: 0.9423 | Val Loss: 0.1906 Acc: 0.9287\n",
      "Epoch 032 | Train Loss: 0.1536 Acc: 0.9407 | Val Loss: 0.1726 Acc: 0.9318\n",
      "Epoch 033 | Train Loss: 0.1396 Acc: 0.9456 | Val Loss: 0.1620 Acc: 0.9402\n",
      "Epoch 034 | Train Loss: 0.1464 Acc: 0.9398 | Val Loss: 0.1604 Acc: 0.9342\n",
      "Epoch 035 | Train Loss: 0.1274 Acc: 0.9508 | Val Loss: 0.1553 Acc: 0.9348\n",
      "Epoch 036 | Train Loss: 0.1218 Acc: 0.9533 | Val Loss: 0.1915 Acc: 0.9336\n",
      "Epoch 037 | Train Loss: 0.1137 Acc: 0.9553 | Val Loss: 0.1599 Acc: 0.9360\n",
      "Epoch 038 | Train Loss: 0.1182 Acc: 0.9567 | Val Loss: 0.1852 Acc: 0.9324\n",
      "Epoch 039 | Train Loss: 0.1188 Acc: 0.9568 | Val Loss: 0.2301 Acc: 0.9161\n",
      "Epoch 040 | Train Loss: 0.1182 Acc: 0.9546 | Val Loss: 0.1862 Acc: 0.9330\n",
      "Epoch 041 | Train Loss: 0.1146 Acc: 0.9571 | Val Loss: 0.1468 Acc: 0.9384\n",
      "Epoch 042 | Train Loss: 0.1071 Acc: 0.9598 | Val Loss: 0.1722 Acc: 0.9366\n",
      "Epoch 043 | Train Loss: 0.1102 Acc: 0.9598 | Val Loss: 0.1845 Acc: 0.9269\n",
      "Epoch 044 | Train Loss: 0.0956 Acc: 0.9635 | Val Loss: 0.1628 Acc: 0.9420\n",
      "Epoch 045 | Train Loss: 0.0974 Acc: 0.9639 | Val Loss: 0.1863 Acc: 0.9324\n",
      "Epoch 046 | Train Loss: 0.1018 Acc: 0.9597 | Val Loss: 0.1600 Acc: 0.9378\n",
      "Epoch 047 | Train Loss: 0.0982 Acc: 0.9624 | Val Loss: 0.1386 Acc: 0.9499\n",
      "Epoch 048 | Train Loss: 0.0950 Acc: 0.9620 | Val Loss: 0.1519 Acc: 0.9408\n",
      "Epoch 049 | Train Loss: 0.0913 Acc: 0.9669 | Val Loss: 0.1733 Acc: 0.9366\n",
      "Epoch 050 | Train Loss: 0.0959 Acc: 0.9642 | Val Loss: 0.1586 Acc: 0.9475\n",
      "Epoch 051 | Train Loss: 0.0915 Acc: 0.9626 | Val Loss: 0.1656 Acc: 0.9378\n",
      "Epoch 052 | Train Loss: 0.0828 Acc: 0.9700 | Val Loss: 0.1600 Acc: 0.9499\n",
      "Epoch 053 | Train Loss: 0.0868 Acc: 0.9681 | Val Loss: 0.1765 Acc: 0.9402\n",
      "Epoch 054 | Train Loss: 0.0807 Acc: 0.9698 | Val Loss: 0.2020 Acc: 0.9396\n",
      "Epoch 055 | Train Loss: 0.0861 Acc: 0.9672 | Val Loss: 0.1359 Acc: 0.9541\n",
      "Epoch 056 | Train Loss: 0.0706 Acc: 0.9743 | Val Loss: 0.1944 Acc: 0.9420\n",
      "Epoch 057 | Train Loss: 0.0810 Acc: 0.9680 | Val Loss: 0.1827 Acc: 0.9432\n",
      "Epoch 058 | Train Loss: 0.0769 Acc: 0.9710 | Val Loss: 0.1805 Acc: 0.9475\n",
      "Epoch 059 | Train Loss: 0.0680 Acc: 0.9758 | Val Loss: 0.1330 Acc: 0.9529\n",
      "Epoch 060 | Train Loss: 0.0737 Acc: 0.9718 | Val Loss: 0.1576 Acc: 0.9547\n",
      "Iteration 36/40 | Best Val Loss: 0.1122 | Iter Time: 225.54s | Total Time: 146.17 min\n",
      "Epoch 001 | Train Loss: 0.6833 Acc: 0.5756 | Val Loss: 0.6813 Acc: 0.5725\n",
      "Epoch 002 | Train Loss: 0.6770 Acc: 0.5922 | Val Loss: 0.6772 Acc: 0.5894\n",
      "Epoch 003 | Train Loss: 0.6770 Acc: 0.5895 | Val Loss: 0.6751 Acc: 0.5906\n",
      "Epoch 004 | Train Loss: 0.6801 Acc: 0.5742 | Val Loss: 0.6857 Acc: 0.5586\n",
      "Epoch 005 | Train Loss: 0.6806 Acc: 0.5778 | Val Loss: 0.6749 Acc: 0.5918\n",
      "Epoch 006 | Train Loss: 0.6744 Acc: 0.5957 | Val Loss: 0.6771 Acc: 0.5839\n",
      "Epoch 007 | Train Loss: 0.6736 Acc: 0.5889 | Val Loss: 0.6723 Acc: 0.5936\n",
      "Epoch 008 | Train Loss: 0.6668 Acc: 0.6046 | Val Loss: 0.6598 Acc: 0.6008\n",
      "Epoch 009 | Train Loss: 0.6516 Acc: 0.6157 | Val Loss: 0.6341 Acc: 0.6413\n",
      "Epoch 010 | Train Loss: 0.6238 Acc: 0.6570 | Val Loss: 0.6017 Acc: 0.6751\n",
      "Epoch 011 | Train Loss: 0.5891 Acc: 0.6962 | Val Loss: 0.5860 Acc: 0.6932\n",
      "Epoch 012 | Train Loss: 0.5541 Acc: 0.7252 | Val Loss: 0.5409 Acc: 0.7228\n",
      "Epoch 013 | Train Loss: 0.5359 Acc: 0.7350 | Val Loss: 0.5386 Acc: 0.7295\n",
      "Epoch 014 | Train Loss: 0.5164 Acc: 0.7488 | Val Loss: 0.5162 Acc: 0.7440\n",
      "Epoch 015 | Train Loss: 0.5054 Acc: 0.7642 | Val Loss: 0.5084 Acc: 0.7518\n",
      "Epoch 016 | Train Loss: 0.4838 Acc: 0.7703 | Val Loss: 0.4854 Acc: 0.7639\n",
      "Epoch 017 | Train Loss: 0.4630 Acc: 0.7827 | Val Loss: 0.4736 Acc: 0.7711\n",
      "Epoch 018 | Train Loss: 0.4412 Acc: 0.7947 | Val Loss: 0.4285 Acc: 0.7953\n",
      "Epoch 019 | Train Loss: 0.4121 Acc: 0.8141 | Val Loss: 0.4199 Acc: 0.8031\n",
      "Epoch 020 | Train Loss: 0.3910 Acc: 0.8297 | Val Loss: 0.3717 Acc: 0.8309\n",
      "Epoch 021 | Train Loss: 0.3633 Acc: 0.8463 | Val Loss: 0.3542 Acc: 0.8430\n",
      "Epoch 022 | Train Loss: 0.3454 Acc: 0.8531 | Val Loss: 0.3400 Acc: 0.8575\n",
      "Epoch 023 | Train Loss: 0.3150 Acc: 0.8680 | Val Loss: 0.3361 Acc: 0.8442\n",
      "Epoch 024 | Train Loss: 0.3099 Acc: 0.8679 | Val Loss: 0.2990 Acc: 0.8744\n",
      "Epoch 025 | Train Loss: 0.2884 Acc: 0.8807 | Val Loss: 0.2822 Acc: 0.8738\n",
      "Epoch 026 | Train Loss: 0.2720 Acc: 0.8868 | Val Loss: 0.2814 Acc: 0.8810\n",
      "Epoch 027 | Train Loss: 0.2439 Acc: 0.9032 | Val Loss: 0.2596 Acc: 0.8883\n",
      "Epoch 028 | Train Loss: 0.2355 Acc: 0.9003 | Val Loss: 0.2484 Acc: 0.9022\n",
      "Epoch 029 | Train Loss: 0.2260 Acc: 0.9118 | Val Loss: 0.2411 Acc: 0.8961\n",
      "Epoch 030 | Train Loss: 0.2156 Acc: 0.9173 | Val Loss: 0.2296 Acc: 0.9028\n",
      "Epoch 031 | Train Loss: 0.2049 Acc: 0.9183 | Val Loss: 0.2255 Acc: 0.9052\n",
      "Epoch 032 | Train Loss: 0.2000 Acc: 0.9200 | Val Loss: 0.2218 Acc: 0.9052\n",
      "Epoch 033 | Train Loss: 0.1905 Acc: 0.9245 | Val Loss: 0.2322 Acc: 0.9046\n",
      "Epoch 034 | Train Loss: 0.1780 Acc: 0.9298 | Val Loss: 0.1976 Acc: 0.9209\n",
      "Epoch 035 | Train Loss: 0.1609 Acc: 0.9358 | Val Loss: 0.2102 Acc: 0.9112\n",
      "Epoch 036 | Train Loss: 0.1693 Acc: 0.9334 | Val Loss: 0.1758 Acc: 0.9263\n",
      "Epoch 037 | Train Loss: 0.1682 Acc: 0.9366 | Val Loss: 0.1865 Acc: 0.9173\n",
      "Epoch 038 | Train Loss: 0.1568 Acc: 0.9370 | Val Loss: 0.1971 Acc: 0.9300\n",
      "Epoch 039 | Train Loss: 0.1555 Acc: 0.9407 | Val Loss: 0.2386 Acc: 0.9052\n",
      "Epoch 040 | Train Loss: 0.1476 Acc: 0.9469 | Val Loss: 0.1859 Acc: 0.9245\n",
      "Epoch 041 | Train Loss: 0.1438 Acc: 0.9450 | Val Loss: 0.1905 Acc: 0.9318\n",
      "Epoch 042 | Train Loss: 0.1328 Acc: 0.9515 | Val Loss: 0.1954 Acc: 0.9197\n",
      "Epoch 043 | Train Loss: 0.1419 Acc: 0.9499 | Val Loss: 0.1916 Acc: 0.9251\n",
      "Epoch 044 | Train Loss: 0.1365 Acc: 0.9478 | Val Loss: 0.1616 Acc: 0.9342\n",
      "Epoch 045 | Train Loss: 0.1202 Acc: 0.9550 | Val Loss: 0.1706 Acc: 0.9348\n",
      "Epoch 046 | Train Loss: 0.1269 Acc: 0.9530 | Val Loss: 0.1538 Acc: 0.9420\n",
      "Epoch 047 | Train Loss: 0.1142 Acc: 0.9562 | Val Loss: 0.1587 Acc: 0.9444\n",
      "Epoch 048 | Train Loss: 0.1023 Acc: 0.9642 | Val Loss: 0.1558 Acc: 0.9438\n",
      "Epoch 049 | Train Loss: 0.1064 Acc: 0.9588 | Val Loss: 0.1852 Acc: 0.9330\n",
      "Epoch 050 | Train Loss: 0.1121 Acc: 0.9555 | Val Loss: 0.1526 Acc: 0.9438\n",
      "Epoch 051 | Train Loss: 0.1042 Acc: 0.9607 | Val Loss: 0.1913 Acc: 0.9354\n",
      "Epoch 052 | Train Loss: 0.1148 Acc: 0.9585 | Val Loss: 0.1411 Acc: 0.9469\n",
      "Epoch 053 | Train Loss: 0.1119 Acc: 0.9577 | Val Loss: 0.1762 Acc: 0.9402\n",
      "Epoch 054 | Train Loss: 0.0960 Acc: 0.9615 | Val Loss: 0.1468 Acc: 0.9408\n",
      "Epoch 055 | Train Loss: 0.1033 Acc: 0.9606 | Val Loss: 0.1530 Acc: 0.9426\n",
      "Epoch 056 | Train Loss: 0.0902 Acc: 0.9669 | Val Loss: 0.1383 Acc: 0.9487\n",
      "Epoch 057 | Train Loss: 0.0835 Acc: 0.9703 | Val Loss: 0.1632 Acc: 0.9408\n",
      "Epoch 058 | Train Loss: 0.0931 Acc: 0.9641 | Val Loss: 0.1286 Acc: 0.9499\n",
      "Epoch 059 | Train Loss: 0.0862 Acc: 0.9697 | Val Loss: 0.1755 Acc: 0.9390\n",
      "Epoch 060 | Train Loss: 0.0873 Acc: 0.9678 | Val Loss: 0.1461 Acc: 0.9457\n",
      "Epoch 001 | Train Loss: 0.6804 Acc: 0.5781 | Val Loss: 0.6769 Acc: 0.5833\n",
      "Epoch 002 | Train Loss: 0.6744 Acc: 0.5920 | Val Loss: 0.6887 Acc: 0.5634\n",
      "Epoch 003 | Train Loss: 0.6648 Acc: 0.6017 | Val Loss: 0.6527 Acc: 0.6123\n",
      "Epoch 004 | Train Loss: 0.6339 Acc: 0.6523 | Val Loss: 0.5962 Acc: 0.6944\n",
      "Epoch 005 | Train Loss: 0.5882 Acc: 0.7000 | Val Loss: 0.5575 Acc: 0.7186\n",
      "Epoch 006 | Train Loss: 0.5348 Acc: 0.7358 | Val Loss: 0.5253 Acc: 0.7397\n",
      "Epoch 007 | Train Loss: 0.5106 Acc: 0.7549 | Val Loss: 0.5095 Acc: 0.7476\n",
      "Epoch 008 | Train Loss: 0.4848 Acc: 0.7664 | Val Loss: 0.5250 Acc: 0.7470\n",
      "Epoch 009 | Train Loss: 0.4704 Acc: 0.7785 | Val Loss: 0.4799 Acc: 0.7657\n",
      "Epoch 010 | Train Loss: 0.4380 Acc: 0.7992 | Val Loss: 0.4524 Acc: 0.7826\n",
      "Epoch 011 | Train Loss: 0.4083 Acc: 0.8153 | Val Loss: 0.4044 Acc: 0.8104\n",
      "Epoch 012 | Train Loss: 0.3930 Acc: 0.8229 | Val Loss: 0.3943 Acc: 0.8188\n",
      "Epoch 013 | Train Loss: 0.3546 Acc: 0.8455 | Val Loss: 0.3485 Acc: 0.8424\n",
      "Epoch 014 | Train Loss: 0.3476 Acc: 0.8517 | Val Loss: 0.3349 Acc: 0.8466\n",
      "Epoch 015 | Train Loss: 0.3189 Acc: 0.8609 | Val Loss: 0.3313 Acc: 0.8496\n",
      "Epoch 016 | Train Loss: 0.2951 Acc: 0.8745 | Val Loss: 0.3182 Acc: 0.8527\n",
      "Epoch 017 | Train Loss: 0.2745 Acc: 0.8845 | Val Loss: 0.2693 Acc: 0.8853\n",
      "Epoch 018 | Train Loss: 0.2668 Acc: 0.8937 | Val Loss: 0.2692 Acc: 0.8895\n",
      "Epoch 019 | Train Loss: 0.2434 Acc: 0.8994 | Val Loss: 0.2522 Acc: 0.8973\n",
      "Epoch 020 | Train Loss: 0.2389 Acc: 0.9019 | Val Loss: 0.2842 Acc: 0.8750\n",
      "Epoch 021 | Train Loss: 0.2131 Acc: 0.9148 | Val Loss: 0.2389 Acc: 0.9016\n",
      "Epoch 022 | Train Loss: 0.1940 Acc: 0.9212 | Val Loss: 0.2145 Acc: 0.9161\n",
      "Epoch 023 | Train Loss: 0.1943 Acc: 0.9221 | Val Loss: 0.2406 Acc: 0.8961\n",
      "Epoch 024 | Train Loss: 0.1824 Acc: 0.9265 | Val Loss: 0.2550 Acc: 0.8859\n",
      "Epoch 025 | Train Loss: 0.1689 Acc: 0.9339 | Val Loss: 0.2288 Acc: 0.9040\n",
      "Epoch 026 | Train Loss: 0.1544 Acc: 0.9401 | Val Loss: 0.2106 Acc: 0.9179\n",
      "Epoch 027 | Train Loss: 0.1551 Acc: 0.9379 | Val Loss: 0.2170 Acc: 0.9034\n",
      "Epoch 028 | Train Loss: 0.1396 Acc: 0.9459 | Val Loss: 0.2232 Acc: 0.9100\n",
      "Epoch 029 | Train Loss: 0.1382 Acc: 0.9453 | Val Loss: 0.1721 Acc: 0.9300\n",
      "Epoch 030 | Train Loss: 0.1252 Acc: 0.9514 | Val Loss: 0.2020 Acc: 0.9203\n",
      "Epoch 031 | Train Loss: 0.1310 Acc: 0.9493 | Val Loss: 0.2078 Acc: 0.9293\n",
      "Epoch 032 | Train Loss: 0.1187 Acc: 0.9529 | Val Loss: 0.1814 Acc: 0.9275\n",
      "Epoch 033 | Train Loss: 0.1187 Acc: 0.9529 | Val Loss: 0.1928 Acc: 0.9239\n",
      "Epoch 034 | Train Loss: 0.1146 Acc: 0.9567 | Val Loss: 0.1989 Acc: 0.9179\n",
      "Epoch 035 | Train Loss: 0.0974 Acc: 0.9638 | Val Loss: 0.1968 Acc: 0.9324\n",
      "Epoch 036 | Train Loss: 0.1056 Acc: 0.9607 | Val Loss: 0.1888 Acc: 0.9287\n",
      "Epoch 037 | Train Loss: 0.0961 Acc: 0.9642 | Val Loss: 0.1996 Acc: 0.9330\n",
      "Epoch 038 | Train Loss: 0.0981 Acc: 0.9600 | Val Loss: 0.1973 Acc: 0.9366\n",
      "Epoch 039 | Train Loss: 0.0961 Acc: 0.9657 | Val Loss: 0.1885 Acc: 0.9378\n",
      "Early stopping triggered.\n",
      "Epoch 001 | Train Loss: 0.6820 Acc: 0.5726 | Val Loss: 0.6766 Acc: 0.5894\n",
      "Epoch 002 | Train Loss: 0.6753 Acc: 0.5901 | Val Loss: 0.6703 Acc: 0.5960\n",
      "Epoch 003 | Train Loss: 0.6626 Acc: 0.6080 | Val Loss: 0.6403 Acc: 0.6612\n",
      "Epoch 004 | Train Loss: 0.6311 Acc: 0.6583 | Val Loss: 0.6045 Acc: 0.6763\n",
      "Epoch 005 | Train Loss: 0.6013 Acc: 0.6903 | Val Loss: 0.5975 Acc: 0.6890\n",
      "Epoch 006 | Train Loss: 0.5674 Acc: 0.7222 | Val Loss: 0.5477 Acc: 0.7258\n",
      "Epoch 007 | Train Loss: 0.5436 Acc: 0.7379 | Val Loss: 0.5386 Acc: 0.7277\n",
      "Epoch 008 | Train Loss: 0.5154 Acc: 0.7537 | Val Loss: 0.5143 Acc: 0.7470\n",
      "Epoch 009 | Train Loss: 0.4939 Acc: 0.7684 | Val Loss: 0.5033 Acc: 0.7536\n",
      "Epoch 010 | Train Loss: 0.4814 Acc: 0.7723 | Val Loss: 0.4848 Acc: 0.7585\n",
      "Epoch 011 | Train Loss: 0.4520 Acc: 0.7918 | Val Loss: 0.4663 Acc: 0.7784\n",
      "Epoch 012 | Train Loss: 0.4341 Acc: 0.8016 | Val Loss: 0.4458 Acc: 0.7905\n",
      "Epoch 013 | Train Loss: 0.4087 Acc: 0.8181 | Val Loss: 0.4274 Acc: 0.7977\n",
      "Epoch 014 | Train Loss: 0.3949 Acc: 0.8193 | Val Loss: 0.3904 Acc: 0.8164\n",
      "Epoch 015 | Train Loss: 0.3734 Acc: 0.8338 | Val Loss: 0.3666 Acc: 0.8327\n",
      "Epoch 016 | Train Loss: 0.3528 Acc: 0.8436 | Val Loss: 0.3578 Acc: 0.8376\n",
      "Epoch 017 | Train Loss: 0.3286 Acc: 0.8572 | Val Loss: 0.3476 Acc: 0.8400\n",
      "Epoch 018 | Train Loss: 0.3203 Acc: 0.8582 | Val Loss: 0.3201 Acc: 0.8557\n",
      "Epoch 019 | Train Loss: 0.3074 Acc: 0.8698 | Val Loss: 0.3171 Acc: 0.8678\n",
      "Epoch 020 | Train Loss: 0.2758 Acc: 0.8845 | Val Loss: 0.3010 Acc: 0.8696\n",
      "Epoch 021 | Train Loss: 0.2765 Acc: 0.8810 | Val Loss: 0.2790 Acc: 0.8829\n",
      "Epoch 022 | Train Loss: 0.2565 Acc: 0.8952 | Val Loss: 0.2639 Acc: 0.8895\n",
      "Epoch 023 | Train Loss: 0.2427 Acc: 0.9029 | Val Loss: 0.2726 Acc: 0.8859\n",
      "Epoch 024 | Train Loss: 0.2279 Acc: 0.9071 | Val Loss: 0.2387 Acc: 0.9004\n",
      "Epoch 025 | Train Loss: 0.2193 Acc: 0.9135 | Val Loss: 0.2626 Acc: 0.8901\n",
      "Epoch 026 | Train Loss: 0.2089 Acc: 0.9132 | Val Loss: 0.2312 Acc: 0.9118\n",
      "Epoch 027 | Train Loss: 0.1975 Acc: 0.9204 | Val Loss: 0.2482 Acc: 0.8931\n",
      "Epoch 028 | Train Loss: 0.1938 Acc: 0.9197 | Val Loss: 0.2112 Acc: 0.9191\n",
      "Epoch 029 | Train Loss: 0.1784 Acc: 0.9302 | Val Loss: 0.2229 Acc: 0.9100\n",
      "Epoch 030 | Train Loss: 0.1826 Acc: 0.9268 | Val Loss: 0.1849 Acc: 0.9215\n",
      "Epoch 031 | Train Loss: 0.1655 Acc: 0.9358 | Val Loss: 0.1965 Acc: 0.9263\n",
      "Epoch 032 | Train Loss: 0.1582 Acc: 0.9395 | Val Loss: 0.1994 Acc: 0.9233\n",
      "Epoch 033 | Train Loss: 0.1430 Acc: 0.9461 | Val Loss: 0.1966 Acc: 0.9233\n",
      "Epoch 034 | Train Loss: 0.1457 Acc: 0.9420 | Val Loss: 0.1790 Acc: 0.9324\n",
      "Epoch 035 | Train Loss: 0.1376 Acc: 0.9467 | Val Loss: 0.1766 Acc: 0.9306\n",
      "Epoch 036 | Train Loss: 0.1316 Acc: 0.9488 | Val Loss: 0.2312 Acc: 0.9209\n",
      "Epoch 037 | Train Loss: 0.1313 Acc: 0.9526 | Val Loss: 0.2067 Acc: 0.9185\n",
      "Epoch 038 | Train Loss: 0.1305 Acc: 0.9503 | Val Loss: 0.2367 Acc: 0.9034\n",
      "Epoch 039 | Train Loss: 0.1267 Acc: 0.9517 | Val Loss: 0.1829 Acc: 0.9330\n",
      "Epoch 040 | Train Loss: 0.1143 Acc: 0.9553 | Val Loss: 0.1761 Acc: 0.9390\n",
      "Epoch 041 | Train Loss: 0.1121 Acc: 0.9553 | Val Loss: 0.1859 Acc: 0.9306\n",
      "Epoch 042 | Train Loss: 0.1124 Acc: 0.9580 | Val Loss: 0.1736 Acc: 0.9348\n",
      "Epoch 043 | Train Loss: 0.1093 Acc: 0.9615 | Val Loss: 0.1802 Acc: 0.9354\n",
      "Epoch 044 | Train Loss: 0.1020 Acc: 0.9609 | Val Loss: 0.1619 Acc: 0.9450\n",
      "Epoch 045 | Train Loss: 0.1119 Acc: 0.9576 | Val Loss: 0.1876 Acc: 0.9372\n",
      "Epoch 046 | Train Loss: 0.0859 Acc: 0.9703 | Val Loss: 0.1778 Acc: 0.9396\n",
      "Epoch 047 | Train Loss: 0.1033 Acc: 0.9623 | Val Loss: 0.1668 Acc: 0.9444\n",
      "Epoch 048 | Train Loss: 0.0838 Acc: 0.9684 | Val Loss: 0.1649 Acc: 0.9469\n",
      "Epoch 049 | Train Loss: 0.0958 Acc: 0.9644 | Val Loss: 0.1933 Acc: 0.9330\n",
      "Epoch 050 | Train Loss: 0.0934 Acc: 0.9672 | Val Loss: 0.1946 Acc: 0.9306\n",
      "Epoch 051 | Train Loss: 0.0795 Acc: 0.9716 | Val Loss: 0.1557 Acc: 0.9469\n",
      "Epoch 052 | Train Loss: 0.0906 Acc: 0.9663 | Val Loss: 0.1697 Acc: 0.9402\n",
      "Epoch 053 | Train Loss: 0.0825 Acc: 0.9683 | Val Loss: 0.1833 Acc: 0.9384\n",
      "Epoch 054 | Train Loss: 0.0777 Acc: 0.9719 | Val Loss: 0.1845 Acc: 0.9366\n",
      "Epoch 055 | Train Loss: 0.0795 Acc: 0.9716 | Val Loss: 0.1623 Acc: 0.9420\n",
      "Epoch 056 | Train Loss: 0.0811 Acc: 0.9700 | Val Loss: 0.1745 Acc: 0.9402\n",
      "Epoch 057 | Train Loss: 0.0694 Acc: 0.9755 | Val Loss: 0.1750 Acc: 0.9438\n",
      "Epoch 058 | Train Loss: 0.0834 Acc: 0.9662 | Val Loss: 0.2260 Acc: 0.9300\n",
      "Epoch 059 | Train Loss: 0.0682 Acc: 0.9728 | Val Loss: 0.1595 Acc: 0.9378\n",
      "Epoch 060 | Train Loss: 0.0702 Acc: 0.9733 | Val Loss: 0.1557 Acc: 0.9487\n",
      "Epoch 001 | Train Loss: 0.6781 Acc: 0.5821 | Val Loss: 0.6754 Acc: 0.5942\n",
      "Epoch 002 | Train Loss: 0.6647 Acc: 0.6047 | Val Loss: 0.6605 Acc: 0.6063\n",
      "Epoch 003 | Train Loss: 0.6311 Acc: 0.6480 | Val Loss: 0.5988 Acc: 0.6932\n",
      "Epoch 004 | Train Loss: 0.5770 Acc: 0.7127 | Val Loss: 0.5587 Acc: 0.7277\n",
      "Epoch 005 | Train Loss: 0.5422 Acc: 0.7311 | Val Loss: 0.5398 Acc: 0.7379\n",
      "Epoch 006 | Train Loss: 0.5236 Acc: 0.7445 | Val Loss: 0.5194 Acc: 0.7458\n",
      "Epoch 007 | Train Loss: 0.4956 Acc: 0.7643 | Val Loss: 0.5060 Acc: 0.7572\n",
      "Epoch 008 | Train Loss: 0.4813 Acc: 0.7719 | Val Loss: 0.4856 Acc: 0.7645\n",
      "Epoch 009 | Train Loss: 0.4585 Acc: 0.7856 | Val Loss: 0.4690 Acc: 0.7681\n",
      "Epoch 010 | Train Loss: 0.4334 Acc: 0.7972 | Val Loss: 0.4294 Acc: 0.7977\n",
      "Epoch 011 | Train Loss: 0.4074 Acc: 0.8137 | Val Loss: 0.4258 Acc: 0.7893\n",
      "Epoch 012 | Train Loss: 0.3808 Acc: 0.8291 | Val Loss: 0.3614 Acc: 0.8345\n",
      "Epoch 013 | Train Loss: 0.3570 Acc: 0.8419 | Val Loss: 0.3491 Acc: 0.8364\n",
      "Epoch 014 | Train Loss: 0.3208 Acc: 0.8632 | Val Loss: 0.3125 Acc: 0.8581\n",
      "Epoch 015 | Train Loss: 0.2946 Acc: 0.8771 | Val Loss: 0.3369 Acc: 0.8514\n",
      "Epoch 016 | Train Loss: 0.2728 Acc: 0.8824 | Val Loss: 0.2939 Acc: 0.8726\n",
      "Epoch 017 | Train Loss: 0.2729 Acc: 0.8852 | Val Loss: 0.2639 Acc: 0.8816\n",
      "Epoch 018 | Train Loss: 0.2323 Acc: 0.9049 | Val Loss: 0.2377 Acc: 0.9010\n",
      "Epoch 019 | Train Loss: 0.2142 Acc: 0.9109 | Val Loss: 0.2847 Acc: 0.8768\n",
      "Epoch 020 | Train Loss: 0.2077 Acc: 0.9142 | Val Loss: 0.2483 Acc: 0.8961\n",
      "Epoch 021 | Train Loss: 0.1924 Acc: 0.9230 | Val Loss: 0.2484 Acc: 0.8877\n",
      "Epoch 022 | Train Loss: 0.1824 Acc: 0.9244 | Val Loss: 0.2005 Acc: 0.9136\n",
      "Epoch 023 | Train Loss: 0.1667 Acc: 0.9342 | Val Loss: 0.2074 Acc: 0.9076\n",
      "Epoch 024 | Train Loss: 0.1608 Acc: 0.9358 | Val Loss: 0.2114 Acc: 0.9070\n",
      "Epoch 025 | Train Loss: 0.1485 Acc: 0.9419 | Val Loss: 0.2038 Acc: 0.9130\n",
      "Epoch 026 | Train Loss: 0.1266 Acc: 0.9496 | Val Loss: 0.1949 Acc: 0.9215\n",
      "Epoch 027 | Train Loss: 0.1260 Acc: 0.9536 | Val Loss: 0.1737 Acc: 0.9287\n",
      "Epoch 028 | Train Loss: 0.1199 Acc: 0.9538 | Val Loss: 0.1588 Acc: 0.9342\n",
      "Epoch 029 | Train Loss: 0.1226 Acc: 0.9515 | Val Loss: 0.1771 Acc: 0.9287\n",
      "Epoch 030 | Train Loss: 0.1092 Acc: 0.9571 | Val Loss: 0.1611 Acc: 0.9384\n",
      "Epoch 031 | Train Loss: 0.1030 Acc: 0.9624 | Val Loss: 0.1415 Acc: 0.9481\n",
      "Epoch 032 | Train Loss: 0.0966 Acc: 0.9610 | Val Loss: 0.1645 Acc: 0.9396\n",
      "Epoch 033 | Train Loss: 0.0825 Acc: 0.9693 | Val Loss: 0.1729 Acc: 0.9354\n",
      "Epoch 034 | Train Loss: 0.0838 Acc: 0.9690 | Val Loss: 0.2089 Acc: 0.9233\n",
      "Epoch 035 | Train Loss: 0.0873 Acc: 0.9681 | Val Loss: 0.1555 Acc: 0.9384\n",
      "Epoch 036 | Train Loss: 0.0852 Acc: 0.9683 | Val Loss: 0.1773 Acc: 0.9360\n",
      "Epoch 037 | Train Loss: 0.0663 Acc: 0.9760 | Val Loss: 0.1514 Acc: 0.9396\n",
      "Epoch 038 | Train Loss: 0.0684 Acc: 0.9739 | Val Loss: 0.1652 Acc: 0.9360\n",
      "Epoch 039 | Train Loss: 0.0706 Acc: 0.9736 | Val Loss: 0.1902 Acc: 0.9281\n",
      "Epoch 040 | Train Loss: 0.0604 Acc: 0.9778 | Val Loss: 0.1455 Acc: 0.9457\n",
      "Epoch 041 | Train Loss: 0.0597 Acc: 0.9763 | Val Loss: 0.1512 Acc: 0.9450\n",
      "Early stopping triggered.\n",
      "Epoch 001 | Train Loss: 0.6804 Acc: 0.5738 | Val Loss: 0.6744 Acc: 0.5924\n",
      "Epoch 002 | Train Loss: 0.6692 Acc: 0.6002 | Val Loss: 0.6640 Acc: 0.6051\n",
      "Epoch 003 | Train Loss: 0.6609 Acc: 0.6091 | Val Loss: 0.6530 Acc: 0.6135\n",
      "Epoch 004 | Train Loss: 0.6233 Acc: 0.6659 | Val Loss: 0.6034 Acc: 0.6914\n",
      "Epoch 005 | Train Loss: 0.5919 Acc: 0.7012 | Val Loss: 0.5907 Acc: 0.6890\n",
      "Epoch 006 | Train Loss: 0.5602 Acc: 0.7255 | Val Loss: 0.5553 Acc: 0.7180\n",
      "Epoch 007 | Train Loss: 0.5478 Acc: 0.7305 | Val Loss: 0.5623 Acc: 0.7138\n",
      "Epoch 008 | Train Loss: 0.5391 Acc: 0.7356 | Val Loss: 0.5383 Acc: 0.7258\n",
      "Epoch 009 | Train Loss: 0.5177 Acc: 0.7504 | Val Loss: 0.5384 Acc: 0.7307\n",
      "Epoch 010 | Train Loss: 0.5080 Acc: 0.7581 | Val Loss: 0.5065 Acc: 0.7446\n",
      "Epoch 011 | Train Loss: 0.4881 Acc: 0.7670 | Val Loss: 0.4848 Acc: 0.7748\n",
      "Epoch 012 | Train Loss: 0.4699 Acc: 0.7771 | Val Loss: 0.5341 Acc: 0.7458\n",
      "Epoch 013 | Train Loss: 0.4430 Acc: 0.7939 | Val Loss: 0.4729 Acc: 0.7621\n",
      "Epoch 014 | Train Loss: 0.4369 Acc: 0.7934 | Val Loss: 0.4308 Acc: 0.7941\n",
      "Epoch 015 | Train Loss: 0.4227 Acc: 0.8040 | Val Loss: 0.4083 Acc: 0.8050\n",
      "Epoch 016 | Train Loss: 0.4092 Acc: 0.8120 | Val Loss: 0.4001 Acc: 0.8188\n",
      "Epoch 017 | Train Loss: 0.3858 Acc: 0.8271 | Val Loss: 0.3970 Acc: 0.8080\n",
      "Epoch 018 | Train Loss: 0.3665 Acc: 0.8344 | Val Loss: 0.3713 Acc: 0.8357\n",
      "Epoch 019 | Train Loss: 0.3567 Acc: 0.8422 | Val Loss: 0.3437 Acc: 0.8472\n",
      "Epoch 020 | Train Loss: 0.3202 Acc: 0.8612 | Val Loss: 0.3166 Acc: 0.8617\n",
      "Epoch 021 | Train Loss: 0.3056 Acc: 0.8724 | Val Loss: 0.3340 Acc: 0.8484\n",
      "Epoch 022 | Train Loss: 0.2789 Acc: 0.8837 | Val Loss: 0.2903 Acc: 0.8829\n",
      "Epoch 023 | Train Loss: 0.2692 Acc: 0.8880 | Val Loss: 0.2708 Acc: 0.8919\n",
      "Epoch 024 | Train Loss: 0.2510 Acc: 0.8945 | Val Loss: 0.2518 Acc: 0.8955\n",
      "Epoch 025 | Train Loss: 0.2409 Acc: 0.8978 | Val Loss: 0.2704 Acc: 0.8841\n",
      "Epoch 026 | Train Loss: 0.2390 Acc: 0.9028 | Val Loss: 0.2658 Acc: 0.8895\n",
      "Epoch 027 | Train Loss: 0.2209 Acc: 0.9061 | Val Loss: 0.2356 Acc: 0.9070\n",
      "Epoch 028 | Train Loss: 0.2093 Acc: 0.9150 | Val Loss: 0.2349 Acc: 0.9052\n",
      "Epoch 029 | Train Loss: 0.2012 Acc: 0.9222 | Val Loss: 0.2381 Acc: 0.9028\n",
      "Epoch 030 | Train Loss: 0.1928 Acc: 0.9228 | Val Loss: 0.2220 Acc: 0.9130\n",
      "Epoch 031 | Train Loss: 0.1905 Acc: 0.9238 | Val Loss: 0.2059 Acc: 0.9185\n",
      "Epoch 032 | Train Loss: 0.1817 Acc: 0.9286 | Val Loss: 0.2168 Acc: 0.9143\n",
      "Epoch 033 | Train Loss: 0.1702 Acc: 0.9330 | Val Loss: 0.1787 Acc: 0.9263\n",
      "Epoch 034 | Train Loss: 0.1606 Acc: 0.9358 | Val Loss: 0.1866 Acc: 0.9263\n",
      "Epoch 035 | Train Loss: 0.1431 Acc: 0.9455 | Val Loss: 0.1978 Acc: 0.9143\n",
      "Epoch 036 | Train Loss: 0.1518 Acc: 0.9423 | Val Loss: 0.2076 Acc: 0.9281\n",
      "Epoch 037 | Train Loss: 0.1378 Acc: 0.9455 | Val Loss: 0.1862 Acc: 0.9281\n",
      "Epoch 038 | Train Loss: 0.1433 Acc: 0.9440 | Val Loss: 0.1891 Acc: 0.9233\n",
      "Epoch 039 | Train Loss: 0.1295 Acc: 0.9526 | Val Loss: 0.1722 Acc: 0.9342\n",
      "Epoch 040 | Train Loss: 0.1337 Acc: 0.9470 | Val Loss: 0.1899 Acc: 0.9293\n",
      "Epoch 041 | Train Loss: 0.1309 Acc: 0.9518 | Val Loss: 0.1802 Acc: 0.9324\n",
      "Epoch 042 | Train Loss: 0.1200 Acc: 0.9530 | Val Loss: 0.1866 Acc: 0.9293\n",
      "Epoch 043 | Train Loss: 0.1074 Acc: 0.9588 | Val Loss: 0.2034 Acc: 0.9342\n",
      "Epoch 044 | Train Loss: 0.1262 Acc: 0.9535 | Val Loss: 0.1617 Acc: 0.9390\n",
      "Epoch 045 | Train Loss: 0.1073 Acc: 0.9589 | Val Loss: 0.1919 Acc: 0.9318\n",
      "Epoch 046 | Train Loss: 0.1026 Acc: 0.9616 | Val Loss: 0.2003 Acc: 0.9360\n",
      "Epoch 047 | Train Loss: 0.1034 Acc: 0.9627 | Val Loss: 0.1829 Acc: 0.9318\n",
      "Epoch 048 | Train Loss: 0.0994 Acc: 0.9626 | Val Loss: 0.1628 Acc: 0.9414\n",
      "Epoch 049 | Train Loss: 0.0986 Acc: 0.9647 | Val Loss: 0.1988 Acc: 0.9293\n",
      "Epoch 050 | Train Loss: 0.0944 Acc: 0.9642 | Val Loss: 0.1612 Acc: 0.9432\n",
      "Epoch 051 | Train Loss: 0.0981 Acc: 0.9657 | Val Loss: 0.1742 Acc: 0.9366\n",
      "Epoch 052 | Train Loss: 0.0965 Acc: 0.9647 | Val Loss: 0.1678 Acc: 0.9330\n",
      "Epoch 053 | Train Loss: 0.0911 Acc: 0.9671 | Val Loss: 0.2132 Acc: 0.9239\n",
      "Epoch 054 | Train Loss: 0.0922 Acc: 0.9648 | Val Loss: 0.2162 Acc: 0.9348\n",
      "Epoch 055 | Train Loss: 0.0848 Acc: 0.9701 | Val Loss: 0.1724 Acc: 0.9336\n",
      "Epoch 056 | Train Loss: 0.0809 Acc: 0.9703 | Val Loss: 0.1866 Acc: 0.9360\n",
      "Epoch 057 | Train Loss: 0.0788 Acc: 0.9718 | Val Loss: 0.1836 Acc: 0.9300\n",
      "Epoch 058 | Train Loss: 0.0814 Acc: 0.9684 | Val Loss: 0.1630 Acc: 0.9414\n",
      "Epoch 059 | Train Loss: 0.0791 Acc: 0.9707 | Val Loss: 0.2055 Acc: 0.9390\n",
      "Epoch 060 | Train Loss: 0.0866 Acc: 0.9678 | Val Loss: 0.1658 Acc: 0.9420\n",
      "Early stopping triggered.\n",
      "Epoch 001 | Train Loss: 0.6824 Acc: 0.5748 | Val Loss: 0.6806 Acc: 0.5713\n",
      "Epoch 002 | Train Loss: 0.6707 Acc: 0.5911 | Val Loss: 0.6499 Acc: 0.6492\n",
      "Epoch 003 | Train Loss: 0.6080 Acc: 0.6814 | Val Loss: 0.6003 Acc: 0.6769\n",
      "Epoch 004 | Train Loss: 0.5694 Acc: 0.7184 | Val Loss: 0.5772 Acc: 0.7162\n",
      "Epoch 005 | Train Loss: 0.5502 Acc: 0.7290 | Val Loss: 0.5566 Acc: 0.7162\n",
      "Epoch 006 | Train Loss: 0.5257 Acc: 0.7427 | Val Loss: 0.5321 Acc: 0.7367\n",
      "Epoch 007 | Train Loss: 0.5087 Acc: 0.7503 | Val Loss: 0.5034 Acc: 0.7476\n",
      "Epoch 008 | Train Loss: 0.4891 Acc: 0.7708 | Val Loss: 0.5054 Acc: 0.7458\n",
      "Epoch 009 | Train Loss: 0.4705 Acc: 0.7793 | Val Loss: 0.4627 Acc: 0.7717\n",
      "Epoch 010 | Train Loss: 0.4508 Acc: 0.7882 | Val Loss: 0.4695 Acc: 0.7772\n",
      "Epoch 011 | Train Loss: 0.4295 Acc: 0.7987 | Val Loss: 0.4306 Acc: 0.7953\n",
      "Epoch 012 | Train Loss: 0.3984 Acc: 0.8200 | Val Loss: 0.4085 Acc: 0.8116\n",
      "Epoch 013 | Train Loss: 0.3766 Acc: 0.8329 | Val Loss: 0.3599 Acc: 0.8255\n",
      "Epoch 014 | Train Loss: 0.3486 Acc: 0.8463 | Val Loss: 0.3403 Acc: 0.8514\n",
      "Epoch 015 | Train Loss: 0.3330 Acc: 0.8570 | Val Loss: 0.3775 Acc: 0.8261\n",
      "Epoch 016 | Train Loss: 0.3139 Acc: 0.8668 | Val Loss: 0.3145 Acc: 0.8575\n",
      "Epoch 017 | Train Loss: 0.2993 Acc: 0.8766 | Val Loss: 0.2915 Acc: 0.8744\n",
      "Epoch 018 | Train Loss: 0.2779 Acc: 0.8863 | Val Loss: 0.2653 Acc: 0.8841\n",
      "Epoch 019 | Train Loss: 0.2693 Acc: 0.8886 | Val Loss: 0.2850 Acc: 0.8780\n",
      "Epoch 020 | Train Loss: 0.2497 Acc: 0.8979 | Val Loss: 0.2366 Acc: 0.9100\n",
      "Epoch 021 | Train Loss: 0.2272 Acc: 0.9091 | Val Loss: 0.2825 Acc: 0.8835\n",
      "Epoch 022 | Train Loss: 0.2399 Acc: 0.9011 | Val Loss: 0.2401 Acc: 0.8986\n",
      "Epoch 023 | Train Loss: 0.2160 Acc: 0.9182 | Val Loss: 0.2131 Acc: 0.9185\n",
      "Epoch 024 | Train Loss: 0.2141 Acc: 0.9148 | Val Loss: 0.2147 Acc: 0.9179\n",
      "Epoch 025 | Train Loss: 0.1998 Acc: 0.9219 | Val Loss: 0.2240 Acc: 0.9058\n",
      "Epoch 026 | Train Loss: 0.1984 Acc: 0.9213 | Val Loss: 0.2309 Acc: 0.9076\n",
      "Epoch 027 | Train Loss: 0.1833 Acc: 0.9292 | Val Loss: 0.1922 Acc: 0.9209\n",
      "Epoch 028 | Train Loss: 0.1800 Acc: 0.9284 | Val Loss: 0.1907 Acc: 0.9263\n",
      "Epoch 029 | Train Loss: 0.1621 Acc: 0.9342 | Val Loss: 0.2108 Acc: 0.9082\n",
      "Epoch 030 | Train Loss: 0.1671 Acc: 0.9325 | Val Loss: 0.2141 Acc: 0.9016\n",
      "Epoch 031 | Train Loss: 0.1539 Acc: 0.9396 | Val Loss: 0.1951 Acc: 0.9233\n",
      "Epoch 032 | Train Loss: 0.1510 Acc: 0.9393 | Val Loss: 0.1766 Acc: 0.9251\n",
      "Epoch 033 | Train Loss: 0.1445 Acc: 0.9437 | Val Loss: 0.1905 Acc: 0.9221\n",
      "Epoch 034 | Train Loss: 0.1367 Acc: 0.9452 | Val Loss: 0.1740 Acc: 0.9300\n",
      "Epoch 035 | Train Loss: 0.1391 Acc: 0.9465 | Val Loss: 0.2005 Acc: 0.9215\n",
      "Epoch 036 | Train Loss: 0.1250 Acc: 0.9535 | Val Loss: 0.2038 Acc: 0.9257\n",
      "Epoch 037 | Train Loss: 0.1230 Acc: 0.9541 | Val Loss: 0.2235 Acc: 0.9112\n",
      "Epoch 038 | Train Loss: 0.1179 Acc: 0.9532 | Val Loss: 0.1574 Acc: 0.9384\n",
      "Epoch 039 | Train Loss: 0.1098 Acc: 0.9591 | Val Loss: 0.1383 Acc: 0.9505\n",
      "Epoch 040 | Train Loss: 0.1097 Acc: 0.9583 | Val Loss: 0.1771 Acc: 0.9312\n",
      "Epoch 041 | Train Loss: 0.1065 Acc: 0.9638 | Val Loss: 0.2169 Acc: 0.9239\n",
      "Epoch 042 | Train Loss: 0.1111 Acc: 0.9594 | Val Loss: 0.1488 Acc: 0.9426\n",
      "Epoch 043 | Train Loss: 0.0978 Acc: 0.9656 | Val Loss: 0.1678 Acc: 0.9384\n",
      "Epoch 044 | Train Loss: 0.0917 Acc: 0.9639 | Val Loss: 0.1574 Acc: 0.9463\n",
      "Epoch 045 | Train Loss: 0.0937 Acc: 0.9644 | Val Loss: 0.1543 Acc: 0.9457\n",
      "Epoch 046 | Train Loss: 0.0931 Acc: 0.9650 | Val Loss: 0.1481 Acc: 0.9505\n",
      "Epoch 047 | Train Loss: 0.0876 Acc: 0.9672 | Val Loss: 0.2173 Acc: 0.9269\n",
      "Epoch 048 | Train Loss: 0.0832 Acc: 0.9687 | Val Loss: 0.1552 Acc: 0.9463\n",
      "Epoch 049 | Train Loss: 0.0954 Acc: 0.9636 | Val Loss: 0.1268 Acc: 0.9535\n",
      "Epoch 050 | Train Loss: 0.0797 Acc: 0.9730 | Val Loss: 0.1987 Acc: 0.9420\n",
      "Epoch 051 | Train Loss: 0.0858 Acc: 0.9701 | Val Loss: 0.1801 Acc: 0.9378\n",
      "Epoch 052 | Train Loss: 0.0810 Acc: 0.9686 | Val Loss: 0.1688 Acc: 0.9450\n",
      "Epoch 053 | Train Loss: 0.0854 Acc: 0.9666 | Val Loss: 0.1367 Acc: 0.9523\n",
      "Epoch 054 | Train Loss: 0.0753 Acc: 0.9730 | Val Loss: 0.1465 Acc: 0.9475\n",
      "Epoch 055 | Train Loss: 0.0712 Acc: 0.9745 | Val Loss: 0.1819 Acc: 0.9499\n",
      "Epoch 056 | Train Loss: 0.0829 Acc: 0.9703 | Val Loss: 0.1352 Acc: 0.9499\n",
      "Epoch 057 | Train Loss: 0.0721 Acc: 0.9725 | Val Loss: 0.1460 Acc: 0.9444\n",
      "Epoch 058 | Train Loss: 0.0785 Acc: 0.9718 | Val Loss: 0.1371 Acc: 0.9457\n",
      "Epoch 059 | Train Loss: 0.0748 Acc: 0.9730 | Val Loss: 0.1492 Acc: 0.9523\n",
      "Early stopping triggered.\n",
      "Epoch 001 | Train Loss: 0.6816 Acc: 0.5748 | Val Loss: 0.6756 Acc: 0.5882\n",
      "Epoch 002 | Train Loss: 0.6676 Acc: 0.5997 | Val Loss: 0.6628 Acc: 0.6063\n",
      "Epoch 003 | Train Loss: 0.6527 Acc: 0.6225 | Val Loss: 0.6463 Acc: 0.6135\n",
      "Epoch 004 | Train Loss: 0.6104 Acc: 0.6811 | Val Loss: 0.5964 Acc: 0.6866\n",
      "Epoch 005 | Train Loss: 0.5689 Acc: 0.7115 | Val Loss: 0.5790 Acc: 0.7071\n",
      "Epoch 006 | Train Loss: 0.5484 Acc: 0.7318 | Val Loss: 0.5478 Acc: 0.7144\n",
      "Epoch 007 | Train Loss: 0.5224 Acc: 0.7439 | Val Loss: 0.5158 Acc: 0.7500\n",
      "Epoch 008 | Train Loss: 0.5084 Acc: 0.7506 | Val Loss: 0.5036 Acc: 0.7488\n",
      "Epoch 009 | Train Loss: 0.4865 Acc: 0.7705 | Val Loss: 0.4989 Acc: 0.7530\n",
      "Epoch 010 | Train Loss: 0.4606 Acc: 0.7853 | Val Loss: 0.4528 Acc: 0.7995\n",
      "Epoch 011 | Train Loss: 0.4345 Acc: 0.8021 | Val Loss: 0.4370 Acc: 0.7905\n",
      "Epoch 012 | Train Loss: 0.4094 Acc: 0.8137 | Val Loss: 0.4205 Acc: 0.8031\n",
      "Epoch 013 | Train Loss: 0.3893 Acc: 0.8215 | Val Loss: 0.3870 Acc: 0.8297\n",
      "Epoch 014 | Train Loss: 0.3672 Acc: 0.8404 | Val Loss: 0.3722 Acc: 0.8315\n",
      "Epoch 015 | Train Loss: 0.3547 Acc: 0.8425 | Val Loss: 0.3735 Acc: 0.8237\n",
      "Epoch 016 | Train Loss: 0.3231 Acc: 0.8596 | Val Loss: 0.3470 Acc: 0.8388\n",
      "Epoch 017 | Train Loss: 0.3039 Acc: 0.8677 | Val Loss: 0.3032 Acc: 0.8684\n",
      "Epoch 018 | Train Loss: 0.2872 Acc: 0.8791 | Val Loss: 0.3092 Acc: 0.8611\n",
      "Epoch 019 | Train Loss: 0.2771 Acc: 0.8824 | Val Loss: 0.3045 Acc: 0.8593\n",
      "Epoch 020 | Train Loss: 0.2500 Acc: 0.8975 | Val Loss: 0.2615 Acc: 0.8871\n",
      "Epoch 021 | Train Loss: 0.2286 Acc: 0.9071 | Val Loss: 0.2347 Acc: 0.8992\n",
      "Epoch 022 | Train Loss: 0.2273 Acc: 0.9082 | Val Loss: 0.2526 Acc: 0.8961\n",
      "Epoch 023 | Train Loss: 0.2122 Acc: 0.9130 | Val Loss: 0.2504 Acc: 0.8979\n",
      "Epoch 024 | Train Loss: 0.2000 Acc: 0.9207 | Val Loss: 0.2349 Acc: 0.9016\n",
      "Epoch 025 | Train Loss: 0.1821 Acc: 0.9244 | Val Loss: 0.2133 Acc: 0.9076\n",
      "Epoch 026 | Train Loss: 0.1844 Acc: 0.9253 | Val Loss: 0.2365 Acc: 0.9010\n",
      "Epoch 027 | Train Loss: 0.1752 Acc: 0.9321 | Val Loss: 0.2154 Acc: 0.9136\n",
      "Epoch 028 | Train Loss: 0.1654 Acc: 0.9349 | Val Loss: 0.2058 Acc: 0.9136\n",
      "Epoch 029 | Train Loss: 0.1571 Acc: 0.9370 | Val Loss: 0.2192 Acc: 0.9136\n",
      "Epoch 030 | Train Loss: 0.1510 Acc: 0.9440 | Val Loss: 0.2612 Acc: 0.9058\n",
      "Epoch 031 | Train Loss: 0.1364 Acc: 0.9473 | Val Loss: 0.2001 Acc: 0.9257\n",
      "Epoch 032 | Train Loss: 0.1357 Acc: 0.9490 | Val Loss: 0.2395 Acc: 0.9052\n",
      "Epoch 033 | Train Loss: 0.1323 Acc: 0.9500 | Val Loss: 0.1720 Acc: 0.9293\n",
      "Epoch 034 | Train Loss: 0.1227 Acc: 0.9529 | Val Loss: 0.1980 Acc: 0.9251\n",
      "Epoch 035 | Train Loss: 0.1217 Acc: 0.9533 | Val Loss: 0.1885 Acc: 0.9318\n",
      "Epoch 036 | Train Loss: 0.1296 Acc: 0.9481 | Val Loss: 0.1615 Acc: 0.9354\n",
      "Epoch 037 | Train Loss: 0.1098 Acc: 0.9562 | Val Loss: 0.1944 Acc: 0.9203\n",
      "Epoch 038 | Train Loss: 0.1060 Acc: 0.9601 | Val Loss: 0.1966 Acc: 0.9306\n",
      "Epoch 039 | Train Loss: 0.1048 Acc: 0.9603 | Val Loss: 0.1885 Acc: 0.9360\n",
      "Epoch 040 | Train Loss: 0.0912 Acc: 0.9683 | Val Loss: 0.1769 Acc: 0.9342\n",
      "Epoch 041 | Train Loss: 0.1030 Acc: 0.9613 | Val Loss: 0.1705 Acc: 0.9372\n",
      "Epoch 042 | Train Loss: 0.0933 Acc: 0.9665 | Val Loss: 0.1756 Acc: 0.9378\n",
      "Epoch 043 | Train Loss: 0.0898 Acc: 0.9656 | Val Loss: 0.2059 Acc: 0.9318\n",
      "Epoch 044 | Train Loss: 0.0853 Acc: 0.9697 | Val Loss: 0.2081 Acc: 0.9366\n",
      "Epoch 045 | Train Loss: 0.0883 Acc: 0.9680 | Val Loss: 0.1560 Acc: 0.9438\n",
      "Epoch 046 | Train Loss: 0.0800 Acc: 0.9709 | Val Loss: 0.1567 Acc: 0.9450\n",
      "Epoch 047 | Train Loss: 0.0822 Acc: 0.9690 | Val Loss: 0.1839 Acc: 0.9372\n",
      "Epoch 048 | Train Loss: 0.0786 Acc: 0.9706 | Val Loss: 0.1532 Acc: 0.9390\n",
      "Epoch 049 | Train Loss: 0.0865 Acc: 0.9675 | Val Loss: 0.1480 Acc: 0.9402\n",
      "Epoch 050 | Train Loss: 0.0751 Acc: 0.9700 | Val Loss: 0.1610 Acc: 0.9438\n",
      "Epoch 051 | Train Loss: 0.0687 Acc: 0.9737 | Val Loss: 0.1593 Acc: 0.9450\n",
      "Epoch 052 | Train Loss: 0.0702 Acc: 0.9746 | Val Loss: 0.1828 Acc: 0.9251\n",
      "Epoch 053 | Train Loss: 0.0802 Acc: 0.9704 | Val Loss: 0.1388 Acc: 0.9438\n",
      "Epoch 054 | Train Loss: 0.0751 Acc: 0.9719 | Val Loss: 0.1664 Acc: 0.9444\n",
      "Epoch 055 | Train Loss: 0.0730 Acc: 0.9733 | Val Loss: 0.1680 Acc: 0.9390\n",
      "Epoch 056 | Train Loss: 0.0726 Acc: 0.9751 | Val Loss: 0.1674 Acc: 0.9444\n",
      "Epoch 057 | Train Loss: 0.0582 Acc: 0.9786 | Val Loss: 0.1643 Acc: 0.9420\n",
      "Epoch 058 | Train Loss: 0.0618 Acc: 0.9787 | Val Loss: 0.1873 Acc: 0.9366\n",
      "Epoch 059 | Train Loss: 0.0554 Acc: 0.9807 | Val Loss: 0.1887 Acc: 0.9372\n",
      "Epoch 060 | Train Loss: 0.0633 Acc: 0.9769 | Val Loss: 0.1449 Acc: 0.9493\n",
      "Epoch 001 | Train Loss: 0.6832 Acc: 0.5713 | Val Loss: 0.6785 Acc: 0.5803\n",
      "Epoch 002 | Train Loss: 0.6748 Acc: 0.5941 | Val Loss: 0.7052 Acc: 0.5707\n",
      "Epoch 003 | Train Loss: 0.6700 Acc: 0.5941 | Val Loss: 0.6719 Acc: 0.5870\n",
      "Epoch 004 | Train Loss: 0.6637 Acc: 0.6037 | Val Loss: 0.6528 Acc: 0.6196\n",
      "Epoch 005 | Train Loss: 0.6463 Acc: 0.6378 | Val Loss: 0.6579 Acc: 0.6184\n",
      "Epoch 006 | Train Loss: 0.6173 Acc: 0.6784 | Val Loss: 0.5803 Acc: 0.7114\n",
      "Epoch 007 | Train Loss: 0.5810 Acc: 0.7134 | Val Loss: 0.5706 Acc: 0.7083\n",
      "Epoch 008 | Train Loss: 0.5627 Acc: 0.7193 | Val Loss: 0.5853 Acc: 0.7204\n",
      "Epoch 009 | Train Loss: 0.5520 Acc: 0.7320 | Val Loss: 0.5575 Acc: 0.7192\n",
      "Epoch 010 | Train Loss: 0.5488 Acc: 0.7352 | Val Loss: 0.5449 Acc: 0.7264\n",
      "Epoch 011 | Train Loss: 0.5341 Acc: 0.7444 | Val Loss: 0.5972 Acc: 0.6963\n",
      "Epoch 012 | Train Loss: 0.5253 Acc: 0.7462 | Val Loss: 0.5348 Acc: 0.7283\n",
      "Epoch 013 | Train Loss: 0.5107 Acc: 0.7528 | Val Loss: 0.5122 Acc: 0.7530\n",
      "Epoch 014 | Train Loss: 0.4997 Acc: 0.7616 | Val Loss: 0.5004 Acc: 0.7536\n",
      "Epoch 015 | Train Loss: 0.4894 Acc: 0.7691 | Val Loss: 0.4986 Acc: 0.7452\n",
      "Epoch 016 | Train Loss: 0.4753 Acc: 0.7746 | Val Loss: 0.4968 Acc: 0.7434\n",
      "Epoch 017 | Train Loss: 0.4636 Acc: 0.7859 | Val Loss: 0.4564 Acc: 0.7778\n",
      "Epoch 018 | Train Loss: 0.4427 Acc: 0.7945 | Val Loss: 0.4411 Acc: 0.7911\n",
      "Epoch 019 | Train Loss: 0.4307 Acc: 0.8008 | Val Loss: 0.4429 Acc: 0.7923\n",
      "Epoch 020 | Train Loss: 0.4308 Acc: 0.8028 | Val Loss: 0.4300 Acc: 0.7886\n",
      "Epoch 021 | Train Loss: 0.4114 Acc: 0.8087 | Val Loss: 0.4369 Acc: 0.7808\n",
      "Epoch 022 | Train Loss: 0.4132 Acc: 0.8134 | Val Loss: 0.4291 Acc: 0.7935\n",
      "Epoch 023 | Train Loss: 0.4159 Acc: 0.8140 | Val Loss: 0.4046 Acc: 0.7977\n",
      "Epoch 024 | Train Loss: 0.3819 Acc: 0.8261 | Val Loss: 0.4084 Acc: 0.8128\n",
      "Epoch 025 | Train Loss: 0.3721 Acc: 0.8386 | Val Loss: 0.3875 Acc: 0.8104\n",
      "Epoch 026 | Train Loss: 0.3606 Acc: 0.8401 | Val Loss: 0.3455 Acc: 0.8382\n",
      "Epoch 027 | Train Loss: 0.3479 Acc: 0.8449 | Val Loss: 0.3704 Acc: 0.8339\n",
      "Epoch 028 | Train Loss: 0.3413 Acc: 0.8499 | Val Loss: 0.3562 Acc: 0.8460\n",
      "Epoch 029 | Train Loss: 0.3433 Acc: 0.8532 | Val Loss: 0.3368 Acc: 0.8521\n",
      "Epoch 030 | Train Loss: 0.3203 Acc: 0.8634 | Val Loss: 0.3300 Acc: 0.8539\n",
      "Epoch 031 | Train Loss: 0.3003 Acc: 0.8692 | Val Loss: 0.3092 Acc: 0.8605\n",
      "Epoch 032 | Train Loss: 0.2985 Acc: 0.8748 | Val Loss: 0.2984 Acc: 0.8732\n",
      "Epoch 033 | Train Loss: 0.2941 Acc: 0.8797 | Val Loss: 0.3158 Acc: 0.8629\n",
      "Epoch 034 | Train Loss: 0.2981 Acc: 0.8771 | Val Loss: 0.2736 Acc: 0.8835\n",
      "Epoch 035 | Train Loss: 0.2710 Acc: 0.8886 | Val Loss: 0.2747 Acc: 0.8810\n",
      "Epoch 036 | Train Loss: 0.2627 Acc: 0.8901 | Val Loss: 0.2805 Acc: 0.8816\n",
      "Epoch 037 | Train Loss: 0.2663 Acc: 0.8914 | Val Loss: 0.2729 Acc: 0.8847\n",
      "Epoch 038 | Train Loss: 0.2595 Acc: 0.8940 | Val Loss: 0.2639 Acc: 0.8925\n",
      "Epoch 039 | Train Loss: 0.2569 Acc: 0.9026 | Val Loss: 0.2716 Acc: 0.8786\n",
      "Epoch 040 | Train Loss: 0.2350 Acc: 0.9046 | Val Loss: 0.2512 Acc: 0.8907\n",
      "Epoch 041 | Train Loss: 0.2462 Acc: 0.9000 | Val Loss: 0.2693 Acc: 0.8792\n",
      "Epoch 042 | Train Loss: 0.2371 Acc: 0.9070 | Val Loss: 0.2567 Acc: 0.8967\n",
      "Epoch 043 | Train Loss: 0.2199 Acc: 0.9111 | Val Loss: 0.2359 Acc: 0.9112\n",
      "Epoch 044 | Train Loss: 0.2078 Acc: 0.9132 | Val Loss: 0.3109 Acc: 0.8786\n",
      "Epoch 045 | Train Loss: 0.2169 Acc: 0.9112 | Val Loss: 0.2318 Acc: 0.9064\n",
      "Epoch 046 | Train Loss: 0.2017 Acc: 0.9210 | Val Loss: 0.2253 Acc: 0.9094\n",
      "Epoch 047 | Train Loss: 0.2032 Acc: 0.9210 | Val Loss: 0.2198 Acc: 0.9064\n",
      "Epoch 048 | Train Loss: 0.1961 Acc: 0.9245 | Val Loss: 0.2198 Acc: 0.9124\n",
      "Epoch 049 | Train Loss: 0.1886 Acc: 0.9292 | Val Loss: 0.2431 Acc: 0.9058\n",
      "Epoch 050 | Train Loss: 0.1964 Acc: 0.9281 | Val Loss: 0.2215 Acc: 0.9076\n",
      "Epoch 051 | Train Loss: 0.1832 Acc: 0.9315 | Val Loss: 0.2190 Acc: 0.9118\n",
      "Epoch 052 | Train Loss: 0.1890 Acc: 0.9281 | Val Loss: 0.2170 Acc: 0.9149\n",
      "Epoch 053 | Train Loss: 0.1774 Acc: 0.9301 | Val Loss: 0.2074 Acc: 0.9136\n",
      "Epoch 054 | Train Loss: 0.1628 Acc: 0.9373 | Val Loss: 0.2321 Acc: 0.9058\n",
      "Epoch 055 | Train Loss: 0.1815 Acc: 0.9290 | Val Loss: 0.1973 Acc: 0.9197\n",
      "Epoch 056 | Train Loss: 0.1564 Acc: 0.9407 | Val Loss: 0.2179 Acc: 0.9173\n",
      "Epoch 057 | Train Loss: 0.1598 Acc: 0.9384 | Val Loss: 0.2042 Acc: 0.9191\n",
      "Epoch 058 | Train Loss: 0.1570 Acc: 0.9390 | Val Loss: 0.2529 Acc: 0.9143\n",
      "Epoch 059 | Train Loss: 0.1439 Acc: 0.9447 | Val Loss: 0.1949 Acc: 0.9251\n",
      "Epoch 060 | Train Loss: 0.1455 Acc: 0.9410 | Val Loss: 0.2060 Acc: 0.9094\n",
      "Epoch 001 | Train Loss: 0.6805 Acc: 0.5706 | Val Loss: 0.6743 Acc: 0.5809\n",
      "Epoch 002 | Train Loss: 0.6517 Acc: 0.6242 | Val Loss: 0.6119 Acc: 0.6787\n",
      "Epoch 003 | Train Loss: 0.5900 Acc: 0.6995 | Val Loss: 0.5839 Acc: 0.6878\n",
      "Epoch 004 | Train Loss: 0.5606 Acc: 0.7232 | Val Loss: 0.5611 Acc: 0.7120\n",
      "Epoch 005 | Train Loss: 0.5474 Acc: 0.7308 | Val Loss: 0.5323 Acc: 0.7337\n",
      "Epoch 006 | Train Loss: 0.5306 Acc: 0.7429 | Val Loss: 0.5278 Acc: 0.7301\n",
      "Epoch 007 | Train Loss: 0.5066 Acc: 0.7500 | Val Loss: 0.5087 Acc: 0.7434\n",
      "Epoch 008 | Train Loss: 0.4905 Acc: 0.7655 | Val Loss: 0.4822 Acc: 0.7615\n",
      "Epoch 009 | Train Loss: 0.4677 Acc: 0.7824 | Val Loss: 0.4612 Acc: 0.7814\n",
      "Epoch 010 | Train Loss: 0.4430 Acc: 0.7945 | Val Loss: 0.4482 Acc: 0.7923\n",
      "Epoch 011 | Train Loss: 0.4330 Acc: 0.7984 | Val Loss: 0.4127 Acc: 0.8122\n",
      "Epoch 012 | Train Loss: 0.4196 Acc: 0.8037 | Val Loss: 0.4242 Acc: 0.7989\n",
      "Epoch 013 | Train Loss: 0.3905 Acc: 0.8261 | Val Loss: 0.3914 Acc: 0.8086\n",
      "Epoch 014 | Train Loss: 0.3804 Acc: 0.8285 | Val Loss: 0.3720 Acc: 0.8291\n",
      "Epoch 015 | Train Loss: 0.3517 Acc: 0.8464 | Val Loss: 0.3859 Acc: 0.8249\n",
      "Epoch 016 | Train Loss: 0.3327 Acc: 0.8502 | Val Loss: 0.3429 Acc: 0.8454\n",
      "Epoch 017 | Train Loss: 0.3228 Acc: 0.8634 | Val Loss: 0.3627 Acc: 0.8261\n",
      "Epoch 018 | Train Loss: 0.3041 Acc: 0.8688 | Val Loss: 0.3066 Acc: 0.8635\n",
      "Epoch 019 | Train Loss: 0.2774 Acc: 0.8854 | Val Loss: 0.2865 Acc: 0.8810\n",
      "Epoch 020 | Train Loss: 0.2667 Acc: 0.8899 | Val Loss: 0.2762 Acc: 0.8780\n",
      "Epoch 021 | Train Loss: 0.2589 Acc: 0.8931 | Val Loss: 0.2592 Acc: 0.8841\n",
      "Epoch 022 | Train Loss: 0.2341 Acc: 0.9000 | Val Loss: 0.2736 Acc: 0.8786\n",
      "Epoch 023 | Train Loss: 0.2285 Acc: 0.9082 | Val Loss: 0.2625 Acc: 0.8901\n",
      "Epoch 024 | Train Loss: 0.2067 Acc: 0.9133 | Val Loss: 0.2456 Acc: 0.9028\n",
      "Epoch 025 | Train Loss: 0.2066 Acc: 0.9191 | Val Loss: 0.2729 Acc: 0.8816\n",
      "Epoch 026 | Train Loss: 0.1941 Acc: 0.9227 | Val Loss: 0.2480 Acc: 0.8937\n",
      "Epoch 027 | Train Loss: 0.1851 Acc: 0.9238 | Val Loss: 0.2072 Acc: 0.9191\n",
      "Epoch 028 | Train Loss: 0.1717 Acc: 0.9327 | Val Loss: 0.2139 Acc: 0.9088\n",
      "Epoch 029 | Train Loss: 0.1686 Acc: 0.9325 | Val Loss: 0.2120 Acc: 0.9124\n",
      "Epoch 030 | Train Loss: 0.1655 Acc: 0.9337 | Val Loss: 0.2164 Acc: 0.9143\n",
      "Epoch 031 | Train Loss: 0.1639 Acc: 0.9349 | Val Loss: 0.2462 Acc: 0.8925\n",
      "Epoch 032 | Train Loss: 0.1430 Acc: 0.9423 | Val Loss: 0.1996 Acc: 0.9257\n",
      "Epoch 033 | Train Loss: 0.1578 Acc: 0.9357 | Val Loss: 0.1885 Acc: 0.9275\n",
      "Epoch 034 | Train Loss: 0.1379 Acc: 0.9493 | Val Loss: 0.1949 Acc: 0.9185\n",
      "Epoch 035 | Train Loss: 0.1321 Acc: 0.9497 | Val Loss: 0.1860 Acc: 0.9336\n",
      "Epoch 036 | Train Loss: 0.1321 Acc: 0.9493 | Val Loss: 0.2063 Acc: 0.9293\n",
      "Epoch 037 | Train Loss: 0.1216 Acc: 0.9555 | Val Loss: 0.1753 Acc: 0.9306\n",
      "Epoch 038 | Train Loss: 0.1245 Acc: 0.9536 | Val Loss: 0.1804 Acc: 0.9281\n",
      "Epoch 039 | Train Loss: 0.1270 Acc: 0.9523 | Val Loss: 0.2213 Acc: 0.9130\n",
      "Epoch 040 | Train Loss: 0.1180 Acc: 0.9517 | Val Loss: 0.1817 Acc: 0.9336\n",
      "Epoch 041 | Train Loss: 0.1119 Acc: 0.9586 | Val Loss: 0.1900 Acc: 0.9312\n",
      "Epoch 042 | Train Loss: 0.1064 Acc: 0.9585 | Val Loss: 0.2015 Acc: 0.9191\n",
      "Epoch 043 | Train Loss: 0.0980 Acc: 0.9638 | Val Loss: 0.1629 Acc: 0.9444\n",
      "Epoch 044 | Train Loss: 0.0950 Acc: 0.9660 | Val Loss: 0.1647 Acc: 0.9432\n",
      "Epoch 045 | Train Loss: 0.0996 Acc: 0.9642 | Val Loss: 0.1946 Acc: 0.9372\n",
      "Epoch 046 | Train Loss: 0.0961 Acc: 0.9624 | Val Loss: 0.1860 Acc: 0.9354\n",
      "Epoch 047 | Train Loss: 0.1024 Acc: 0.9592 | Val Loss: 0.1590 Acc: 0.9378\n",
      "Epoch 048 | Train Loss: 0.1027 Acc: 0.9610 | Val Loss: 0.1898 Acc: 0.9251\n",
      "Epoch 049 | Train Loss: 0.0977 Acc: 0.9650 | Val Loss: 0.1637 Acc: 0.9318\n",
      "Epoch 050 | Train Loss: 0.0831 Acc: 0.9675 | Val Loss: 0.1670 Acc: 0.9432\n",
      "Epoch 051 | Train Loss: 0.0895 Acc: 0.9684 | Val Loss: 0.1674 Acc: 0.9432\n",
      "Epoch 052 | Train Loss: 0.0880 Acc: 0.9680 | Val Loss: 0.1670 Acc: 0.9390\n",
      "Epoch 053 | Train Loss: 0.0897 Acc: 0.9698 | Val Loss: 0.2009 Acc: 0.9227\n",
      "Epoch 054 | Train Loss: 0.0819 Acc: 0.9693 | Val Loss: 0.2037 Acc: 0.9330\n",
      "Epoch 055 | Train Loss: 0.0822 Acc: 0.9706 | Val Loss: 0.1394 Acc: 0.9499\n",
      "Epoch 056 | Train Loss: 0.0713 Acc: 0.9749 | Val Loss: 0.1799 Acc: 0.9378\n",
      "Epoch 057 | Train Loss: 0.0806 Acc: 0.9703 | Val Loss: 0.1552 Acc: 0.9517\n",
      "Epoch 058 | Train Loss: 0.0798 Acc: 0.9695 | Val Loss: 0.1731 Acc: 0.9408\n",
      "Epoch 059 | Train Loss: 0.0763 Acc: 0.9713 | Val Loss: 0.1667 Acc: 0.9438\n",
      "Epoch 060 | Train Loss: 0.0825 Acc: 0.9695 | Val Loss: 0.1676 Acc: 0.9372\n",
      "Epoch 001 | Train Loss: 0.6799 Acc: 0.5833 | Val Loss: 0.6838 Acc: 0.5700\n",
      "Epoch 002 | Train Loss: 0.6733 Acc: 0.5911 | Val Loss: 0.6673 Acc: 0.5990\n",
      "Epoch 003 | Train Loss: 0.6634 Acc: 0.6100 | Val Loss: 0.6668 Acc: 0.6051\n",
      "Epoch 004 | Train Loss: 0.6362 Acc: 0.6483 | Val Loss: 0.6141 Acc: 0.6630\n",
      "Epoch 005 | Train Loss: 0.5963 Acc: 0.7013 | Val Loss: 0.5885 Acc: 0.6908\n",
      "Epoch 006 | Train Loss: 0.5760 Acc: 0.7086 | Val Loss: 0.5637 Acc: 0.7071\n",
      "Epoch 007 | Train Loss: 0.5391 Acc: 0.7373 | Val Loss: 0.5234 Acc: 0.7325\n",
      "Epoch 008 | Train Loss: 0.5081 Acc: 0.7554 | Val Loss: 0.5320 Acc: 0.7325\n",
      "Epoch 009 | Train Loss: 0.4983 Acc: 0.7639 | Val Loss: 0.4782 Acc: 0.7675\n",
      "Epoch 010 | Train Loss: 0.4831 Acc: 0.7758 | Val Loss: 0.4793 Acc: 0.7657\n",
      "Epoch 011 | Train Loss: 0.4562 Acc: 0.7860 | Val Loss: 0.4716 Acc: 0.7687\n",
      "Epoch 012 | Train Loss: 0.4331 Acc: 0.8033 | Val Loss: 0.4333 Acc: 0.7983\n",
      "Epoch 013 | Train Loss: 0.4129 Acc: 0.8114 | Val Loss: 0.3932 Acc: 0.8237\n",
      "Epoch 014 | Train Loss: 0.4041 Acc: 0.8187 | Val Loss: 0.3888 Acc: 0.8213\n",
      "Epoch 015 | Train Loss: 0.3878 Acc: 0.8235 | Val Loss: 0.3616 Acc: 0.8364\n",
      "Epoch 016 | Train Loss: 0.3588 Acc: 0.8418 | Val Loss: 0.3850 Acc: 0.8237\n",
      "Epoch 017 | Train Loss: 0.3541 Acc: 0.8418 | Val Loss: 0.3486 Acc: 0.8533\n",
      "Epoch 018 | Train Loss: 0.3284 Acc: 0.8561 | Val Loss: 0.3209 Acc: 0.8659\n",
      "Epoch 019 | Train Loss: 0.3162 Acc: 0.8659 | Val Loss: 0.3527 Acc: 0.8321\n",
      "Epoch 020 | Train Loss: 0.3149 Acc: 0.8646 | Val Loss: 0.3027 Acc: 0.8756\n",
      "Epoch 021 | Train Loss: 0.2937 Acc: 0.8763 | Val Loss: 0.2909 Acc: 0.8786\n",
      "Epoch 022 | Train Loss: 0.2734 Acc: 0.8848 | Val Loss: 0.3249 Acc: 0.8647\n",
      "Epoch 023 | Train Loss: 0.2586 Acc: 0.8934 | Val Loss: 0.2536 Acc: 0.8986\n",
      "Epoch 024 | Train Loss: 0.2568 Acc: 0.8904 | Val Loss: 0.2600 Acc: 0.8919\n",
      "Epoch 025 | Train Loss: 0.2410 Acc: 0.9019 | Val Loss: 0.2667 Acc: 0.8883\n",
      "Epoch 026 | Train Loss: 0.2313 Acc: 0.9046 | Val Loss: 0.2232 Acc: 0.9022\n",
      "Epoch 027 | Train Loss: 0.2228 Acc: 0.9070 | Val Loss: 0.2277 Acc: 0.9070\n",
      "Epoch 028 | Train Loss: 0.2208 Acc: 0.9136 | Val Loss: 0.2503 Acc: 0.9004\n",
      "Epoch 029 | Train Loss: 0.2250 Acc: 0.9067 | Val Loss: 0.2099 Acc: 0.9094\n",
      "Epoch 030 | Train Loss: 0.2144 Acc: 0.9109 | Val Loss: 0.2123 Acc: 0.9215\n",
      "Epoch 031 | Train Loss: 0.1953 Acc: 0.9213 | Val Loss: 0.2212 Acc: 0.9191\n",
      "Epoch 032 | Train Loss: 0.1831 Acc: 0.9289 | Val Loss: 0.2021 Acc: 0.9185\n",
      "Epoch 033 | Train Loss: 0.1806 Acc: 0.9265 | Val Loss: 0.1881 Acc: 0.9293\n",
      "Epoch 034 | Train Loss: 0.1689 Acc: 0.9287 | Val Loss: 0.2073 Acc: 0.9209\n",
      "Epoch 035 | Train Loss: 0.1654 Acc: 0.9343 | Val Loss: 0.2035 Acc: 0.9215\n",
      "Epoch 036 | Train Loss: 0.1679 Acc: 0.9339 | Val Loss: 0.1878 Acc: 0.9293\n",
      "Epoch 037 | Train Loss: 0.1504 Acc: 0.9417 | Val Loss: 0.1939 Acc: 0.9293\n",
      "Epoch 038 | Train Loss: 0.1521 Acc: 0.9390 | Val Loss: 0.1869 Acc: 0.9239\n",
      "Epoch 039 | Train Loss: 0.1539 Acc: 0.9417 | Val Loss: 0.1811 Acc: 0.9348\n",
      "Epoch 040 | Train Loss: 0.1515 Acc: 0.9419 | Val Loss: 0.2116 Acc: 0.9130\n",
      "Epoch 041 | Train Loss: 0.1515 Acc: 0.9396 | Val Loss: 0.1637 Acc: 0.9378\n",
      "Epoch 042 | Train Loss: 0.1343 Acc: 0.9475 | Val Loss: 0.2043 Acc: 0.9215\n",
      "Epoch 043 | Train Loss: 0.1399 Acc: 0.9452 | Val Loss: 0.1601 Acc: 0.9378\n",
      "Epoch 044 | Train Loss: 0.1249 Acc: 0.9500 | Val Loss: 0.1960 Acc: 0.9263\n",
      "Epoch 045 | Train Loss: 0.1347 Acc: 0.9499 | Val Loss: 0.2016 Acc: 0.9257\n",
      "Epoch 046 | Train Loss: 0.1226 Acc: 0.9505 | Val Loss: 0.1558 Acc: 0.9450\n",
      "Epoch 047 | Train Loss: 0.1291 Acc: 0.9497 | Val Loss: 0.1566 Acc: 0.9438\n",
      "Epoch 048 | Train Loss: 0.1187 Acc: 0.9536 | Val Loss: 0.1581 Acc: 0.9426\n",
      "Epoch 049 | Train Loss: 0.1133 Acc: 0.9550 | Val Loss: 0.1632 Acc: 0.9378\n",
      "Epoch 050 | Train Loss: 0.1179 Acc: 0.9530 | Val Loss: 0.1885 Acc: 0.9330\n",
      "Epoch 051 | Train Loss: 0.1187 Acc: 0.9555 | Val Loss: 0.1754 Acc: 0.9348\n",
      "Epoch 052 | Train Loss: 0.1112 Acc: 0.9577 | Val Loss: 0.1457 Acc: 0.9432\n",
      "Epoch 053 | Train Loss: 0.1121 Acc: 0.9577 | Val Loss: 0.2099 Acc: 0.9203\n",
      "Epoch 054 | Train Loss: 0.1035 Acc: 0.9601 | Val Loss: 0.1624 Acc: 0.9444\n",
      "Epoch 055 | Train Loss: 0.1021 Acc: 0.9585 | Val Loss: 0.1890 Acc: 0.9318\n",
      "Epoch 056 | Train Loss: 0.1040 Acc: 0.9633 | Val Loss: 0.1717 Acc: 0.9354\n",
      "Epoch 057 | Train Loss: 0.0956 Acc: 0.9630 | Val Loss: 0.1527 Acc: 0.9432\n",
      "Epoch 058 | Train Loss: 0.1004 Acc: 0.9616 | Val Loss: 0.1408 Acc: 0.9390\n",
      "Epoch 059 | Train Loss: 0.0928 Acc: 0.9641 | Val Loss: 0.1631 Acc: 0.9438\n",
      "Epoch 060 | Train Loss: 0.0996 Acc: 0.9633 | Val Loss: 0.1588 Acc: 0.9475\n",
      "Iteration 37/40 | Best Val Loss: 0.1122 | Iter Time: 222.81s | Total Time: 149.88 min\n",
      "Epoch 001 | Train Loss: 0.6832 Acc: 0.5718 | Val Loss: 0.6755 Acc: 0.5906\n",
      "Epoch 002 | Train Loss: 0.6733 Acc: 0.5907 | Val Loss: 0.6653 Acc: 0.5978\n",
      "Epoch 003 | Train Loss: 0.6327 Acc: 0.6526 | Val Loss: 0.5966 Acc: 0.6866\n",
      "Epoch 004 | Train Loss: 0.5736 Acc: 0.7121 | Val Loss: 0.5633 Acc: 0.7083\n",
      "Epoch 005 | Train Loss: 0.5472 Acc: 0.7282 | Val Loss: 0.5424 Acc: 0.7222\n",
      "Epoch 006 | Train Loss: 0.5232 Acc: 0.7460 | Val Loss: 0.5286 Acc: 0.7367\n",
      "Epoch 007 | Train Loss: 0.4993 Acc: 0.7575 | Val Loss: 0.4956 Acc: 0.7548\n",
      "Epoch 008 | Train Loss: 0.4823 Acc: 0.7705 | Val Loss: 0.4963 Acc: 0.7711\n",
      "Epoch 009 | Train Loss: 0.4607 Acc: 0.7797 | Val Loss: 0.4582 Acc: 0.7681\n",
      "Epoch 010 | Train Loss: 0.4320 Acc: 0.8001 | Val Loss: 0.4511 Acc: 0.7868\n",
      "Epoch 011 | Train Loss: 0.4016 Acc: 0.8175 | Val Loss: 0.4163 Acc: 0.8056\n",
      "Epoch 012 | Train Loss: 0.3756 Acc: 0.8338 | Val Loss: 0.3489 Acc: 0.8508\n",
      "Epoch 013 | Train Loss: 0.3434 Acc: 0.8537 | Val Loss: 0.3374 Acc: 0.8490\n",
      "Epoch 014 | Train Loss: 0.3203 Acc: 0.8667 | Val Loss: 0.2989 Acc: 0.8804\n",
      "Epoch 015 | Train Loss: 0.3091 Acc: 0.8671 | Val Loss: 0.3007 Acc: 0.8659\n",
      "Epoch 016 | Train Loss: 0.2807 Acc: 0.8842 | Val Loss: 0.3000 Acc: 0.8792\n",
      "Epoch 017 | Train Loss: 0.2615 Acc: 0.8936 | Val Loss: 0.2669 Acc: 0.8853\n",
      "Epoch 018 | Train Loss: 0.2336 Acc: 0.9023 | Val Loss: 0.2820 Acc: 0.8792\n",
      "Epoch 019 | Train Loss: 0.2324 Acc: 0.9055 | Val Loss: 0.2545 Acc: 0.8992\n",
      "Epoch 020 | Train Loss: 0.2146 Acc: 0.9153 | Val Loss: 0.2841 Acc: 0.8756\n",
      "Epoch 021 | Train Loss: 0.2126 Acc: 0.9168 | Val Loss: 0.2369 Acc: 0.8973\n",
      "Epoch 022 | Train Loss: 0.1936 Acc: 0.9280 | Val Loss: 0.2456 Acc: 0.9088\n",
      "Epoch 023 | Train Loss: 0.1916 Acc: 0.9218 | Val Loss: 0.2430 Acc: 0.9022\n",
      "Epoch 024 | Train Loss: 0.1789 Acc: 0.9311 | Val Loss: 0.2020 Acc: 0.9094\n",
      "Epoch 025 | Train Loss: 0.1659 Acc: 0.9398 | Val Loss: 0.2194 Acc: 0.9185\n",
      "Epoch 026 | Train Loss: 0.1690 Acc: 0.9348 | Val Loss: 0.2062 Acc: 0.9191\n",
      "Epoch 027 | Train Loss: 0.1524 Acc: 0.9408 | Val Loss: 0.2038 Acc: 0.9203\n",
      "Epoch 028 | Train Loss: 0.1523 Acc: 0.9444 | Val Loss: 0.1793 Acc: 0.9293\n",
      "Epoch 029 | Train Loss: 0.1487 Acc: 0.9402 | Val Loss: 0.1737 Acc: 0.9330\n",
      "Epoch 030 | Train Loss: 0.1465 Acc: 0.9420 | Val Loss: 0.1912 Acc: 0.9245\n",
      "Epoch 031 | Train Loss: 0.1296 Acc: 0.9541 | Val Loss: 0.1981 Acc: 0.9257\n",
      "Epoch 032 | Train Loss: 0.1389 Acc: 0.9479 | Val Loss: 0.2006 Acc: 0.9281\n",
      "Epoch 033 | Train Loss: 0.1431 Acc: 0.9473 | Val Loss: 0.1902 Acc: 0.9269\n",
      "Epoch 034 | Train Loss: 0.1223 Acc: 0.9549 | Val Loss: 0.1587 Acc: 0.9438\n",
      "Epoch 035 | Train Loss: 0.1212 Acc: 0.9535 | Val Loss: 0.1538 Acc: 0.9457\n",
      "Epoch 036 | Train Loss: 0.1132 Acc: 0.9586 | Val Loss: 0.1667 Acc: 0.9366\n",
      "Epoch 037 | Train Loss: 0.1079 Acc: 0.9613 | Val Loss: 0.1704 Acc: 0.9372\n",
      "Epoch 038 | Train Loss: 0.1255 Acc: 0.9527 | Val Loss: 0.1654 Acc: 0.9432\n",
      "Epoch 039 | Train Loss: 0.1072 Acc: 0.9609 | Val Loss: 0.1559 Acc: 0.9390\n",
      "Epoch 040 | Train Loss: 0.1073 Acc: 0.9615 | Val Loss: 0.1507 Acc: 0.9481\n",
      "Epoch 041 | Train Loss: 0.1014 Acc: 0.9612 | Val Loss: 0.1656 Acc: 0.9420\n",
      "Epoch 042 | Train Loss: 0.1041 Acc: 0.9600 | Val Loss: 0.1511 Acc: 0.9432\n",
      "Epoch 043 | Train Loss: 0.0981 Acc: 0.9633 | Val Loss: 0.1464 Acc: 0.9450\n",
      "Epoch 044 | Train Loss: 0.0964 Acc: 0.9660 | Val Loss: 0.2452 Acc: 0.9191\n",
      "Epoch 045 | Train Loss: 0.0894 Acc: 0.9663 | Val Loss: 0.1716 Acc: 0.9432\n",
      "Epoch 046 | Train Loss: 0.0991 Acc: 0.9641 | Val Loss: 0.1393 Acc: 0.9559\n",
      "Epoch 047 | Train Loss: 0.0767 Acc: 0.9715 | Val Loss: 0.1492 Acc: 0.9463\n",
      "Epoch 048 | Train Loss: 0.0918 Acc: 0.9647 | Val Loss: 0.1406 Acc: 0.9565\n",
      "Epoch 049 | Train Loss: 0.0931 Acc: 0.9645 | Val Loss: 0.1505 Acc: 0.9408\n",
      "Epoch 050 | Train Loss: 0.0833 Acc: 0.9693 | Val Loss: 0.1389 Acc: 0.9505\n",
      "Epoch 051 | Train Loss: 0.0823 Acc: 0.9697 | Val Loss: 0.1717 Acc: 0.9463\n",
      "Epoch 052 | Train Loss: 0.0922 Acc: 0.9666 | Val Loss: 0.1820 Acc: 0.9354\n",
      "Epoch 053 | Train Loss: 0.0875 Acc: 0.9662 | Val Loss: 0.1681 Acc: 0.9432\n",
      "Epoch 054 | Train Loss: 0.0851 Acc: 0.9684 | Val Loss: 0.1618 Acc: 0.9463\n",
      "Epoch 055 | Train Loss: 0.0948 Acc: 0.9648 | Val Loss: 0.1403 Acc: 0.9517\n",
      "Epoch 056 | Train Loss: 0.0718 Acc: 0.9731 | Val Loss: 0.1428 Acc: 0.9499\n",
      "Epoch 057 | Train Loss: 0.0747 Acc: 0.9704 | Val Loss: 0.1588 Acc: 0.9475\n",
      "Epoch 058 | Train Loss: 0.0724 Acc: 0.9743 | Val Loss: 0.1531 Acc: 0.9517\n",
      "Epoch 059 | Train Loss: 0.0743 Acc: 0.9733 | Val Loss: 0.1438 Acc: 0.9475\n",
      "Epoch 060 | Train Loss: 0.0696 Acc: 0.9740 | Val Loss: 0.1790 Acc: 0.9408\n",
      "Early stopping triggered.\n",
      "Epoch 001 | Train Loss: 0.6810 Acc: 0.5766 | Val Loss: 0.6823 Acc: 0.5713\n",
      "Epoch 002 | Train Loss: 0.6775 Acc: 0.5830 | Val Loss: 0.6770 Acc: 0.5779\n",
      "Epoch 003 | Train Loss: 0.6579 Acc: 0.6147 | Val Loss: 0.6425 Acc: 0.6335\n",
      "Epoch 004 | Train Loss: 0.6085 Acc: 0.6941 | Val Loss: 0.5872 Acc: 0.6938\n",
      "Epoch 005 | Train Loss: 0.5651 Acc: 0.7181 | Val Loss: 0.5693 Acc: 0.7120\n",
      "Epoch 006 | Train Loss: 0.5503 Acc: 0.7278 | Val Loss: 0.5454 Acc: 0.7150\n",
      "Epoch 007 | Train Loss: 0.5179 Acc: 0.7486 | Val Loss: 0.5230 Acc: 0.7361\n",
      "Epoch 008 | Train Loss: 0.5015 Acc: 0.7599 | Val Loss: 0.5049 Acc: 0.7536\n",
      "Epoch 009 | Train Loss: 0.4780 Acc: 0.7700 | Val Loss: 0.4642 Acc: 0.7814\n",
      "Epoch 010 | Train Loss: 0.4568 Acc: 0.7883 | Val Loss: 0.4434 Acc: 0.7856\n",
      "Epoch 011 | Train Loss: 0.4276 Acc: 0.8069 | Val Loss: 0.4056 Acc: 0.8074\n",
      "Epoch 012 | Train Loss: 0.4025 Acc: 0.8197 | Val Loss: 0.4170 Acc: 0.7995\n",
      "Epoch 013 | Train Loss: 0.3725 Acc: 0.8357 | Val Loss: 0.3883 Acc: 0.8231\n",
      "Epoch 014 | Train Loss: 0.3538 Acc: 0.8454 | Val Loss: 0.3333 Acc: 0.8557\n",
      "Epoch 015 | Train Loss: 0.3276 Acc: 0.8566 | Val Loss: 0.3313 Acc: 0.8551\n",
      "Epoch 016 | Train Loss: 0.3101 Acc: 0.8668 | Val Loss: 0.2999 Acc: 0.8653\n",
      "Epoch 017 | Train Loss: 0.2942 Acc: 0.8726 | Val Loss: 0.3046 Acc: 0.8623\n",
      "Epoch 018 | Train Loss: 0.2727 Acc: 0.8834 | Val Loss: 0.2766 Acc: 0.8853\n",
      "Epoch 019 | Train Loss: 0.2549 Acc: 0.8954 | Val Loss: 0.2848 Acc: 0.8835\n",
      "Epoch 020 | Train Loss: 0.2436 Acc: 0.8985 | Val Loss: 0.2576 Acc: 0.9034\n",
      "Epoch 021 | Train Loss: 0.2335 Acc: 0.9052 | Val Loss: 0.2447 Acc: 0.9010\n",
      "Epoch 022 | Train Loss: 0.2177 Acc: 0.9124 | Val Loss: 0.2465 Acc: 0.9052\n",
      "Epoch 023 | Train Loss: 0.2046 Acc: 0.9228 | Val Loss: 0.2490 Acc: 0.9028\n",
      "Epoch 024 | Train Loss: 0.1958 Acc: 0.9227 | Val Loss: 0.2176 Acc: 0.9191\n",
      "Epoch 025 | Train Loss: 0.1869 Acc: 0.9277 | Val Loss: 0.2162 Acc: 0.9130\n",
      "Epoch 026 | Train Loss: 0.1764 Acc: 0.9301 | Val Loss: 0.2268 Acc: 0.9161\n",
      "Epoch 027 | Train Loss: 0.1687 Acc: 0.9342 | Val Loss: 0.2134 Acc: 0.9112\n",
      "Epoch 028 | Train Loss: 0.1614 Acc: 0.9355 | Val Loss: 0.2105 Acc: 0.9197\n",
      "Epoch 029 | Train Loss: 0.1500 Acc: 0.9414 | Val Loss: 0.1912 Acc: 0.9318\n",
      "Epoch 030 | Train Loss: 0.1515 Acc: 0.9408 | Val Loss: 0.2056 Acc: 0.9191\n",
      "Epoch 031 | Train Loss: 0.1428 Acc: 0.9437 | Val Loss: 0.2197 Acc: 0.9167\n",
      "Epoch 032 | Train Loss: 0.1338 Acc: 0.9487 | Val Loss: 0.2297 Acc: 0.9118\n",
      "Epoch 033 | Train Loss: 0.1319 Acc: 0.9502 | Val Loss: 0.1856 Acc: 0.9306\n",
      "Epoch 034 | Train Loss: 0.1221 Acc: 0.9506 | Val Loss: 0.1831 Acc: 0.9312\n",
      "Epoch 035 | Train Loss: 0.1210 Acc: 0.9532 | Val Loss: 0.2039 Acc: 0.9233\n",
      "Epoch 036 | Train Loss: 0.1160 Acc: 0.9552 | Val Loss: 0.2190 Acc: 0.9185\n",
      "Epoch 037 | Train Loss: 0.1086 Acc: 0.9579 | Val Loss: 0.1900 Acc: 0.9372\n",
      "Epoch 038 | Train Loss: 0.1062 Acc: 0.9603 | Val Loss: 0.2204 Acc: 0.9269\n",
      "Epoch 039 | Train Loss: 0.1108 Acc: 0.9571 | Val Loss: 0.1614 Acc: 0.9336\n",
      "Epoch 040 | Train Loss: 0.1089 Acc: 0.9621 | Val Loss: 0.1723 Acc: 0.9348\n",
      "Epoch 041 | Train Loss: 0.0946 Acc: 0.9636 | Val Loss: 0.1813 Acc: 0.9378\n",
      "Epoch 042 | Train Loss: 0.0949 Acc: 0.9610 | Val Loss: 0.1760 Acc: 0.9348\n",
      "Epoch 043 | Train Loss: 0.0895 Acc: 0.9641 | Val Loss: 0.1850 Acc: 0.9384\n",
      "Epoch 044 | Train Loss: 0.0808 Acc: 0.9697 | Val Loss: 0.1735 Acc: 0.9432\n",
      "Epoch 045 | Train Loss: 0.0882 Acc: 0.9683 | Val Loss: 0.1439 Acc: 0.9517\n",
      "Epoch 046 | Train Loss: 0.0849 Acc: 0.9690 | Val Loss: 0.1589 Acc: 0.9457\n",
      "Epoch 047 | Train Loss: 0.0781 Acc: 0.9704 | Val Loss: 0.2123 Acc: 0.9366\n",
      "Epoch 048 | Train Loss: 0.0902 Acc: 0.9680 | Val Loss: 0.1621 Acc: 0.9432\n",
      "Epoch 049 | Train Loss: 0.0806 Acc: 0.9698 | Val Loss: 0.1715 Acc: 0.9390\n",
      "Epoch 050 | Train Loss: 0.0844 Acc: 0.9698 | Val Loss: 0.1563 Acc: 0.9408\n",
      "Epoch 051 | Train Loss: 0.0719 Acc: 0.9743 | Val Loss: 0.1982 Acc: 0.9360\n",
      "Epoch 052 | Train Loss: 0.0778 Acc: 0.9719 | Val Loss: 0.1617 Acc: 0.9499\n",
      "Epoch 053 | Train Loss: 0.0801 Acc: 0.9712 | Val Loss: 0.1418 Acc: 0.9444\n",
      "Epoch 054 | Train Loss: 0.0679 Acc: 0.9739 | Val Loss: 0.1688 Acc: 0.9444\n",
      "Epoch 055 | Train Loss: 0.0647 Acc: 0.9763 | Val Loss: 0.1672 Acc: 0.9426\n",
      "Epoch 056 | Train Loss: 0.0693 Acc: 0.9757 | Val Loss: 0.1541 Acc: 0.9499\n",
      "Epoch 057 | Train Loss: 0.0726 Acc: 0.9718 | Val Loss: 0.1699 Acc: 0.9450\n",
      "Epoch 058 | Train Loss: 0.0699 Acc: 0.9734 | Val Loss: 0.1454 Acc: 0.9493\n",
      "Epoch 059 | Train Loss: 0.0615 Acc: 0.9754 | Val Loss: 0.1568 Acc: 0.9499\n",
      "Epoch 060 | Train Loss: 0.0604 Acc: 0.9796 | Val Loss: 0.1604 Acc: 0.9487\n",
      "Epoch 001 | Train Loss: 0.6775 Acc: 0.5849 | Val Loss: 0.6795 Acc: 0.5755\n",
      "Epoch 002 | Train Loss: 0.6659 Acc: 0.5991 | Val Loss: 0.6570 Acc: 0.6093\n",
      "Epoch 003 | Train Loss: 0.6465 Acc: 0.6307 | Val Loss: 0.6285 Acc: 0.6582\n",
      "Epoch 004 | Train Loss: 0.6023 Acc: 0.6862 | Val Loss: 0.5963 Acc: 0.6920\n",
      "Epoch 005 | Train Loss: 0.5796 Acc: 0.7134 | Val Loss: 0.5915 Acc: 0.6914\n",
      "Epoch 006 | Train Loss: 0.5641 Acc: 0.7222 | Val Loss: 0.5907 Acc: 0.7095\n",
      "Epoch 007 | Train Loss: 0.5469 Acc: 0.7279 | Val Loss: 0.5470 Acc: 0.7264\n",
      "Epoch 008 | Train Loss: 0.5250 Acc: 0.7465 | Val Loss: 0.5263 Acc: 0.7446\n",
      "Epoch 009 | Train Loss: 0.5037 Acc: 0.7610 | Val Loss: 0.5273 Acc: 0.7403\n",
      "Epoch 010 | Train Loss: 0.4961 Acc: 0.7586 | Val Loss: 0.5105 Acc: 0.7530\n",
      "Epoch 011 | Train Loss: 0.4687 Acc: 0.7799 | Val Loss: 0.4858 Acc: 0.7597\n",
      "Epoch 012 | Train Loss: 0.4581 Acc: 0.7761 | Val Loss: 0.4611 Acc: 0.7754\n",
      "Epoch 013 | Train Loss: 0.4329 Acc: 0.7954 | Val Loss: 0.4612 Acc: 0.7699\n",
      "Epoch 014 | Train Loss: 0.4233 Acc: 0.8033 | Val Loss: 0.4501 Acc: 0.7820\n",
      "Epoch 015 | Train Loss: 0.3962 Acc: 0.8214 | Val Loss: 0.4168 Acc: 0.8068\n",
      "Epoch 016 | Train Loss: 0.3863 Acc: 0.8252 | Val Loss: 0.3992 Acc: 0.8110\n",
      "Epoch 017 | Train Loss: 0.3645 Acc: 0.8383 | Val Loss: 0.4254 Acc: 0.8013\n",
      "Epoch 018 | Train Loss: 0.3421 Acc: 0.8483 | Val Loss: 0.3561 Acc: 0.8436\n",
      "Epoch 019 | Train Loss: 0.3323 Acc: 0.8513 | Val Loss: 0.3553 Acc: 0.8418\n",
      "Epoch 020 | Train Loss: 0.3177 Acc: 0.8591 | Val Loss: 0.3101 Acc: 0.8605\n",
      "Epoch 021 | Train Loss: 0.2891 Acc: 0.8751 | Val Loss: 0.3088 Acc: 0.8690\n",
      "Epoch 022 | Train Loss: 0.2810 Acc: 0.8834 | Val Loss: 0.2869 Acc: 0.8835\n",
      "Epoch 023 | Train Loss: 0.2548 Acc: 0.8922 | Val Loss: 0.2717 Acc: 0.8816\n",
      "Epoch 024 | Train Loss: 0.2388 Acc: 0.8994 | Val Loss: 0.2788 Acc: 0.8853\n",
      "Epoch 025 | Train Loss: 0.2299 Acc: 0.9014 | Val Loss: 0.2606 Acc: 0.8998\n",
      "Epoch 026 | Train Loss: 0.2173 Acc: 0.9115 | Val Loss: 0.2746 Acc: 0.8883\n",
      "Epoch 027 | Train Loss: 0.2122 Acc: 0.9144 | Val Loss: 0.2789 Acc: 0.8889\n",
      "Epoch 028 | Train Loss: 0.2029 Acc: 0.9173 | Val Loss: 0.2411 Acc: 0.8998\n",
      "Epoch 029 | Train Loss: 0.1939 Acc: 0.9207 | Val Loss: 0.2108 Acc: 0.9191\n",
      "Epoch 030 | Train Loss: 0.1845 Acc: 0.9242 | Val Loss: 0.1965 Acc: 0.9251\n",
      "Epoch 031 | Train Loss: 0.1790 Acc: 0.9301 | Val Loss: 0.2418 Acc: 0.9076\n",
      "Epoch 032 | Train Loss: 0.1828 Acc: 0.9272 | Val Loss: 0.2032 Acc: 0.9179\n",
      "Epoch 033 | Train Loss: 0.1638 Acc: 0.9321 | Val Loss: 0.2100 Acc: 0.9191\n",
      "Epoch 034 | Train Loss: 0.1674 Acc: 0.9334 | Val Loss: 0.2205 Acc: 0.9215\n",
      "Epoch 035 | Train Loss: 0.1535 Acc: 0.9393 | Val Loss: 0.2039 Acc: 0.9221\n",
      "Epoch 036 | Train Loss: 0.1609 Acc: 0.9366 | Val Loss: 0.2029 Acc: 0.9269\n",
      "Epoch 037 | Train Loss: 0.1408 Acc: 0.9469 | Val Loss: 0.2118 Acc: 0.9191\n",
      "Epoch 038 | Train Loss: 0.1252 Acc: 0.9502 | Val Loss: 0.1795 Acc: 0.9348\n",
      "Epoch 039 | Train Loss: 0.1394 Acc: 0.9472 | Val Loss: 0.2124 Acc: 0.9130\n",
      "Epoch 040 | Train Loss: 0.1324 Acc: 0.9490 | Val Loss: 0.2613 Acc: 0.9034\n",
      "Epoch 041 | Train Loss: 0.1381 Acc: 0.9487 | Val Loss: 0.1901 Acc: 0.9221\n",
      "Epoch 042 | Train Loss: 0.1137 Acc: 0.9571 | Val Loss: 0.1839 Acc: 0.9348\n",
      "Epoch 043 | Train Loss: 0.1158 Acc: 0.9574 | Val Loss: 0.2088 Acc: 0.9245\n",
      "Epoch 044 | Train Loss: 0.1255 Acc: 0.9509 | Val Loss: 0.1870 Acc: 0.9287\n",
      "Epoch 045 | Train Loss: 0.1045 Acc: 0.9594 | Val Loss: 0.1923 Acc: 0.9281\n",
      "Epoch 046 | Train Loss: 0.1098 Acc: 0.9601 | Val Loss: 0.1789 Acc: 0.9330\n",
      "Epoch 047 | Train Loss: 0.1084 Acc: 0.9591 | Val Loss: 0.1816 Acc: 0.9318\n",
      "Epoch 048 | Train Loss: 0.1184 Acc: 0.9561 | Val Loss: 0.1543 Acc: 0.9408\n",
      "Epoch 049 | Train Loss: 0.0912 Acc: 0.9665 | Val Loss: 0.1833 Acc: 0.9348\n",
      "Epoch 050 | Train Loss: 0.1033 Acc: 0.9610 | Val Loss: 0.1517 Acc: 0.9450\n",
      "Epoch 051 | Train Loss: 0.0928 Acc: 0.9648 | Val Loss: 0.1513 Acc: 0.9444\n",
      "Epoch 052 | Train Loss: 0.0954 Acc: 0.9650 | Val Loss: 0.1583 Acc: 0.9438\n",
      "Epoch 053 | Train Loss: 0.0920 Acc: 0.9654 | Val Loss: 0.1506 Acc: 0.9432\n",
      "Epoch 054 | Train Loss: 0.0873 Acc: 0.9672 | Val Loss: 0.1854 Acc: 0.9372\n",
      "Epoch 055 | Train Loss: 0.0849 Acc: 0.9687 | Val Loss: 0.2019 Acc: 0.9263\n",
      "Epoch 056 | Train Loss: 0.0957 Acc: 0.9660 | Val Loss: 0.1627 Acc: 0.9438\n",
      "Epoch 057 | Train Loss: 0.0908 Acc: 0.9672 | Val Loss: 0.1715 Acc: 0.9396\n",
      "Epoch 058 | Train Loss: 0.0799 Acc: 0.9727 | Val Loss: 0.2005 Acc: 0.9336\n",
      "Epoch 059 | Train Loss: 0.0830 Acc: 0.9692 | Val Loss: 0.1502 Acc: 0.9517\n",
      "Epoch 060 | Train Loss: 0.0832 Acc: 0.9686 | Val Loss: 0.1647 Acc: 0.9438\n",
      "Epoch 001 | Train Loss: 0.6791 Acc: 0.5795 | Val Loss: 0.6789 Acc: 0.5827\n",
      "Epoch 002 | Train Loss: 0.6575 Acc: 0.6094 | Val Loss: 0.6382 Acc: 0.6238\n",
      "Epoch 003 | Train Loss: 0.6126 Acc: 0.6781 | Val Loss: 0.6000 Acc: 0.6872\n",
      "Epoch 004 | Train Loss: 0.5645 Acc: 0.7149 | Val Loss: 0.5505 Acc: 0.7186\n",
      "Epoch 005 | Train Loss: 0.5424 Acc: 0.7314 | Val Loss: 0.5309 Acc: 0.7313\n",
      "Epoch 006 | Train Loss: 0.5132 Acc: 0.7524 | Val Loss: 0.5681 Acc: 0.7144\n",
      "Epoch 007 | Train Loss: 0.4827 Acc: 0.7687 | Val Loss: 0.5007 Acc: 0.7518\n",
      "Epoch 008 | Train Loss: 0.4657 Acc: 0.7797 | Val Loss: 0.4523 Acc: 0.7766\n",
      "Epoch 009 | Train Loss: 0.4369 Acc: 0.7975 | Val Loss: 0.4515 Acc: 0.7838\n",
      "Epoch 010 | Train Loss: 0.4080 Acc: 0.8117 | Val Loss: 0.3965 Acc: 0.8176\n",
      "Epoch 011 | Train Loss: 0.3749 Acc: 0.8268 | Val Loss: 0.3807 Acc: 0.8291\n",
      "Epoch 012 | Train Loss: 0.3466 Acc: 0.8474 | Val Loss: 0.3705 Acc: 0.8333\n",
      "Epoch 013 | Train Loss: 0.3063 Acc: 0.8692 | Val Loss: 0.2877 Acc: 0.8780\n",
      "Epoch 014 | Train Loss: 0.2914 Acc: 0.8744 | Val Loss: 0.2919 Acc: 0.8744\n",
      "Epoch 015 | Train Loss: 0.2649 Acc: 0.8923 | Val Loss: 0.2606 Acc: 0.8907\n",
      "Epoch 016 | Train Loss: 0.2370 Acc: 0.9044 | Val Loss: 0.2527 Acc: 0.8859\n",
      "Epoch 017 | Train Loss: 0.2215 Acc: 0.9055 | Val Loss: 0.2370 Acc: 0.9088\n",
      "Epoch 018 | Train Loss: 0.2044 Acc: 0.9212 | Val Loss: 0.2627 Acc: 0.8931\n",
      "Epoch 019 | Train Loss: 0.1965 Acc: 0.9219 | Val Loss: 0.2270 Acc: 0.9040\n",
      "Epoch 020 | Train Loss: 0.1769 Acc: 0.9289 | Val Loss: 0.2244 Acc: 0.9040\n",
      "Epoch 021 | Train Loss: 0.1639 Acc: 0.9366 | Val Loss: 0.1845 Acc: 0.9324\n",
      "Epoch 022 | Train Loss: 0.1530 Acc: 0.9388 | Val Loss: 0.1941 Acc: 0.9287\n",
      "Epoch 023 | Train Loss: 0.1437 Acc: 0.9425 | Val Loss: 0.1972 Acc: 0.9185\n",
      "Epoch 024 | Train Loss: 0.1315 Acc: 0.9487 | Val Loss: 0.1889 Acc: 0.9300\n",
      "Epoch 025 | Train Loss: 0.1295 Acc: 0.9524 | Val Loss: 0.1837 Acc: 0.9293\n",
      "Epoch 026 | Train Loss: 0.1317 Acc: 0.9479 | Val Loss: 0.2033 Acc: 0.9167\n",
      "Epoch 027 | Train Loss: 0.1167 Acc: 0.9536 | Val Loss: 0.1680 Acc: 0.9263\n",
      "Epoch 028 | Train Loss: 0.0974 Acc: 0.9647 | Val Loss: 0.1556 Acc: 0.9372\n",
      "Epoch 029 | Train Loss: 0.1053 Acc: 0.9598 | Val Loss: 0.1819 Acc: 0.9348\n",
      "Epoch 030 | Train Loss: 0.0970 Acc: 0.9641 | Val Loss: 0.2193 Acc: 0.9227\n",
      "Epoch 031 | Train Loss: 0.0901 Acc: 0.9674 | Val Loss: 0.1456 Acc: 0.9481\n",
      "Epoch 032 | Train Loss: 0.0822 Acc: 0.9677 | Val Loss: 0.1765 Acc: 0.9336\n",
      "Epoch 033 | Train Loss: 0.0879 Acc: 0.9642 | Val Loss: 0.1534 Acc: 0.9426\n",
      "Epoch 034 | Train Loss: 0.0704 Acc: 0.9748 | Val Loss: 0.1837 Acc: 0.9384\n",
      "Epoch 035 | Train Loss: 0.0870 Acc: 0.9690 | Val Loss: 0.1769 Acc: 0.9390\n",
      "Epoch 036 | Train Loss: 0.0707 Acc: 0.9733 | Val Loss: 0.1514 Acc: 0.9432\n",
      "Epoch 037 | Train Loss: 0.0708 Acc: 0.9734 | Val Loss: 0.1687 Acc: 0.9396\n",
      "Epoch 038 | Train Loss: 0.0747 Acc: 0.9745 | Val Loss: 0.1576 Acc: 0.9444\n",
      "Epoch 039 | Train Loss: 0.0642 Acc: 0.9752 | Val Loss: 0.1510 Acc: 0.9487\n",
      "Epoch 040 | Train Loss: 0.0676 Acc: 0.9749 | Val Loss: 0.1606 Acc: 0.9426\n",
      "Epoch 041 | Train Loss: 0.0543 Acc: 0.9790 | Val Loss: 0.2009 Acc: 0.9330\n",
      "Early stopping triggered.\n",
      "Epoch 001 | Train Loss: 0.6790 Acc: 0.5795 | Val Loss: 0.6755 Acc: 0.5888\n",
      "Epoch 002 | Train Loss: 0.6708 Acc: 0.5955 | Val Loss: 0.6659 Acc: 0.5894\n",
      "Epoch 003 | Train Loss: 0.6316 Acc: 0.6502 | Val Loss: 0.6441 Acc: 0.6570\n",
      "Epoch 004 | Train Loss: 0.5935 Acc: 0.6918 | Val Loss: 0.5703 Acc: 0.7107\n",
      "Epoch 005 | Train Loss: 0.5705 Acc: 0.7158 | Val Loss: 0.5639 Acc: 0.7186\n",
      "Epoch 006 | Train Loss: 0.5382 Acc: 0.7334 | Val Loss: 0.5397 Acc: 0.7234\n",
      "Epoch 007 | Train Loss: 0.5319 Acc: 0.7362 | Val Loss: 0.5247 Acc: 0.7307\n",
      "Epoch 008 | Train Loss: 0.4940 Acc: 0.7663 | Val Loss: 0.4742 Acc: 0.7699\n",
      "Epoch 009 | Train Loss: 0.4712 Acc: 0.7787 | Val Loss: 0.4603 Acc: 0.7868\n",
      "Epoch 010 | Train Loss: 0.4366 Acc: 0.7922 | Val Loss: 0.4449 Acc: 0.7850\n",
      "Epoch 011 | Train Loss: 0.4325 Acc: 0.7992 | Val Loss: 0.4209 Acc: 0.8007\n",
      "Epoch 012 | Train Loss: 0.3889 Acc: 0.8211 | Val Loss: 0.4131 Acc: 0.8134\n",
      "Epoch 013 | Train Loss: 0.3797 Acc: 0.8300 | Val Loss: 0.3686 Acc: 0.8351\n",
      "Epoch 014 | Train Loss: 0.3551 Acc: 0.8440 | Val Loss: 0.3443 Acc: 0.8400\n",
      "Epoch 015 | Train Loss: 0.3426 Acc: 0.8510 | Val Loss: 0.3311 Acc: 0.8551\n",
      "Epoch 016 | Train Loss: 0.3079 Acc: 0.8724 | Val Loss: 0.2852 Acc: 0.8786\n",
      "Epoch 017 | Train Loss: 0.2925 Acc: 0.8748 | Val Loss: 0.3344 Acc: 0.8496\n",
      "Epoch 018 | Train Loss: 0.2804 Acc: 0.8813 | Val Loss: 0.2854 Acc: 0.8895\n",
      "Epoch 019 | Train Loss: 0.2554 Acc: 0.8963 | Val Loss: 0.2369 Acc: 0.9034\n",
      "Epoch 020 | Train Loss: 0.2456 Acc: 0.9000 | Val Loss: 0.2305 Acc: 0.9076\n",
      "Epoch 021 | Train Loss: 0.2289 Acc: 0.9037 | Val Loss: 0.2501 Acc: 0.8967\n",
      "Epoch 022 | Train Loss: 0.2106 Acc: 0.9144 | Val Loss: 0.2386 Acc: 0.8979\n",
      "Epoch 023 | Train Loss: 0.2061 Acc: 0.9133 | Val Loss: 0.2059 Acc: 0.9209\n",
      "Epoch 024 | Train Loss: 0.1896 Acc: 0.9236 | Val Loss: 0.2089 Acc: 0.9130\n",
      "Epoch 025 | Train Loss: 0.1730 Acc: 0.9307 | Val Loss: 0.2089 Acc: 0.9100\n",
      "Epoch 026 | Train Loss: 0.1643 Acc: 0.9346 | Val Loss: 0.1911 Acc: 0.9227\n",
      "Epoch 027 | Train Loss: 0.1603 Acc: 0.9337 | Val Loss: 0.1893 Acc: 0.9251\n",
      "Epoch 028 | Train Loss: 0.1440 Acc: 0.9431 | Val Loss: 0.2007 Acc: 0.9215\n",
      "Epoch 029 | Train Loss: 0.1465 Acc: 0.9422 | Val Loss: 0.1922 Acc: 0.9306\n",
      "Epoch 030 | Train Loss: 0.1409 Acc: 0.9482 | Val Loss: 0.2572 Acc: 0.8979\n",
      "Epoch 031 | Train Loss: 0.1415 Acc: 0.9456 | Val Loss: 0.1565 Acc: 0.9378\n",
      "Epoch 032 | Train Loss: 0.1353 Acc: 0.9482 | Val Loss: 0.1495 Acc: 0.9463\n",
      "Epoch 033 | Train Loss: 0.1139 Acc: 0.9580 | Val Loss: 0.2067 Acc: 0.9191\n",
      "Epoch 034 | Train Loss: 0.1271 Acc: 0.9523 | Val Loss: 0.1355 Acc: 0.9505\n",
      "Epoch 035 | Train Loss: 0.1132 Acc: 0.9571 | Val Loss: 0.1597 Acc: 0.9402\n",
      "Epoch 036 | Train Loss: 0.1096 Acc: 0.9598 | Val Loss: 0.1602 Acc: 0.9390\n",
      "Epoch 037 | Train Loss: 0.1157 Acc: 0.9550 | Val Loss: 0.1555 Acc: 0.9463\n",
      "Epoch 038 | Train Loss: 0.1106 Acc: 0.9600 | Val Loss: 0.1621 Acc: 0.9306\n",
      "Epoch 039 | Train Loss: 0.1050 Acc: 0.9601 | Val Loss: 0.1568 Acc: 0.9390\n",
      "Epoch 040 | Train Loss: 0.0958 Acc: 0.9621 | Val Loss: 0.1399 Acc: 0.9499\n",
      "Epoch 041 | Train Loss: 0.0886 Acc: 0.9653 | Val Loss: 0.1503 Acc: 0.9469\n",
      "Epoch 042 | Train Loss: 0.0927 Acc: 0.9647 | Val Loss: 0.1465 Acc: 0.9432\n",
      "Epoch 043 | Train Loss: 0.0875 Acc: 0.9677 | Val Loss: 0.1272 Acc: 0.9505\n",
      "Epoch 044 | Train Loss: 0.0931 Acc: 0.9650 | Val Loss: 0.1390 Acc: 0.9499\n",
      "Epoch 045 | Train Loss: 0.0687 Acc: 0.9743 | Val Loss: 0.1470 Acc: 0.9511\n",
      "Epoch 046 | Train Loss: 0.0822 Acc: 0.9700 | Val Loss: 0.1319 Acc: 0.9541\n",
      "Epoch 047 | Train Loss: 0.0747 Acc: 0.9730 | Val Loss: 0.1280 Acc: 0.9541\n",
      "Epoch 048 | Train Loss: 0.0795 Acc: 0.9715 | Val Loss: 0.1392 Acc: 0.9493\n",
      "Epoch 049 | Train Loss: 0.0710 Acc: 0.9736 | Val Loss: 0.1422 Acc: 0.9505\n",
      "Epoch 050 | Train Loss: 0.0773 Acc: 0.9707 | Val Loss: 0.1577 Acc: 0.9420\n",
      "Epoch 051 | Train Loss: 0.0723 Acc: 0.9733 | Val Loss: 0.1244 Acc: 0.9614\n",
      "Epoch 052 | Train Loss: 0.0752 Acc: 0.9728 | Val Loss: 0.1236 Acc: 0.9607\n",
      "Epoch 053 | Train Loss: 0.0683 Acc: 0.9770 | Val Loss: 0.1409 Acc: 0.9547\n",
      "Epoch 054 | Train Loss: 0.0663 Acc: 0.9758 | Val Loss: 0.1194 Acc: 0.9535\n",
      "Epoch 055 | Train Loss: 0.0650 Acc: 0.9778 | Val Loss: 0.1426 Acc: 0.9469\n",
      "Epoch 056 | Train Loss: 0.0690 Acc: 0.9742 | Val Loss: 0.1663 Acc: 0.9372\n",
      "Epoch 057 | Train Loss: 0.0660 Acc: 0.9761 | Val Loss: 0.1210 Acc: 0.9626\n",
      "Epoch 058 | Train Loss: 0.0544 Acc: 0.9802 | Val Loss: 0.1420 Acc: 0.9541\n",
      "Epoch 059 | Train Loss: 0.0623 Acc: 0.9770 | Val Loss: 0.1559 Acc: 0.9463\n",
      "Epoch 060 | Train Loss: 0.0564 Acc: 0.9810 | Val Loss: 0.1282 Acc: 0.9523\n",
      "Epoch 001 | Train Loss: 0.6818 Acc: 0.5721 | Val Loss: 0.6782 Acc: 0.5821\n",
      "Epoch 002 | Train Loss: 0.6710 Acc: 0.5973 | Val Loss: 0.6593 Acc: 0.6075\n",
      "Epoch 003 | Train Loss: 0.6529 Acc: 0.6191 | Val Loss: 0.6281 Acc: 0.6564\n",
      "Epoch 004 | Train Loss: 0.6148 Acc: 0.6757 | Val Loss: 0.5902 Acc: 0.6981\n",
      "Epoch 005 | Train Loss: 0.5774 Acc: 0.7121 | Val Loss: 0.5555 Acc: 0.7132\n",
      "Epoch 006 | Train Loss: 0.5438 Acc: 0.7350 | Val Loss: 0.5426 Acc: 0.7240\n",
      "Epoch 007 | Train Loss: 0.5248 Acc: 0.7441 | Val Loss: 0.5211 Acc: 0.7367\n",
      "Epoch 008 | Train Loss: 0.5055 Acc: 0.7557 | Val Loss: 0.4866 Acc: 0.7621\n",
      "Epoch 009 | Train Loss: 0.4744 Acc: 0.7737 | Val Loss: 0.4831 Acc: 0.7554\n",
      "Epoch 010 | Train Loss: 0.4544 Acc: 0.7915 | Val Loss: 0.5155 Acc: 0.7476\n",
      "Epoch 011 | Train Loss: 0.4407 Acc: 0.7937 | Val Loss: 0.4501 Acc: 0.7760\n",
      "Epoch 012 | Train Loss: 0.4213 Acc: 0.8061 | Val Loss: 0.4122 Acc: 0.8104\n",
      "Epoch 013 | Train Loss: 0.3966 Acc: 0.8224 | Val Loss: 0.4066 Acc: 0.8043\n",
      "Epoch 014 | Train Loss: 0.3757 Acc: 0.8324 | Val Loss: 0.4150 Acc: 0.8068\n",
      "Epoch 015 | Train Loss: 0.3498 Acc: 0.8489 | Val Loss: 0.3279 Acc: 0.8581\n",
      "Epoch 016 | Train Loss: 0.3473 Acc: 0.8483 | Val Loss: 0.3165 Acc: 0.8599\n",
      "Epoch 017 | Train Loss: 0.3193 Acc: 0.8602 | Val Loss: 0.3365 Acc: 0.8430\n",
      "Epoch 018 | Train Loss: 0.3030 Acc: 0.8726 | Val Loss: 0.2909 Acc: 0.8786\n",
      "Epoch 019 | Train Loss: 0.2869 Acc: 0.8789 | Val Loss: 0.3227 Acc: 0.8575\n",
      "Epoch 020 | Train Loss: 0.2687 Acc: 0.8854 | Val Loss: 0.2871 Acc: 0.8786\n",
      "Epoch 021 | Train Loss: 0.2608 Acc: 0.8895 | Val Loss: 0.2713 Acc: 0.8829\n",
      "Epoch 022 | Train Loss: 0.2360 Acc: 0.9091 | Val Loss: 0.2757 Acc: 0.8847\n",
      "Epoch 023 | Train Loss: 0.2373 Acc: 0.9016 | Val Loss: 0.2239 Acc: 0.9185\n",
      "Epoch 024 | Train Loss: 0.2299 Acc: 0.9105 | Val Loss: 0.2195 Acc: 0.9167\n",
      "Epoch 025 | Train Loss: 0.2088 Acc: 0.9173 | Val Loss: 0.2183 Acc: 0.9149\n",
      "Epoch 026 | Train Loss: 0.2023 Acc: 0.9194 | Val Loss: 0.2111 Acc: 0.9239\n",
      "Epoch 027 | Train Loss: 0.1900 Acc: 0.9242 | Val Loss: 0.2048 Acc: 0.9136\n",
      "Epoch 028 | Train Loss: 0.1854 Acc: 0.9257 | Val Loss: 0.2368 Acc: 0.9040\n",
      "Epoch 029 | Train Loss: 0.1745 Acc: 0.9315 | Val Loss: 0.2156 Acc: 0.9233\n",
      "Epoch 030 | Train Loss: 0.1763 Acc: 0.9311 | Val Loss: 0.1996 Acc: 0.9306\n",
      "Epoch 031 | Train Loss: 0.1796 Acc: 0.9319 | Val Loss: 0.1877 Acc: 0.9233\n",
      "Epoch 032 | Train Loss: 0.1523 Acc: 0.9413 | Val Loss: 0.1662 Acc: 0.9330\n",
      "Epoch 033 | Train Loss: 0.1496 Acc: 0.9382 | Val Loss: 0.3496 Acc: 0.8756\n",
      "Epoch 034 | Train Loss: 0.1426 Acc: 0.9452 | Val Loss: 0.1707 Acc: 0.9318\n",
      "Epoch 035 | Train Loss: 0.1329 Acc: 0.9506 | Val Loss: 0.1773 Acc: 0.9360\n",
      "Epoch 036 | Train Loss: 0.1317 Acc: 0.9505 | Val Loss: 0.1951 Acc: 0.9281\n",
      "Epoch 037 | Train Loss: 0.1221 Acc: 0.9511 | Val Loss: 0.1804 Acc: 0.9366\n",
      "Epoch 038 | Train Loss: 0.1378 Acc: 0.9494 | Val Loss: 0.2022 Acc: 0.9251\n",
      "Epoch 039 | Train Loss: 0.1243 Acc: 0.9538 | Val Loss: 0.1507 Acc: 0.9481\n",
      "Epoch 040 | Train Loss: 0.1115 Acc: 0.9604 | Val Loss: 0.1607 Acc: 0.9408\n",
      "Epoch 041 | Train Loss: 0.1147 Acc: 0.9582 | Val Loss: 0.1601 Acc: 0.9360\n",
      "Epoch 042 | Train Loss: 0.1210 Acc: 0.9552 | Val Loss: 0.1672 Acc: 0.9378\n",
      "Epoch 043 | Train Loss: 0.1170 Acc: 0.9562 | Val Loss: 0.1712 Acc: 0.9336\n",
      "Epoch 044 | Train Loss: 0.1174 Acc: 0.9576 | Val Loss: 0.1738 Acc: 0.9360\n",
      "Epoch 045 | Train Loss: 0.0962 Acc: 0.9630 | Val Loss: 0.1989 Acc: 0.9275\n",
      "Epoch 046 | Train Loss: 0.1083 Acc: 0.9598 | Val Loss: 0.1516 Acc: 0.9438\n",
      "Epoch 047 | Train Loss: 0.0986 Acc: 0.9618 | Val Loss: 0.1688 Acc: 0.9384\n",
      "Epoch 048 | Train Loss: 0.0993 Acc: 0.9618 | Val Loss: 0.2038 Acc: 0.9281\n",
      "Epoch 049 | Train Loss: 0.0979 Acc: 0.9627 | Val Loss: 0.1680 Acc: 0.9330\n",
      "Early stopping triggered.\n",
      "Epoch 001 | Train Loss: 0.6810 Acc: 0.5799 | Val Loss: 0.6764 Acc: 0.5876\n",
      "Epoch 002 | Train Loss: 0.6748 Acc: 0.5922 | Val Loss: 0.6767 Acc: 0.5960\n",
      "Epoch 003 | Train Loss: 0.6686 Acc: 0.6027 | Val Loss: 0.6611 Acc: 0.6051\n",
      "Epoch 004 | Train Loss: 0.6327 Acc: 0.6509 | Val Loss: 0.5942 Acc: 0.7029\n",
      "Epoch 005 | Train Loss: 0.5653 Acc: 0.7186 | Val Loss: 0.5503 Acc: 0.7150\n",
      "Epoch 006 | Train Loss: 0.5191 Acc: 0.7497 | Val Loss: 0.5424 Acc: 0.7379\n",
      "Epoch 007 | Train Loss: 0.5029 Acc: 0.7590 | Val Loss: 0.4925 Acc: 0.7542\n",
      "Epoch 008 | Train Loss: 0.4577 Acc: 0.7891 | Val Loss: 0.4599 Acc: 0.7899\n",
      "Epoch 009 | Train Loss: 0.4413 Acc: 0.8001 | Val Loss: 0.4338 Acc: 0.7911\n",
      "Epoch 010 | Train Loss: 0.4014 Acc: 0.8218 | Val Loss: 0.4476 Acc: 0.8007\n",
      "Epoch 011 | Train Loss: 0.3746 Acc: 0.8295 | Val Loss: 0.3717 Acc: 0.8182\n",
      "Epoch 012 | Train Loss: 0.3576 Acc: 0.8371 | Val Loss: 0.3547 Acc: 0.8370\n",
      "Epoch 013 | Train Loss: 0.3271 Acc: 0.8544 | Val Loss: 0.3101 Acc: 0.8641\n",
      "Epoch 014 | Train Loss: 0.3088 Acc: 0.8692 | Val Loss: 0.3096 Acc: 0.8551\n",
      "Epoch 015 | Train Loss: 0.2815 Acc: 0.8854 | Val Loss: 0.3120 Acc: 0.8665\n",
      "Epoch 016 | Train Loss: 0.2541 Acc: 0.8963 | Val Loss: 0.2859 Acc: 0.8708\n",
      "Epoch 017 | Train Loss: 0.2496 Acc: 0.8996 | Val Loss: 0.2699 Acc: 0.8883\n",
      "Epoch 018 | Train Loss: 0.2230 Acc: 0.9117 | Val Loss: 0.2598 Acc: 0.8865\n",
      "Epoch 019 | Train Loss: 0.2121 Acc: 0.9164 | Val Loss: 0.2342 Acc: 0.9058\n",
      "Epoch 020 | Train Loss: 0.1964 Acc: 0.9234 | Val Loss: 0.2333 Acc: 0.8979\n",
      "Epoch 021 | Train Loss: 0.1870 Acc: 0.9241 | Val Loss: 0.2379 Acc: 0.9088\n",
      "Epoch 022 | Train Loss: 0.1732 Acc: 0.9327 | Val Loss: 0.2134 Acc: 0.9130\n",
      "Epoch 023 | Train Loss: 0.1622 Acc: 0.9393 | Val Loss: 0.2510 Acc: 0.9064\n",
      "Epoch 024 | Train Loss: 0.1681 Acc: 0.9345 | Val Loss: 0.2147 Acc: 0.9112\n",
      "Epoch 025 | Train Loss: 0.1449 Acc: 0.9422 | Val Loss: 0.2091 Acc: 0.9167\n",
      "Epoch 026 | Train Loss: 0.1400 Acc: 0.9459 | Val Loss: 0.2168 Acc: 0.9179\n",
      "Epoch 027 | Train Loss: 0.1377 Acc: 0.9470 | Val Loss: 0.2402 Acc: 0.9203\n",
      "Epoch 028 | Train Loss: 0.1401 Acc: 0.9469 | Val Loss: 0.2263 Acc: 0.9094\n",
      "Epoch 029 | Train Loss: 0.1205 Acc: 0.9532 | Val Loss: 0.2081 Acc: 0.9221\n",
      "Epoch 030 | Train Loss: 0.1128 Acc: 0.9571 | Val Loss: 0.1752 Acc: 0.9372\n",
      "Epoch 031 | Train Loss: 0.1068 Acc: 0.9603 | Val Loss: 0.2077 Acc: 0.9281\n",
      "Epoch 032 | Train Loss: 0.1174 Acc: 0.9556 | Val Loss: 0.1831 Acc: 0.9293\n",
      "Epoch 033 | Train Loss: 0.1023 Acc: 0.9616 | Val Loss: 0.1857 Acc: 0.9287\n",
      "Epoch 034 | Train Loss: 0.0935 Acc: 0.9650 | Val Loss: 0.1791 Acc: 0.9366\n",
      "Epoch 035 | Train Loss: 0.0967 Acc: 0.9656 | Val Loss: 0.1972 Acc: 0.9263\n",
      "Epoch 036 | Train Loss: 0.0919 Acc: 0.9680 | Val Loss: 0.1704 Acc: 0.9426\n",
      "Epoch 037 | Train Loss: 0.0751 Acc: 0.9751 | Val Loss: 0.1853 Acc: 0.9360\n",
      "Epoch 038 | Train Loss: 0.0906 Acc: 0.9648 | Val Loss: 0.1869 Acc: 0.9306\n",
      "Epoch 039 | Train Loss: 0.0716 Acc: 0.9754 | Val Loss: 0.1941 Acc: 0.9354\n",
      "Epoch 040 | Train Loss: 0.0781 Acc: 0.9718 | Val Loss: 0.1905 Acc: 0.9384\n",
      "Epoch 041 | Train Loss: 0.0799 Acc: 0.9709 | Val Loss: 0.1878 Acc: 0.9342\n",
      "Epoch 042 | Train Loss: 0.0719 Acc: 0.9736 | Val Loss: 0.1836 Acc: 0.9342\n",
      "Epoch 043 | Train Loss: 0.0840 Acc: 0.9695 | Val Loss: 0.1871 Acc: 0.9390\n",
      "Epoch 044 | Train Loss: 0.0677 Acc: 0.9754 | Val Loss: 0.1729 Acc: 0.9372\n",
      "Epoch 045 | Train Loss: 0.0745 Acc: 0.9742 | Val Loss: 0.1752 Acc: 0.9342\n",
      "Epoch 046 | Train Loss: 0.0664 Acc: 0.9746 | Val Loss: 0.1951 Acc: 0.9360\n",
      "Early stopping triggered.\n",
      "Epoch 001 | Train Loss: 0.6836 Acc: 0.5730 | Val Loss: 0.6786 Acc: 0.5785\n",
      "Epoch 002 | Train Loss: 0.6753 Acc: 0.5917 | Val Loss: 0.6709 Acc: 0.5966\n",
      "Epoch 003 | Train Loss: 0.6625 Acc: 0.6127 | Val Loss: 0.6639 Acc: 0.6099\n",
      "Epoch 004 | Train Loss: 0.6343 Acc: 0.6515 | Val Loss: 0.6066 Acc: 0.6999\n",
      "Epoch 005 | Train Loss: 0.5874 Acc: 0.7095 | Val Loss: 0.5682 Acc: 0.7095\n",
      "Epoch 006 | Train Loss: 0.5607 Acc: 0.7275 | Val Loss: 0.5699 Acc: 0.7192\n",
      "Epoch 007 | Train Loss: 0.5476 Acc: 0.7406 | Val Loss: 0.5480 Acc: 0.7331\n",
      "Epoch 008 | Train Loss: 0.5429 Acc: 0.7400 | Val Loss: 0.5401 Acc: 0.7367\n",
      "Epoch 009 | Train Loss: 0.5277 Acc: 0.7497 | Val Loss: 0.5241 Acc: 0.7476\n",
      "Epoch 010 | Train Loss: 0.5073 Acc: 0.7593 | Val Loss: 0.5012 Acc: 0.7560\n",
      "Epoch 011 | Train Loss: 0.4938 Acc: 0.7685 | Val Loss: 0.4840 Acc: 0.7687\n",
      "Epoch 012 | Train Loss: 0.4738 Acc: 0.7761 | Val Loss: 0.4917 Acc: 0.7530\n",
      "Epoch 013 | Train Loss: 0.4642 Acc: 0.7845 | Val Loss: 0.5189 Acc: 0.7367\n",
      "Epoch 014 | Train Loss: 0.4532 Acc: 0.7847 | Val Loss: 0.4370 Acc: 0.7874\n",
      "Epoch 015 | Train Loss: 0.4227 Acc: 0.8049 | Val Loss: 0.4367 Acc: 0.7862\n",
      "Epoch 016 | Train Loss: 0.4220 Acc: 0.8060 | Val Loss: 0.4385 Acc: 0.7868\n",
      "Epoch 017 | Train Loss: 0.3993 Acc: 0.8188 | Val Loss: 0.3829 Acc: 0.8152\n",
      "Epoch 018 | Train Loss: 0.3760 Acc: 0.8335 | Val Loss: 0.3735 Acc: 0.8370\n",
      "Epoch 019 | Train Loss: 0.3486 Acc: 0.8424 | Val Loss: 0.3352 Acc: 0.8478\n",
      "Epoch 020 | Train Loss: 0.3314 Acc: 0.8567 | Val Loss: 0.3914 Acc: 0.8188\n",
      "Epoch 021 | Train Loss: 0.3120 Acc: 0.8664 | Val Loss: 0.3482 Acc: 0.8424\n",
      "Epoch 022 | Train Loss: 0.3143 Acc: 0.8655 | Val Loss: 0.3266 Acc: 0.8617\n",
      "Epoch 023 | Train Loss: 0.2850 Acc: 0.8806 | Val Loss: 0.2949 Acc: 0.8750\n",
      "Epoch 024 | Train Loss: 0.2690 Acc: 0.8886 | Val Loss: 0.2806 Acc: 0.8780\n",
      "Epoch 025 | Train Loss: 0.2693 Acc: 0.8905 | Val Loss: 0.3119 Acc: 0.8690\n",
      "Epoch 026 | Train Loss: 0.2536 Acc: 0.8960 | Val Loss: 0.2532 Acc: 0.8949\n",
      "Epoch 027 | Train Loss: 0.2453 Acc: 0.9032 | Val Loss: 0.2636 Acc: 0.8774\n",
      "Epoch 028 | Train Loss: 0.2419 Acc: 0.9016 | Val Loss: 0.2503 Acc: 0.8943\n",
      "Epoch 029 | Train Loss: 0.2602 Acc: 0.8946 | Val Loss: 0.2967 Acc: 0.8629\n",
      "Epoch 030 | Train Loss: 0.2198 Acc: 0.9151 | Val Loss: 0.2260 Acc: 0.9118\n",
      "Epoch 031 | Train Loss: 0.2052 Acc: 0.9188 | Val Loss: 0.2167 Acc: 0.9040\n",
      "Epoch 032 | Train Loss: 0.1971 Acc: 0.9219 | Val Loss: 0.2174 Acc: 0.9161\n",
      "Epoch 033 | Train Loss: 0.1898 Acc: 0.9228 | Val Loss: 0.2347 Acc: 0.9058\n",
      "Epoch 034 | Train Loss: 0.1785 Acc: 0.9290 | Val Loss: 0.2371 Acc: 0.8992\n",
      "Epoch 035 | Train Loss: 0.1771 Acc: 0.9318 | Val Loss: 0.1910 Acc: 0.9287\n",
      "Epoch 036 | Train Loss: 0.1713 Acc: 0.9304 | Val Loss: 0.1988 Acc: 0.9173\n",
      "Epoch 037 | Train Loss: 0.1674 Acc: 0.9346 | Val Loss: 0.2237 Acc: 0.9106\n",
      "Epoch 038 | Train Loss: 0.1774 Acc: 0.9336 | Val Loss: 0.1888 Acc: 0.9257\n",
      "Epoch 039 | Train Loss: 0.1499 Acc: 0.9428 | Val Loss: 0.1768 Acc: 0.9342\n",
      "Epoch 040 | Train Loss: 0.1567 Acc: 0.9390 | Val Loss: 0.2253 Acc: 0.9167\n",
      "Epoch 041 | Train Loss: 0.1407 Acc: 0.9473 | Val Loss: 0.1980 Acc: 0.9203\n",
      "Epoch 042 | Train Loss: 0.1339 Acc: 0.9473 | Val Loss: 0.2451 Acc: 0.9173\n",
      "Epoch 043 | Train Loss: 0.1341 Acc: 0.9502 | Val Loss: 0.2086 Acc: 0.9161\n",
      "Epoch 044 | Train Loss: 0.1413 Acc: 0.9488 | Val Loss: 0.1968 Acc: 0.9239\n",
      "Epoch 045 | Train Loss: 0.1313 Acc: 0.9499 | Val Loss: 0.1691 Acc: 0.9336\n",
      "Epoch 046 | Train Loss: 0.1278 Acc: 0.9538 | Val Loss: 0.1685 Acc: 0.9360\n",
      "Epoch 047 | Train Loss: 0.1317 Acc: 0.9511 | Val Loss: 0.2127 Acc: 0.9263\n",
      "Epoch 048 | Train Loss: 0.1301 Acc: 0.9552 | Val Loss: 0.2141 Acc: 0.9227\n",
      "Epoch 049 | Train Loss: 0.1237 Acc: 0.9553 | Val Loss: 0.1865 Acc: 0.9293\n",
      "Epoch 050 | Train Loss: 0.1237 Acc: 0.9524 | Val Loss: 0.1756 Acc: 0.9348\n",
      "Epoch 051 | Train Loss: 0.1083 Acc: 0.9603 | Val Loss: 0.1717 Acc: 0.9402\n",
      "Epoch 052 | Train Loss: 0.1136 Acc: 0.9585 | Val Loss: 0.1671 Acc: 0.9318\n",
      "Epoch 053 | Train Loss: 0.1068 Acc: 0.9616 | Val Loss: 0.1675 Acc: 0.9384\n",
      "Epoch 054 | Train Loss: 0.0961 Acc: 0.9662 | Val Loss: 0.1699 Acc: 0.9426\n",
      "Epoch 055 | Train Loss: 0.1082 Acc: 0.9573 | Val Loss: 0.1537 Acc: 0.9420\n",
      "Epoch 056 | Train Loss: 0.0984 Acc: 0.9633 | Val Loss: 0.2260 Acc: 0.9312\n",
      "Epoch 057 | Train Loss: 0.0977 Acc: 0.9665 | Val Loss: 0.1591 Acc: 0.9463\n",
      "Epoch 058 | Train Loss: 0.1023 Acc: 0.9638 | Val Loss: 0.1720 Acc: 0.9378\n",
      "Epoch 059 | Train Loss: 0.1070 Acc: 0.9610 | Val Loss: 0.1725 Acc: 0.9420\n",
      "Epoch 060 | Train Loss: 0.0950 Acc: 0.9647 | Val Loss: 0.1469 Acc: 0.9469\n",
      "Epoch 001 | Train Loss: 0.6790 Acc: 0.5795 | Val Loss: 0.6726 Acc: 0.5966\n",
      "Epoch 002 | Train Loss: 0.6569 Acc: 0.6212 | Val Loss: 0.6095 Acc: 0.6842\n",
      "Epoch 003 | Train Loss: 0.5954 Acc: 0.6961 | Val Loss: 0.5944 Acc: 0.6938\n",
      "Epoch 004 | Train Loss: 0.5543 Acc: 0.7272 | Val Loss: 0.5574 Acc: 0.7283\n",
      "Epoch 005 | Train Loss: 0.5232 Acc: 0.7432 | Val Loss: 0.5229 Acc: 0.7367\n",
      "Epoch 006 | Train Loss: 0.4963 Acc: 0.7589 | Val Loss: 0.4926 Acc: 0.7585\n",
      "Epoch 007 | Train Loss: 0.4682 Acc: 0.7800 | Val Loss: 0.4635 Acc: 0.7754\n",
      "Epoch 008 | Train Loss: 0.4436 Acc: 0.7959 | Val Loss: 0.4344 Acc: 0.7983\n",
      "Epoch 009 | Train Loss: 0.4040 Acc: 0.8161 | Val Loss: 0.4518 Acc: 0.7905\n",
      "Epoch 010 | Train Loss: 0.3812 Acc: 0.8294 | Val Loss: 0.3903 Acc: 0.8249\n",
      "Epoch 011 | Train Loss: 0.3552 Acc: 0.8430 | Val Loss: 0.3402 Acc: 0.8533\n",
      "Epoch 012 | Train Loss: 0.3092 Acc: 0.8661 | Val Loss: 0.3256 Acc: 0.8678\n",
      "Epoch 013 | Train Loss: 0.2915 Acc: 0.8780 | Val Loss: 0.3124 Acc: 0.8605\n",
      "Epoch 014 | Train Loss: 0.2748 Acc: 0.8834 | Val Loss: 0.2897 Acc: 0.8816\n",
      "Epoch 015 | Train Loss: 0.2505 Acc: 0.8984 | Val Loss: 0.2640 Acc: 0.8955\n",
      "Epoch 016 | Train Loss: 0.2270 Acc: 0.9073 | Val Loss: 0.3973 Acc: 0.8551\n",
      "Epoch 017 | Train Loss: 0.2218 Acc: 0.9150 | Val Loss: 0.2720 Acc: 0.8943\n",
      "Epoch 018 | Train Loss: 0.2040 Acc: 0.9161 | Val Loss: 0.2323 Acc: 0.9088\n",
      "Epoch 019 | Train Loss: 0.1865 Acc: 0.9268 | Val Loss: 0.2062 Acc: 0.9179\n",
      "Epoch 020 | Train Loss: 0.1742 Acc: 0.9305 | Val Loss: 0.2398 Acc: 0.9070\n",
      "Epoch 021 | Train Loss: 0.1766 Acc: 0.9311 | Val Loss: 0.2217 Acc: 0.9173\n",
      "Epoch 022 | Train Loss: 0.1554 Acc: 0.9387 | Val Loss: 0.1993 Acc: 0.9275\n",
      "Epoch 023 | Train Loss: 0.1388 Acc: 0.9462 | Val Loss: 0.2634 Acc: 0.9130\n",
      "Epoch 024 | Train Loss: 0.1414 Acc: 0.9435 | Val Loss: 0.1874 Acc: 0.9342\n",
      "Epoch 025 | Train Loss: 0.1306 Acc: 0.9509 | Val Loss: 0.2080 Acc: 0.9233\n",
      "Epoch 026 | Train Loss: 0.1452 Acc: 0.9428 | Val Loss: 0.1778 Acc: 0.9336\n",
      "Epoch 027 | Train Loss: 0.1133 Acc: 0.9549 | Val Loss: 0.2206 Acc: 0.9263\n",
      "Epoch 028 | Train Loss: 0.1200 Acc: 0.9547 | Val Loss: 0.1847 Acc: 0.9354\n",
      "Epoch 029 | Train Loss: 0.1031 Acc: 0.9607 | Val Loss: 0.2004 Acc: 0.9269\n",
      "Epoch 030 | Train Loss: 0.1039 Acc: 0.9624 | Val Loss: 0.1735 Acc: 0.9360\n",
      "Epoch 031 | Train Loss: 0.0899 Acc: 0.9648 | Val Loss: 0.1925 Acc: 0.9402\n",
      "Epoch 032 | Train Loss: 0.0940 Acc: 0.9647 | Val Loss: 0.1827 Acc: 0.9336\n",
      "Epoch 033 | Train Loss: 0.0877 Acc: 0.9678 | Val Loss: 0.1769 Acc: 0.9426\n",
      "Epoch 034 | Train Loss: 0.0836 Acc: 0.9683 | Val Loss: 0.1911 Acc: 0.9372\n",
      "Epoch 035 | Train Loss: 0.0780 Acc: 0.9722 | Val Loss: 0.1701 Acc: 0.9463\n",
      "Epoch 036 | Train Loss: 0.0746 Acc: 0.9724 | Val Loss: 0.1847 Acc: 0.9366\n",
      "Epoch 037 | Train Loss: 0.0867 Acc: 0.9671 | Val Loss: 0.1710 Acc: 0.9390\n",
      "Epoch 038 | Train Loss: 0.0779 Acc: 0.9695 | Val Loss: 0.1983 Acc: 0.9438\n",
      "Epoch 039 | Train Loss: 0.0692 Acc: 0.9737 | Val Loss: 0.2129 Acc: 0.9372\n",
      "Epoch 040 | Train Loss: 0.0770 Acc: 0.9710 | Val Loss: 0.1939 Acc: 0.9390\n",
      "Epoch 041 | Train Loss: 0.0593 Acc: 0.9784 | Val Loss: 0.1595 Acc: 0.9493\n",
      "Epoch 042 | Train Loss: 0.0657 Acc: 0.9754 | Val Loss: 0.1725 Acc: 0.9438\n",
      "Epoch 043 | Train Loss: 0.0578 Acc: 0.9804 | Val Loss: 0.1651 Acc: 0.9535\n",
      "Epoch 044 | Train Loss: 0.0643 Acc: 0.9767 | Val Loss: 0.1587 Acc: 0.9505\n",
      "Epoch 045 | Train Loss: 0.0553 Acc: 0.9796 | Val Loss: 0.1972 Acc: 0.9354\n",
      "Epoch 046 | Train Loss: 0.0764 Acc: 0.9718 | Val Loss: 0.1958 Acc: 0.9426\n",
      "Epoch 047 | Train Loss: 0.0618 Acc: 0.9766 | Val Loss: 0.1807 Acc: 0.9463\n",
      "Epoch 048 | Train Loss: 0.0579 Acc: 0.9801 | Val Loss: 0.1882 Acc: 0.9499\n",
      "Epoch 049 | Train Loss: 0.0577 Acc: 0.9808 | Val Loss: 0.1758 Acc: 0.9505\n",
      "Epoch 050 | Train Loss: 0.0521 Acc: 0.9810 | Val Loss: 0.2149 Acc: 0.9360\n",
      "Epoch 051 | Train Loss: 0.0606 Acc: 0.9787 | Val Loss: 0.1859 Acc: 0.9463\n",
      "Epoch 052 | Train Loss: 0.0589 Acc: 0.9789 | Val Loss: 0.1883 Acc: 0.9469\n",
      "Epoch 053 | Train Loss: 0.0573 Acc: 0.9813 | Val Loss: 0.1676 Acc: 0.9432\n",
      "Epoch 054 | Train Loss: 0.0531 Acc: 0.9802 | Val Loss: 0.1895 Acc: 0.9390\n",
      "Early stopping triggered.\n",
      "Epoch 001 | Train Loss: 0.6805 Acc: 0.5765 | Val Loss: 0.6864 Acc: 0.5586\n",
      "Epoch 002 | Train Loss: 0.6784 Acc: 0.5828 | Val Loss: 0.6704 Acc: 0.6021\n",
      "Epoch 003 | Train Loss: 0.6666 Acc: 0.6062 | Val Loss: 0.6510 Acc: 0.6341\n",
      "Epoch 004 | Train Loss: 0.6397 Acc: 0.6413 | Val Loss: 0.6122 Acc: 0.6793\n",
      "Epoch 005 | Train Loss: 0.5904 Acc: 0.6986 | Val Loss: 0.5543 Acc: 0.7138\n",
      "Epoch 006 | Train Loss: 0.5431 Acc: 0.7317 | Val Loss: 0.5751 Acc: 0.7065\n",
      "Epoch 007 | Train Loss: 0.5163 Acc: 0.7492 | Val Loss: 0.4970 Acc: 0.7488\n",
      "Epoch 008 | Train Loss: 0.4872 Acc: 0.7682 | Val Loss: 0.4679 Acc: 0.7621\n",
      "Epoch 009 | Train Loss: 0.4611 Acc: 0.7883 | Val Loss: 0.4422 Acc: 0.7778\n",
      "Epoch 010 | Train Loss: 0.4368 Acc: 0.7978 | Val Loss: 0.4495 Acc: 0.7790\n",
      "Epoch 011 | Train Loss: 0.4070 Acc: 0.8132 | Val Loss: 0.4036 Acc: 0.8056\n",
      "Epoch 012 | Train Loss: 0.3905 Acc: 0.8223 | Val Loss: 0.4052 Acc: 0.8050\n",
      "Epoch 013 | Train Loss: 0.3616 Acc: 0.8421 | Val Loss: 0.3770 Acc: 0.8225\n",
      "Epoch 014 | Train Loss: 0.3470 Acc: 0.8483 | Val Loss: 0.3577 Acc: 0.8357\n",
      "Epoch 015 | Train Loss: 0.3199 Acc: 0.8646 | Val Loss: 0.4035 Acc: 0.8170\n",
      "Epoch 016 | Train Loss: 0.3124 Acc: 0.8673 | Val Loss: 0.3331 Acc: 0.8569\n",
      "Epoch 017 | Train Loss: 0.2979 Acc: 0.8750 | Val Loss: 0.3088 Acc: 0.8653\n",
      "Epoch 018 | Train Loss: 0.2822 Acc: 0.8816 | Val Loss: 0.3122 Acc: 0.8671\n",
      "Epoch 019 | Train Loss: 0.2600 Acc: 0.8928 | Val Loss: 0.3286 Acc: 0.8521\n",
      "Epoch 020 | Train Loss: 0.2454 Acc: 0.8979 | Val Loss: 0.3242 Acc: 0.8593\n",
      "Epoch 021 | Train Loss: 0.2364 Acc: 0.9046 | Val Loss: 0.2936 Acc: 0.8780\n",
      "Epoch 022 | Train Loss: 0.2190 Acc: 0.9109 | Val Loss: 0.3015 Acc: 0.8702\n",
      "Epoch 023 | Train Loss: 0.2075 Acc: 0.9153 | Val Loss: 0.2543 Acc: 0.8961\n",
      "Epoch 024 | Train Loss: 0.2020 Acc: 0.9224 | Val Loss: 0.2652 Acc: 0.8853\n",
      "Epoch 025 | Train Loss: 0.1853 Acc: 0.9265 | Val Loss: 0.2624 Acc: 0.8973\n",
      "Epoch 026 | Train Loss: 0.1826 Acc: 0.9250 | Val Loss: 0.2837 Acc: 0.8847\n",
      "Epoch 027 | Train Loss: 0.1778 Acc: 0.9307 | Val Loss: 0.2509 Acc: 0.8943\n",
      "Epoch 028 | Train Loss: 0.1646 Acc: 0.9345 | Val Loss: 0.2203 Acc: 0.9136\n",
      "Epoch 029 | Train Loss: 0.1489 Acc: 0.9426 | Val Loss: 0.2351 Acc: 0.9064\n",
      "Epoch 030 | Train Loss: 0.1568 Acc: 0.9387 | Val Loss: 0.2078 Acc: 0.9173\n",
      "Epoch 031 | Train Loss: 0.1466 Acc: 0.9425 | Val Loss: 0.2225 Acc: 0.9173\n",
      "Epoch 032 | Train Loss: 0.1294 Acc: 0.9526 | Val Loss: 0.2155 Acc: 0.9221\n",
      "Epoch 033 | Train Loss: 0.1342 Acc: 0.9491 | Val Loss: 0.2303 Acc: 0.9155\n",
      "Epoch 034 | Train Loss: 0.1250 Acc: 0.9509 | Val Loss: 0.2423 Acc: 0.9070\n",
      "Epoch 035 | Train Loss: 0.1239 Acc: 0.9526 | Val Loss: 0.1803 Acc: 0.9318\n",
      "Epoch 036 | Train Loss: 0.1163 Acc: 0.9558 | Val Loss: 0.2125 Acc: 0.9167\n",
      "Epoch 037 | Train Loss: 0.1059 Acc: 0.9609 | Val Loss: 0.2218 Acc: 0.9136\n",
      "Epoch 038 | Train Loss: 0.1014 Acc: 0.9616 | Val Loss: 0.2151 Acc: 0.9239\n",
      "Epoch 039 | Train Loss: 0.1029 Acc: 0.9603 | Val Loss: 0.2398 Acc: 0.9173\n",
      "Epoch 040 | Train Loss: 0.1023 Acc: 0.9612 | Val Loss: 0.2160 Acc: 0.9209\n",
      "Epoch 041 | Train Loss: 0.0994 Acc: 0.9618 | Val Loss: 0.1866 Acc: 0.9257\n",
      "Epoch 042 | Train Loss: 0.0838 Acc: 0.9684 | Val Loss: 0.1956 Acc: 0.9324\n",
      "Epoch 043 | Train Loss: 0.0924 Acc: 0.9627 | Val Loss: 0.1885 Acc: 0.9336\n",
      "Epoch 044 | Train Loss: 0.0962 Acc: 0.9632 | Val Loss: 0.1871 Acc: 0.9287\n",
      "Epoch 045 | Train Loss: 0.0938 Acc: 0.9660 | Val Loss: 0.1907 Acc: 0.9281\n",
      "Early stopping triggered.\n",
      "Iteration 38/40 | Best Val Loss: 0.1122 | Iter Time: 210.20s | Total Time: 153.39 min\n",
      "Epoch 001 | Train Loss: 0.6817 Acc: 0.5786 | Val Loss: 0.6807 Acc: 0.5658\n",
      "Epoch 002 | Train Loss: 0.6605 Acc: 0.6153 | Val Loss: 0.6309 Acc: 0.6443\n",
      "Epoch 003 | Train Loss: 0.6116 Acc: 0.6796 | Val Loss: 0.5979 Acc: 0.6836\n",
      "Epoch 004 | Train Loss: 0.5705 Acc: 0.7173 | Val Loss: 0.5634 Acc: 0.7101\n",
      "Epoch 005 | Train Loss: 0.5410 Acc: 0.7392 | Val Loss: 0.5452 Acc: 0.7319\n",
      "Epoch 006 | Train Loss: 0.5225 Acc: 0.7498 | Val Loss: 0.5315 Acc: 0.7271\n",
      "Epoch 007 | Train Loss: 0.4872 Acc: 0.7663 | Val Loss: 0.4969 Acc: 0.7615\n",
      "Epoch 008 | Train Loss: 0.4685 Acc: 0.7859 | Val Loss: 0.4710 Acc: 0.7760\n",
      "Epoch 009 | Train Loss: 0.4404 Acc: 0.7959 | Val Loss: 0.4360 Acc: 0.7953\n",
      "Epoch 010 | Train Loss: 0.4145 Acc: 0.8129 | Val Loss: 0.3996 Acc: 0.8213\n",
      "Epoch 011 | Train Loss: 0.3836 Acc: 0.8268 | Val Loss: 0.3996 Acc: 0.8037\n",
      "Epoch 012 | Train Loss: 0.3658 Acc: 0.8369 | Val Loss: 0.3471 Acc: 0.8430\n",
      "Epoch 013 | Train Loss: 0.3261 Acc: 0.8584 | Val Loss: 0.3265 Acc: 0.8514\n",
      "Epoch 014 | Train Loss: 0.3198 Acc: 0.8614 | Val Loss: 0.2915 Acc: 0.8744\n",
      "Epoch 015 | Train Loss: 0.2834 Acc: 0.8842 | Val Loss: 0.3046 Acc: 0.8659\n",
      "Epoch 016 | Train Loss: 0.2803 Acc: 0.8842 | Val Loss: 0.2796 Acc: 0.8816\n",
      "Epoch 017 | Train Loss: 0.2448 Acc: 0.9029 | Val Loss: 0.2723 Acc: 0.8829\n",
      "Epoch 018 | Train Loss: 0.2389 Acc: 0.9010 | Val Loss: 0.2576 Acc: 0.8992\n",
      "Epoch 019 | Train Loss: 0.2115 Acc: 0.9179 | Val Loss: 0.2488 Acc: 0.8919\n",
      "Epoch 020 | Train Loss: 0.2071 Acc: 0.9191 | Val Loss: 0.2194 Acc: 0.9124\n",
      "Epoch 021 | Train Loss: 0.2008 Acc: 0.9189 | Val Loss: 0.2105 Acc: 0.9106\n",
      "Epoch 022 | Train Loss: 0.1892 Acc: 0.9227 | Val Loss: 0.2265 Acc: 0.9100\n",
      "Epoch 023 | Train Loss: 0.1839 Acc: 0.9256 | Val Loss: 0.2129 Acc: 0.9161\n",
      "Epoch 024 | Train Loss: 0.1715 Acc: 0.9340 | Val Loss: 0.2094 Acc: 0.9143\n",
      "Epoch 025 | Train Loss: 0.1553 Acc: 0.9413 | Val Loss: 0.1949 Acc: 0.9227\n",
      "Epoch 026 | Train Loss: 0.1556 Acc: 0.9449 | Val Loss: 0.2148 Acc: 0.9100\n",
      "Epoch 027 | Train Loss: 0.1440 Acc: 0.9456 | Val Loss: 0.1843 Acc: 0.9245\n",
      "Epoch 028 | Train Loss: 0.1391 Acc: 0.9484 | Val Loss: 0.1890 Acc: 0.9275\n",
      "Epoch 029 | Train Loss: 0.1307 Acc: 0.9527 | Val Loss: 0.2005 Acc: 0.9167\n",
      "Epoch 030 | Train Loss: 0.1450 Acc: 0.9476 | Val Loss: 0.1998 Acc: 0.9227\n",
      "Epoch 031 | Train Loss: 0.1251 Acc: 0.9535 | Val Loss: 0.1735 Acc: 0.9306\n",
      "Epoch 032 | Train Loss: 0.1205 Acc: 0.9555 | Val Loss: 0.2214 Acc: 0.9124\n",
      "Epoch 033 | Train Loss: 0.1199 Acc: 0.9533 | Val Loss: 0.1813 Acc: 0.9312\n",
      "Epoch 034 | Train Loss: 0.1184 Acc: 0.9553 | Val Loss: 0.1791 Acc: 0.9281\n",
      "Epoch 035 | Train Loss: 0.1093 Acc: 0.9561 | Val Loss: 0.1462 Acc: 0.9426\n",
      "Epoch 036 | Train Loss: 0.1113 Acc: 0.9600 | Val Loss: 0.1574 Acc: 0.9372\n",
      "Epoch 037 | Train Loss: 0.1022 Acc: 0.9610 | Val Loss: 0.1478 Acc: 0.9408\n",
      "Epoch 038 | Train Loss: 0.0995 Acc: 0.9623 | Val Loss: 0.1870 Acc: 0.9378\n",
      "Epoch 039 | Train Loss: 0.1020 Acc: 0.9629 | Val Loss: 0.1631 Acc: 0.9348\n",
      "Epoch 040 | Train Loss: 0.1014 Acc: 0.9613 | Val Loss: 0.1640 Acc: 0.9396\n",
      "Epoch 041 | Train Loss: 0.0821 Acc: 0.9703 | Val Loss: 0.1756 Acc: 0.9432\n",
      "Epoch 042 | Train Loss: 0.0867 Acc: 0.9681 | Val Loss: 0.1745 Acc: 0.9348\n",
      "Epoch 043 | Train Loss: 0.0896 Acc: 0.9647 | Val Loss: 0.1888 Acc: 0.9300\n",
      "Epoch 044 | Train Loss: 0.0828 Acc: 0.9648 | Val Loss: 0.1835 Acc: 0.9457\n",
      "Epoch 045 | Train Loss: 0.0861 Acc: 0.9697 | Val Loss: 0.1682 Acc: 0.9360\n",
      "Early stopping triggered.\n",
      "Epoch 001 | Train Loss: 0.6810 Acc: 0.5721 | Val Loss: 0.6750 Acc: 0.5894\n",
      "Epoch 002 | Train Loss: 0.6750 Acc: 0.5878 | Val Loss: 0.6666 Acc: 0.5888\n",
      "Epoch 003 | Train Loss: 0.6488 Acc: 0.6277 | Val Loss: 0.6338 Acc: 0.6655\n",
      "Epoch 004 | Train Loss: 0.5962 Acc: 0.6980 | Val Loss: 0.5901 Acc: 0.6969\n",
      "Epoch 005 | Train Loss: 0.5598 Acc: 0.7229 | Val Loss: 0.5563 Acc: 0.7144\n",
      "Epoch 006 | Train Loss: 0.5342 Acc: 0.7356 | Val Loss: 0.5527 Acc: 0.7150\n",
      "Epoch 007 | Train Loss: 0.5235 Acc: 0.7506 | Val Loss: 0.5072 Acc: 0.7385\n",
      "Epoch 008 | Train Loss: 0.4984 Acc: 0.7631 | Val Loss: 0.4916 Acc: 0.7518\n",
      "Epoch 009 | Train Loss: 0.4685 Acc: 0.7812 | Val Loss: 0.4439 Acc: 0.7838\n",
      "Epoch 010 | Train Loss: 0.4460 Acc: 0.7936 | Val Loss: 0.4305 Acc: 0.7905\n",
      "Epoch 011 | Train Loss: 0.4135 Acc: 0.8120 | Val Loss: 0.3929 Acc: 0.8140\n",
      "Epoch 012 | Train Loss: 0.3949 Acc: 0.8194 | Val Loss: 0.3866 Acc: 0.8116\n",
      "Epoch 013 | Train Loss: 0.3688 Acc: 0.8371 | Val Loss: 0.3871 Acc: 0.8134\n",
      "Epoch 014 | Train Loss: 0.3421 Acc: 0.8557 | Val Loss: 0.3112 Acc: 0.8641\n",
      "Epoch 015 | Train Loss: 0.3345 Acc: 0.8522 | Val Loss: 0.3164 Acc: 0.8629\n",
      "Epoch 016 | Train Loss: 0.3115 Acc: 0.8661 | Val Loss: 0.2937 Acc: 0.8786\n",
      "Epoch 017 | Train Loss: 0.2933 Acc: 0.8768 | Val Loss: 0.3224 Acc: 0.8593\n",
      "Epoch 018 | Train Loss: 0.2811 Acc: 0.8836 | Val Loss: 0.2887 Acc: 0.8774\n",
      "Epoch 019 | Train Loss: 0.2600 Acc: 0.8934 | Val Loss: 0.2597 Acc: 0.8841\n",
      "Epoch 020 | Train Loss: 0.2414 Acc: 0.9013 | Val Loss: 0.2573 Acc: 0.8992\n",
      "Epoch 021 | Train Loss: 0.2341 Acc: 0.9074 | Val Loss: 0.2422 Acc: 0.9094\n",
      "Epoch 022 | Train Loss: 0.2237 Acc: 0.9100 | Val Loss: 0.2639 Acc: 0.8889\n",
      "Epoch 023 | Train Loss: 0.2096 Acc: 0.9168 | Val Loss: 0.2282 Acc: 0.9130\n",
      "Epoch 024 | Train Loss: 0.1963 Acc: 0.9197 | Val Loss: 0.2525 Acc: 0.9118\n",
      "Epoch 025 | Train Loss: 0.1956 Acc: 0.9245 | Val Loss: 0.2273 Acc: 0.9197\n",
      "Epoch 026 | Train Loss: 0.1868 Acc: 0.9289 | Val Loss: 0.1973 Acc: 0.9269\n",
      "Epoch 027 | Train Loss: 0.1762 Acc: 0.9293 | Val Loss: 0.2026 Acc: 0.9191\n",
      "Epoch 028 | Train Loss: 0.1692 Acc: 0.9277 | Val Loss: 0.2027 Acc: 0.9306\n",
      "Epoch 029 | Train Loss: 0.1548 Acc: 0.9390 | Val Loss: 0.2000 Acc: 0.9191\n",
      "Epoch 030 | Train Loss: 0.1568 Acc: 0.9387 | Val Loss: 0.1874 Acc: 0.9209\n",
      "Epoch 031 | Train Loss: 0.1400 Acc: 0.9450 | Val Loss: 0.2078 Acc: 0.9239\n",
      "Epoch 032 | Train Loss: 0.1448 Acc: 0.9453 | Val Loss: 0.1792 Acc: 0.9348\n",
      "Epoch 033 | Train Loss: 0.1356 Acc: 0.9469 | Val Loss: 0.2125 Acc: 0.9215\n",
      "Epoch 034 | Train Loss: 0.1399 Acc: 0.9458 | Val Loss: 0.2103 Acc: 0.9215\n",
      "Epoch 035 | Train Loss: 0.1206 Acc: 0.9517 | Val Loss: 0.1843 Acc: 0.9300\n",
      "Epoch 036 | Train Loss: 0.1218 Acc: 0.9526 | Val Loss: 0.1793 Acc: 0.9293\n",
      "Epoch 037 | Train Loss: 0.1225 Acc: 0.9527 | Val Loss: 0.1631 Acc: 0.9402\n",
      "Epoch 038 | Train Loss: 0.1125 Acc: 0.9568 | Val Loss: 0.1659 Acc: 0.9457\n",
      "Epoch 039 | Train Loss: 0.1045 Acc: 0.9589 | Val Loss: 0.1708 Acc: 0.9378\n",
      "Epoch 040 | Train Loss: 0.1112 Acc: 0.9610 | Val Loss: 0.1664 Acc: 0.9378\n",
      "Epoch 041 | Train Loss: 0.1027 Acc: 0.9607 | Val Loss: 0.2170 Acc: 0.9251\n",
      "Epoch 042 | Train Loss: 0.1095 Acc: 0.9609 | Val Loss: 0.1998 Acc: 0.9293\n",
      "Epoch 043 | Train Loss: 0.1029 Acc: 0.9626 | Val Loss: 0.1675 Acc: 0.9396\n",
      "Epoch 044 | Train Loss: 0.0968 Acc: 0.9645 | Val Loss: 0.1687 Acc: 0.9336\n",
      "Epoch 045 | Train Loss: 0.0890 Acc: 0.9671 | Val Loss: 0.1696 Acc: 0.9384\n",
      "Epoch 046 | Train Loss: 0.0960 Acc: 0.9633 | Val Loss: 0.1465 Acc: 0.9469\n",
      "Epoch 047 | Train Loss: 0.0916 Acc: 0.9656 | Val Loss: 0.1538 Acc: 0.9444\n",
      "Epoch 048 | Train Loss: 0.0865 Acc: 0.9668 | Val Loss: 0.1462 Acc: 0.9511\n",
      "Epoch 049 | Train Loss: 0.0815 Acc: 0.9706 | Val Loss: 0.1666 Acc: 0.9420\n",
      "Epoch 050 | Train Loss: 0.0825 Acc: 0.9724 | Val Loss: 0.1697 Acc: 0.9372\n",
      "Epoch 051 | Train Loss: 0.0776 Acc: 0.9724 | Val Loss: 0.1910 Acc: 0.9342\n",
      "Epoch 052 | Train Loss: 0.0791 Acc: 0.9727 | Val Loss: 0.1676 Acc: 0.9372\n",
      "Epoch 053 | Train Loss: 0.0808 Acc: 0.9700 | Val Loss: 0.1948 Acc: 0.9318\n",
      "Epoch 054 | Train Loss: 0.0723 Acc: 0.9730 | Val Loss: 0.1556 Acc: 0.9469\n",
      "Epoch 055 | Train Loss: 0.0772 Acc: 0.9712 | Val Loss: 0.1714 Acc: 0.9457\n",
      "Epoch 056 | Train Loss: 0.0700 Acc: 0.9740 | Val Loss: 0.1637 Acc: 0.9414\n",
      "Epoch 057 | Train Loss: 0.0731 Acc: 0.9743 | Val Loss: 0.1576 Acc: 0.9402\n",
      "Epoch 058 | Train Loss: 0.0785 Acc: 0.9703 | Val Loss: 0.1650 Acc: 0.9390\n",
      "Early stopping triggered.\n",
      "Epoch 001 | Train Loss: 0.6812 Acc: 0.5792 | Val Loss: 0.6776 Acc: 0.5821\n",
      "Epoch 002 | Train Loss: 0.6735 Acc: 0.5923 | Val Loss: 0.6707 Acc: 0.5930\n",
      "Epoch 003 | Train Loss: 0.6640 Acc: 0.6079 | Val Loss: 0.6507 Acc: 0.6105\n",
      "Epoch 004 | Train Loss: 0.6095 Acc: 0.6793 | Val Loss: 0.5842 Acc: 0.7011\n",
      "Epoch 005 | Train Loss: 0.5696 Acc: 0.7127 | Val Loss: 0.5721 Acc: 0.7077\n",
      "Epoch 006 | Train Loss: 0.5386 Acc: 0.7340 | Val Loss: 0.5393 Acc: 0.7379\n",
      "Epoch 007 | Train Loss: 0.5313 Acc: 0.7409 | Val Loss: 0.5241 Acc: 0.7500\n",
      "Epoch 008 | Train Loss: 0.5063 Acc: 0.7571 | Val Loss: 0.5181 Acc: 0.7464\n",
      "Epoch 009 | Train Loss: 0.4924 Acc: 0.7649 | Val Loss: 0.4872 Acc: 0.7651\n",
      "Epoch 010 | Train Loss: 0.4737 Acc: 0.7758 | Val Loss: 0.4613 Acc: 0.7772\n",
      "Epoch 011 | Train Loss: 0.4478 Acc: 0.7930 | Val Loss: 0.4340 Acc: 0.7893\n",
      "Epoch 012 | Train Loss: 0.4283 Acc: 0.8048 | Val Loss: 0.4427 Acc: 0.7935\n",
      "Epoch 013 | Train Loss: 0.4118 Acc: 0.8128 | Val Loss: 0.4147 Acc: 0.7977\n",
      "Epoch 014 | Train Loss: 0.3828 Acc: 0.8315 | Val Loss: 0.3820 Acc: 0.8182\n",
      "Epoch 015 | Train Loss: 0.3593 Acc: 0.8449 | Val Loss: 0.3393 Acc: 0.8521\n",
      "Epoch 016 | Train Loss: 0.3349 Acc: 0.8513 | Val Loss: 0.3272 Acc: 0.8490\n",
      "Epoch 017 | Train Loss: 0.3281 Acc: 0.8587 | Val Loss: 0.2925 Acc: 0.8768\n",
      "Epoch 018 | Train Loss: 0.3106 Acc: 0.8646 | Val Loss: 0.3144 Acc: 0.8647\n",
      "Epoch 019 | Train Loss: 0.2758 Acc: 0.8862 | Val Loss: 0.3041 Acc: 0.8768\n",
      "Epoch 020 | Train Loss: 0.2735 Acc: 0.8862 | Val Loss: 0.2873 Acc: 0.8768\n",
      "Epoch 021 | Train Loss: 0.2616 Acc: 0.8911 | Val Loss: 0.2480 Acc: 0.8931\n",
      "Epoch 022 | Train Loss: 0.2404 Acc: 0.9000 | Val Loss: 0.2374 Acc: 0.9028\n",
      "Epoch 023 | Train Loss: 0.2332 Acc: 0.9053 | Val Loss: 0.2215 Acc: 0.9100\n",
      "Epoch 024 | Train Loss: 0.2170 Acc: 0.9135 | Val Loss: 0.2087 Acc: 0.9143\n",
      "Epoch 025 | Train Loss: 0.2043 Acc: 0.9198 | Val Loss: 0.1985 Acc: 0.9239\n",
      "Epoch 026 | Train Loss: 0.1982 Acc: 0.9221 | Val Loss: 0.1938 Acc: 0.9185\n",
      "Epoch 027 | Train Loss: 0.1876 Acc: 0.9247 | Val Loss: 0.1993 Acc: 0.9257\n",
      "Epoch 028 | Train Loss: 0.1878 Acc: 0.9277 | Val Loss: 0.2261 Acc: 0.9082\n",
      "Epoch 029 | Train Loss: 0.1669 Acc: 0.9382 | Val Loss: 0.1913 Acc: 0.9275\n",
      "Epoch 030 | Train Loss: 0.1626 Acc: 0.9384 | Val Loss: 0.1711 Acc: 0.9348\n",
      "Epoch 031 | Train Loss: 0.1614 Acc: 0.9378 | Val Loss: 0.2020 Acc: 0.9173\n",
      "Epoch 032 | Train Loss: 0.1531 Acc: 0.9414 | Val Loss: 0.1843 Acc: 0.9330\n",
      "Epoch 033 | Train Loss: 0.1408 Acc: 0.9462 | Val Loss: 0.2204 Acc: 0.9106\n",
      "Epoch 034 | Train Loss: 0.1473 Acc: 0.9423 | Val Loss: 0.1862 Acc: 0.9281\n",
      "Epoch 035 | Train Loss: 0.1469 Acc: 0.9434 | Val Loss: 0.2261 Acc: 0.9040\n",
      "Epoch 036 | Train Loss: 0.1325 Acc: 0.9473 | Val Loss: 0.1680 Acc: 0.9372\n",
      "Epoch 037 | Train Loss: 0.1232 Acc: 0.9524 | Val Loss: 0.1766 Acc: 0.9342\n",
      "Epoch 038 | Train Loss: 0.1270 Acc: 0.9506 | Val Loss: 0.1605 Acc: 0.9354\n",
      "Epoch 039 | Train Loss: 0.1163 Acc: 0.9561 | Val Loss: 0.2000 Acc: 0.9257\n",
      "Epoch 040 | Train Loss: 0.1177 Acc: 0.9564 | Val Loss: 0.1669 Acc: 0.9384\n",
      "Epoch 041 | Train Loss: 0.1096 Acc: 0.9579 | Val Loss: 0.1749 Acc: 0.9306\n",
      "Epoch 042 | Train Loss: 0.1025 Acc: 0.9618 | Val Loss: 0.1684 Acc: 0.9366\n",
      "Epoch 043 | Train Loss: 0.1060 Acc: 0.9598 | Val Loss: 0.1672 Acc: 0.9384\n",
      "Epoch 044 | Train Loss: 0.1036 Acc: 0.9597 | Val Loss: 0.1728 Acc: 0.9366\n",
      "Epoch 045 | Train Loss: 0.1083 Acc: 0.9597 | Val Loss: 0.1623 Acc: 0.9390\n",
      "Epoch 046 | Train Loss: 0.1103 Acc: 0.9613 | Val Loss: 0.1920 Acc: 0.9227\n",
      "Epoch 047 | Train Loss: 0.1024 Acc: 0.9616 | Val Loss: 0.1525 Acc: 0.9372\n",
      "Epoch 048 | Train Loss: 0.1053 Acc: 0.9592 | Val Loss: 0.1460 Acc: 0.9426\n",
      "Epoch 049 | Train Loss: 0.0924 Acc: 0.9653 | Val Loss: 0.1539 Acc: 0.9414\n",
      "Epoch 050 | Train Loss: 0.0890 Acc: 0.9656 | Val Loss: 0.2195 Acc: 0.9263\n",
      "Epoch 051 | Train Loss: 0.0950 Acc: 0.9642 | Val Loss: 0.1636 Acc: 0.9366\n",
      "Epoch 052 | Train Loss: 0.0892 Acc: 0.9692 | Val Loss: 0.1748 Acc: 0.9402\n",
      "Epoch 053 | Train Loss: 0.0901 Acc: 0.9674 | Val Loss: 0.1443 Acc: 0.9444\n",
      "Epoch 054 | Train Loss: 0.0845 Acc: 0.9675 | Val Loss: 0.1395 Acc: 0.9535\n",
      "Epoch 055 | Train Loss: 0.0936 Acc: 0.9672 | Val Loss: 0.1410 Acc: 0.9463\n",
      "Epoch 056 | Train Loss: 0.0719 Acc: 0.9734 | Val Loss: 0.1594 Acc: 0.9426\n",
      "Epoch 057 | Train Loss: 0.0818 Acc: 0.9683 | Val Loss: 0.1411 Acc: 0.9505\n",
      "Epoch 058 | Train Loss: 0.0845 Acc: 0.9681 | Val Loss: 0.1474 Acc: 0.9475\n",
      "Epoch 059 | Train Loss: 0.0711 Acc: 0.9734 | Val Loss: 0.2156 Acc: 0.9366\n",
      "Epoch 060 | Train Loss: 0.0742 Acc: 0.9730 | Val Loss: 0.1728 Acc: 0.9432\n",
      "Epoch 001 | Train Loss: 0.6834 Acc: 0.5721 | Val Loss: 0.6844 Acc: 0.5586\n",
      "Epoch 002 | Train Loss: 0.6757 Acc: 0.5908 | Val Loss: 0.6702 Acc: 0.5978\n",
      "Epoch 003 | Train Loss: 0.6669 Acc: 0.6044 | Val Loss: 0.6614 Acc: 0.6051\n",
      "Epoch 004 | Train Loss: 0.6539 Acc: 0.6218 | Val Loss: 0.6445 Acc: 0.6238\n",
      "Epoch 005 | Train Loss: 0.6249 Acc: 0.6648 | Val Loss: 0.6123 Acc: 0.6878\n",
      "Epoch 006 | Train Loss: 0.5890 Acc: 0.7048 | Val Loss: 0.5620 Acc: 0.7180\n",
      "Epoch 007 | Train Loss: 0.5615 Acc: 0.7250 | Val Loss: 0.5497 Acc: 0.7240\n",
      "Epoch 008 | Train Loss: 0.5434 Acc: 0.7391 | Val Loss: 0.5501 Acc: 0.7180\n",
      "Epoch 009 | Train Loss: 0.5275 Acc: 0.7485 | Val Loss: 0.5193 Acc: 0.7482\n",
      "Epoch 010 | Train Loss: 0.5087 Acc: 0.7625 | Val Loss: 0.5021 Acc: 0.7609\n",
      "Epoch 011 | Train Loss: 0.4950 Acc: 0.7619 | Val Loss: 0.4858 Acc: 0.7675\n",
      "Epoch 012 | Train Loss: 0.4635 Acc: 0.7845 | Val Loss: 0.4577 Acc: 0.7808\n",
      "Epoch 013 | Train Loss: 0.4428 Acc: 0.7981 | Val Loss: 0.4310 Acc: 0.8043\n",
      "Epoch 014 | Train Loss: 0.4322 Acc: 0.7963 | Val Loss: 0.4413 Acc: 0.7832\n",
      "Epoch 015 | Train Loss: 0.4202 Acc: 0.8079 | Val Loss: 0.4058 Acc: 0.8043\n",
      "Epoch 016 | Train Loss: 0.3921 Acc: 0.8223 | Val Loss: 0.3867 Acc: 0.8237\n",
      "Epoch 017 | Train Loss: 0.3852 Acc: 0.8239 | Val Loss: 0.3808 Acc: 0.8279\n",
      "Epoch 018 | Train Loss: 0.3708 Acc: 0.8348 | Val Loss: 0.3393 Acc: 0.8424\n",
      "Epoch 019 | Train Loss: 0.3500 Acc: 0.8470 | Val Loss: 0.3289 Acc: 0.8539\n",
      "Epoch 020 | Train Loss: 0.3161 Acc: 0.8637 | Val Loss: 0.3097 Acc: 0.8684\n",
      "Epoch 021 | Train Loss: 0.2987 Acc: 0.8763 | Val Loss: 0.2895 Acc: 0.8780\n",
      "Epoch 022 | Train Loss: 0.2811 Acc: 0.8834 | Val Loss: 0.2747 Acc: 0.8768\n",
      "Epoch 023 | Train Loss: 0.2687 Acc: 0.8884 | Val Loss: 0.2735 Acc: 0.8816\n",
      "Epoch 024 | Train Loss: 0.2511 Acc: 0.8969 | Val Loss: 0.2425 Acc: 0.9022\n",
      "Epoch 025 | Train Loss: 0.2379 Acc: 0.9046 | Val Loss: 0.2454 Acc: 0.8943\n",
      "Epoch 026 | Train Loss: 0.2205 Acc: 0.9109 | Val Loss: 0.2443 Acc: 0.8949\n",
      "Epoch 027 | Train Loss: 0.2256 Acc: 0.9105 | Val Loss: 0.2266 Acc: 0.9082\n",
      "Epoch 028 | Train Loss: 0.2113 Acc: 0.9200 | Val Loss: 0.2522 Acc: 0.8998\n",
      "Epoch 029 | Train Loss: 0.2022 Acc: 0.9192 | Val Loss: 0.2352 Acc: 0.9034\n",
      "Epoch 030 | Train Loss: 0.1865 Acc: 0.9262 | Val Loss: 0.2657 Acc: 0.8889\n",
      "Epoch 031 | Train Loss: 0.1995 Acc: 0.9215 | Val Loss: 0.2545 Acc: 0.8895\n",
      "Epoch 032 | Train Loss: 0.1651 Acc: 0.9419 | Val Loss: 0.2355 Acc: 0.9022\n",
      "Epoch 033 | Train Loss: 0.1774 Acc: 0.9315 | Val Loss: 0.2470 Acc: 0.8961\n",
      "Epoch 034 | Train Loss: 0.1635 Acc: 0.9355 | Val Loss: 0.2058 Acc: 0.9221\n",
      "Epoch 035 | Train Loss: 0.1547 Acc: 0.9378 | Val Loss: 0.1816 Acc: 0.9239\n",
      "Epoch 036 | Train Loss: 0.1400 Acc: 0.9484 | Val Loss: 0.2230 Acc: 0.9215\n",
      "Epoch 037 | Train Loss: 0.1346 Acc: 0.9476 | Val Loss: 0.2337 Acc: 0.9191\n",
      "Epoch 038 | Train Loss: 0.1413 Acc: 0.9472 | Val Loss: 0.1916 Acc: 0.9306\n",
      "Epoch 039 | Train Loss: 0.1386 Acc: 0.9469 | Val Loss: 0.2243 Acc: 0.9179\n",
      "Epoch 040 | Train Loss: 0.1345 Acc: 0.9506 | Val Loss: 0.1868 Acc: 0.9263\n",
      "Epoch 041 | Train Loss: 0.1260 Acc: 0.9511 | Val Loss: 0.1893 Acc: 0.9221\n",
      "Epoch 042 | Train Loss: 0.1171 Acc: 0.9568 | Val Loss: 0.2318 Acc: 0.9143\n",
      "Epoch 043 | Train Loss: 0.1099 Acc: 0.9562 | Val Loss: 0.1849 Acc: 0.9390\n",
      "Epoch 044 | Train Loss: 0.1127 Acc: 0.9553 | Val Loss: 0.1805 Acc: 0.9245\n",
      "Epoch 045 | Train Loss: 0.1149 Acc: 0.9586 | Val Loss: 0.1949 Acc: 0.9293\n",
      "Epoch 046 | Train Loss: 0.1018 Acc: 0.9612 | Val Loss: 0.1897 Acc: 0.9330\n",
      "Epoch 047 | Train Loss: 0.1048 Acc: 0.9610 | Val Loss: 0.1871 Acc: 0.9342\n",
      "Epoch 048 | Train Loss: 0.0952 Acc: 0.9657 | Val Loss: 0.1859 Acc: 0.9420\n",
      "Epoch 049 | Train Loss: 0.0981 Acc: 0.9633 | Val Loss: 0.1994 Acc: 0.9275\n",
      "Epoch 050 | Train Loss: 0.0884 Acc: 0.9712 | Val Loss: 0.1982 Acc: 0.9293\n",
      "Epoch 051 | Train Loss: 0.0957 Acc: 0.9632 | Val Loss: 0.1748 Acc: 0.9293\n",
      "Epoch 052 | Train Loss: 0.0959 Acc: 0.9623 | Val Loss: 0.1993 Acc: 0.9239\n",
      "Epoch 053 | Train Loss: 0.0897 Acc: 0.9687 | Val Loss: 0.1794 Acc: 0.9342\n",
      "Epoch 054 | Train Loss: 0.0810 Acc: 0.9704 | Val Loss: 0.2151 Acc: 0.9336\n",
      "Epoch 055 | Train Loss: 0.0836 Acc: 0.9706 | Val Loss: 0.1687 Acc: 0.9372\n",
      "Epoch 056 | Train Loss: 0.0934 Acc: 0.9648 | Val Loss: 0.1937 Acc: 0.9372\n",
      "Epoch 057 | Train Loss: 0.0794 Acc: 0.9713 | Val Loss: 0.1877 Acc: 0.9378\n",
      "Epoch 058 | Train Loss: 0.0835 Acc: 0.9672 | Val Loss: 0.2007 Acc: 0.9269\n",
      "Epoch 059 | Train Loss: 0.0856 Acc: 0.9680 | Val Loss: 0.1596 Acc: 0.9432\n",
      "Epoch 060 | Train Loss: 0.0714 Acc: 0.9742 | Val Loss: 0.2233 Acc: 0.9318\n",
      "Epoch 001 | Train Loss: 0.6847 Acc: 0.5656 | Val Loss: 0.6864 Acc: 0.5586\n",
      "Epoch 002 | Train Loss: 0.6800 Acc: 0.5796 | Val Loss: 0.6695 Acc: 0.6002\n",
      "Epoch 003 | Train Loss: 0.6702 Acc: 0.5952 | Val Loss: 0.6674 Acc: 0.5876\n",
      "Epoch 004 | Train Loss: 0.6540 Acc: 0.6236 | Val Loss: 0.6292 Acc: 0.6655\n",
      "Epoch 005 | Train Loss: 0.6273 Acc: 0.6680 | Val Loss: 0.5892 Acc: 0.6969\n",
      "Epoch 006 | Train Loss: 0.5866 Acc: 0.7024 | Val Loss: 0.5824 Acc: 0.6981\n",
      "Epoch 007 | Train Loss: 0.5569 Acc: 0.7232 | Val Loss: 0.5502 Acc: 0.7216\n",
      "Epoch 008 | Train Loss: 0.5450 Acc: 0.7370 | Val Loss: 0.5373 Acc: 0.7301\n",
      "Epoch 009 | Train Loss: 0.5193 Acc: 0.7495 | Val Loss: 0.5221 Acc: 0.7488\n",
      "Epoch 010 | Train Loss: 0.5080 Acc: 0.7574 | Val Loss: 0.4891 Acc: 0.7687\n",
      "Epoch 011 | Train Loss: 0.4902 Acc: 0.7700 | Val Loss: 0.4754 Acc: 0.7723\n",
      "Epoch 012 | Train Loss: 0.4691 Acc: 0.7761 | Val Loss: 0.4738 Acc: 0.7693\n",
      "Epoch 013 | Train Loss: 0.4583 Acc: 0.7838 | Val Loss: 0.4570 Acc: 0.7808\n",
      "Epoch 014 | Train Loss: 0.4481 Acc: 0.7972 | Val Loss: 0.4289 Acc: 0.7983\n",
      "Epoch 015 | Train Loss: 0.4211 Acc: 0.8075 | Val Loss: 0.4102 Acc: 0.8092\n",
      "Epoch 016 | Train Loss: 0.4044 Acc: 0.8196 | Val Loss: 0.4040 Acc: 0.8170\n",
      "Epoch 017 | Train Loss: 0.3973 Acc: 0.8212 | Val Loss: 0.3959 Acc: 0.8194\n",
      "Epoch 018 | Train Loss: 0.3848 Acc: 0.8291 | Val Loss: 0.3849 Acc: 0.8285\n",
      "Epoch 019 | Train Loss: 0.3720 Acc: 0.8357 | Val Loss: 0.3956 Acc: 0.8116\n",
      "Epoch 020 | Train Loss: 0.3644 Acc: 0.8390 | Val Loss: 0.4275 Acc: 0.8056\n",
      "Epoch 021 | Train Loss: 0.3570 Acc: 0.8455 | Val Loss: 0.3892 Acc: 0.8122\n",
      "Epoch 022 | Train Loss: 0.3307 Acc: 0.8575 | Val Loss: 0.3295 Acc: 0.8539\n",
      "Epoch 023 | Train Loss: 0.3081 Acc: 0.8723 | Val Loss: 0.3171 Acc: 0.8605\n",
      "Epoch 024 | Train Loss: 0.3131 Acc: 0.8653 | Val Loss: 0.3317 Acc: 0.8539\n",
      "Epoch 025 | Train Loss: 0.3006 Acc: 0.8729 | Val Loss: 0.3047 Acc: 0.8629\n",
      "Epoch 026 | Train Loss: 0.2924 Acc: 0.8760 | Val Loss: 0.2869 Acc: 0.8768\n",
      "Epoch 027 | Train Loss: 0.2654 Acc: 0.8856 | Val Loss: 0.3488 Acc: 0.8478\n",
      "Epoch 028 | Train Loss: 0.2692 Acc: 0.8910 | Val Loss: 0.2811 Acc: 0.8804\n",
      "Epoch 029 | Train Loss: 0.2696 Acc: 0.8831 | Val Loss: 0.2868 Acc: 0.8786\n",
      "Epoch 030 | Train Loss: 0.2540 Acc: 0.8952 | Val Loss: 0.3189 Acc: 0.8611\n",
      "Epoch 031 | Train Loss: 0.2330 Acc: 0.9058 | Val Loss: 0.2525 Acc: 0.8949\n",
      "Epoch 032 | Train Loss: 0.2337 Acc: 0.9043 | Val Loss: 0.2604 Acc: 0.8829\n",
      "Epoch 033 | Train Loss: 0.2270 Acc: 0.9079 | Val Loss: 0.2469 Acc: 0.8998\n",
      "Epoch 034 | Train Loss: 0.2162 Acc: 0.9074 | Val Loss: 0.2790 Acc: 0.8871\n",
      "Epoch 035 | Train Loss: 0.2080 Acc: 0.9161 | Val Loss: 0.2523 Acc: 0.9022\n",
      "Epoch 036 | Train Loss: 0.2183 Acc: 0.9114 | Val Loss: 0.2387 Acc: 0.9034\n",
      "Epoch 037 | Train Loss: 0.1911 Acc: 0.9201 | Val Loss: 0.2695 Acc: 0.8998\n",
      "Epoch 038 | Train Loss: 0.1857 Acc: 0.9290 | Val Loss: 0.2617 Acc: 0.8919\n",
      "Epoch 039 | Train Loss: 0.1883 Acc: 0.9262 | Val Loss: 0.2557 Acc: 0.8889\n",
      "Epoch 040 | Train Loss: 0.1730 Acc: 0.9331 | Val Loss: 0.2222 Acc: 0.9179\n",
      "Epoch 041 | Train Loss: 0.1705 Acc: 0.9340 | Val Loss: 0.2394 Acc: 0.9010\n",
      "Epoch 042 | Train Loss: 0.1779 Acc: 0.9284 | Val Loss: 0.2145 Acc: 0.9239\n",
      "Epoch 043 | Train Loss: 0.1698 Acc: 0.9280 | Val Loss: 0.2186 Acc: 0.9149\n",
      "Epoch 044 | Train Loss: 0.1506 Acc: 0.9382 | Val Loss: 0.1990 Acc: 0.9227\n",
      "Epoch 045 | Train Loss: 0.1545 Acc: 0.9408 | Val Loss: 0.2352 Acc: 0.9088\n",
      "Epoch 046 | Train Loss: 0.1437 Acc: 0.9441 | Val Loss: 0.2231 Acc: 0.9100\n",
      "Epoch 047 | Train Loss: 0.1416 Acc: 0.9475 | Val Loss: 0.2213 Acc: 0.9173\n",
      "Epoch 048 | Train Loss: 0.1372 Acc: 0.9464 | Val Loss: 0.2068 Acc: 0.9227\n",
      "Epoch 049 | Train Loss: 0.1365 Acc: 0.9452 | Val Loss: 0.1949 Acc: 0.9251\n",
      "Epoch 050 | Train Loss: 0.1436 Acc: 0.9426 | Val Loss: 0.2157 Acc: 0.9239\n",
      "Epoch 051 | Train Loss: 0.1286 Acc: 0.9488 | Val Loss: 0.2026 Acc: 0.9209\n",
      "Epoch 052 | Train Loss: 0.1271 Acc: 0.9506 | Val Loss: 0.1843 Acc: 0.9330\n",
      "Epoch 053 | Train Loss: 0.1345 Acc: 0.9470 | Val Loss: 0.2125 Acc: 0.9161\n",
      "Epoch 054 | Train Loss: 0.1354 Acc: 0.9476 | Val Loss: 0.2172 Acc: 0.9149\n",
      "Epoch 055 | Train Loss: 0.1154 Acc: 0.9559 | Val Loss: 0.2070 Acc: 0.9167\n",
      "Epoch 056 | Train Loss: 0.1227 Acc: 0.9536 | Val Loss: 0.1992 Acc: 0.9227\n",
      "Epoch 057 | Train Loss: 0.1103 Acc: 0.9567 | Val Loss: 0.1966 Acc: 0.9281\n",
      "Epoch 058 | Train Loss: 0.1119 Acc: 0.9573 | Val Loss: 0.2272 Acc: 0.9112\n",
      "Epoch 059 | Train Loss: 0.1128 Acc: 0.9571 | Val Loss: 0.1925 Acc: 0.9263\n",
      "Epoch 060 | Train Loss: 0.1045 Acc: 0.9624 | Val Loss: 0.1945 Acc: 0.9293\n",
      "Epoch 001 | Train Loss: 0.6778 Acc: 0.5816 | Val Loss: 0.6667 Acc: 0.6057\n",
      "Epoch 002 | Train Loss: 0.6519 Acc: 0.6308 | Val Loss: 0.6340 Acc: 0.6570\n",
      "Epoch 003 | Train Loss: 0.6201 Acc: 0.6662 | Val Loss: 0.6033 Acc: 0.6890\n",
      "Epoch 004 | Train Loss: 0.5684 Acc: 0.7163 | Val Loss: 0.5926 Acc: 0.7029\n",
      "Epoch 005 | Train Loss: 0.5485 Acc: 0.7297 | Val Loss: 0.5688 Acc: 0.7186\n",
      "Epoch 006 | Train Loss: 0.5227 Acc: 0.7445 | Val Loss: 0.5257 Acc: 0.7403\n",
      "Epoch 007 | Train Loss: 0.5051 Acc: 0.7551 | Val Loss: 0.5035 Acc: 0.7566\n",
      "Epoch 008 | Train Loss: 0.4822 Acc: 0.7791 | Val Loss: 0.4797 Acc: 0.7663\n",
      "Epoch 009 | Train Loss: 0.4646 Acc: 0.7851 | Val Loss: 0.4850 Acc: 0.7778\n",
      "Epoch 010 | Train Loss: 0.4501 Acc: 0.7919 | Val Loss: 0.4534 Acc: 0.7917\n",
      "Epoch 011 | Train Loss: 0.4267 Acc: 0.8048 | Val Loss: 0.4244 Acc: 0.7929\n",
      "Epoch 012 | Train Loss: 0.4025 Acc: 0.8182 | Val Loss: 0.4081 Acc: 0.8074\n",
      "Epoch 013 | Train Loss: 0.3930 Acc: 0.8202 | Val Loss: 0.4126 Acc: 0.8043\n",
      "Epoch 014 | Train Loss: 0.3724 Acc: 0.8362 | Val Loss: 0.3539 Acc: 0.8460\n",
      "Epoch 015 | Train Loss: 0.3500 Acc: 0.8461 | Val Loss: 0.3489 Acc: 0.8357\n",
      "Epoch 016 | Train Loss: 0.3223 Acc: 0.8578 | Val Loss: 0.4003 Acc: 0.8237\n",
      "Epoch 017 | Train Loss: 0.3217 Acc: 0.8591 | Val Loss: 0.3118 Acc: 0.8599\n",
      "Epoch 018 | Train Loss: 0.3069 Acc: 0.8665 | Val Loss: 0.3376 Acc: 0.8460\n",
      "Epoch 019 | Train Loss: 0.2938 Acc: 0.8723 | Val Loss: 0.3102 Acc: 0.8708\n",
      "Epoch 020 | Train Loss: 0.2651 Acc: 0.8914 | Val Loss: 0.2888 Acc: 0.8780\n",
      "Epoch 021 | Train Loss: 0.2627 Acc: 0.8908 | Val Loss: 0.2537 Acc: 0.8889\n",
      "Epoch 022 | Train Loss: 0.2436 Acc: 0.8970 | Val Loss: 0.3397 Acc: 0.8412\n",
      "Epoch 023 | Train Loss: 0.2368 Acc: 0.9000 | Val Loss: 0.2392 Acc: 0.8992\n",
      "Epoch 024 | Train Loss: 0.2289 Acc: 0.9062 | Val Loss: 0.2482 Acc: 0.8937\n",
      "Epoch 025 | Train Loss: 0.2145 Acc: 0.9091 | Val Loss: 0.2268 Acc: 0.9076\n",
      "Epoch 026 | Train Loss: 0.2095 Acc: 0.9139 | Val Loss: 0.2269 Acc: 0.9022\n",
      "Epoch 027 | Train Loss: 0.2015 Acc: 0.9191 | Val Loss: 0.2357 Acc: 0.9052\n",
      "Epoch 028 | Train Loss: 0.1842 Acc: 0.9257 | Val Loss: 0.2070 Acc: 0.9173\n",
      "Epoch 029 | Train Loss: 0.1830 Acc: 0.9256 | Val Loss: 0.2200 Acc: 0.9082\n",
      "Epoch 030 | Train Loss: 0.1801 Acc: 0.9259 | Val Loss: 0.1866 Acc: 0.9191\n",
      "Epoch 031 | Train Loss: 0.1657 Acc: 0.9366 | Val Loss: 0.2061 Acc: 0.9149\n",
      "Epoch 032 | Train Loss: 0.1610 Acc: 0.9402 | Val Loss: 0.2222 Acc: 0.9136\n",
      "Epoch 033 | Train Loss: 0.1658 Acc: 0.9330 | Val Loss: 0.1778 Acc: 0.9257\n",
      "Epoch 034 | Train Loss: 0.1498 Acc: 0.9441 | Val Loss: 0.1869 Acc: 0.9185\n",
      "Epoch 035 | Train Loss: 0.1381 Acc: 0.9469 | Val Loss: 0.1619 Acc: 0.9300\n",
      "Epoch 036 | Train Loss: 0.1345 Acc: 0.9485 | Val Loss: 0.1978 Acc: 0.9239\n",
      "Epoch 037 | Train Loss: 0.1396 Acc: 0.9462 | Val Loss: 0.1530 Acc: 0.9330\n",
      "Epoch 038 | Train Loss: 0.1202 Acc: 0.9518 | Val Loss: 0.2109 Acc: 0.9149\n",
      "Epoch 039 | Train Loss: 0.1314 Acc: 0.9499 | Val Loss: 0.1512 Acc: 0.9396\n",
      "Epoch 040 | Train Loss: 0.1271 Acc: 0.9517 | Val Loss: 0.1583 Acc: 0.9336\n",
      "Epoch 041 | Train Loss: 0.1098 Acc: 0.9589 | Val Loss: 0.1487 Acc: 0.9450\n",
      "Epoch 042 | Train Loss: 0.1082 Acc: 0.9594 | Val Loss: 0.1677 Acc: 0.9384\n",
      "Epoch 043 | Train Loss: 0.1142 Acc: 0.9556 | Val Loss: 0.1412 Acc: 0.9481\n",
      "Epoch 044 | Train Loss: 0.1114 Acc: 0.9577 | Val Loss: 0.1594 Acc: 0.9414\n",
      "Epoch 045 | Train Loss: 0.1066 Acc: 0.9586 | Val Loss: 0.1693 Acc: 0.9360\n",
      "Epoch 046 | Train Loss: 0.1050 Acc: 0.9595 | Val Loss: 0.1474 Acc: 0.9426\n",
      "Epoch 047 | Train Loss: 0.1014 Acc: 0.9591 | Val Loss: 0.1666 Acc: 0.9312\n",
      "Epoch 048 | Train Loss: 0.1011 Acc: 0.9604 | Val Loss: 0.1654 Acc: 0.9414\n",
      "Epoch 049 | Train Loss: 0.1027 Acc: 0.9607 | Val Loss: 0.1393 Acc: 0.9463\n",
      "Epoch 050 | Train Loss: 0.0857 Acc: 0.9659 | Val Loss: 0.1524 Acc: 0.9450\n",
      "Epoch 051 | Train Loss: 0.0981 Acc: 0.9616 | Val Loss: 0.1445 Acc: 0.9481\n",
      "Epoch 052 | Train Loss: 0.1019 Acc: 0.9621 | Val Loss: 0.1371 Acc: 0.9511\n",
      "Epoch 053 | Train Loss: 0.0878 Acc: 0.9653 | Val Loss: 0.1297 Acc: 0.9523\n",
      "Epoch 054 | Train Loss: 0.0774 Acc: 0.9731 | Val Loss: 0.1635 Acc: 0.9414\n",
      "Epoch 055 | Train Loss: 0.0834 Acc: 0.9687 | Val Loss: 0.1606 Acc: 0.9384\n",
      "Epoch 056 | Train Loss: 0.0826 Acc: 0.9672 | Val Loss: 0.1636 Acc: 0.9360\n",
      "Epoch 057 | Train Loss: 0.0862 Acc: 0.9677 | Val Loss: 0.1459 Acc: 0.9487\n",
      "Epoch 058 | Train Loss: 0.0840 Acc: 0.9683 | Val Loss: 0.1478 Acc: 0.9469\n",
      "Epoch 059 | Train Loss: 0.0755 Acc: 0.9693 | Val Loss: 0.1429 Acc: 0.9499\n",
      "Epoch 060 | Train Loss: 0.0751 Acc: 0.9716 | Val Loss: 0.1512 Acc: 0.9463\n",
      "Epoch 001 | Train Loss: 0.6793 Acc: 0.5801 | Val Loss: 0.6748 Acc: 0.5888\n",
      "Epoch 002 | Train Loss: 0.6704 Acc: 0.5963 | Val Loss: 0.6619 Acc: 0.6021\n",
      "Epoch 003 | Train Loss: 0.6473 Acc: 0.6210 | Val Loss: 0.6290 Acc: 0.6540\n",
      "Epoch 004 | Train Loss: 0.6167 Acc: 0.6742 | Val Loss: 0.6001 Acc: 0.6854\n",
      "Epoch 005 | Train Loss: 0.5951 Acc: 0.6872 | Val Loss: 0.5807 Acc: 0.6975\n",
      "Epoch 006 | Train Loss: 0.5679 Acc: 0.7151 | Val Loss: 0.5642 Acc: 0.7071\n",
      "Epoch 007 | Train Loss: 0.5541 Acc: 0.7266 | Val Loss: 0.5966 Acc: 0.6884\n",
      "Epoch 008 | Train Loss: 0.5455 Acc: 0.7315 | Val Loss: 0.5528 Acc: 0.7192\n",
      "Epoch 009 | Train Loss: 0.5231 Acc: 0.7439 | Val Loss: 0.5172 Acc: 0.7421\n",
      "Epoch 010 | Train Loss: 0.5071 Acc: 0.7577 | Val Loss: 0.5099 Acc: 0.7452\n",
      "Epoch 011 | Train Loss: 0.5056 Acc: 0.7586 | Val Loss: 0.4950 Acc: 0.7554\n",
      "Epoch 012 | Train Loss: 0.4743 Acc: 0.7747 | Val Loss: 0.4717 Acc: 0.7742\n",
      "Epoch 013 | Train Loss: 0.4522 Acc: 0.7915 | Val Loss: 0.4474 Acc: 0.7784\n",
      "Epoch 014 | Train Loss: 0.4390 Acc: 0.7947 | Val Loss: 0.4222 Acc: 0.8019\n",
      "Epoch 015 | Train Loss: 0.4215 Acc: 0.8033 | Val Loss: 0.4099 Acc: 0.8025\n",
      "Epoch 016 | Train Loss: 0.3916 Acc: 0.8229 | Val Loss: 0.3805 Acc: 0.8200\n",
      "Epoch 017 | Train Loss: 0.3768 Acc: 0.8329 | Val Loss: 0.3615 Acc: 0.8285\n",
      "Epoch 018 | Train Loss: 0.3614 Acc: 0.8319 | Val Loss: 0.3444 Acc: 0.8454\n",
      "Epoch 019 | Train Loss: 0.3366 Acc: 0.8477 | Val Loss: 0.3892 Acc: 0.8219\n",
      "Epoch 020 | Train Loss: 0.3218 Acc: 0.8599 | Val Loss: 0.3069 Acc: 0.8617\n",
      "Epoch 021 | Train Loss: 0.2966 Acc: 0.8756 | Val Loss: 0.3031 Acc: 0.8690\n",
      "Epoch 022 | Train Loss: 0.2764 Acc: 0.8831 | Val Loss: 0.2869 Acc: 0.8762\n",
      "Epoch 023 | Train Loss: 0.2584 Acc: 0.8919 | Val Loss: 0.2964 Acc: 0.8768\n",
      "Epoch 024 | Train Loss: 0.2536 Acc: 0.8910 | Val Loss: 0.2910 Acc: 0.8720\n",
      "Epoch 025 | Train Loss: 0.2354 Acc: 0.9031 | Val Loss: 0.2487 Acc: 0.9022\n",
      "Epoch 026 | Train Loss: 0.2109 Acc: 0.9127 | Val Loss: 0.2959 Acc: 0.8744\n",
      "Epoch 027 | Train Loss: 0.2122 Acc: 0.9154 | Val Loss: 0.2958 Acc: 0.8720\n",
      "Epoch 028 | Train Loss: 0.2040 Acc: 0.9213 | Val Loss: 0.2405 Acc: 0.8986\n",
      "Epoch 029 | Train Loss: 0.1832 Acc: 0.9271 | Val Loss: 0.2420 Acc: 0.9082\n",
      "Epoch 030 | Train Loss: 0.1831 Acc: 0.9268 | Val Loss: 0.2317 Acc: 0.9124\n",
      "Epoch 031 | Train Loss: 0.1798 Acc: 0.9284 | Val Loss: 0.2323 Acc: 0.8998\n",
      "Epoch 032 | Train Loss: 0.1774 Acc: 0.9284 | Val Loss: 0.2065 Acc: 0.9173\n",
      "Epoch 033 | Train Loss: 0.1543 Acc: 0.9372 | Val Loss: 0.1859 Acc: 0.9269\n",
      "Epoch 034 | Train Loss: 0.1527 Acc: 0.9411 | Val Loss: 0.2183 Acc: 0.9136\n",
      "Epoch 035 | Train Loss: 0.1405 Acc: 0.9449 | Val Loss: 0.1986 Acc: 0.9239\n",
      "Epoch 036 | Train Loss: 0.1412 Acc: 0.9423 | Val Loss: 0.2157 Acc: 0.9106\n",
      "Epoch 037 | Train Loss: 0.1331 Acc: 0.9491 | Val Loss: 0.1703 Acc: 0.9342\n",
      "Epoch 038 | Train Loss: 0.1220 Acc: 0.9541 | Val Loss: 0.1776 Acc: 0.9281\n",
      "Epoch 039 | Train Loss: 0.1191 Acc: 0.9530 | Val Loss: 0.1735 Acc: 0.9281\n",
      "Epoch 040 | Train Loss: 0.1209 Acc: 0.9583 | Val Loss: 0.1989 Acc: 0.9281\n",
      "Epoch 041 | Train Loss: 0.1023 Acc: 0.9651 | Val Loss: 0.1798 Acc: 0.9342\n",
      "Epoch 042 | Train Loss: 0.1036 Acc: 0.9603 | Val Loss: 0.1868 Acc: 0.9287\n",
      "Epoch 043 | Train Loss: 0.1202 Acc: 0.9524 | Val Loss: 0.1627 Acc: 0.9384\n",
      "Epoch 044 | Train Loss: 0.0972 Acc: 0.9630 | Val Loss: 0.1832 Acc: 0.9312\n",
      "Epoch 045 | Train Loss: 0.0857 Acc: 0.9680 | Val Loss: 0.1740 Acc: 0.9390\n",
      "Epoch 046 | Train Loss: 0.0975 Acc: 0.9648 | Val Loss: 0.1743 Acc: 0.9342\n",
      "Epoch 047 | Train Loss: 0.0831 Acc: 0.9690 | Val Loss: 0.1766 Acc: 0.9378\n",
      "Epoch 048 | Train Loss: 0.0759 Acc: 0.9737 | Val Loss: 0.2068 Acc: 0.9330\n",
      "Epoch 049 | Train Loss: 0.0842 Acc: 0.9663 | Val Loss: 0.1430 Acc: 0.9463\n",
      "Epoch 050 | Train Loss: 0.0929 Acc: 0.9662 | Val Loss: 0.1541 Acc: 0.9408\n",
      "Epoch 051 | Train Loss: 0.0815 Acc: 0.9715 | Val Loss: 0.1575 Acc: 0.9469\n",
      "Epoch 052 | Train Loss: 0.0727 Acc: 0.9716 | Val Loss: 0.1685 Acc: 0.9408\n",
      "Epoch 053 | Train Loss: 0.0768 Acc: 0.9736 | Val Loss: 0.1516 Acc: 0.9469\n",
      "Epoch 054 | Train Loss: 0.0747 Acc: 0.9734 | Val Loss: 0.1562 Acc: 0.9469\n",
      "Epoch 055 | Train Loss: 0.0792 Acc: 0.9700 | Val Loss: 0.1485 Acc: 0.9414\n",
      "Epoch 056 | Train Loss: 0.0625 Acc: 0.9749 | Val Loss: 0.1852 Acc: 0.9342\n",
      "Epoch 057 | Train Loss: 0.0700 Acc: 0.9725 | Val Loss: 0.1700 Acc: 0.9408\n",
      "Epoch 058 | Train Loss: 0.0726 Acc: 0.9703 | Val Loss: 0.1456 Acc: 0.9463\n",
      "Epoch 059 | Train Loss: 0.0680 Acc: 0.9754 | Val Loss: 0.1489 Acc: 0.9450\n",
      "Early stopping triggered.\n",
      "Epoch 001 | Train Loss: 0.6810 Acc: 0.5796 | Val Loss: 0.6746 Acc: 0.5906\n",
      "Epoch 002 | Train Loss: 0.6681 Acc: 0.6011 | Val Loss: 0.6713 Acc: 0.5876\n",
      "Epoch 003 | Train Loss: 0.6644 Acc: 0.6044 | Val Loss: 0.6616 Acc: 0.6027\n",
      "Epoch 004 | Train Loss: 0.6532 Acc: 0.6136 | Val Loss: 0.6212 Acc: 0.6691\n",
      "Epoch 005 | Train Loss: 0.6064 Acc: 0.6834 | Val Loss: 0.5914 Acc: 0.6999\n",
      "Epoch 006 | Train Loss: 0.5693 Acc: 0.7204 | Val Loss: 0.5747 Acc: 0.7035\n",
      "Epoch 007 | Train Loss: 0.5425 Acc: 0.7358 | Val Loss: 0.5613 Acc: 0.7228\n",
      "Epoch 008 | Train Loss: 0.5201 Acc: 0.7480 | Val Loss: 0.5209 Acc: 0.7391\n",
      "Epoch 009 | Train Loss: 0.5049 Acc: 0.7625 | Val Loss: 0.4974 Acc: 0.7506\n",
      "Epoch 010 | Train Loss: 0.4819 Acc: 0.7749 | Val Loss: 0.4780 Acc: 0.7585\n",
      "Epoch 011 | Train Loss: 0.4607 Acc: 0.7888 | Val Loss: 0.4816 Acc: 0.7711\n",
      "Epoch 012 | Train Loss: 0.4375 Acc: 0.8051 | Val Loss: 0.4564 Acc: 0.7772\n",
      "Epoch 013 | Train Loss: 0.4308 Acc: 0.7995 | Val Loss: 0.4375 Acc: 0.7874\n",
      "Epoch 014 | Train Loss: 0.4135 Acc: 0.8108 | Val Loss: 0.4067 Acc: 0.8122\n",
      "Epoch 015 | Train Loss: 0.3860 Acc: 0.8258 | Val Loss: 0.3771 Acc: 0.8267\n",
      "Epoch 016 | Train Loss: 0.3692 Acc: 0.8407 | Val Loss: 0.3763 Acc: 0.8273\n",
      "Epoch 017 | Train Loss: 0.3633 Acc: 0.8410 | Val Loss: 0.3413 Acc: 0.8478\n",
      "Epoch 018 | Train Loss: 0.3461 Acc: 0.8464 | Val Loss: 0.3330 Acc: 0.8430\n",
      "Epoch 019 | Train Loss: 0.3306 Acc: 0.8560 | Val Loss: 0.3466 Acc: 0.8406\n",
      "Epoch 020 | Train Loss: 0.3117 Acc: 0.8671 | Val Loss: 0.2931 Acc: 0.8720\n",
      "Epoch 021 | Train Loss: 0.2956 Acc: 0.8714 | Val Loss: 0.3002 Acc: 0.8623\n",
      "Epoch 022 | Train Loss: 0.2739 Acc: 0.8848 | Val Loss: 0.2706 Acc: 0.8913\n",
      "Epoch 023 | Train Loss: 0.2569 Acc: 0.8902 | Val Loss: 0.2900 Acc: 0.8786\n",
      "Epoch 024 | Train Loss: 0.2552 Acc: 0.8976 | Val Loss: 0.2401 Acc: 0.9022\n",
      "Epoch 025 | Train Loss: 0.2476 Acc: 0.8993 | Val Loss: 0.2397 Acc: 0.8949\n",
      "Epoch 026 | Train Loss: 0.2293 Acc: 0.9067 | Val Loss: 0.2436 Acc: 0.9010\n",
      "Epoch 027 | Train Loss: 0.2310 Acc: 0.9091 | Val Loss: 0.2442 Acc: 0.8967\n",
      "Epoch 028 | Train Loss: 0.2142 Acc: 0.9144 | Val Loss: 0.2183 Acc: 0.9058\n",
      "Epoch 029 | Train Loss: 0.1957 Acc: 0.9222 | Val Loss: 0.2247 Acc: 0.9076\n",
      "Epoch 030 | Train Loss: 0.1987 Acc: 0.9212 | Val Loss: 0.2083 Acc: 0.9227\n",
      "Epoch 031 | Train Loss: 0.1921 Acc: 0.9227 | Val Loss: 0.1906 Acc: 0.9233\n",
      "Epoch 032 | Train Loss: 0.1777 Acc: 0.9310 | Val Loss: 0.1994 Acc: 0.9203\n",
      "Epoch 033 | Train Loss: 0.1675 Acc: 0.9346 | Val Loss: 0.2298 Acc: 0.9058\n",
      "Epoch 034 | Train Loss: 0.1752 Acc: 0.9316 | Val Loss: 0.1904 Acc: 0.9239\n",
      "Epoch 035 | Train Loss: 0.1648 Acc: 0.9376 | Val Loss: 0.2099 Acc: 0.9161\n",
      "Epoch 036 | Train Loss: 0.1542 Acc: 0.9413 | Val Loss: 0.1961 Acc: 0.9197\n",
      "Epoch 037 | Train Loss: 0.1497 Acc: 0.9432 | Val Loss: 0.1951 Acc: 0.9185\n",
      "Epoch 038 | Train Loss: 0.1504 Acc: 0.9405 | Val Loss: 0.2049 Acc: 0.9203\n",
      "Epoch 039 | Train Loss: 0.1420 Acc: 0.9465 | Val Loss: 0.1856 Acc: 0.9269\n",
      "Epoch 040 | Train Loss: 0.1373 Acc: 0.9473 | Val Loss: 0.1767 Acc: 0.9275\n",
      "Epoch 041 | Train Loss: 0.1300 Acc: 0.9488 | Val Loss: 0.1754 Acc: 0.9342\n",
      "Epoch 042 | Train Loss: 0.1332 Acc: 0.9479 | Val Loss: 0.1889 Acc: 0.9269\n",
      "Epoch 043 | Train Loss: 0.1417 Acc: 0.9452 | Val Loss: 0.1960 Acc: 0.9245\n",
      "Epoch 044 | Train Loss: 0.1348 Acc: 0.9515 | Val Loss: 0.1922 Acc: 0.9306\n",
      "Epoch 045 | Train Loss: 0.1202 Acc: 0.9567 | Val Loss: 0.1668 Acc: 0.9348\n",
      "Epoch 046 | Train Loss: 0.1276 Acc: 0.9517 | Val Loss: 0.1415 Acc: 0.9499\n",
      "Epoch 047 | Train Loss: 0.1301 Acc: 0.9503 | Val Loss: 0.2073 Acc: 0.9209\n",
      "Epoch 048 | Train Loss: 0.1182 Acc: 0.9533 | Val Loss: 0.1842 Acc: 0.9300\n",
      "Epoch 049 | Train Loss: 0.1058 Acc: 0.9610 | Val Loss: 0.1714 Acc: 0.9372\n",
      "Epoch 050 | Train Loss: 0.1128 Acc: 0.9553 | Val Loss: 0.1668 Acc: 0.9330\n",
      "Epoch 051 | Train Loss: 0.1091 Acc: 0.9589 | Val Loss: 0.1453 Acc: 0.9420\n",
      "Epoch 052 | Train Loss: 0.1151 Acc: 0.9570 | Val Loss: 0.1451 Acc: 0.9420\n",
      "Epoch 053 | Train Loss: 0.0945 Acc: 0.9660 | Val Loss: 0.1657 Acc: 0.9324\n",
      "Epoch 054 | Train Loss: 0.0931 Acc: 0.9638 | Val Loss: 0.1644 Acc: 0.9384\n",
      "Epoch 055 | Train Loss: 0.0975 Acc: 0.9629 | Val Loss: 0.1771 Acc: 0.9324\n",
      "Epoch 056 | Train Loss: 0.0979 Acc: 0.9621 | Val Loss: 0.1912 Acc: 0.9336\n",
      "Early stopping triggered.\n",
      "Epoch 001 | Train Loss: 0.6834 Acc: 0.5729 | Val Loss: 0.6804 Acc: 0.5821\n",
      "Epoch 002 | Train Loss: 0.6750 Acc: 0.5870 | Val Loss: 0.6760 Acc: 0.5827\n",
      "Epoch 003 | Train Loss: 0.6666 Acc: 0.5966 | Val Loss: 0.6494 Acc: 0.6033\n",
      "Epoch 004 | Train Loss: 0.6182 Acc: 0.6639 | Val Loss: 0.5986 Acc: 0.6926\n",
      "Epoch 005 | Train Loss: 0.5707 Acc: 0.7180 | Val Loss: 0.5674 Acc: 0.7144\n",
      "Epoch 006 | Train Loss: 0.5393 Acc: 0.7385 | Val Loss: 0.5180 Acc: 0.7518\n",
      "Epoch 007 | Train Loss: 0.5067 Acc: 0.7608 | Val Loss: 0.5119 Acc: 0.7548\n",
      "Epoch 008 | Train Loss: 0.4867 Acc: 0.7726 | Val Loss: 0.4950 Acc: 0.7506\n",
      "Epoch 009 | Train Loss: 0.4632 Acc: 0.7835 | Val Loss: 0.4536 Acc: 0.7802\n",
      "Epoch 010 | Train Loss: 0.4368 Acc: 0.7983 | Val Loss: 0.4497 Acc: 0.7911\n",
      "Epoch 011 | Train Loss: 0.4100 Acc: 0.8153 | Val Loss: 0.4058 Acc: 0.8086\n",
      "Epoch 012 | Train Loss: 0.3840 Acc: 0.8295 | Val Loss: 0.3774 Acc: 0.8237\n",
      "Epoch 013 | Train Loss: 0.3680 Acc: 0.8424 | Val Loss: 0.3573 Acc: 0.8339\n",
      "Epoch 014 | Train Loss: 0.3350 Acc: 0.8575 | Val Loss: 0.3633 Acc: 0.8309\n",
      "Epoch 015 | Train Loss: 0.3239 Acc: 0.8576 | Val Loss: 0.3029 Acc: 0.8629\n",
      "Epoch 016 | Train Loss: 0.2822 Acc: 0.8785 | Val Loss: 0.3124 Acc: 0.8629\n",
      "Epoch 017 | Train Loss: 0.2672 Acc: 0.8902 | Val Loss: 0.2760 Acc: 0.8816\n",
      "Epoch 018 | Train Loss: 0.2440 Acc: 0.9008 | Val Loss: 0.2919 Acc: 0.8708\n",
      "Epoch 019 | Train Loss: 0.2288 Acc: 0.9074 | Val Loss: 0.2642 Acc: 0.8895\n",
      "Epoch 020 | Train Loss: 0.2145 Acc: 0.9132 | Val Loss: 0.2453 Acc: 0.8992\n",
      "Epoch 021 | Train Loss: 0.2165 Acc: 0.9153 | Val Loss: 0.2659 Acc: 0.8816\n",
      "Epoch 022 | Train Loss: 0.2027 Acc: 0.9200 | Val Loss: 0.2275 Acc: 0.9070\n",
      "Epoch 023 | Train Loss: 0.1937 Acc: 0.9244 | Val Loss: 0.2324 Acc: 0.9040\n",
      "Epoch 024 | Train Loss: 0.1710 Acc: 0.9336 | Val Loss: 0.2143 Acc: 0.9094\n",
      "Epoch 025 | Train Loss: 0.1610 Acc: 0.9364 | Val Loss: 0.2444 Acc: 0.9022\n",
      "Epoch 026 | Train Loss: 0.1517 Acc: 0.9422 | Val Loss: 0.1947 Acc: 0.9191\n",
      "Epoch 027 | Train Loss: 0.1398 Acc: 0.9481 | Val Loss: 0.2294 Acc: 0.9149\n",
      "Epoch 028 | Train Loss: 0.1416 Acc: 0.9446 | Val Loss: 0.1949 Acc: 0.9227\n",
      "Epoch 029 | Train Loss: 0.1267 Acc: 0.9550 | Val Loss: 0.2029 Acc: 0.9185\n",
      "Epoch 030 | Train Loss: 0.1193 Acc: 0.9532 | Val Loss: 0.2741 Acc: 0.9088\n",
      "Epoch 031 | Train Loss: 0.1162 Acc: 0.9568 | Val Loss: 0.2273 Acc: 0.9173\n",
      "Epoch 032 | Train Loss: 0.1178 Acc: 0.9573 | Val Loss: 0.2200 Acc: 0.9215\n",
      "Epoch 033 | Train Loss: 0.1109 Acc: 0.9576 | Val Loss: 0.1966 Acc: 0.9221\n",
      "Epoch 034 | Train Loss: 0.0972 Acc: 0.9620 | Val Loss: 0.2394 Acc: 0.9239\n",
      "Epoch 035 | Train Loss: 0.1031 Acc: 0.9627 | Val Loss: 0.1770 Acc: 0.9312\n",
      "Epoch 036 | Train Loss: 0.0952 Acc: 0.9642 | Val Loss: 0.1824 Acc: 0.9336\n",
      "Epoch 037 | Train Loss: 0.0986 Acc: 0.9616 | Val Loss: 0.2100 Acc: 0.9076\n",
      "Epoch 038 | Train Loss: 0.0912 Acc: 0.9642 | Val Loss: 0.1866 Acc: 0.9306\n",
      "Epoch 039 | Train Loss: 0.0849 Acc: 0.9687 | Val Loss: 0.1966 Acc: 0.9287\n",
      "Epoch 040 | Train Loss: 0.0802 Acc: 0.9719 | Val Loss: 0.1751 Acc: 0.9312\n",
      "Epoch 041 | Train Loss: 0.0837 Acc: 0.9684 | Val Loss: 0.2511 Acc: 0.9161\n",
      "Epoch 042 | Train Loss: 0.0813 Acc: 0.9725 | Val Loss: 0.1916 Acc: 0.9324\n",
      "Epoch 043 | Train Loss: 0.0843 Acc: 0.9693 | Val Loss: 0.1682 Acc: 0.9378\n",
      "Epoch 044 | Train Loss: 0.0667 Acc: 0.9764 | Val Loss: 0.1750 Acc: 0.9378\n",
      "Epoch 045 | Train Loss: 0.0667 Acc: 0.9775 | Val Loss: 0.1652 Acc: 0.9390\n",
      "Epoch 046 | Train Loss: 0.0725 Acc: 0.9733 | Val Loss: 0.1611 Acc: 0.9384\n",
      "Epoch 047 | Train Loss: 0.0642 Acc: 0.9763 | Val Loss: 0.2050 Acc: 0.9306\n",
      "Epoch 048 | Train Loss: 0.0657 Acc: 0.9761 | Val Loss: 0.2374 Acc: 0.9257\n",
      "Epoch 049 | Train Loss: 0.0639 Acc: 0.9760 | Val Loss: 0.1827 Acc: 0.9372\n",
      "Epoch 050 | Train Loss: 0.0660 Acc: 0.9737 | Val Loss: 0.1987 Acc: 0.9378\n",
      "Epoch 051 | Train Loss: 0.0645 Acc: 0.9758 | Val Loss: 0.1618 Acc: 0.9414\n",
      "Epoch 052 | Train Loss: 0.0767 Acc: 0.9710 | Val Loss: 0.1654 Acc: 0.9360\n",
      "Epoch 053 | Train Loss: 0.0607 Acc: 0.9764 | Val Loss: 0.1697 Acc: 0.9438\n",
      "Epoch 054 | Train Loss: 0.0580 Acc: 0.9787 | Val Loss: 0.2315 Acc: 0.9281\n",
      "Epoch 055 | Train Loss: 0.0547 Acc: 0.9810 | Val Loss: 0.1839 Acc: 0.9293\n",
      "Epoch 056 | Train Loss: 0.0533 Acc: 0.9810 | Val Loss: 0.2060 Acc: 0.9324\n",
      "Early stopping triggered.\n",
      "Epoch 001 | Train Loss: 0.6792 Acc: 0.5834 | Val Loss: 0.6744 Acc: 0.5894\n",
      "Epoch 002 | Train Loss: 0.6720 Acc: 0.5953 | Val Loss: 0.6766 Acc: 0.5767\n",
      "Epoch 003 | Train Loss: 0.6360 Acc: 0.6437 | Val Loss: 0.6097 Acc: 0.6751\n",
      "Epoch 004 | Train Loss: 0.5877 Acc: 0.6979 | Val Loss: 0.5708 Acc: 0.7180\n",
      "Epoch 005 | Train Loss: 0.5456 Acc: 0.7314 | Val Loss: 0.5619 Acc: 0.7114\n",
      "Epoch 006 | Train Loss: 0.5259 Acc: 0.7510 | Val Loss: 0.5157 Acc: 0.7434\n",
      "Epoch 007 | Train Loss: 0.4843 Acc: 0.7702 | Val Loss: 0.5200 Acc: 0.7361\n",
      "Epoch 008 | Train Loss: 0.4765 Acc: 0.7708 | Val Loss: 0.4584 Acc: 0.7886\n",
      "Epoch 009 | Train Loss: 0.4458 Acc: 0.7925 | Val Loss: 0.4368 Acc: 0.7929\n",
      "Epoch 010 | Train Loss: 0.4179 Acc: 0.8037 | Val Loss: 0.4287 Acc: 0.7905\n",
      "Epoch 011 | Train Loss: 0.3907 Acc: 0.8244 | Val Loss: 0.3994 Acc: 0.8207\n",
      "Epoch 012 | Train Loss: 0.3583 Acc: 0.8416 | Val Loss: 0.3360 Acc: 0.8533\n",
      "Epoch 013 | Train Loss: 0.3238 Acc: 0.8614 | Val Loss: 0.3189 Acc: 0.8496\n",
      "Epoch 014 | Train Loss: 0.3123 Acc: 0.8668 | Val Loss: 0.3312 Acc: 0.8581\n",
      "Epoch 015 | Train Loss: 0.2871 Acc: 0.8813 | Val Loss: 0.2883 Acc: 0.8792\n",
      "Epoch 016 | Train Loss: 0.2618 Acc: 0.8934 | Val Loss: 0.2791 Acc: 0.8804\n",
      "Epoch 017 | Train Loss: 0.2528 Acc: 0.8985 | Val Loss: 0.3068 Acc: 0.8744\n",
      "Epoch 018 | Train Loss: 0.2294 Acc: 0.9076 | Val Loss: 0.2765 Acc: 0.8835\n",
      "Epoch 019 | Train Loss: 0.2092 Acc: 0.9189 | Val Loss: 0.2292 Acc: 0.9058\n",
      "Epoch 020 | Train Loss: 0.2007 Acc: 0.9203 | Val Loss: 0.2204 Acc: 0.9076\n",
      "Epoch 021 | Train Loss: 0.1745 Acc: 0.9287 | Val Loss: 0.2241 Acc: 0.9112\n",
      "Epoch 022 | Train Loss: 0.1729 Acc: 0.9292 | Val Loss: 0.2550 Acc: 0.9040\n",
      "Epoch 023 | Train Loss: 0.1667 Acc: 0.9340 | Val Loss: 0.2166 Acc: 0.9106\n",
      "Epoch 024 | Train Loss: 0.1500 Acc: 0.9422 | Val Loss: 0.2059 Acc: 0.9191\n",
      "Epoch 025 | Train Loss: 0.1393 Acc: 0.9444 | Val Loss: 0.2221 Acc: 0.9149\n",
      "Epoch 026 | Train Loss: 0.1280 Acc: 0.9517 | Val Loss: 0.2005 Acc: 0.9227\n",
      "Epoch 027 | Train Loss: 0.1313 Acc: 0.9491 | Val Loss: 0.2217 Acc: 0.9155\n",
      "Epoch 028 | Train Loss: 0.1164 Acc: 0.9568 | Val Loss: 0.2028 Acc: 0.9245\n",
      "Epoch 029 | Train Loss: 0.1294 Acc: 0.9506 | Val Loss: 0.2005 Acc: 0.9215\n",
      "Epoch 030 | Train Loss: 0.1083 Acc: 0.9589 | Val Loss: 0.1836 Acc: 0.9275\n",
      "Epoch 031 | Train Loss: 0.1025 Acc: 0.9606 | Val Loss: 0.1898 Acc: 0.9293\n",
      "Epoch 032 | Train Loss: 0.1007 Acc: 0.9620 | Val Loss: 0.2153 Acc: 0.9191\n",
      "Epoch 033 | Train Loss: 0.1028 Acc: 0.9638 | Val Loss: 0.1791 Acc: 0.9300\n",
      "Epoch 034 | Train Loss: 0.0957 Acc: 0.9644 | Val Loss: 0.1788 Acc: 0.9360\n",
      "Epoch 035 | Train Loss: 0.0854 Acc: 0.9675 | Val Loss: 0.2072 Acc: 0.9300\n",
      "Epoch 036 | Train Loss: 0.0845 Acc: 0.9684 | Val Loss: 0.1892 Acc: 0.9306\n",
      "Epoch 037 | Train Loss: 0.0893 Acc: 0.9666 | Val Loss: 0.2064 Acc: 0.9155\n",
      "Epoch 038 | Train Loss: 0.1017 Acc: 0.9603 | Val Loss: 0.1741 Acc: 0.9366\n",
      "Epoch 039 | Train Loss: 0.0807 Acc: 0.9692 | Val Loss: 0.1595 Acc: 0.9396\n",
      "Epoch 040 | Train Loss: 0.0742 Acc: 0.9730 | Val Loss: 0.1846 Acc: 0.9384\n",
      "Epoch 041 | Train Loss: 0.0747 Acc: 0.9736 | Val Loss: 0.1581 Acc: 0.9457\n",
      "Epoch 042 | Train Loss: 0.0787 Acc: 0.9701 | Val Loss: 0.1501 Acc: 0.9481\n",
      "Epoch 043 | Train Loss: 0.0655 Acc: 0.9757 | Val Loss: 0.1806 Acc: 0.9378\n",
      "Epoch 044 | Train Loss: 0.0700 Acc: 0.9734 | Val Loss: 0.1715 Acc: 0.9396\n",
      "Epoch 045 | Train Loss: 0.0531 Acc: 0.9817 | Val Loss: 0.1930 Acc: 0.9384\n",
      "Epoch 046 | Train Loss: 0.0763 Acc: 0.9718 | Val Loss: 0.1737 Acc: 0.9372\n",
      "Epoch 047 | Train Loss: 0.0681 Acc: 0.9749 | Val Loss: 0.1839 Acc: 0.9402\n",
      "Epoch 048 | Train Loss: 0.0691 Acc: 0.9751 | Val Loss: 0.1970 Acc: 0.9348\n",
      "Epoch 049 | Train Loss: 0.0651 Acc: 0.9743 | Val Loss: 0.1639 Acc: 0.9432\n",
      "Epoch 050 | Train Loss: 0.0597 Acc: 0.9790 | Val Loss: 0.1673 Acc: 0.9420\n",
      "Epoch 051 | Train Loss: 0.0523 Acc: 0.9799 | Val Loss: 0.1961 Acc: 0.9378\n",
      "Epoch 052 | Train Loss: 0.0582 Acc: 0.9816 | Val Loss: 0.1642 Acc: 0.9396\n",
      "Early stopping triggered.\n",
      "Iteration 39/40 | Best Val Loss: 0.1122 | Iter Time: 225.10s | Total Time: 157.14 min\n",
      "Epoch 001 | Train Loss: 0.6824 Acc: 0.5744 | Val Loss: 0.6764 Acc: 0.5851\n",
      "Epoch 002 | Train Loss: 0.6751 Acc: 0.5884 | Val Loss: 0.6725 Acc: 0.5755\n",
      "Epoch 003 | Train Loss: 0.6434 Acc: 0.6334 | Val Loss: 0.6159 Acc: 0.6655\n",
      "Epoch 004 | Train Loss: 0.5998 Acc: 0.6918 | Val Loss: 0.5922 Acc: 0.6812\n",
      "Epoch 005 | Train Loss: 0.5657 Acc: 0.7158 | Val Loss: 0.5524 Acc: 0.7271\n",
      "Epoch 006 | Train Loss: 0.5377 Acc: 0.7376 | Val Loss: 0.5694 Acc: 0.6902\n",
      "Epoch 007 | Train Loss: 0.5171 Acc: 0.7530 | Val Loss: 0.5117 Acc: 0.7500\n",
      "Epoch 008 | Train Loss: 0.5057 Acc: 0.7555 | Val Loss: 0.4954 Acc: 0.7609\n",
      "Epoch 009 | Train Loss: 0.4846 Acc: 0.7720 | Val Loss: 0.4986 Acc: 0.7560\n",
      "Epoch 010 | Train Loss: 0.4594 Acc: 0.7812 | Val Loss: 0.4377 Acc: 0.7947\n",
      "Epoch 011 | Train Loss: 0.4454 Acc: 0.7913 | Val Loss: 0.4333 Acc: 0.7941\n",
      "Epoch 012 | Train Loss: 0.4268 Acc: 0.8033 | Val Loss: 0.3993 Acc: 0.8068\n",
      "Epoch 013 | Train Loss: 0.4177 Acc: 0.8095 | Val Loss: 0.4191 Acc: 0.7989\n",
      "Epoch 014 | Train Loss: 0.3907 Acc: 0.8253 | Val Loss: 0.3702 Acc: 0.8255\n",
      "Epoch 015 | Train Loss: 0.3671 Acc: 0.8401 | Val Loss: 0.3530 Acc: 0.8357\n",
      "Epoch 016 | Train Loss: 0.3462 Acc: 0.8480 | Val Loss: 0.3282 Acc: 0.8490\n",
      "Epoch 017 | Train Loss: 0.3335 Acc: 0.8599 | Val Loss: 0.3421 Acc: 0.8430\n",
      "Epoch 018 | Train Loss: 0.3139 Acc: 0.8647 | Val Loss: 0.2950 Acc: 0.8696\n",
      "Epoch 019 | Train Loss: 0.2910 Acc: 0.8768 | Val Loss: 0.3049 Acc: 0.8659\n",
      "Epoch 020 | Train Loss: 0.2815 Acc: 0.8889 | Val Loss: 0.2640 Acc: 0.8883\n",
      "Epoch 021 | Train Loss: 0.2622 Acc: 0.8895 | Val Loss: 0.2485 Acc: 0.8979\n",
      "Epoch 022 | Train Loss: 0.2490 Acc: 0.8994 | Val Loss: 0.2680 Acc: 0.8913\n",
      "Epoch 023 | Train Loss: 0.2515 Acc: 0.8958 | Val Loss: 0.2282 Acc: 0.9028\n",
      "Epoch 024 | Train Loss: 0.2373 Acc: 0.9031 | Val Loss: 0.2544 Acc: 0.8967\n",
      "Epoch 025 | Train Loss: 0.2188 Acc: 0.9121 | Val Loss: 0.2411 Acc: 0.8955\n",
      "Epoch 026 | Train Loss: 0.2114 Acc: 0.9159 | Val Loss: 0.2325 Acc: 0.9022\n",
      "Epoch 027 | Train Loss: 0.1980 Acc: 0.9230 | Val Loss: 0.2198 Acc: 0.9155\n",
      "Epoch 028 | Train Loss: 0.1945 Acc: 0.9218 | Val Loss: 0.2110 Acc: 0.9161\n",
      "Epoch 029 | Train Loss: 0.1820 Acc: 0.9269 | Val Loss: 0.2111 Acc: 0.9179\n",
      "Epoch 030 | Train Loss: 0.1920 Acc: 0.9248 | Val Loss: 0.1853 Acc: 0.9251\n",
      "Epoch 031 | Train Loss: 0.1723 Acc: 0.9352 | Val Loss: 0.1755 Acc: 0.9281\n",
      "Epoch 032 | Train Loss: 0.1790 Acc: 0.9339 | Val Loss: 0.1737 Acc: 0.9342\n",
      "Epoch 033 | Train Loss: 0.1770 Acc: 0.9340 | Val Loss: 0.1725 Acc: 0.9300\n",
      "Epoch 034 | Train Loss: 0.1559 Acc: 0.9399 | Val Loss: 0.1695 Acc: 0.9306\n",
      "Epoch 035 | Train Loss: 0.1608 Acc: 0.9372 | Val Loss: 0.1757 Acc: 0.9318\n",
      "Epoch 036 | Train Loss: 0.1559 Acc: 0.9408 | Val Loss: 0.1696 Acc: 0.9318\n",
      "Epoch 037 | Train Loss: 0.1617 Acc: 0.9390 | Val Loss: 0.2041 Acc: 0.9275\n",
      "Epoch 038 | Train Loss: 0.1473 Acc: 0.9449 | Val Loss: 0.1686 Acc: 0.9336\n",
      "Epoch 039 | Train Loss: 0.1382 Acc: 0.9465 | Val Loss: 0.1402 Acc: 0.9523\n",
      "Epoch 040 | Train Loss: 0.1322 Acc: 0.9481 | Val Loss: 0.1644 Acc: 0.9414\n",
      "Epoch 041 | Train Loss: 0.1417 Acc: 0.9447 | Val Loss: 0.1885 Acc: 0.9263\n",
      "Epoch 042 | Train Loss: 0.1267 Acc: 0.9538 | Val Loss: 0.1826 Acc: 0.9251\n",
      "Epoch 043 | Train Loss: 0.1256 Acc: 0.9530 | Val Loss: 0.1546 Acc: 0.9438\n",
      "Epoch 044 | Train Loss: 0.1235 Acc: 0.9549 | Val Loss: 0.1762 Acc: 0.9312\n",
      "Epoch 045 | Train Loss: 0.1237 Acc: 0.9499 | Val Loss: 0.1409 Acc: 0.9511\n",
      "Epoch 046 | Train Loss: 0.1094 Acc: 0.9561 | Val Loss: 0.1525 Acc: 0.9414\n",
      "Epoch 047 | Train Loss: 0.1089 Acc: 0.9594 | Val Loss: 0.1424 Acc: 0.9457\n",
      "Epoch 048 | Train Loss: 0.1058 Acc: 0.9606 | Val Loss: 0.1425 Acc: 0.9499\n",
      "Epoch 049 | Train Loss: 0.1033 Acc: 0.9595 | Val Loss: 0.1623 Acc: 0.9408\n",
      "Early stopping triggered.\n",
      "Epoch 001 | Train Loss: 0.6791 Acc: 0.5831 | Val Loss: 0.6714 Acc: 0.5924\n",
      "Epoch 002 | Train Loss: 0.6506 Acc: 0.6274 | Val Loss: 0.6302 Acc: 0.6455\n",
      "Epoch 003 | Train Loss: 0.5868 Acc: 0.7003 | Val Loss: 0.5771 Acc: 0.6926\n",
      "Epoch 004 | Train Loss: 0.5434 Acc: 0.7308 | Val Loss: 0.5430 Acc: 0.7240\n",
      "Epoch 005 | Train Loss: 0.5232 Acc: 0.7465 | Val Loss: 0.5325 Acc: 0.7361\n",
      "Epoch 006 | Train Loss: 0.4968 Acc: 0.7611 | Val Loss: 0.4937 Acc: 0.7609\n",
      "Epoch 007 | Train Loss: 0.4767 Acc: 0.7741 | Val Loss: 0.4768 Acc: 0.7693\n",
      "Epoch 008 | Train Loss: 0.4467 Acc: 0.7916 | Val Loss: 0.4959 Acc: 0.7621\n",
      "Epoch 009 | Train Loss: 0.4249 Acc: 0.8046 | Val Loss: 0.4499 Acc: 0.7766\n",
      "Epoch 010 | Train Loss: 0.3924 Acc: 0.8233 | Val Loss: 0.3688 Acc: 0.8291\n",
      "Epoch 011 | Train Loss: 0.3563 Acc: 0.8442 | Val Loss: 0.3422 Acc: 0.8436\n",
      "Epoch 012 | Train Loss: 0.3294 Acc: 0.8564 | Val Loss: 0.3345 Acc: 0.8454\n",
      "Epoch 013 | Train Loss: 0.3029 Acc: 0.8708 | Val Loss: 0.3018 Acc: 0.8714\n",
      "Epoch 014 | Train Loss: 0.2878 Acc: 0.8763 | Val Loss: 0.3098 Acc: 0.8708\n",
      "Epoch 015 | Train Loss: 0.2672 Acc: 0.8913 | Val Loss: 0.2890 Acc: 0.8804\n",
      "Epoch 016 | Train Loss: 0.2617 Acc: 0.8884 | Val Loss: 0.2839 Acc: 0.8768\n",
      "Epoch 017 | Train Loss: 0.2320 Acc: 0.9031 | Val Loss: 0.3100 Acc: 0.8623\n",
      "Epoch 018 | Train Loss: 0.2165 Acc: 0.9096 | Val Loss: 0.2435 Acc: 0.8961\n",
      "Epoch 019 | Train Loss: 0.2044 Acc: 0.9168 | Val Loss: 0.2421 Acc: 0.9058\n",
      "Epoch 020 | Train Loss: 0.1913 Acc: 0.9216 | Val Loss: 0.2441 Acc: 0.9040\n",
      "Epoch 021 | Train Loss: 0.1818 Acc: 0.9287 | Val Loss: 0.2173 Acc: 0.9136\n",
      "Epoch 022 | Train Loss: 0.1638 Acc: 0.9348 | Val Loss: 0.2344 Acc: 0.9034\n",
      "Epoch 023 | Train Loss: 0.1650 Acc: 0.9330 | Val Loss: 0.2128 Acc: 0.9143\n",
      "Epoch 024 | Train Loss: 0.1542 Acc: 0.9414 | Val Loss: 0.2241 Acc: 0.9070\n",
      "Epoch 025 | Train Loss: 0.1470 Acc: 0.9434 | Val Loss: 0.2107 Acc: 0.9239\n",
      "Epoch 026 | Train Loss: 0.1406 Acc: 0.9447 | Val Loss: 0.2010 Acc: 0.9209\n",
      "Epoch 027 | Train Loss: 0.1357 Acc: 0.9459 | Val Loss: 0.1787 Acc: 0.9366\n",
      "Epoch 028 | Train Loss: 0.1186 Acc: 0.9527 | Val Loss: 0.1942 Acc: 0.9245\n",
      "Epoch 029 | Train Loss: 0.1158 Acc: 0.9573 | Val Loss: 0.1880 Acc: 0.9312\n",
      "Epoch 030 | Train Loss: 0.1119 Acc: 0.9564 | Val Loss: 0.1992 Acc: 0.9275\n",
      "Epoch 031 | Train Loss: 0.1131 Acc: 0.9570 | Val Loss: 0.1917 Acc: 0.9348\n",
      "Epoch 032 | Train Loss: 0.1019 Acc: 0.9597 | Val Loss: 0.1773 Acc: 0.9360\n",
      "Epoch 033 | Train Loss: 0.1033 Acc: 0.9609 | Val Loss: 0.2139 Acc: 0.9239\n",
      "Epoch 034 | Train Loss: 0.0956 Acc: 0.9648 | Val Loss: 0.1806 Acc: 0.9384\n",
      "Epoch 035 | Train Loss: 0.1014 Acc: 0.9600 | Val Loss: 0.1725 Acc: 0.9348\n",
      "Epoch 036 | Train Loss: 0.0963 Acc: 0.9633 | Val Loss: 0.1484 Acc: 0.9390\n",
      "Epoch 037 | Train Loss: 0.0873 Acc: 0.9666 | Val Loss: 0.1871 Acc: 0.9366\n",
      "Epoch 038 | Train Loss: 0.0842 Acc: 0.9687 | Val Loss: 0.1511 Acc: 0.9457\n",
      "Epoch 039 | Train Loss: 0.0763 Acc: 0.9693 | Val Loss: 0.1523 Acc: 0.9432\n",
      "Epoch 040 | Train Loss: 0.0754 Acc: 0.9704 | Val Loss: 0.1885 Acc: 0.9432\n",
      "Epoch 041 | Train Loss: 0.0724 Acc: 0.9724 | Val Loss: 0.1948 Acc: 0.9402\n",
      "Epoch 042 | Train Loss: 0.0685 Acc: 0.9749 | Val Loss: 0.1442 Acc: 0.9487\n",
      "Epoch 043 | Train Loss: 0.0754 Acc: 0.9707 | Val Loss: 0.1405 Acc: 0.9463\n",
      "Epoch 044 | Train Loss: 0.0602 Acc: 0.9784 | Val Loss: 0.1668 Acc: 0.9499\n",
      "Epoch 045 | Train Loss: 0.0696 Acc: 0.9724 | Val Loss: 0.2151 Acc: 0.9306\n",
      "Epoch 046 | Train Loss: 0.0696 Acc: 0.9737 | Val Loss: 0.1732 Acc: 0.9457\n",
      "Epoch 047 | Train Loss: 0.0613 Acc: 0.9774 | Val Loss: 0.1626 Acc: 0.9402\n",
      "Epoch 048 | Train Loss: 0.0581 Acc: 0.9789 | Val Loss: 0.1937 Acc: 0.9420\n",
      "Epoch 049 | Train Loss: 0.0683 Acc: 0.9758 | Val Loss: 0.1960 Acc: 0.9257\n",
      "Epoch 050 | Train Loss: 0.0645 Acc: 0.9749 | Val Loss: 0.1647 Acc: 0.9450\n",
      "Epoch 051 | Train Loss: 0.0555 Acc: 0.9786 | Val Loss: 0.1886 Acc: 0.9432\n",
      "Epoch 052 | Train Loss: 0.0668 Acc: 0.9742 | Val Loss: 0.1657 Acc: 0.9450\n",
      "Epoch 053 | Train Loss: 0.0590 Acc: 0.9780 | Val Loss: 0.1365 Acc: 0.9541\n",
      "Epoch 054 | Train Loss: 0.0523 Acc: 0.9820 | Val Loss: 0.1810 Acc: 0.9408\n",
      "Epoch 055 | Train Loss: 0.0495 Acc: 0.9811 | Val Loss: 0.2104 Acc: 0.9245\n",
      "Epoch 056 | Train Loss: 0.0497 Acc: 0.9805 | Val Loss: 0.1741 Acc: 0.9438\n",
      "Epoch 057 | Train Loss: 0.0546 Acc: 0.9802 | Val Loss: 0.1913 Acc: 0.9348\n",
      "Epoch 058 | Train Loss: 0.0526 Acc: 0.9802 | Val Loss: 0.3152 Acc: 0.9118\n",
      "Epoch 059 | Train Loss: 0.0620 Acc: 0.9786 | Val Loss: 0.1571 Acc: 0.9457\n",
      "Epoch 060 | Train Loss: 0.0471 Acc: 0.9834 | Val Loss: 0.1726 Acc: 0.9438\n",
      "Epoch 001 | Train Loss: 0.6805 Acc: 0.5718 | Val Loss: 0.6674 Acc: 0.5954\n",
      "Epoch 002 | Train Loss: 0.6601 Acc: 0.6126 | Val Loss: 0.6367 Acc: 0.6636\n",
      "Epoch 003 | Train Loss: 0.6032 Acc: 0.6881 | Val Loss: 0.6175 Acc: 0.6721\n",
      "Epoch 004 | Train Loss: 0.5640 Acc: 0.7155 | Val Loss: 0.5671 Acc: 0.6950\n",
      "Epoch 005 | Train Loss: 0.5376 Acc: 0.7341 | Val Loss: 0.5331 Acc: 0.7397\n",
      "Epoch 006 | Train Loss: 0.5166 Acc: 0.7394 | Val Loss: 0.5046 Acc: 0.7536\n",
      "Epoch 007 | Train Loss: 0.4956 Acc: 0.7583 | Val Loss: 0.5034 Acc: 0.7603\n",
      "Epoch 008 | Train Loss: 0.4653 Acc: 0.7818 | Val Loss: 0.4724 Acc: 0.7609\n",
      "Epoch 009 | Train Loss: 0.4528 Acc: 0.7845 | Val Loss: 0.4278 Acc: 0.7947\n",
      "Epoch 010 | Train Loss: 0.4176 Acc: 0.8049 | Val Loss: 0.3975 Acc: 0.8080\n",
      "Epoch 011 | Train Loss: 0.3849 Acc: 0.8267 | Val Loss: 0.3828 Acc: 0.8164\n",
      "Epoch 012 | Train Loss: 0.3741 Acc: 0.8353 | Val Loss: 0.3689 Acc: 0.8273\n",
      "Epoch 013 | Train Loss: 0.3358 Acc: 0.8523 | Val Loss: 0.3239 Acc: 0.8490\n",
      "Epoch 014 | Train Loss: 0.3196 Acc: 0.8603 | Val Loss: 0.3222 Acc: 0.8496\n",
      "Epoch 015 | Train Loss: 0.2942 Acc: 0.8732 | Val Loss: 0.3330 Acc: 0.8508\n",
      "Epoch 016 | Train Loss: 0.2794 Acc: 0.8843 | Val Loss: 0.2788 Acc: 0.8841\n",
      "Epoch 017 | Train Loss: 0.2632 Acc: 0.8887 | Val Loss: 0.2578 Acc: 0.8913\n",
      "Epoch 018 | Train Loss: 0.2318 Acc: 0.9061 | Val Loss: 0.2485 Acc: 0.8949\n",
      "Epoch 019 | Train Loss: 0.2281 Acc: 0.9093 | Val Loss: 0.2343 Acc: 0.9016\n",
      "Epoch 020 | Train Loss: 0.2053 Acc: 0.9180 | Val Loss: 0.2449 Acc: 0.9028\n",
      "Epoch 021 | Train Loss: 0.1971 Acc: 0.9221 | Val Loss: 0.2145 Acc: 0.9094\n",
      "Epoch 022 | Train Loss: 0.1963 Acc: 0.9201 | Val Loss: 0.2375 Acc: 0.8986\n",
      "Epoch 023 | Train Loss: 0.1760 Acc: 0.9271 | Val Loss: 0.1998 Acc: 0.9179\n",
      "Epoch 024 | Train Loss: 0.1651 Acc: 0.9367 | Val Loss: 0.1885 Acc: 0.9275\n",
      "Epoch 025 | Train Loss: 0.1562 Acc: 0.9388 | Val Loss: 0.1800 Acc: 0.9245\n",
      "Epoch 026 | Train Loss: 0.1540 Acc: 0.9414 | Val Loss: 0.1934 Acc: 0.9185\n",
      "Epoch 027 | Train Loss: 0.1422 Acc: 0.9444 | Val Loss: 0.1919 Acc: 0.9221\n",
      "Epoch 028 | Train Loss: 0.1335 Acc: 0.9472 | Val Loss: 0.1969 Acc: 0.9209\n",
      "Epoch 029 | Train Loss: 0.1340 Acc: 0.9497 | Val Loss: 0.1832 Acc: 0.9269\n",
      "Epoch 030 | Train Loss: 0.1299 Acc: 0.9523 | Val Loss: 0.1836 Acc: 0.9293\n",
      "Epoch 031 | Train Loss: 0.1205 Acc: 0.9565 | Val Loss: 0.2063 Acc: 0.9239\n",
      "Epoch 032 | Train Loss: 0.1227 Acc: 0.9546 | Val Loss: 0.1853 Acc: 0.9300\n",
      "Epoch 033 | Train Loss: 0.1117 Acc: 0.9547 | Val Loss: 0.1694 Acc: 0.9306\n",
      "Epoch 034 | Train Loss: 0.0954 Acc: 0.9644 | Val Loss: 0.1763 Acc: 0.9318\n",
      "Epoch 035 | Train Loss: 0.1017 Acc: 0.9612 | Val Loss: 0.2367 Acc: 0.9094\n",
      "Epoch 036 | Train Loss: 0.0960 Acc: 0.9630 | Val Loss: 0.1841 Acc: 0.9312\n",
      "Epoch 037 | Train Loss: 0.1010 Acc: 0.9609 | Val Loss: 0.1766 Acc: 0.9336\n",
      "Epoch 038 | Train Loss: 0.0842 Acc: 0.9683 | Val Loss: 0.1743 Acc: 0.9330\n",
      "Epoch 039 | Train Loss: 0.0894 Acc: 0.9674 | Val Loss: 0.1680 Acc: 0.9378\n",
      "Epoch 040 | Train Loss: 0.0946 Acc: 0.9642 | Val Loss: 0.2245 Acc: 0.9269\n",
      "Epoch 041 | Train Loss: 0.0845 Acc: 0.9689 | Val Loss: 0.1497 Acc: 0.9426\n",
      "Epoch 042 | Train Loss: 0.0872 Acc: 0.9669 | Val Loss: 0.1371 Acc: 0.9499\n",
      "Epoch 043 | Train Loss: 0.0785 Acc: 0.9686 | Val Loss: 0.2053 Acc: 0.9281\n",
      "Epoch 044 | Train Loss: 0.0882 Acc: 0.9663 | Val Loss: 0.1542 Acc: 0.9450\n",
      "Epoch 045 | Train Loss: 0.0708 Acc: 0.9719 | Val Loss: 0.1533 Acc: 0.9444\n",
      "Epoch 046 | Train Loss: 0.0814 Acc: 0.9690 | Val Loss: 0.1455 Acc: 0.9481\n",
      "Epoch 047 | Train Loss: 0.0687 Acc: 0.9733 | Val Loss: 0.1607 Acc: 0.9426\n",
      "Epoch 048 | Train Loss: 0.0741 Acc: 0.9728 | Val Loss: 0.2238 Acc: 0.9293\n",
      "Epoch 049 | Train Loss: 0.0739 Acc: 0.9728 | Val Loss: 0.1518 Acc: 0.9493\n",
      "Epoch 050 | Train Loss: 0.0656 Acc: 0.9751 | Val Loss: 0.1658 Acc: 0.9408\n",
      "Epoch 051 | Train Loss: 0.0677 Acc: 0.9751 | Val Loss: 0.1452 Acc: 0.9444\n",
      "Epoch 052 | Train Loss: 0.0687 Acc: 0.9751 | Val Loss: 0.1466 Acc: 0.9505\n",
      "Early stopping triggered.\n",
      "Epoch 001 | Train Loss: 0.6821 Acc: 0.5763 | Val Loss: 0.6831 Acc: 0.5700\n",
      "Epoch 002 | Train Loss: 0.6772 Acc: 0.5901 | Val Loss: 0.6736 Acc: 0.5906\n",
      "Epoch 003 | Train Loss: 0.6655 Acc: 0.6032 | Val Loss: 0.6527 Acc: 0.6063\n",
      "Epoch 004 | Train Loss: 0.6186 Acc: 0.6711 | Val Loss: 0.5958 Acc: 0.6812\n",
      "Epoch 005 | Train Loss: 0.5745 Acc: 0.7104 | Val Loss: 0.5588 Acc: 0.7107\n",
      "Epoch 006 | Train Loss: 0.5519 Acc: 0.7238 | Val Loss: 0.5454 Acc: 0.7277\n",
      "Epoch 007 | Train Loss: 0.5185 Acc: 0.7465 | Val Loss: 0.5205 Acc: 0.7506\n",
      "Epoch 008 | Train Loss: 0.5025 Acc: 0.7507 | Val Loss: 0.4923 Acc: 0.7542\n",
      "Epoch 009 | Train Loss: 0.4721 Acc: 0.7755 | Val Loss: 0.4607 Acc: 0.7742\n",
      "Epoch 010 | Train Loss: 0.4486 Acc: 0.7889 | Val Loss: 0.4457 Acc: 0.7802\n",
      "Epoch 011 | Train Loss: 0.4213 Acc: 0.8055 | Val Loss: 0.4110 Acc: 0.7983\n",
      "Epoch 012 | Train Loss: 0.4081 Acc: 0.8125 | Val Loss: 0.4030 Acc: 0.8098\n",
      "Epoch 013 | Train Loss: 0.3789 Acc: 0.8261 | Val Loss: 0.3963 Acc: 0.8164\n",
      "Epoch 014 | Train Loss: 0.3735 Acc: 0.8342 | Val Loss: 0.3669 Acc: 0.8273\n",
      "Epoch 015 | Train Loss: 0.3361 Acc: 0.8502 | Val Loss: 0.3748 Acc: 0.8279\n",
      "Epoch 016 | Train Loss: 0.3231 Acc: 0.8621 | Val Loss: 0.3207 Acc: 0.8533\n",
      "Epoch 017 | Train Loss: 0.3078 Acc: 0.8655 | Val Loss: 0.3243 Acc: 0.8496\n",
      "Epoch 018 | Train Loss: 0.2907 Acc: 0.8759 | Val Loss: 0.3254 Acc: 0.8508\n",
      "Epoch 019 | Train Loss: 0.2793 Acc: 0.8827 | Val Loss: 0.3096 Acc: 0.8605\n",
      "Epoch 020 | Train Loss: 0.2637 Acc: 0.8916 | Val Loss: 0.3097 Acc: 0.8641\n",
      "Epoch 021 | Train Loss: 0.2556 Acc: 0.8942 | Val Loss: 0.2762 Acc: 0.8750\n",
      "Epoch 022 | Train Loss: 0.2323 Acc: 0.9064 | Val Loss: 0.2501 Acc: 0.8913\n",
      "Epoch 023 | Train Loss: 0.2274 Acc: 0.9097 | Val Loss: 0.2597 Acc: 0.8871\n",
      "Epoch 024 | Train Loss: 0.2054 Acc: 0.9185 | Val Loss: 0.2603 Acc: 0.8871\n",
      "Epoch 025 | Train Loss: 0.1909 Acc: 0.9224 | Val Loss: 0.2500 Acc: 0.8913\n",
      "Epoch 026 | Train Loss: 0.1890 Acc: 0.9266 | Val Loss: 0.2477 Acc: 0.9052\n",
      "Epoch 027 | Train Loss: 0.1829 Acc: 0.9298 | Val Loss: 0.2273 Acc: 0.9034\n",
      "Epoch 028 | Train Loss: 0.1804 Acc: 0.9281 | Val Loss: 0.2239 Acc: 0.9064\n",
      "Epoch 029 | Train Loss: 0.1704 Acc: 0.9349 | Val Loss: 0.2263 Acc: 0.9100\n",
      "Epoch 030 | Train Loss: 0.1623 Acc: 0.9372 | Val Loss: 0.2110 Acc: 0.9149\n",
      "Epoch 031 | Train Loss: 0.1531 Acc: 0.9419 | Val Loss: 0.2193 Acc: 0.9149\n",
      "Epoch 032 | Train Loss: 0.1346 Acc: 0.9485 | Val Loss: 0.2974 Acc: 0.8992\n",
      "Epoch 033 | Train Loss: 0.1527 Acc: 0.9405 | Val Loss: 0.2093 Acc: 0.9173\n",
      "Epoch 034 | Train Loss: 0.1297 Acc: 0.9487 | Val Loss: 0.2356 Acc: 0.9076\n",
      "Epoch 035 | Train Loss: 0.1345 Acc: 0.9494 | Val Loss: 0.1962 Acc: 0.9179\n",
      "Epoch 036 | Train Loss: 0.1337 Acc: 0.9493 | Val Loss: 0.2791 Acc: 0.8961\n",
      "Epoch 037 | Train Loss: 0.1187 Acc: 0.9588 | Val Loss: 0.2170 Acc: 0.9106\n",
      "Epoch 038 | Train Loss: 0.1212 Acc: 0.9561 | Val Loss: 0.2106 Acc: 0.9130\n",
      "Epoch 039 | Train Loss: 0.1190 Acc: 0.9543 | Val Loss: 0.2174 Acc: 0.9094\n",
      "Epoch 040 | Train Loss: 0.1076 Acc: 0.9592 | Val Loss: 0.2306 Acc: 0.9136\n",
      "Epoch 041 | Train Loss: 0.1160 Acc: 0.9520 | Val Loss: 0.1969 Acc: 0.9191\n",
      "Epoch 042 | Train Loss: 0.0923 Acc: 0.9662 | Val Loss: 0.2308 Acc: 0.9179\n",
      "Epoch 043 | Train Loss: 0.0996 Acc: 0.9615 | Val Loss: 0.1976 Acc: 0.9275\n",
      "Epoch 044 | Train Loss: 0.1133 Acc: 0.9568 | Val Loss: 0.1824 Acc: 0.9336\n",
      "Epoch 045 | Train Loss: 0.0992 Acc: 0.9613 | Val Loss: 0.2104 Acc: 0.9215\n",
      "Epoch 046 | Train Loss: 0.0943 Acc: 0.9644 | Val Loss: 0.1799 Acc: 0.9336\n",
      "Epoch 047 | Train Loss: 0.0907 Acc: 0.9654 | Val Loss: 0.2396 Acc: 0.9197\n",
      "Epoch 048 | Train Loss: 0.0859 Acc: 0.9674 | Val Loss: 0.1945 Acc: 0.9318\n",
      "Epoch 049 | Train Loss: 0.0801 Acc: 0.9728 | Val Loss: 0.1838 Acc: 0.9324\n",
      "Epoch 050 | Train Loss: 0.0841 Acc: 0.9677 | Val Loss: 0.2155 Acc: 0.9221\n",
      "Epoch 051 | Train Loss: 0.0987 Acc: 0.9638 | Val Loss: 0.1938 Acc: 0.9293\n",
      "Epoch 052 | Train Loss: 0.0839 Acc: 0.9680 | Val Loss: 0.1837 Acc: 0.9390\n",
      "Epoch 053 | Train Loss: 0.0866 Acc: 0.9703 | Val Loss: 0.1802 Acc: 0.9318\n",
      "Epoch 054 | Train Loss: 0.0823 Acc: 0.9698 | Val Loss: 0.1664 Acc: 0.9408\n",
      "Epoch 055 | Train Loss: 0.0695 Acc: 0.9743 | Val Loss: 0.1852 Acc: 0.9390\n",
      "Epoch 056 | Train Loss: 0.0761 Acc: 0.9727 | Val Loss: 0.2151 Acc: 0.9263\n",
      "Epoch 057 | Train Loss: 0.0765 Acc: 0.9701 | Val Loss: 0.1763 Acc: 0.9366\n",
      "Epoch 058 | Train Loss: 0.0776 Acc: 0.9695 | Val Loss: 0.1643 Acc: 0.9336\n",
      "Epoch 059 | Train Loss: 0.0694 Acc: 0.9752 | Val Loss: 0.1815 Acc: 0.9372\n",
      "Epoch 060 | Train Loss: 0.0768 Acc: 0.9695 | Val Loss: 0.1796 Acc: 0.9348\n",
      "Epoch 001 | Train Loss: 0.6841 Acc: 0.5707 | Val Loss: 0.6785 Acc: 0.5851\n",
      "Epoch 002 | Train Loss: 0.6732 Acc: 0.5923 | Val Loss: 0.6654 Acc: 0.5942\n",
      "Epoch 003 | Train Loss: 0.6400 Acc: 0.6480 | Val Loss: 0.6086 Acc: 0.6800\n",
      "Epoch 004 | Train Loss: 0.5871 Acc: 0.7081 | Val Loss: 0.5695 Acc: 0.7011\n",
      "Epoch 005 | Train Loss: 0.5558 Acc: 0.7247 | Val Loss: 0.5354 Acc: 0.7295\n",
      "Epoch 006 | Train Loss: 0.5161 Acc: 0.7486 | Val Loss: 0.5136 Acc: 0.7373\n",
      "Epoch 007 | Train Loss: 0.4952 Acc: 0.7614 | Val Loss: 0.4927 Acc: 0.7591\n",
      "Epoch 008 | Train Loss: 0.4703 Acc: 0.7830 | Val Loss: 0.4783 Acc: 0.7814\n",
      "Epoch 009 | Train Loss: 0.4430 Acc: 0.7897 | Val Loss: 0.4309 Acc: 0.7911\n",
      "Epoch 010 | Train Loss: 0.4297 Acc: 0.8030 | Val Loss: 0.4033 Acc: 0.7983\n",
      "Epoch 011 | Train Loss: 0.4012 Acc: 0.8141 | Val Loss: 0.3909 Acc: 0.8182\n",
      "Epoch 012 | Train Loss: 0.3863 Acc: 0.8274 | Val Loss: 0.4015 Acc: 0.8086\n",
      "Epoch 013 | Train Loss: 0.3485 Acc: 0.8431 | Val Loss: 0.3277 Acc: 0.8514\n",
      "Epoch 014 | Train Loss: 0.3291 Acc: 0.8590 | Val Loss: 0.3089 Acc: 0.8702\n",
      "Epoch 015 | Train Loss: 0.3072 Acc: 0.8674 | Val Loss: 0.3335 Acc: 0.8545\n",
      "Epoch 016 | Train Loss: 0.2866 Acc: 0.8840 | Val Loss: 0.2805 Acc: 0.8865\n",
      "Epoch 017 | Train Loss: 0.2712 Acc: 0.8896 | Val Loss: 0.2533 Acc: 0.8955\n",
      "Epoch 018 | Train Loss: 0.2458 Acc: 0.8999 | Val Loss: 0.2967 Acc: 0.8738\n",
      "Epoch 019 | Train Loss: 0.2423 Acc: 0.9044 | Val Loss: 0.2437 Acc: 0.9028\n",
      "Epoch 020 | Train Loss: 0.2437 Acc: 0.9032 | Val Loss: 0.2400 Acc: 0.9028\n",
      "Epoch 021 | Train Loss: 0.2126 Acc: 0.9151 | Val Loss: 0.2305 Acc: 0.9082\n",
      "Epoch 022 | Train Loss: 0.2043 Acc: 0.9194 | Val Loss: 0.2230 Acc: 0.9106\n",
      "Epoch 023 | Train Loss: 0.1992 Acc: 0.9215 | Val Loss: 0.2260 Acc: 0.9076\n",
      "Epoch 024 | Train Loss: 0.1914 Acc: 0.9254 | Val Loss: 0.1996 Acc: 0.9155\n",
      "Epoch 025 | Train Loss: 0.1735 Acc: 0.9343 | Val Loss: 0.2297 Acc: 0.9028\n",
      "Epoch 026 | Train Loss: 0.1680 Acc: 0.9324 | Val Loss: 0.2086 Acc: 0.9263\n",
      "Epoch 027 | Train Loss: 0.1629 Acc: 0.9351 | Val Loss: 0.1744 Acc: 0.9318\n",
      "Epoch 028 | Train Loss: 0.1566 Acc: 0.9401 | Val Loss: 0.1987 Acc: 0.9239\n",
      "Epoch 029 | Train Loss: 0.1444 Acc: 0.9462 | Val Loss: 0.1830 Acc: 0.9293\n",
      "Epoch 030 | Train Loss: 0.1403 Acc: 0.9461 | Val Loss: 0.1732 Acc: 0.9300\n",
      "Epoch 031 | Train Loss: 0.1338 Acc: 0.9493 | Val Loss: 0.1823 Acc: 0.9263\n",
      "Epoch 032 | Train Loss: 0.1354 Acc: 0.9452 | Val Loss: 0.1796 Acc: 0.9366\n",
      "Epoch 033 | Train Loss: 0.1242 Acc: 0.9532 | Val Loss: 0.1705 Acc: 0.9354\n",
      "Epoch 034 | Train Loss: 0.1151 Acc: 0.9533 | Val Loss: 0.1861 Acc: 0.9281\n",
      "Epoch 035 | Train Loss: 0.1063 Acc: 0.9600 | Val Loss: 0.2058 Acc: 0.9281\n",
      "Epoch 036 | Train Loss: 0.1111 Acc: 0.9567 | Val Loss: 0.1675 Acc: 0.9372\n",
      "Epoch 037 | Train Loss: 0.1121 Acc: 0.9562 | Val Loss: 0.1840 Acc: 0.9269\n",
      "Epoch 038 | Train Loss: 0.1073 Acc: 0.9615 | Val Loss: 0.1578 Acc: 0.9438\n",
      "Epoch 039 | Train Loss: 0.0998 Acc: 0.9627 | Val Loss: 0.1711 Acc: 0.9384\n",
      "Epoch 040 | Train Loss: 0.0843 Acc: 0.9693 | Val Loss: 0.1703 Acc: 0.9306\n",
      "Epoch 041 | Train Loss: 0.0892 Acc: 0.9659 | Val Loss: 0.1652 Acc: 0.9384\n",
      "Epoch 042 | Train Loss: 0.0936 Acc: 0.9656 | Val Loss: 0.1508 Acc: 0.9384\n",
      "Epoch 043 | Train Loss: 0.0950 Acc: 0.9621 | Val Loss: 0.1672 Acc: 0.9348\n",
      "Epoch 044 | Train Loss: 0.0888 Acc: 0.9668 | Val Loss: 0.2040 Acc: 0.9257\n",
      "Epoch 045 | Train Loss: 0.0874 Acc: 0.9638 | Val Loss: 0.1725 Acc: 0.9360\n",
      "Epoch 046 | Train Loss: 0.0898 Acc: 0.9669 | Val Loss: 0.1625 Acc: 0.9390\n",
      "Epoch 047 | Train Loss: 0.0906 Acc: 0.9671 | Val Loss: 0.1762 Acc: 0.9402\n",
      "Epoch 048 | Train Loss: 0.0849 Acc: 0.9684 | Val Loss: 0.1514 Acc: 0.9505\n",
      "Epoch 049 | Train Loss: 0.0744 Acc: 0.9713 | Val Loss: 0.1551 Acc: 0.9444\n",
      "Epoch 050 | Train Loss: 0.0750 Acc: 0.9727 | Val Loss: 0.1463 Acc: 0.9469\n",
      "Epoch 051 | Train Loss: 0.0796 Acc: 0.9701 | Val Loss: 0.1910 Acc: 0.9390\n",
      "Epoch 052 | Train Loss: 0.0772 Acc: 0.9700 | Val Loss: 0.2039 Acc: 0.9173\n",
      "Epoch 053 | Train Loss: 0.0713 Acc: 0.9722 | Val Loss: 0.1511 Acc: 0.9469\n",
      "Epoch 054 | Train Loss: 0.0684 Acc: 0.9748 | Val Loss: 0.1315 Acc: 0.9553\n",
      "Epoch 055 | Train Loss: 0.0762 Acc: 0.9718 | Val Loss: 0.1436 Acc: 0.9505\n",
      "Epoch 056 | Train Loss: 0.0611 Acc: 0.9777 | Val Loss: 0.1411 Acc: 0.9469\n",
      "Epoch 057 | Train Loss: 0.0596 Acc: 0.9792 | Val Loss: 0.1485 Acc: 0.9444\n",
      "Epoch 058 | Train Loss: 0.0698 Acc: 0.9746 | Val Loss: 0.1437 Acc: 0.9523\n",
      "Epoch 059 | Train Loss: 0.0694 Acc: 0.9748 | Val Loss: 0.1566 Acc: 0.9469\n",
      "Epoch 060 | Train Loss: 0.0587 Acc: 0.9796 | Val Loss: 0.1603 Acc: 0.9463\n",
      "Epoch 001 | Train Loss: 0.6799 Acc: 0.5795 | Val Loss: 0.6787 Acc: 0.5870\n",
      "Epoch 002 | Train Loss: 0.6712 Acc: 0.5966 | Val Loss: 0.6692 Acc: 0.5948\n",
      "Epoch 003 | Train Loss: 0.6598 Acc: 0.6092 | Val Loss: 0.6387 Acc: 0.6449\n",
      "Epoch 004 | Train Loss: 0.6282 Acc: 0.6645 | Val Loss: 0.6232 Acc: 0.6667\n",
      "Epoch 005 | Train Loss: 0.5938 Acc: 0.6944 | Val Loss: 0.5851 Acc: 0.6957\n",
      "Epoch 006 | Train Loss: 0.5672 Acc: 0.7142 | Val Loss: 0.5494 Acc: 0.7264\n",
      "Epoch 007 | Train Loss: 0.5416 Acc: 0.7299 | Val Loss: 0.5319 Acc: 0.7319\n",
      "Epoch 008 | Train Loss: 0.5158 Acc: 0.7486 | Val Loss: 0.5251 Acc: 0.7349\n",
      "Epoch 009 | Train Loss: 0.4936 Acc: 0.7584 | Val Loss: 0.5092 Acc: 0.7482\n",
      "Epoch 010 | Train Loss: 0.4719 Acc: 0.7746 | Val Loss: 0.4699 Acc: 0.7687\n",
      "Epoch 011 | Train Loss: 0.4448 Acc: 0.7903 | Val Loss: 0.4267 Acc: 0.8031\n",
      "Epoch 012 | Train Loss: 0.4222 Acc: 0.8084 | Val Loss: 0.3970 Acc: 0.8092\n",
      "Epoch 013 | Train Loss: 0.3970 Acc: 0.8199 | Val Loss: 0.4223 Acc: 0.7935\n",
      "Epoch 014 | Train Loss: 0.3941 Acc: 0.8262 | Val Loss: 0.3990 Acc: 0.8019\n",
      "Epoch 015 | Train Loss: 0.3672 Acc: 0.8400 | Val Loss: 0.4167 Acc: 0.8037\n",
      "Epoch 016 | Train Loss: 0.3385 Acc: 0.8496 | Val Loss: 0.3449 Acc: 0.8382\n",
      "Epoch 017 | Train Loss: 0.3260 Acc: 0.8612 | Val Loss: 0.3173 Acc: 0.8708\n",
      "Epoch 018 | Train Loss: 0.3030 Acc: 0.8688 | Val Loss: 0.2899 Acc: 0.8829\n",
      "Epoch 019 | Train Loss: 0.2793 Acc: 0.8801 | Val Loss: 0.2784 Acc: 0.8804\n",
      "Epoch 020 | Train Loss: 0.2723 Acc: 0.8866 | Val Loss: 0.2960 Acc: 0.8774\n",
      "Epoch 021 | Train Loss: 0.2630 Acc: 0.8922 | Val Loss: 0.2687 Acc: 0.8847\n",
      "Epoch 022 | Train Loss: 0.2513 Acc: 0.8952 | Val Loss: 0.2520 Acc: 0.8949\n",
      "Epoch 023 | Train Loss: 0.2499 Acc: 0.8964 | Val Loss: 0.2275 Acc: 0.9094\n",
      "Epoch 024 | Train Loss: 0.2341 Acc: 0.9040 | Val Loss: 0.2252 Acc: 0.9046\n",
      "Epoch 025 | Train Loss: 0.2161 Acc: 0.9142 | Val Loss: 0.2535 Acc: 0.8949\n",
      "Epoch 026 | Train Loss: 0.2093 Acc: 0.9179 | Val Loss: 0.2173 Acc: 0.9136\n",
      "Epoch 027 | Train Loss: 0.2026 Acc: 0.9170 | Val Loss: 0.1998 Acc: 0.9167\n",
      "Epoch 028 | Train Loss: 0.1830 Acc: 0.9295 | Val Loss: 0.2406 Acc: 0.9052\n",
      "Epoch 029 | Train Loss: 0.1938 Acc: 0.9207 | Val Loss: 0.2240 Acc: 0.9070\n",
      "Epoch 030 | Train Loss: 0.1840 Acc: 0.9295 | Val Loss: 0.2190 Acc: 0.9064\n",
      "Epoch 031 | Train Loss: 0.1877 Acc: 0.9227 | Val Loss: 0.2039 Acc: 0.9203\n",
      "Epoch 032 | Train Loss: 0.1673 Acc: 0.9336 | Val Loss: 0.2057 Acc: 0.9251\n",
      "Epoch 033 | Train Loss: 0.1677 Acc: 0.9351 | Val Loss: 0.1875 Acc: 0.9263\n",
      "Epoch 034 | Train Loss: 0.1635 Acc: 0.9378 | Val Loss: 0.2064 Acc: 0.9106\n",
      "Epoch 035 | Train Loss: 0.1607 Acc: 0.9348 | Val Loss: 0.1978 Acc: 0.9257\n",
      "Epoch 036 | Train Loss: 0.1495 Acc: 0.9411 | Val Loss: 0.1991 Acc: 0.9185\n",
      "Epoch 037 | Train Loss: 0.1492 Acc: 0.9401 | Val Loss: 0.1882 Acc: 0.9197\n",
      "Epoch 038 | Train Loss: 0.1384 Acc: 0.9470 | Val Loss: 0.2274 Acc: 0.9143\n",
      "Epoch 039 | Train Loss: 0.1430 Acc: 0.9465 | Val Loss: 0.2064 Acc: 0.9130\n",
      "Epoch 040 | Train Loss: 0.1336 Acc: 0.9467 | Val Loss: 0.1778 Acc: 0.9342\n",
      "Epoch 041 | Train Loss: 0.1326 Acc: 0.9515 | Val Loss: 0.1874 Acc: 0.9257\n",
      "Epoch 042 | Train Loss: 0.1272 Acc: 0.9490 | Val Loss: 0.1793 Acc: 0.9330\n",
      "Epoch 043 | Train Loss: 0.1165 Acc: 0.9549 | Val Loss: 0.1958 Acc: 0.9155\n",
      "Epoch 044 | Train Loss: 0.1289 Acc: 0.9520 | Val Loss: 0.1850 Acc: 0.9306\n",
      "Epoch 045 | Train Loss: 0.1252 Acc: 0.9520 | Val Loss: 0.1701 Acc: 0.9306\n",
      "Epoch 046 | Train Loss: 0.1114 Acc: 0.9591 | Val Loss: 0.1911 Acc: 0.9179\n",
      "Epoch 047 | Train Loss: 0.1217 Acc: 0.9532 | Val Loss: 0.1693 Acc: 0.9390\n",
      "Epoch 048 | Train Loss: 0.1114 Acc: 0.9577 | Val Loss: 0.1608 Acc: 0.9408\n",
      "Epoch 049 | Train Loss: 0.1038 Acc: 0.9603 | Val Loss: 0.1752 Acc: 0.9281\n",
      "Epoch 050 | Train Loss: 0.1030 Acc: 0.9613 | Val Loss: 0.1803 Acc: 0.9293\n",
      "Epoch 051 | Train Loss: 0.1064 Acc: 0.9567 | Val Loss: 0.1857 Acc: 0.9275\n",
      "Epoch 052 | Train Loss: 0.1125 Acc: 0.9567 | Val Loss: 0.1666 Acc: 0.9336\n",
      "Epoch 053 | Train Loss: 0.1005 Acc: 0.9615 | Val Loss: 0.1886 Acc: 0.9312\n",
      "Epoch 054 | Train Loss: 0.0964 Acc: 0.9630 | Val Loss: 0.1656 Acc: 0.9330\n",
      "Epoch 055 | Train Loss: 0.0946 Acc: 0.9610 | Val Loss: 0.1873 Acc: 0.9360\n",
      "Epoch 056 | Train Loss: 0.0973 Acc: 0.9644 | Val Loss: 0.1817 Acc: 0.9312\n",
      "Epoch 057 | Train Loss: 0.0984 Acc: 0.9626 | Val Loss: 0.1552 Acc: 0.9408\n",
      "Epoch 058 | Train Loss: 0.0881 Acc: 0.9651 | Val Loss: 0.2248 Acc: 0.9221\n",
      "Epoch 059 | Train Loss: 0.0888 Acc: 0.9663 | Val Loss: 0.1973 Acc: 0.9342\n",
      "Epoch 060 | Train Loss: 0.0857 Acc: 0.9693 | Val Loss: 0.1671 Acc: 0.9457\n",
      "Epoch 001 | Train Loss: 0.6808 Acc: 0.5839 | Val Loss: 0.6770 Acc: 0.5797\n",
      "Epoch 002 | Train Loss: 0.6738 Acc: 0.5934 | Val Loss: 0.6778 Acc: 0.5791\n",
      "Epoch 003 | Train Loss: 0.6648 Acc: 0.6030 | Val Loss: 0.6634 Acc: 0.5984\n",
      "Epoch 004 | Train Loss: 0.6431 Acc: 0.6419 | Val Loss: 0.6095 Acc: 0.6818\n",
      "Epoch 005 | Train Loss: 0.6084 Acc: 0.6825 | Val Loss: 0.5856 Acc: 0.7023\n",
      "Epoch 006 | Train Loss: 0.5844 Acc: 0.7015 | Val Loss: 0.5684 Acc: 0.7114\n",
      "Epoch 007 | Train Loss: 0.5644 Acc: 0.7207 | Val Loss: 0.5797 Acc: 0.7041\n",
      "Epoch 008 | Train Loss: 0.5485 Acc: 0.7254 | Val Loss: 0.5516 Acc: 0.7174\n",
      "Epoch 009 | Train Loss: 0.5311 Acc: 0.7435 | Val Loss: 0.5485 Acc: 0.7246\n",
      "Epoch 010 | Train Loss: 0.5175 Acc: 0.7498 | Val Loss: 0.5235 Acc: 0.7452\n",
      "Epoch 011 | Train Loss: 0.5090 Acc: 0.7563 | Val Loss: 0.5377 Acc: 0.7313\n",
      "Epoch 012 | Train Loss: 0.4852 Acc: 0.7673 | Val Loss: 0.4931 Acc: 0.7482\n",
      "Epoch 013 | Train Loss: 0.4813 Acc: 0.7667 | Val Loss: 0.4845 Acc: 0.7651\n",
      "Epoch 014 | Train Loss: 0.4687 Acc: 0.7726 | Val Loss: 0.4987 Acc: 0.7355\n",
      "Epoch 015 | Train Loss: 0.4492 Acc: 0.7844 | Val Loss: 0.4415 Acc: 0.7905\n",
      "Epoch 016 | Train Loss: 0.4399 Acc: 0.7910 | Val Loss: 0.4301 Acc: 0.7917\n",
      "Epoch 017 | Train Loss: 0.4104 Acc: 0.8057 | Val Loss: 0.4044 Acc: 0.8152\n",
      "Epoch 018 | Train Loss: 0.4069 Acc: 0.8120 | Val Loss: 0.4143 Acc: 0.7947\n",
      "Epoch 019 | Train Loss: 0.3872 Acc: 0.8184 | Val Loss: 0.4063 Acc: 0.7983\n",
      "Epoch 020 | Train Loss: 0.3882 Acc: 0.8202 | Val Loss: 0.3733 Acc: 0.8261\n",
      "Epoch 021 | Train Loss: 0.3542 Acc: 0.8418 | Val Loss: 0.3769 Acc: 0.8261\n",
      "Epoch 022 | Train Loss: 0.3488 Acc: 0.8384 | Val Loss: 0.3651 Acc: 0.8321\n",
      "Epoch 023 | Train Loss: 0.3219 Acc: 0.8569 | Val Loss: 0.3315 Acc: 0.8466\n",
      "Epoch 024 | Train Loss: 0.3198 Acc: 0.8628 | Val Loss: 0.3390 Acc: 0.8400\n",
      "Epoch 025 | Train Loss: 0.3049 Acc: 0.8670 | Val Loss: 0.3156 Acc: 0.8490\n",
      "Epoch 026 | Train Loss: 0.2898 Acc: 0.8788 | Val Loss: 0.3011 Acc: 0.8678\n",
      "Epoch 027 | Train Loss: 0.2732 Acc: 0.8789 | Val Loss: 0.2717 Acc: 0.8708\n",
      "Epoch 028 | Train Loss: 0.2680 Acc: 0.8831 | Val Loss: 0.3279 Acc: 0.8605\n",
      "Epoch 029 | Train Loss: 0.2494 Acc: 0.8985 | Val Loss: 0.2827 Acc: 0.8792\n",
      "Epoch 030 | Train Loss: 0.2417 Acc: 0.8999 | Val Loss: 0.2320 Acc: 0.8992\n",
      "Epoch 031 | Train Loss: 0.2274 Acc: 0.9073 | Val Loss: 0.2705 Acc: 0.8810\n",
      "Epoch 032 | Train Loss: 0.2097 Acc: 0.9139 | Val Loss: 0.2377 Acc: 0.9040\n",
      "Epoch 033 | Train Loss: 0.2121 Acc: 0.9118 | Val Loss: 0.2372 Acc: 0.9010\n",
      "Epoch 034 | Train Loss: 0.1942 Acc: 0.9209 | Val Loss: 0.2504 Acc: 0.9064\n",
      "Epoch 035 | Train Loss: 0.1821 Acc: 0.9260 | Val Loss: 0.2216 Acc: 0.9149\n",
      "Epoch 036 | Train Loss: 0.1711 Acc: 0.9327 | Val Loss: 0.1901 Acc: 0.9221\n",
      "Epoch 037 | Train Loss: 0.1597 Acc: 0.9334 | Val Loss: 0.2203 Acc: 0.9094\n",
      "Epoch 038 | Train Loss: 0.1632 Acc: 0.9328 | Val Loss: 0.1990 Acc: 0.9209\n",
      "Epoch 039 | Train Loss: 0.1469 Acc: 0.9444 | Val Loss: 0.1902 Acc: 0.9318\n",
      "Epoch 040 | Train Loss: 0.1573 Acc: 0.9379 | Val Loss: 0.2390 Acc: 0.8979\n",
      "Epoch 041 | Train Loss: 0.1390 Acc: 0.9494 | Val Loss: 0.1890 Acc: 0.9263\n",
      "Epoch 042 | Train Loss: 0.1364 Acc: 0.9462 | Val Loss: 0.2014 Acc: 0.9191\n",
      "Epoch 043 | Train Loss: 0.1307 Acc: 0.9485 | Val Loss: 0.1849 Acc: 0.9318\n",
      "Epoch 044 | Train Loss: 0.1222 Acc: 0.9539 | Val Loss: 0.1832 Acc: 0.9306\n",
      "Epoch 045 | Train Loss: 0.1270 Acc: 0.9518 | Val Loss: 0.1929 Acc: 0.9203\n",
      "Epoch 046 | Train Loss: 0.1295 Acc: 0.9508 | Val Loss: 0.1836 Acc: 0.9239\n",
      "Epoch 047 | Train Loss: 0.1151 Acc: 0.9529 | Val Loss: 0.1956 Acc: 0.9269\n",
      "Epoch 048 | Train Loss: 0.1080 Acc: 0.9612 | Val Loss: 0.1646 Acc: 0.9360\n",
      "Epoch 049 | Train Loss: 0.1157 Acc: 0.9576 | Val Loss: 0.1549 Acc: 0.9414\n",
      "Epoch 050 | Train Loss: 0.1050 Acc: 0.9613 | Val Loss: 0.2259 Acc: 0.9203\n",
      "Epoch 051 | Train Loss: 0.0927 Acc: 0.9654 | Val Loss: 0.1828 Acc: 0.9324\n",
      "Epoch 052 | Train Loss: 0.0899 Acc: 0.9651 | Val Loss: 0.1546 Acc: 0.9475\n",
      "Epoch 053 | Train Loss: 0.0953 Acc: 0.9659 | Val Loss: 0.2509 Acc: 0.9100\n",
      "Epoch 054 | Train Loss: 0.0874 Acc: 0.9666 | Val Loss: 0.1532 Acc: 0.9438\n",
      "Epoch 055 | Train Loss: 0.0813 Acc: 0.9703 | Val Loss: 0.1430 Acc: 0.9493\n",
      "Epoch 056 | Train Loss: 0.0926 Acc: 0.9659 | Val Loss: 0.1858 Acc: 0.9281\n",
      "Epoch 057 | Train Loss: 0.0899 Acc: 0.9681 | Val Loss: 0.1682 Acc: 0.9336\n",
      "Epoch 058 | Train Loss: 0.0912 Acc: 0.9671 | Val Loss: 0.1459 Acc: 0.9511\n",
      "Epoch 059 | Train Loss: 0.0719 Acc: 0.9730 | Val Loss: 0.1615 Acc: 0.9384\n",
      "Epoch 060 | Train Loss: 0.0742 Acc: 0.9740 | Val Loss: 0.1813 Acc: 0.9390\n",
      "Epoch 001 | Train Loss: 0.6820 Acc: 0.5753 | Val Loss: 0.6754 Acc: 0.5912\n",
      "Epoch 002 | Train Loss: 0.6751 Acc: 0.5938 | Val Loss: 0.6749 Acc: 0.5827\n",
      "Epoch 003 | Train Loss: 0.6463 Acc: 0.6284 | Val Loss: 0.6341 Acc: 0.6479\n",
      "Epoch 004 | Train Loss: 0.5973 Acc: 0.6900 | Val Loss: 0.5812 Acc: 0.6999\n",
      "Epoch 005 | Train Loss: 0.5658 Acc: 0.7231 | Val Loss: 0.5788 Acc: 0.7138\n",
      "Epoch 006 | Train Loss: 0.5392 Acc: 0.7441 | Val Loss: 0.5367 Acc: 0.7319\n",
      "Epoch 007 | Train Loss: 0.5191 Acc: 0.7522 | Val Loss: 0.5257 Acc: 0.7476\n",
      "Epoch 008 | Train Loss: 0.4984 Acc: 0.7622 | Val Loss: 0.5021 Acc: 0.7633\n",
      "Epoch 009 | Train Loss: 0.4796 Acc: 0.7738 | Val Loss: 0.4810 Acc: 0.7699\n",
      "Epoch 010 | Train Loss: 0.4661 Acc: 0.7832 | Val Loss: 0.4703 Acc: 0.7790\n",
      "Epoch 011 | Train Loss: 0.4420 Acc: 0.7978 | Val Loss: 0.4627 Acc: 0.7838\n",
      "Epoch 012 | Train Loss: 0.4155 Acc: 0.8147 | Val Loss: 0.4297 Acc: 0.7977\n",
      "Epoch 013 | Train Loss: 0.3912 Acc: 0.8306 | Val Loss: 0.3814 Acc: 0.8219\n",
      "Epoch 014 | Train Loss: 0.3643 Acc: 0.8396 | Val Loss: 0.4317 Acc: 0.8019\n",
      "Epoch 015 | Train Loss: 0.3358 Acc: 0.8600 | Val Loss: 0.3439 Acc: 0.8364\n",
      "Epoch 016 | Train Loss: 0.3248 Acc: 0.8614 | Val Loss: 0.3356 Acc: 0.8521\n",
      "Epoch 017 | Train Loss: 0.3013 Acc: 0.8733 | Val Loss: 0.2963 Acc: 0.8738\n",
      "Epoch 018 | Train Loss: 0.2917 Acc: 0.8794 | Val Loss: 0.2840 Acc: 0.8756\n",
      "Epoch 019 | Train Loss: 0.2657 Acc: 0.8902 | Val Loss: 0.2569 Acc: 0.8907\n",
      "Epoch 020 | Train Loss: 0.2462 Acc: 0.8952 | Val Loss: 0.2760 Acc: 0.8816\n",
      "Epoch 021 | Train Loss: 0.2394 Acc: 0.9038 | Val Loss: 0.2224 Acc: 0.9094\n",
      "Epoch 022 | Train Loss: 0.2246 Acc: 0.9136 | Val Loss: 0.2241 Acc: 0.9022\n",
      "Epoch 023 | Train Loss: 0.2124 Acc: 0.9191 | Val Loss: 0.2194 Acc: 0.9100\n",
      "Epoch 024 | Train Loss: 0.1966 Acc: 0.9215 | Val Loss: 0.2318 Acc: 0.9076\n",
      "Epoch 025 | Train Loss: 0.1983 Acc: 0.9224 | Val Loss: 0.2029 Acc: 0.9167\n",
      "Epoch 026 | Train Loss: 0.1709 Acc: 0.9345 | Val Loss: 0.1964 Acc: 0.9203\n",
      "Epoch 027 | Train Loss: 0.1685 Acc: 0.9352 | Val Loss: 0.2112 Acc: 0.9167\n",
      "Epoch 028 | Train Loss: 0.1656 Acc: 0.9363 | Val Loss: 0.1876 Acc: 0.9221\n",
      "Epoch 029 | Train Loss: 0.1578 Acc: 0.9390 | Val Loss: 0.1841 Acc: 0.9215\n",
      "Epoch 030 | Train Loss: 0.1398 Acc: 0.9459 | Val Loss: 0.1628 Acc: 0.9324\n",
      "Epoch 031 | Train Loss: 0.1374 Acc: 0.9465 | Val Loss: 0.1992 Acc: 0.9203\n",
      "Epoch 032 | Train Loss: 0.1598 Acc: 0.9388 | Val Loss: 0.1932 Acc: 0.9203\n",
      "Epoch 033 | Train Loss: 0.1232 Acc: 0.9533 | Val Loss: 0.1982 Acc: 0.9239\n",
      "Epoch 034 | Train Loss: 0.1531 Acc: 0.9410 | Val Loss: 0.2135 Acc: 0.9124\n",
      "Epoch 035 | Train Loss: 0.1266 Acc: 0.9514 | Val Loss: 0.1770 Acc: 0.9293\n",
      "Epoch 036 | Train Loss: 0.1172 Acc: 0.9583 | Val Loss: 0.1629 Acc: 0.9324\n",
      "Epoch 037 | Train Loss: 0.1276 Acc: 0.9520 | Val Loss: 0.1686 Acc: 0.9360\n",
      "Epoch 038 | Train Loss: 0.1119 Acc: 0.9592 | Val Loss: 0.2152 Acc: 0.9155\n",
      "Epoch 039 | Train Loss: 0.1109 Acc: 0.9579 | Val Loss: 0.1671 Acc: 0.9366\n",
      "Epoch 040 | Train Loss: 0.1088 Acc: 0.9592 | Val Loss: 0.1771 Acc: 0.9306\n",
      "Early stopping triggered.\n",
      "Epoch 001 | Train Loss: 0.6791 Acc: 0.5789 | Val Loss: 0.6776 Acc: 0.5857\n",
      "Epoch 002 | Train Loss: 0.6726 Acc: 0.5896 | Val Loss: 0.6656 Acc: 0.6008\n",
      "Epoch 003 | Train Loss: 0.6616 Acc: 0.6032 | Val Loss: 0.6330 Acc: 0.6570\n",
      "Epoch 004 | Train Loss: 0.6075 Acc: 0.6846 | Val Loss: 0.6033 Acc: 0.6854\n",
      "Epoch 005 | Train Loss: 0.5673 Acc: 0.7149 | Val Loss: 0.5576 Acc: 0.7132\n",
      "Epoch 006 | Train Loss: 0.5460 Acc: 0.7346 | Val Loss: 0.5539 Acc: 0.7289\n",
      "Epoch 007 | Train Loss: 0.5252 Acc: 0.7420 | Val Loss: 0.5405 Acc: 0.7174\n",
      "Epoch 008 | Train Loss: 0.5061 Acc: 0.7537 | Val Loss: 0.5294 Acc: 0.7313\n",
      "Epoch 009 | Train Loss: 0.4885 Acc: 0.7663 | Val Loss: 0.4913 Acc: 0.7603\n",
      "Epoch 010 | Train Loss: 0.4598 Acc: 0.7871 | Val Loss: 0.4646 Acc: 0.7778\n",
      "Epoch 011 | Train Loss: 0.4485 Acc: 0.7904 | Val Loss: 0.4237 Acc: 0.8031\n",
      "Epoch 012 | Train Loss: 0.4262 Acc: 0.8004 | Val Loss: 0.4100 Acc: 0.8128\n",
      "Epoch 013 | Train Loss: 0.4067 Acc: 0.8158 | Val Loss: 0.4208 Acc: 0.8013\n",
      "Epoch 014 | Train Loss: 0.3836 Acc: 0.8247 | Val Loss: 0.3604 Acc: 0.8514\n",
      "Epoch 015 | Train Loss: 0.3631 Acc: 0.8356 | Val Loss: 0.4040 Acc: 0.8128\n",
      "Epoch 016 | Train Loss: 0.3412 Acc: 0.8532 | Val Loss: 0.3229 Acc: 0.8653\n",
      "Epoch 017 | Train Loss: 0.3180 Acc: 0.8621 | Val Loss: 0.3173 Acc: 0.8690\n",
      "Epoch 018 | Train Loss: 0.2902 Acc: 0.8786 | Val Loss: 0.2806 Acc: 0.8810\n",
      "Epoch 019 | Train Loss: 0.2831 Acc: 0.8860 | Val Loss: 0.2891 Acc: 0.8696\n",
      "Epoch 020 | Train Loss: 0.2497 Acc: 0.8955 | Val Loss: 0.2556 Acc: 0.8949\n",
      "Epoch 021 | Train Loss: 0.2424 Acc: 0.9000 | Val Loss: 0.2829 Acc: 0.8762\n",
      "Epoch 022 | Train Loss: 0.2288 Acc: 0.9050 | Val Loss: 0.2696 Acc: 0.8907\n",
      "Epoch 023 | Train Loss: 0.2242 Acc: 0.9074 | Val Loss: 0.2510 Acc: 0.8937\n",
      "Epoch 024 | Train Loss: 0.2165 Acc: 0.9165 | Val Loss: 0.2365 Acc: 0.9034\n",
      "Epoch 025 | Train Loss: 0.1915 Acc: 0.9259 | Val Loss: 0.2221 Acc: 0.9118\n",
      "Epoch 026 | Train Loss: 0.1715 Acc: 0.9324 | Val Loss: 0.1852 Acc: 0.9275\n",
      "Epoch 027 | Train Loss: 0.1766 Acc: 0.9331 | Val Loss: 0.2196 Acc: 0.9082\n",
      "Epoch 028 | Train Loss: 0.1565 Acc: 0.9414 | Val Loss: 0.2417 Acc: 0.9076\n",
      "Epoch 029 | Train Loss: 0.1599 Acc: 0.9378 | Val Loss: 0.2017 Acc: 0.9155\n",
      "Epoch 030 | Train Loss: 0.1525 Acc: 0.9379 | Val Loss: 0.2054 Acc: 0.9143\n",
      "Epoch 031 | Train Loss: 0.1468 Acc: 0.9437 | Val Loss: 0.1886 Acc: 0.9263\n",
      "Epoch 032 | Train Loss: 0.1503 Acc: 0.9414 | Val Loss: 0.1789 Acc: 0.9306\n",
      "Epoch 033 | Train Loss: 0.1342 Acc: 0.9493 | Val Loss: 0.1856 Acc: 0.9300\n",
      "Epoch 034 | Train Loss: 0.1312 Acc: 0.9491 | Val Loss: 0.1819 Acc: 0.9287\n",
      "Epoch 035 | Train Loss: 0.1219 Acc: 0.9521 | Val Loss: 0.1843 Acc: 0.9275\n",
      "Epoch 036 | Train Loss: 0.1268 Acc: 0.9521 | Val Loss: 0.1695 Acc: 0.9366\n",
      "Epoch 037 | Train Loss: 0.1162 Acc: 0.9577 | Val Loss: 0.1563 Acc: 0.9438\n",
      "Epoch 038 | Train Loss: 0.1111 Acc: 0.9583 | Val Loss: 0.1515 Acc: 0.9426\n",
      "Epoch 039 | Train Loss: 0.0981 Acc: 0.9630 | Val Loss: 0.1788 Acc: 0.9384\n",
      "Epoch 040 | Train Loss: 0.1054 Acc: 0.9592 | Val Loss: 0.1755 Acc: 0.9402\n",
      "Epoch 041 | Train Loss: 0.1003 Acc: 0.9610 | Val Loss: 0.1972 Acc: 0.9281\n",
      "Epoch 042 | Train Loss: 0.0999 Acc: 0.9635 | Val Loss: 0.1835 Acc: 0.9300\n",
      "Epoch 043 | Train Loss: 0.0942 Acc: 0.9645 | Val Loss: 0.1563 Acc: 0.9414\n",
      "Epoch 044 | Train Loss: 0.0957 Acc: 0.9613 | Val Loss: 0.1455 Acc: 0.9463\n",
      "Epoch 045 | Train Loss: 0.0931 Acc: 0.9650 | Val Loss: 0.2161 Acc: 0.9245\n",
      "Epoch 046 | Train Loss: 0.0928 Acc: 0.9656 | Val Loss: 0.1821 Acc: 0.9275\n",
      "Epoch 047 | Train Loss: 0.0819 Acc: 0.9678 | Val Loss: 0.2138 Acc: 0.9312\n",
      "Epoch 048 | Train Loss: 0.0890 Acc: 0.9680 | Val Loss: 0.2000 Acc: 0.9354\n",
      "Epoch 049 | Train Loss: 0.0848 Acc: 0.9697 | Val Loss: 0.1840 Acc: 0.9426\n",
      "Epoch 050 | Train Loss: 0.0825 Acc: 0.9715 | Val Loss: 0.1793 Acc: 0.9372\n",
      "Epoch 051 | Train Loss: 0.0776 Acc: 0.9710 | Val Loss: 0.1620 Acc: 0.9408\n",
      "Epoch 052 | Train Loss: 0.0746 Acc: 0.9725 | Val Loss: 0.1647 Acc: 0.9493\n",
      "Epoch 053 | Train Loss: 0.0731 Acc: 0.9740 | Val Loss: 0.1580 Acc: 0.9475\n",
      "Epoch 054 | Train Loss: 0.0803 Acc: 0.9733 | Val Loss: 0.1349 Acc: 0.9553\n",
      "Epoch 055 | Train Loss: 0.0743 Acc: 0.9733 | Val Loss: 0.1424 Acc: 0.9571\n",
      "Epoch 056 | Train Loss: 0.0685 Acc: 0.9751 | Val Loss: 0.1453 Acc: 0.9565\n",
      "Epoch 057 | Train Loss: 0.0825 Acc: 0.9687 | Val Loss: 0.1396 Acc: 0.9493\n",
      "Epoch 058 | Train Loss: 0.0718 Acc: 0.9716 | Val Loss: 0.1241 Acc: 0.9517\n",
      "Epoch 059 | Train Loss: 0.0708 Acc: 0.9748 | Val Loss: 0.1516 Acc: 0.9499\n",
      "Epoch 060 | Train Loss: 0.0655 Acc: 0.9764 | Val Loss: 0.1203 Acc: 0.9553\n",
      "Epoch 001 | Train Loss: 0.6806 Acc: 0.5827 | Val Loss: 0.6828 Acc: 0.5664\n",
      "Epoch 002 | Train Loss: 0.6726 Acc: 0.5946 | Val Loss: 0.6678 Acc: 0.5984\n",
      "Epoch 003 | Train Loss: 0.6713 Acc: 0.5931 | Val Loss: 0.6688 Acc: 0.6039\n",
      "Epoch 004 | Train Loss: 0.6611 Acc: 0.6059 | Val Loss: 0.6595 Acc: 0.6111\n",
      "Epoch 005 | Train Loss: 0.6319 Acc: 0.6524 | Val Loss: 0.6083 Acc: 0.6890\n",
      "Epoch 006 | Train Loss: 0.5924 Acc: 0.7004 | Val Loss: 0.5890 Acc: 0.6950\n",
      "Epoch 007 | Train Loss: 0.5719 Acc: 0.7189 | Val Loss: 0.5594 Acc: 0.7174\n",
      "Epoch 008 | Train Loss: 0.5420 Acc: 0.7355 | Val Loss: 0.5290 Acc: 0.7325\n",
      "Epoch 009 | Train Loss: 0.5115 Acc: 0.7566 | Val Loss: 0.5106 Acc: 0.7566\n",
      "Epoch 010 | Train Loss: 0.5018 Acc: 0.7637 | Val Loss: 0.4954 Acc: 0.7669\n",
      "Epoch 011 | Train Loss: 0.4689 Acc: 0.7814 | Val Loss: 0.4712 Acc: 0.7742\n",
      "Epoch 012 | Train Loss: 0.4500 Acc: 0.7951 | Val Loss: 0.4330 Acc: 0.7983\n",
      "Epoch 013 | Train Loss: 0.4267 Acc: 0.8105 | Val Loss: 0.4121 Acc: 0.8062\n",
      "Epoch 014 | Train Loss: 0.4026 Acc: 0.8217 | Val Loss: 0.3833 Acc: 0.8273\n",
      "Epoch 015 | Train Loss: 0.3782 Acc: 0.8309 | Val Loss: 0.3967 Acc: 0.8164\n",
      "Epoch 016 | Train Loss: 0.3617 Acc: 0.8389 | Val Loss: 0.3213 Acc: 0.8641\n",
      "Epoch 017 | Train Loss: 0.3413 Acc: 0.8517 | Val Loss: 0.3195 Acc: 0.8575\n",
      "Epoch 018 | Train Loss: 0.3066 Acc: 0.8677 | Val Loss: 0.3023 Acc: 0.8702\n",
      "Epoch 019 | Train Loss: 0.2948 Acc: 0.8766 | Val Loss: 0.2832 Acc: 0.8822\n",
      "Epoch 020 | Train Loss: 0.2748 Acc: 0.8865 | Val Loss: 0.2723 Acc: 0.8810\n",
      "Epoch 021 | Train Loss: 0.2740 Acc: 0.8866 | Val Loss: 0.2500 Acc: 0.8998\n",
      "Epoch 022 | Train Loss: 0.2571 Acc: 0.8917 | Val Loss: 0.2632 Acc: 0.8998\n",
      "Epoch 023 | Train Loss: 0.2403 Acc: 0.9035 | Val Loss: 0.2298 Acc: 0.9130\n",
      "Epoch 024 | Train Loss: 0.2382 Acc: 0.9049 | Val Loss: 0.2252 Acc: 0.9118\n",
      "Epoch 025 | Train Loss: 0.2190 Acc: 0.9099 | Val Loss: 0.2037 Acc: 0.9136\n",
      "Epoch 026 | Train Loss: 0.2025 Acc: 0.9168 | Val Loss: 0.2085 Acc: 0.9185\n",
      "Epoch 027 | Train Loss: 0.1969 Acc: 0.9225 | Val Loss: 0.2079 Acc: 0.9191\n",
      "Epoch 028 | Train Loss: 0.1947 Acc: 0.9224 | Val Loss: 0.2278 Acc: 0.9112\n",
      "Epoch 029 | Train Loss: 0.1831 Acc: 0.9284 | Val Loss: 0.2021 Acc: 0.9173\n",
      "Epoch 030 | Train Loss: 0.1821 Acc: 0.9269 | Val Loss: 0.2346 Acc: 0.9130\n",
      "Epoch 031 | Train Loss: 0.1637 Acc: 0.9366 | Val Loss: 0.1914 Acc: 0.9245\n",
      "Epoch 032 | Train Loss: 0.1641 Acc: 0.9367 | Val Loss: 0.1833 Acc: 0.9318\n",
      "Epoch 033 | Train Loss: 0.1585 Acc: 0.9388 | Val Loss: 0.1671 Acc: 0.9366\n",
      "Epoch 034 | Train Loss: 0.1508 Acc: 0.9376 | Val Loss: 0.1688 Acc: 0.9372\n",
      "Epoch 035 | Train Loss: 0.1480 Acc: 0.9414 | Val Loss: 0.1945 Acc: 0.9293\n",
      "Epoch 036 | Train Loss: 0.1457 Acc: 0.9425 | Val Loss: 0.1843 Acc: 0.9348\n",
      "Epoch 037 | Train Loss: 0.1310 Acc: 0.9487 | Val Loss: 0.1663 Acc: 0.9366\n",
      "Epoch 038 | Train Loss: 0.1389 Acc: 0.9455 | Val Loss: 0.2034 Acc: 0.9191\n",
      "Epoch 039 | Train Loss: 0.1337 Acc: 0.9467 | Val Loss: 0.1523 Acc: 0.9372\n",
      "Epoch 040 | Train Loss: 0.1210 Acc: 0.9562 | Val Loss: 0.1640 Acc: 0.9366\n",
      "Epoch 041 | Train Loss: 0.1262 Acc: 0.9515 | Val Loss: 0.1712 Acc: 0.9354\n",
      "Epoch 042 | Train Loss: 0.1209 Acc: 0.9544 | Val Loss: 0.1748 Acc: 0.9300\n",
      "Epoch 043 | Train Loss: 0.1104 Acc: 0.9580 | Val Loss: 0.1579 Acc: 0.9414\n",
      "Epoch 044 | Train Loss: 0.1167 Acc: 0.9543 | Val Loss: 0.1550 Acc: 0.9426\n",
      "Epoch 045 | Train Loss: 0.1163 Acc: 0.9541 | Val Loss: 0.1706 Acc: 0.9293\n",
      "Epoch 046 | Train Loss: 0.1081 Acc: 0.9574 | Val Loss: 0.1524 Acc: 0.9408\n",
      "Epoch 047 | Train Loss: 0.1096 Acc: 0.9600 | Val Loss: 0.1514 Acc: 0.9438\n",
      "Epoch 048 | Train Loss: 0.1000 Acc: 0.9620 | Val Loss: 0.1392 Acc: 0.9438\n",
      "Epoch 049 | Train Loss: 0.0989 Acc: 0.9648 | Val Loss: 0.1569 Acc: 0.9396\n",
      "Epoch 050 | Train Loss: 0.0973 Acc: 0.9638 | Val Loss: 0.1815 Acc: 0.9318\n",
      "Epoch 051 | Train Loss: 0.1023 Acc: 0.9623 | Val Loss: 0.1600 Acc: 0.9384\n",
      "Epoch 052 | Train Loss: 0.1010 Acc: 0.9626 | Val Loss: 0.1688 Acc: 0.9360\n",
      "Epoch 053 | Train Loss: 0.0973 Acc: 0.9638 | Val Loss: 0.1660 Acc: 0.9390\n",
      "Epoch 054 | Train Loss: 0.0866 Acc: 0.9671 | Val Loss: 0.1282 Acc: 0.9535\n",
      "Epoch 055 | Train Loss: 0.0987 Acc: 0.9618 | Val Loss: 0.1684 Acc: 0.9360\n",
      "Epoch 056 | Train Loss: 0.1016 Acc: 0.9623 | Val Loss: 0.1336 Acc: 0.9457\n",
      "Epoch 057 | Train Loss: 0.0923 Acc: 0.9681 | Val Loss: 0.1558 Acc: 0.9444\n",
      "Epoch 058 | Train Loss: 0.0885 Acc: 0.9666 | Val Loss: 0.1487 Acc: 0.9463\n",
      "Epoch 059 | Train Loss: 0.0936 Acc: 0.9654 | Val Loss: 0.1442 Acc: 0.9481\n",
      "Epoch 060 | Train Loss: 0.0889 Acc: 0.9662 | Val Loss: 0.2229 Acc: 0.9281\n",
      "Iteration 40/40 | Best Val Loss: 0.1122 | Iter Time: 216.92s | Total Time: 160.75 min\n",
      "Optimization finished.\n",
      "Best Hyperparams: {'cnn_kernels_1': 25, 'cnn_kernel_size_1': 5, 'cnn_kernels_2': 75, 'cnn_dropout': np.float64(0.37986810385665165), 'cnn_dense': 253, 'lstm_hidden_size': 60, 'lstm_layers': 2, 'lstm_dense': 172, 'learning_rate': np.float64(0.001811051641330436), 'batch_size': 64}\n"
     ]
    }
   ],
   "source": [
    "# Initialize swarm\n",
    "n_particles = 10\n",
    "max_iter = 40\n",
    "w, c1, c2 = 0.7, 1.5, 1.5\n",
    "\n",
    "positions = np.random.rand(n_particles, dim)\n",
    "velocities = np.random.randn(n_particles, dim) * 0.1\n",
    "pbest_positions = positions.copy()\n",
    "pbest_scores = np.full(n_particles, np.inf)\n",
    "\n",
    "gbest_position = None\n",
    "gbest_score = np.inf\n",
    "\n",
    "def decode_position(pos):\n",
    "    \"\"\"Map particle position [0,1] to real hyperparams.\"\"\"\n",
    "    hp = {}\n",
    "    for i, k in enumerate(keys):\n",
    "        low, high = bounds[k]\n",
    "        if k in ['cnn_kernels_1','cnn_kernel_size_1','cnn_kernels_2',\n",
    "                 'cnn_dense','lstm_hidden_size','lstm_layers','lstm_dense','batch_size']:\n",
    "            hp[k] = int(np.round(low + pos[i] * (high - low)))\n",
    "            # ensure valid odd kernel size if needed\n",
    "            if k == 'cnn_kernel_size_1':\n",
    "                hp[k] = 3 if hp[k] < 4 else 5\n",
    "        else:  # continuous\n",
    "            hp[k] = low + pos[i] * (high - low)\n",
    "    return hp\n",
    "\n",
    "def objective(params):\n",
    "    \"\"\"Train and validate model with given hyperparams; return val_loss.\"\"\"\n",
    "    # Build loaders\n",
    "    train_loader = DataLoader(train_ds, batch_size=params['batch_size'], shuffle=True)\n",
    "    val_loader   = DataLoader(test_ds,  batch_size=params['batch_size'], shuffle=False)\n",
    "\n",
    "    model = EEG_CNN_LSTM_HPO(\n",
    "        cnn_kernels_1=params['cnn_kernels_1'],\n",
    "        cnn_kernel_size_1=params['cnn_kernel_size_1'],\n",
    "        cnn_kernels_2=params['cnn_kernels_2'],\n",
    "        cnn_dropout=float(params['cnn_dropout']),\n",
    "        cnn_dense=params['cnn_dense'],\n",
    "        lstm_hidden_size=params['lstm_hidden_size'],\n",
    "        lstm_layers=params['lstm_layers'],\n",
    "        lstm_dense=params['lstm_dense'],\n",
    "        dropout=float(params['cnn_dropout']),\n",
    "        num_classes=2\n",
    "    ).to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=params['learning_rate'], weight_decay=1e-4)\n",
    "\n",
    "    history = model.fit(\n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader,\n",
    "        epochs=60,\n",
    "        criterion=criterion,\n",
    "        optimizer=optimizer,\n",
    "        device=device,\n",
    "        patience=10\n",
    "    )\n",
    "\n",
    "    return float(np.min(history['val_losses'])) if len(history['val_losses']) > 0 else np.inf\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Main PSO loop with timer\n",
    "# ---------------------------------------------------------\n",
    "total_start = time.time()\n",
    "\n",
    "for it in range(max_iter):\n",
    "    iter_start = time.time()\n",
    "\n",
    "    for i in range(n_particles):\n",
    "        params = decode_position(positions[i])\n",
    "        loss = objective(params)\n",
    "\n",
    "        if loss < pbest_scores[i]:\n",
    "            pbest_scores[i] = loss\n",
    "            pbest_positions[i] = positions[i].copy()\n",
    "\n",
    "        if loss < gbest_score:\n",
    "            gbest_score = loss\n",
    "            gbest_position = positions[i].copy()\n",
    "\n",
    "    # Update velocities and positions\n",
    "    for i in range(n_particles):\n",
    "        r1, r2 = np.random.rand(dim), np.random.rand(dim)\n",
    "        velocities[i] = (w * velocities[i] +\n",
    "                         c1 * r1 * (pbest_positions[i] - positions[i]) +\n",
    "                         c2 * r2 * (gbest_position - positions[i]))\n",
    "        positions[i] += velocities[i]\n",
    "        positions[i] = np.clip(positions[i], 0.0, 1.0)\n",
    "\n",
    "    iter_time = time.time() - iter_start\n",
    "    total_time = time.time() - total_start\n",
    "    print(f\"Iteration {it+1}/{max_iter} | \"\n",
    "          f\"Best Val Loss: {gbest_score:.4f} | \"\n",
    "          f\"Iter Time: {iter_time:.2f}s | \"\n",
    "          f\"Total Time: {total_time/60:.2f} min\")\n",
    "\n",
    "print(\"Optimization finished.\")\n",
    "best_hyperparams = decode_position(gbest_position)\n",
    "print(\"Best Hyperparams:\", best_hyperparams)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a51e5733-6ec8-4f0c-a775-113ec89d0351",
   "metadata": {},
   "source": [
    "### Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "c2c57160-290a-45e1-a656-0935c3d92a40",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Trial 1/20 params: {'cnn_kernels_1': 24, 'cnn_kernel_size_1': 3, 'cnn_kernels_2': 35, 'cnn_dropout': 0.44105563115380825, 'cnn_dense': 210, 'lstm_hidden_size': 118, 'lstm_layers': 1, 'lstm_dense': 231, 'learning_rate': 0.002329335326653157, 'batch_size': 23}\n",
      "Epoch 001 | Train Loss: 0.6822 Acc: 0.5753 | Val Loss: 0.6739 Acc: 0.5954\n",
      "Epoch 002 | Train Loss: 0.6454 Acc: 0.6355 | Val Loss: 0.6062 Acc: 0.6806\n",
      "Epoch 003 | Train Loss: 0.5984 Acc: 0.6974 | Val Loss: 0.6047 Acc: 0.6842\n",
      "Epoch 004 | Train Loss: 0.5841 Acc: 0.7051 | Val Loss: 0.5800 Acc: 0.7095\n",
      "Epoch 005 | Train Loss: 0.5665 Acc: 0.7195 | Val Loss: 0.5638 Acc: 0.7150\n",
      "Epoch 006 | Train Loss: 0.5489 Acc: 0.7264 | Val Loss: 0.5824 Acc: 0.7156\n",
      "Epoch 007 | Train Loss: 0.5443 Acc: 0.7305 | Val Loss: 0.5147 Acc: 0.7566\n",
      "Epoch 008 | Train Loss: 0.5143 Acc: 0.7521 | Val Loss: 0.5325 Acc: 0.7367\n",
      "Epoch 009 | Train Loss: 0.5071 Acc: 0.7613 | Val Loss: 0.5140 Acc: 0.7446\n",
      "Epoch 010 | Train Loss: 0.4799 Acc: 0.7731 | Val Loss: 0.4648 Acc: 0.7772\n",
      "Epoch 011 | Train Loss: 0.4675 Acc: 0.7818 | Val Loss: 0.4528 Acc: 0.7838\n",
      "Epoch 012 | Train Loss: 0.4507 Acc: 0.7922 | Val Loss: 0.4524 Acc: 0.7880\n",
      "Epoch 013 | Train Loss: 0.4191 Acc: 0.8085 | Val Loss: 0.4261 Acc: 0.7989\n",
      "Epoch 014 | Train Loss: 0.4118 Acc: 0.8125 | Val Loss: 0.4228 Acc: 0.7923\n",
      "Epoch 015 | Train Loss: 0.3817 Acc: 0.8315 | Val Loss: 0.3835 Acc: 0.8400\n",
      "Epoch 016 | Train Loss: 0.3737 Acc: 0.8347 | Val Loss: 0.3601 Acc: 0.8321\n",
      "Epoch 017 | Train Loss: 0.3599 Acc: 0.8416 | Val Loss: 0.3487 Acc: 0.8382\n",
      "Epoch 018 | Train Loss: 0.3402 Acc: 0.8578 | Val Loss: 0.3411 Acc: 0.8508\n",
      "Epoch 019 | Train Loss: 0.3256 Acc: 0.8572 | Val Loss: 0.3249 Acc: 0.8593\n",
      "Epoch 020 | Train Loss: 0.3179 Acc: 0.8650 | Val Loss: 0.3600 Acc: 0.8454\n",
      "Epoch 021 | Train Loss: 0.3092 Acc: 0.8708 | Val Loss: 0.3044 Acc: 0.8756\n",
      "Epoch 022 | Train Loss: 0.2935 Acc: 0.8730 | Val Loss: 0.3136 Acc: 0.8738\n",
      "Epoch 023 | Train Loss: 0.2810 Acc: 0.8842 | Val Loss: 0.3095 Acc: 0.8635\n",
      "Epoch 024 | Train Loss: 0.2669 Acc: 0.8890 | Val Loss: 0.2976 Acc: 0.8732\n",
      "Epoch 025 | Train Loss: 0.2574 Acc: 0.8907 | Val Loss: 0.2660 Acc: 0.8865\n",
      "Epoch 026 | Train Loss: 0.2620 Acc: 0.8923 | Val Loss: 0.2775 Acc: 0.8847\n",
      "Epoch 027 | Train Loss: 0.2473 Acc: 0.8937 | Val Loss: 0.2582 Acc: 0.8973\n",
      "Epoch 028 | Train Loss: 0.2451 Acc: 0.9006 | Val Loss: 0.2353 Acc: 0.9064\n",
      "Epoch 029 | Train Loss: 0.2361 Acc: 0.9041 | Val Loss: 0.2699 Acc: 0.8889\n",
      "Epoch 030 | Train Loss: 0.2178 Acc: 0.9111 | Val Loss: 0.2395 Acc: 0.8998\n",
      "Epoch 031 | Train Loss: 0.2193 Acc: 0.9118 | Val Loss: 0.2505 Acc: 0.8931\n",
      "Epoch 032 | Train Loss: 0.2174 Acc: 0.9132 | Val Loss: 0.2302 Acc: 0.9004\n",
      "Epoch 033 | Train Loss: 0.2129 Acc: 0.9165 | Val Loss: 0.2289 Acc: 0.9046\n",
      "Epoch 034 | Train Loss: 0.1981 Acc: 0.9224 | Val Loss: 0.2717 Acc: 0.8943\n",
      "Epoch 035 | Train Loss: 0.2085 Acc: 0.9127 | Val Loss: 0.2074 Acc: 0.9179\n",
      "Epoch 036 | Train Loss: 0.1954 Acc: 0.9207 | Val Loss: 0.2140 Acc: 0.9191\n",
      "Epoch 037 | Train Loss: 0.1957 Acc: 0.9189 | Val Loss: 0.1834 Acc: 0.9251\n",
      "Epoch 038 | Train Loss: 0.1914 Acc: 0.9228 | Val Loss: 0.2446 Acc: 0.8998\n",
      "Epoch 039 | Train Loss: 0.1781 Acc: 0.9296 | Val Loss: 0.2071 Acc: 0.9191\n",
      "Epoch 040 | Train Loss: 0.1895 Acc: 0.9268 | Val Loss: 0.1960 Acc: 0.9215\n",
      "Epoch 041 | Train Loss: 0.1750 Acc: 0.9296 | Val Loss: 0.1845 Acc: 0.9275\n",
      "Epoch 042 | Train Loss: 0.1769 Acc: 0.9281 | Val Loss: 0.1888 Acc: 0.9263\n",
      "Epoch 043 | Train Loss: 0.1671 Acc: 0.9322 | Val Loss: 0.1868 Acc: 0.9197\n",
      "Epoch 044 | Train Loss: 0.1662 Acc: 0.9360 | Val Loss: 0.1947 Acc: 0.9179\n",
      "Epoch 045 | Train Loss: 0.1587 Acc: 0.9404 | Val Loss: 0.1693 Acc: 0.9275\n",
      "Epoch 046 | Train Loss: 0.1634 Acc: 0.9337 | Val Loss: 0.1747 Acc: 0.9275\n",
      "Epoch 047 | Train Loss: 0.1592 Acc: 0.9382 | Val Loss: 0.2009 Acc: 0.9197\n",
      "Epoch 048 | Train Loss: 0.1699 Acc: 0.9310 | Val Loss: 0.1809 Acc: 0.9287\n",
      "Epoch 049 | Train Loss: 0.1565 Acc: 0.9388 | Val Loss: 0.1842 Acc: 0.9269\n",
      "Epoch 050 | Train Loss: 0.1546 Acc: 0.9372 | Val Loss: 0.1678 Acc: 0.9330\n",
      "Epoch 051 | Train Loss: 0.1483 Acc: 0.9428 | Val Loss: 0.1677 Acc: 0.9330\n",
      "Epoch 052 | Train Loss: 0.1511 Acc: 0.9407 | Val Loss: 0.1860 Acc: 0.9251\n",
      "Epoch 053 | Train Loss: 0.1445 Acc: 0.9420 | Val Loss: 0.1517 Acc: 0.9396\n",
      "Epoch 054 | Train Loss: 0.1478 Acc: 0.9444 | Val Loss: 0.1783 Acc: 0.9306\n",
      "Epoch 055 | Train Loss: 0.1305 Acc: 0.9514 | Val Loss: 0.1775 Acc: 0.9300\n",
      "Epoch 056 | Train Loss: 0.1421 Acc: 0.9441 | Val Loss: 0.1575 Acc: 0.9366\n",
      "Epoch 057 | Train Loss: 0.1316 Acc: 0.9472 | Val Loss: 0.1631 Acc: 0.9336\n",
      "Epoch 058 | Train Loss: 0.1349 Acc: 0.9472 | Val Loss: 0.1682 Acc: 0.9408\n",
      "Epoch 059 | Train Loss: 0.1432 Acc: 0.9456 | Val Loss: 0.1753 Acc: 0.9330\n",
      "Epoch 060 | Train Loss: 0.1243 Acc: 0.9520 | Val Loss: 0.1429 Acc: 0.9414\n",
      "Trial 1/20 | Val Loss: 0.1429 | Best So Far: 0.1429 | Trial Time: 54.64s | Total Time: 0.91 min\n",
      "\n",
      "Trial 2/20 params: {'cnn_kernels_1': 31, 'cnn_kernel_size_1': 3, 'cnn_kernels_2': 25, 'cnn_dropout': 0.3358640152341014, 'cnn_dense': 123, 'lstm_hidden_size': 80, 'lstm_layers': 2, 'lstm_dense': 102, 'learning_rate': 0.004187261744637984, 'batch_size': 63}\n",
      "Epoch 001 | Train Loss: 0.6808 Acc: 0.5716 | Val Loss: 0.6731 Acc: 0.5888\n",
      "Epoch 002 | Train Loss: 0.6420 Acc: 0.6391 | Val Loss: 0.6065 Acc: 0.6781\n",
      "Epoch 003 | Train Loss: 0.5949 Acc: 0.6985 | Val Loss: 0.5871 Acc: 0.6920\n",
      "Epoch 004 | Train Loss: 0.5705 Acc: 0.7148 | Val Loss: 0.5703 Acc: 0.7101\n",
      "Epoch 005 | Train Loss: 0.5611 Acc: 0.7275 | Val Loss: 0.5622 Acc: 0.7132\n",
      "Epoch 006 | Train Loss: 0.5524 Acc: 0.7308 | Val Loss: 0.5423 Acc: 0.7343\n",
      "Epoch 007 | Train Loss: 0.5285 Acc: 0.7441 | Val Loss: 0.5554 Acc: 0.7144\n",
      "Epoch 008 | Train Loss: 0.5151 Acc: 0.7498 | Val Loss: 0.4992 Acc: 0.7476\n",
      "Epoch 009 | Train Loss: 0.4989 Acc: 0.7663 | Val Loss: 0.5157 Acc: 0.7355\n",
      "Epoch 010 | Train Loss: 0.4951 Acc: 0.7673 | Val Loss: 0.4777 Acc: 0.7627\n",
      "Epoch 011 | Train Loss: 0.4717 Acc: 0.7752 | Val Loss: 0.4577 Acc: 0.7820\n",
      "Epoch 012 | Train Loss: 0.4522 Acc: 0.7864 | Val Loss: 0.4335 Acc: 0.7929\n",
      "Epoch 013 | Train Loss: 0.4658 Acc: 0.7860 | Val Loss: 0.4207 Acc: 0.8092\n",
      "Epoch 014 | Train Loss: 0.4282 Acc: 0.8045 | Val Loss: 0.4231 Acc: 0.8164\n",
      "Epoch 015 | Train Loss: 0.4258 Acc: 0.8027 | Val Loss: 0.3757 Acc: 0.8297\n",
      "Epoch 016 | Train Loss: 0.3895 Acc: 0.8256 | Val Loss: 0.3663 Acc: 0.8255\n",
      "Epoch 017 | Train Loss: 0.3978 Acc: 0.8212 | Val Loss: 0.3772 Acc: 0.8291\n",
      "Epoch 018 | Train Loss: 0.3742 Acc: 0.8338 | Val Loss: 0.3600 Acc: 0.8297\n",
      "Epoch 019 | Train Loss: 0.3570 Acc: 0.8458 | Val Loss: 0.3865 Acc: 0.8194\n",
      "Epoch 020 | Train Loss: 0.3588 Acc: 0.8474 | Val Loss: 0.3553 Acc: 0.8412\n",
      "Epoch 021 | Train Loss: 0.3464 Acc: 0.8502 | Val Loss: 0.3424 Acc: 0.8545\n",
      "Epoch 022 | Train Loss: 0.3411 Acc: 0.8531 | Val Loss: 0.3231 Acc: 0.8611\n",
      "Epoch 023 | Train Loss: 0.3219 Acc: 0.8659 | Val Loss: 0.2771 Acc: 0.8816\n",
      "Epoch 024 | Train Loss: 0.3163 Acc: 0.8686 | Val Loss: 0.3107 Acc: 0.8653\n",
      "Epoch 025 | Train Loss: 0.3222 Acc: 0.8656 | Val Loss: 0.3061 Acc: 0.8702\n",
      "Epoch 026 | Train Loss: 0.3147 Acc: 0.8717 | Val Loss: 0.2999 Acc: 0.8702\n",
      "Epoch 027 | Train Loss: 0.2987 Acc: 0.8763 | Val Loss: 0.3060 Acc: 0.8816\n",
      "Epoch 028 | Train Loss: 0.2872 Acc: 0.8831 | Val Loss: 0.2667 Acc: 0.8865\n",
      "Epoch 029 | Train Loss: 0.2730 Acc: 0.8830 | Val Loss: 0.2851 Acc: 0.8726\n",
      "Epoch 030 | Train Loss: 0.2932 Acc: 0.8774 | Val Loss: 0.2507 Acc: 0.8955\n",
      "Epoch 031 | Train Loss: 0.2578 Acc: 0.8925 | Val Loss: 0.2893 Acc: 0.8756\n",
      "Epoch 032 | Train Loss: 0.2724 Acc: 0.8911 | Val Loss: 0.2694 Acc: 0.8973\n",
      "Epoch 033 | Train Loss: 0.2545 Acc: 0.8991 | Val Loss: 0.2541 Acc: 0.8961\n",
      "Epoch 034 | Train Loss: 0.2436 Acc: 0.9016 | Val Loss: 0.2459 Acc: 0.8998\n",
      "Epoch 035 | Train Loss: 0.2455 Acc: 0.8991 | Val Loss: 0.2332 Acc: 0.9082\n",
      "Epoch 036 | Train Loss: 0.2383 Acc: 0.9046 | Val Loss: 0.2282 Acc: 0.8913\n",
      "Epoch 037 | Train Loss: 0.2314 Acc: 0.9085 | Val Loss: 0.2376 Acc: 0.8998\n",
      "Epoch 038 | Train Loss: 0.2231 Acc: 0.9074 | Val Loss: 0.2312 Acc: 0.9070\n",
      "Epoch 039 | Train Loss: 0.2191 Acc: 0.9058 | Val Loss: 0.2249 Acc: 0.9130\n",
      "Epoch 040 | Train Loss: 0.2133 Acc: 0.9150 | Val Loss: 0.2289 Acc: 0.9034\n",
      "Epoch 041 | Train Loss: 0.2131 Acc: 0.9111 | Val Loss: 0.2250 Acc: 0.9167\n",
      "Epoch 042 | Train Loss: 0.2035 Acc: 0.9186 | Val Loss: 0.2025 Acc: 0.9203\n",
      "Epoch 043 | Train Loss: 0.1976 Acc: 0.9239 | Val Loss: 0.2082 Acc: 0.9209\n",
      "Epoch 044 | Train Loss: 0.2175 Acc: 0.9112 | Val Loss: 0.1861 Acc: 0.9263\n",
      "Epoch 045 | Train Loss: 0.2051 Acc: 0.9192 | Val Loss: 0.2030 Acc: 0.9149\n",
      "Epoch 046 | Train Loss: 0.2000 Acc: 0.9218 | Val Loss: 0.1809 Acc: 0.9251\n",
      "Epoch 047 | Train Loss: 0.1919 Acc: 0.9315 | Val Loss: 0.3070 Acc: 0.8762\n",
      "Epoch 048 | Train Loss: 0.1900 Acc: 0.9274 | Val Loss: 0.2273 Acc: 0.9143\n",
      "Epoch 049 | Train Loss: 0.1829 Acc: 0.9336 | Val Loss: 0.2630 Acc: 0.8907\n",
      "Epoch 050 | Train Loss: 0.1900 Acc: 0.9269 | Val Loss: 0.1994 Acc: 0.9269\n",
      "Epoch 051 | Train Loss: 0.1796 Acc: 0.9283 | Val Loss: 0.1836 Acc: 0.9257\n",
      "Epoch 052 | Train Loss: 0.1754 Acc: 0.9354 | Val Loss: 0.1836 Acc: 0.9251\n",
      "Epoch 053 | Train Loss: 0.1729 Acc: 0.9305 | Val Loss: 0.1929 Acc: 0.9257\n",
      "Epoch 054 | Train Loss: 0.1794 Acc: 0.9308 | Val Loss: 0.2012 Acc: 0.9221\n",
      "Epoch 055 | Train Loss: 0.1810 Acc: 0.9313 | Val Loss: 0.1733 Acc: 0.9348\n",
      "Epoch 056 | Train Loss: 0.1721 Acc: 0.9319 | Val Loss: 0.2330 Acc: 0.9076\n",
      "Epoch 057 | Train Loss: 0.1649 Acc: 0.9381 | Val Loss: 0.1830 Acc: 0.9269\n",
      "Epoch 058 | Train Loss: 0.1644 Acc: 0.9398 | Val Loss: 0.1942 Acc: 0.9239\n",
      "Epoch 059 | Train Loss: 0.1603 Acc: 0.9379 | Val Loss: 0.1747 Acc: 0.9287\n",
      "Epoch 060 | Train Loss: 0.1628 Acc: 0.9413 | Val Loss: 0.1808 Acc: 0.9300\n",
      "Trial 2/20 | Val Loss: 0.1733 | Best So Far: 0.1429 | Trial Time: 24.80s | Total Time: 1.32 min\n",
      "\n",
      "Trial 3/20 params: {'cnn_kernels_1': 39, 'cnn_kernel_size_1': 5, 'cnn_kernels_2': 43, 'cnn_dropout': 0.025173932513513117, 'cnn_dense': 202, 'lstm_hidden_size': 42, 'lstm_layers': 1, 'lstm_dense': 84, 'learning_rate': 0.007558209047259118, 'batch_size': 30}\n",
      "Epoch 001 | Train Loss: 0.6838 Acc: 0.5692 | Val Loss: 0.6765 Acc: 0.5851\n",
      "Epoch 002 | Train Loss: 0.6763 Acc: 0.5875 | Val Loss: 0.6863 Acc: 0.5586\n",
      "Epoch 003 | Train Loss: 0.6868 Acc: 0.5582 | Val Loss: 0.6863 Acc: 0.5586\n",
      "Epoch 004 | Train Loss: 0.6867 Acc: 0.5582 | Val Loss: 0.6865 Acc: 0.5586\n",
      "Epoch 005 | Train Loss: 0.6867 Acc: 0.5582 | Val Loss: 0.6864 Acc: 0.5586\n",
      "Epoch 006 | Train Loss: 0.6869 Acc: 0.5582 | Val Loss: 0.6863 Acc: 0.5586\n",
      "Epoch 007 | Train Loss: 0.6869 Acc: 0.5582 | Val Loss: 0.6864 Acc: 0.5586\n",
      "Epoch 008 | Train Loss: 0.6868 Acc: 0.5582 | Val Loss: 0.6863 Acc: 0.5586\n",
      "Epoch 009 | Train Loss: 0.6869 Acc: 0.5582 | Val Loss: 0.6863 Acc: 0.5586\n",
      "Epoch 010 | Train Loss: 0.6873 Acc: 0.5555 | Val Loss: 0.6865 Acc: 0.5586\n",
      "Epoch 011 | Train Loss: 0.6868 Acc: 0.5582 | Val Loss: 0.6864 Acc: 0.5586\n",
      "Early stopping triggered.\n",
      "Trial 3/20 | Val Loss: 0.6765 | Best So Far: 0.1429 | Trial Time: 7.74s | Total Time: 1.45 min\n",
      "\n",
      "Trial 4/20 params: {'cnn_kernels_1': 26, 'cnn_kernel_size_1': 5, 'cnn_kernels_2': 44, 'cnn_dropout': 0.6808917737408321, 'cnn_dense': 134, 'lstm_hidden_size': 126, 'lstm_layers': 3, 'lstm_dense': 147, 'learning_rate': 0.0007051016265884198, 'batch_size': 18}\n",
      "Epoch 001 | Train Loss: 0.6812 Acc: 0.5703 | Val Loss: 0.6776 Acc: 0.5821\n",
      "Epoch 002 | Train Loss: 0.6730 Acc: 0.5934 | Val Loss: 0.6786 Acc: 0.5948\n",
      "Epoch 003 | Train Loss: 0.6672 Acc: 0.6037 | Val Loss: 0.6591 Acc: 0.6051\n",
      "Epoch 004 | Train Loss: 0.6476 Acc: 0.6342 | Val Loss: 0.6490 Acc: 0.6268\n",
      "Epoch 005 | Train Loss: 0.6166 Acc: 0.6788 | Val Loss: 0.5940 Acc: 0.6938\n",
      "Epoch 006 | Train Loss: 0.5995 Acc: 0.6977 | Val Loss: 0.5991 Acc: 0.6975\n",
      "Epoch 007 | Train Loss: 0.5933 Acc: 0.6983 | Val Loss: 0.5745 Acc: 0.7071\n",
      "Epoch 008 | Train Loss: 0.5808 Acc: 0.7077 | Val Loss: 0.5626 Acc: 0.7144\n",
      "Epoch 009 | Train Loss: 0.5693 Acc: 0.7192 | Val Loss: 0.5636 Acc: 0.7156\n",
      "Epoch 010 | Train Loss: 0.5646 Acc: 0.7199 | Val Loss: 0.5634 Acc: 0.7101\n",
      "Epoch 011 | Train Loss: 0.5598 Acc: 0.7266 | Val Loss: 0.5538 Acc: 0.7150\n",
      "Epoch 012 | Train Loss: 0.5532 Acc: 0.7254 | Val Loss: 0.5611 Acc: 0.7180\n",
      "Epoch 013 | Train Loss: 0.5550 Acc: 0.7284 | Val Loss: 0.5450 Acc: 0.7192\n",
      "Epoch 014 | Train Loss: 0.5514 Acc: 0.7308 | Val Loss: 0.5383 Acc: 0.7240\n",
      "Epoch 015 | Train Loss: 0.5414 Acc: 0.7395 | Val Loss: 0.5451 Acc: 0.7246\n",
      "Epoch 016 | Train Loss: 0.5321 Acc: 0.7420 | Val Loss: 0.5331 Acc: 0.7307\n",
      "Epoch 017 | Train Loss: 0.5316 Acc: 0.7368 | Val Loss: 0.5435 Acc: 0.7210\n",
      "Epoch 018 | Train Loss: 0.5306 Acc: 0.7426 | Val Loss: 0.5608 Acc: 0.7216\n",
      "Epoch 019 | Train Loss: 0.5186 Acc: 0.7540 | Val Loss: 0.5398 Acc: 0.7271\n",
      "Epoch 020 | Train Loss: 0.5178 Acc: 0.7495 | Val Loss: 0.5279 Acc: 0.7301\n",
      "Epoch 021 | Train Loss: 0.5149 Acc: 0.7510 | Val Loss: 0.5027 Acc: 0.7476\n",
      "Epoch 022 | Train Loss: 0.5064 Acc: 0.7571 | Val Loss: 0.5091 Acc: 0.7397\n",
      "Epoch 023 | Train Loss: 0.5019 Acc: 0.7598 | Val Loss: 0.5040 Acc: 0.7446\n",
      "Epoch 024 | Train Loss: 0.4937 Acc: 0.7622 | Val Loss: 0.4841 Acc: 0.7597\n",
      "Epoch 025 | Train Loss: 0.4919 Acc: 0.7643 | Val Loss: 0.4769 Acc: 0.7687\n",
      "Epoch 026 | Train Loss: 0.4869 Acc: 0.7693 | Val Loss: 0.4719 Acc: 0.7736\n",
      "Epoch 027 | Train Loss: 0.4747 Acc: 0.7762 | Val Loss: 0.4636 Acc: 0.7772\n",
      "Epoch 028 | Train Loss: 0.4750 Acc: 0.7746 | Val Loss: 0.4763 Acc: 0.7566\n",
      "Epoch 029 | Train Loss: 0.4696 Acc: 0.7820 | Val Loss: 0.4624 Acc: 0.7766\n",
      "Epoch 030 | Train Loss: 0.4685 Acc: 0.7799 | Val Loss: 0.4498 Acc: 0.7862\n",
      "Epoch 031 | Train Loss: 0.4561 Acc: 0.7897 | Val Loss: 0.4572 Acc: 0.7778\n",
      "Epoch 032 | Train Loss: 0.4591 Acc: 0.7808 | Val Loss: 0.4472 Acc: 0.7862\n",
      "Epoch 033 | Train Loss: 0.4506 Acc: 0.7924 | Val Loss: 0.4556 Acc: 0.7796\n",
      "Epoch 034 | Train Loss: 0.4419 Acc: 0.7984 | Val Loss: 0.4839 Acc: 0.7560\n",
      "Epoch 035 | Train Loss: 0.4438 Acc: 0.7957 | Val Loss: 0.4226 Acc: 0.7971\n",
      "Epoch 036 | Train Loss: 0.4352 Acc: 0.8024 | Val Loss: 0.4182 Acc: 0.8062\n",
      "Epoch 037 | Train Loss: 0.4237 Acc: 0.8070 | Val Loss: 0.4020 Acc: 0.8110\n",
      "Epoch 038 | Train Loss: 0.4221 Acc: 0.8057 | Val Loss: 0.4143 Acc: 0.8007\n",
      "Epoch 039 | Train Loss: 0.4189 Acc: 0.8052 | Val Loss: 0.4041 Acc: 0.8134\n",
      "Epoch 040 | Train Loss: 0.4179 Acc: 0.8078 | Val Loss: 0.3882 Acc: 0.8200\n",
      "Epoch 041 | Train Loss: 0.4141 Acc: 0.8095 | Val Loss: 0.3972 Acc: 0.8249\n",
      "Epoch 042 | Train Loss: 0.3949 Acc: 0.8279 | Val Loss: 0.3872 Acc: 0.8279\n",
      "Epoch 043 | Train Loss: 0.3965 Acc: 0.8211 | Val Loss: 0.3883 Acc: 0.8146\n",
      "Epoch 044 | Train Loss: 0.3902 Acc: 0.8256 | Val Loss: 0.4150 Acc: 0.8080\n",
      "Epoch 045 | Train Loss: 0.3875 Acc: 0.8270 | Val Loss: 0.3502 Acc: 0.8376\n",
      "Epoch 046 | Train Loss: 0.3786 Acc: 0.8286 | Val Loss: 0.3666 Acc: 0.8327\n",
      "Epoch 047 | Train Loss: 0.3638 Acc: 0.8413 | Val Loss: 0.3656 Acc: 0.8315\n",
      "Epoch 048 | Train Loss: 0.3753 Acc: 0.8318 | Val Loss: 0.3945 Acc: 0.8080\n",
      "Epoch 049 | Train Loss: 0.3624 Acc: 0.8393 | Val Loss: 0.3556 Acc: 0.8376\n",
      "Epoch 050 | Train Loss: 0.3588 Acc: 0.8446 | Val Loss: 0.3576 Acc: 0.8569\n",
      "Epoch 051 | Train Loss: 0.3596 Acc: 0.8437 | Val Loss: 0.3311 Acc: 0.8545\n",
      "Epoch 052 | Train Loss: 0.3506 Acc: 0.8463 | Val Loss: 0.3081 Acc: 0.8629\n",
      "Epoch 053 | Train Loss: 0.3443 Acc: 0.8516 | Val Loss: 0.3032 Acc: 0.8659\n",
      "Epoch 054 | Train Loss: 0.3341 Acc: 0.8576 | Val Loss: 0.3106 Acc: 0.8617\n",
      "Epoch 055 | Train Loss: 0.3364 Acc: 0.8508 | Val Loss: 0.2911 Acc: 0.8738\n",
      "Epoch 056 | Train Loss: 0.3272 Acc: 0.8599 | Val Loss: 0.3037 Acc: 0.8659\n",
      "Epoch 057 | Train Loss: 0.3271 Acc: 0.8554 | Val Loss: 0.3023 Acc: 0.8647\n",
      "Epoch 058 | Train Loss: 0.3182 Acc: 0.8653 | Val Loss: 0.2680 Acc: 0.8853\n",
      "Epoch 059 | Train Loss: 0.3230 Acc: 0.8558 | Val Loss: 0.2795 Acc: 0.8883\n",
      "Epoch 060 | Train Loss: 0.3175 Acc: 0.8614 | Val Loss: 0.2780 Acc: 0.8859\n",
      "Trial 4/20 | Val Loss: 0.2680 | Best So Far: 0.1429 | Trial Time: 87.37s | Total Time: 2.91 min\n",
      "\n",
      "Trial 5/20 params: {'cnn_kernels_1': 49, 'cnn_kernel_size_1': 5, 'cnn_kernels_2': 56, 'cnn_dropout': 0.5281695679460859, 'cnn_dense': 222, 'lstm_hidden_size': 87, 'lstm_layers': 1, 'lstm_dense': 145, 'learning_rate': 0.004365722603393715, 'batch_size': 57}\n",
      "Epoch 001 | Train Loss: 0.6836 Acc: 0.5522 | Val Loss: 0.6755 Acc: 0.5851\n",
      "Epoch 002 | Train Loss: 0.6486 Acc: 0.6323 | Val Loss: 0.6402 Acc: 0.6371\n",
      "Epoch 003 | Train Loss: 0.5910 Acc: 0.6952 | Val Loss: 0.5633 Acc: 0.7162\n",
      "Epoch 004 | Train Loss: 0.5578 Acc: 0.7228 | Val Loss: 0.5751 Acc: 0.7047\n",
      "Epoch 005 | Train Loss: 0.5383 Acc: 0.7309 | Val Loss: 0.5559 Acc: 0.7156\n",
      "Epoch 006 | Train Loss: 0.5224 Acc: 0.7471 | Val Loss: 0.5282 Acc: 0.7240\n",
      "Epoch 007 | Train Loss: 0.5137 Acc: 0.7516 | Val Loss: 0.5467 Acc: 0.7150\n",
      "Epoch 008 | Train Loss: 0.5050 Acc: 0.7580 | Val Loss: 0.5083 Acc: 0.7452\n",
      "Epoch 009 | Train Loss: 0.4826 Acc: 0.7649 | Val Loss: 0.4919 Acc: 0.7536\n",
      "Epoch 010 | Train Loss: 0.4757 Acc: 0.7719 | Val Loss: 0.4805 Acc: 0.7754\n",
      "Epoch 011 | Train Loss: 0.4631 Acc: 0.7799 | Val Loss: 0.4913 Acc: 0.7428\n",
      "Epoch 012 | Train Loss: 0.4647 Acc: 0.7765 | Val Loss: 0.4334 Acc: 0.7935\n",
      "Epoch 013 | Train Loss: 0.4449 Acc: 0.7922 | Val Loss: 0.4735 Acc: 0.7560\n",
      "Epoch 014 | Train Loss: 0.4428 Acc: 0.7927 | Val Loss: 0.4346 Acc: 0.7923\n",
      "Epoch 015 | Train Loss: 0.4252 Acc: 0.7978 | Val Loss: 0.3966 Acc: 0.8116\n",
      "Epoch 016 | Train Loss: 0.4134 Acc: 0.8066 | Val Loss: 0.3878 Acc: 0.8213\n",
      "Epoch 017 | Train Loss: 0.4003 Acc: 0.8176 | Val Loss: 0.3805 Acc: 0.8285\n",
      "Epoch 018 | Train Loss: 0.3849 Acc: 0.8304 | Val Loss: 0.3753 Acc: 0.8297\n",
      "Epoch 019 | Train Loss: 0.3868 Acc: 0.8247 | Val Loss: 0.3771 Acc: 0.8345\n",
      "Epoch 020 | Train Loss: 0.3853 Acc: 0.8297 | Val Loss: 0.3534 Acc: 0.8327\n",
      "Epoch 021 | Train Loss: 0.3576 Acc: 0.8396 | Val Loss: 0.3921 Acc: 0.8170\n",
      "Epoch 022 | Train Loss: 0.3530 Acc: 0.8386 | Val Loss: 0.3268 Acc: 0.8569\n",
      "Epoch 023 | Train Loss: 0.3464 Acc: 0.8484 | Val Loss: 0.3445 Acc: 0.8605\n",
      "Epoch 024 | Train Loss: 0.3420 Acc: 0.8520 | Val Loss: 0.3136 Acc: 0.8690\n",
      "Epoch 025 | Train Loss: 0.3297 Acc: 0.8555 | Val Loss: 0.3342 Acc: 0.8527\n",
      "Epoch 026 | Train Loss: 0.3185 Acc: 0.8572 | Val Loss: 0.2756 Acc: 0.8822\n",
      "Epoch 027 | Train Loss: 0.3102 Acc: 0.8661 | Val Loss: 0.3111 Acc: 0.8641\n",
      "Epoch 028 | Train Loss: 0.3007 Acc: 0.8677 | Val Loss: 0.3242 Acc: 0.8575\n",
      "Epoch 029 | Train Loss: 0.2851 Acc: 0.8741 | Val Loss: 0.2765 Acc: 0.8804\n",
      "Epoch 030 | Train Loss: 0.2852 Acc: 0.8798 | Val Loss: 0.2937 Acc: 0.8804\n",
      "Epoch 031 | Train Loss: 0.2694 Acc: 0.8871 | Val Loss: 0.2897 Acc: 0.8768\n",
      "Epoch 032 | Train Loss: 0.2626 Acc: 0.8955 | Val Loss: 0.2392 Acc: 0.8949\n",
      "Epoch 033 | Train Loss: 0.2586 Acc: 0.8933 | Val Loss: 0.2645 Acc: 0.8913\n",
      "Epoch 034 | Train Loss: 0.2558 Acc: 0.8940 | Val Loss: 0.2636 Acc: 0.8883\n",
      "Epoch 035 | Train Loss: 0.2472 Acc: 0.9010 | Val Loss: 0.2369 Acc: 0.9010\n",
      "Epoch 036 | Train Loss: 0.2453 Acc: 0.9002 | Val Loss: 0.2240 Acc: 0.9064\n",
      "Epoch 037 | Train Loss: 0.2372 Acc: 0.9028 | Val Loss: 0.2733 Acc: 0.8829\n",
      "Epoch 038 | Train Loss: 0.2346 Acc: 0.9002 | Val Loss: 0.2161 Acc: 0.9058\n",
      "Epoch 039 | Train Loss: 0.2279 Acc: 0.9087 | Val Loss: 0.2244 Acc: 0.8961\n",
      "Epoch 040 | Train Loss: 0.2166 Acc: 0.9111 | Val Loss: 0.2089 Acc: 0.9167\n",
      "Epoch 041 | Train Loss: 0.2231 Acc: 0.9109 | Val Loss: 0.2299 Acc: 0.9070\n",
      "Epoch 042 | Train Loss: 0.2131 Acc: 0.9126 | Val Loss: 0.2077 Acc: 0.9143\n",
      "Epoch 043 | Train Loss: 0.1984 Acc: 0.9195 | Val Loss: 0.2376 Acc: 0.8961\n",
      "Epoch 044 | Train Loss: 0.2146 Acc: 0.9142 | Val Loss: 0.2613 Acc: 0.8841\n",
      "Epoch 045 | Train Loss: 0.1967 Acc: 0.9221 | Val Loss: 0.2563 Acc: 0.8907\n",
      "Epoch 046 | Train Loss: 0.2024 Acc: 0.9174 | Val Loss: 0.2302 Acc: 0.9040\n",
      "Epoch 047 | Train Loss: 0.2104 Acc: 0.9127 | Val Loss: 0.2152 Acc: 0.9034\n",
      "Epoch 048 | Train Loss: 0.1855 Acc: 0.9239 | Val Loss: 0.2054 Acc: 0.9263\n",
      "Epoch 049 | Train Loss: 0.1911 Acc: 0.9207 | Val Loss: 0.1895 Acc: 0.9221\n",
      "Epoch 050 | Train Loss: 0.1858 Acc: 0.9251 | Val Loss: 0.1758 Acc: 0.9257\n",
      "Epoch 051 | Train Loss: 0.1863 Acc: 0.9262 | Val Loss: 0.1773 Acc: 0.9239\n",
      "Epoch 052 | Train Loss: 0.1787 Acc: 0.9336 | Val Loss: 0.2197 Acc: 0.9064\n",
      "Epoch 053 | Train Loss: 0.1835 Acc: 0.9262 | Val Loss: 0.1700 Acc: 0.9287\n",
      "Epoch 054 | Train Loss: 0.1804 Acc: 0.9307 | Val Loss: 0.1755 Acc: 0.9300\n",
      "Epoch 055 | Train Loss: 0.1814 Acc: 0.9281 | Val Loss: 0.2108 Acc: 0.9118\n",
      "Epoch 056 | Train Loss: 0.1715 Acc: 0.9315 | Val Loss: 0.1732 Acc: 0.9269\n",
      "Epoch 057 | Train Loss: 0.1717 Acc: 0.9308 | Val Loss: 0.2022 Acc: 0.9209\n",
      "Epoch 058 | Train Loss: 0.1632 Acc: 0.9363 | Val Loss: 0.1969 Acc: 0.9203\n",
      "Epoch 059 | Train Loss: 0.1620 Acc: 0.9322 | Val Loss: 0.1811 Acc: 0.9287\n",
      "Epoch 060 | Train Loss: 0.1692 Acc: 0.9357 | Val Loss: 0.1824 Acc: 0.9269\n",
      "Trial 5/20 | Val Loss: 0.1700 | Best So Far: 0.1429 | Trial Time: 25.07s | Total Time: 3.33 min\n",
      "\n",
      "Trial 6/20 params: {'cnn_kernels_1': 52, 'cnn_kernel_size_1': 3, 'cnn_kernels_2': 96, 'cnn_dropout': 0.2508510741066411, 'cnn_dense': 204, 'lstm_hidden_size': 121, 'lstm_layers': 2, 'lstm_dense': 111, 'learning_rate': 0.007719412610157963, 'batch_size': 59}\n",
      "Epoch 001 | Train Loss: 0.6822 Acc: 0.5638 | Val Loss: 0.6870 Acc: 0.5586\n",
      "Epoch 002 | Train Loss: 0.6866 Acc: 0.5582 | Val Loss: 0.6865 Acc: 0.5586\n",
      "Epoch 003 | Train Loss: 0.6861 Acc: 0.5564 | Val Loss: 0.6857 Acc: 0.5586\n",
      "Epoch 004 | Train Loss: 0.6857 Acc: 0.5573 | Val Loss: 0.6852 Acc: 0.5586\n",
      "Epoch 005 | Train Loss: 0.6822 Acc: 0.5621 | Val Loss: 0.6731 Acc: 0.5761\n",
      "Epoch 006 | Train Loss: 0.6585 Acc: 0.6240 | Val Loss: 0.6365 Acc: 0.6383\n",
      "Epoch 007 | Train Loss: 0.6302 Acc: 0.6589 | Val Loss: 0.6004 Acc: 0.6793\n",
      "Epoch 008 | Train Loss: 0.5952 Acc: 0.6939 | Val Loss: 0.5792 Acc: 0.6914\n",
      "Epoch 009 | Train Loss: 0.5801 Acc: 0.7095 | Val Loss: 0.5672 Acc: 0.7101\n",
      "Epoch 010 | Train Loss: 0.5633 Acc: 0.7167 | Val Loss: 0.5703 Acc: 0.7162\n",
      "Epoch 011 | Train Loss: 0.5538 Acc: 0.7267 | Val Loss: 0.5498 Acc: 0.7337\n",
      "Epoch 012 | Train Loss: 0.5494 Acc: 0.7317 | Val Loss: 0.5211 Acc: 0.7367\n",
      "Epoch 013 | Train Loss: 0.5418 Acc: 0.7385 | Val Loss: 0.5241 Acc: 0.7415\n",
      "Epoch 014 | Train Loss: 0.5331 Acc: 0.7392 | Val Loss: 0.5206 Acc: 0.7295\n",
      "Epoch 015 | Train Loss: 0.5152 Acc: 0.7577 | Val Loss: 0.5165 Acc: 0.7446\n",
      "Epoch 016 | Train Loss: 0.5126 Acc: 0.7549 | Val Loss: 0.5077 Acc: 0.7500\n",
      "Epoch 017 | Train Loss: 0.4923 Acc: 0.7664 | Val Loss: 0.4882 Acc: 0.7536\n",
      "Epoch 018 | Train Loss: 0.4765 Acc: 0.7725 | Val Loss: 0.4545 Acc: 0.7760\n",
      "Epoch 019 | Train Loss: 0.4855 Acc: 0.7663 | Val Loss: 0.4581 Acc: 0.7657\n",
      "Epoch 020 | Train Loss: 0.4627 Acc: 0.7824 | Val Loss: 0.4433 Acc: 0.7711\n",
      "Epoch 021 | Train Loss: 0.4453 Acc: 0.7924 | Val Loss: 0.4557 Acc: 0.7717\n",
      "Epoch 022 | Train Loss: 0.4496 Acc: 0.7916 | Val Loss: 0.4562 Acc: 0.7868\n",
      "Epoch 023 | Train Loss: 0.4263 Acc: 0.8088 | Val Loss: 0.4491 Acc: 0.7796\n",
      "Epoch 024 | Train Loss: 0.4152 Acc: 0.8125 | Val Loss: 0.3823 Acc: 0.8231\n",
      "Epoch 025 | Train Loss: 0.4164 Acc: 0.8114 | Val Loss: 0.4752 Acc: 0.7947\n",
      "Epoch 026 | Train Loss: 0.4103 Acc: 0.8156 | Val Loss: 0.4080 Acc: 0.8092\n",
      "Epoch 027 | Train Loss: 0.4072 Acc: 0.8184 | Val Loss: 0.3683 Acc: 0.8225\n",
      "Epoch 028 | Train Loss: 0.3925 Acc: 0.8279 | Val Loss: 0.3644 Acc: 0.8490\n",
      "Epoch 029 | Train Loss: 0.3828 Acc: 0.8323 | Val Loss: 0.3683 Acc: 0.8412\n",
      "Epoch 030 | Train Loss: 0.3727 Acc: 0.8401 | Val Loss: 0.4350 Acc: 0.7748\n",
      "Epoch 031 | Train Loss: 0.3732 Acc: 0.8372 | Val Loss: 0.3434 Acc: 0.8454\n",
      "Epoch 032 | Train Loss: 0.3605 Acc: 0.8457 | Val Loss: 0.3572 Acc: 0.8466\n",
      "Epoch 033 | Train Loss: 0.3537 Acc: 0.8501 | Val Loss: 0.3955 Acc: 0.8261\n",
      "Epoch 034 | Train Loss: 0.3525 Acc: 0.8437 | Val Loss: 0.3676 Acc: 0.8484\n",
      "Epoch 035 | Train Loss: 0.3446 Acc: 0.8508 | Val Loss: 0.3169 Acc: 0.8665\n",
      "Epoch 036 | Train Loss: 0.3443 Acc: 0.8489 | Val Loss: 0.3346 Acc: 0.8659\n",
      "Epoch 037 | Train Loss: 0.3297 Acc: 0.8560 | Val Loss: 0.3255 Acc: 0.8611\n",
      "Epoch 038 | Train Loss: 0.3164 Acc: 0.8682 | Val Loss: 0.3307 Acc: 0.8527\n",
      "Epoch 039 | Train Loss: 0.3031 Acc: 0.8729 | Val Loss: 0.2815 Acc: 0.8822\n",
      "Epoch 040 | Train Loss: 0.3191 Acc: 0.8708 | Val Loss: 0.3165 Acc: 0.8768\n",
      "Epoch 041 | Train Loss: 0.3171 Acc: 0.8677 | Val Loss: 0.2807 Acc: 0.8967\n",
      "Epoch 042 | Train Loss: 0.3006 Acc: 0.8748 | Val Loss: 0.2714 Acc: 0.8847\n",
      "Epoch 043 | Train Loss: 0.2903 Acc: 0.8810 | Val Loss: 0.3415 Acc: 0.8551\n",
      "Epoch 044 | Train Loss: 0.2930 Acc: 0.8782 | Val Loss: 0.2875 Acc: 0.8786\n",
      "Epoch 045 | Train Loss: 0.2804 Acc: 0.8833 | Val Loss: 0.2768 Acc: 0.8931\n",
      "Epoch 046 | Train Loss: 0.2757 Acc: 0.8919 | Val Loss: 0.2631 Acc: 0.8883\n",
      "Epoch 047 | Train Loss: 0.2643 Acc: 0.8939 | Val Loss: 0.2715 Acc: 0.8931\n",
      "Epoch 048 | Train Loss: 0.2694 Acc: 0.8933 | Val Loss: 0.2543 Acc: 0.9022\n",
      "Epoch 049 | Train Loss: 0.2648 Acc: 0.8954 | Val Loss: 0.2765 Acc: 0.8925\n",
      "Epoch 050 | Train Loss: 0.2487 Acc: 0.8966 | Val Loss: 0.2643 Acc: 0.8822\n",
      "Epoch 051 | Train Loss: 0.2423 Acc: 0.9017 | Val Loss: 0.2715 Acc: 0.9016\n",
      "Epoch 052 | Train Loss: 0.2447 Acc: 0.9020 | Val Loss: 0.2439 Acc: 0.9082\n",
      "Epoch 053 | Train Loss: 0.2388 Acc: 0.9008 | Val Loss: 0.2147 Acc: 0.9143\n",
      "Epoch 054 | Train Loss: 0.2354 Acc: 0.9100 | Val Loss: 0.2554 Acc: 0.9082\n",
      "Epoch 055 | Train Loss: 0.2241 Acc: 0.9112 | Val Loss: 0.2948 Acc: 0.8720\n",
      "Epoch 056 | Train Loss: 0.2333 Acc: 0.9028 | Val Loss: 0.2414 Acc: 0.9155\n",
      "Epoch 057 | Train Loss: 0.2456 Acc: 0.9041 | Val Loss: 0.2430 Acc: 0.9010\n",
      "Epoch 058 | Train Loss: 0.2338 Acc: 0.9074 | Val Loss: 0.2201 Acc: 0.9161\n",
      "Epoch 059 | Train Loss: 0.2177 Acc: 0.9147 | Val Loss: 0.2161 Acc: 0.9215\n",
      "Epoch 060 | Train Loss: 0.2279 Acc: 0.9112 | Val Loss: 0.2121 Acc: 0.9185\n",
      "Trial 6/20 | Val Loss: 0.2121 | Best So Far: 0.1429 | Trial Time: 27.50s | Total Time: 3.79 min\n",
      "\n",
      "Trial 7/20 params: {'cnn_kernels_1': 54, 'cnn_kernel_size_1': 5, 'cnn_kernels_2': 53, 'cnn_dropout': 0.45120521936912156, 'cnn_dense': 118, 'lstm_hidden_size': 45, 'lstm_layers': 2, 'lstm_dense': 208, 'learning_rate': 0.0045155837771488645, 'batch_size': 56}\n",
      "Epoch 001 | Train Loss: 0.6813 Acc: 0.5795 | Val Loss: 0.6767 Acc: 0.5851\n",
      "Epoch 002 | Train Loss: 0.6633 Acc: 0.6124 | Val Loss: 0.5998 Acc: 0.6800\n",
      "Epoch 003 | Train Loss: 0.5960 Acc: 0.6977 | Val Loss: 0.5794 Acc: 0.7023\n",
      "Epoch 004 | Train Loss: 0.5833 Acc: 0.7093 | Val Loss: 0.5536 Acc: 0.7337\n",
      "Epoch 005 | Train Loss: 0.5605 Acc: 0.7249 | Val Loss: 0.5576 Acc: 0.7240\n",
      "Epoch 006 | Train Loss: 0.5416 Acc: 0.7385 | Val Loss: 0.5498 Acc: 0.7361\n",
      "Epoch 007 | Train Loss: 0.5264 Acc: 0.7441 | Val Loss: 0.5267 Acc: 0.7470\n",
      "Epoch 008 | Train Loss: 0.5195 Acc: 0.7482 | Val Loss: 0.4922 Acc: 0.7651\n",
      "Epoch 009 | Train Loss: 0.4951 Acc: 0.7593 | Val Loss: 0.4784 Acc: 0.7609\n",
      "Epoch 010 | Train Loss: 0.4841 Acc: 0.7722 | Val Loss: 0.4857 Acc: 0.7681\n",
      "Epoch 011 | Train Loss: 0.4596 Acc: 0.7850 | Val Loss: 0.4368 Acc: 0.7893\n",
      "Epoch 012 | Train Loss: 0.4402 Acc: 0.7993 | Val Loss: 0.4160 Acc: 0.7941\n",
      "Epoch 013 | Train Loss: 0.4136 Acc: 0.8111 | Val Loss: 0.3930 Acc: 0.8152\n",
      "Epoch 014 | Train Loss: 0.3972 Acc: 0.8227 | Val Loss: 0.3594 Acc: 0.8339\n",
      "Epoch 015 | Train Loss: 0.3822 Acc: 0.8321 | Val Loss: 0.3612 Acc: 0.8339\n",
      "Epoch 016 | Train Loss: 0.3733 Acc: 0.8387 | Val Loss: 0.3244 Acc: 0.8569\n",
      "Epoch 017 | Train Loss: 0.3486 Acc: 0.8499 | Val Loss: 0.3322 Acc: 0.8581\n",
      "Epoch 018 | Train Loss: 0.3419 Acc: 0.8504 | Val Loss: 0.3165 Acc: 0.8653\n",
      "Epoch 019 | Train Loss: 0.3256 Acc: 0.8621 | Val Loss: 0.3428 Acc: 0.8629\n",
      "Epoch 020 | Train Loss: 0.3153 Acc: 0.8667 | Val Loss: 0.2815 Acc: 0.8829\n",
      "Epoch 021 | Train Loss: 0.3089 Acc: 0.8697 | Val Loss: 0.2905 Acc: 0.8822\n",
      "Epoch 022 | Train Loss: 0.2987 Acc: 0.8736 | Val Loss: 0.3214 Acc: 0.8653\n",
      "Epoch 023 | Train Loss: 0.2903 Acc: 0.8797 | Val Loss: 0.3028 Acc: 0.8690\n",
      "Epoch 024 | Train Loss: 0.2918 Acc: 0.8788 | Val Loss: 0.2814 Acc: 0.8841\n",
      "Epoch 025 | Train Loss: 0.2687 Acc: 0.8914 | Val Loss: 0.2746 Acc: 0.8913\n",
      "Epoch 026 | Train Loss: 0.2718 Acc: 0.8852 | Val Loss: 0.2875 Acc: 0.8750\n",
      "Epoch 027 | Train Loss: 0.2663 Acc: 0.8943 | Val Loss: 0.2391 Acc: 0.8949\n",
      "Epoch 028 | Train Loss: 0.2499 Acc: 0.8996 | Val Loss: 0.2707 Acc: 0.8895\n",
      "Epoch 029 | Train Loss: 0.2467 Acc: 0.8994 | Val Loss: 0.2457 Acc: 0.9034\n",
      "Epoch 030 | Train Loss: 0.2442 Acc: 0.9023 | Val Loss: 0.2403 Acc: 0.9052\n",
      "Epoch 031 | Train Loss: 0.2428 Acc: 0.9011 | Val Loss: 0.2374 Acc: 0.9022\n",
      "Epoch 032 | Train Loss: 0.2368 Acc: 0.9070 | Val Loss: 0.2317 Acc: 0.9124\n",
      "Epoch 033 | Train Loss: 0.2373 Acc: 0.9017 | Val Loss: 0.2373 Acc: 0.9016\n",
      "Epoch 034 | Train Loss: 0.2256 Acc: 0.9080 | Val Loss: 0.2453 Acc: 0.9016\n",
      "Epoch 035 | Train Loss: 0.2224 Acc: 0.9097 | Val Loss: 0.2266 Acc: 0.9100\n",
      "Epoch 036 | Train Loss: 0.2304 Acc: 0.9105 | Val Loss: 0.2149 Acc: 0.9118\n",
      "Epoch 037 | Train Loss: 0.2117 Acc: 0.9174 | Val Loss: 0.2067 Acc: 0.9185\n",
      "Epoch 038 | Train Loss: 0.2100 Acc: 0.9176 | Val Loss: 0.2348 Acc: 0.9040\n",
      "Epoch 039 | Train Loss: 0.2029 Acc: 0.9210 | Val Loss: 0.2183 Acc: 0.9112\n",
      "Epoch 040 | Train Loss: 0.1996 Acc: 0.9198 | Val Loss: 0.2136 Acc: 0.9100\n",
      "Epoch 041 | Train Loss: 0.2099 Acc: 0.9153 | Val Loss: 0.2251 Acc: 0.9046\n",
      "Epoch 042 | Train Loss: 0.2131 Acc: 0.9123 | Val Loss: 0.2202 Acc: 0.9185\n",
      "Epoch 043 | Train Loss: 0.1979 Acc: 0.9210 | Val Loss: 0.2330 Acc: 0.8973\n",
      "Epoch 044 | Train Loss: 0.1925 Acc: 0.9253 | Val Loss: 0.2228 Acc: 0.9058\n",
      "Epoch 045 | Train Loss: 0.1933 Acc: 0.9269 | Val Loss: 0.1991 Acc: 0.9155\n",
      "Epoch 046 | Train Loss: 0.1808 Acc: 0.9286 | Val Loss: 0.1930 Acc: 0.9257\n",
      "Epoch 047 | Train Loss: 0.1940 Acc: 0.9257 | Val Loss: 0.1990 Acc: 0.9239\n",
      "Epoch 048 | Train Loss: 0.1716 Acc: 0.9327 | Val Loss: 0.2758 Acc: 0.8955\n",
      "Epoch 049 | Train Loss: 0.1835 Acc: 0.9315 | Val Loss: 0.1888 Acc: 0.9239\n",
      "Epoch 050 | Train Loss: 0.1840 Acc: 0.9286 | Val Loss: 0.1918 Acc: 0.9293\n",
      "Epoch 051 | Train Loss: 0.1693 Acc: 0.9334 | Val Loss: 0.1898 Acc: 0.9191\n",
      "Epoch 052 | Train Loss: 0.1690 Acc: 0.9334 | Val Loss: 0.2188 Acc: 0.9070\n",
      "Epoch 053 | Train Loss: 0.1695 Acc: 0.9308 | Val Loss: 0.1980 Acc: 0.9221\n",
      "Epoch 054 | Train Loss: 0.1634 Acc: 0.9364 | Val Loss: 0.2028 Acc: 0.9161\n",
      "Epoch 055 | Train Loss: 0.1682 Acc: 0.9351 | Val Loss: 0.1764 Acc: 0.9269\n",
      "Epoch 056 | Train Loss: 0.1741 Acc: 0.9325 | Val Loss: 0.2095 Acc: 0.9070\n",
      "Epoch 057 | Train Loss: 0.1690 Acc: 0.9370 | Val Loss: 0.1841 Acc: 0.9239\n",
      "Epoch 058 | Train Loss: 0.1611 Acc: 0.9407 | Val Loss: 0.1668 Acc: 0.9293\n",
      "Epoch 059 | Train Loss: 0.1553 Acc: 0.9416 | Val Loss: 0.1811 Acc: 0.9293\n",
      "Epoch 060 | Train Loss: 0.1697 Acc: 0.9334 | Val Loss: 0.1798 Acc: 0.9239\n",
      "Trial 7/20 | Val Loss: 0.1668 | Best So Far: 0.1429 | Trial Time: 28.50s | Total Time: 4.26 min\n",
      "\n",
      "Trial 8/20 params: {'cnn_kernels_1': 63, 'cnn_kernel_size_1': 3, 'cnn_kernels_2': 95, 'cnn_dropout': 0.6653802075759618, 'cnn_dense': 149, 'lstm_hidden_size': 81, 'lstm_layers': 1, 'lstm_dense': 88, 'learning_rate': 0.007160756295056639, 'batch_size': 35}\n",
      "Epoch 001 | Train Loss: 0.6869 Acc: 0.5540 | Val Loss: 0.6712 Acc: 0.5954\n",
      "Epoch 002 | Train Loss: 0.6829 Acc: 0.5531 | Val Loss: 0.6731 Acc: 0.5586\n",
      "Epoch 003 | Train Loss: 0.6672 Acc: 0.5960 | Val Loss: 0.6572 Acc: 0.6178\n",
      "Epoch 004 | Train Loss: 0.6528 Acc: 0.6265 | Val Loss: 0.6419 Acc: 0.6383\n",
      "Epoch 005 | Train Loss: 0.6561 Acc: 0.6233 | Val Loss: 0.6247 Acc: 0.6594\n",
      "Epoch 006 | Train Loss: 0.6379 Acc: 0.6500 | Val Loss: 0.6205 Acc: 0.6685\n",
      "Epoch 007 | Train Loss: 0.6193 Acc: 0.6672 | Val Loss: 0.6000 Acc: 0.6842\n",
      "Epoch 008 | Train Loss: 0.6171 Acc: 0.6705 | Val Loss: 0.5878 Acc: 0.6963\n",
      "Epoch 009 | Train Loss: 0.6043 Acc: 0.6829 | Val Loss: 0.5988 Acc: 0.6848\n",
      "Epoch 010 | Train Loss: 0.6077 Acc: 0.6728 | Val Loss: 0.6255 Acc: 0.6516\n",
      "Epoch 011 | Train Loss: 0.5989 Acc: 0.6884 | Val Loss: 0.5520 Acc: 0.7192\n",
      "Epoch 012 | Train Loss: 0.5860 Acc: 0.6944 | Val Loss: 0.5568 Acc: 0.7114\n",
      "Epoch 013 | Train Loss: 0.5721 Acc: 0.7063 | Val Loss: 0.5909 Acc: 0.6896\n",
      "Epoch 014 | Train Loss: 0.5711 Acc: 0.7066 | Val Loss: 0.5275 Acc: 0.7391\n",
      "Epoch 015 | Train Loss: 0.5641 Acc: 0.7081 | Val Loss: 0.5444 Acc: 0.7234\n",
      "Epoch 016 | Train Loss: 0.5529 Acc: 0.7173 | Val Loss: 0.5229 Acc: 0.7500\n",
      "Epoch 017 | Train Loss: 0.5457 Acc: 0.7261 | Val Loss: 0.5138 Acc: 0.7458\n",
      "Epoch 018 | Train Loss: 0.5431 Acc: 0.7260 | Val Loss: 0.5237 Acc: 0.7409\n",
      "Epoch 019 | Train Loss: 0.5454 Acc: 0.7247 | Val Loss: 0.5215 Acc: 0.7397\n",
      "Epoch 020 | Train Loss: 0.5238 Acc: 0.7401 | Val Loss: 0.5034 Acc: 0.7512\n",
      "Epoch 021 | Train Loss: 0.5245 Acc: 0.7305 | Val Loss: 0.4920 Acc: 0.7482\n",
      "Epoch 022 | Train Loss: 0.5281 Acc: 0.7374 | Val Loss: 0.4938 Acc: 0.7615\n",
      "Epoch 023 | Train Loss: 0.5216 Acc: 0.7409 | Val Loss: 0.5088 Acc: 0.7240\n",
      "Epoch 024 | Train Loss: 0.5102 Acc: 0.7472 | Val Loss: 0.4811 Acc: 0.7627\n",
      "Epoch 025 | Train Loss: 0.5112 Acc: 0.7509 | Val Loss: 0.5000 Acc: 0.7572\n",
      "Epoch 026 | Train Loss: 0.4953 Acc: 0.7566 | Val Loss: 0.4850 Acc: 0.7687\n",
      "Epoch 027 | Train Loss: 0.5019 Acc: 0.7598 | Val Loss: 0.5044 Acc: 0.7458\n",
      "Epoch 028 | Train Loss: 0.4945 Acc: 0.7601 | Val Loss: 0.4833 Acc: 0.7742\n",
      "Epoch 029 | Train Loss: 0.4943 Acc: 0.7555 | Val Loss: 0.4645 Acc: 0.7814\n",
      "Epoch 030 | Train Loss: 0.4913 Acc: 0.7605 | Val Loss: 0.4646 Acc: 0.7838\n",
      "Epoch 031 | Train Loss: 0.4861 Acc: 0.7658 | Val Loss: 0.5053 Acc: 0.7603\n",
      "Epoch 032 | Train Loss: 0.4882 Acc: 0.7622 | Val Loss: 0.4493 Acc: 0.7941\n",
      "Epoch 033 | Train Loss: 0.4790 Acc: 0.7663 | Val Loss: 0.4479 Acc: 0.7838\n",
      "Epoch 034 | Train Loss: 0.4647 Acc: 0.7859 | Val Loss: 0.4625 Acc: 0.7808\n",
      "Epoch 035 | Train Loss: 0.4559 Acc: 0.7856 | Val Loss: 0.4742 Acc: 0.7790\n",
      "Epoch 036 | Train Loss: 0.4668 Acc: 0.7830 | Val Loss: 0.4557 Acc: 0.7911\n",
      "Epoch 037 | Train Loss: 0.4671 Acc: 0.7802 | Val Loss: 0.4467 Acc: 0.8007\n",
      "Epoch 038 | Train Loss: 0.4572 Acc: 0.7820 | Val Loss: 0.4534 Acc: 0.7868\n",
      "Epoch 039 | Train Loss: 0.4523 Acc: 0.7857 | Val Loss: 0.4357 Acc: 0.8013\n",
      "Epoch 040 | Train Loss: 0.4515 Acc: 0.7886 | Val Loss: 0.4857 Acc: 0.7675\n",
      "Epoch 041 | Train Loss: 0.4399 Acc: 0.7933 | Val Loss: 0.4207 Acc: 0.8062\n",
      "Epoch 042 | Train Loss: 0.4414 Acc: 0.7984 | Val Loss: 0.4252 Acc: 0.8025\n",
      "Epoch 043 | Train Loss: 0.4392 Acc: 0.7978 | Val Loss: 0.4321 Acc: 0.7856\n",
      "Epoch 044 | Train Loss: 0.4355 Acc: 0.8007 | Val Loss: 0.4324 Acc: 0.8152\n",
      "Epoch 045 | Train Loss: 0.4383 Acc: 0.8002 | Val Loss: 0.4284 Acc: 0.8110\n",
      "Epoch 046 | Train Loss: 0.4412 Acc: 0.8005 | Val Loss: 0.4144 Acc: 0.8110\n",
      "Epoch 047 | Train Loss: 0.4253 Acc: 0.8088 | Val Loss: 0.4058 Acc: 0.8140\n",
      "Epoch 048 | Train Loss: 0.4339 Acc: 0.8022 | Val Loss: 0.4101 Acc: 0.8200\n",
      "Epoch 049 | Train Loss: 0.4237 Acc: 0.8072 | Val Loss: 0.4190 Acc: 0.8025\n",
      "Epoch 050 | Train Loss: 0.4293 Acc: 0.8046 | Val Loss: 0.3965 Acc: 0.8243\n",
      "Epoch 051 | Train Loss: 0.4128 Acc: 0.8137 | Val Loss: 0.3913 Acc: 0.8231\n",
      "Epoch 052 | Train Loss: 0.4154 Acc: 0.8088 | Val Loss: 0.4795 Acc: 0.7675\n",
      "Epoch 053 | Train Loss: 0.4127 Acc: 0.8067 | Val Loss: 0.3850 Acc: 0.8207\n",
      "Epoch 054 | Train Loss: 0.4106 Acc: 0.8167 | Val Loss: 0.4075 Acc: 0.8176\n",
      "Epoch 055 | Train Loss: 0.3961 Acc: 0.8209 | Val Loss: 0.3701 Acc: 0.8321\n",
      "Epoch 056 | Train Loss: 0.4004 Acc: 0.8206 | Val Loss: 0.3791 Acc: 0.8249\n",
      "Epoch 057 | Train Loss: 0.3980 Acc: 0.8230 | Val Loss: 0.3882 Acc: 0.8243\n",
      "Epoch 058 | Train Loss: 0.4067 Acc: 0.8158 | Val Loss: 0.3531 Acc: 0.8424\n",
      "Epoch 059 | Train Loss: 0.3842 Acc: 0.8304 | Val Loss: 0.3629 Acc: 0.8327\n",
      "Epoch 060 | Train Loss: 0.3882 Acc: 0.8273 | Val Loss: 0.4031 Acc: 0.8122\n",
      "Trial 8/20 | Val Loss: 0.3531 | Best So Far: 0.1429 | Trial Time: 41.25s | Total Time: 4.95 min\n",
      "\n",
      "Trial 9/20 params: {'cnn_kernels_1': 39, 'cnn_kernel_size_1': 3, 'cnn_kernels_2': 35, 'cnn_dropout': 0.25916808305926686, 'cnn_dense': 42, 'lstm_hidden_size': 96, 'lstm_layers': 3, 'lstm_dense': 166, 'learning_rate': 0.007827612584085769, 'batch_size': 42}\n",
      "Epoch 001 | Train Loss: 0.6890 Acc: 0.5499 | Val Loss: 0.6881 Acc: 0.5586\n",
      "Epoch 002 | Train Loss: 0.6869 Acc: 0.5582 | Val Loss: 0.6865 Acc: 0.5586\n",
      "Epoch 003 | Train Loss: 0.6868 Acc: 0.5582 | Val Loss: 0.6863 Acc: 0.5586\n",
      "Epoch 004 | Train Loss: 0.6866 Acc: 0.5582 | Val Loss: 0.6865 Acc: 0.5586\n",
      "Epoch 005 | Train Loss: 0.6868 Acc: 0.5582 | Val Loss: 0.6863 Acc: 0.5586\n",
      "Epoch 006 | Train Loss: 0.6866 Acc: 0.5582 | Val Loss: 0.6882 Acc: 0.5586\n",
      "Epoch 007 | Train Loss: 0.6870 Acc: 0.5582 | Val Loss: 0.6866 Acc: 0.5586\n",
      "Epoch 008 | Train Loss: 0.6866 Acc: 0.5582 | Val Loss: 0.6867 Acc: 0.5586\n",
      "Epoch 009 | Train Loss: 0.6868 Acc: 0.5582 | Val Loss: 0.6863 Acc: 0.5586\n",
      "Epoch 010 | Train Loss: 0.6868 Acc: 0.5582 | Val Loss: 0.6863 Acc: 0.5586\n",
      "Epoch 011 | Train Loss: 0.6864 Acc: 0.5582 | Val Loss: 0.6872 Acc: 0.5586\n",
      "Epoch 012 | Train Loss: 0.6870 Acc: 0.5582 | Val Loss: 0.6863 Acc: 0.5586\n",
      "Epoch 013 | Train Loss: 0.6866 Acc: 0.5582 | Val Loss: 0.6868 Acc: 0.5586\n",
      "Epoch 014 | Train Loss: 0.6868 Acc: 0.5582 | Val Loss: 0.6863 Acc: 0.5586\n",
      "Epoch 015 | Train Loss: 0.6869 Acc: 0.5582 | Val Loss: 0.6864 Acc: 0.5586\n",
      "Epoch 016 | Train Loss: 0.6866 Acc: 0.5582 | Val Loss: 0.6865 Acc: 0.5586\n",
      "Epoch 017 | Train Loss: 0.6866 Acc: 0.5582 | Val Loss: 0.6863 Acc: 0.5586\n",
      "Epoch 018 | Train Loss: 0.6865 Acc: 0.5582 | Val Loss: 0.6868 Acc: 0.5586\n",
      "Epoch 019 | Train Loss: 0.6864 Acc: 0.5582 | Val Loss: 0.6882 Acc: 0.5586\n",
      "Early stopping triggered.\n",
      "Trial 9/20 | Val Loss: 0.6863 | Best So Far: 0.1429 | Trial Time: 11.54s | Total Time: 5.14 min\n",
      "\n",
      "Trial 10/20 params: {'cnn_kernels_1': 64, 'cnn_kernel_size_1': 5, 'cnn_kernels_2': 25, 'cnn_dropout': 0.6901675502651347, 'cnn_dense': 51, 'lstm_hidden_size': 61, 'lstm_layers': 2, 'lstm_dense': 155, 'learning_rate': 0.007828274799259006, 'batch_size': 19}\n",
      "Epoch 001 | Train Loss: 0.6908 Acc: 0.5466 | Val Loss: 0.6867 Acc: 0.5586\n",
      "Epoch 002 | Train Loss: 0.6874 Acc: 0.5573 | Val Loss: 0.6864 Acc: 0.5586\n",
      "Epoch 003 | Train Loss: 0.6870 Acc: 0.5582 | Val Loss: 0.6867 Acc: 0.5586\n",
      "Epoch 004 | Train Loss: 0.6867 Acc: 0.5582 | Val Loss: 0.6872 Acc: 0.5586\n",
      "Epoch 005 | Train Loss: 0.6871 Acc: 0.5582 | Val Loss: 0.6863 Acc: 0.5586\n",
      "Epoch 006 | Train Loss: 0.6869 Acc: 0.5582 | Val Loss: 0.6863 Acc: 0.5586\n",
      "Epoch 007 | Train Loss: 0.6870 Acc: 0.5582 | Val Loss: 0.6863 Acc: 0.5586\n",
      "Epoch 008 | Train Loss: 0.6869 Acc: 0.5582 | Val Loss: 0.6863 Acc: 0.5586\n",
      "Epoch 009 | Train Loss: 0.6869 Acc: 0.5582 | Val Loss: 0.6864 Acc: 0.5586\n",
      "Epoch 010 | Train Loss: 0.6867 Acc: 0.5582 | Val Loss: 0.6863 Acc: 0.5586\n",
      "Epoch 011 | Train Loss: 0.6870 Acc: 0.5582 | Val Loss: 0.6870 Acc: 0.5586\n",
      "Epoch 012 | Train Loss: 0.6869 Acc: 0.5582 | Val Loss: 0.6863 Acc: 0.5586\n",
      "Epoch 013 | Train Loss: 0.6870 Acc: 0.5582 | Val Loss: 0.6864 Acc: 0.5586\n",
      "Epoch 014 | Train Loss: 0.6868 Acc: 0.5582 | Val Loss: 0.6869 Acc: 0.5586\n",
      "Epoch 015 | Train Loss: 0.6867 Acc: 0.5582 | Val Loss: 0.6863 Acc: 0.5586\n",
      "Epoch 016 | Train Loss: 0.6873 Acc: 0.5582 | Val Loss: 0.6863 Acc: 0.5586\n",
      "Epoch 017 | Train Loss: 0.6870 Acc: 0.5582 | Val Loss: 0.6863 Acc: 0.5586\n",
      "Epoch 018 | Train Loss: 0.6869 Acc: 0.5582 | Val Loss: 0.6864 Acc: 0.5586\n",
      "Epoch 019 | Train Loss: 0.6869 Acc: 0.5582 | Val Loss: 0.6865 Acc: 0.5586\n",
      "Epoch 020 | Train Loss: 0.6870 Acc: 0.5582 | Val Loss: 0.6863 Acc: 0.5586\n",
      "Early stopping triggered.\n",
      "Trial 10/20 | Val Loss: 0.6863 | Best So Far: 0.1429 | Trial Time: 26.07s | Total Time: 5.57 min\n",
      "\n",
      "Trial 11/20 params: {'cnn_kernels_1': 38, 'cnn_kernel_size_1': 3, 'cnn_kernels_2': 39, 'cnn_dropout': 0.40414683345224184, 'cnn_dense': 71, 'lstm_hidden_size': 32, 'lstm_layers': 3, 'lstm_dense': 119, 'learning_rate': 0.003314812756835822, 'batch_size': 19}\n",
      "Epoch 001 | Train Loss: 0.6850 Acc: 0.5727 | Val Loss: 0.6782 Acc: 0.5839\n",
      "Epoch 002 | Train Loss: 0.6851 Acc: 0.5644 | Val Loss: 0.6868 Acc: 0.5586\n",
      "Epoch 003 | Train Loss: 0.6868 Acc: 0.5587 | Val Loss: 0.6787 Acc: 0.5839\n",
      "Epoch 004 | Train Loss: 0.6861 Acc: 0.5600 | Val Loss: 0.6864 Acc: 0.5586\n",
      "Epoch 005 | Train Loss: 0.6868 Acc: 0.5582 | Val Loss: 0.6863 Acc: 0.5586\n",
      "Epoch 006 | Train Loss: 0.6867 Acc: 0.5582 | Val Loss: 0.6863 Acc: 0.5586\n",
      "Epoch 007 | Train Loss: 0.6866 Acc: 0.5582 | Val Loss: 0.6866 Acc: 0.5586\n",
      "Epoch 008 | Train Loss: 0.6867 Acc: 0.5582 | Val Loss: 0.6863 Acc: 0.5586\n",
      "Epoch 009 | Train Loss: 0.6869 Acc: 0.5582 | Val Loss: 0.6863 Acc: 0.5586\n",
      "Epoch 010 | Train Loss: 0.6866 Acc: 0.5582 | Val Loss: 0.6863 Acc: 0.5586\n",
      "Epoch 011 | Train Loss: 0.6867 Acc: 0.5582 | Val Loss: 0.6864 Acc: 0.5586\n",
      "Early stopping triggered.\n",
      "Trial 11/20 | Val Loss: 0.6782 | Best So Far: 0.1429 | Trial Time: 14.98s | Total Time: 5.82 min\n",
      "\n",
      "Trial 12/20 params: {'cnn_kernels_1': 51, 'cnn_kernel_size_1': 3, 'cnn_kernels_2': 55, 'cnn_dropout': 0.11728639571275355, 'cnn_dense': 128, 'lstm_hidden_size': 66, 'lstm_layers': 1, 'lstm_dense': 240, 'learning_rate': 0.004660189330770357, 'batch_size': 59}\n",
      "Epoch 001 | Train Loss: 0.6788 Acc: 0.5852 | Val Loss: 0.6736 Acc: 0.5888\n",
      "Epoch 002 | Train Loss: 0.6428 Acc: 0.6329 | Val Loss: 0.6249 Acc: 0.6546\n",
      "Epoch 003 | Train Loss: 0.5852 Acc: 0.7032 | Val Loss: 0.5577 Acc: 0.7144\n",
      "Epoch 004 | Train Loss: 0.5476 Acc: 0.7306 | Val Loss: 0.5294 Acc: 0.7325\n",
      "Epoch 005 | Train Loss: 0.5235 Acc: 0.7409 | Val Loss: 0.5269 Acc: 0.7506\n",
      "Epoch 006 | Train Loss: 0.4897 Acc: 0.7673 | Val Loss: 0.4918 Acc: 0.7579\n",
      "Epoch 007 | Train Loss: 0.4642 Acc: 0.7833 | Val Loss: 0.4796 Acc: 0.7621\n",
      "Epoch 008 | Train Loss: 0.4463 Acc: 0.7927 | Val Loss: 0.4823 Acc: 0.7862\n",
      "Epoch 009 | Train Loss: 0.4213 Acc: 0.8128 | Val Loss: 0.4354 Acc: 0.7959\n",
      "Epoch 010 | Train Loss: 0.4028 Acc: 0.8156 | Val Loss: 0.4053 Acc: 0.8146\n",
      "Epoch 011 | Train Loss: 0.3808 Acc: 0.8319 | Val Loss: 0.4214 Acc: 0.8037\n",
      "Epoch 012 | Train Loss: 0.3578 Acc: 0.8508 | Val Loss: 0.3582 Acc: 0.8418\n",
      "Epoch 013 | Train Loss: 0.3287 Acc: 0.8558 | Val Loss: 0.3473 Acc: 0.8382\n",
      "Epoch 014 | Train Loss: 0.3250 Acc: 0.8617 | Val Loss: 0.3524 Acc: 0.8406\n",
      "Epoch 015 | Train Loss: 0.3162 Acc: 0.8647 | Val Loss: 0.3349 Acc: 0.8496\n",
      "Epoch 016 | Train Loss: 0.2917 Acc: 0.8730 | Val Loss: 0.3370 Acc: 0.8702\n",
      "Epoch 017 | Train Loss: 0.2694 Acc: 0.8845 | Val Loss: 0.3278 Acc: 0.8593\n",
      "Epoch 018 | Train Loss: 0.2630 Acc: 0.8926 | Val Loss: 0.3212 Acc: 0.8714\n",
      "Epoch 019 | Train Loss: 0.2554 Acc: 0.8988 | Val Loss: 0.3198 Acc: 0.8617\n",
      "Epoch 020 | Train Loss: 0.2452 Acc: 0.8979 | Val Loss: 0.2712 Acc: 0.8889\n",
      "Epoch 021 | Train Loss: 0.2240 Acc: 0.9108 | Val Loss: 0.3056 Acc: 0.8756\n",
      "Epoch 022 | Train Loss: 0.2290 Acc: 0.9056 | Val Loss: 0.2697 Acc: 0.8895\n",
      "Epoch 023 | Train Loss: 0.2135 Acc: 0.9121 | Val Loss: 0.3104 Acc: 0.8786\n",
      "Epoch 024 | Train Loss: 0.2010 Acc: 0.9216 | Val Loss: 0.3012 Acc: 0.8678\n",
      "Epoch 025 | Train Loss: 0.1969 Acc: 0.9227 | Val Loss: 0.2782 Acc: 0.8859\n",
      "Epoch 026 | Train Loss: 0.1955 Acc: 0.9228 | Val Loss: 0.2492 Acc: 0.8931\n",
      "Epoch 027 | Train Loss: 0.1787 Acc: 0.9295 | Val Loss: 0.2846 Acc: 0.8810\n",
      "Epoch 028 | Train Loss: 0.1724 Acc: 0.9310 | Val Loss: 0.2713 Acc: 0.8895\n",
      "Epoch 029 | Train Loss: 0.1796 Acc: 0.9284 | Val Loss: 0.2930 Acc: 0.8895\n",
      "Epoch 030 | Train Loss: 0.1659 Acc: 0.9340 | Val Loss: 0.2933 Acc: 0.8889\n",
      "Epoch 031 | Train Loss: 0.1715 Acc: 0.9292 | Val Loss: 0.2917 Acc: 0.8774\n",
      "Epoch 032 | Train Loss: 0.1589 Acc: 0.9408 | Val Loss: 0.2712 Acc: 0.8925\n",
      "Epoch 033 | Train Loss: 0.1556 Acc: 0.9398 | Val Loss: 0.2616 Acc: 0.9106\n",
      "Epoch 034 | Train Loss: 0.1423 Acc: 0.9461 | Val Loss: 0.2904 Acc: 0.8931\n",
      "Epoch 035 | Train Loss: 0.1532 Acc: 0.9405 | Val Loss: 0.2484 Acc: 0.9040\n",
      "Epoch 036 | Train Loss: 0.1388 Acc: 0.9470 | Val Loss: 0.2545 Acc: 0.9076\n",
      "Epoch 037 | Train Loss: 0.1314 Acc: 0.9536 | Val Loss: 0.2892 Acc: 0.8943\n",
      "Epoch 038 | Train Loss: 0.1331 Acc: 0.9518 | Val Loss: 0.3102 Acc: 0.8998\n",
      "Epoch 039 | Train Loss: 0.1293 Acc: 0.9476 | Val Loss: 0.2528 Acc: 0.9070\n",
      "Epoch 040 | Train Loss: 0.1435 Acc: 0.9423 | Val Loss: 0.2522 Acc: 0.9070\n",
      "Epoch 041 | Train Loss: 0.1315 Acc: 0.9487 | Val Loss: 0.2641 Acc: 0.9052\n",
      "Epoch 042 | Train Loss: 0.1254 Acc: 0.9515 | Val Loss: 0.2385 Acc: 0.9094\n",
      "Epoch 043 | Train Loss: 0.1273 Acc: 0.9521 | Val Loss: 0.2586 Acc: 0.9070\n",
      "Epoch 044 | Train Loss: 0.1257 Acc: 0.9515 | Val Loss: 0.2423 Acc: 0.9070\n",
      "Epoch 045 | Train Loss: 0.1178 Acc: 0.9559 | Val Loss: 0.2881 Acc: 0.8931\n",
      "Epoch 046 | Train Loss: 0.1203 Acc: 0.9547 | Val Loss: 0.2511 Acc: 0.9016\n",
      "Epoch 047 | Train Loss: 0.1449 Acc: 0.9441 | Val Loss: 0.2308 Acc: 0.9112\n",
      "Epoch 048 | Train Loss: 0.1186 Acc: 0.9574 | Val Loss: 0.2379 Acc: 0.9040\n",
      "Epoch 049 | Train Loss: 0.1001 Acc: 0.9613 | Val Loss: 0.2673 Acc: 0.9064\n",
      "Epoch 050 | Train Loss: 0.1016 Acc: 0.9621 | Val Loss: 0.2984 Acc: 0.9064\n",
      "Epoch 051 | Train Loss: 0.1210 Acc: 0.9544 | Val Loss: 0.2522 Acc: 0.9167\n",
      "Epoch 052 | Train Loss: 0.1087 Acc: 0.9603 | Val Loss: 0.2272 Acc: 0.9118\n",
      "Epoch 053 | Train Loss: 0.0960 Acc: 0.9635 | Val Loss: 0.2417 Acc: 0.9112\n",
      "Epoch 054 | Train Loss: 0.0970 Acc: 0.9639 | Val Loss: 0.2495 Acc: 0.9076\n",
      "Epoch 055 | Train Loss: 0.0992 Acc: 0.9612 | Val Loss: 0.2561 Acc: 0.9185\n",
      "Epoch 056 | Train Loss: 0.0989 Acc: 0.9629 | Val Loss: 0.2726 Acc: 0.9082\n",
      "Epoch 057 | Train Loss: 0.0815 Acc: 0.9693 | Val Loss: 0.2602 Acc: 0.9161\n",
      "Epoch 058 | Train Loss: 0.0998 Acc: 0.9657 | Val Loss: 0.2126 Acc: 0.9118\n",
      "Epoch 059 | Train Loss: 0.1025 Acc: 0.9601 | Val Loss: 0.2677 Acc: 0.9106\n",
      "Epoch 060 | Train Loss: 0.0946 Acc: 0.9663 | Val Loss: 0.2556 Acc: 0.9064\n",
      "Trial 12/20 | Val Loss: 0.2126 | Best So Far: 0.1429 | Trial Time: 23.66s | Total Time: 6.22 min\n",
      "\n",
      "Trial 13/20 params: {'cnn_kernels_1': 37, 'cnn_kernel_size_1': 5, 'cnn_kernels_2': 36, 'cnn_dropout': 0.5747695630530355, 'cnn_dense': 50, 'lstm_hidden_size': 51, 'lstm_layers': 3, 'lstm_dense': 130, 'learning_rate': 0.00943203896773469, 'batch_size': 41}\n",
      "Epoch 001 | Train Loss: 0.6878 Acc: 0.5552 | Val Loss: 0.6889 Acc: 0.5399\n",
      "Epoch 002 | Train Loss: 0.6870 Acc: 0.5573 | Val Loss: 0.6794 Acc: 0.5930\n",
      "Epoch 003 | Train Loss: 0.6870 Acc: 0.5581 | Val Loss: 0.6868 Acc: 0.5586\n",
      "Epoch 004 | Train Loss: 0.6867 Acc: 0.5582 | Val Loss: 0.6863 Acc: 0.5586\n",
      "Epoch 005 | Train Loss: 0.6869 Acc: 0.5573 | Val Loss: 0.6863 Acc: 0.5586\n",
      "Epoch 006 | Train Loss: 0.6869 Acc: 0.5582 | Val Loss: 0.6863 Acc: 0.5586\n",
      "Epoch 007 | Train Loss: 0.6868 Acc: 0.5582 | Val Loss: 0.6863 Acc: 0.5586\n",
      "Epoch 008 | Train Loss: 0.6867 Acc: 0.5582 | Val Loss: 0.6863 Acc: 0.5586\n",
      "Epoch 009 | Train Loss: 0.6872 Acc: 0.5582 | Val Loss: 0.6863 Acc: 0.5586\n",
      "Epoch 010 | Train Loss: 0.6874 Acc: 0.5582 | Val Loss: 0.6867 Acc: 0.5586\n",
      "Epoch 011 | Train Loss: 0.6865 Acc: 0.5582 | Val Loss: 0.6863 Acc: 0.5586\n",
      "Epoch 012 | Train Loss: 0.6868 Acc: 0.5582 | Val Loss: 0.6863 Acc: 0.5586\n",
      "Early stopping triggered.\n",
      "Trial 13/20 | Val Loss: 0.6794 | Best So Far: 0.1429 | Trial Time: 7.90s | Total Time: 6.35 min\n",
      "\n",
      "Trial 14/20 params: {'cnn_kernels_1': 38, 'cnn_kernel_size_1': 5, 'cnn_kernels_2': 29, 'cnn_dropout': 0.5405150624541316, 'cnn_dense': 248, 'lstm_hidden_size': 32, 'lstm_layers': 1, 'lstm_dense': 177, 'learning_rate': 0.006014998504372056, 'batch_size': 35}\n",
      "Epoch 001 | Train Loss: 0.6871 Acc: 0.5543 | Val Loss: 0.6753 Acc: 0.5749\n",
      "Epoch 002 | Train Loss: 0.6599 Acc: 0.6024 | Val Loss: 0.6574 Acc: 0.5966\n",
      "Epoch 003 | Train Loss: 0.6340 Acc: 0.6514 | Val Loss: 0.6419 Acc: 0.6316\n",
      "Epoch 004 | Train Loss: 0.6119 Acc: 0.6784 | Val Loss: 0.6001 Acc: 0.6842\n",
      "Epoch 005 | Train Loss: 0.5957 Acc: 0.6850 | Val Loss: 0.5788 Acc: 0.6842\n",
      "Epoch 006 | Train Loss: 0.5889 Acc: 0.6959 | Val Loss: 0.5710 Acc: 0.7023\n",
      "Epoch 007 | Train Loss: 0.5708 Acc: 0.7116 | Val Loss: 0.5522 Acc: 0.7114\n",
      "Epoch 008 | Train Loss: 0.5656 Acc: 0.7107 | Val Loss: 0.5835 Acc: 0.6751\n",
      "Epoch 009 | Train Loss: 0.5624 Acc: 0.7148 | Val Loss: 0.5479 Acc: 0.7186\n",
      "Epoch 010 | Train Loss: 0.5512 Acc: 0.7225 | Val Loss: 0.5543 Acc: 0.7089\n",
      "Epoch 011 | Train Loss: 0.5455 Acc: 0.7232 | Val Loss: 0.5209 Acc: 0.7313\n",
      "Epoch 012 | Train Loss: 0.5505 Acc: 0.7152 | Val Loss: 0.5463 Acc: 0.7083\n",
      "Epoch 013 | Train Loss: 0.5364 Acc: 0.7331 | Val Loss: 0.5248 Acc: 0.7307\n",
      "Epoch 014 | Train Loss: 0.5331 Acc: 0.7252 | Val Loss: 0.5606 Acc: 0.7023\n",
      "Epoch 015 | Train Loss: 0.5162 Acc: 0.7383 | Val Loss: 0.5376 Acc: 0.7319\n",
      "Epoch 016 | Train Loss: 0.5210 Acc: 0.7365 | Val Loss: 0.5227 Acc: 0.7228\n",
      "Epoch 017 | Train Loss: 0.5156 Acc: 0.7408 | Val Loss: 0.5082 Acc: 0.7367\n",
      "Epoch 018 | Train Loss: 0.5118 Acc: 0.7447 | Val Loss: 0.5042 Acc: 0.7572\n",
      "Epoch 019 | Train Loss: 0.5089 Acc: 0.7489 | Val Loss: 0.5105 Acc: 0.7434\n",
      "Epoch 020 | Train Loss: 0.5117 Acc: 0.7465 | Val Loss: 0.4943 Acc: 0.7415\n",
      "Epoch 021 | Train Loss: 0.5041 Acc: 0.7483 | Val Loss: 0.4886 Acc: 0.7434\n",
      "Epoch 022 | Train Loss: 0.4991 Acc: 0.7534 | Val Loss: 0.4958 Acc: 0.7512\n",
      "Epoch 023 | Train Loss: 0.4921 Acc: 0.7551 | Val Loss: 0.4660 Acc: 0.7651\n",
      "Epoch 024 | Train Loss: 0.4877 Acc: 0.7590 | Val Loss: 0.4706 Acc: 0.7572\n",
      "Epoch 025 | Train Loss: 0.4960 Acc: 0.7512 | Val Loss: 0.4956 Acc: 0.7415\n",
      "Epoch 026 | Train Loss: 0.4859 Acc: 0.7554 | Val Loss: 0.4545 Acc: 0.7766\n",
      "Epoch 027 | Train Loss: 0.4803 Acc: 0.7640 | Val Loss: 0.4652 Acc: 0.7705\n",
      "Epoch 028 | Train Loss: 0.4798 Acc: 0.7649 | Val Loss: 0.4588 Acc: 0.7681\n",
      "Epoch 029 | Train Loss: 0.4731 Acc: 0.7697 | Val Loss: 0.4667 Acc: 0.7585\n",
      "Epoch 030 | Train Loss: 0.4694 Acc: 0.7648 | Val Loss: 0.4397 Acc: 0.7868\n",
      "Epoch 031 | Train Loss: 0.4745 Acc: 0.7735 | Val Loss: 0.4128 Acc: 0.8007\n",
      "Epoch 032 | Train Loss: 0.4662 Acc: 0.7771 | Val Loss: 0.4276 Acc: 0.7989\n",
      "Epoch 033 | Train Loss: 0.4563 Acc: 0.7774 | Val Loss: 0.4824 Acc: 0.7494\n",
      "Epoch 034 | Train Loss: 0.4621 Acc: 0.7728 | Val Loss: 0.4461 Acc: 0.7723\n",
      "Epoch 035 | Train Loss: 0.4550 Acc: 0.7844 | Val Loss: 0.4100 Acc: 0.8134\n",
      "Epoch 036 | Train Loss: 0.4491 Acc: 0.7906 | Val Loss: 0.4285 Acc: 0.7995\n",
      "Epoch 037 | Train Loss: 0.4403 Acc: 0.7885 | Val Loss: 0.4356 Acc: 0.7880\n",
      "Epoch 038 | Train Loss: 0.4377 Acc: 0.7959 | Val Loss: 0.4261 Acc: 0.7935\n",
      "Epoch 039 | Train Loss: 0.4458 Acc: 0.7886 | Val Loss: 0.4540 Acc: 0.7862\n",
      "Epoch 040 | Train Loss: 0.4261 Acc: 0.8025 | Val Loss: 0.4169 Acc: 0.7995\n",
      "Epoch 041 | Train Loss: 0.4254 Acc: 0.8024 | Val Loss: 0.3856 Acc: 0.8279\n",
      "Epoch 042 | Train Loss: 0.4347 Acc: 0.7987 | Val Loss: 0.3852 Acc: 0.8219\n",
      "Epoch 043 | Train Loss: 0.4286 Acc: 0.8027 | Val Loss: 0.3887 Acc: 0.8261\n",
      "Epoch 044 | Train Loss: 0.4190 Acc: 0.8043 | Val Loss: 0.3971 Acc: 0.8152\n",
      "Epoch 045 | Train Loss: 0.4194 Acc: 0.8128 | Val Loss: 0.3646 Acc: 0.8345\n",
      "Epoch 046 | Train Loss: 0.4135 Acc: 0.8117 | Val Loss: 0.3781 Acc: 0.8134\n",
      "Epoch 047 | Train Loss: 0.4023 Acc: 0.8122 | Val Loss: 0.3757 Acc: 0.8418\n",
      "Epoch 048 | Train Loss: 0.4083 Acc: 0.8126 | Val Loss: 0.3623 Acc: 0.8382\n",
      "Epoch 049 | Train Loss: 0.4005 Acc: 0.8178 | Val Loss: 0.3568 Acc: 0.8382\n",
      "Epoch 050 | Train Loss: 0.3962 Acc: 0.8178 | Val Loss: 0.3609 Acc: 0.8291\n",
      "Epoch 051 | Train Loss: 0.4027 Acc: 0.8143 | Val Loss: 0.3955 Acc: 0.8128\n",
      "Epoch 052 | Train Loss: 0.4026 Acc: 0.8232 | Val Loss: 0.3866 Acc: 0.8225\n",
      "Epoch 053 | Train Loss: 0.3996 Acc: 0.8197 | Val Loss: 0.3678 Acc: 0.8309\n",
      "Epoch 054 | Train Loss: 0.3987 Acc: 0.8202 | Val Loss: 0.3792 Acc: 0.8110\n",
      "Epoch 055 | Train Loss: 0.3874 Acc: 0.8262 | Val Loss: 0.3917 Acc: 0.8213\n",
      "Epoch 056 | Train Loss: 0.3859 Acc: 0.8323 | Val Loss: 0.3483 Acc: 0.8472\n",
      "Epoch 057 | Train Loss: 0.3819 Acc: 0.8327 | Val Loss: 0.3520 Acc: 0.8527\n",
      "Epoch 058 | Train Loss: 0.3878 Acc: 0.8238 | Val Loss: 0.3536 Acc: 0.8382\n",
      "Epoch 059 | Train Loss: 0.3733 Acc: 0.8341 | Val Loss: 0.3359 Acc: 0.8490\n",
      "Epoch 060 | Train Loss: 0.3785 Acc: 0.8341 | Val Loss: 0.3346 Acc: 0.8424\n",
      "Trial 14/20 | Val Loss: 0.3346 | Best So Far: 0.1429 | Trial Time: 39.98s | Total Time: 7.02 min\n",
      "\n",
      "Trial 15/20 params: {'cnn_kernels_1': 38, 'cnn_kernel_size_1': 5, 'cnn_kernels_2': 42, 'cnn_dropout': 0.6768167278828457, 'cnn_dense': 199, 'lstm_hidden_size': 56, 'lstm_layers': 3, 'lstm_dense': 234, 'learning_rate': 0.0004969318813195839, 'batch_size': 27}\n",
      "Epoch 001 | Train Loss: 0.6839 Acc: 0.5633 | Val Loss: 0.6768 Acc: 0.5870\n",
      "Epoch 002 | Train Loss: 0.6755 Acc: 0.5896 | Val Loss: 0.6705 Acc: 0.5894\n",
      "Epoch 003 | Train Loss: 0.6653 Acc: 0.6020 | Val Loss: 0.6607 Acc: 0.6027\n",
      "Epoch 004 | Train Loss: 0.6554 Acc: 0.6181 | Val Loss: 0.6498 Acc: 0.6244\n",
      "Epoch 005 | Train Loss: 0.6421 Acc: 0.6512 | Val Loss: 0.6117 Acc: 0.6896\n",
      "Epoch 006 | Train Loss: 0.6182 Acc: 0.6721 | Val Loss: 0.5929 Acc: 0.7059\n",
      "Epoch 007 | Train Loss: 0.5976 Acc: 0.7027 | Val Loss: 0.5871 Acc: 0.7126\n",
      "Epoch 008 | Train Loss: 0.5795 Acc: 0.7161 | Val Loss: 0.5725 Acc: 0.7162\n",
      "Epoch 009 | Train Loss: 0.5739 Acc: 0.7178 | Val Loss: 0.5834 Acc: 0.7095\n",
      "Epoch 010 | Train Loss: 0.5631 Acc: 0.7261 | Val Loss: 0.5561 Acc: 0.7295\n",
      "Epoch 011 | Train Loss: 0.5630 Acc: 0.7279 | Val Loss: 0.5572 Acc: 0.7234\n",
      "Epoch 012 | Train Loss: 0.5518 Acc: 0.7391 | Val Loss: 0.5573 Acc: 0.7325\n",
      "Epoch 013 | Train Loss: 0.5472 Acc: 0.7350 | Val Loss: 0.5360 Acc: 0.7385\n",
      "Epoch 014 | Train Loss: 0.5410 Acc: 0.7418 | Val Loss: 0.5364 Acc: 0.7373\n",
      "Epoch 015 | Train Loss: 0.5349 Acc: 0.7460 | Val Loss: 0.5394 Acc: 0.7391\n",
      "Epoch 016 | Train Loss: 0.5355 Acc: 0.7450 | Val Loss: 0.5252 Acc: 0.7409\n",
      "Epoch 017 | Train Loss: 0.5269 Acc: 0.7515 | Val Loss: 0.5274 Acc: 0.7403\n",
      "Epoch 018 | Train Loss: 0.5217 Acc: 0.7540 | Val Loss: 0.5155 Acc: 0.7500\n",
      "Epoch 019 | Train Loss: 0.5077 Acc: 0.7640 | Val Loss: 0.5106 Acc: 0.7458\n",
      "Epoch 020 | Train Loss: 0.5116 Acc: 0.7620 | Val Loss: 0.5029 Acc: 0.7530\n",
      "Epoch 021 | Train Loss: 0.5039 Acc: 0.7640 | Val Loss: 0.4967 Acc: 0.7542\n",
      "Epoch 022 | Train Loss: 0.4955 Acc: 0.7664 | Val Loss: 0.5067 Acc: 0.7482\n",
      "Epoch 023 | Train Loss: 0.4869 Acc: 0.7752 | Val Loss: 0.4914 Acc: 0.7609\n",
      "Epoch 024 | Train Loss: 0.4947 Acc: 0.7676 | Val Loss: 0.4971 Acc: 0.7579\n",
      "Epoch 025 | Train Loss: 0.4826 Acc: 0.7744 | Val Loss: 0.4756 Acc: 0.7687\n",
      "Epoch 026 | Train Loss: 0.4784 Acc: 0.7744 | Val Loss: 0.4683 Acc: 0.7705\n",
      "Epoch 027 | Train Loss: 0.4710 Acc: 0.7799 | Val Loss: 0.4526 Acc: 0.7874\n",
      "Epoch 028 | Train Loss: 0.4608 Acc: 0.7833 | Val Loss: 0.4648 Acc: 0.7760\n",
      "Epoch 029 | Train Loss: 0.4564 Acc: 0.7873 | Val Loss: 0.4383 Acc: 0.7941\n",
      "Epoch 030 | Train Loss: 0.4463 Acc: 0.7922 | Val Loss: 0.4266 Acc: 0.7965\n",
      "Epoch 031 | Train Loss: 0.4549 Acc: 0.7879 | Val Loss: 0.4344 Acc: 0.7959\n",
      "Epoch 032 | Train Loss: 0.4297 Acc: 0.8025 | Val Loss: 0.4362 Acc: 0.7905\n",
      "Epoch 033 | Train Loss: 0.4320 Acc: 0.8004 | Val Loss: 0.4228 Acc: 0.7989\n",
      "Epoch 034 | Train Loss: 0.4297 Acc: 0.8061 | Val Loss: 0.4097 Acc: 0.8062\n",
      "Epoch 035 | Train Loss: 0.4235 Acc: 0.8091 | Val Loss: 0.3949 Acc: 0.8152\n",
      "Epoch 036 | Train Loss: 0.4099 Acc: 0.8087 | Val Loss: 0.3888 Acc: 0.8158\n",
      "Epoch 037 | Train Loss: 0.4065 Acc: 0.8149 | Val Loss: 0.3883 Acc: 0.8152\n",
      "Epoch 038 | Train Loss: 0.4029 Acc: 0.8170 | Val Loss: 0.3834 Acc: 0.8255\n",
      "Epoch 039 | Train Loss: 0.3982 Acc: 0.8155 | Val Loss: 0.3976 Acc: 0.8031\n",
      "Epoch 040 | Train Loss: 0.3940 Acc: 0.8221 | Val Loss: 0.4198 Acc: 0.7995\n",
      "Epoch 041 | Train Loss: 0.3905 Acc: 0.8247 | Val Loss: 0.3675 Acc: 0.8297\n",
      "Epoch 042 | Train Loss: 0.3837 Acc: 0.8298 | Val Loss: 0.3820 Acc: 0.8146\n",
      "Epoch 043 | Train Loss: 0.3799 Acc: 0.8313 | Val Loss: 0.3639 Acc: 0.8400\n",
      "Epoch 044 | Train Loss: 0.3724 Acc: 0.8310 | Val Loss: 0.3533 Acc: 0.8454\n",
      "Epoch 045 | Train Loss: 0.3664 Acc: 0.8350 | Val Loss: 0.3553 Acc: 0.8357\n",
      "Epoch 046 | Train Loss: 0.3612 Acc: 0.8421 | Val Loss: 0.3421 Acc: 0.8412\n",
      "Epoch 047 | Train Loss: 0.3582 Acc: 0.8390 | Val Loss: 0.3380 Acc: 0.8406\n",
      "Epoch 048 | Train Loss: 0.3462 Acc: 0.8505 | Val Loss: 0.3335 Acc: 0.8527\n",
      "Epoch 049 | Train Loss: 0.3574 Acc: 0.8372 | Val Loss: 0.3236 Acc: 0.8533\n",
      "Epoch 050 | Train Loss: 0.3463 Acc: 0.8516 | Val Loss: 0.3152 Acc: 0.8647\n",
      "Epoch 051 | Train Loss: 0.3472 Acc: 0.8461 | Val Loss: 0.3056 Acc: 0.8659\n",
      "Epoch 052 | Train Loss: 0.3304 Acc: 0.8582 | Val Loss: 0.3336 Acc: 0.8533\n",
      "Epoch 053 | Train Loss: 0.3332 Acc: 0.8551 | Val Loss: 0.3087 Acc: 0.8671\n",
      "Epoch 054 | Train Loss: 0.3308 Acc: 0.8567 | Val Loss: 0.3243 Acc: 0.8533\n",
      "Epoch 055 | Train Loss: 0.3230 Acc: 0.8617 | Val Loss: 0.2927 Acc: 0.8732\n",
      "Epoch 056 | Train Loss: 0.3278 Acc: 0.8563 | Val Loss: 0.2957 Acc: 0.8810\n",
      "Epoch 057 | Train Loss: 0.3123 Acc: 0.8671 | Val Loss: 0.2908 Acc: 0.8829\n",
      "Epoch 058 | Train Loss: 0.3117 Acc: 0.8673 | Val Loss: 0.3522 Acc: 0.8406\n",
      "Epoch 059 | Train Loss: 0.3146 Acc: 0.8650 | Val Loss: 0.2788 Acc: 0.8804\n",
      "Epoch 060 | Train Loss: 0.3067 Acc: 0.8665 | Val Loss: 0.2994 Acc: 0.8678\n",
      "Trial 15/20 | Val Loss: 0.2788 | Best So Far: 0.1429 | Trial Time: 57.61s | Total Time: 7.98 min\n",
      "\n",
      "Trial 16/20 params: {'cnn_kernels_1': 61, 'cnn_kernel_size_1': 3, 'cnn_kernels_2': 53, 'cnn_dropout': 0.08290109235261917, 'cnn_dense': 198, 'lstm_hidden_size': 99, 'lstm_layers': 3, 'lstm_dense': 205, 'learning_rate': 0.004430385055107655, 'batch_size': 27}\n",
      "Epoch 001 | Train Loss: 0.6864 Acc: 0.5609 | Val Loss: 0.6843 Acc: 0.5586\n",
      "Epoch 002 | Train Loss: 0.6786 Acc: 0.5784 | Val Loss: 0.6570 Acc: 0.6178\n",
      "Epoch 003 | Train Loss: 0.6872 Acc: 0.5603 | Val Loss: 0.6839 Acc: 0.5586\n",
      "Epoch 004 | Train Loss: 0.6692 Acc: 0.5922 | Val Loss: 0.6760 Acc: 0.5785\n",
      "Epoch 005 | Train Loss: 0.6538 Acc: 0.6166 | Val Loss: 0.6154 Acc: 0.6842\n",
      "Epoch 006 | Train Loss: 0.6087 Acc: 0.6838 | Val Loss: 0.5948 Acc: 0.6860\n",
      "Epoch 007 | Train Loss: 0.5849 Acc: 0.7000 | Val Loss: 0.5654 Acc: 0.7083\n",
      "Epoch 008 | Train Loss: 0.5618 Acc: 0.7222 | Val Loss: 0.5654 Acc: 0.7126\n",
      "Epoch 009 | Train Loss: 0.5606 Acc: 0.7235 | Val Loss: 0.5550 Acc: 0.7271\n",
      "Epoch 010 | Train Loss: 0.5418 Acc: 0.7380 | Val Loss: 0.5646 Acc: 0.7041\n",
      "Epoch 011 | Train Loss: 0.5527 Acc: 0.7297 | Val Loss: 0.5590 Acc: 0.7101\n",
      "Epoch 012 | Train Loss: 0.5281 Acc: 0.7453 | Val Loss: 0.5496 Acc: 0.7126\n",
      "Epoch 013 | Train Loss: 0.5234 Acc: 0.7483 | Val Loss: 0.5155 Acc: 0.7349\n",
      "Epoch 014 | Train Loss: 0.5135 Acc: 0.7498 | Val Loss: 0.4970 Acc: 0.7536\n",
      "Epoch 015 | Train Loss: 0.4947 Acc: 0.7643 | Val Loss: 0.5149 Acc: 0.7428\n",
      "Epoch 016 | Train Loss: 0.4803 Acc: 0.7737 | Val Loss: 0.4877 Acc: 0.7603\n",
      "Epoch 017 | Train Loss: 0.4575 Acc: 0.7876 | Val Loss: 0.4636 Acc: 0.7784\n",
      "Epoch 018 | Train Loss: 0.4213 Acc: 0.8084 | Val Loss: 0.4490 Acc: 0.7802\n",
      "Epoch 019 | Train Loss: 0.4052 Acc: 0.8187 | Val Loss: 0.4059 Acc: 0.8128\n",
      "Epoch 020 | Train Loss: 0.3914 Acc: 0.8241 | Val Loss: 0.3885 Acc: 0.8200\n",
      "Epoch 021 | Train Loss: 0.3706 Acc: 0.8431 | Val Loss: 0.3588 Acc: 0.8364\n",
      "Epoch 022 | Train Loss: 0.3458 Acc: 0.8541 | Val Loss: 0.4526 Acc: 0.8194\n",
      "Epoch 023 | Train Loss: 0.3316 Acc: 0.8602 | Val Loss: 0.3274 Acc: 0.8508\n",
      "Epoch 024 | Train Loss: 0.3109 Acc: 0.8706 | Val Loss: 0.3534 Acc: 0.8484\n",
      "Epoch 025 | Train Loss: 0.2971 Acc: 0.8834 | Val Loss: 0.3139 Acc: 0.8623\n",
      "Epoch 026 | Train Loss: 0.2876 Acc: 0.8795 | Val Loss: 0.3259 Acc: 0.8490\n",
      "Epoch 027 | Train Loss: 0.2675 Acc: 0.8933 | Val Loss: 0.2862 Acc: 0.8708\n",
      "Epoch 028 | Train Loss: 0.2476 Acc: 0.9016 | Val Loss: 0.3392 Acc: 0.8563\n",
      "Epoch 029 | Train Loss: 0.2422 Acc: 0.9031 | Val Loss: 0.3569 Acc: 0.8496\n",
      "Epoch 030 | Train Loss: 0.2411 Acc: 0.9038 | Val Loss: 0.3497 Acc: 0.8671\n",
      "Epoch 031 | Train Loss: 0.2160 Acc: 0.9179 | Val Loss: 0.2900 Acc: 0.8804\n",
      "Epoch 032 | Train Loss: 0.2141 Acc: 0.9167 | Val Loss: 0.2943 Acc: 0.9016\n",
      "Epoch 033 | Train Loss: 0.2143 Acc: 0.9168 | Val Loss: 0.2857 Acc: 0.8756\n",
      "Epoch 034 | Train Loss: 0.2095 Acc: 0.9177 | Val Loss: 0.2796 Acc: 0.8901\n",
      "Epoch 035 | Train Loss: 0.2029 Acc: 0.9200 | Val Loss: 0.2884 Acc: 0.8714\n",
      "Epoch 036 | Train Loss: 0.1857 Acc: 0.9228 | Val Loss: 0.2741 Acc: 0.8907\n",
      "Epoch 037 | Train Loss: 0.1857 Acc: 0.9299 | Val Loss: 0.2641 Acc: 0.8877\n",
      "Epoch 038 | Train Loss: 0.1800 Acc: 0.9308 | Val Loss: 0.2602 Acc: 0.8919\n",
      "Epoch 039 | Train Loss: 0.1803 Acc: 0.9315 | Val Loss: 0.2648 Acc: 0.8883\n",
      "Epoch 040 | Train Loss: 0.1632 Acc: 0.9408 | Val Loss: 0.2414 Acc: 0.8998\n",
      "Epoch 041 | Train Loss: 0.1593 Acc: 0.9385 | Val Loss: 0.2447 Acc: 0.8943\n",
      "Epoch 042 | Train Loss: 0.1573 Acc: 0.9434 | Val Loss: 0.2237 Acc: 0.9155\n",
      "Epoch 043 | Train Loss: 0.1537 Acc: 0.9405 | Val Loss: 0.2397 Acc: 0.9016\n",
      "Epoch 044 | Train Loss: 0.1340 Acc: 0.9497 | Val Loss: 0.2792 Acc: 0.8998\n",
      "Epoch 045 | Train Loss: 0.1784 Acc: 0.9315 | Val Loss: 0.2671 Acc: 0.9010\n",
      "Epoch 046 | Train Loss: 0.1490 Acc: 0.9443 | Val Loss: 0.2640 Acc: 0.9034\n",
      "Epoch 047 | Train Loss: 0.1339 Acc: 0.9502 | Val Loss: 0.2407 Acc: 0.9094\n",
      "Epoch 048 | Train Loss: 0.1344 Acc: 0.9467 | Val Loss: 0.2364 Acc: 0.9167\n",
      "Epoch 049 | Train Loss: 0.1349 Acc: 0.9499 | Val Loss: 0.2516 Acc: 0.9058\n",
      "Epoch 050 | Train Loss: 0.1276 Acc: 0.9499 | Val Loss: 0.2277 Acc: 0.9100\n",
      "Epoch 051 | Train Loss: 0.1302 Acc: 0.9500 | Val Loss: 0.2507 Acc: 0.9070\n",
      "Epoch 052 | Train Loss: 0.1182 Acc: 0.9565 | Val Loss: 0.2269 Acc: 0.9167\n",
      "Early stopping triggered.\n",
      "Trial 16/20 | Val Loss: 0.2237 | Best So Far: 0.1429 | Trial Time: 50.95s | Total Time: 8.83 min\n",
      "\n",
      "Trial 17/20 params: {'cnn_kernels_1': 17, 'cnn_kernel_size_1': 3, 'cnn_kernels_2': 54, 'cnn_dropout': 0.4498977479176672, 'cnn_dense': 98, 'lstm_hidden_size': 94, 'lstm_layers': 3, 'lstm_dense': 65, 'learning_rate': 0.0015094982260205427, 'batch_size': 20}\n",
      "Epoch 001 | Train Loss: 0.6789 Acc: 0.5795 | Val Loss: 0.6732 Acc: 0.5930\n",
      "Epoch 002 | Train Loss: 0.6688 Acc: 0.5985 | Val Loss: 0.6778 Acc: 0.5864\n",
      "Epoch 003 | Train Loss: 0.6599 Acc: 0.6117 | Val Loss: 0.6544 Acc: 0.6123\n",
      "Epoch 004 | Train Loss: 0.6514 Acc: 0.6307 | Val Loss: 0.6299 Acc: 0.6443\n",
      "Epoch 005 | Train Loss: 0.6121 Acc: 0.6808 | Val Loss: 0.5928 Acc: 0.6836\n",
      "Epoch 006 | Train Loss: 0.5933 Acc: 0.7044 | Val Loss: 0.5720 Acc: 0.7029\n",
      "Epoch 007 | Train Loss: 0.5763 Acc: 0.7149 | Val Loss: 0.5634 Acc: 0.7083\n",
      "Epoch 008 | Train Loss: 0.5618 Acc: 0.7257 | Val Loss: 0.5546 Acc: 0.7077\n",
      "Epoch 009 | Train Loss: 0.5575 Acc: 0.7300 | Val Loss: 0.5314 Acc: 0.7458\n",
      "Epoch 010 | Train Loss: 0.5471 Acc: 0.7338 | Val Loss: 0.5308 Acc: 0.7452\n",
      "Epoch 011 | Train Loss: 0.5324 Acc: 0.7444 | Val Loss: 0.5013 Acc: 0.7579\n",
      "Epoch 012 | Train Loss: 0.5233 Acc: 0.7491 | Val Loss: 0.5028 Acc: 0.7554\n",
      "Epoch 013 | Train Loss: 0.5166 Acc: 0.7512 | Val Loss: 0.4892 Acc: 0.7717\n",
      "Epoch 014 | Train Loss: 0.5054 Acc: 0.7562 | Val Loss: 0.5439 Acc: 0.7192\n",
      "Epoch 015 | Train Loss: 0.4920 Acc: 0.7652 | Val Loss: 0.4849 Acc: 0.7572\n",
      "Epoch 016 | Train Loss: 0.4846 Acc: 0.7705 | Val Loss: 0.4900 Acc: 0.7603\n",
      "Epoch 017 | Train Loss: 0.4754 Acc: 0.7743 | Val Loss: 0.4833 Acc: 0.7675\n",
      "Epoch 018 | Train Loss: 0.4651 Acc: 0.7776 | Val Loss: 0.4647 Acc: 0.7778\n",
      "Epoch 019 | Train Loss: 0.4582 Acc: 0.7824 | Val Loss: 0.4644 Acc: 0.7929\n",
      "Epoch 020 | Train Loss: 0.4495 Acc: 0.7900 | Val Loss: 0.4678 Acc: 0.7796\n",
      "Epoch 021 | Train Loss: 0.4387 Acc: 0.7948 | Val Loss: 0.4417 Acc: 0.7838\n",
      "Epoch 022 | Train Loss: 0.4199 Acc: 0.8082 | Val Loss: 0.4264 Acc: 0.8037\n",
      "Epoch 023 | Train Loss: 0.4304 Acc: 0.8058 | Val Loss: 0.4005 Acc: 0.8231\n",
      "Epoch 024 | Train Loss: 0.4089 Acc: 0.8120 | Val Loss: 0.3997 Acc: 0.8146\n",
      "Epoch 025 | Train Loss: 0.4036 Acc: 0.8149 | Val Loss: 0.4081 Acc: 0.8213\n",
      "Epoch 026 | Train Loss: 0.4046 Acc: 0.8188 | Val Loss: 0.3917 Acc: 0.8279\n",
      "Epoch 027 | Train Loss: 0.3870 Acc: 0.8297 | Val Loss: 0.3888 Acc: 0.8225\n",
      "Epoch 028 | Train Loss: 0.3885 Acc: 0.8271 | Val Loss: 0.3804 Acc: 0.8255\n",
      "Epoch 029 | Train Loss: 0.3689 Acc: 0.8353 | Val Loss: 0.3600 Acc: 0.8406\n",
      "Epoch 030 | Train Loss: 0.3583 Acc: 0.8464 | Val Loss: 0.3667 Acc: 0.8303\n",
      "Epoch 031 | Train Loss: 0.3554 Acc: 0.8467 | Val Loss: 0.3499 Acc: 0.8412\n",
      "Epoch 032 | Train Loss: 0.3497 Acc: 0.8478 | Val Loss: 0.3304 Acc: 0.8593\n",
      "Epoch 033 | Train Loss: 0.3453 Acc: 0.8517 | Val Loss: 0.3081 Acc: 0.8708\n",
      "Epoch 034 | Train Loss: 0.3339 Acc: 0.8529 | Val Loss: 0.3147 Acc: 0.8696\n",
      "Epoch 035 | Train Loss: 0.3231 Acc: 0.8582 | Val Loss: 0.3032 Acc: 0.8744\n",
      "Epoch 036 | Train Loss: 0.3241 Acc: 0.8576 | Val Loss: 0.3276 Acc: 0.8478\n",
      "Epoch 037 | Train Loss: 0.3099 Acc: 0.8664 | Val Loss: 0.3102 Acc: 0.8641\n",
      "Epoch 038 | Train Loss: 0.3116 Acc: 0.8700 | Val Loss: 0.3078 Acc: 0.8678\n",
      "Epoch 039 | Train Loss: 0.3050 Acc: 0.8709 | Val Loss: 0.3105 Acc: 0.8690\n",
      "Epoch 040 | Train Loss: 0.2970 Acc: 0.8775 | Val Loss: 0.2737 Acc: 0.8877\n",
      "Epoch 041 | Train Loss: 0.2835 Acc: 0.8836 | Val Loss: 0.2825 Acc: 0.8786\n",
      "Epoch 042 | Train Loss: 0.2899 Acc: 0.8801 | Val Loss: 0.2722 Acc: 0.8907\n",
      "Epoch 043 | Train Loss: 0.2788 Acc: 0.8859 | Val Loss: 0.2572 Acc: 0.8913\n",
      "Epoch 044 | Train Loss: 0.2805 Acc: 0.8859 | Val Loss: 0.2798 Acc: 0.8816\n",
      "Epoch 045 | Train Loss: 0.2668 Acc: 0.8907 | Val Loss: 0.2644 Acc: 0.8931\n",
      "Epoch 046 | Train Loss: 0.2552 Acc: 0.8919 | Val Loss: 0.2944 Acc: 0.8774\n",
      "Epoch 047 | Train Loss: 0.2532 Acc: 0.8973 | Val Loss: 0.2880 Acc: 0.8883\n",
      "Epoch 048 | Train Loss: 0.2505 Acc: 0.8955 | Val Loss: 0.2950 Acc: 0.8720\n",
      "Epoch 049 | Train Loss: 0.2540 Acc: 0.8955 | Val Loss: 0.2666 Acc: 0.8841\n",
      "Epoch 050 | Train Loss: 0.2428 Acc: 0.9029 | Val Loss: 0.2436 Acc: 0.8961\n",
      "Epoch 051 | Train Loss: 0.2248 Acc: 0.9088 | Val Loss: 0.2427 Acc: 0.9010\n",
      "Epoch 052 | Train Loss: 0.2394 Acc: 0.9035 | Val Loss: 0.2463 Acc: 0.8967\n",
      "Epoch 053 | Train Loss: 0.2345 Acc: 0.9083 | Val Loss: 0.2399 Acc: 0.8998\n",
      "Epoch 054 | Train Loss: 0.2346 Acc: 0.9068 | Val Loss: 0.2401 Acc: 0.9034\n",
      "Epoch 055 | Train Loss: 0.2200 Acc: 0.9150 | Val Loss: 0.2600 Acc: 0.8877\n",
      "Epoch 056 | Train Loss: 0.2145 Acc: 0.9165 | Val Loss: 0.3245 Acc: 0.8659\n",
      "Epoch 057 | Train Loss: 0.2313 Acc: 0.9070 | Val Loss: 0.2578 Acc: 0.8865\n",
      "Epoch 058 | Train Loss: 0.2182 Acc: 0.9144 | Val Loss: 0.2028 Acc: 0.9136\n",
      "Epoch 059 | Train Loss: 0.2034 Acc: 0.9228 | Val Loss: 0.2358 Acc: 0.9064\n",
      "Epoch 060 | Train Loss: 0.1949 Acc: 0.9244 | Val Loss: 0.2220 Acc: 0.9149\n",
      "Trial 17/20 | Val Loss: 0.2028 | Best So Far: 0.1429 | Trial Time: 74.91s | Total Time: 10.07 min\n",
      "\n",
      "Trial 18/20 params: {'cnn_kernels_1': 61, 'cnn_kernel_size_1': 3, 'cnn_kernels_2': 53, 'cnn_dropout': 0.07113030748736811, 'cnn_dense': 238, 'lstm_hidden_size': 67, 'lstm_layers': 1, 'lstm_dense': 207, 'learning_rate': 0.0011788025525842156, 'batch_size': 38}\n",
      "Epoch 001 | Train Loss: 0.6799 Acc: 0.5834 | Val Loss: 0.6752 Acc: 0.5888\n",
      "Epoch 002 | Train Loss: 0.6556 Acc: 0.6141 | Val Loss: 0.6346 Acc: 0.6588\n",
      "Epoch 003 | Train Loss: 0.5940 Acc: 0.6882 | Val Loss: 0.5773 Acc: 0.7035\n",
      "Epoch 004 | Train Loss: 0.5466 Acc: 0.7306 | Val Loss: 0.5387 Acc: 0.7301\n",
      "Epoch 005 | Train Loss: 0.5101 Acc: 0.7537 | Val Loss: 0.5159 Acc: 0.7446\n",
      "Epoch 006 | Train Loss: 0.4697 Acc: 0.7768 | Val Loss: 0.4879 Acc: 0.7657\n",
      "Epoch 007 | Train Loss: 0.4411 Acc: 0.7936 | Val Loss: 0.4874 Acc: 0.7754\n",
      "Epoch 008 | Train Loss: 0.4043 Acc: 0.8158 | Val Loss: 0.4495 Acc: 0.7772\n",
      "Epoch 009 | Train Loss: 0.3683 Acc: 0.8395 | Val Loss: 0.4118 Acc: 0.8086\n",
      "Epoch 010 | Train Loss: 0.3320 Acc: 0.8552 | Val Loss: 0.3840 Acc: 0.8339\n",
      "Epoch 011 | Train Loss: 0.3084 Acc: 0.8698 | Val Loss: 0.3325 Acc: 0.8593\n",
      "Epoch 012 | Train Loss: 0.2769 Acc: 0.8825 | Val Loss: 0.3193 Acc: 0.8605\n",
      "Epoch 013 | Train Loss: 0.2401 Acc: 0.9014 | Val Loss: 0.3087 Acc: 0.8659\n",
      "Epoch 014 | Train Loss: 0.2221 Acc: 0.9096 | Val Loss: 0.2790 Acc: 0.8762\n",
      "Epoch 015 | Train Loss: 0.1937 Acc: 0.9228 | Val Loss: 0.2699 Acc: 0.8895\n",
      "Epoch 016 | Train Loss: 0.1722 Acc: 0.9345 | Val Loss: 0.2464 Acc: 0.9022\n",
      "Epoch 017 | Train Loss: 0.1615 Acc: 0.9366 | Val Loss: 0.2771 Acc: 0.8961\n",
      "Epoch 018 | Train Loss: 0.1435 Acc: 0.9470 | Val Loss: 0.2729 Acc: 0.8919\n",
      "Epoch 019 | Train Loss: 0.1426 Acc: 0.9455 | Val Loss: 0.3439 Acc: 0.8671\n",
      "Epoch 020 | Train Loss: 0.1261 Acc: 0.9478 | Val Loss: 0.2569 Acc: 0.9004\n",
      "Epoch 021 | Train Loss: 0.1118 Acc: 0.9573 | Val Loss: 0.2313 Acc: 0.9149\n",
      "Epoch 022 | Train Loss: 0.1131 Acc: 0.9571 | Val Loss: 0.2452 Acc: 0.9064\n",
      "Epoch 023 | Train Loss: 0.0855 Acc: 0.9686 | Val Loss: 0.2227 Acc: 0.9203\n",
      "Epoch 024 | Train Loss: 0.0967 Acc: 0.9633 | Val Loss: 0.2648 Acc: 0.9058\n",
      "Epoch 025 | Train Loss: 0.0792 Acc: 0.9709 | Val Loss: 0.3254 Acc: 0.9004\n",
      "Epoch 026 | Train Loss: 0.0815 Acc: 0.9715 | Val Loss: 0.2697 Acc: 0.9130\n",
      "Epoch 027 | Train Loss: 0.0755 Acc: 0.9721 | Val Loss: 0.2446 Acc: 0.9149\n",
      "Epoch 028 | Train Loss: 0.0663 Acc: 0.9758 | Val Loss: 0.2335 Acc: 0.9233\n",
      "Epoch 029 | Train Loss: 0.0623 Acc: 0.9787 | Val Loss: 0.2470 Acc: 0.9179\n",
      "Epoch 030 | Train Loss: 0.0557 Acc: 0.9781 | Val Loss: 0.2037 Acc: 0.9342\n",
      "Epoch 031 | Train Loss: 0.0544 Acc: 0.9792 | Val Loss: 0.2711 Acc: 0.9136\n",
      "Epoch 032 | Train Loss: 0.0601 Acc: 0.9784 | Val Loss: 0.2079 Acc: 0.9233\n",
      "Epoch 033 | Train Loss: 0.0542 Acc: 0.9822 | Val Loss: 0.2421 Acc: 0.9257\n",
      "Epoch 034 | Train Loss: 0.0494 Acc: 0.9825 | Val Loss: 0.2296 Acc: 0.9263\n",
      "Epoch 035 | Train Loss: 0.0436 Acc: 0.9837 | Val Loss: 0.2263 Acc: 0.9306\n",
      "Epoch 036 | Train Loss: 0.0351 Acc: 0.9878 | Val Loss: 0.2327 Acc: 0.9300\n",
      "Epoch 037 | Train Loss: 0.0378 Acc: 0.9846 | Val Loss: 0.2286 Acc: 0.9342\n",
      "Epoch 038 | Train Loss: 0.0402 Acc: 0.9844 | Val Loss: 0.2896 Acc: 0.9209\n",
      "Epoch 039 | Train Loss: 0.0441 Acc: 0.9848 | Val Loss: 0.2478 Acc: 0.9342\n",
      "Epoch 040 | Train Loss: 0.0385 Acc: 0.9887 | Val Loss: 0.2222 Acc: 0.9306\n",
      "Early stopping triggered.\n",
      "Trial 18/20 | Val Loss: 0.2037 | Best So Far: 0.1429 | Trial Time: 24.33s | Total Time: 10.48 min\n",
      "\n",
      "Trial 19/20 params: {'cnn_kernels_1': 54, 'cnn_kernel_size_1': 3, 'cnn_kernels_2': 84, 'cnn_dropout': 0.5044935761443795, 'cnn_dense': 174, 'lstm_hidden_size': 80, 'lstm_layers': 2, 'lstm_dense': 71, 'learning_rate': 0.007892070320206987, 'batch_size': 64}\n",
      "Epoch 001 | Train Loss: 0.6879 Acc: 0.5494 | Val Loss: 0.6911 Acc: 0.5773\n",
      "Epoch 002 | Train Loss: 0.6878 Acc: 0.5579 | Val Loss: 0.6862 Acc: 0.5586\n",
      "Epoch 003 | Train Loss: 0.6876 Acc: 0.5594 | Val Loss: 0.6863 Acc: 0.5586\n",
      "Epoch 004 | Train Loss: 0.6868 Acc: 0.5585 | Val Loss: 0.6863 Acc: 0.5586\n",
      "Epoch 005 | Train Loss: 0.6865 Acc: 0.5599 | Val Loss: 0.6875 Acc: 0.5586\n",
      "Epoch 006 | Train Loss: 0.6869 Acc: 0.5562 | Val Loss: 0.6863 Acc: 0.5586\n",
      "Epoch 007 | Train Loss: 0.6867 Acc: 0.5582 | Val Loss: 0.6863 Acc: 0.5586\n",
      "Epoch 008 | Train Loss: 0.6866 Acc: 0.5582 | Val Loss: 0.6866 Acc: 0.5586\n",
      "Epoch 009 | Train Loss: 0.6866 Acc: 0.5582 | Val Loss: 0.6863 Acc: 0.5586\n",
      "Epoch 010 | Train Loss: 0.6865 Acc: 0.5582 | Val Loss: 0.6864 Acc: 0.5586\n",
      "Epoch 011 | Train Loss: 0.6867 Acc: 0.5582 | Val Loss: 0.6865 Acc: 0.5586\n",
      "Epoch 012 | Train Loss: 0.6867 Acc: 0.5582 | Val Loss: 0.6864 Acc: 0.5586\n",
      "Early stopping triggered.\n",
      "Trial 19/20 | Val Loss: 0.6862 | Best So Far: 0.1429 | Trial Time: 5.00s | Total Time: 10.56 min\n",
      "\n",
      "Trial 20/20 params: {'cnn_kernels_1': 43, 'cnn_kernel_size_1': 3, 'cnn_kernels_2': 81, 'cnn_dropout': 0.13155960066222763, 'cnn_dense': 240, 'lstm_hidden_size': 57, 'lstm_layers': 3, 'lstm_dense': 130, 'learning_rate': 0.003172539899680242, 'batch_size': 45}\n",
      "Epoch 001 | Train Loss: 0.6854 Acc: 0.5635 | Val Loss: 0.6906 Acc: 0.5586\n",
      "Epoch 002 | Train Loss: 0.6878 Acc: 0.5514 | Val Loss: 0.6866 Acc: 0.5586\n",
      "Epoch 003 | Train Loss: 0.6870 Acc: 0.5591 | Val Loss: 0.6821 Acc: 0.5773\n",
      "Epoch 004 | Train Loss: 0.6810 Acc: 0.5798 | Val Loss: 0.6762 Acc: 0.5912\n",
      "Epoch 005 | Train Loss: 0.6817 Acc: 0.5732 | Val Loss: 0.6872 Acc: 0.5586\n",
      "Epoch 006 | Train Loss: 0.6839 Acc: 0.5653 | Val Loss: 0.6771 Acc: 0.5882\n",
      "Epoch 007 | Train Loss: 0.6764 Acc: 0.5907 | Val Loss: 0.6755 Acc: 0.5870\n",
      "Epoch 008 | Train Loss: 0.6753 Acc: 0.5919 | Val Loss: 0.6766 Acc: 0.5827\n",
      "Epoch 009 | Train Loss: 0.6735 Acc: 0.5987 | Val Loss: 0.6744 Acc: 0.5924\n",
      "Epoch 010 | Train Loss: 0.6740 Acc: 0.5967 | Val Loss: 0.6725 Acc: 0.5930\n",
      "Epoch 011 | Train Loss: 0.6690 Acc: 0.5999 | Val Loss: 0.6730 Acc: 0.5912\n",
      "Epoch 012 | Train Loss: 0.6698 Acc: 0.6003 | Val Loss: 0.6814 Acc: 0.5773\n",
      "Epoch 013 | Train Loss: 0.6720 Acc: 0.5970 | Val Loss: 0.6718 Acc: 0.5936\n",
      "Epoch 014 | Train Loss: 0.6679 Acc: 0.6050 | Val Loss: 0.6758 Acc: 0.5833\n",
      "Epoch 015 | Train Loss: 0.6678 Acc: 0.6023 | Val Loss: 0.6741 Acc: 0.5888\n",
      "Epoch 016 | Train Loss: 0.6677 Acc: 0.6020 | Val Loss: 0.6829 Acc: 0.5936\n",
      "Epoch 017 | Train Loss: 0.6693 Acc: 0.6035 | Val Loss: 0.6772 Acc: 0.5797\n",
      "Epoch 018 | Train Loss: 0.6670 Acc: 0.6050 | Val Loss: 0.6721 Acc: 0.5918\n",
      "Epoch 019 | Train Loss: 0.6666 Acc: 0.6035 | Val Loss: 0.6702 Acc: 0.6039\n",
      "Epoch 020 | Train Loss: 0.6640 Acc: 0.6106 | Val Loss: 0.6677 Acc: 0.6039\n",
      "Epoch 021 | Train Loss: 0.6621 Acc: 0.6127 | Val Loss: 0.6660 Acc: 0.5984\n",
      "Epoch 022 | Train Loss: 0.6720 Acc: 0.5944 | Val Loss: 0.6701 Acc: 0.6008\n",
      "Epoch 023 | Train Loss: 0.6642 Acc: 0.6089 | Val Loss: 0.6792 Acc: 0.5749\n",
      "Epoch 024 | Train Loss: 0.6866 Acc: 0.5593 | Val Loss: 0.6833 Acc: 0.5646\n",
      "Epoch 025 | Train Loss: 0.6735 Acc: 0.5908 | Val Loss: 0.6668 Acc: 0.6033\n",
      "Epoch 026 | Train Loss: 0.6581 Acc: 0.6219 | Val Loss: 0.6341 Acc: 0.6570\n",
      "Epoch 027 | Train Loss: 0.6159 Acc: 0.6763 | Val Loss: 0.6259 Acc: 0.6655\n",
      "Epoch 028 | Train Loss: 0.5887 Acc: 0.6968 | Val Loss: 0.5809 Acc: 0.6963\n",
      "Epoch 029 | Train Loss: 0.5646 Acc: 0.7195 | Val Loss: 0.5583 Acc: 0.7277\n",
      "Epoch 030 | Train Loss: 0.5370 Acc: 0.7414 | Val Loss: 0.5520 Acc: 0.7132\n",
      "Epoch 031 | Train Loss: 0.5256 Acc: 0.7494 | Val Loss: 0.5318 Acc: 0.7397\n",
      "Epoch 032 | Train Loss: 0.5088 Acc: 0.7504 | Val Loss: 0.5101 Acc: 0.7572\n",
      "Epoch 033 | Train Loss: 0.4974 Acc: 0.7589 | Val Loss: 0.4908 Acc: 0.7742\n",
      "Epoch 034 | Train Loss: 0.4748 Acc: 0.7785 | Val Loss: 0.5477 Acc: 0.7476\n",
      "Epoch 035 | Train Loss: 0.4673 Acc: 0.7726 | Val Loss: 0.4977 Acc: 0.7572\n",
      "Epoch 036 | Train Loss: 0.4458 Acc: 0.7931 | Val Loss: 0.4603 Acc: 0.7820\n",
      "Epoch 037 | Train Loss: 0.4372 Acc: 0.7998 | Val Loss: 0.4208 Acc: 0.7995\n",
      "Epoch 038 | Train Loss: 0.4167 Acc: 0.8140 | Val Loss: 0.4118 Acc: 0.8098\n",
      "Epoch 039 | Train Loss: 0.3961 Acc: 0.8206 | Val Loss: 0.3932 Acc: 0.8104\n",
      "Epoch 040 | Train Loss: 0.3800 Acc: 0.8312 | Val Loss: 0.4567 Acc: 0.7856\n",
      "Epoch 041 | Train Loss: 0.3733 Acc: 0.8332 | Val Loss: 0.4051 Acc: 0.8062\n",
      "Epoch 042 | Train Loss: 0.3572 Acc: 0.8458 | Val Loss: 0.3965 Acc: 0.8345\n",
      "Epoch 043 | Train Loss: 0.3324 Acc: 0.8566 | Val Loss: 0.3613 Acc: 0.8303\n",
      "Epoch 044 | Train Loss: 0.3082 Acc: 0.8674 | Val Loss: 0.3455 Acc: 0.8508\n",
      "Epoch 045 | Train Loss: 0.3056 Acc: 0.8689 | Val Loss: 0.3931 Acc: 0.8400\n",
      "Epoch 046 | Train Loss: 0.2954 Acc: 0.8788 | Val Loss: 0.3193 Acc: 0.8653\n",
      "Epoch 047 | Train Loss: 0.2753 Acc: 0.8889 | Val Loss: 0.3285 Acc: 0.8575\n",
      "Epoch 048 | Train Loss: 0.2669 Acc: 0.8920 | Val Loss: 0.2877 Acc: 0.8810\n",
      "Epoch 049 | Train Loss: 0.2443 Acc: 0.9019 | Val Loss: 0.3138 Acc: 0.8684\n",
      "Epoch 050 | Train Loss: 0.2468 Acc: 0.9008 | Val Loss: 0.3034 Acc: 0.8756\n",
      "Epoch 051 | Train Loss: 0.2359 Acc: 0.9038 | Val Loss: 0.2858 Acc: 0.8829\n",
      "Epoch 052 | Train Loss: 0.2147 Acc: 0.9148 | Val Loss: 0.2790 Acc: 0.8780\n",
      "Epoch 053 | Train Loss: 0.2116 Acc: 0.9157 | Val Loss: 0.2795 Acc: 0.8835\n",
      "Epoch 054 | Train Loss: 0.1988 Acc: 0.9216 | Val Loss: 0.3140 Acc: 0.8841\n",
      "Epoch 055 | Train Loss: 0.2040 Acc: 0.9225 | Val Loss: 0.3270 Acc: 0.8744\n",
      "Epoch 056 | Train Loss: 0.1859 Acc: 0.9271 | Val Loss: 0.2709 Acc: 0.8829\n",
      "Epoch 057 | Train Loss: 0.1925 Acc: 0.9253 | Val Loss: 0.2418 Acc: 0.8949\n",
      "Epoch 058 | Train Loss: 0.1754 Acc: 0.9296 | Val Loss: 0.2732 Acc: 0.8816\n",
      "Epoch 059 | Train Loss: 0.1841 Acc: 0.9302 | Val Loss: 0.2597 Acc: 0.8967\n",
      "Epoch 060 | Train Loss: 0.1694 Acc: 0.9345 | Val Loss: 0.2486 Acc: 0.8992\n",
      "Trial 20/20 | Val Loss: 0.2418 | Best So Far: 0.1429 | Trial Time: 37.94s | Total Time: 11.20 min\n",
      "\n",
      "Random Search finished.\n",
      "Best Validation Loss: 0.14288051460041767\n",
      "Best Hyperparameters: {'cnn_kernels_1': 24, 'cnn_kernel_size_1': 3, 'cnn_kernels_2': 35, 'cnn_dropout': 0.44105563115380825, 'cnn_dense': 210, 'lstm_hidden_size': 118, 'lstm_layers': 1, 'lstm_dense': 231, 'learning_rate': 0.002329335326653157, 'batch_size': 23}\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Search space (same as PSO)\n",
    "# ---------------------------------------------------------\n",
    "bounds = {\n",
    "    'cnn_kernels_1'    : [16, 64],\n",
    "    'cnn_kernel_size_1': [3, 5],\n",
    "    'cnn_kernels_2'    : [16, 96],\n",
    "    'cnn_dropout'      : [0.0, 0.7],\n",
    "    'cnn_dense'        : [32, 256],\n",
    "    'lstm_hidden_size' : [32, 128],\n",
    "    'lstm_layers'      : [1, 3],\n",
    "    'lstm_dense'       : [32, 256],\n",
    "    'learning_rate'    : [1e-4, 1e-2],\n",
    "    'batch_size'       : [16, 64]\n",
    "}\n",
    "\n",
    "# Helper to sample a random configuration\n",
    "def sample_params():\n",
    "    p = {}\n",
    "    for k,(low,high) in bounds.items():\n",
    "        if k in ['cnn_kernels_1','cnn_kernel_size_1','cnn_kernels_2',\n",
    "                 'cnn_dense','lstm_hidden_size','lstm_layers','lstm_dense','batch_size']:\n",
    "            # integer space\n",
    "            val = np.random.randint(low, high+1)\n",
    "            if k == 'cnn_kernel_size_1':\n",
    "                # restrict to odd kernels used before (3 or 5)\n",
    "                val = 3 if np.random.rand() < 0.5 else 5\n",
    "            p[k] = int(val)\n",
    "        else:\n",
    "            # continuous uniform\n",
    "            p[k] = float(np.random.uniform(low, high))\n",
    "    return p\n",
    "\n",
    "def objective(params):\n",
    "    \"\"\"Train and validate model with given hyperparams; return best val loss.\"\"\"\n",
    "    # Build dataloaders\n",
    "    train_loader = DataLoader(train_ds, batch_size=params['batch_size'], shuffle=True)\n",
    "    val_loader   = DataLoader(test_ds,  batch_size=params['batch_size'], shuffle=False)\n",
    "\n",
    "    model = EEG_CNN_LSTM_HPO(\n",
    "        cnn_kernels_1=params['cnn_kernels_1'],\n",
    "        cnn_kernel_size_1=params['cnn_kernel_size_1'],\n",
    "        cnn_kernels_2=params['cnn_kernels_2'],\n",
    "        cnn_dropout=params['cnn_dropout'],\n",
    "        cnn_dense=params['cnn_dense'],\n",
    "        lstm_hidden_size=params['lstm_hidden_size'],\n",
    "        lstm_layers=params['lstm_layers'],\n",
    "        lstm_dense=params['lstm_dense'],\n",
    "        dropout=params['cnn_dropout'],\n",
    "        num_classes=2\n",
    "    ).to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(),\n",
    "                           lr=params['learning_rate'],\n",
    "                           weight_decay=1e-4)\n",
    "\n",
    "    history = model.fit(\n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader,\n",
    "        epochs=60,\n",
    "        criterion=criterion,\n",
    "        optimizer=optimizer,\n",
    "        device=device,\n",
    "        patience=10\n",
    "    )\n",
    "\n",
    "    return float(np.min(history['val_losses'])) if len(history['val_losses']) > 0 else np.inf\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Random Search Loop with Timers\n",
    "# ---------------------------------------------------------\n",
    "n_trials = 20  # adjust as needed\n",
    "\n",
    "best_score = np.inf\n",
    "best_params = None\n",
    "\n",
    "total_start = time.time()\n",
    "for t in range(n_trials):\n",
    "    trial_start = time.time()\n",
    "\n",
    "    params = sample_params()\n",
    "    print(f\"\\nTrial {t+1}/{n_trials} params: {params}\")\n",
    "\n",
    "    val_loss = objective(params)\n",
    "\n",
    "    if val_loss < best_score:\n",
    "        best_score = val_loss\n",
    "        best_params = params\n",
    "\n",
    "    iter_time = time.time() - trial_start\n",
    "    total_time = time.time() - total_start\n",
    "    print(f\"Trial {t+1}/{n_trials} | \"\n",
    "          f\"Val Loss: {val_loss:.4f} | \"\n",
    "          f\"Best So Far: {best_score:.4f} | \"\n",
    "          f\"Trial Time: {iter_time:.2f}s | \"\n",
    "          f\"Total Time: {total_time/60:.2f} min\")\n",
    "\n",
    "print(\"\\nRandom Search finished.\")\n",
    "print(\"Best Validation Loss:\", best_score)\n",
    "print(\"Best Hyperparameters:\", best_params)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

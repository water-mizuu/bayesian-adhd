{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "181da2fc-dae6-4638-8d23-8214b7560c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import Adam, RMSprop, SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af714077-585f-4de6-b357-1e50dc4993ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (6623, 77, 19, 1)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"./processed_adhdata.csv\")\n",
    "df['Class'] = LabelEncoder().fit_transform(df['Class'])  # ADHD->1, Control->0\n",
    "\n",
    "frequency_count = len(df['Frequency'].unique())\n",
    "window_count = len(df['Window'].unique())\n",
    "numeric_df = df.drop(['ID', 'Window'], axis=1)\n",
    "\n",
    "# shape: (windows, freqs, features)\n",
    "full_ndarray = numeric_df.values.reshape((window_count, frequency_count, numeric_df.shape[1]))\n",
    "\n",
    "X = full_ndarray[:, :, 2:]     # drop ID/Class columns\n",
    "y = full_ndarray[:, 0, 0]      # class label is repeated across freq rows\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y)\n",
    "\n",
    "# Add channel dimension (N, 1, freq, electrodes)\n",
    "X_train = X_train[..., np.newaxis]   # (N, freq, electrodes, 1)\n",
    "X_test  = X_test[...,  np.newaxis]\n",
    "\n",
    "# Standardize across the entire dataset\n",
    "scaler = StandardScaler()\n",
    "X_train_flat = X_train.reshape(-1, X_train.shape[-1])\n",
    "X_test_flat  = X_test.reshape(-1, X_test.shape[-1])\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train_flat)\n",
    "X_test_scaled  = scaler.transform(X_test_flat)\n",
    "\n",
    "X_train = X_train_scaled.reshape(X_train.shape)\n",
    "X_test  = X_test_scaled.reshape(X_test.shape)\n",
    "\n",
    "print(\"Train shape:\", X_train.shape)  # (N, freq, electrodes, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2595397-63c0-4fd7-9f9a-4242370f5bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EEGDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32).permute(0, 3, 1, 2)  \n",
    "        # -> (N, 1, freq, electrodes)\n",
    "        self.y = torch.tensor(y, dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "train_ds = EEGDataset(X_train, y_train)\n",
    "test_ds  = EEGDataset(X_test,  y_test)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=32, shuffle=True)\n",
    "test_loader  = DataLoader(test_ds, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3e658ff5-0dd2-4898-9f4a-d71d0cc79bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EEGHybrid(nn.Module):\n",
    "    def __init__(self, n_features: int, n_classes: int, seq_len: int):\n",
    "        super().__init__()\n",
    "        # ----- LSTM branch -----\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=n_features,   # features per time step\n",
    "            hidden_size=64,\n",
    "            batch_first=True\n",
    "        )\n",
    "        # ----- CNN branch -----\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.AvgPool2d(2),\n",
    "            nn.Conv2d(16, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool2d((2, 2)),\n",
    "            nn.Flatten(),\n",
    "        )\n",
    "\n",
    "        # Dynamically compute CNN flattened output size\n",
    "        with torch.no_grad():\n",
    "            dummy = torch.zeros(1, 1, seq_len, n_features)\n",
    "            cnn_out_size = self.cnn(dummy).shape[1]\n",
    "\n",
    "        # ----- Final classifier -----\n",
    "        self.fc = nn.Linear(64 + cnn_out_size, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x: [batch, 1, seq_len, n_features]\n",
    "        \"\"\"\n",
    "        # LSTM branch: seq_len as time, n_features as feature dim\n",
    "        lstm_in = x.squeeze(1)            # [batch, seq_len, n_features]\n",
    "        lstm_out, _ = self.lstm(lstm_in)\n",
    "        lstm_feat = lstm_out[:, -1, :]    # final time step\n",
    "\n",
    "        # CNN branch: keep 4-D input\n",
    "        cnn_feat = self.cnn(x)\n",
    "\n",
    "        # Concatenate both branches\n",
    "        features = torch.cat([lstm_feat, cnn_feat], dim=1)\n",
    "        return self.fc(features)\n",
    "\n",
    "    def fit(self, train_loader, val_loader, epochs, criterion, optimizer, device):\n",
    "        best_val_loss = float('inf')\n",
    "        patience = 30\n",
    "        no_improve = 0\n",
    "\n",
    "        train_losses, train_accs = [], []\n",
    "        val_losses, val_accs     = [], []\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            # --- Train ---\n",
    "            self.train()\n",
    "            train_loss, train_correct = 0.0, 0\n",
    "            for xb, yb in train_loader:\n",
    "                xb, yb = xb.to(device), yb.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                out = self(xb)\n",
    "                loss = criterion(out, yb)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                train_loss += loss.item() * xb.size(0)\n",
    "                train_correct += (out.argmax(1) == yb).sum().item()\n",
    "\n",
    "            train_loss /= len(train_loader.dataset)\n",
    "            train_acc  = train_correct / len(train_loader.dataset)\n",
    "            train_losses.append(train_loss)\n",
    "            train_accs.append(train_acc)\n",
    "\n",
    "            # --- Validate ---\n",
    "            self.eval()\n",
    "            val_loss, val_correct = 0.0, 0\n",
    "            with torch.no_grad():\n",
    "                for xb, yb in val_loader:\n",
    "                    xb, yb = xb.to(device), yb.to(device)\n",
    "                    out = self(xb)\n",
    "                    loss = criterion(out, yb)\n",
    "                    val_loss += loss.item() * xb.size(0)\n",
    "                    val_correct += (out.argmax(1) == yb).sum().item()\n",
    "\n",
    "            val_loss /= len(val_loader.dataset)\n",
    "            val_acc  = val_correct / len(val_loader.dataset)\n",
    "            val_losses.append(val_loss)\n",
    "            val_accs.append(val_acc)\n",
    "\n",
    "            print(f\"Epoch {epoch+1:03d} | \"\n",
    "                  f\"Train Loss: {train_loss:.4f} Acc: {train_acc:.4f} | \"\n",
    "                  f\"Val Loss: {val_loss:.4f} Acc: {val_acc:.4f}\")\n",
    "\n",
    "            # Early stopping\n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                best_state = self.state_dict()\n",
    "                no_improve = 0\n",
    "            else:\n",
    "                no_improve += 1\n",
    "                if no_improve >= patience:\n",
    "                    print(\"Early stopping triggered.\")\n",
    "                    break\n",
    "\n",
    "        self.load_state_dict(best_state)\n",
    "        return {\n",
    "            \"train_accs\": np.array(train_accs),\n",
    "            \"train_losses\": np.array(train_losses),\n",
    "            \"val_accs\":   np.array(val_accs),\n",
    "            \"val_losses\": np.array(val_losses)\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "01683741-6af7-471c-8440-c72a1b8fd652",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6623, 1, 77, 19])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Given input size: (32x1x19). Calculated output size: (32x0x9). Output size is too small",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[32]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m device = torch.device(\u001b[33m\"\u001b[39m\u001b[33mcuda\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch.cuda.is_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(train_ds.X.shape)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m model = \u001b[43mEEGHybrid\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_features\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_ds\u001b[49m\u001b[43m.\u001b[49m\u001b[43mX\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m                  \u001b[49m\u001b[43mn_classes\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m                  \u001b[49m\u001b[43mseq_len\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_ds\u001b[49m\u001b[43m.\u001b[49m\u001b[43mX\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m.to(device)\n\u001b[32m      6\u001b[39m history = model.fit(train_loader,\n\u001b[32m      7\u001b[39m           test_loader,\n\u001b[32m      8\u001b[39m           \u001b[32m200\u001b[39m,\n\u001b[32m      9\u001b[39m           nn.CrossEntropyLoss(),\n\u001b[32m     10\u001b[39m           RMSprop(model.parameters(), lr=\u001b[32m5e-5\u001b[39m, weight_decay=\u001b[32m1e-5\u001b[39m),\n\u001b[32m     11\u001b[39m           device)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[31]\u001b[39m\u001b[32m, line 24\u001b[39m, in \u001b[36mEEGHybrid.__init__\u001b[39m\u001b[34m(self, n_features, n_classes, seq_len)\u001b[39m\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m     23\u001b[39m     dummy = torch.zeros(\u001b[32m1\u001b[39m, \u001b[32m1\u001b[39m, seq_len, n_features)\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m     cnn_out_size = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcnn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdummy\u001b[49m\u001b[43m)\u001b[49m.shape[\u001b[32m1\u001b[39m]\n\u001b[32m     26\u001b[39m \u001b[38;5;66;03m# ----- Final classifier -----\u001b[39;00m\n\u001b[32m     27\u001b[39m \u001b[38;5;28mself\u001b[39m.fc = nn.Linear(\u001b[32m64\u001b[39m + cnn_out_size, n_classes)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/container.py:244\u001b[39m, in \u001b[36mSequential.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    242\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[32m    243\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m244\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    245\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/pooling.py:773\u001b[39m, in \u001b[36mAvgPool2d.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    772\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mavg_pool2d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    774\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    775\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkernel_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    776\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    777\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    778\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mceil_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    779\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcount_include_pad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    780\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdivisor_override\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    781\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mRuntimeError\u001b[39m: Given input size: (32x1x19). Calculated output size: (32x0x9). Output size is too small"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(train_ds.X.shape)\n",
    "model = EEGHybrid(n_features=train_ds.X.shape[3],\n",
    "                  n_classes=2,\n",
    "                  seq_len=train_ds.X.shape[1]).to(device)\n",
    "history = model.fit(train_loader,\n",
    "          test_loader,\n",
    "          200,\n",
    "          nn.CrossEntropyLoss(),\n",
    "          RMSprop(model.parameters(), lr=5e-5, weight_decay=1e-5),\n",
    "          device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e20ab9a3-cf9a-4fbf-b321-8d29d0797a49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Accuracy: 0.7856280193236715\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.94      0.83       925\n",
      "           1       0.88      0.59      0.71       731\n",
      "\n",
      "    accuracy                           0.79      1656\n",
      "   macro avg       0.81      0.77      0.77      1656\n",
      "weighted avg       0.81      0.79      0.78      1656\n",
      "\n",
      "[[868  57]\n",
      " [298 433]]\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "all_preds, all_labels = [], []\n",
    "with torch.no_grad():\n",
    "    for xb, yb in test_loader:\n",
    "        xb = xb.to(device)\n",
    "        preds = model(xb).argmax(1).cpu().numpy()\n",
    "        all_preds.append(preds)\n",
    "        all_labels.append(yb.numpy())\n",
    "\n",
    "all_preds = np.concatenate(all_preds)\n",
    "all_labels = np.concatenate(all_labels)\n",
    "\n",
    "print(\"\\nTest Accuracy:\", accuracy_score(all_labels, all_preds))\n",
    "print(classification_report(all_labels, all_preds))\n",
    "print(confusion_matrix(all_labels, all_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f5ba6aae-6a97-4f20-9edd-a31e8d0a355d",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'train_accs'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m plt.figure(figsize=(\u001b[32m12\u001b[39m, \u001b[32m4\u001b[39m))\n\u001b[32m      5\u001b[39m plt.subplot(\u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m, \u001b[32m1\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m plt.plot(\u001b[43mhistory\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtrain_accs\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m, label=\u001b[33m'\u001b[39m\u001b[33mTraining Accuracy\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      7\u001b[39m plt.plot(history[\u001b[33m'\u001b[39m\u001b[33mval_accs\u001b[39m\u001b[33m'\u001b[39m], label=\u001b[33m'\u001b[39m\u001b[33mValidation Accuracy\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      8\u001b[39m plt.title(\u001b[33m'\u001b[39m\u001b[33mModel Accuracy\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mKeyError\u001b[39m: 'train_accs'"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history['train_accs'], label='Training Accuracy')\n",
    "plt.plot(history['val_accs'], label='Validation Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history['train_losses'], label='Training Loss')\n",
    "plt.plot(history['val_losses'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a44a95e4-3107-4685-b3c1-8b5acc451aaf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

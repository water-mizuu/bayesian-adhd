{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7abd7b09",
   "metadata": {},
   "source": [
    "# EEG Model Activation Map Visualization\n",
    "\n",
    "This notebook loads the trained CNN-LSTM model and generates activation maps to visualize:\n",
    "1. **Gradient-based Saliency Maps** - Which input features influence the prediction most\n",
    "2. **CNN Feature Maps** - What the convolutional layers are learning\n",
    "3. **Class Activation Maps (CAM)** - Spatial importance for ADHD vs Control classification\n",
    "4. **LSTM Attention Weights** - Temporal importance across frequency bands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6810ca08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e215f1a",
   "metadata": {},
   "source": [
    "## 1. Load Model Architecture and Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd43803",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model architecture\n",
    "class EEG_CNN_LSTM_HPO(nn.Module):\n",
    "    def __init__(self,\n",
    "                cnn_kernels_1=32,\n",
    "                cnn_kernel_size_1=3,\n",
    "                cnn_kernels_2=64,\n",
    "                cnn_kernel_size_2=3,\n",
    "                cnn_dropout=0.3,\n",
    "                cnn_dense=64,\n",
    "                lstm_hidden_size=64,\n",
    "                lstm_layers=2,\n",
    "                lstm_dense=64,\n",
    "                dropout=0.3,\n",
    "                num_classes=2):\n",
    "        super().__init__()\n",
    "\n",
    "        # CNN feature extractor\n",
    "        pad1 = cnn_kernel_size_1 // 2\n",
    "        self.conv1 = nn.Conv2d(1, int(cnn_kernels_1), kernel_size=cnn_kernel_size_1, padding=pad1)\n",
    "        self.pool1 = nn.AvgPool2d(2)\n",
    "        pad2 = cnn_kernel_size_2 // 2\n",
    "        self.conv2 = nn.Conv2d(int(cnn_kernels_1), int(cnn_kernels_2), kernel_size=cnn_kernel_size_2, padding=pad2)\n",
    "        self.pool2 = nn.AvgPool2d(2)\n",
    "        self.cnn_dropout = nn.Dropout(cnn_dropout)\n",
    "\n",
    "        # Compute dims after CNN\n",
    "        with torch.no_grad():\n",
    "            dummy = torch.zeros(1, 1, 77, 19)\n",
    "            out = self._forward_cnn(dummy)\n",
    "            self.seq_len = out.size(-1)\n",
    "            self.feature_dim = out.size(1) * out.size(2)\n",
    "\n",
    "        self.cnn_dense = nn.Linear(self.feature_dim, int(cnn_dense))\n",
    "\n",
    "        # LSTM\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=int(cnn_dense),\n",
    "            hidden_size=int(lstm_hidden_size),\n",
    "            num_layers=int(lstm_layers),\n",
    "            batch_first=True,\n",
    "            dropout=dropout if lstm_layers > 1 else 0.0\n",
    "        )\n",
    "\n",
    "        self.lstm_dense = nn.Linear(int(lstm_hidden_size), int(lstm_dense))\n",
    "\n",
    "        # Classifier\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(int(lstm_dense), num_classes)\n",
    "        )\n",
    "        \n",
    "        # For storing activations\n",
    "        self.conv1_activations = None\n",
    "        self.conv2_activations = None\n",
    "        self.lstm_outputs = None\n",
    "\n",
    "    def _forward_cnn(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool1(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool2(x)\n",
    "        x = self.cnn_dropout(x)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x, save_activations=False):\n",
    "        # CNN extraction\n",
    "        if save_activations:\n",
    "            x = F.relu(self.conv1(x))\n",
    "            self.conv1_activations = x.clone()\n",
    "            x = self.pool1(x)\n",
    "            x = F.relu(self.conv2(x))\n",
    "            self.conv2_activations = x.clone()\n",
    "            x = self.pool2(x)\n",
    "            x = self.cnn_dropout(x)\n",
    "        else:\n",
    "            x = self._forward_cnn(x)\n",
    "\n",
    "        # Prepare for LSTM\n",
    "        x = x.permute(0, 3, 1, 2)\n",
    "        x = x.reshape(x.size(0), x.size(1), -1)\n",
    "        x = F.relu(self.cnn_dense(x))\n",
    "\n",
    "        # LSTM\n",
    "        if save_activations:\n",
    "            lstm_out, (h_n, _) = self.lstm(x)\n",
    "            self.lstm_outputs = lstm_out.clone()\n",
    "            out = h_n[-1]\n",
    "        else:\n",
    "            _, (h_n, _) = self.lstm(x)\n",
    "            out = h_n[-1]\n",
    "\n",
    "        # Classifier\n",
    "        out = F.relu(self.lstm_dense(out))\n",
    "        return self.classifier(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b5e481",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the trained model\n",
    "params = {'batch_size': 80, 'cnn_dense': 256, 'cnn_dropout': np.float64(0.38218620920862145), 'cnn_kernel_size_1': 5, 'cnn_kernel_size_2': 5, 'cnn_kernels_1': 48, 'cnn_kernels_2': 32, 'learning_rate': np.float64(0.0017576118123159641), 'lstm_dense': 32, 'lstm_hidden_size': 128, 'lstm_layers': 3, 'optimizer': 'rmsprop'}\n",
    "\n",
    "model = EEG_CNN_LSTM_HPO(\n",
    "    cnn_kernels_1=params['cnn_kernels_1'],\n",
    "    cnn_kernel_size_1=params['cnn_kernel_size_1'],\n",
    "    cnn_kernels_2=params['cnn_kernels_2'],\n",
    "    cnn_dropout=float(params['cnn_dropout']),\n",
    "    cnn_dense=params['cnn_dense'],\n",
    "    lstm_hidden_size=params['lstm_hidden_size'],\n",
    "    lstm_layers=params['lstm_layers'],\n",
    "    lstm_dense=params['lstm_dense'],\n",
    "    dropout=float(params['cnn_dropout']),  # use cnn_dropout as a simple shared dropout param\n",
    "    num_classes=2\n",
    ").to(device)\n",
    "model.load_state_dict(torch.load('exports/eeg_cnn_lstm_hpo.pth', map_location=device))\n",
    "model.eval()\n",
    "print(\"✓ Model loaded successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3715f36",
   "metadata": {},
   "source": [
    "## 2. Load Test Data and Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4e19e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load EEGScaler\n",
    "class EEGScaler:\n",
    "    \"\"\"Standardize EEG data per electrode (channel).\"\"\"\n",
    "    def __init__(self):\n",
    "        self.mean_ = None\n",
    "        self.scale_ = None\n",
    "\n",
    "    def fit(self, X):\n",
    "        self.mean_ = X.mean(axis=(0, 1), keepdims=True)\n",
    "        self.scale_ = X.std(axis=(0, 1), keepdims=True) + 1e-8\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return (X - self.mean_) / self.scale_\n",
    "\n",
    "    def fit_transform(self, X):\n",
    "        return self.fit(X).transform(X)\n",
    "\n",
    "    def inverse_transform(self, X_scaled):\n",
    "        return X_scaled * self.scale_ + self.mean_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0098bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a sample EEG file for visualization\n",
    "sample_file = 'extracted_eegs/v107.csv'  # Change this to test different subjects\n",
    "sample_df = pd.read_csv(sample_file)\n",
    "\n",
    "print(f\"Loaded sample: {sample_file}\")\n",
    "print(f\"Shape: {sample_df.shape}\")\n",
    "print(f\"Electrodes: {sample_df.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "776b4e19",
   "metadata": {},
   "source": [
    "## 3. Preprocess Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396cd48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert raw EEG to frequency domain representation (matching training data format)\n",
    "from scipy.signal import welch\n",
    "\n",
    "SAMPLE_RATE = 128  # Hz\n",
    "\n",
    "def eeg_to_frequency_features(df, sfreq=SAMPLE_RATE, nperseg=256):\n",
    "    \"\"\"\n",
    "    Convert time-domain EEG to frequency-domain features matching training format.\n",
    "    Returns shape: (n_windows, n_frequencies, n_electrodes)\n",
    "    \"\"\"\n",
    "    electrodes = df.columns.tolist()\n",
    "    n_electrodes = len(electrodes)\n",
    "    \n",
    "    # Compute PSD for each electrode\n",
    "    psd_list = []\n",
    "    for electrode in electrodes:\n",
    "        signal = df[electrode].to_numpy()\n",
    "        freqs, psd = welch(signal, sfreq, nperseg=nperseg)\n",
    "        psd_list.append(psd)\n",
    "    \n",
    "    # Stack: (n_electrodes, n_frequencies)\n",
    "    psd_matrix = np.array(psd_list).T  # (n_frequencies, n_electrodes)\n",
    "    \n",
    "    # Add window dimension (treating as single window)\n",
    "    psd_matrix = psd_matrix[np.newaxis, ...]  # (1, n_frequencies, n_electrodes)\n",
    "    \n",
    "    return psd_matrix, freqs, electrodes\n",
    "\n",
    "# Process sample\n",
    "X_sample, freqs, electrodes = eeg_to_frequency_features(sample_df)\n",
    "print(f\"Frequency features shape: {X_sample.shape}\")\n",
    "print(f\"Frequency range: {freqs[0]:.2f} - {freqs[-1]:.2f} Hz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a323c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load scaler and normalize\n",
    "with open('saved_scaler.pkl', 'rb') as f:\n",
    "    scaler = pickle.load(f)\n",
    "\n",
    "# Add channel dimension and scale\n",
    "X_sample = X_sample[..., np.newaxis]  # (1, freq, electrodes, 1)\n",
    "X_sample_scaled = scaler.transform(X_sample)\n",
    "\n",
    "# Convert to tensor\n",
    "X_tensor = torch.tensor(X_sample_scaled, dtype=torch.float32).permute(0, 3, 1, 2)  # (1, 1, freq, electrodes)\n",
    "X_tensor = X_tensor.to(device)\n",
    "\n",
    "print(f\"Model input shape: {X_tensor.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b01995",
   "metadata": {},
   "source": [
    "## 4. Make Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ed1940",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get prediction\n",
    "with torch.no_grad():\n",
    "    output = model(X_tensor)\n",
    "    probabilities = F.softmax(output, dim=1)\n",
    "    predicted_class = torch.argmax(probabilities, dim=1).item()\n",
    "    confidence = probabilities[0, predicted_class].item()\n",
    "\n",
    "class_names = ['ADHD', 'Control']\n",
    "print(f\"\\nPrediction: {class_names[predicted_class]}\")\n",
    "print(f\"Confidence: {confidence:.2%}\")\n",
    "print(f\"\\nClass probabilities:\")\n",
    "for i, name in enumerate(class_names):\n",
    "    print(f\"  {name}: {probabilities[0, i].item():.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788452d2",
   "metadata": {},
   "source": [
    "## 5. Generate Gradient-Based Saliency Map\n",
    "\n",
    "This shows which input features (frequency × electrode combinations) most influence the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ac02c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_saliency_map(model, input_tensor, target_class):\n",
    "    \"\"\"\n",
    "    Compute gradient-based saliency map.\n",
    "    Higher values indicate more important features for the prediction.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    input_tensor.requires_grad = True\n",
    "    \n",
    "    # Forward pass\n",
    "    output = model(input_tensor)\n",
    "    \n",
    "    # Backward pass for target class\n",
    "    model.zero_grad()\n",
    "    output[0, target_class].backward()\n",
    "    \n",
    "    # Get gradients\n",
    "    saliency = input_tensor.grad.data.abs().squeeze().cpu().numpy()\n",
    "    \n",
    "    return saliency\n",
    "\n",
    "# Compute saliency map for predicted class\n",
    "saliency_map = compute_saliency_map(model, X_tensor, predicted_class)\n",
    "print(f\"Saliency map shape: {saliency_map.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e873d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize saliency map\n",
    "fig, ax = plt.subplots(figsize=(14, 8))\n",
    "\n",
    "# Limit to 0-40 Hz for better visualization\n",
    "freq_mask = freqs <= 40\n",
    "freqs_plot = freqs[freq_mask]\n",
    "saliency_plot = saliency_map[:len(freqs_plot), :]\n",
    "\n",
    "im = ax.imshow(saliency_plot, aspect='auto', cmap='hot', interpolation='bilinear')\n",
    "ax.set_xlabel('Electrodes', fontsize=12)\n",
    "ax.set_ylabel('Frequency (Hz)', fontsize=12)\n",
    "ax.set_title(f'Saliency Map - {class_names[predicted_class]} Prediction\\n' + \n",
    "             f'(Brighter = More Important for Classification)', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Set electrode labels\n",
    "ax.set_xticks(range(len(electrodes)))\n",
    "ax.set_xticklabels(electrodes, rotation=45, ha='right')\n",
    "\n",
    "# Set frequency labels\n",
    "y_ticks = np.linspace(0, len(freqs_plot)-1, 10, dtype=int)\n",
    "ax.set_yticks(y_ticks)\n",
    "ax.set_yticklabels([f'{freqs_plot[i]:.1f}' for i in y_ticks])\n",
    "\n",
    "# Add frequency band regions\n",
    "bands = [\n",
    "    (0.5, 4, 'Delta', 'purple'),\n",
    "    (4, 8, 'Theta', 'blue'),\n",
    "    (8, 13, 'Alpha', 'green'),\n",
    "    (13, 30, 'Beta', 'orange')\n",
    "]\n",
    "\n",
    "for low, high, name, color in bands:\n",
    "    low_idx = np.argmin(np.abs(freqs_plot - low))\n",
    "    high_idx = np.argmin(np.abs(freqs_plot - high))\n",
    "    ax.axhspan(low_idx, high_idx, alpha=0.1, color=color, label=name)\n",
    "\n",
    "plt.colorbar(im, ax=ax, label='Gradient Magnitude')\n",
    "ax.legend(loc='upper right', fontsize=10)\n",
    "plt.tight_layout()\n",
    "plt.savefig('activation_maps/saliency_map.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Saliency map saved to activation_maps/saliency_map.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a79cadaa",
   "metadata": {},
   "source": [
    "## 6. Visualize CNN Feature Maps\n",
    "\n",
    "This shows what patterns the convolutional layers are detecting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14d19ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward pass with activation saving\n",
    "with torch.no_grad():\n",
    "    _ = model(X_tensor, save_activations=True)\n",
    "\n",
    "conv1_act = model.conv1_activations.squeeze().cpu().numpy()\n",
    "conv2_act = model.conv2_activations.squeeze().cpu().numpy()\n",
    "\n",
    "print(f\"Conv1 activations shape: {conv1_act.shape}\")\n",
    "print(f\"Conv2 activations shape: {conv2_act.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219144cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize first layer feature maps (show first 16 filters)\n",
    "n_filters = min(16, conv1_act.shape[0])\n",
    "fig, axes = plt.subplots(4, 4, figsize=(16, 12))\n",
    "fig.suptitle('Conv1 Feature Maps (First 16 Filters)', fontsize=16, fontweight='bold')\n",
    "\n",
    "for idx, ax in enumerate(axes.flat):\n",
    "    if idx < n_filters:\n",
    "        im = ax.imshow(conv1_act[idx], aspect='auto', cmap='viridis')\n",
    "        ax.set_title(f'Filter {idx+1}', fontsize=10)\n",
    "        ax.axis('off')\n",
    "        plt.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
    "    else:\n",
    "        ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('activation_maps/conv1_feature_maps.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Conv1 feature maps saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca38941",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize second layer feature maps (show first 16 filters)\n",
    "n_filters = min(16, conv2_act.shape[0])\n",
    "fig, axes = plt.subplots(4, 4, figsize=(16, 12))\n",
    "fig.suptitle('Conv2 Feature Maps (First 16 Filters)', fontsize=16, fontweight='bold')\n",
    "\n",
    "for idx, ax in enumerate(axes.flat):\n",
    "    if idx < n_filters:\n",
    "        im = ax.imshow(conv2_act[idx], aspect='auto', cmap='viridis')\n",
    "        ax.set_title(f'Filter {idx+1}', fontsize=10)\n",
    "        ax.axis('off')\n",
    "        plt.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
    "    else:\n",
    "        ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('activation_maps/conv2_feature_maps.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Conv2 feature maps saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb4426f3",
   "metadata": {},
   "source": [
    "## 7. Visualize Average Feature Map per Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3aa638",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average across all filters to see overall activation pattern\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Conv1 average\n",
    "conv1_avg = conv1_act.mean(axis=0)\n",
    "im1 = ax1.imshow(conv1_avg, aspect='auto', cmap='plasma')\n",
    "ax1.set_title('Conv1 Average Activation', fontsize=14, fontweight='bold')\n",
    "ax1.set_xlabel('Width (Electrode dimension)', fontsize=12)\n",
    "ax1.set_ylabel('Height (Frequency dimension)', fontsize=12)\n",
    "plt.colorbar(im1, ax=ax1, label='Activation')\n",
    "\n",
    "# Conv2 average\n",
    "conv2_avg = conv2_act.mean(axis=0)\n",
    "im2 = ax2.imshow(conv2_avg, aspect='auto', cmap='plasma')\n",
    "ax2.set_title('Conv2 Average Activation', fontsize=14, fontweight='bold')\n",
    "ax2.set_xlabel('Width (Electrode dimension)', fontsize=12)\n",
    "ax2.set_ylabel('Height (Frequency dimension)', fontsize=12)\n",
    "plt.colorbar(im2, ax=ax2, label='Activation')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('activation_maps/average_activations.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Average activation maps saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c3d11b",
   "metadata": {},
   "source": [
    "## 8. LSTM Temporal Attention Analysis\n",
    "\n",
    "Visualize which temporal positions (frequency bands) the LSTM focuses on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4384ae4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get LSTM outputs\n",
    "lstm_out = model.lstm_outputs.squeeze().cpu().numpy()  # (seq_len, hidden_size)\n",
    "print(f\"LSTM outputs shape: {lstm_out.shape}\")\n",
    "\n",
    "# Compute attention as the magnitude of each time step\n",
    "temporal_attention = np.linalg.norm(lstm_out, axis=1)\n",
    "temporal_attention = temporal_attention / temporal_attention.max()  # Normalize\n",
    "\n",
    "print(f\"Temporal attention shape: {temporal_attention.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a585039a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize temporal attention\n",
    "fig, ax = plt.subplots(figsize=(14, 6))\n",
    "\n",
    "time_steps = np.arange(len(temporal_attention))\n",
    "ax.bar(time_steps, temporal_attention, color='steelblue', alpha=0.7, edgecolor='navy')\n",
    "ax.set_xlabel('Temporal Position (Electrode-related sequence)', fontsize=12)\n",
    "ax.set_ylabel('Attention Weight (Normalized)', fontsize=12)\n",
    "ax.set_title('LSTM Temporal Attention Weights\\n(Higher values = More important for classification)', \n",
    "             fontsize=14, fontweight='bold')\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('activation_maps/lstm_temporal_attention.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ LSTM temporal attention saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6997c52f",
   "metadata": {},
   "source": [
    "## 9. Feature Importance by Electrode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d139229",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sum saliency across frequencies for each electrode\n",
    "electrode_importance = saliency_map.sum(axis=0)\n",
    "electrode_importance = electrode_importance / electrode_importance.max()  # Normalize\n",
    "\n",
    "# Create DataFrame for visualization\n",
    "importance_df = pd.DataFrame({\n",
    "    'Electrode': electrodes,\n",
    "    'Importance': electrode_importance\n",
    "}).sort_values('Importance', ascending=True)\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "bars = ax.barh(importance_df['Electrode'], importance_df['Importance'], \n",
    "                color='coral', edgecolor='darkred', alpha=0.8)\n",
    "\n",
    "# Highlight top 5\n",
    "for i, bar in enumerate(bars[-5:]):\n",
    "    bar.set_color('crimson')\n",
    "    bar.set_alpha(1.0)\n",
    "\n",
    "ax.set_xlabel('Normalized Importance', fontsize=12)\n",
    "ax.set_ylabel('Electrode', fontsize=12)\n",
    "ax.set_title(f'Electrode Importance for {class_names[predicted_class]} Classification\\n' + \n",
    "             '(Top 5 highlighted in red)', fontsize=14, fontweight='bold')\n",
    "ax.grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('activation_maps/electrode_importance.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nTop 5 Most Important Electrodes:\")\n",
    "print(importance_df.tail(5).to_string(index=False))\n",
    "print(\"\\n✓ Electrode importance saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08cf55b5",
   "metadata": {},
   "source": [
    "## 10. Feature Importance by Frequency Band"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70090cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define frequency bands\n",
    "bands = [\n",
    "    (0.5, 4, 'Delta'),\n",
    "    (4, 8, 'Theta'),\n",
    "    (8, 13, 'Alpha'),\n",
    "    (13, 30, 'Beta'),\n",
    "    (30, 40, 'Gamma')\n",
    "]\n",
    "\n",
    "# Compute importance for each band\n",
    "band_importance = []\n",
    "for low, high, name in bands:\n",
    "    mask = (freqs >= low) & (freqs < high)\n",
    "    if mask.sum() > 0:\n",
    "        importance = saliency_map[mask, :].sum()\n",
    "        band_importance.append({'Band': name, 'Frequency': f'{low}-{high} Hz', 'Importance': importance})\n",
    "\n",
    "band_df = pd.DataFrame(band_importance)\n",
    "band_df['Importance'] = band_df['Importance'] / band_df['Importance'].max()\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "colors = ['purple', 'blue', 'green', 'orange', 'red']\n",
    "bars = ax.bar(band_df['Band'], band_df['Importance'], color=colors, alpha=0.7, edgecolor='black')\n",
    "\n",
    "ax.set_ylabel('Normalized Importance', fontsize=12)\n",
    "ax.set_xlabel('Frequency Band', fontsize=12)\n",
    "ax.set_title(f'Frequency Band Importance for {class_names[predicted_class]} Classification', \n",
    "             fontsize=14, fontweight='bold')\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "            f'{height:.2f}',\n",
    "            ha='center', va='bottom', fontsize=10, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('activation_maps/band_importance.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nFrequency Band Importance:\")\n",
    "print(band_df.to_string(index=False))\n",
    "print(\"\\n✓ Band importance saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb0a19b",
   "metadata": {},
   "source": [
    "## 11. Create Summary Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948a8001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive summary figure\n",
    "fig = plt.figure(figsize=(20, 12))\n",
    "gs = fig.add_gridspec(3, 3, hspace=0.3, wspace=0.3)\n",
    "\n",
    "# 1. Saliency Map\n",
    "ax1 = fig.add_subplot(gs[0:2, 0:2])\n",
    "im1 = ax1.imshow(saliency_plot, aspect='auto', cmap='hot', interpolation='bilinear')\n",
    "ax1.set_xlabel('Electrodes', fontsize=10)\n",
    "ax1.set_ylabel('Frequency (Hz)', fontsize=10)\n",
    "ax1.set_title('Saliency Map', fontsize=12, fontweight='bold')\n",
    "ax1.set_xticks(range(len(electrodes)))\n",
    "ax1.set_xticklabels(electrodes, rotation=45, ha='right', fontsize=8)\n",
    "y_ticks = np.linspace(0, len(freqs_plot)-1, 8, dtype=int)\n",
    "ax1.set_yticks(y_ticks)\n",
    "ax1.set_yticklabels([f'{freqs_plot[i]:.1f}' for i in y_ticks], fontsize=8)\n",
    "plt.colorbar(im1, ax=ax1, fraction=0.046, pad=0.04)\n",
    "\n",
    "# 2. Electrode Importance\n",
    "ax2 = fig.add_subplot(gs[0, 2])\n",
    "top_5_electrodes = importance_df.tail(5)\n",
    "ax2.barh(top_5_electrodes['Electrode'], top_5_electrodes['Importance'], \n",
    "         color='crimson', alpha=0.8)\n",
    "ax2.set_xlabel('Importance', fontsize=10)\n",
    "ax2.set_title('Top 5 Electrodes', fontsize=12, fontweight='bold')\n",
    "ax2.grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "# 3. Band Importance\n",
    "ax3 = fig.add_subplot(gs[1, 2])\n",
    "ax3.bar(band_df['Band'], band_df['Importance'], color=colors, alpha=0.7, edgecolor='black')\n",
    "ax3.set_ylabel('Importance', fontsize=10)\n",
    "ax3.set_title('Frequency Bands', fontsize=12, fontweight='bold')\n",
    "ax3.tick_params(axis='x', rotation=45)\n",
    "ax3.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# 4. Prediction Info\n",
    "ax4 = fig.add_subplot(gs[2, 0])\n",
    "ax4.axis('off')\n",
    "info_text = f\"\"\"PREDICTION SUMMARY\n",
    "\n",
    "Sample: {sample_file.split('/')[-1]}\n",
    "Predicted Class: {class_names[predicted_class]}\n",
    "Confidence: {confidence:.2%}\n",
    "\n",
    "Class Probabilities:\n",
    "  ADHD: {probabilities[0, 0].item():.2%}\n",
    "  Control: {probabilities[0, 1].item():.2%}\n",
    "\"\"\"\n",
    "ax4.text(0.1, 0.5, info_text, fontsize=11, verticalalignment='center',\n",
    "         bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5),\n",
    "         family='monospace')\n",
    "\n",
    "# 5. Conv1 Average\n",
    "ax5 = fig.add_subplot(gs[2, 1])\n",
    "im5 = ax5.imshow(conv1_avg, aspect='auto', cmap='plasma')\n",
    "ax5.set_title('Conv1 Avg Activation', fontsize=12, fontweight='bold')\n",
    "ax5.set_xlabel('Width', fontsize=10)\n",
    "ax5.set_ylabel('Height', fontsize=10)\n",
    "plt.colorbar(im5, ax=ax5, fraction=0.046, pad=0.04)\n",
    "\n",
    "# 6. Conv2 Average\n",
    "ax6 = fig.add_subplot(gs[2, 2])\n",
    "im6 = ax6.imshow(conv2_avg, aspect='auto', cmap='plasma')\n",
    "ax6.set_title('Conv2 Avg Activation', fontsize=12, fontweight='bold')\n",
    "ax6.set_xlabel('Width', fontsize=10)\n",
    "ax6.set_ylabel('Height', fontsize=10)\n",
    "plt.colorbar(im6, ax=ax6, fraction=0.046, pad=0.04)\n",
    "\n",
    "fig.suptitle('EEG Model Activation Analysis - Complete Summary', \n",
    "             fontsize=16, fontweight='bold', y=0.995)\n",
    "\n",
    "plt.savefig('activation_maps/complete_summary.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n✓ Complete summary visualization saved to activation_maps/complete_summary.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e2b11da",
   "metadata": {},
   "source": [
    "## 12. Export Results to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3921405",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save numerical results\n",
    "results = {\n",
    "    'sample': sample_file.split('/')[-1],\n",
    "    'predicted_class': class_names[predicted_class],\n",
    "    'confidence': confidence,\n",
    "    'adhd_probability': probabilities[0, 0].item(),\n",
    "    'control_probability': probabilities[0, 1].item(),\n",
    "}\n",
    "\n",
    "# Add top electrodes\n",
    "for i, row in enumerate(importance_df.tail(5).iterrows(), 1):\n",
    "    results[f'top_electrode_{i}'] = row[1]['Electrode']\n",
    "    results[f'top_electrode_{i}_importance'] = row[1]['Importance']\n",
    "\n",
    "# Add band importance\n",
    "for _, row in band_df.iterrows():\n",
    "    results[f'{row[\"Band\"].lower()}_importance'] = row['Importance']\n",
    "\n",
    "results_df = pd.DataFrame([results])\n",
    "results_df.to_csv('activation_maps/activation_analysis_results.csv', index=False)\n",
    "\n",
    "print(\"\\n✓ Results exported to activation_maps/activation_analysis_results.csv\")\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ANALYSIS COMPLETE\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nGenerated files:\")\n",
    "print(\"  - saliency_map.png\")\n",
    "print(\"  - conv1_feature_maps.png\")\n",
    "print(\"  - conv2_feature_maps.png\")\n",
    "print(\"  - average_activations.png\")\n",
    "print(\"  - lstm_temporal_attention.png\")\n",
    "print(\"  - electrode_importance.png\")\n",
    "print(\"  - band_importance.png\")\n",
    "print(\"  - complete_summary.png\")\n",
    "print(\"  - activation_analysis_results.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "483a028f",
   "metadata": {},
   "source": [
    "## 13. Batch Process Multiple Samples (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8dcd11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to process multiple samples\n",
    "\"\"\"\n",
    "from pathlib import Path\n",
    "\n",
    "sample_files = sorted(Path('extracted_eegs').glob('*.csv'))[:5]  # Process first 5\n",
    "all_results = []\n",
    "\n",
    "for sample_path in sample_files:\n",
    "    print(f\"\\nProcessing {sample_path.name}...\")\n",
    "    \n",
    "    # Load and process\n",
    "    df = pd.read_csv(sample_path)\n",
    "    X, freqs, electrodes = eeg_to_frequency_features(df)\n",
    "    X = X[..., np.newaxis]\n",
    "    X = scaler.transform(X)\n",
    "    X_tensor = torch.tensor(X, dtype=torch.float32).permute(0, 3, 1, 2).to(device)\n",
    "    \n",
    "    # Predict\n",
    "    with torch.no_grad():\n",
    "        output = model(X_tensor)\n",
    "        probs = F.softmax(output, dim=1)\n",
    "        pred = torch.argmax(probs, dim=1).item()\n",
    "        conf = probs[0, pred].item()\n",
    "    \n",
    "    # Compute saliency\n",
    "    saliency = compute_saliency_map(model, X_tensor, pred)\n",
    "    \n",
    "    # Save results\n",
    "    result = {\n",
    "        'sample': sample_path.name,\n",
    "        'predicted_class': class_names[pred],\n",
    "        'confidence': conf\n",
    "    }\n",
    "    all_results.append(result)\n",
    "    \n",
    "    # Save individual saliency map\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    plt.imshow(saliency[:len(freqs_plot), :], aspect='auto', cmap='hot')\n",
    "    plt.title(f'{sample_path.stem} - {class_names[pred]} ({conf:.2%})')\n",
    "    plt.colorbar(label='Gradient Magnitude')\n",
    "    plt.savefig(f'activation_maps/{sample_path.stem}_saliency.png', dpi=150)\n",
    "    plt.close()\n",
    "\n",
    "# Save batch results\n",
    "batch_df = pd.DataFrame(all_results)\n",
    "batch_df.to_csv('activation_maps/batch_results.csv', index=False)\n",
    "print(f\"\\n✓ Processed {len(all_results)} samples\")\n",
    "\"\"\"\n",
    "pass"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
